---
title: 18、缓存失效：重新计算换缓存空间
---
## 📚 目录

1. [缓存失效的基本概念](#1-缓存失效的基本概念)
2. [时间与空间的权衡体现](#2-时间与空间的权衡体现)
3. [LRU最近最少使用算法](#3-LRU最近最少使用算法)
4. [TTL时间驱动清理机制](#4-TTL时间驱动清理机制)
5. [缓存预热策略](#5-缓存预热策略)
6. [多级缓存淘汰管理](#6-多级缓存淘汰管理)
7. [实际应用场景分析](#7-实际应用场景分析)
8. [核心要点总结](#8-核心要点总结)

---

## 1. 🗂️ 缓存失效的基本概念


### 1.1 什么是缓存失效


**通俗理解**：就像家里的冰箱空间有限，当东西放满了，我们需要清理掉一些食物来腾出空间

```
缓存失效的本质：
旧数据 → 清除 → 释放空间 → 需要时重新获取

就像：
冰箱满了 → 扔掉过期食物 → 腾出空间 → 需要时重新购买
```

**核心定义**：
- **缓存失效**：主动移除缓存中的数据来释放存储空间
- **目的**：在有限的内存空间中，保持最有价值的数据
- **代价**：数据被清除后，再次需要时必须重新计算或获取

### 1.2 为什么需要缓存失效


**空间限制的现实**：
```
服务器内存：8GB
数据库大小：100GB
显然：不可能把所有数据都缓存在内存中

解决方案：
✅ 只缓存最常用的数据
✅ 定期清理不常用的数据  
✅ 需要时重新加载数据
```

**生活中的类比**：
```
手机相册：
空间有限 → 删除旧照片 → 释放空间 → 拍新照片
需要旧照片时 → 从云盘重新下载 → 花费时间但节省空间

缓存系统：
内存有限 → 删除旧数据 → 释放空间 → 存储新数据  
需要旧数据时 → 从数据库重新查询 → 花费时间但节省空间
```

---

## 2. ⚖️ 时间与空间的权衡体现


### 2.1 权衡的核心矛盾


**基本矛盾**：我们总是希望数据访问既快又不占太多空间，但现实中必须做选择

```
理想状态：
┌─────────────┐
│  访问速度快  │ ← 所有数据都在内存中
│  +          │
│  占用空间少  │ ← 内存使用量很小
└─────────────┘
↑ 这是不可能的！

现实选择：
方案A：更多缓存          方案B：更少缓存
┌─────────────┐         ┌─────────────┐
│ 访问速度：快 │         │ 访问速度：慢 │
│ 占用空间：大 │   VS    │ 占用空间：小 │  
└─────────────┘         └─────────────┘
```

### 2.2 具体权衡场景


**场景1：电商网站商品信息**
```
选择A - 缓存所有商品：
✅ 优点：用户访问任何商品都很快
❌ 缺点：需要大量内存（可能几GB）

选择B - 只缓存热门商品：
✅ 优点：内存使用少（可能几百MB）
❌ 缺点：访问冷门商品需要查数据库（慢几十毫秒）

实际选择：选择B，因为80%的用户只看20%的商品
```

**场景2：用户会话信息**
```
选择A - 永久缓存所有用户会话：
✅ 优点：任何用户操作都不需要重新验证
❌ 缺点：内存会无限增长，最终崩溃

选择B - 定时清理过期会话：
✅ 优点：内存使用可控
❌ 缺点：用户可能需要重新登录（体验略差但可接受）

实际选择：选择B，设置会话30分钟过期
```

### 2.3 权衡的量化分析


**成本收益分析表**：

| 策略类型 | **内存占用** | **访问速度** | **重建成本** | **适用场景** |
|---------|------------|-------------|-------------|-------------|
| 🔥 **激进缓存** | `高（80%+内存）` | `极快（<1ms）` | `低（很少重建）` | `读多写少，内存充足` |
| ⚖️ **均衡缓存** | `中（30-50%内存）` | `较快（1-10ms）` | `中等` | `一般业务场景` |
| 💾 **保守缓存** | `低（<20%内存）` | `慢（10-100ms）` | `高（频繁重建）` | `内存紧张，实时性要求不高` |

---

## 3. 🔄 LRU最近最少使用算法


### 3.1 LRU算法的基本思想


**核心理念**：最近用过的东西，未来还可能会用；很久没用的东西，未来用到的可能性小

```
生活中的例子：
你的书桌只能放5本书，现在已经放满了：
[数学书][语文书][英语书][物理书][化学书]

现在要放一本新的历史书，怎么办？
LRU策略：把最久没翻过的书收起来，给新书让位置

如果化学书是最久没用的：
[数学书][语文书][英语书][物理书][历史书] ← 化学书被移除
```

### 3.2 LRU的工作机制


**访问更新机制**：
```
初始状态（容量3）：
[A] [B] [C]
↑ 最新   ↑ 最旧

访问B：B移到最前面
[B] [A] [C]
↑ 最新   ↑ 最旧

插入新数据D：C被淘汰
[D] [B] [A]
↑ 最新   ↑ 最旧
```

**简化的Python实现理解**：
```python
class SimpleLRU:
    def __init__(self, capacity):
        self.capacity = capacity
        self.cache = {}  # 存储数据
        self.order = []  # 记录使用顺序
    
    def get(self, key):
        if key in self.cache:
            # 移到最前面（标记为最近使用）
            self.order.remove(key)
            self.order.append(key)
            return self.cache[key]
        return None
    
    def put(self, key, value):
        if len(self.cache) >= self.capacity:
            # 移除最少使用的（列表第一个）
            oldest = self.order.pop(0)
            del self.cache[oldest]
        
        self.cache[key] = value
        self.order.append(key)
```

### 3.3 LRU的适用场景


**✅ 适合LRU的场景**：
```
Web页面缓存：
- 热门页面被频繁访问
- 冷门页面很少被访问
- LRU可以自动保持热门页面在缓存中

数据库查询结果缓存：
- 某些查询经常执行
- 某些查询很少执行  
- LRU让常用查询结果保持可用
```

**❌ 不适合LRU的场景**：
```
循环访问模式：
A → B → C → D → A → B → C → D...
如果缓存容量是3，每次访问都会miss

解决方案：使用更大的缓存容量或其他算法
```

---

## 4. ⏰ TTL时间驱动清理机制


### 4.1 TTL的基本概念


**TTL全称**：Time To Live，生存时间，就像食物的保质期

```
食物保质期类比：
牛奶：保质期7天 → 7天后必须扔掉，无论是否变质
面包：保质期3天 → 3天后必须扔掉

缓存TTL：
用户信息：TTL 30分钟 → 30分钟后自动清理
商品价格：TTL 5分钟 → 5分钟后自动清理
```

**TTL的工作原理**：
```
数据存入时：记录当前时间 + TTL时长 = 过期时间
定期检查：当前时间 > 过期时间 → 删除数据

示例：
存入时间：14:00:00
TTL：30分钟  
过期时间：14:30:00
当前时间：14:35:00 → 数据过期，删除！
```

### 4.2 TTL的实现方式


**被动过期**：访问时检查
```java
class TTLCache {
    class CacheItem {
        Object value;
        long expireTime;
        
        boolean isExpired() {
            return System.currentTimeMillis() > expireTime;
        }
    }
    
    public Object get(String key) {
        CacheItem item = cache.get(key);
        if (item == null || item.isExpired()) {
            cache.remove(key);  // 清理过期数据
            return null;
        }
        return item.value;
    }
}
```

**主动过期**：定时清理
```java
// 每分钟执行一次清理任务
@Scheduled(fixedRate = 60000)
public void cleanExpiredData() {
    long now = System.currentTimeMillis();
    cache.entrySet().removeIf(entry -> 
        entry.getValue().expireTime < now);
}
```

### 4.3 TTL策略的选择


**不同数据的TTL设置**：

| 数据类型 | **TTL时长** | **原因** | **示例** |
|---------|-----------|---------|---------|
| 🔥 **实时数据** | `1-5分钟` | `变化频繁，需要保证时效性` | `股票价格、天气信息` |
| 📊 **准实时数据** | `10-30分钟` | `变化较频繁，允许短延迟` | `商品库存、用户在线状态` |
| 📋 **相对稳定数据** | `1-24小时` | `变化不频繁，可容忍长延迟` | `商品详情、用户基本信息` |
| 🗂️ **静态数据** | `7天或更长` | `很少变化，主要为了节省空间` | `配置信息、字典数据` |

---

## 5. 🚀 缓存预热策略


### 5.1 什么是缓存预热


**问题场景**：系统刚启动时，缓存是空的，用户访问会很慢

```
冷启动问题：
系统重启 → 缓存清空 → 第一批用户访问很慢 → 用户体验差

就像：
餐厅刚开门 → 什么菜都没准备 → 第一批客人等很久 → 客人不满意

解决思路：
餐厅提前准备 → 预制一些热门菜品 → 客人来了立即上菜

缓存预热：
系统启动时 → 预先加载热门数据 → 用户访问立即返回
```

### 5.2 预热策略的类型


**全量预热**：启动时加载所有数据
```java
@PostConstruct  // Spring启动时执行
public void warmUpCache() {
    List<Product> allProducts = productService.getAllProducts();
    for (Product product : allProducts) {
        cache.put("product:" + product.getId(), product);
    }
    log.info("缓存预热完成，加载{}个商品", allProducts.size());
}
```

**热点预热**：只加载热门数据（推荐）
```java
@PostConstruct
public void warmUpHotData() {
    // 加载最近30天访问最多的1000个商品
    List<Product> hotProducts = productService.getHotProducts(1000);
    for (Product product : hotProducts) {
        cache.put("product:" + product.getId(), product);
    }
    log.info("热点缓存预热完成，加载{}个热门商品", hotProducts.size());
}
```

**渐进式预热**：分批逐步加载
```java
@Scheduled(fixedDelay = 5000)  // 每5秒加载一批
public void gradualWarmUp() {
    if (!warmUpComplete) {
        List<Product> batch = getNextBatch(100);  // 每次100个
        for (Product product : batch) {
            cache.put("product:" + product.getId(), product);
        }
        if (batch.size() < 100) {
            warmUpComplete = true;
            log.info("渐进式预热完成");
        }
    }
}
```

### 5.3 预热策略的选择


**选择依据**：

```
数据量小（<1万条）：
→ 选择全量预热
→ 启动时间影响小，用户体验最好

数据量中等（1万-100万条）：
→ 选择热点预热  
→ 平衡启动时间和用户体验

数据量大（>100万条）：
→ 选择渐进式预热
→ 避免启动时间过长
```

---

## 6. 🏗️ 多级缓存淘汰管理


### 6.1 多级缓存的概念


**多级缓存**：就像家里的存储空间分层管理

```
家庭存储类比：
口袋（最快访问）→ 书桌（快速访问）→ 书柜（一般访问）→ 储物间（慢访问）
容量小，速度快    容量中，速度中    容量大，速度慢    容量很大，速度很慢

系统缓存分层：
L1缓存（内存）→ L2缓存（Redis）→ L3缓存（数据库缓存）→ 磁盘存储
容量小，速度快   容量中，速度中    容量大，速度慢        容量很大，速度很慢
```

### 6.2 多级淘汰的工作机制


**数据流动过程**：
```
查询流程：
用户请求 → L1缓存（命中？）→ L2缓存（命中？）→ L3缓存（命中？）→ 数据库
         ↓ 有数据              ↓ 有数据            ↓ 有数据
         直接返回              返回+存入L1         返回+存入L1,L2

淘汰流程：
L1满了 → 淘汰数据 → 部分数据降级到L2
L2满了 → 淘汰数据 → 部分数据降级到L3
L3满了 → 淘汰数据 → 数据彻底删除
```

### 6.3 不同级别的淘汰策略


**L1级缓存（内存）**：
```java
// 使用LRU，容量较小，淘汰频繁
LRUCache<String, Object> l1Cache = new LRUCache<>(1000);

// L1淘汰时，热点数据降级到L2
@Override
protected void onEvict(String key, Object value) {
    if (isHotData(key)) {
        l2Cache.put(key, value);  // 降级到L2
    }
}
```

**L2级缓存（Redis）**：
```java
// 使用TTL + LRU组合策略
@Cacheable(value = "products", expire = 3600)  // 1小时TTL
public Product getProduct(Long id) {
    return productService.findById(id);
}

// Redis配置：内存不足时自动LRU淘汰
redis.conf:
maxmemory 2gb
maxmemory-policy allkeys-lru
```

**L3级缓存（数据库缓存）**：
```sql
-- 数据库层面的缓存策略
-- 定期清理超过24小时的缓存记录
DELETE FROM cache_table 
WHERE create_time < NOW() - INTERVAL 24 HOUR;
```

---

## 7. 🌍 实际应用场景分析


### 7.1 Web缓存应用


**CDN内容分发网络**：
```
全球CDN节点缓存策略：
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   北京节点       │    │   上海节点       │    │   广州节点       │
│ LRU淘汰策略     │    │ LRU淘汰策略     │    │ LRU淘汰策略     │  
│ 容量：10GB      │    │ 容量：10GB      │    │ 容量：10GB      │
│ TTL：24小时     │    │ TTL：24小时     │    │ TTL：24小时     │
└─────────────────┘    └─────────────────┘    └─────────────────┘
        ↑                       ↑                       ↑
   命中率95%              命中率95%              命中率95%

未命中时：回源到中心服务器获取 → 时间稍长但节省大量存储空间
```

**浏览器缓存**：
```
浏览器缓存层次：
内存缓存（Memory Cache）→ 磁盘缓存（Disk Cache）→ 网络请求

淘汰策略：
- 内存缓存：页面关闭时清理
- 磁盘缓存：LRU + 容量限制（通常几GB）
- TTL控制：根据HTTP头的Cache-Control
```

### 7.2 数据库缓存应用


**MySQL查询缓存**：
```sql
-- 查询缓存配置
SET GLOBAL query_cache_size = 268435456;  -- 256MB
SET GLOBAL query_cache_type = ON;

-- 自动淘汰机制
- 表数据修改 → 相关缓存失效
- 内存不足 → LRU淘汰最少使用的查询
- 定期清理 → 清理过期的缓存项
```

**应用层数据库缓存**：
```java
@Service
public class UserService {
    
    @Cacheable(value = "users", key = "#id")
    public User getUserById(Long id) {
        return userRepository.findById(id);
    }
    
    @CacheEvict(value = "users", key = "#user.id")  
    public User updateUser(User user) {
        return userRepository.save(user);
    }
}

// 缓存配置
spring.cache.caffeine.spec=maximumSize=10000,expireAfterWrite=30m
```

### 7.3 分布式缓存应用


**Redis集群缓存**：
```
Redis主从 + 哨兵模式：
┌─────────────┐    ┌─────────────┐    ┌─────────────┐
│  Master     │    │   Slave1    │    │   Slave2    │
│  写入操作   │───▶│   读取操作   │    │   读取操作   │
│  LRU淘汰    │    │   LRU淘汰    │    │   LRU淘汰    │
└─────────────┘    └─────────────┘    └─────────────┘

数据一致性：
- 写入Master → 异步同步到Slave
- 主节点故障 → 哨兵自动切换
- 缓存失效 → 所有节点同步失效
```

---

## 8. 📋 核心要点总结


### 8.1 必须掌握的核心概念


```
🔸 缓存失效本质：用时间换空间，移除数据释放内存
🔸 LRU策略：最近最少使用的数据优先淘汰
🔸 TTL机制：基于时间自动过期清理
🔸 缓存预热：系统启动时预加载热点数据
🔸 多级管理：不同层级使用不同的淘汰策略
🔸 权衡选择：根据业务需求平衡时间和空间
```

### 8.2 关键理解要点


**🔹 缓存失效的权衡思维**
```
不是技术问题，而是资源分配问题：
- 有限的内存如何分配给无限的数据需求
- 快速访问与存储空间的永恒矛盾
- 业务价值驱动的技术决策
```

**🔹 策略选择的决策依据**
```
数据特征分析：
- 访问频率：高频数据优先保留
- 数据大小：大数据优先淘汰  
- 业务重要性：核心业务数据优先保留
- 重建成本：成本高的数据优先保留
```

**🔹 实际应用的平衡艺术**
```
没有完美的策略，只有合适的选择：
- 内存充足时：激进缓存，用空间换时间
- 内存紧张时：保守缓存，用时间换空间
- 访问模式稳定时：LRU效果好
- 访问模式多变时：TTL更可控
```

### 8.3 实际应用指导


**✅ 推荐的最佳实践**：
```
1. 组合使用多种策略：
   - 热点数据：长TTL + LRU保护
   - 一般数据：中等TTL + LRU淘汰
   - 临时数据：短TTL + 主动清理

2. 分层缓存设计：
   - L1：小容量，极速访问，LRU淘汰
   - L2：中容量，快速访问，TTL + LRU
   - L3：大容量，一般访问，定期清理

3. 监控和调优：
   - 缓存命中率监控
   - 内存使用率监控  
   - 淘汰频率监控
   - 根据监控数据调整策略
```

**⚠️ 常见误区避免**：
```
误区1：认为缓存越多越好
正解：适量缓存，避免内存溢出

误区2：所有数据使用相同TTL
正解：根据数据特性设置不同TTL

误区3：忽略缓存预热的重要性  
正解：冷启动时必须考虑预热策略

误区4：缓存策略一成不变
正解：根据业务发展调整缓存策略
```

**核心记忆**：
- 缓存失效本质是资源分配，用时间换空间
- LRU适合访问有热点的场景，TTL适合数据有时效的场景
- 多级缓存分而治之，不同层级用不同策略
- 缓存预热解决冷启动问题，提升用户体验
- 监控数据驱动策略调整，没有一成不变的最优解