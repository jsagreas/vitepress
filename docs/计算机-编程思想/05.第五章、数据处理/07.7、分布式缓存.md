---
title: 7ã€åˆ†å¸ƒå¼ç¼“å­˜
---
## ğŸ“š ç›®å½•

1. [åˆ†å¸ƒå¼ç¼“å­˜æ ¸å¿ƒæ¦‚å¿µ](#1-åˆ†å¸ƒå¼ç¼“å­˜æ ¸å¿ƒæ¦‚å¿µ)
2. [Redisé›†ç¾¤è®¾è®¡](#2-Redisé›†ç¾¤è®¾è®¡)
3. [ç¼“å­˜åˆ†ç‰‡ç­–ç•¥](#3-ç¼“å­˜åˆ†ç‰‡ç­–ç•¥)
4. [ç¼“å­˜é¢„çƒ­æœºåˆ¶](#4-ç¼“å­˜é¢„çƒ­æœºåˆ¶)
5. [ç¼“å­˜ç›‘æ§å‘Šè­¦](#5-ç¼“å­˜ç›‘æ§å‘Šè­¦)
6. [æ ¸å¿ƒè¦ç‚¹æ€»ç»“](#6-æ ¸å¿ƒè¦ç‚¹æ€»ç»“)

---

## 1. ğŸ¯ åˆ†å¸ƒå¼ç¼“å­˜æ ¸å¿ƒæ¦‚å¿µ


### 1.1 ä»€ä¹ˆæ˜¯åˆ†å¸ƒå¼ç¼“å­˜


**ç®€å•ç†è§£**ï¼šå°±åƒåœ¨å¤šä¸ªä»“åº“é‡Œå­˜æ”¾å•†å“ï¼Œå®¢æˆ·å¯ä»¥å°±è¿‘å–è´§

```
å•æœºç¼“å­˜ vs åˆ†å¸ƒå¼ç¼“å­˜ï¼š

å•æœºç¼“å­˜ï¼ˆä¸€ä¸ªä»“åº“ï¼‰ï¼š
åº”ç”¨ â†’ æœ¬åœ°ç¼“å­˜ â†’ æ•°æ®åº“
ä¼˜ç‚¹ï¼šé€Ÿåº¦å¿«
ç¼ºç‚¹ï¼šå®¹é‡æœ‰é™ï¼Œæ•°æ®ä¸å…±äº«

åˆ†å¸ƒå¼ç¼“å­˜ï¼ˆå¤šä¸ªä»“åº“ç½‘ç»œï¼‰ï¼š
åº”ç”¨A â†’ ç¼“å­˜èŠ‚ç‚¹1 â†˜
åº”ç”¨B â†’ ç¼“å­˜èŠ‚ç‚¹2 â†’ æ•°æ®åº“
åº”ç”¨C â†’ ç¼“å­˜èŠ‚ç‚¹3 â†—
ä¼˜ç‚¹ï¼šå®¹é‡å¤§ï¼Œæ•°æ®å…±äº«ï¼Œé«˜å¯ç”¨
```

### 1.2 ä¸ºä»€ä¹ˆéœ€è¦åˆ†å¸ƒå¼ç¼“å­˜


**ğŸ”¸ å®¹é‡é—®é¢˜**
```
å•æœºå†…å­˜é™åˆ¶ï¼š
- æ™®é€šæœåŠ¡å™¨ï¼š8GB-32GBå†…å­˜
- å¤§å‹æ•°æ®ï¼šTBçº§åˆ«å­˜å‚¨éœ€æ±‚
- è§£å†³æ–¹æ¡ˆï¼šå¤šå°æœºå™¨ç»„æˆç¼“å­˜é›†ç¾¤
```

**ğŸ”¸ å¯ç”¨æ€§é—®é¢˜**
```
å•ç‚¹æ•…éšœé£é™©ï¼š
ç¼“å­˜æœåŠ¡å™¨å®•æœº â†’ æ•´ä¸ªç³»ç»Ÿæ€§èƒ½ä¸‹é™
è§£å†³æ–¹æ¡ˆï¼šå¤šèŠ‚ç‚¹å¤‡ä»½ï¼Œæ•…éšœè‡ªåŠ¨åˆ‡æ¢
```

**ğŸ”¸ å¹¶å‘å¤„ç†é—®é¢˜**
```
é«˜å¹¶å‘è®¿é—®ï¼š
å•æœºQPSï¼š10ä¸‡/ç§’
é›†ç¾¤QPSï¼š100ä¸‡/ç§’
è§£å†³æ–¹æ¡ˆï¼šè´Ÿè½½åˆ†æ•£åˆ°å¤šä¸ªèŠ‚ç‚¹
```

### 1.3 åˆ†å¸ƒå¼ç¼“å­˜çš„æ ¸å¿ƒæŒ‘æˆ˜


**ğŸ’¡ æ•°æ®ä¸€è‡´æ€§**
```
é—®é¢˜ï¼šå¤šä¸ªèŠ‚ç‚¹å¦‚ä½•ä¿è¯æ•°æ®åŒæ­¥ï¼Ÿ
AèŠ‚ç‚¹ï¼šuser:123 = "å¼ ä¸‰"
BèŠ‚ç‚¹ï¼šuser:123 = "æå››"  â† æ•°æ®ä¸ä¸€è‡´ï¼

è§£å†³æ€è·¯ï¼š
âœ… ä¸»ä»å¤åˆ¶
âœ… æ•°æ®åˆ†ç‰‡ï¼ˆæ¯ä¸ªkeyåªå­˜ä¸€ä¸ªåœ°æ–¹ï¼‰
âœ… ç‰ˆæœ¬æ§åˆ¶
```

**ğŸ’¡ æ•…éšœå¤„ç†**
```
é—®é¢˜ï¼šæŸä¸ªèŠ‚ç‚¹å®•æœºæ€ä¹ˆåŠï¼Ÿ
è§£å†³æ€è·¯ï¼š
âœ… æ•°æ®å¤‡ä»½ï¼ˆæ¯ä»½æ•°æ®å­˜å¤šä¸ªåœ°æ–¹ï¼‰
âœ… æ•…éšœæ£€æµ‹ï¼ˆå¿ƒè·³ç›‘æ§ï¼‰
âœ… è‡ªåŠ¨åˆ‡æ¢ï¼ˆæ•…éšœè½¬ç§»ï¼‰
```

**ğŸ’¡ æ‰©å®¹ç¼©å®¹**
```
é—®é¢˜ï¼šå¦‚ä½•åŠ¨æ€è°ƒæ•´é›†ç¾¤è§„æ¨¡ï¼Ÿ
è§£å†³æ€è·¯ï¼š
âœ… ä¸€è‡´æ€§å“ˆå¸Œï¼ˆå‡å°‘æ•°æ®è¿ç§»ï¼‰
âœ… æ¸è¿›å¼è¿ç§»ï¼ˆåˆ†æ‰¹è½¬ç§»æ•°æ®ï¼‰
âœ… åœ¨çº¿æ‰©å®¹ï¼ˆä¸åœæœåŠ¡ï¼‰
```

---

## 2. ğŸ—ï¸ Redisé›†ç¾¤è®¾è®¡


### 2.1 Redisé›†ç¾¤æ¶æ„æ¨¡å¼


#### ğŸ”¸ ä¸»ä»å¤åˆ¶æ¨¡å¼ï¼ˆMaster-Slaveï¼‰


**åŸºæœ¬åŸç†**ï¼šä¸€ä¸ªä¸»èŠ‚ç‚¹ï¼Œå¤šä¸ªä»èŠ‚ç‚¹

```
æ¶æ„å›¾ï¼š
    Master (å†™)
    /    |    \
Slave1  Slave2  Slave3 (è¯»)

å·¥ä½œæµç¨‹ï¼š
1. åº”ç”¨å†™æ•°æ® â†’ MasterèŠ‚ç‚¹
2. MasteråŒæ­¥æ•°æ® â†’ æ‰€æœ‰SlaveèŠ‚ç‚¹  
3. åº”ç”¨è¯»æ•°æ® â†’ ä»»æ„SlaveèŠ‚ç‚¹
```

**ä¼˜ç‚¹ä¸å±€é™**ï¼š
```
âœ… ä¼˜ç‚¹ï¼š
- è¯»å†™åˆ†ç¦»ï¼Œæé«˜å¹¶å‘
- æ•°æ®å¤‡ä»½ï¼Œæé«˜å¯ç”¨æ€§
- å®ç°ç®€å•ï¼Œæ˜“äºç†è§£

âŒ å±€é™ï¼š
- Masterå•ç‚¹æ•…éšœ
- å†™æ“ä½œæ— æ³•æ‰©å±•ï¼ˆåªæœ‰ä¸€ä¸ªMasterï¼‰
- æ•…éšœåˆ‡æ¢éœ€è¦äººå·¥ä»‹å…¥
```

**ä»£ç ç¤ºä¾‹**ï¼š
```python
# ä¸»ä»æ¨¡å¼è¿æ¥ç¤ºä¾‹
import redis

# å†™æ“ä½œï¼šè¿æ¥Master
master = redis.Redis(host='master.redis.com', port=6379)
master.set('user:123', 'å¼ ä¸‰')

# è¯»æ“ä½œï¼šè¿æ¥Slave
slave = redis.Redis(host='slave1.redis.com', port=6379)
user_name = slave.get('user:123')
```

#### ğŸ”¸ å“¨å…µæ¨¡å¼ï¼ˆSentinelï¼‰


**åŸºæœ¬åŸç†**ï¼šåœ¨ä¸»ä»åŸºç¡€ä¸Šå¢åŠ å“¨å…µèŠ‚ç‚¹ï¼Œå®ç°è‡ªåŠ¨æ•…éšœåˆ‡æ¢

```
æ¶æ„å›¾ï¼š
  Sentinel1  Sentinel2  Sentinel3 (ç›‘æ§)
      |         |         |
      â†“         â†“         â†“
    Master â†â†’ Slave1 â†â†’ Slave2

æ•…éšœåˆ‡æ¢æµç¨‹ï¼š
1. Masterå®•æœº
2. Sentinelæ£€æµ‹åˆ°æ•…éšœ
3. Sentinelé€‰ä¸¾æ–°çš„Master
4. é€šçŸ¥åº”ç”¨æ–°çš„Masteråœ°å€
```

**è§£å†³çš„é—®é¢˜**ï¼š
```
ğŸ¯ è‡ªåŠ¨æ•…éšœæ£€æµ‹ï¼š
- å“¨å…µå®šæœŸping Master
- è¶…æ—¶è®¤ä¸ºMasteræ•…éšœ

ğŸ¯ è‡ªåŠ¨ä¸»å¤‡åˆ‡æ¢ï¼š
- ä»Slaveä¸­é€‰ä¸¾æ–°Master
- é‡æ–°é…ç½®ä¸»ä»å…³ç³»

ğŸ¯ æœåŠ¡å‘ç°ï¼š
- åº”ç”¨è¿æ¥Sentinelè·å–Masteråœ°å€
- Masterå˜æ›´æ—¶è‡ªåŠ¨é€šçŸ¥åº”ç”¨
```

#### ğŸ”¸ é›†ç¾¤æ¨¡å¼ï¼ˆClusterï¼‰


**åŸºæœ¬åŸç†**ï¼šæ•°æ®åˆ†ç‰‡å­˜å‚¨ï¼Œæ¯ä¸ªèŠ‚ç‚¹è´Ÿè´£ä¸€éƒ¨åˆ†æ•°æ®

```
é›†ç¾¤æ¶æ„ï¼š
Node1 (Slot: 0-5460)     â†â†’ Node1-Slave
Node2 (Slot: 5461-10922) â†â†’ Node2-Slave  
Node3 (Slot: 10923-16383)â†â†’ Node3-Slave

æ•°æ®åˆ†å¸ƒï¼š
key â†’ CRC16(key) % 16384 â†’ æ‰¾åˆ°å¯¹åº”Slot â†’ è·¯ç”±åˆ°å…·ä½“Node
```

**æ ¸å¿ƒç‰¹æ€§**ï¼š
```
ğŸ”¸ æ•°æ®åˆ†ç‰‡ï¼š
- 16384ä¸ªSlotï¼ˆæ§½ä½ï¼‰
- æ¯ä¸ªèŠ‚ç‚¹è´Ÿè´£éƒ¨åˆ†Slot
- keyæ ¹æ®hashåˆ†é…åˆ°ä¸åŒèŠ‚ç‚¹

ğŸ”¸ è‡ªåŠ¨æ•…éšœåˆ‡æ¢ï¼š
- æ¯ä¸ªMasteræœ‰Slaveå¤‡ä»½
- Masteræ•…éšœæ—¶Slaveè‡ªåŠ¨æå‡

ğŸ”¸ æ°´å¹³æ‰©å±•ï¼š
- å¯ä»¥åŠ¨æ€æ·»åŠ /åˆ é™¤èŠ‚ç‚¹
- è‡ªåŠ¨é‡æ–°åˆ†é…Slot
```

### 2.2 é›†ç¾¤è®¾è®¡å…³é”®å†³ç­–


#### ğŸ¯ é€‰æ‹©åˆé€‚çš„æ¨¡å¼


```markdown
| æ¨¡å¼ | é€‚ç”¨åœºæ™¯ | æ•°æ®é‡ | å¹¶å‘é‡ | å¤æ‚åº¦ |
|------|----------|--------|--------|--------|
| **ä¸»ä»å¤åˆ¶** | å°å‹åº”ç”¨ | < 10GB | < 1ä¸‡QPS | â­ |
| **å“¨å…µæ¨¡å¼** | ä¸­å‹åº”ç”¨ | < 50GB | < 5ä¸‡QPS | â­â­ |
| **é›†ç¾¤æ¨¡å¼** | å¤§å‹åº”ç”¨ | > 50GB | > 10ä¸‡QPS | â­â­â­ |
```

#### ğŸ¯ èŠ‚ç‚¹è§„åˆ’


**èŠ‚ç‚¹æ•°é‡è§„åˆ’**ï¼š
```
æœ€å°é›†ç¾¤ï¼š3ä¸ªMaster + 3ä¸ªSlave = 6èŠ‚ç‚¹
æ¨èé›†ç¾¤ï¼š6ä¸ªMaster + 6ä¸ªSlave = 12èŠ‚ç‚¹

è®¡ç®—å…¬å¼ï¼š
èŠ‚ç‚¹æ•° = (æ•°æ®æ€»é‡ / å•èŠ‚ç‚¹å®¹é‡) Ã— 2ï¼ˆè€ƒè™‘å¤‡ä»½ï¼‰

ç¤ºä¾‹ï¼š
æ•°æ®æ€»é‡ï¼š200GB
å•èŠ‚ç‚¹å®¹é‡ï¼š32GB  
éœ€è¦èŠ‚ç‚¹ï¼š200/32 Ã— 2 = 14ä¸ªèŠ‚ç‚¹
```

**ç¡¬ä»¶é…ç½®**ï¼š
```
ğŸ’» CPUï¼š8æ ¸å¿ƒä»¥ä¸Šï¼ˆå¤„ç†å¹¶å‘è¯·æ±‚ï¼‰
ğŸ’¾ å†…å­˜ï¼š32GBä»¥ä¸Šï¼ˆå­˜å‚¨çƒ­ç‚¹æ•°æ®ï¼‰
ğŸ’½ ç£ç›˜ï¼šSSDï¼ˆæŒä¹…åŒ–æ€§èƒ½ï¼‰
ğŸŒ ç½‘ç»œï¼šä¸‡å…†ç½‘å¡ï¼ˆèŠ‚ç‚¹é—´é€šä¿¡ï¼‰
```

### 2.3 é›†ç¾¤éƒ¨ç½²å®è·µ


**é…ç½®ç¤ºä¾‹**ï¼š
```bash
# Redisé›†ç¾¤é…ç½®æ–‡ä»¶
port 7001
cluster-enabled yes                 # å¯ç”¨é›†ç¾¤æ¨¡å¼
cluster-config-file nodes.conf     # é›†ç¾¤é…ç½®æ–‡ä»¶
cluster-node-timeout 5000          # èŠ‚ç‚¹è¶…æ—¶æ—¶é—´
appendonly yes                      # å¼€å¯AOFæŒä¹…åŒ–

# åˆ›å»ºé›†ç¾¤
redis-cli --cluster create \
  192.168.1.11:7001 192.168.1.12:7001 192.168.1.13:7001 \
  192.168.1.11:7002 192.168.1.12:7002 192.168.1.13:7002 \
  --cluster-replicas 1              # æ¯ä¸ªMasterä¸€ä¸ªSlave
```

**åº”ç”¨è¿æ¥ç¤ºä¾‹**ï¼š
```java
// Javaåº”ç”¨è¿æ¥Redisé›†ç¾¤
JedisCluster jedisCluster = new JedisCluster(
    Set.of(
        new HostAndPort("192.168.1.11", 7001),
        new HostAndPort("192.168.1.12", 7001),
        new HostAndPort("192.168.1.13", 7001)
    )
);

// è‡ªåŠ¨è·¯ç”±åˆ°æ­£ç¡®èŠ‚ç‚¹
jedisCluster.set("user:123", "å¼ ä¸‰");
String userName = jedisCluster.get("user:123");
```

---

## 3. ğŸ”€ ç¼“å­˜åˆ†ç‰‡ç­–ç•¥


### 3.1 ä»€ä¹ˆæ˜¯ç¼“å­˜åˆ†ç‰‡


**é€šä¿—ç†è§£**ï¼šæŠŠæ•°æ®æŒ‰è§„åˆ™åˆ†æ•£å­˜å‚¨åˆ°ä¸åŒçš„ç¼“å­˜èŠ‚ç‚¹

```
æœªåˆ†ç‰‡ï¼ˆå•èŠ‚ç‚¹ï¼‰ï¼š
æ‰€æœ‰æ•°æ® â†’ ä¸€ä¸ªRedisèŠ‚ç‚¹ â†’ å®¹é‡é™åˆ¶

åˆ†ç‰‡åï¼ˆå¤šèŠ‚ç‚¹ï¼‰ï¼š
ç”¨æˆ·æ•°æ® â†’ Node1
å•†å“æ•°æ® â†’ Node2  
è®¢å•æ•°æ® â†’ Node3
```

### 3.2 åˆ†ç‰‡ç­–ç•¥ç±»å‹


#### ğŸ”¸ èŒƒå›´åˆ†ç‰‡ï¼ˆRange-basedï¼‰


**åŸç†**ï¼šæŒ‰æ•°æ®èŒƒå›´åˆ†é…åˆ°ä¸åŒèŠ‚ç‚¹

```
ç”¨æˆ·IDåˆ†ç‰‡ç¤ºä¾‹ï¼š
Node1ï¼šuser_id 1-100ä¸‡
Node2ï¼šuser_id 100-200ä¸‡
Node3ï¼šuser_id 200-300ä¸‡

ä¼˜ç‚¹ï¼š
âœ… é€»è¾‘ç®€å•ï¼Œæ˜“äºç†è§£
âœ… èŒƒå›´æŸ¥è¯¢æ•ˆç‡é«˜

ç¼ºç‚¹ï¼š
âŒ æ•°æ®åˆ†å¸ƒå¯èƒ½ä¸å‡åŒ€
âŒ çƒ­ç‚¹æ•°æ®é›†ä¸­åœ¨æŸä¸ªèŠ‚ç‚¹
```

**ä»£ç å®ç°**ï¼š
```python
def range_shard(user_id, node_count=3):
    """èŒƒå›´åˆ†ç‰‡"""
    if user_id <= 1000000:
        return "node1"
    elif user_id <= 2000000:
        return "node2"
    else:
        return "node3"

# ä½¿ç”¨ç¤ºä¾‹
user_id = 1500000
node = range_shard(user_id)
print(f"ç”¨æˆ·{user_id}åˆ†é…åˆ°{node}")  # ç”¨æˆ·1500000åˆ†é…åˆ°node2
```

#### ğŸ”¸ å“ˆå¸Œåˆ†ç‰‡ï¼ˆHash-basedï¼‰


**åŸç†**ï¼šé€šè¿‡å“ˆå¸Œå‡½æ•°å°†æ•°æ®å‡åŒ€åˆ†å¸ƒåˆ°å„èŠ‚ç‚¹

```
å“ˆå¸Œåˆ†ç‰‡æµç¨‹ï¼š
1. è®¡ç®—keyçš„hashå€¼
2. hashå€¼å¯¹èŠ‚ç‚¹æ•°å–æ¨¡
3. å¾—åˆ°ç›®æ ‡èŠ‚ç‚¹ç¼–å·

ç¤ºä¾‹ï¼š
key = "user:123"
hash = CRC32("user:123") = 2580765787
node = hash % 3 = 1  â†’ åˆ†é…åˆ°Node1
```

**ä»£ç å®ç°**ï¼š
```python
import hashlib

def hash_shard(key, node_count=3):
    """å“ˆå¸Œåˆ†ç‰‡"""
    # è®¡ç®—MD5å“ˆå¸Œå€¼
    hash_value = int(hashlib.md5(key.encode()).hexdigest(), 16)
    # å–æ¨¡å¾—åˆ°èŠ‚ç‚¹ç¼–å·
    node_index = hash_value % node_count
    return f"node{node_index + 1}"

# ä½¿ç”¨ç¤ºä¾‹
keys = ["user:123", "user:456", "user:789"]
for key in keys:
    node = hash_shard(key)
    print(f"{key} â†’ {node}")

# è¾“å‡ºï¼š
# user:123 â†’ node2
# user:456 â†’ node1  
# user:789 â†’ node3
```

**ä¼˜ç¼ºç‚¹å¯¹æ¯”**ï¼š
```
âœ… ä¼˜ç‚¹ï¼š
- æ•°æ®åˆ†å¸ƒå‡åŒ€
- è®¡ç®—ç®€å•é«˜æ•ˆ
- é¿å…çƒ­ç‚¹é—®é¢˜

âŒ ç¼ºç‚¹ï¼š
- æ‰©å®¹æ—¶éœ€è¦å¤§é‡æ•°æ®è¿ç§»
- ä¸æ”¯æŒèŒƒå›´æŸ¥è¯¢
```

#### ğŸ”¸ ä¸€è‡´æ€§å“ˆå¸Œï¼ˆConsistent Hashï¼‰


**è§£å†³çš„é—®é¢˜**ï¼šæ™®é€šå“ˆå¸Œåœ¨èŠ‚ç‚¹å˜åŒ–æ—¶éœ€è¦è¿ç§»å¤§é‡æ•°æ®

```
é—®é¢˜æ¼”ç¤ºï¼š
åŸæ¥3ä¸ªèŠ‚ç‚¹ï¼šhash % 3
ç°åœ¨4ä¸ªèŠ‚ç‚¹ï¼šhash % 4
å‡ ä¹æ‰€æœ‰æ•°æ®çš„èŠ‚ç‚¹åˆ†é…éƒ½ä¼šæ”¹å˜ï¼

ä¸€è‡´æ€§å“ˆå¸Œè§£å†³æ–¹æ¡ˆï¼š
1. å°†hashç©ºé—´çœ‹ä½œä¸€ä¸ªç¯ï¼ˆ0 ~ 2^32-1ï¼‰
2. èŠ‚ç‚¹å’Œæ•°æ®éƒ½æ˜ å°„åˆ°ç¯ä¸Š
3. æ•°æ®é¡ºæ—¶é’ˆæ‰¾æœ€è¿‘çš„èŠ‚ç‚¹
```

**ä¸€è‡´æ€§å“ˆå¸Œç¯**ï¼š
```
         Node1(100)
             |
    æ•°æ®D(80) â—‹â”€â”€â”€â”€â”€â”€â”€â”€â”€â—‹ æ•°æ®A(150)
            /             \
          /                 \
        /                     \
   Node3(300)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Node2(200)
        \                     /
         \                   /
           â—‹â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â—‹
      æ•°æ®C(280)     æ•°æ®B(250)

æ•°æ®è·¯ç”±è§„åˆ™ï¼š
- æ•°æ®A(150) â†’ é¡ºæ—¶é’ˆæœ€è¿‘çš„Node2(200)
- æ•°æ®B(250) â†’ é¡ºæ—¶é’ˆæœ€è¿‘çš„Node3(300)
- æ•°æ®C(280) â†’ é¡ºæ—¶é’ˆæœ€è¿‘çš„Node3(300)  
- æ•°æ®D(80)  â†’ é¡ºæ—¶é’ˆæœ€è¿‘çš„Node1(100)
```

**æ‰©å®¹å½±å“åˆ†æ**ï¼š
```
æ·»åŠ Node4(250)åï¼š
- æ•°æ®A(150) â†’ ä»ç„¶æ˜¯Node2(200) âœ…
- æ•°æ®B(250) â†’ æ”¹ä¸ºNode4(250) âš ï¸ éœ€è¿ç§»
- æ•°æ®C(280) â†’ ä»ç„¶æ˜¯Node3(300) âœ…
- æ•°æ®D(80)  â†’ ä»ç„¶æ˜¯Node1(100) âœ…

è¿ç§»æ¯”ä¾‹ï¼šåªæœ‰25%çš„æ•°æ®éœ€è¦è¿ç§»ï¼
æ™®é€šå“ˆå¸Œï¼š75%çš„æ•°æ®éœ€è¦è¿ç§»
```

**ä»£ç å®ç°**ï¼š
```python
import hashlib
import bisect

class ConsistentHash:
    def __init__(self, nodes=None, replicas=3):
        """
        nodes: èŠ‚ç‚¹åˆ—è¡¨
        replicas: è™šæ‹ŸèŠ‚ç‚¹æ•°ï¼ˆè§£å†³æ•°æ®åˆ†å¸ƒä¸å‡é—®é¢˜ï¼‰
        """
        self.replicas = replicas
        self.ring = {}          # å“ˆå¸Œç¯ï¼š{hash_value: node}
        self.sorted_keys = []   # æœ‰åºçš„hashå€¼åˆ—è¡¨
        
        if nodes:
            for node in nodes:
                self.add_node(node)
    
    def _hash(self, key):
        """è®¡ç®—hashå€¼"""
        return int(hashlib.md5(key.encode()).hexdigest(), 16)
    
    def add_node(self, node):
        """æ·»åŠ èŠ‚ç‚¹"""
        for i in range(self.replicas):
            # åˆ›å»ºè™šæ‹ŸèŠ‚ç‚¹
            virtual_key = f"{node}:{i}"
            hash_value = self._hash(virtual_key)
            self.ring[hash_value] = node
            bisect.insort(self.sorted_keys, hash_value)
    
    def remove_node(self, node):
        """åˆ é™¤èŠ‚ç‚¹"""
        for i in range(self.replicas):
            virtual_key = f"{node}:{i}"
            hash_value = self._hash(virtual_key)
            del self.ring[hash_value]
            self.sorted_keys.remove(hash_value)
    
    def get_node(self, key):
        """è·å–keyå¯¹åº”çš„èŠ‚ç‚¹"""
        if not self.ring:
            return None
        
        hash_value = self._hash(key)
        # æ‰¾åˆ°ç¬¬ä¸€ä¸ªå¤§äºç­‰äºhash_valueçš„èŠ‚ç‚¹
        index = bisect.bisect_right(self.sorted_keys, hash_value)
        
        # å¦‚æœè¶…å‡ºèŒƒå›´ï¼Œå›åˆ°ç¯çš„å¼€å§‹
        if index == len(self.sorted_keys):
            index = 0
        
        return self.ring[self.sorted_keys[index]]

# ä½¿ç”¨ç¤ºä¾‹
ch = ConsistentHash(['node1', 'node2', 'node3'])

# æµ‹è¯•æ•°æ®åˆ†å¸ƒ
keys = ['user:123', 'user:456', 'user:789', 'product:001']
for key in keys:
    node = ch.get_node(key)
    print(f"{key} â†’ {node}")

# æ‰©å®¹æµ‹è¯•
print("\n--- æ·»åŠ node4å ---")
ch.add_node('node4')
for key in keys:
    node = ch.get_node(key)
    print(f"{key} â†’ {node}")
```

### 3.3 åˆ†ç‰‡ç­–ç•¥é€‰æ‹©æŒ‡å—


```markdown
| ç­–ç•¥ | é€‚ç”¨åœºæ™¯ | æ•°æ®åˆ†å¸ƒ | æ‰©å®¹æˆæœ¬ | å®ç°å¤æ‚åº¦ |
|------|----------|----------|----------|-----------|
| **èŒƒå›´åˆ†ç‰‡** | æœ‰æ˜ç¡®èŒƒå›´çš„æ•°æ® | å¯èƒ½ä¸å‡ | ä½ | â­ |
| **å“ˆå¸Œåˆ†ç‰‡** | å‡åŒ€åˆ†å¸ƒéœ€æ±‚ | å‡åŒ€ | é«˜ | â­â­ |
| **ä¸€è‡´æ€§å“ˆå¸Œ** | é¢‘ç¹æ‰©ç¼©å®¹åœºæ™¯ | ç›¸å¯¹å‡åŒ€ | ä½ | â­â­â­ |
```

**é€‰æ‹©å»ºè®®**ï¼š
```
ğŸ¯ å°å‹ç³»ç»Ÿï¼šç®€å•å“ˆå¸Œåˆ†ç‰‡
ğŸ¯ ä¸­å‹ç³»ç»Ÿï¼šä¸€è‡´æ€§å“ˆå¸Œ + è™šæ‹ŸèŠ‚ç‚¹
ğŸ¯ å¤§å‹ç³»ç»Ÿï¼šRedis Clusterï¼ˆå†…ç½®ä¸€è‡´æ€§å“ˆå¸Œï¼‰
```

---

## 4. ğŸ”¥ ç¼“å­˜é¢„çƒ­æœºåˆ¶


### 4.1 ä»€ä¹ˆæ˜¯ç¼“å­˜é¢„çƒ­


**é€šä¿—ç†è§£**ï¼šåœ¨ç³»ç»Ÿæ­£å¼å¯¹å¤–æœåŠ¡å‰ï¼Œæå‰æŠŠçƒ­ç‚¹æ•°æ®åŠ è½½åˆ°ç¼“å­˜ä¸­

```
å†·å¯åŠ¨é—®é¢˜ï¼š
ç³»ç»Ÿå¯åŠ¨ â†’ ç¼“å­˜ä¸ºç©º â†’ ç”¨æˆ·è®¿é—® â†’ ç¼“å­˜miss â†’ æŸ¥è¯¢æ•°æ®åº“ â†’ å“åº”æ…¢

é¢„çƒ­åæ•ˆæœï¼š
ç³»ç»Ÿå¯åŠ¨ â†’ é¢„çƒ­çƒ­ç‚¹æ•°æ® â†’ ç”¨æˆ·è®¿é—® â†’ ç¼“å­˜hit â†’ å¿«é€Ÿå“åº”
```

### 4.2 ä¸ºä»€ä¹ˆéœ€è¦ç¼“å­˜é¢„çƒ­


**ğŸ”¸ é¿å…ç¼“å­˜é›ªå´©**
```
åœºæ™¯ï¼šç”µå•†å¤§ä¿ƒæ´»åŠ¨å¼€å§‹
é—®é¢˜ï¼šç¬é—´å¤§é‡ç”¨æˆ·è®¿é—® â†’ ç¼“å­˜ä¸ºç©º â†’ æ‰€æœ‰è¯·æ±‚æ‰“åˆ°æ•°æ®åº“ â†’ æ•°æ®åº“å´©æºƒ

è§£å†³ï¼šæå‰é¢„çƒ­çƒ­é—¨å•†å“æ•°æ®
æ•ˆæœï¼šç”¨æˆ·è®¿é—®ç›´æ¥å‘½ä¸­ç¼“å­˜ï¼Œæ•°æ®åº“å‹åŠ›å¹³ç¨³
```

**ğŸ”¸ æå‡ç”¨æˆ·ä½“éªŒ**
```
é¢„çƒ­å‰ï¼šé¦–æ¬¡è®¿é—®å“åº”æ—¶é—´1000ms
é¢„çƒ­åï¼šé¦–æ¬¡è®¿é—®å“åº”æ—¶é—´50ms
æå‡ï¼š20å€å“åº”é€Ÿåº¦æå‡
```

**ğŸ”¸ ä¿æŠ¤æ•°æ®åº“**
```
æ•°æ®åº“å¹¶å‘èƒ½åŠ›ï¼š1000 QPS
ç”¨æˆ·è®¿é—®å³°å€¼ï¼š10000 QPS
é¢„çƒ­è¦†ç›–ç‡ï¼š90%
å®é™…æ•°æ®åº“å‹åŠ›ï¼š10000 Ã— 10% = 1000 QPS âœ… å®‰å…¨
```

### 4.3 é¢„çƒ­ç­–ç•¥ç±»å‹


#### ğŸ”¸ å…¨é‡é¢„çƒ­


**é€‚ç”¨åœºæ™¯**ï¼šæ•°æ®é‡ä¸å¤§ï¼Œéœ€è¦é«˜å‘½ä¸­ç‡

```python
def full_warm_up():
    """å…¨é‡é¢„çƒ­ï¼šåŠ è½½æ‰€æœ‰æ•°æ®åˆ°ç¼“å­˜"""
    print("å¼€å§‹å…¨é‡é¢„çƒ­...")
    
    # ä»æ•°æ®åº“åŠ è½½æ‰€æœ‰ç”¨æˆ·æ•°æ®
    users = db.execute("SELECT id, name, email FROM users")
    
    for user in users:
        cache_key = f"user:{user['id']}"
        cache_value = {
            'name': user['name'],
            'email': user['email']
        }
        redis_client.setex(cache_key, 3600, json.dumps(cache_value))
    
    print(f"é¢„çƒ­å®Œæˆï¼Œå…±åŠ è½½{len(users)}æ¡ç”¨æˆ·æ•°æ®")

# ä¼˜ç¼ºç‚¹
âœ… ä¼˜ç‚¹ï¼šå‘½ä¸­ç‡100%ï¼Œç”¨æˆ·ä½“éªŒæœ€ä½³
âŒ ç¼ºç‚¹ï¼šè€—æ—¶é•¿ï¼Œå†…å­˜å ç”¨å¤§
```

#### ğŸ”¸ çƒ­ç‚¹æ•°æ®é¢„çƒ­


**é€‚ç”¨åœºæ™¯**ï¼šæ•°æ®é‡å¤§ï¼Œåªé¢„çƒ­æ ¸å¿ƒçƒ­ç‚¹æ•°æ®

```python
def hotspot_warm_up():
    """çƒ­ç‚¹æ•°æ®é¢„çƒ­ï¼šåªåŠ è½½é«˜é¢‘è®¿é—®çš„æ•°æ®"""
    print("å¼€å§‹çƒ­ç‚¹æ•°æ®é¢„çƒ­...")
    
    # è·å–çƒ­é—¨å•†å“ï¼ˆåŸºäºè®¿é—®ç»Ÿè®¡ï¼‰
    hot_products = db.execute("""
        SELECT product_id, COUNT(*) as visit_count 
        FROM access_log 
        WHERE create_time >= DATE_SUB(NOW(), INTERVAL 7 DAY)
        GROUP BY product_id 
        ORDER BY visit_count DESC 
        LIMIT 1000
    """)
    
    for product in hot_products:
        product_id = product['product_id']
        # åŠ è½½å•†å“è¯¦ç»†ä¿¡æ¯
        product_info = db.execute(
            "SELECT * FROM products WHERE id = %s", 
            (product_id,)
        )
        
        cache_key = f"product:{product_id}"
        redis_client.setex(
            cache_key, 
            7200,  # 2å°æ—¶è¿‡æœŸ
            json.dumps(product_info)
        )
    
    print(f"çƒ­ç‚¹é¢„çƒ­å®Œæˆï¼Œå…±åŠ è½½{len(hot_products)}ä¸ªçƒ­é—¨å•†å“")

# ä¼˜ç¼ºç‚¹  
âœ… ä¼˜ç‚¹ï¼šåŠ è½½é€Ÿåº¦å¿«ï¼Œå†…å­˜ä½¿ç”¨åˆç†
âŒ ç¼ºç‚¹ï¼šå‘½ä¸­ç‡ç•¥ä½ï¼Œéœ€è¦è®¿é—®ç»Ÿè®¡æ•°æ®
```

#### ğŸ”¸ æŒ‰éœ€é¢„çƒ­


**é€‚ç”¨åœºæ™¯**ï¼šç‰¹å®šæ—¶é—´æ®µæˆ–äº‹ä»¶è§¦å‘çš„é¢„çƒ­

```python
def event_driven_warm_up(event_type):
    """äº‹ä»¶é©±åŠ¨é¢„çƒ­ï¼šæ ¹æ®ç‰¹å®šäº‹ä»¶é¢„çƒ­ç›¸å…³æ•°æ®"""
    
    if event_type == "flash_sale":
        # ç§’æ€æ´»åŠ¨é¢„çƒ­
        print("ç§’æ€æ´»åŠ¨é¢„çƒ­ä¸­...")
        sale_products = db.execute("""
            SELECT product_id FROM flash_sale_products 
            WHERE sale_time <= NOW() + INTERVAL 10 MINUTE
        """)
        
        for product in sale_products:
            # é¢„çƒ­å•†å“ä¿¡æ¯
            load_product_to_cache(product['product_id'])
            # é¢„çƒ­åº“å­˜ä¿¡æ¯
            load_inventory_to_cache(product['product_id'])
            
    elif event_type == "user_login":
        # ç”¨æˆ·ç™»å½•åé¢„çƒ­ä¸ªäººæ•°æ®
        print("ç”¨æˆ·ä¸ªäººæ•°æ®é¢„çƒ­ä¸­...")
        # é¢„çƒ­ç”¨æˆ·å¸¸è®¿é—®çš„æ•°æ®
        load_user_preferences_to_cache()
        load_user_recent_orders_to_cache()

# ä½¿ç”¨ç¤ºä¾‹
# å®šæ—¶ä»»åŠ¡ï¼šç§’æ€å‰10åˆ†é’Ÿé¢„çƒ­
schedule.every().day.at("19:50").do(
    event_driven_warm_up, "flash_sale"
)
```

### 4.4 é¢„çƒ­å®æ–½æ–¹æ¡ˆ


#### ğŸ¯ åˆ†æ‰¹é¢„çƒ­


**é¿å…ç³»ç»Ÿå‹åŠ›è¿‡å¤§**ï¼š
```python
import time
from concurrent.futures import ThreadPoolExecutor

def batch_warm_up(batch_size=100, delay=0.1):
    """åˆ†æ‰¹é¢„çƒ­ï¼šé¿å…ç¬é—´å‹åŠ›è¿‡å¤§"""
    
    # è·å–éœ€è¦é¢„çƒ­çš„æ•°æ®åˆ—è¡¨
    data_list = get_warm_up_data_list()
    
    # åˆ†æ‰¹å¤„ç†
    for i in range(0, len(data_list), batch_size):
        batch = data_list[i:i + batch_size]
        
        # å¹¶è¡ŒåŠ è½½å½“å‰æ‰¹æ¬¡
        with ThreadPoolExecutor(max_workers=10) as executor:
            futures = []
            for item in batch:
                future = executor.submit(load_single_item_to_cache, item)
                futures.append(future)
            
            # ç­‰å¾…å½“å‰æ‰¹æ¬¡å®Œæˆ
            for future in futures:
                try:
                    future.result(timeout=5)  # 5ç§’è¶…æ—¶
                except Exception as e:
                    print(f"é¢„çƒ­å¤±è´¥: {e}")
        
        # æ‰¹æ¬¡é—´å»¶è¿Ÿï¼Œé¿å…å‹åŠ›è¿‡å¤§
        time.sleep(delay)
        print(f"å·²å®Œæˆ{i + len(batch)}/{len(data_list)}é¡¹é¢„çƒ­")

def load_single_item_to_cache(item):
    """åŠ è½½å•ä¸ªæ•°æ®é¡¹åˆ°ç¼“å­˜"""
    try:
        # ä»æ•°æ®åº“è·å–æ•°æ®
        data = db.get_data(item['id'])
        # å­˜å…¥ç¼“å­˜
        cache_key = f"data:{item['id']}"
        redis_client.setex(cache_key, 3600, json.dumps(data))
        return True
    except Exception as e:
        print(f"åŠ è½½å¤±è´¥ {item['id']}: {e}")
        return False
```

#### ğŸ¯ æ™ºèƒ½é¢„çƒ­


**åŸºäºæœºå™¨å­¦ä¹ é¢„æµ‹**ï¼š
```python
class SmartWarmUp:
    def __init__(self):
        self.access_pattern_analyzer = AccessPatternAnalyzer()
        
    def predict_and_warm_up(self):
        """åŸºäºè®¿é—®æ¨¡å¼é¢„æµ‹å¹¶é¢„çƒ­"""
        
        # åˆ†æå†å²è®¿é—®æ¨¡å¼
        patterns = self.access_pattern_analyzer.analyze_patterns()
        
        # é¢„æµ‹å³å°†çƒ­é—¨çš„æ•°æ®
        predicted_hot_data = self.predict_hot_data(patterns)
        
        # é¢„çƒ­é¢„æµ‹çš„çƒ­ç‚¹æ•°æ®
        for data_id in predicted_hot_data:
            self.warm_up_single_data(data_id)
    
    def predict_hot_data(self, patterns):
        """é¢„æµ‹çƒ­ç‚¹æ•°æ®"""
        predictions = []
        
        for pattern in patterns:
            # æ—¶é—´æ¨¡å¼ï¼šå‘¨ä¸€ä¸Šåˆ9ç‚¹ï¼Œç”¨æˆ·ç™»å½•é‡å¤§
            if self.is_peak_time(pattern):
                predictions.extend(pattern['related_data'])
            
            # å…³è”æ¨¡å¼ï¼šç”¨æˆ·æŸ¥çœ‹å•†å“Aï¼Œé€šå¸¸ä¹Ÿä¼šæŸ¥çœ‹å•†å“B
            if pattern['correlation'] > 0.8:
                predictions.extend(pattern['correlated_items'])
        
        return list(set(predictions))  # å»é‡
    
    def is_peak_time(self, pattern):
        """åˆ¤æ–­æ˜¯å¦æ¥è¿‘é«˜å³°æœŸ"""
        now = datetime.now()
        peak_times = pattern['peak_hours']
        
        for peak_time in peak_times:
            time_diff = abs((now.hour - peak_time) * 60 + now.minute)
            if time_diff <= 30:  # 30åˆ†é’Ÿå†…
                return True
        return False
```

### 4.5 é¢„çƒ­ç›‘æ§ä¸ä¼˜åŒ–


**é¢„çƒ­æ•ˆæœç›‘æ§**ï¼š
```python
class WarmUpMonitor:
    def __init__(self):
        self.metrics = {
            'warm_up_time': 0,      # é¢„çƒ­è€—æ—¶
            'warm_up_count': 0,     # é¢„çƒ­æ•°é‡
            'hit_rate_before': 0,   # é¢„çƒ­å‰å‘½ä¸­ç‡
            'hit_rate_after': 0,    # é¢„çƒ­åå‘½ä¸­ç‡
            'db_pressure_reduced': 0 # æ•°æ®åº“å‹åŠ›å‡å°‘
        }
    
    def monitor_warm_up(self, warm_up_func):
        """ç›‘æ§é¢„çƒ­è¿‡ç¨‹"""
        start_time = time.time()
        
        # è®°å½•é¢„çƒ­å‰çš„å‘½ä¸­ç‡
        self.metrics['hit_rate_before'] = self.calculate_hit_rate()
        
        # æ‰§è¡Œé¢„çƒ­
        result = warm_up_func()
        
        # è®°å½•é¢„çƒ­æŒ‡æ ‡
        self.metrics['warm_up_time'] = time.time() - start_time
        self.metrics['warm_up_count'] = result.get('count', 0)
        
        # ç­‰å¾…ä¸€æ®µæ—¶é—´åæµ‹é‡é¢„çƒ­æ•ˆæœ
        time.sleep(60)  # ç­‰å¾…1åˆ†é’Ÿ
        self.metrics['hit_rate_after'] = self.calculate_hit_rate()
        
        # è®¡ç®—æ”¹å–„æ•ˆæœ
        hit_rate_improvement = (
            self.metrics['hit_rate_after'] - 
            self.metrics['hit_rate_before']
        )
        
        print(f"""
        é¢„çƒ­å®ŒæˆæŠ¥å‘Šï¼š
        â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        â±ï¸  é¢„çƒ­è€—æ—¶: {self.metrics['warm_up_time']:.2f}ç§’
        ğŸ“¦ é¢„çƒ­æ•°é‡: {self.metrics['warm_up_count']}é¡¹
        ğŸ“Š å‘½ä¸­ç‡æå‡: {hit_rate_improvement:.2%}
        ğŸ¯ å½“å‰å‘½ä¸­ç‡: {self.metrics['hit_rate_after']:.2%}
        â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        """)
    
    def calculate_hit_rate(self):
        """è®¡ç®—ç¼“å­˜å‘½ä¸­ç‡"""
        info = redis_client.info()
        hits = info.get('keyspace_hits', 0)
        misses = info.get('keyspace_misses', 0)
        
        if hits + misses == 0:
            return 0
        return hits / (hits + misses)
```

---

## 5. ğŸ“Š ç¼“å­˜ç›‘æ§å‘Šè­¦


### 5.1 ç›‘æ§æŒ‡æ ‡ä½“ç³»


#### ğŸ”¸ æ€§èƒ½æŒ‡æ ‡


**QPSï¼ˆæ¯ç§’è¯·æ±‚æ•°ï¼‰**ï¼š
```python
class CacheMetrics:
    def __init__(self):
        self.request_count = 0
        self.start_time = time.time()
    
    def record_request(self):
        """è®°å½•ä¸€æ¬¡è¯·æ±‚"""
        self.request_count += 1
    
    def get_qps(self):
        """è®¡ç®—QPS"""
        elapsed = time.time() - self.start_time
        if elapsed == 0:
            return 0
        return self.request_count / elapsed
    
    def reset_metrics(self):
        """é‡ç½®è®¡æ•°å™¨"""
        self.request_count = 0
        self.start_time = time.time()

# ä½¿ç”¨ç¤ºä¾‹
metrics = CacheMetrics()

def cache_get(key):
    metrics.record_request()  # è®°å½•è¯·æ±‚
    return redis_client.get(key)

# å®šæœŸè¾“å‡ºQPS
def print_qps():
    qps = metrics.get_qps()
    print(f"å½“å‰QPS: {qps:.2f}")
    metrics.reset_metrics()

# æ¯10ç§’è¾“å‡ºä¸€æ¬¡
import threading
threading.Timer(10.0, print_qps).start()
```

**å“åº”æ—¶é—´ç›‘æ§**ï¼š
```python
import time
import statistics
from collections import deque

class ResponseTimeMonitor:
    def __init__(self, window_size=100):
        self.response_times = deque(maxlen=window_size)
    
    def measure_operation(self, operation_func, *args, **kwargs):
        """æµ‹é‡æ“ä½œå“åº”æ—¶é—´"""
        start_time = time.time()
        try:
            result = operation_func(*args, **kwargs)
            success = True
        except Exception as e:
            result = None
            success = False
        
        response_time = (time.time() - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
        self.response_times.append(response_time)
        
        return {
            'result': result,
            'response_time': response_time,
            'success': success
        }
    
    def get_stats(self):
        """è·å–å“åº”æ—¶é—´ç»Ÿè®¡"""
        if not self.response_times:
            return {}
        
        times = list(self.response_times)
        return {
            'avg': statistics.mean(times),
            'p50': statistics.median(times),
            'p95': sorted(times)[int(len(times) * 0.95)],
            'p99': sorted(times)[int(len(times) * 0.99)],
            'max': max(times),
            'min': min(times)
        }

# ä½¿ç”¨ç¤ºä¾‹
monitor = ResponseTimeMonitor()

def monitored_cache_get(key):
    return monitor.measure_operation(redis_client.get, key)

# è·å–ç»Ÿè®¡ä¿¡æ¯
result = monitored_cache_get("user:123")
print(f"å“åº”æ—¶é—´: {result['response_time']:.2f}ms")

stats = monitor.get_stats()
print(f"å¹³å‡å“åº”æ—¶é—´: {stats['avg']:.2f}ms")
print(f"P95å“åº”æ—¶é—´: {stats['p95']:.2f}ms")
```

#### ğŸ”¸ å¯ç”¨æ€§æŒ‡æ ‡


**å‘½ä¸­ç‡ç›‘æ§**ï¼š
```python
class HitRateMonitor:
    def __init__(self):
        self.hits = 0
        self.total = 0
    
    def record_hit(self):
        """è®°å½•ç¼“å­˜å‘½ä¸­"""
        self.hits += 1
        self.total += 1
    
    def record_miss(self):
        """è®°å½•ç¼“å­˜æœªå‘½ä¸­"""
        self.total += 1
    
    def get_hit_rate(self):
        """è·å–å‘½ä¸­ç‡"""
        if self.total == 0:
            return 0
        return self.hits / self.total
    
    def reset(self):
        """é‡ç½®è®¡æ•°å™¨"""
        self.hits = 0
        self.total = 0

# é›†æˆåˆ°ç¼“å­˜æ“ä½œä¸­
hit_monitor = HitRateMonitor()

def smart_cache_get(key):
    """å¸¦ç›‘æ§çš„ç¼“å­˜è·å–"""
    # å°è¯•ä»ç¼“å­˜è·å–
    value = redis_client.get(key)
    
    if value is not None:
        hit_monitor.record_hit()
        return json.loads(value)
    else:
        hit_monitor.record_miss()
        # ä»æ•°æ®åº“è·å–å¹¶ç¼“å­˜
        db_value = get_from_database(key)
        if db_value:
            redis_client.setex(key, 3600, json.dumps(db_value))
        return db_value

# å®šæœŸæ£€æŸ¥å‘½ä¸­ç‡
def check_hit_rate():
    hit_rate = hit_monitor.get_hit_rate()
    print(f"ç¼“å­˜å‘½ä¸­ç‡: {hit_rate:.2%}")
    
    # å‘½ä¸­ç‡è¿‡ä½æ—¶å‘Šè­¦
    if hit_rate < 0.8:  # ä½äº80%å‘Šè­¦
        send_alert(f"ç¼“å­˜å‘½ä¸­ç‡è¿‡ä½: {hit_rate:.2%}")
    
    hit_monitor.reset()
```

**èŠ‚ç‚¹å¥åº·ç›‘æ§**ï¼š
```python
def check_redis_health(host, port):
    """æ£€æŸ¥RedisèŠ‚ç‚¹å¥åº·çŠ¶æ€"""
    try:
        client = redis.Redis(host=host, port=port, socket_timeout=5)
        
        # æ£€æŸ¥è¿æ¥
        response = client.ping()
        if not response:
            return {'status': 'error', 'message': 'pingå¤±è´¥'}
        
        # æ£€æŸ¥å†…å­˜ä½¿ç”¨
        info = client.info()
        memory_usage = info['used_memory'] / info['total_system_memory']
        
        # æ£€æŸ¥è¿æ¥æ•°
        connected_clients = info['connected_clients']
        max_clients = info.get('maxclients', 10000)
        
        health_status = {
            'status': 'healthy',
            'memory_usage': f"{memory_usage:.2%}",
            'connected_clients': f"{connected_clients}/{max_clients}",
            'uptime': info['uptime_in_seconds']
        }
        
        # å¥åº·çŠ¶æ€åˆ¤æ–­
        if memory_usage > 0.9:
            health_status['status'] = 'warning'
            health_status['message'] = 'å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜'
        elif connected_clients > max_clients * 0.8:
            health_status['status'] = 'warning'  
            health_status['message'] = 'è¿æ¥æ•°è¿‡å¤š'
        
        return health_status
        
    except Exception as e:
        return {
            'status': 'error',
            'message': f'è¿æ¥å¤±è´¥: {str(e)}'
        }

# ç›‘æ§æ‰€æœ‰èŠ‚ç‚¹
nodes = [
    ('192.168.1.11', 6379),
    ('192.168.1.12', 6379),
    ('192.168.1.13', 6379)
]

def monitor_all_nodes():
    """ç›‘æ§æ‰€æœ‰RedisèŠ‚ç‚¹"""
    for host, port in nodes:
        health = check_redis_health(host, port)
        print(f"èŠ‚ç‚¹ {host}:{port} - {health['status']}")
        
        if health['status'] != 'healthy':
            send_alert(f"RedisèŠ‚ç‚¹å¼‚å¸¸: {host}:{port} - {health['message']}")
```

### 5.2 å‘Šè­¦æœºåˆ¶è®¾è®¡


#### ğŸ”¸ é˜ˆå€¼å‘Šè­¦


```python
class AlertManager:
    def __init__(self):
        self.alert_rules = {
            'hit_rate_low': {
                'threshold': 0.8,
                'description': 'ç¼“å­˜å‘½ä¸­ç‡è¿‡ä½'
            },
            'response_time_high': {
                'threshold': 100,  # æ¯«ç§’
                'description': 'å“åº”æ—¶é—´è¿‡é«˜'
            },
            'memory_usage_high': {
                'threshold': 0.85,
                'description': 'å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜'
            },
            'qps_high': {
                'threshold': 10000,
                'description': 'QPSè¿‡é«˜'
            }
        }
    
    def check_alerts(self, metrics):
        """æ£€æŸ¥æ˜¯å¦éœ€è¦å‘Šè­¦"""
        alerts = []
        
        # æ£€æŸ¥å‘½ä¸­ç‡
        if metrics.get('hit_rate', 1) < self.alert_rules['hit_rate_low']['threshold']:
            alerts.append({
                'type': 'hit_rate_low',
                'value': metrics['hit_rate'],
                'threshold': self.alert_rules['hit_rate_low']['threshold'],
                'message': f"å‘½ä¸­ç‡{metrics['hit_rate']:.2%}ä½äºé˜ˆå€¼{self.alert_rules['hit_rate_low']['threshold']:.2%}"
            })
        
        # æ£€æŸ¥å“åº”æ—¶é—´
        if metrics.get('avg_response_time', 0) > self.alert_rules['response_time_high']['threshold']:
            alerts.append({
                'type': 'response_time_high',
                'value': metrics['avg_response_time'],
                'threshold': self.alert_rules['response_time_high']['threshold'],
                'message': f"å¹³å‡å“åº”æ—¶é—´{metrics['avg_response_time']:.2f}msè¶…è¿‡é˜ˆå€¼"
            })
        
        # å‘é€å‘Šè­¦
        for alert in alerts:
            self.send_alert(alert)
        
        return alerts
    
    def send_alert(self, alert):
        """å‘é€å‘Šè­¦ï¼ˆå¯ä»¥æ˜¯é‚®ä»¶ã€çŸ­ä¿¡ã€ä¼ä¸šå¾®ä¿¡ç­‰ï¼‰"""
        message = f"""
        ğŸš¨ Redisç¼“å­˜å‘Šè­¦
        
        å‘Šè­¦ç±»å‹: {alert['type']}
        å½“å‰å€¼: {alert['value']}
        é˜ˆå€¼: {alert['threshold']}
        æè¿°: {alert['message']}
        æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
        """
        
        # è¿™é‡Œå®ç°å…·ä½“çš„å‘Šè­¦å‘é€é€»è¾‘
        print(message)
        # send_email(message)
        # send_sms(message)
        # send_wechat(message)
```

#### ğŸ”¸ æ™ºèƒ½å‘Šè­¦


```python
class SmartAlertManager:
    def __init__(self):
        self.baseline_metrics = {}  # åŸºçº¿æŒ‡æ ‡
        self.alert_history = []     # å‘Šè­¦å†å²
    
    def update_baseline(self, metrics):
        """æ›´æ–°åŸºçº¿æŒ‡æ ‡ï¼ˆåŸºäºå†å²æ•°æ®ï¼‰"""
        for key, value in metrics.items():
            if key not in self.baseline_metrics:
                self.baseline_metrics[key] = [value]
            else:
                # ä¿ç•™æœ€è¿‘100ä¸ªæ•°æ®ç‚¹
                self.baseline_metrics[key].append(value)
                if len(self.baseline_metrics[key]) > 100:
                    self.baseline_metrics[key].pop(0)
    
    def detect_anomaly(self, current_metrics):
        """å¼‚å¸¸æ£€æµ‹ï¼ˆåŸºäºç»Ÿè®¡å­¦æ–¹æ³•ï¼‰"""
        anomalies = []
        
        for key, current_value in current_metrics.items():
            if key in self.baseline_metrics and len(self.baseline_metrics[key]) >= 10:
                baseline_values = self.baseline_metrics[key]
                
                # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
                mean = statistics.mean(baseline_values)
                std_dev = statistics.stdev(baseline_values)
                
                # 3-sigmaè§„åˆ™ï¼šè¶…è¿‡3ä¸ªæ ‡å‡†å·®è®¤ä¸ºå¼‚å¸¸
                if abs(current_value - mean) > 3 * std_dev:
                    anomalies.append({
                        'metric': key,
                        'current_value': current_value,
                        'baseline_mean': mean,
                        'deviation': abs(current_value - mean) / std_dev,
                        'message': f"{key}å‡ºç°å¼‚å¸¸æ³¢åŠ¨"
                    })
        
        return anomalies
    
    def should_suppress_alert(self, alert_type):
        """å‘Šè­¦æŠ‘åˆ¶ï¼šé¿å…é‡å¤å‘Šè­¦"""
        recent_alerts = [
            alert for alert in self.alert_history 
            if alert['type'] == alert_type and 
               (datetime.now() - alert['time']).seconds < 300  # 5åˆ†é’Ÿå†…
        ]
        
        # 5åˆ†é’Ÿå†…å·²æœ‰åŒç±»å‹å‘Šè­¦ï¼ŒæŠ‘åˆ¶
        return len(recent_alerts) > 0
```

### 5.3 ç›‘æ§æ•°æ®å¯è§†åŒ–


**ç›‘æ§å¤§ç›˜é…ç½®**ï¼š
```python
class CacheDashboard:
    def __init__(self):
        self.metrics_collector = MetricsCollector()
    
    def generate_dashboard_data(self):
        """ç”Ÿæˆç›‘æ§å¤§ç›˜æ•°æ®"""
        current_time = datetime.now()
        
        # æ”¶é›†å®æ—¶æŒ‡æ ‡
        metrics = {
            'timestamp': current_time.isoformat(),
            'qps': self.metrics_collector.get_qps(),
            'hit_rate': self.metrics_collector.get_hit_rate(),
            'avg_response_time': self.metrics_collector.get_avg_response_time(),
            'memory_usage': self.metrics_collector.get_memory_usage(),
            'connected_clients': self.metrics_collector.get_connected_clients(),
            'node_status': self.metrics_collector.get_node_status()
        }
        
        return metrics
    
    def export_metrics_for_grafana(self):
        """å¯¼å‡ºGrafanaæ ¼å¼çš„ç›‘æ§æ•°æ®"""
        metrics = self.generate_dashboard_data()
        
        grafana_data = []
        for key, value in metrics.items():
            if isinstance(value, (int, float)):
                grafana_data.append({
                    'measurement': 'redis_metrics',
                    'tags': {'instance': 'redis-cluster'},
                    'fields': {key: value},
                    'timestamp': int(time.time() * 1000)
                })
        
        return grafana_data

# å®šæœŸæ¨é€ç›‘æ§æ•°æ®
def push_metrics_to_influxdb():
    """æ¨é€ç›‘æ§æ•°æ®åˆ°InfluxDB"""
    dashboard = CacheDashboard()
    data = dashboard.export_metrics_for_grafana()
    
    # æ¨é€åˆ°InfluxDBï¼ˆæ—¶åºæ•°æ®åº“ï¼‰
    # influxdb_client.write_points(data)
    print(f"æ¨é€{len(data)}ä¸ªç›‘æ§æŒ‡æ ‡åˆ°InfluxDB")

# æ¯30ç§’æ¨é€ä¸€æ¬¡
import schedule
schedule.every(30).seconds.do(push_metrics_to_influxdb)
```

---

## 6. ğŸ“‹ æ ¸å¿ƒè¦ç‚¹æ€»ç»“


### 6.1 å¿…é¡»æŒæ¡çš„åŸºæœ¬æ¦‚å¿µ


```
ğŸ”¸ åˆ†å¸ƒå¼ç¼“å­˜ï¼šå¤šèŠ‚ç‚¹åä½œçš„ç¼“å­˜ç³»ç»Ÿï¼Œè§£å†³å®¹é‡å’Œå¯ç”¨æ€§é—®é¢˜
ğŸ”¸ Redisé›†ç¾¤ï¼šæ”¯æŒæ•°æ®åˆ†ç‰‡å’Œè‡ªåŠ¨æ•…éšœåˆ‡æ¢çš„Rediséƒ¨ç½²æ¨¡å¼  
ğŸ”¸ ç¼“å­˜åˆ†ç‰‡ï¼šå°†æ•°æ®æŒ‰è§„åˆ™åˆ†æ•£åˆ°ä¸åŒèŠ‚ç‚¹ï¼Œæé«˜å¹¶å‘å’Œå®¹é‡
ğŸ”¸ ç¼“å­˜é¢„çƒ­ï¼šæå‰åŠ è½½çƒ­ç‚¹æ•°æ®ï¼Œé¿å…å†·å¯åŠ¨é—®é¢˜
ğŸ”¸ ç›‘æ§å‘Šè­¦ï¼šå®æ—¶ç›‘æ§ç³»ç»ŸçŠ¶æ€ï¼ŒåŠæ—¶å‘ç°å’Œå¤„ç†é—®é¢˜
```

### 6.2 å…³é”®ç†è§£è¦ç‚¹


**ğŸ”¹ æ¶æ„æ¨¡å¼é€‰æ‹©**
```
æ•°æ®é‡å° + ç®€å•åœºæ™¯ â†’ ä¸»ä»å¤åˆ¶
æ•°æ®é‡ä¸­ + é«˜å¯ç”¨éœ€æ±‚ â†’ å“¨å…µæ¨¡å¼  
æ•°æ®é‡å¤§ + é«˜å¹¶å‘åœºæ™¯ â†’ é›†ç¾¤æ¨¡å¼
```

**ğŸ”¹ åˆ†ç‰‡ç­–ç•¥é€‰æ‹©**
```
æ•°æ®åˆ†å¸ƒå‡åŒ€ â†’ å“ˆå¸Œåˆ†ç‰‡
é¢‘ç¹æ‰©ç¼©å®¹ â†’ ä¸€è‡´æ€§å“ˆå¸Œ
æœ‰èŒƒå›´æŸ¥è¯¢éœ€æ±‚ â†’ èŒƒå›´åˆ†ç‰‡
```

**ğŸ”¹ é¢„çƒ­æ—¶æœºæŠŠæ¡**
```
ç³»ç»Ÿå¯åŠ¨å‰ â†’ å…¨é‡é¢„çƒ­æ ¸å¿ƒæ•°æ®
é«˜å³°æœŸå‰ â†’ æŒ‰éœ€é¢„çƒ­çƒ­ç‚¹æ•°æ®
ç‰¹æ®Šæ´»åŠ¨å‰ â†’ äº‹ä»¶é©±åŠ¨é¢„çƒ­
```

### 6.3 å®é™…åº”ç”¨ä»·å€¼


**ğŸ’¼ ä¸šåŠ¡åœºæ™¯åº”ç”¨**
- **ç”µå•†ç½‘ç«™**ï¼šå•†å“ä¿¡æ¯ç¼“å­˜é›†ç¾¤ï¼Œæ”¯æŒå¤§ä¿ƒæ´»åŠ¨
- **ç¤¾äº¤åº”ç”¨**ï¼šç”¨æˆ·å…³ç³»æ•°æ®åˆ†ç‰‡å­˜å‚¨ï¼Œå¿«é€ŸæŸ¥è¯¢
- **å†…å®¹å¹³å°**ï¼šçƒ­ç‚¹å†…å®¹é¢„çƒ­ï¼Œä¿è¯ç”¨æˆ·ä½“éªŒ
- **é‡‘èç³»ç»Ÿ**ï¼šäº¤æ˜“æ•°æ®ç¼“å­˜ï¼Œä¸¥æ ¼ç›‘æ§èµ„é‡‘å®‰å…¨

**ğŸ”§ å·¥ç¨‹å®è·µ**
- **å®¹é‡è§„åˆ’**ï¼šåŸºäºä¸šåŠ¡å¢é•¿é¢„æµ‹ï¼Œæå‰æ‰©å®¹
- **æ€§èƒ½è°ƒä¼˜**ï¼šæ ¹æ®ç›‘æ§æ•°æ®ï¼Œä¼˜åŒ–ç¼“å­˜ç­–ç•¥
- **æ•…éšœå¤„ç†**ï¼šå»ºç«‹è‡ªåŠ¨åŒ–è¿ç»´ï¼Œå¿«é€Ÿæ¢å¤æœåŠ¡
- **æˆæœ¬æ§åˆ¶**ï¼šå¹³è¡¡æ€§èƒ½å’Œèµ„æºæˆæœ¬ï¼Œåˆç†é…ç½®

**æ ¸å¿ƒè®°å¿†**ï¼š
- åˆ†å¸ƒå¼ç¼“å­˜è§£å†³å•æœºé™åˆ¶ï¼Œå¤šèŠ‚ç‚¹åä½œæå‡èƒ½åŠ›
- æ¶æ„é€‰æ‹©çœ‹åœºæ™¯ï¼Œåˆ†ç‰‡ç­–ç•¥çœ‹éœ€æ±‚ï¼Œé¢„çƒ­ç­–ç•¥çœ‹æ—¶æœº  
- ç›‘æ§å‘Šè­¦æ˜¯ä¿éšœï¼Œå®æ—¶æŒæ¡ç³»ç»Ÿå¥åº·çŠ¶æ€
- å·¥ç¨‹å®è·µé‡ç»éªŒï¼ŒæŒç»­ä¼˜åŒ–è¿½æ±‚æ›´å¥½æ•ˆæœ