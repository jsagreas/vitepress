---
title: 3、运维操作命令详解
---
## 📚 目录

1. [服务管理命令](#1-服务管理命令)
2. [配置管理命令](#2-配置管理命令)
3. [内存管理命令](#3-内存管理命令)
4. [性能监控命令](#4-性能监控命令)
5. [数据库管理命令](#5-数据库管理命令)
6. [键值管理命令](#6-键值管理命令)
7. [复制和集群命令](#7-复制和集群命令)
8. [调试和诊断命令](#8-调试和诊断命令)
9. [运维脚本和自动化](#9-运维脚本和自动化)
10. [故障诊断和监控](#10-故障诊断和监控)
11. [核心要点总结](#11-核心要点总结)

---

## 1. 🔧 服务管理命令


### 1.1 Redis服务控制


#### 🔴 SHUTDOWN - 安全关闭服务


**作用**：安全优雅地关闭Redis服务器，确保数据不丢失

```bash
# 基本语法
SHUTDOWN [SAVE|NOSAVE]

# 实际使用
SHUTDOWN           # 默认会先保存数据再关闭
SHUTDOWN SAVE      # 强制保存数据后关闭
SHUTDOWN NOSAVE    # 不保存数据直接关闭（危险操作）
```

**🛡️ 优雅停机流程**
```
SHUTDOWN执行过程：
1. 停止接收新的客户端连接
2. 等待当前命令执行完成
3. 执行数据持久化（如果配置了）
4. 关闭所有客户端连接
5. 退出服务器进程

与kill -9的区别：
kill -9：强制杀死进程，可能导致数据丢失
SHUTDOWN：优雅关闭，保证数据安全
```

#### 🏥 PING - 连接测试


**作用**：检测Redis服务器是否正常响应

```bash
# 基本使用
redis-cli ping
# 返回：PONG

# 带消息的ping
redis-cli ping "Hello Redis"
# 返回：Hello Redis

# 脚本中的健康检查
if redis-cli ping > /dev/null 2>&1; then
    echo "Redis服务正常"
else
    echo "Redis服务异常"
fi
```

#### 🔊 ECHO - 回显测试


**作用**：测试客户端与服务器的通信是否正常

```bash
# 基本语法
ECHO message

# 实际示例
ECHO "测试连接"      # 返回："测试连接"
ECHO "Hello World"   # 返回："Hello World"

# 用于调试网络连接问题
```

#### ⏰ TIME - 服务器时间


**作用**：获取Redis服务器的当前时间戳

```bash
# 获取服务器时间
TIME
# 返回：
# 1) "1693276800"    # Unix时间戳（秒）
# 2) "123456"        # 微秒部分

# 用于时钟同步检查
def check_time_sync():
    redis_time = redis.time()
    local_time = time.time()
    if abs(redis_time[0] - local_time) > 5:
        alert("Redis服务器时钟偏差超过5秒")
```

### 1.2 服务信息查看


#### 📊 INFO - 服务器信息


**作用**：获取Redis服务器的详细运行信息，是运维监控的核心命令

```bash
# 基本语法
INFO [section]

# 获取所有信息
INFO

# 获取特定分段信息
INFO server          # 服务器基本信息
INFO memory          # 内存使用信息
INFO clients         # 客户端连接信息
INFO persistence     # 持久化信息
INFO stats           # 统计信息
INFO replication     # 复制信息
INFO cpu             # CPU使用信息
INFO keyspace        # 键空间信息
```

**📈 INFO各分段详解**
```
INFO server输出示例：
redis_version:7.0.0              # Redis版本
redis_mode:standalone            # 运行模式（standalone/cluster）
os:Linux 5.4.0-42-generic      # 操作系统信息
arch_bits:64                    # 架构位数
process_id:12345                # 进程ID
uptime_in_seconds:86400         # 运行时间（秒）

INFO memory输出示例：
used_memory:1048576             # 已使用内存（字节）
used_memory_human:1.00M         # 人类可读格式
used_memory_peak:2097152        # 内存使用峰值
mem_fragmentation_ratio:1.05    # 内存碎片率

INFO clients输出示例：
connected_clients:10            # 当前连接的客户端数
blocked_clients:2               # 阻塞的客户端数
```

#### 🔍 INFO专项信息查看


**🔄 INFO replication - 主从复制信息**
```bash
INFO replication
# 主服务器输出：
role:master                     # 角色：主服务器
connected_slaves:2              # 连接的从服务器数量
slave0:ip=192.168.1.101,port=6379,state=online,offset=1024
slave1:ip=192.168.1.102,port=6379,state=online,offset=1024

# 从服务器输出：
role:slave                      # 角色：从服务器  
master_host:192.168.1.100       # 主服务器地址
master_port:6379                # 主服务器端口
master_link_status:up           # 主从连接状态
```

**💾 INFO persistence - 持久化信息**
```bash
INFO persistence
# 关键输出：
loading:0                       # 是否正在加载数据
rdb_changes_since_last_save:10  # 自上次保存后的变更数
rdb_last_save_time:1693276800   # 上次RDB保存时间
rdb_last_bgsave_status:ok       # 上次后台保存状态
aof_enabled:1                   # AOF是否启用
aof_rewrite_in_progress:0       # 是否正在重写AOF
```

**📈 INFO stats - 统计信息**
```bash
INFO stats
# 关键指标：
total_commands_processed:1000000    # 总处理命令数
total_connections_received:5000     # 总连接数
expired_keys:100                    # 过期键数量
evicted_keys:50                     # 被驱逐键数量
keyspace_hits:800000               # 命中次数
keyspace_misses:200000             # 未命中次数
```

### 1.3 客户端连接管理


#### 👥 CLIENT LIST - 连接查看


**作用**：查看当前所有客户端连接信息

```bash
# 查看所有连接
CLIENT LIST

# 输出示例
id=3 addr=127.0.0.1:52623 fd=8 name= age=183 idle=0 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=26 qbuf-free=32742 obl=0 oll=0 omem=0 events=r cmd=client

# 关键字段解释：
id=3              # 客户端ID
addr=127.0.0.1    # 客户端IP和端口
age=183           # 连接存活时间（秒）
idle=0            # 空闲时间（秒）
flags=N           # 连接标志（N=normal）
db=0              # 当前选择的数据库
cmd=client        # 最后执行的命令
```

#### ⚡ CLIENT KILL - 连接管理


**作用**：关闭指定的客户端连接

```bash
# 根据IP:PORT关闭连接
CLIENT KILL 127.0.0.1:52623

# 根据ID关闭连接  
CLIENT KILL ID 3

# 批量关闭连接
CLIENT KILL TYPE normal          # 关闭普通连接
CLIENT KILL ADDR 192.168.1.100   # 关闭指定IP的所有连接

# 关闭空闲连接
CLIENT KILL IDLE 300             # 关闭空闲5分钟以上的连接
```

**🔧 连接监控脚本**
```bash
# 监控异常连接
def monitor_connections():
    connections = redis.execute_command("CLIENT LIST")
    
    for conn in connections.split('\n'):
        if not conn:
            continue
            
        # 解析连接信息
        conn_info = parse_connection_info(conn)
        
        # 检查异常连接
        if conn_info['idle'] > 3600:  # 空闲超过1小时
            redis.execute_command(f"CLIENT KILL ID {conn_info['id']}")
            
        if conn_info['qbuf'] > 1024*1024:  # 查询缓冲区过大
            alert(f"客户端{conn_info['addr']}缓冲区过大")
```

---

## 2. ⚙️ 配置管理命令


### 2.1 动态配置管理


#### 🔍 CONFIG GET - 配置查看


**作用**：查看Redis的配置参数，无需重启服务器

```bash
# 查看所有配置
CONFIG GET "*"

# 查看特定配置
CONFIG GET maxmemory         # 最大内存限制
CONFIG GET timeout           # 客户端超时时间
CONFIG GET save              # RDB保存策略
CONFIG GET appendonly        # AOF配置

# 查看配置示例
CONFIG GET maxmemory
# 返回：
# 1) "maxmemory"
# 2) "1073741824"    # 1GB

CONFIG GET save
# 返回：
# 1) "save"  
# 2) "900 1 300 10 60 10000"    # 900秒1次变更 或 300秒10次变更 或 60秒10000次变更
```

#### ⚡ CONFIG SET - 动态配置


**作用**：在线修改Redis配置，立即生效，无需重启

```bash
# 基本语法
CONFIG SET parameter value

# 内存配置调整
CONFIG SET maxmemory 2147483648        # 设置最大内存2GB
CONFIG SET maxmemory-policy allkeys-lru # 设置内存淘汰策略

# 客户端超时设置
CONFIG SET timeout 300                 # 客户端5分钟无活动自动断开

# 日志级别调整
CONFIG SET loglevel notice            # 设置日志级别

# AOF配置调整
CONFIG SET auto-aof-rewrite-percentage 100   # AOF重写阈值
CONFIG SET auto-aof-rewrite-min-size 67108864 # AOF重写最小文件大小
```

**⚠️ 配置修改注意事项**
```
临时生效：CONFIG SET只影响当前运行实例
持久化：需要执行CONFIG REWRITE写入配置文件
验证修改：使用CONFIG GET确认修改结果

# 持久化配置修改
CONFIG SET maxmemory 2gb
CONFIG REWRITE                 # 写入redis.conf文件
```

### 2.2 模块管理


#### 🧩 MODULE命令 - 模块管理


**作用**：动态加载和管理Redis模块，扩展Redis功能

```bash
# 查看已加载模块
MODULE LIST
# 返回示例：
# 1) 1) "name"
#    2) "ReJSON"
#    3) "ver"  
#    4) 999999

# 加载模块
MODULE LOAD /path/to/module.so

# 卸载模块
MODULE UNLOAD module_name

# 实际应用示例
MODULE LOAD /usr/lib/redis/modules/rejson.so    # 加载JSON模块
MODULE LIST                                     # 确认加载成功
MODULE UNLOAD ReJSON                            # 卸载模块
```

---

## 3. 💾 内存管理命令


### 3.1 内存使用分析


#### 📏 MEMORY USAGE - 键内存占用


**作用**：精确计算指定键的内存占用，帮助识别大key

```bash
# 基本语法
MEMORY USAGE key [SAMPLES count]

# 实际示例
MEMORY USAGE user:1001               # 返回：96（字节）
MEMORY USAGE large_hash              # 返回：2048576（约2MB）

# 采样模式（提高大对象分析精度）
MEMORY USAGE large_set SAMPLES 10   # 使用10个样本估算

# 批量分析脚本
def find_large_keys():
    large_keys = []
    cursor = 0
    
    while True:
        cursor, keys = redis.scan(cursor, count=100)
        for key in keys:
            memory_usage = redis.memory_usage(key)
            if memory_usage > 1024*1024:  # 大于1MB
                large_keys.append({
                    'key': key,
                    'memory': memory_usage,
                    'type': redis.type(key)
                })
        
        if cursor == 0:
            break
    
    return sorted(large_keys, key=lambda x: x['memory'], reverse=True)
```

#### 📊 MEMORY STATS - 内存统计


**作用**：获取Redis内存使用的详细统计信息

```bash
MEMORY STATS

# 返回详细内存信息
 1) "peak.allocated"          # 历史内存使用峰值
 2) (integer) 2097152
 3) "total.allocated"         # 当前分配的内存总量
 4) (integer) 1048576
 5) "startup.allocated"       # 启动时分配的内存
 6) (integer) 524288
 7) "replication.backlog"     # 复制积压缓冲区内存
 8) (integer) 0
 9) "clients.slaves"          # 从服务器客户端内存
10) (integer) 0
11) "clients.normal"          # 普通客户端内存
12) (integer) 16384
13) "aof.buffer"             # AOF缓冲区内存
14) (integer) 0
```

### 3.2 内存优化


#### 🧹 MEMORY PURGE - 内存碎片整理


**作用**：主动触发内存碎片整理，优化内存使用效率

```bash
# 执行内存整理
MEMORY PURGE

# 整理效果检查
INFO memory
# 查看mem_fragmentation_ratio（内存碎片率）
# 1.0 = 无碎片，>1.5 = 碎片较多，需要整理
```

**⚡ 内存碎片分析**
```
内存碎片产生原因：
1. 频繁的键删除操作
2. 键值大小变化
3. 数据类型转换
4. 长时间运行

碎片率计算：
fragmentation_ratio = used_memory_rss / used_memory

健康标准：
1.0 - 1.3：正常范围
1.3 - 1.5：需要关注  
> 1.5：需要整理碎片
```

#### 🩺 MEMORY DOCTOR - 内存诊断


**作用**：分析内存使用情况并提供优化建议

```bash
MEMORY DOCTOR

# 可能的输出示例：
# "Hi Sam, I can see a few issues with your Reids instance memory implants:
#  
# * Peak memory: In the past your instance used considerably more memory than it is currently using. Make sure to set the maxmemory directive carefully.
#  
# * High fragmentation: This instance has a memory fragmentation greater than 1.4 (it is 1.53). This can be a source of memory usage inefficiency."

# 常见建议类型：
# - 内存碎片过高建议
# - maxmemory配置建议
# - 大key优化建议
# - 数据过期策略建议
```

---

## 4. 📈 性能监控命令


### 4.1 实时监控


#### 👁️ MONITOR - 实时命令监控


**作用**：实时显示Redis服务器接收的所有命令，用于调试和分析

```bash
# 启动监控
MONITOR

# 实时输出示例：
1693276890.123456 [0 127.0.0.1:52623] "SET" "user:1001" "张三"
1693276891.456789 [0 127.0.0.1:52624] "GET" "user:1001" 
1693276892.789123 [0 127.0.0.1:52625] "LPUSH" "task_queue" "send_email"

# 输出格式解释：
时间戳 [数据库ID 客户端地址] "命令" "参数1" "参数2"
```

**⚠️ 使用注意事项**
```
性能影响：MONITOR会降低Redis性能约50%
生产环境：仅在故障排查时短时间使用
调试场景：开发环境分析命令执行情况
替代方案：使用slowlog监控慢查询
```

### 4.2 慢查询监控


#### 🐌 SLOWLOG - 慢查询日志


**作用**：记录和分析执行时间较长的命令，定位性能瓶颈

```bash
# 获取慢查询日志
SLOWLOG GET         # 获取所有慢查询记录
SLOWLOG GET 10      # 获取最近10条慢查询

# 慢查询日志长度
SLOWLOG LEN         # 返回：15（当前有15条慢查询记录）

# 重置慢查询日志
SLOWLOG RESET       # 清空所有慢查询记录
```

**📊 慢查询记录格式**
```
SLOWLOG GET 1
# 返回：
1) 1) (integer) 14              # 日志ID
   2) (integer) 1693276890      # 执行时间戳  
   3) (integer) 15000           # 执行耗时（微秒）
   4) 1) "KEYS"                 # 执行的命令
      2) "*"                    # 命令参数
   5) "127.0.0.1:52623"        # 客户端地址
   6) ""                       # 客户端名称

解读：命令KEYS *耗时15ms，来自127.0.0.1:52623
```

**⚙️ 慢查询配置**
```bash
# 查看慢查询配置
CONFIG GET slowlog*
# 返回：
# 1) "slowlog-log-slower-than"
# 2) "10000"          # 超过10ms记录为慢查询
# 3) "slowlog-max-len"  
# 4) "128"            # 最多保存128条记录

# 调整慢查询阈值
CONFIG SET slowlog-log-slower-than 5000    # 5ms以上记录
CONFIG SET slowlog-max-len 256             # 保存256条记录
```

### 4.3 延迟监控


#### ⏱️ LATENCY - 延迟监控


**作用**：监控Redis各种操作的延迟情况

```bash
# 查看最新延迟信息
LATENCY LATEST

# 返回示例：
1) 1) "command"        # 事件类型
   2) (integer) 1693276890   # 时间戳
   3) (integer) 250     # 延迟时间（毫秒）
   4) (integer) 500     # 最大延迟

# 查看延迟历史
LATENCY HISTORY command

# 延迟监控配置
CONFIG SET latency-monitor-threshold 100    # 监控超过100ms的操作
```

### 4.4 性能基准测试


#### 🏃 REDIS-BENCHMARK - 性能测试


**作用**：对Redis进行压力测试，评估性能表现

```bash
# 基础性能测试
redis-benchmark

# 自定义测试参数
redis-benchmark -h 127.0.0.1 -p 6379 -c 50 -n 10000
# -h: 主机地址
# -p: 端口
# -c: 并发连接数
# -n: 请求总数

# 测试特定命令
redis-benchmark -t set,get -n 100000    # 只测试SET和GET
redis-benchmark -t lpush -n 50000       # 只测试LPUSH

# 测试输出示例：
====== SET ======
  100000 requests completed in 1.23 seconds
  50 parallel clients
  3 bytes payload
  keep alive: 1

99.99% <= 1 milliseconds
100.00% <= 1 milliseconds
81300.81 requests per second
```

### 4.5 命令统计


#### 📊 COMMAND - 命令信息


**作用**：获取Redis命令的使用统计和详细信息

```bash
# 获取命令总数
COMMAND COUNT        # 返回：Redis支持的命令总数

# 获取命令详细信息
COMMAND INFO SET GET LPUSH

# 返回示例：
1) 1) "set"          # 命令名
   2) (integer) -3    # 参数数量（-3表示至少3个参数）
   3) 1) write        # 命令标志
   4) (integer) 1     # 第一个key的位置
   5) (integer) 1     # 最后一个key的位置
   6) (integer) 1     # key步长
```

---

## 5. 🗄️ 数据库管理命令


### 5.1 数据库操作


#### 🗑️ FLUSHDB/FLUSHALL - 数据清空


**作用**：清空数据库中的所有键值

```bash
# 清空当前数据库
FLUSHDB

# 清空所有数据库（0-15）
FLUSHALL  

# 异步清空（推荐生产环境）
FLUSHDB ASYNC     # 后台异步清空，不阻塞服务
FLUSHALL ASYNC    # 异步清空所有数据库
```

> 🚨 **危险操作警告**：FLUSHDB/FLUSHALL会删除所有数据，生产环境需要确认再确认！

**🛡️ 安全防护措施**
```bash
# 生产环境防护脚本
def safe_flush():
    # 1. 确认环境
    if is_production():
        raise Exception("生产环境禁止FLUSH操作")
    
    # 2. 备份确认
    if not has_recent_backup():
        raise Exception("请先创建备份")
    
    # 3. 二次确认
    confirm = input("确认清空数据库？输入'YES'确认：")
    if confirm != 'YES':
        return "操作已取消"
    
    # 4. 执行清空
    redis.flushdb()
```

#### 📐 DBSIZE - 数据库大小


**作用**：获取当前数据库的键数量

```bash
DBSIZE    # 返回：10000（当前数据库有10000个键）

# 监控脚本示例
def monitor_database_size():
    for db_num in range(16):  # Redis默认16个数据库
        redis.select(db_num)
        size = redis.dbsize()
        if size > 0:
            print(f"数据库{db_num}: {size}个键")
```

### 5.2 数据备份


#### 💾 BGSAVE/SAVE - 数据备份


**作用**：手动触发RDB快照备份

```bash
# 后台异步保存（推荐）
BGSAVE
# 返回："Background saving started"

# 阻塞保存（会阻塞Redis服务）  
SAVE
# 返回："OK"

# 检查备份状态
LASTSAVE    # 返回上次备份的Unix时间戳
```

**🔄 备份流程对比**
```
BGSAVE流程：
1. fork子进程
2. 子进程创建RDB文件
3. 主进程继续服务客户端
4. 备份完成后替换旧文件

SAVE流程：
1. 阻塞所有客户端请求
2. 创建RDB快照文件  
3. 完成后恢复服务

建议：生产环境使用BGSAVE，避免服务中断
```

#### 🕐 LASTSAVE - 备份状态


**作用**：获取最后一次成功执行SAVE/BGSAVE的时间

```bash
LASTSAVE
# 返回：1693276890（Unix时间戳）

# 备份状态检查
def check_backup_status():
    last_save = redis.lastsave()
    current_time = time.time()
    
    # 检查备份是否及时
    if current_time - last_save > 3600:  # 超过1小时未备份
        alert("Redis超过1小时未进行备份")
        
    # 检查备份是否成功
    info = redis.info('persistence')
    if info['rdb_last_bgsave_status'] != 'ok':
        alert("上次备份失败，请检查")
```

---

## 6. 🔑 键值管理命令


### 6.1 键遍历操作


#### 🔍 SCAN - 安全键遍历


**作用**：分批次安全遍历所有键，不会阻塞Redis服务

```bash
# 基本语法
SCAN cursor [MATCH pattern] [COUNT count]

# 基础遍历
SCAN 0              # 从游标0开始扫描
# 返回：
# 1) "6"             # 下次扫描的游标
# 2) 1) "key1"       # 本次返回的键列表
#    2) "key2"
#    3) "key3"

# 继续扫描
SCAN 6              # 使用上次返回的游标

# 模式匹配扫描
SCAN 0 MATCH user:*         # 只返回user:开头的键
SCAN 0 MATCH *:config       # 只返回config结尾的键

# 控制返回数量  
SCAN 0 COUNT 1000           # 每次尽量返回1000个键
```

**🔒 SCAN vs KEYS的区别**
```
KEYS命令：
优点：一次返回所有匹配的键
缺点：会阻塞Redis服务，生产环境危险

SCAN命令：
优点：分批返回，不阻塞服务，生产环境安全
缺点：需要多次调用，可能有重复

生产环境使用：
❌ 禁用：KEYS *
✅ 推荐：SCAN遍历
```

#### 🎲 RANDOMKEY - 随机键获取


**作用**：随机返回数据库中的一个键

```bash
RANDOMKEY
# 返回：随机的键名，如"user:1001"

# 数据抽样检查
def sample_data_check():
    for _ in range(10):  # 抽样10个键
        key = redis.randomkey()
        if key:
            key_type = redis.type(key)
            memory_usage = redis.memory_usage(key)
            ttl = redis.ttl(key)
            
            print(f"键: {key}, 类型: {key_type}, 内存: {memory_usage}字节, TTL: {ttl}")
```

### 6.2 对象分析


#### 🔍 OBJECT - 对象信息


**作用**：查看键的内部存储信息，用于性能分析和优化

```bash
# 查看对象编码
OBJECT ENCODING key_name
# 可能返回：
# "int"        # 整数编码
# "embstr"     # 嵌入字符串编码  
# "raw"        # 原始字符串编码
# "hashtable"  # 哈希表编码
# "ziplist"    # 压缩列表编码

# 查看对象空闲时间
OBJECT IDLETIME key_name    # 返回键的空闲时间（秒）

# 查看引用计数
OBJECT REFCOUNT key_name    # 返回对象的引用计数

# 性能优化分析
def analyze_key_performance(key):
    encoding = redis.execute_command("OBJECT ENCODING", key)
    idle_time = redis.execute_command("OBJECT IDLETIME", key) 
    memory = redis.memory_usage(key)
    
    print(f"键: {key}")
    print(f"编码: {encoding}")
    print(f"空闲时间: {idle_time}秒")
    print(f"内存占用: {memory}字节")
    
    # 优化建议
    if encoding == 'raw' and memory < 64:
        print("建议：小字符串可能可以优化为embstr编码")
```

#### 🔬 DEBUG OBJECT - 调试信息


**作用**：获取键的详细内部调试信息

```bash
DEBUG OBJECT key_name

# 返回示例：
# Value at:0x7f8b8c0a0000 refcount:1 encoding:raw serializedlength:9 lru:677963 lru_seconds_idle:10

# 信息解释：
# Value at: 内存地址
# refcount: 引用计数
# encoding: 编码类型
# serializedlength: 序列化长度
# lru: LRU时间
# lru_seconds_idle: 空闲时间
```

---

## 7. 🔄 复制和集群命令


### 7.1 主从复制


#### 🔗 REPLICAOF - 复制配置


**作用**：配置主从复制关系，实现数据同步和高可用

```bash
# 设置为从服务器
REPLICAOF 192.168.1.100 6379    # 复制192.168.1.100:6379的数据

# 停止复制，变为主服务器
REPLICAOF NO ONE

# 复制状态检查
INFO replication
```

**🏗️ 主从复制架构**
```
主从复制结构：
    主服务器(Master)
    192.168.1.100:6379
           │
    ┌──────┼──────┐
    │      │      │
从服务器1  从服务器2  从服务器3
  :6379    :6379    :6379

数据流向：主服务器 → 从服务器（单向同步）
```

#### 👑 ROLE - 角色查看


**作用**：查看当前Redis实例的角色信息

```bash
ROLE

# 主服务器返回：
1) "master"                    # 角色
2) (integer) 1024             # 复制偏移量
3) 1) 1) "192.168.1.101"      # 从服务器1
      2) "6379"               # 端口
      3) "1024"               # 复制偏移量
   2) 1) "192.168.1.102"      # 从服务器2
      2) "6379"
      3) "1024"

# 从服务器返回：
1) "slave"                    # 角色
2) "192.168.1.100"           # 主服务器IP
3) (integer) 6379            # 主服务器端口
4) "connected"               # 连接状态
5) (integer) 1024            # 复制偏移量
```

### 7.2 集群管理


#### 🌐 CLUSTER INFO - 集群状态


**作用**：查看Redis集群的整体状态信息

```bash
CLUSTER INFO

# 返回示例：
cluster_state:ok                    # 集群状态
cluster_slots_assigned:16384        # 已分配槽数
cluster_slots_ok:16384              # 正常槽数
cluster_slots_pfail:0               # 可能失败槽数
cluster_slots_fail:0                # 失败槽数
cluster_known_nodes:6               # 已知节点数
cluster_size:3                      # 集群大小
```

#### 🔍 CLUSTER NODES - 节点状态


**作用**：查看集群中所有节点的详细状态

```bash
CLUSTER NODES

# 返回示例：
07c37dfeb235213a872192d90877d0cd55635b91 192.168.1.100:6379@16379 myself,master - 0 1693276890000 1 connected 0-5460
279fcacfca9f79dcad983d273a42a5a67f23e5d 192.168.1.101:6379@16379 master - 0 1693276891000 2 connected 5461-10922  
6ec23923021cf3de6f2c9bb6b6b1ad5c0c4b0e3a 192.168.1.102:6379@16379 master - 0 1693276892000 3 connected 10923-16383

# 字段说明：
# 节点ID 节点地址 角色和状态 父节点 ping时间戳 epoch 状态 槽分配
```

#### 🤝 CLUSTER MEET/FORGET - 节点管理


**作用**：动态添加或移除集群节点

```bash
# 添加新节点到集群
CLUSTER MEET 192.168.1.103 6379

# 从集群中移除节点
CLUSTER FORGET 6ec23923021cf3de6f2c9bb6b6b1ad5c0c4b0e3a

# 节点管理脚本
def add_node_to_cluster(new_node_ip, new_node_port):
    # 1. 让现有节点认识新节点
    redis.execute_command("CLUSTER MEET", new_node_ip, new_node_port)
    
    # 2. 等待节点握手完成
    time.sleep(5)
    
    # 3. 检查节点是否成功加入
    nodes = redis.execute_command("CLUSTER NODES")
    if f"{new_node_ip}:{new_node_port}" in nodes:
        print("节点添加成功")
    else:
        print("节点添加失败")
```

---

## 8. 🔍 调试和诊断命令


> 这部分内容已在前面的服务管理命令中覆盖（ping、echo、time），这里不重复

---

## 9. 🤖 运维脚本和自动化


### 9.1 健康监控脚本


**🏥 健康检查脚本**
```python
#!/usr/bin/env python3
import redis
import time
import smtplib
from datetime import datetime

class RedisHealthChecker:
    def __init__(self, host='localhost', port=6379):
        self.redis = redis.Redis(host=host, port=port)
        
    def check_basic_health(self):
        """基础健康检查"""
        try:
            # 连接测试
            self.redis.ping()
            
            # 基础信息获取
            info = self.redis.info()
            return {
                'status': 'healthy',
                'uptime': info['uptime_in_seconds'],
                'memory_usage': info['used_memory'],
                'connected_clients': info['connected_clients']
            }
        except Exception as e:
            return {'status': 'unhealthy', 'error': str(e)}
    
    def check_memory_health(self):
        """内存健康检查"""
        info = self.redis.info('memory')
        
        memory_usage_ratio = info['used_memory'] / info['maxmemory'] if info['maxmemory'] > 0 else 0
        fragmentation_ratio = info.get('mem_fragmentation_ratio', 1.0)
        
        alerts = []
        if memory_usage_ratio > 0.8:
            alerts.append(f"内存使用率过高：{memory_usage_ratio:.2%}")
        
        if fragmentation_ratio > 1.5:
            alerts.append(f"内存碎片率过高：{fragmentation_ratio:.2f}")
        
        return alerts

    def check_slowlog(self):
        """慢查询检查"""  
        slowlog = self.redis.slowlog_get(10)
        recent_slow = []
        
        for log in slowlog:
            if log['start_time'] > time.time() - 300:  # 最近5分钟
                recent_slow.append({
                    'command': ' '.join(log['command']),
                    'duration': log['duration'],
                    'timestamp': log['start_time']
                })
        
        return recent_slow
```

**📊 监控告警脚本**
```python
class RedisMonitor:
    def __init__(self):
        self.redis = redis.Redis()
        self.alert_thresholds = {
            'memory_usage_ratio': 0.85,
            'fragmentation_ratio': 1.5,
            'connected_clients': 1000,
            'slowlog_count': 10
        }
    
    def run_monitoring(self):
        """执行监控检查"""
        alerts = []
        
        # 内存检查
        memory_alerts = self.check_memory()
        alerts.extend(memory_alerts)
        
        # 客户端连接检查
        client_alerts = self.check_clients()
        alerts.extend(client_alerts)
        
        # 慢查询检查
        slowlog_alerts = self.check_slowlog()
        alerts.extend(slowlog_alerts)
        
        # 发送告警
        if alerts:
            self.send_alerts(alerts)
    
    def send_alerts(self, alerts):
        """发送告警通知"""
        message = "Redis告警信息：\n" + "\n".join(alerts)
        # 发送邮件/短信/钉钉通知
        print(f"[ALERT] {datetime.now()}: {message}")
```

### 9.2 数据管理脚本


**💾 自动备份脚本**
```bash
#!/bin/bash
# Redis自动备份脚本

REDIS_CLI="/usr/bin/redis-cli"
BACKUP_DIR="/data/redis/backup"
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="redis_backup_${DATE}.rdb"

# 创建备份目录
mkdir -p ${BACKUP_DIR}

# 执行后台保存
echo "开始备份 Redis 数据..."
${REDIS_CLI} BGSAVE

# 等待备份完成
while true; do
    SAVE_STATUS=$(${REDIS_CLI} LASTSAVE)
    CURRENT_TIME=$(date +%s)
    
    # 检查备份是否完成（时间戳更新）
    if [ $((CURRENT_TIME - SAVE_STATUS)) -lt 10 ]; then
        echo "备份完成"
        break
    fi
    
    sleep 2
done

# 复制RDB文件到备份目录
cp /var/lib/redis/dump.rdb ${BACKUP_DIR}/${BACKUP_FILE}

# 清理7天前的备份
find ${BACKUP_DIR} -name "redis_backup_*.rdb" -mtime +7 -delete

echo "备份完成：${BACKUP_DIR}/${BACKUP_FILE}"
```

**📊 数据迁移脚本**
```python
def redis_data_migration():
    """Redis数据迁移脚本"""
    source_redis = redis.Redis(host='old-server', port=6379)
    target_redis = redis.Redis(host='new-server', port=6379)
    
    cursor = 0
    migrated_count = 0
    
    while True:
        # 分批迁移数据
        cursor, keys = source_redis.scan(cursor, count=1000)
        
        for key in keys:
            try:
                # 获取键的类型和数据
                key_type = source_redis.type(key)
                ttl = source_redis.ttl(key)
                
                if key_type == 'string':
                    value = source_redis.get(key)
                    target_redis.set(key, value)
                elif key_type == 'hash':
                    hash_data = source_redis.hgetall(key)
                    target_redis.hmset(key, hash_data)
                # ... 其他数据类型处理
                
                # 设置过期时间
                if ttl > 0:
                    target_redis.expire(key, ttl)
                    
                migrated_count += 1
                
            except Exception as e:
                print(f"迁移键 {key} 失败: {e}")
        
        print(f"已迁移 {migrated_count} 个键")
        
        if cursor == 0:
            break
    
    print(f"迁移完成，总计 {migrated_count} 个键")
```

### 9.3 性能测试脚本


**🏃 性能测试脚本**
```python
import subprocess
import json
from datetime import datetime

class RedisBenchmarkRunner:
    def __init__(self, host='localhost', port=6379):
        self.host = host
        self.port = port
        
    def run_comprehensive_test(self):
        """全面性能测试"""
        test_configs = [
            {'name': 'SET测试', 'cmd': 'set', 'clients': 50, 'requests': 100000},
            {'name': 'GET测试', 'cmd': 'get', 'clients': 50, 'requests': 100000},
            {'name': 'LPUSH测试', 'cmd': 'lpush', 'clients': 50, 'requests': 50000},
            {'name': 'HSET测试', 'cmd': 'hset', 'clients': 50, 'requests': 50000}
        ]
        
        results = []
        for config in test_configs:
            result = self.run_single_test(config)
            results.append(result)
            
        return self.generate_report(results)
    
    def run_single_test(self, config):
        """执行单项测试"""
        cmd = [
            'redis-benchmark',
            '-h', self.host,
            '-p', str(self.port),
            '-t', config['cmd'],
            '-c', str(config['clients']),
            '-n', str(config['requests']),
            '--csv'
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        # 解析结果
        if result.returncode == 0:
            # 解析CSV输出获取QPS
            lines = result.stdout.strip().split('\n')
            for line in lines:
                if config['cmd'] in line.lower():
                    qps = line.split(',')[1].strip('"')
                    return {
                        'test_name': config['name'],
                        'qps': float(qps),
                        'status': 'success'
                    }
        
        return {
            'test_name': config['name'], 
            'status': 'failed',
            'error': result.stderr
        }
```

### 9.4 故障处理脚本


**🚨 故障处理脚本**
```python
class RedisFailureHandler:
    def __init__(self):
        self.redis = redis.Redis()
        
    def handle_memory_pressure(self):
        """处理内存压力"""
        info = self.redis.info('memory')
        
        if info['used_memory'] / info['maxmemory'] > 0.9:
            print("检测到内存压力，开始处理...")
            
            # 1. 清理过期键
            expired_count = 0
            cursor = 0
            while True:
                cursor, keys = self.redis.scan(cursor, count=1000)
                for key in keys:
                    if self.redis.ttl(key) == -1:  # 没有设置过期时间
                        # 根据业务逻辑设置合理的过期时间
                        self.redis.expire(key, 86400)  # 设置1天过期
                        expired_count += 1
                
                if cursor == 0:
                    break
            
            # 2. 内存碎片整理
            self.redis.execute_command("MEMORY PURGE")
            
            print(f"内存优化完成，处理了{expired_count}个键")
    
    def handle_slow_queries(self):
        """处理慢查询"""
        slowlog = self.redis.slowlog_get(100)
        
        # 统计慢查询命令
        slow_commands = {}
        for log in slowlog:
            cmd = log['command'][0]
            slow_commands[cmd] = slow_commands.get(cmd, 0) + 1
        
        # 输出统计结果
        print("慢查询统计：")
        for cmd, count in sorted(slow_commands.items(), key=lambda x: x[1], reverse=True):
            print(f"{cmd}: {count}次")
        
        # 给出优化建议
        if 'KEYS' in slow_commands:
            print("建议：将KEYS命令替换为SCAN命令")
        if 'SORT' in slow_commands:
            print("建议：检查SORT命令的使用，考虑在应用层排序")
```

---

## 10. 📊 故障诊断和监控


### 10.1 监控指标体系


**📈 INFO命令监控指标详解**
```
核心监控指标分类：

📊 性能指标：
- instantaneous_ops_per_sec：当前QPS
- total_commands_processed：总命令数
- keyspace_hits/keyspace_misses：缓存命中率

💾 内存指标：
- used_memory：已使用内存
- mem_fragmentation_ratio：内存碎片率  
- maxmemory：最大内存限制

👥 连接指标：
- connected_clients：当前连接数
- blocked_clients：阻塞连接数
- rejected_connections：拒绝连接数

💿 持久化指标：
- rdb_changes_since_last_save：未保存的变更数
- aof_current_size：AOF文件当前大小
- aof_rewrite_in_progress：是否正在重写AOF
```

**📊 监控指标计算**
```python
def calculate_metrics():
    info = redis.info()
    
    # 缓存命中率
    hits = info['keyspace_hits']
    misses = info['keyspace_misses']
    hit_rate = hits / (hits + misses) * 100 if (hits + misses) > 0 else 0
    
    # 内存使用率
    memory_usage_ratio = info['used_memory'] / info['maxmemory'] * 100 if info['maxmemory'] > 0 else 0
    
    # 连接使用率
    max_clients = info.get('maxclients', 10000)
    client_usage_ratio = info['connected_clients'] / max_clients * 100
    
    return {
        'hit_rate': f"{hit_rate:.2f}%",
        'memory_usage': f"{memory_usage_ratio:.2f}%", 
        'client_usage': f"{client_usage_ratio:.2f}%",
        'qps': info['instantaneous_ops_per_sec']
    }
```

### 10.2 常见故障排查


**🔧 故障排查方法**
```
故障排查流程：

1️⃣ 基础连接检查：
redis-cli ping
redis-cli -h target_host -p target_port ping

2️⃣ 服务状态检查：
INFO server    # 检查服务器基本状态
INFO stats     # 检查统计信息
CLIENT LIST    # 检查客户端连接

3️⃣ 性能问题排查：
SLOWLOG GET 10         # 查看慢查询
LATENCY LATEST         # 查看延迟信息
MEMORY DOCTOR          # 内存问题诊断

4️⃣ 集群状态检查：
CLUSTER INFO           # 集群整体状态
CLUSTER NODES          # 节点详细状态
INFO replication       # 主从复制状态
```

**🚨 常见故障和解决方案**
```bash
# 故障1：内存不足
INFO memory
# 解决：
CONFIG SET maxmemory-policy allkeys-lru
MEMORY PURGE

# 故障2：连接数过多
CLIENT LIST | wc -l    # 统计连接数
# 解决：
CLIENT KILL TYPE normal IDLE 300    # 关闭空闲连接

# 故障3：慢查询过多  
SLOWLOG GET
# 解决：
CONFIG SET slowlog-log-slower-than 5000    # 调整慢查询阈值

# 故障4：主从同步异常
INFO replication
# 解决：
REPLICAOF 192.168.1.100 6379    # 重新配置主从关系
```

### 10.3 性能基准测试详解


**🏃 redis-benchmark详细使用**
```bash
# 基础性能测试
redis-benchmark -q    # 安静模式，只显示结果

# 自定义测试场景
redis-benchmark -h 192.168.1.100 -p 6379 -c 100 -n 1000000 -d 1024
# -h: 目标主机
# -p: 目标端口  
# -c: 并发客户端数
# -n: 总请求数
# -d: 数据大小（字节）

# 测试特定命令组合
redis-benchmark -t set,get,lpush,lpop -n 100000

# 管道模式测试
redis-benchmark -P 16    # 使用16个命令的管道

# 输出CSV格式结果
redis-benchmark --csv -t set,get

# 性能基准脚本
def run_performance_baseline():
    tests = [
        {'name': '小数据SET/GET', 'cmd': '-t set,get -d 10'},
        {'name': '中数据SET/GET', 'cmd': '-t set,get -d 1024'},  
        {'name': '大数据SET/GET', 'cmd': '-t set,get -d 10240'},
        {'name': 'List操作', 'cmd': '-t lpush,lpop'},
        {'name': 'Hash操作', 'cmd': '-t hset,hget'}
    ]
    
    results = {}
    for test in tests:
        cmd = f"redis-benchmark {test['cmd']} -q"
        result = subprocess.run(cmd.split(), capture_output=True, text=True)
        results[test['name']] = result.stdout
    
    return results
```

---

## 11. 📋 核心要点总结


### 11.1 必须掌握的核心命令


```
🔸 服务管理：SHUTDOWN优雅关闭、INFO状态监控、CLIENT连接管理
🔸 配置管理：CONFIG GET/SET动态配置、MODULE模块管理
🔸 内存管理：MEMORY USAGE分析、MEMORY STATS统计、MEMORY PURGE整理
🔸 性能监控：MONITOR实时监控、SLOWLOG慢查询、LATENCY延迟分析
🔸 数据管理：BGSAVE备份、FLUSHDB清空、SCAN安全遍历
🔸 集群管理：CLUSTER INFO/NODES状态查看、REPLICAOF主从配置
```

### 11.2 运维命令分类使用


| 命令类别 | **生产环境** | **开发环境** | **使用频率** | **风险等级** |
|---------|-------------|-------------|-------------|-------------|
| **INFO系列** | `✅ 安全使用` | `✅ 频繁使用` | `⭐⭐⭐⭐⭐` | `🟢 安全` |
| **CONFIG系列** | `⚠️ 谨慎使用` | `✅ 自由使用` | `⭐⭐⭐` | `🟡 中等` |
| **MEMORY系列** | `✅ 定期使用` | `✅ 随时使用` | `⭐⭐⭐` | `🟢 安全` |
| **MONITOR** | `❌ 禁止长时间使用` | `✅ 调试使用` | `⭐⭐` | `🟡 中等` |
| **FLUSHDB/ALL** | `🚨 严禁使用` | `⚠️ 极谨慎` | `⭐` | `🔴 危险` |
| **KEYS** | `🚨 严禁使用` | `⚠️ 小数据量` | `⭐` | `🔴 危险` |
| **SCAN** | `✅ 推荐使用` | `✅ 推荐使用` | `⭐⭐⭐⭐` | `🟢 安全` |

### 11.3 运维最佳实践


**📊 监控告警策略**
```
关键指标阈值：
- 内存使用率 > 85%：告警
- 内存碎片率 > 1.5：告警  
- 缓存命中率 < 80%：告警
- 连接数 > 最大连接数80%：告警
- 慢查询 > 10条/分钟：告警

监控频率：
- 基础指标：每分钟检查
- 内存指标：每5分钟检查
- 慢查询：每10分钟检查
- 集群状态：每30秒检查
```

**🛡️ 安全操作原则**
```
生产环境规范：
❌ 禁用命令：KEYS、FLUSHALL、FLUSHDB、DEBUG
⚠️ 谨慎使用：CONFIG SET、MONITOR、SHUTDOWN  
✅ 安全使用：INFO、MEMORY系列、SCAN、SLOWLOG

操作前确认：
1. 确认环境（开发/测试/生产）
2. 备份重要数据
3. 评估操作影响
4. 准备回滚方案
5. 在业务低峰期执行
```

**🤖 自动化运维建议**
```
自动化脚本分类：
📊 监控类：健康检查、性能监控、告警通知
💾 备份类：定时备份、备份验证、备份清理
🔧 维护类：内存整理、日志清理、连接清理
🚨 应急类：故障检测、自动恢复、紧急处理

部署建议：
- 使用crontab定时执行监控脚本
- 集成到监控系统（Prometheus、Grafana）
- 配置多渠道告警（邮件、短信、钉钉）
- 建立运维文档和操作手册
```

### 11.4 运维命令使用技巧


**⚡ 高效使用技巧**
```
批量操作：
# 批量获取多个INFO分段
redis-cli INFO server memory clients | grep -E "(redis_version|used_memory|connected_clients)"

管道操作：  
# 使用管道提高效率
echo -e "INFO memory\nSLOWLOG GET 5\nCLIENT LIST" | redis-cli --pipe

脚本自动化：
# 结合shell脚本自动化运维
#!/bin/bash
MEMORY_USAGE=$(redis-cli INFO memory | grep used_memory_human | cut -d: -f2)
echo "当前内存使用：${MEMORY_USAGE}"
```

**📋 运维检查清单**
```
日常检查：
✅ 服务状态（PING、INFO server）
✅ 内存使用（INFO memory、MEMORY STATS）
✅ 客户端连接（CLIENT LIST、连接数统计）
✅ 慢查询（SLOWLOG GET、分析优化）

周期检查：
✅ 备份状态（LASTSAVE、备份文件检查）
✅ 集群状态（CLUSTER INFO、主从同步）
✅ 性能基准（redis-benchmark、性能对比）
✅ 配置检查（CONFIG GET、配置合理性）

应急处理：
✅ 故障诊断（综合INFO信息分析）
✅ 内存清理（MEMORY PURGE、过期键清理）
✅ 连接清理（CLIENT KILL、异常连接处理）
✅ 服务重启（SHUTDOWN、启动检查）
```

**核心记忆要点**：
- 运维命令重在监控，INFO全面MONITOR实时，SLOWLOG找瓶颈
- 内存管理要主动，MEMORY分析SCAN遍历，碎片整理定期做
- 集群运维看状态，CLUSTER信息ROLE角色，主从复制要监控
- 安全第一防故障，备份自动告警及时，脚本自动化运维好