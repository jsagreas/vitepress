---
title: 2、哨兵故障检测和选举机制
---
## 📚 目录

1. [哨兵系统概述](#1-哨兵系统概述)
2. [故障检测机制](#2-故障检测机制)
3. [哨兵选举机制](#3-哨兵选举机制)
4. [新主节点选择](#4-新主节点选择)
5. [故障转移完整流程](#5-故障转移完整流程)
6. [核心要点总结](#6-核心要点总结)

---

## 1. 🔍 哨兵系统概述


### 1.1 哨兵是什么


**通俗理解**：哨兵就像古代城楼上的守卫，专门监视敌情。Redis哨兵就是专门监视Redis主从服务器的"守卫程序"。

```
传统主从架构问题：
    主服务器 ──复制──> 从服务器
       ↓故障
    [人工发现]
       ↓
    [人工切换] ──> 从服务器变主
    
问题：故障发现慢，切换需要人工干预
```

**哨兵的作用**：
- **自动监控**：24小时监视主从服务器状态
- **自动发现故障**：主服务器挂了立即知道
- **自动故障转移**：自动选择新的主服务器
- **通知客户端**：告诉应用程序新主服务器地址

### 1.2 哨兵集群架构


```
哨兵集群监控示意图：

    哨兵1     哨兵2     哨兵3
     |         |         |
     └────┬────┼────┬────┘
          |    |    |
    ┌─────▼────▼────▼─────┐
    │   主服务器(Master)   │
    └─────┬────────────────┘
          │复制
    ┌─────▼─────┬─────────┐
    │ 从服务器1  │ 从服务器2 │
    │(Slave1)   │(Slave2) │
    └───────────┴─────────┘
```

**为什么要多个哨兵**：
- **避免误判**：一个哨兵可能网络有问题，多个哨兵投票更准确
- **高可用**：哨兵本身也可能故障，多个哨兵互相备份
- **民主决策**：多数哨兵同意才执行故障转移

---

## 2. 🚨 故障检测机制


### 2.1 主观下线判断


**什么是主观下线**：单个哨兵认为主服务器出故障了。

**检测过程**：
```
哨兵的心跳检测：
时间: 0s    1s    2s    3s    4s    5s
哨兵: PING → PING → PING → 超时 → 超时 → 主观下线

参数设置：
down-after-milliseconds 30000  # 30秒无响应判定主观下线
```

**代码模拟**：
```python
import time
import redis

class SentinelMonitor:
    def __init__(self, master_host, master_port):
        self.master_host = master_host
        self.master_port = master_port
        self.down_after_ms = 30000  # 30秒
        self.last_ping_time = time.time()
        
    def check_master_health(self):
        """检测主服务器健康状态"""
        try:
            # 尝试连接主服务器
            r = redis.Redis(host=self.master_host, port=self.master_port, socket_timeout=1)
            response = r.ping()
            
            if response:
                self.last_ping_time = time.time()
                return "健康"
        except:
            pass
        
        # 计算无响应时间
        no_response_time = (time.time() - self.last_ping_time) * 1000
        
        if no_response_time > self.down_after_ms:
            return "主观下线"
        else:
            return "可能有问题"
```

### 2.2 客观下线确认


**什么是客观下线**：多个哨兵都认为主服务器出故障了，这样才能确认真的有问题。

**确认过程**：
```
哨兵投票机制：

哨兵1: "我觉得主服务器挂了"  ←─ 发起者
哨兵2: "我也觉得挂了"        ←─ 同意
哨兵3: "我这边还正常"        ←─ 反对

投票结果：2票同意 vs 1票反对
如果同意票数 ≥ quorum，则确认客观下线
```

**配置参数**：
```bash
# 哨兵配置文件 sentinel.conf
sentinel monitor mymaster 127.0.0.1 6379 2

# 解释：
# mymaster: 主服务器名称（自己起的名字）
# 127.0.0.1 6379: 主服务器地址和端口
# 2: quorum值，需要2个哨兵同意才确认下线
```

### 2.3 网络抖动处理


**网络抖动问题**：网络临时不稳定导致的误判。

```
网络抖动示例：
时间线: ────●────●────●──x──●────●────
       正常  正常  正常 断开 正常  正常

如果立即判断下线 → 误判
合理的处理方式 → 连续检测多次
```

**防抖动策略**：
```python
class AntiShakeDetector:
    def __init__(self):
        self.failed_count = 0
        self.max_failed_count = 3  # 连续失败3次才判定
        
    def check_and_update(self, is_healthy):
        """检测并更新状态"""
        if is_healthy:
            self.failed_count = 0  # 恢复正常，重置计数
            return "正常"
        else:
            self.failed_count += 1
            
            if self.failed_count >= self.max_failed_count:
                return "确认故障"
            else:
                return f"可能故障({self.failed_count}/3)"
```

---

## 3. 🗳️ 哨兵选举机制


### 3.1 为什么需要选举


**问题**：多个哨兵发现故障后，谁来负责执行故障转移？

```
没有选举的问题：
哨兵1: "我来切换！"
哨兵2: "我来切换！"  
哨兵3: "我来切换！"
↓
同时操作，互相冲突，系统混乱
```

**选举解决方案**：
```
选举后的协调：
哨兵1: "我是领导者，我来切换"
哨兵2: "好的，我配合"
哨兵3: "好的，我配合"  
↓
统一指挥，避免冲突
```

### 3.2 Raft算法基本思想


**Raft算法简化理解**：就像班级选班长的过程。

```
选举过程：
1. 候选阶段：我想当班长(Candidate)
2. 拉票阶段：请大家投票给我
3. 当选阶段：获得多数票，成为班长(Leader)
4. 任期制：当一段时间班长，然后重新选举
```

**哨兵选举步骤**：
```
步骤1: 发现故障
哨兵A: "主服务器挂了，我要发起选举"

步骤2: 自荐为候选者
哨兵A: "我想当领导者，请投票给我"

步骤3: 其他哨兵投票
哨兵B: "好的，我投票给你"
哨兵C: "我也投票给你"

步骤4: 获得多数票，成为领导者
哨兵A: "我获得2票，超过半数，我是领导者"

步骤5: 执行故障转移
哨兵A: "我来负责选择新主服务器并切换"
```

### 3.3 选举代码实现原理


```python
class SentinelElection:
    def __init__(self, sentinel_id, all_sentinels):
        self.sentinel_id = sentinel_id
        self.all_sentinels = all_sentinels
        self.current_epoch = 0  # 当前轮次
        self.voted_for = None   # 本轮投票给了谁
        
    def start_election(self):
        """发起选举"""
        self.current_epoch += 1
        self.voted_for = self.sentinel_id  # 投票给自己
        votes = 1  # 自己的票
        
        print(f"哨兵{self.sentinel_id}发起选举，轮次{self.current_epoch}")
        
        # 向其他哨兵拉票
        for sentinel in self.all_sentinels:
            if sentinel.can_vote_for(self.sentinel_id, self.current_epoch):
                votes += 1
                print(f"获得哨兵{sentinel.id}的投票")
        
        # 检查是否获得多数票
        majority = len(self.all_sentinels) // 2 + 1
        if votes >= majority:
            print(f"获得{votes}票，超过半数({majority})，成为领导者")
            return True
        else:
            print(f"仅获得{votes}票，未超过半数，选举失败")
            return False
    
    def can_vote_for(self, candidate_id, epoch):
        """判断是否可以投票给某候选者"""
        # 每轮只能投票一次
        if self.voted_for is None or self.current_epoch < epoch:
            self.current_epoch = epoch
            self.voted_for = candidate_id
            return True
        return False
```

### 3.4 脑裂问题处理


**什么是脑裂**：网络分割导致集群分成两部分，每部分都选出了领导者。

```
脑裂场景：
网络分割前：        网络分割后：
哨兵1 ─ 哨兵2        哨兵1   |   哨兵2
  |       |           |     |     |
哨兵3 ─ 哨兵4        哨兵3   |   哨兵4
                             |
                        ─────┼───── 网络故障

结果：左边选出领导者A，右边选出领导者B
```

**解决方案**：**quorum机制**
```bash
# 配置文件中设置
sentinel monitor mymaster 127.0.0.1 6379 3

# 解释：需要至少3个哨兵同意才能执行故障转移
# 如果网络分割，任何一边都无法获得3票
# 避免了脑裂问题
```

---

## 4. 👑 新主节点选择


### 4.1 选择标准


当哨兵领导者确定要故障转移时，需要从多个从服务器中选出最合适的当新主服务器。

**选择考虑因素**：
```
1. 优先级  (配置的slave-priority)
2. 数据完整性 (复制偏移量offset)  
3. 运行时间 (run id最小的)
```

### 4.2 从节点优先级评估


**优先级配置**：
```bash
# 从服务器配置文件
slave-priority 100  # 数值越小优先级越高

# 特殊值
slave-priority 0   # 永远不能成为主服务器
```

**优先级选择逻辑**：
```python
def select_by_priority(slaves):
    """按优先级筛选候选者"""
    # 过滤掉priority为0的从服务器
    candidates = [s for s in slaves if s['priority'] > 0]
    
    if not candidates:
        return None
        
    # 找出最小的优先级值
    min_priority = min(s['priority'] for s in candidates)
    
    # 返回具有最小优先级的从服务器
    return [s for s in candidates if s['priority'] == min_priority]

# 示例
slaves = [
    {'id': 'slave1', 'priority': 100, 'offset': 1000},
    {'id': 'slave2', 'priority': 90, 'offset': 950},   # 优先级最高
    {'id': 'slave3', 'priority': 0, 'offset': 1100},   # 不能选为主
    {'id': 'slave4', 'priority': 90, 'offset': 980}    # 和slave2同优先级
]

result = select_by_priority(slaves)  
# 返回 slave2 和 slave4（都是priority=90）
```

### 4.3 复制偏移量比较


**复制偏移量是什么**：表示从服务器复制了多少数据，数值越大说明数据越完整。

```
主服务器写入数据的进度：
写入数据: A B C D E F G H I J
偏移量:   1 2 3 4 5 6 7 8 9 10

从服务器复制进度：
从服务器1: A B C D E F G ─ (偏移量=7，少了3个数据)
从服务器2: A B C D E F G H I (偏移量=9，少了1个数据) ← 更完整
从服务器3: A B C D E F ─ ─ ─ (偏移量=6，少了4个数据)
```

**选择逻辑**：
```python
def select_by_offset(candidates):
    """按复制偏移量选择"""
    if not candidates:
        return None
        
    # 找出最大的偏移量(数据最完整)
    max_offset = max(s['offset'] for s in candidates)
    
    # 返回偏移量最大的从服务器
    return [s for s in candidates if s['offset'] == max_offset]

# 接上面的例子，如果slave2和slave4优先级相同
final_candidates = select_by_offset(result)
# 会比较它们的offset，选择数据更完整的
```

### 4.4 运行时间考量


**run id是什么**：服务器启动时生成的唯一标识，可以看作"年龄"。

**选择原则**：如果其他条件都相同，选择run id最小的(最早启动的，运行最稳定)。

```python
def final_selection(candidates):
    """最终选择算法"""
    if len(candidates) == 1:
        return candidates[0]
    
    # 按run_id排序，选择最小的(最早启动的)
    candidates.sort(key=lambda s: s['run_id'])
    return candidates[0]

# 完整的选择流程
def select_new_master(slaves):
    """选择新主服务器的完整流程"""
    print("开始选择新主服务器...")
    
    # 第一步：按优先级筛选
    candidates = select_by_priority(slaves)
    print(f"按优先级筛选后剩余: {[s['id'] for s in candidates]}")
    
    # 第二步：按偏移量筛选
    candidates = select_by_offset(candidates)
    print(f"按偏移量筛选后剩余: {[s['id'] for s in candidates]}")
    
    # 第三步：按运行时间选择
    new_master = final_selection(candidates)
    print(f"最终选择: {new_master['id']}")
    
    return new_master
```

---

## 5. 🔄 故障转移完整流程


### 5.1 完整流程时序图


```
时间轴: ──1──2──3──4──5──6──7──8──>

哨兵A     主服务器     从服务器1    从服务器2    客户端
 │           │           │           │           │
 │──PING────>│           │           │           │  1.心跳检测
 │           │×故障      │           │           │
 │<──超时────│           │           │           │  2.主观下线
 │           │           │           │           │
 │──询问────────────────>│           │           │  3.询问其他哨兵
 │<─同意────────────────>│           │           │
 │──询问──────────────────────────>│           │
 │<─同意──────────────────────────>│           │  4.客观下线确认
 │           │           │           │           │
 │───────发起选举─────────────────────────────>│  5.选举领导者
 │<──投票────────────────────────────────────>│
 │           │           │           │           │
 │──────选择新主────────>│           │           │  6.选择最佳从服务器
 │           │           │──SLAVEOF NO ONE──────>│  7.提升为新主
 │           │           │           │           │
 │──────────────────────────────>│──SLAVEOF──>│  8.其他从服务器指向新主
 │           │           │           │           │
 │─────────通知新地址─────────────────────────>│  9.通知客户端
```

### 5.2 故障转移步骤详解


**步骤1：故障确认**
```python
def confirm_master_down():
    """确认主服务器故障"""
    subjective_down_count = 0
    
    for sentinel in all_sentinels:
        if sentinel.is_master_subjective_down():
            subjective_down_count += 1
    
    # 达到quorum数量，确认客观下线
    if subjective_down_count >= quorum:
        print("确认主服务器客观下线")
        return True
    
    return False
```

**步骤2：领导者选举**
```python
def elect_leader():
    """选举哨兵领导者"""
    epoch = get_current_epoch() + 1
    votes = 1  # 给自己投票
    
    for sentinel in other_sentinels:
        if sentinel.request_vote(epoch, self.id):
            votes += 1
    
    majority = (len(all_sentinels) + 1) // 2
    if votes > majority:
        print(f"成为领导者，获得{votes}票")
        return True
        
    return False
```

**步骤3：执行故障转移**
```python
def perform_failover():
    """执行故障转移"""
    # 1. 选择新主服务器
    new_master = select_best_slave()
    print(f"选择 {new_master['host']}:{new_master['port']} 为新主")
    
    # 2. 将选中的从服务器提升为主
    send_command(new_master, "SLAVEOF NO ONE")
    
    # 3. 让其他从服务器指向新主
    for slave in other_slaves:
        cmd = f"SLAVEOF {new_master['host']} {new_master['port']}"
        send_command(slave, cmd)
    
    # 4. 通知所有客户端新主服务器地址
    notify_clients(new_master)
    
    print("故障转移完成")
```

### 5.3 故障转移状态机


```
故障转移状态转换：

监控状态 ──发现故障──> 主观下线
    ↑                    │
    │                    ▼
完成状态 <──转移完成── 客观下线
    ↑                    │
    │                    ▼  
通知客户端 <──选择新主── 选举领导者
    ↑                    │
    │                    ▼
切换从服务器 <──提升主── 执行转移
```

---

## 6. 💡 实际应用场景


### 6.1 高可用Web服务


**场景**：电商网站的Redis缓存高可用部署

```python
# 哨兵配置示例
sentinel_config = """
# 哨兵端口
port 26379

# 监控主服务器
sentinel monitor ecommerce-redis 192.168.1.100 6379 2

# 故障判定时间(毫秒)
sentinel down-after-milliseconds ecommerce-redis 30000

# 故障转移超时时间
sentinel failover-timeout ecommerce-redis 180000

# 并行同步的从服务器数量
sentinel parallel-syncs ecommerce-redis 1
"""

# 客户端连接代码
def get_redis_connection():
    """获取Redis连接"""
    from redis.sentinel import Sentinel
    
    # 哨兵地址列表
    sentinels = [
        ('192.168.1.101', 26379),
        ('192.168.1.102', 26379), 
        ('192.168.1.103', 26379)
    ]
    
    # 创建哨兵连接
    sentinel = Sentinel(sentinels)
    
    # 获取主服务器连接(自动故障转移)
    master = sentinel.master_for('ecommerce-redis', socket_timeout=0.1)
    
    return master
```

### 6.2 监控告警集成


```python
class SentinelMonitor:
    """哨兵监控告警"""
    
    def monitor_events(self):
        """监控哨兵事件"""
        sentinel_conn = redis.Redis(host='127.0.0.1', port=26379)
        
        # 订阅哨兵事件
        pubsub = sentinel_conn.pubsub()
        pubsub.subscribe('__sentinel__:hello')
        
        for message in pubsub.listen():
            if message['type'] == 'message':
                self.handle_sentinel_event(message['data'])
    
    def handle_sentinel_event(self, event_data):
        """处理哨兵事件"""
        event = event_data.decode('utf-8')
        
        if '+sdown' in event:  # 主观下线
            self.send_alert("WARNING", "检测到主服务器可能故障")
            
        elif '+odown' in event:  # 客观下线  
            self.send_alert("CRITICAL", "确认主服务器故障")
            
        elif '+failover-end' in event:  # 故障转移完成
            self.send_alert("INFO", "故障转移完成，服务已恢复")
    
    def send_alert(self, level, message):
        """发送告警"""
        print(f"[{level}] {datetime.now()}: {message}")
        # 这里可以集成邮件、短信、钉钉等告警方式
```

---

## 7. 📋 核心要点总结


### 7.1 必须掌握的核心概念


```
🔸 故障检测：主观下线(单个哨兵判断) → 客观下线(多数哨兵确认)
🔸 选举机制：类似选班长，获得多数票的哨兵成为领导者
🔸 新主选择：按优先级 → 数据完整性 → 运行时间的顺序选择
🔸 防脑裂：通过quorum机制确保只有一个领导者
🔸 自动切换：整个过程无需人工干预，自动完成故障转移
```

### 7.2 关键理解要点


**🔹 为什么需要多个哨兵**
```
单个哨兵问题：
- 可能误判(网络抖动)
- 自身可能故障
- 无法避免脑裂

多哨兵优势：
- 投票机制避免误判
- 互相监督，提高可靠性
- quorum机制防止脑裂
```

**🔹 故障检测的时间平衡**
```
检测时间过短：
- 网络抖动时容易误判
- 频繁的无意义故障转移

检测时间过长：
- 故障发现慢，服务不可用时间长
- 用户体验差

建议配置：
down-after-milliseconds 30000  # 30秒比较合适
```

**🔹 新主选择的智能性**
```
为什么按这个顺序：
1. 优先级：管理员的明确意图
2. 数据完整性：保证数据不丢失
3. 运行时间：选择最稳定的服务器

实际效果：
选出的新主服务器既符合管理意图，又数据完整，还运行稳定
```

### 7.3 实际部署建议


**哨兵数量配置**：
```
3个哨兵：最小推荐配置，可容忍1个故障
5个哨兵：推荐配置，可容忍2个故障  
7个哨兵：大型集群，可容忍3个故障

注意：哨兵数量建议为奇数，避免选举平票
```

**参数调优建议**：
| 参数 | 推荐值 | 说明 |
|------|-------|------|
| `down-after-milliseconds` | **30000** | 30秒无响应判定故障 |
| `failover-timeout` | **180000** | 3分钟故障转移超时 |
| `parallel-syncs` | **1** | 一次只同步一个从服务器 |

**常见问题处理**：

> **问题1**：哨兵频繁误判故障
> **解决**：增加`down-after-milliseconds`参数值

> **问题2**：故障转移时间太长
> **解决**：检查网络延迟，优化`failover-timeout`参数

> **问题3**：从服务器数据不一致  
> **解决**：调整`parallel-syncs`参数，避免同时同步多个从服务器

### 7.4 监控指标


**重要监控项**：
- 哨兵在线数量
- 主观下线/客观下线事件
- 故障转移次数和耗时
- 从服务器复制延迟

**核心记忆要点**：
- 哨兵像守卫，多个守卫投票避免误判
- 故障检测分主观客观，客观确认才行动
- 选举像选班长，多数票获胜当领导
- 新主选择有标准，优先级数据运行时间
- 整个过程全自动，无需人工来干预