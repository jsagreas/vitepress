---
title: 4、哨兵自动故障转移流程
---
## 📚 目录

1. [哨兵故障转移概述](#1-哨兵故障转移概述)
2. [故障转移触发机制](#2-故障转移触发机制)
3. [故障转移执行过程](#3-故障转移执行过程)
4. [故障转移完成与验证](#4-故障转移完成与验证)
5. [客户端感知与处理](#5-客户端感知与处理)
6. [核心要点总结](#6-核心要点总结)

---

## 1. 🚨 哨兵故障转移概述


### 1.1 什么是故障转移

**简单理解**：当Redis主节点挂了，哨兵自动把某个从节点提升为新的主节点，整个过程不需要人工干预。

```
故障前的正常架构：
Master(主节点) ← 客户端写入
   ↓
Slave1, Slave2(从节点) ← 客户端读取

故障发生：
Master(挂了❌) 
   ↓
Slave1, Slave2(孤立状态)

故障转移后：
Slave1(新Master✅) ← 客户端写入  
   ↓
Slave2(从节点) ← 客户端读取
```

### 1.2 故障转移的核心价值

**为什么需要自动故障转移**：
- **高可用性**：系统7×24小时不间断服务
- **减少人工干预**：半夜主节点挂了不用爬起来处理
- **快速恢复**：通常在30秒内完成整个切换过程
- **数据保护**：最大限度减少数据丢失

### 1.3 故障转移的整体流程概览


```
故障转移完整流程：

阶段1：故障检测与判断
┌─────────────────────────────────┐
│ 哨兵定期ping主节点              │
│ ↓                              │
│ 主观下线：单个哨兵认为主节点挂了 │
│ ↓                              │
│ 客观下线：多个哨兵确认主节点挂了 │
└─────────────────────────────────┘
              ↓
阶段2：领导者选举
┌─────────────────────────────────┐
│ 哨兵们投票选出领导者            │
│ ↓                              │
│ 领导者负责执行故障转移          │
└─────────────────────────────────┘
              ↓
阶段3：新主节点选择
┌─────────────────────────────────┐
│ 从可用的从节点中选择最佳候选    │
│ ↓                              │
│ 将选定的从节点提升为主节点      │
└─────────────────────────────────┘
              ↓
阶段4：架构重建
┌─────────────────────────────────┐
│ 其他从节点指向新主节点          │
│ ↓                              │
│ 客户端接收新主节点信息          │
│ ↓                              │
│ 故障转移完成                   │
└─────────────────────────────────┘
```

---

## 2. 🔍 故障转移触发机制


### 2.1 主节点故障判断标准


**什么情况下认为主节点"挂了"**：

#### 主观下线（Subjective Down）

**含义**：单个哨兵认为主节点不可用

```
判断条件：
• 连续ping超时：哨兵ping主节点超过down-after-milliseconds时间
• 连接失败：网络连接建立失败
• 响应异常：收到错误响应或无响应

配置示例：
sentinel down-after-milliseconds mymaster 5000
# 5秒内ping不通就认为主观下线
```

#### 客观下线（Objective Down）

**含义**：足够多的哨兵都认为主节点不可用

```
判断条件：
认为主节点主观下线的哨兵数量 ≥ quorum值

配置示例：
sentinel monitor mymaster 127.0.0.1 6379 2
# quorum = 2，至少2个哨兵认为下线才触发客观下线
```

**💡 为什么需要两个阶段**：
- **主观下线**：防止单点判断错误（网络抖动、哨兵自身问题）
- **客观下线**：多数决策，确保判断准确性

### 2.2 故障转移启动条件


**启动条件检查清单**：
```
✅ 主节点达到客观下线状态
✅ 当前没有正在进行的故障转移
✅ 距离上次故障转移超过故障转移超时时间
✅ 有足够的哨兵节点参与决策
✅ 至少有一个可用的从节点
```

**配置参数说明**：
```bash
# 故障转移超时时间
sentinel failover-timeout mymaster 60000

# 并行同步的从节点数量
sentinel parallel-syncs mymaster 1
```

### 2.3 领导者哨兵选定过程


**为什么需要领导者**：多个哨兵同时执行故障转移会造成混乱，需要选出一个"指挥官"。

```
领导者选举流程：

步骤1：哨兵发现客观下线
┌─────────────┐    ┌─────────────┐    ┌─────────────┐
│  哨兵A      │    │  哨兵B      │    │  哨兵C      │
│ "主节点挂了" │    │ "主节点挂了" │    │ "主节点挂了" │
└─────────────┘    └─────────────┘    └─────────────┘

步骤2：竞选领导者
哨兵A: "我要当领导者，请投票给我"
哨兵B: "我也要当领导者，请投票给我"  
哨兵C: "我投票给先找我的哨兵A"

步骤3：计票结果
哨兵A得票：2票（自己+哨兵C）
哨兵B得票：1票（自己）
→ 哨兵A成为领导者，执行故障转移
```

**选举规则**：
- **先到先得**：最先请求投票的哨兵容易获胜
- **多数原则**：需要获得超过半数哨兵的投票
- **自己投自己**：哨兵会先投票给自己

---

## 3. ⚙️ 故障转移执行过程


### 3.1 新主节点选择策略


**选择标准（按优先级排序）**：

```
优先级1：从节点优先级
sentinel config set mymaster slave-priority 100
# 数值越小优先级越高，0表示不参与主节点选举

优先级2：复制偏移量
选择偏移量最大的从节点（数据最新）

优先级3：运行时ID
如果前面都相同，选择ID较小的
```

**💡 通俗理解选择过程**：
```
假设有3个从节点：

从节点A：priority=10, offset=1000, id=abc123
从节点B：priority=20, offset=1200, id=def456  
从节点C：priority=10, offset=1100, id=ghi789

选择过程：
1. 先比较优先级：A和C的priority都是10，最小，B被淘汰
2. 再比较偏移量：C的offset=1100 > A的offset=1000，C获胜
3. 从节点C被选为新主节点
```

### 3.2 新主节点提升过程


**提升步骤**：
```
步骤1：向选定的从节点发送SLAVEOF NO ONE
       含义：告诉这个从节点"你现在是老大了"

步骤2：等待从节点角色转换
       从节点变成主节点，开始接受写操作

步骤3：验证提升成功
       检查新节点的角色是否已经变为master
```

**代码示例**：
```bash
# 哨兵执行的命令
redis-cli -h 192.168.1.101 -p 6379 SLAVEOF NO ONE

# 验证角色变更
redis-cli -h 192.168.1.101 -p 6379 INFO replication
# role:master 表示提升成功
```

### 3.3 其他从节点重新配置


**重新配置过程**：
```
原来的架构：
Master(192.168.1.100:6379) ❌ 挂了
  ↓
Slave1(192.168.1.101:6379) → 提升为新Master ✅
Slave2(192.168.1.102:6379) → 需要重新配置

重新配置后：
新Master(192.168.1.101:6379) ✅
  ↓
Slave2(192.168.1.102:6379) → 重新指向新Master
```

**配置命令**：
```bash
# 哨兵向Slave2发送命令
SLAVEOF 192.168.1.101 6379
# 含义：现在你要跟随新老大192.168.1.101了
```

### 3.4 原主节点降级处理


**当原主节点恢复时**：
```
场景：原来的主节点修复后重新上线

哨兵的处理方式：
1. 检测到原主节点恢复
2. 向原主节点发送SLAVEOF命令
3. 将其降级为从节点

命令示例：
redis-cli -h 192.168.1.100 -p 6379 SLAVEOF 192.168.1.101 6379
# 原主节点现在变成从节点，跟随新主节点
```

**💡 为什么要降级**：
- 避免脑裂：防止出现多个主节点的情况
- 数据一致性：确保数据同步方向正确
- 架构清晰：维持一主多从的清晰架构

---

## 4. ✅ 故障转移完成与验证


### 4.1 配置更新通知


**哨兵配置自动更新**：
```bash
# 故障转移前的哨兵配置
sentinel monitor mymaster 192.168.1.100 6379 2

# 故障转移后自动更新为
sentinel monitor mymaster 192.168.1.101 6379 2
# 新主节点IP自动更新
```

**配置同步机制**：
- **自动保存**：哨兵自动将新配置写入配置文件
- **广播通知**：领导者哨兵通知其他哨兵更新配置
- **一致性保证**：确保所有哨兵配置保持一致

### 4.2 新架构验证


**验证检查项**：
```
✅ 新主节点状态检查
redis-cli -h 新主节点IP INFO replication
# 确认role:master

✅ 从节点同步检查  
redis-cli -h 从节点IP INFO replication
# 确认master_host指向新主节点

✅ 数据一致性验证
# 在新主节点写入测试数据
SET test_key "failover_test"
# 在从节点读取验证
GET test_key
```

### 4.3 故障转移日志记录


**关键日志信息**：
```bash
# 哨兵日志示例
2025-08-29 15:30:15 # +sdown master mymaster 192.168.1.100 6379
# 主观下线检测

2025-08-29 15:30:18 # +odown master mymaster 192.168.1.100 6379 #quorum 2/2
# 客观下线确认

2025-08-29 15:30:20 # +switch-master mymaster 192.168.1.100 6379 192.168.1.101 6379
# 主节点切换完成

2025-08-29 15:30:25 # +slave slave 192.168.1.102:6379 192.168.1.102 6379 @ mymaster 192.168.1.101 6379
# 从节点重新配置完成
```

---

## 5. 👁️ 客户端感知与处理


### 5.1 客户端重定向处理


**传统客户端处理方式**：
```java
// 问题：硬编码主节点地址
Jedis jedis = new Jedis("192.168.1.100", 6379);
// 主节点挂了，客户端就连不上了
```

**哨兵感知的客户端**：
```java
// 解决方案：使用哨兵客户端
Set<String> sentinels = new HashSet<>();
sentinels.add("192.168.1.201:26379");  // 哨兵1
sentinels.add("192.168.1.202:26379");  // 哨兵2
sentinels.add("192.168.1.203:26379");  // 哨兵3

JedisSentinelPool pool = new JedisSentinelPool(
    "mymaster",  // 主节点名称
    sentinels    // 哨兵地址列表
);

// 客户端自动连接当前的主节点
Jedis jedis = pool.getResource();
```

### 5.2 客户端感知机制


**客户端如何知道主节点变了**：

```
方式1：主动查询
客户端定期向哨兵询问当前主节点信息

方式2：订阅通知  
客户端订阅哨兵的通知消息

方式3：连接失败重试
连接失败时重新查询哨兵获取新主节点
```

**订阅通知示例**：
```java
// 客户端订阅哨兵通知
jedis.subscribe(new JedisPubSub() {
    @Override
    public void onMessage(String channel, String message) {
        if ("+switch-master".equals(channel)) {
            // 解析新主节点信息
            updateMasterInfo(message);
        }
    }
}, "+switch-master");
```

### 5.3 客户端重连策略


**智能重连机制**：
```java
public class SentinelClient {
    private JedisSentinelPool sentinelPool;
    private Jedis currentJedis;
    
    public String get(String key) {
        int retryCount = 0;
        while (retryCount < 3) {
            try {
                return currentJedis.get(key);
            } catch (JedisConnectionException e) {
                // 连接失败，重新获取连接
                refreshConnection();
                retryCount++;
            }
        }
        throw new RuntimeException("无法连接到Redis服务器");
    }
    
    private void refreshConnection() {
        if (currentJedis != null) {
            currentJedis.close();
        }
        currentJedis = sentinelPool.getResource();
    }
}
```

---

## 6. 🔄 完整故障转移流程详解


### 6.1 故障转移时间轴


```
时间轴：故障转移完整过程

T0: 主节点正常运行
    Master(192.168.1.100) + Slave1(192.168.1.101) + Slave2(192.168.1.102)
    
T1: 主节点发生故障(比如服务器断电)
    Master❌ + Slave1✅ + Slave2✅
    
T2: 哨兵检测到故障(5秒后)
    哨兵A: "主节点ping不通了"(主观下线)
    哨兵B: "我也ping不通"(主观下线)
    
T3: 达到客观下线条件(6秒后)  
    quorum=2, 已有2个哨兵认为下线 → 客观下线确认
    
T4: 领导者选举(7秒后)
    哨兵A竞选领导者，获得多数票，成为领导者
    
T5: 新主节点选择(8秒后)
    领导者哨兵选择Slave1作为新主节点
    
T6: 提升从节点(10秒后)
    向Slave1发送 SLAVEOF NO ONE
    Slave1 → 新Master✅
    
T7: 重配置其他从节点(15秒后)
    向Slave2发送 SLAVEOF 192.168.1.101 6379
    
T8: 客户端感知(20秒后)
    哨兵通知客户端新主节点信息
    客户端重新连接到192.168.1.101
    
T9: 故障转移完成(25秒后)
    新架构稳定运行：新Master + Slave2
```

### 6.2 故障转移决策逻辑


**决策树流程**：
```
开始
  ↓
检测到主节点故障？
  ↓ 是
获得足够的哨兵确认？(quorum)
  ↓ 是  
当前是否有故障转移在进行？
  ↓ 否
是否有可用的从节点？
  ↓ 是
选举领导者哨兵
  ↓
领导者选择最优从节点
  ↓  
执行故障转移
  ↓
通知所有客户端
  ↓
故障转移完成
```

### 6.3 并发控制机制


**防止同时故障转移**：
```
问题：多个哨兵同时执行故障转移造成混乱

解决方案：
1. epoch机制：使用版本号确保操作的唯一性
2. 领导者选举：只有一个哨兵负责执行
3. 状态锁定：故障转移期间锁定状态
```

---

## 7. 📊 故障转移性能与参数调优


### 7.1 关键性能指标


| 指标 | **典型值** | **影响因素** | **优化建议** |
|------|-----------|-------------|-------------|
| **检测时间** | `5-30秒` | `down-after-milliseconds` | `生产环境建议5-10秒` |
| **切换时间** | `10-60秒` | `failover-timeout` | `根据网络情况调整` |
| **数据丢失** | `0-几秒数据` | `复制延迟` | `使用同步复制减少丢失` |
| **服务中断** | `20-90秒` | `客户端重连速度` | `使用连接池和重试机制` |

### 7.2 参数调优建议


**生产环境推荐配置**：
```bash
# 哨兵配置文件 sentinel.conf
port 26379

# 主节点监控配置
sentinel monitor mymaster 192.168.1.100 6379 2
# quorum=2，至少2个哨兵确认才故障转移

# 主观下线时间：5秒
sentinel down-after-milliseconds mymaster 5000

# 故障转移超时：60秒  
sentinel failover-timeout mymaster 60000

# 并行同步数量：1个
sentinel parallel-syncs mymaster 1

# 认证配置（如果Redis设置了密码）
sentinel auth-pass mymaster your_redis_password
```

**⚠️ 参数配置要点**：
- **quorum值**：通常设置为哨兵总数的一半+1
- **down-after时间**：过短容易误判，过长影响故障恢复速度
- **parallel-syncs**：设置为1避免同时同步影响性能

### 7.3 故障转移场景分析


**常见故障场景及处理**：

```
场景1：主节点宕机
故障：服务器硬件故障
检测：哨兵ping超时
处理：标准故障转移流程
恢复时间：20-30秒

场景2：网络分区
故障：主节点网络隔离
检测：网络不可达
处理：需要谨慎判断，避免脑裂
恢复时间：网络恢复后自动修复

场景3：主节点进程卡住
故障：Redis进程假死
检测：连接超时或响应超时
处理：强制重启或故障转移
恢复时间：10-20秒

场景4：从节点全部故障
故障：所有从节点不可用
检测：无可用从节点
处理：故障转移无法执行，保持现状
恢复：需要手工干预
```

---

## 8. 🛠️ 故障转移最佳实践


### 8.1 架构设计建议


**哨兵部署策略**：
```
推荐配置：
• 哨兵数量：奇数个（3、5、7）
• 部署位置：不同的物理机器
• 网络要求：低延迟，高可靠性

典型三节点部署：
服务器A：Redis Master + Sentinel1
服务器B：Redis Slave1 + Sentinel2  
服务器C：Redis Slave2 + Sentinel3
```

### 8.2 运维监控要点


**关键监控指标**：
```bash
# 哨兵状态监控
redis-cli -h 127.0.0.1 -p 26379 SENTINEL masters
# 查看监控的主节点状态

redis-cli -h 127.0.0.1 -p 26379 SENTINEL slaves mymaster  
# 查看从节点状态

redis-cli -h 127.0.0.1 -p 26379 SENTINEL sentinels mymaster
# 查看其他哨兵状态
```

**告警设置建议**：
- 主节点状态变化告警
- 故障转移执行告警
- 哨兵节点异常告警
- 客户端连接异常告警

### 8.3 故障演练


**定期故障演练的重要性**：
```
演练目的：
• 验证故障转移机制正常工作
• 测试客户端重连逻辑
• 评估故障恢复时间
• 发现潜在问题

演练步骤：
1. 停止主节点Redis服务
2. 观察哨兵日志和故障转移过程
3. 验证客户端是否正常重连
4. 记录整个过程的时间点
5. 恢复原主节点并观察降级过程
```

---

## 9. 📋 核心要点总结


### 9.1 必须掌握的核心概念


```
🔸 故障转移本质：自动将从节点提升为主节点，保证服务持续可用
🔸 触发条件：主观下线 → 客观下线 → 领导者选举 → 执行转移
🔸 选择策略：优先级 → 复制偏移量 → 运行ID，选最优从节点
🔸 完整流程：故障检测 → 新主选择 → 架构重建 → 客户端更新
🔸 时间要求：通常在30-60秒内完成整个故障转移过程
```

### 9.2 关键理解要点


**🔹 为什么需要多个哨兵**：
```
单点问题：一个哨兵可能误判
网络分区：避免网络问题导致错误决策  
决策准确性：多数决策比单点决策更可靠
```

**🔹 客观下线的重要性**：
```
防止误判：网络抖动不会触发故障转移
提高稳定性：确保真正的故障才执行转移
减少不必要的切换：避免频繁的主从切换
```

**🔹 客户端适配的必要性**：
```
自动感知：客户端能自动发现新的主节点
快速切换：减少业务中断时间
透明切换：业务逻辑无需修改
```

### 9.3 生产环境实践要点


**配置建议**：
- 至少3个哨兵节点，部署在不同机器
- quorum设置为哨兵数量的一半+1
- down-after-milliseconds设置为5-10秒
- 定期进行故障转移演练

**监控要点**：
- 监控哨兵健康状态
- 监控故障转移执行时间
- 监控客户端重连成功率
- 记录和分析故障转移日志

**常见问题**：
- **脑裂问题**：网络分区导致多个主节点
- **数据丢失**：故障转移时未同步的数据丢失
- **客户端兼容**：老客户端不支持哨兵模式

### 9.4 实际应用价值


**业务价值**：
- **高可用保证**：服务可用性从99%提升到99.9%+
- **运维成本降低**：减少人工干预和半夜起床处理故障
- **用户体验改善**：故障恢复时间从小时级降到分钟级
- **数据安全保障**：自动化的故障处理减少人为操作风险

**核心记忆**：
- 哨兵故障转移是Redis高可用的核心机制
- 主观下线→客观下线→领导者选举→执行转移的标准流程
- 客户端必须使用哨兵模式才能自动感知主节点变化
- 合理的参数配置和定期演练是成功的关键