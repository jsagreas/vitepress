---
title: 7ã€Redisé«˜çº§æ•°æ®ç»“æ„è¯¦è§£
---
## ğŸ“š ç›®å½•

1. [é«˜çº§æ•°æ®ç»“æ„æ¦‚è¿°](#1-é«˜çº§æ•°æ®ç»“æ„æ¦‚è¿°)
2. [ä½å›¾Bitmapåº”ç”¨](#2-ä½å›¾bitmapåº”ç”¨)
3. [HyperLogLogåŸºæ•°ç»Ÿè®¡](#3-hyperloglogåŸºæ•°ç»Ÿè®¡)
4. [åœ°ç†ä½ç½®GEO](#4-åœ°ç†ä½ç½®geo)
5. [Streamsæµå¼æ•°æ®](#5-streamsæµå¼æ•°æ®)
6. [æ€§èƒ½å¯¹æ¯”ä¸é€‰æ‹©](#6-æ€§èƒ½å¯¹æ¯”ä¸é€‰æ‹©)
7. [æ ¸å¿ƒè¦ç‚¹æ€»ç»“](#7-æ ¸å¿ƒè¦ç‚¹æ€»ç»“)

---

## 1. ğŸ”§ é«˜çº§æ•°æ®ç»“æ„æ¦‚è¿°


### 1.1 ä»€ä¹ˆæ˜¯é«˜çº§æ•°æ®ç»“æ„ï¼Ÿ


**ğŸ’¡ é€šä¿—ç†è§£**ï¼šå°±åƒå·¥å…·ç®±é‡Œçš„**ä¸“ç”¨å·¥å…·**
```
åŸºç¡€æ•°æ®ç»“æ„ = ä¸‡èƒ½å·¥å…·ï¼ˆèºä¸åˆ€ã€é”¤å­ã€é’³å­ï¼‰
- Stringã€Listã€Hashã€Setã€ZSet

é«˜çº§æ•°æ®ç»“æ„ = ä¸“ç”¨å·¥å…·ï¼ˆç”µé’»ã€è§’ç£¨æœºã€åˆ‡å‰²æœºï¼‰  
- Bitmapã€HyperLogLogã€GEOã€Streams

ç‰¹ç‚¹ï¼šä¸“é—¨è§£å†³ç‰¹å®šé—®é¢˜ï¼Œæ•ˆç‡æ›´é«˜ï¼ŒåŠŸèƒ½æ›´å¼º
```

### 1.2 é«˜çº§ç»“æ„è§£å†³çš„é—®é¢˜


**ğŸ¯ ä¸“ä¸šåœºæ™¯éœ€æ±‚**
```
ä¼ ç»Ÿæ–¹æ¡ˆçš„é—®é¢˜ï¼š
âŒ ç”¨æˆ·ç­¾åˆ°è®°å½• â†’ ç”¨Stringå­˜å‚¨ï¼Œå ç”¨ç©ºé—´å¤§
âŒ ç½‘ç«™UVç»Ÿè®¡ â†’ ç”¨Setå­˜å‚¨ï¼Œå†…å­˜æ¶ˆè€—å·¨å¤§
âŒ é™„è¿‘çš„äººæŸ¥æ‰¾ â†’ å¤æ‚çš„ç»çº¬åº¦è®¡ç®—
âŒ æ—¥å¿—æµå¤„ç† â†’ éœ€è¦ä¸“ä¸šçš„æ¶ˆæ¯é˜Ÿåˆ—

é«˜çº§ç»“æ„çš„è§£å†³ï¼š
âœ… Bitmap â†’ 1ä¸ªbitè®°å½•1ä¸ªç”¨æˆ·çŠ¶æ€
âœ… HyperLogLog â†’ ç”¨å¾ˆå°å†…å­˜ç»Ÿè®¡äº¿çº§æ•°æ®
âœ… GEO â†’ å†…ç½®åœ°ç†ä½ç½®è®¡ç®—åŠŸèƒ½
âœ… Streams â†’ å†…ç½®æ¶ˆæ¯é˜Ÿåˆ—åŠŸèƒ½
```

### 1.3 åº”ç”¨åœºæ™¯æ€»è§ˆ


| æ•°æ®ç»“æ„ | **ä¸»è¦ç”¨é€”** | **å…¸å‹åœºæ™¯** | **å†…å­˜æ•ˆç‡** |
|---------|------------|-------------|-------------|
| ğŸ”¢ **Bitmap** | `ä½å›¾å­˜å‚¨` | `ç­¾åˆ°è®°å½•ã€æ´»è·ƒç»Ÿè®¡` | `æé«˜ï¼ˆ1bit/ç”¨æˆ·ï¼‰` |
| ğŸ“Š **HyperLogLog** | `åŸºæ•°ç»Ÿè®¡` | `UVç»Ÿè®¡ã€å»é‡è®¡æ•°` | `æé«˜ï¼ˆ12KBç»Ÿè®¡äº¿çº§ï¼‰` |
| ğŸ“ **GEO** | `åœ°ç†ä½ç½®` | `é™„è¿‘çš„äººã€ä½ç½®æœåŠ¡` | `é«˜ï¼ˆç»çº¬åº¦ç´¢å¼•ï¼‰` |
| ğŸŒŠ **Streams** | `æµå¼æ•°æ®` | `æ¶ˆæ¯é˜Ÿåˆ—ã€æ—¥å¿—ç³»ç»Ÿ` | `ä¸­ï¼ˆå¯æŒä¹…åŒ–ï¼‰` |

---

## 2. ğŸ”¢ ä½å›¾Bitmapåº”ç”¨


### 2.1 Bitmapæ˜¯ä»€ä¹ˆï¼Ÿ


**ğŸ’¡ ç”Ÿæ´»åŒ–ç†è§£**ï¼šå°±åƒ**æ‰“å¡ç­¾åˆ°è¡¨**
```
ä¼ ç»Ÿç­¾åˆ°è¡¨ï¼š
â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”
â”‚ç”¨æˆ·  â”‚ 1æœˆ â”‚ 2æœˆ â”‚ 3æœˆ â”‚ 4æœˆ â”‚ 5æœˆ â”‚ 6æœˆ â”‚
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¤
â”‚å¼ ä¸‰  â”‚ âœ“   â”‚ âœ—   â”‚ âœ“   â”‚ âœ“   â”‚ âœ—   â”‚ âœ“   â”‚
â”‚æå››  â”‚ âœ—   â”‚ âœ“   â”‚ âœ“   â”‚ âœ—   â”‚ âœ“   â”‚ âœ“   â”‚
â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜

Bitmapå­˜å‚¨ï¼ˆç”¨0å’Œ1è¡¨ç¤ºï¼‰ï¼š
å¼ ä¸‰ç­¾åˆ°: 101101 (ç¬¬1ã€3ã€4ã€6æœˆç­¾åˆ°)
æå››ç­¾åˆ°: 011011 (ç¬¬2ã€3ã€5ã€6æœˆç­¾åˆ°)

ä¼˜åŠ¿ï¼š1ä¸ªbit = 1ä¸ªçŠ¶æ€ï¼ŒèŠ‚çœå¤§é‡ç©ºé—´
```

**ğŸ”¸ Bitmapç‰¹ç‚¹**
- **ç©ºé—´æçœ**ï¼šæ¯ä¸ªç”¨æˆ·çŠ¶æ€åªéœ€1ä¸ªbit
- **æ“ä½œå¿«é€Ÿ**ï¼šä½è¿ç®—é€Ÿåº¦æå¿«
- **å¤©ç„¶ç´¢å¼•**ï¼šä½ç½®ç›´æ¥å¯¹åº”ç”¨æˆ·IDæˆ–æ—¶é—´
- **æ‰¹é‡ç»Ÿè®¡**ï¼šå¯ä»¥å¿«é€Ÿç»Ÿè®¡å¤šä¸ªçŠ¶æ€

### 2.2 ç”¨æˆ·ç­¾åˆ°ç³»ç»Ÿ


**ğŸ“… ç­¾åˆ°è®°å½•è®¾è®¡**
```
ç­¾åˆ°æ•°æ®å­˜å‚¨æ–¹æ¡ˆï¼š

æ–¹æ¡ˆ1ï¼šä¼ ç»Ÿæ–¹å¼ï¼ˆä¸æ¨èï¼‰
sign:user:1001 -> ["2024-01-15", "2024-01-16", "2024-01-18"]
é—®é¢˜ï¼šå ç”¨ç©ºé—´å¤§ï¼ŒæŸ¥è¯¢æ•ˆç‡ä½

æ–¹æ¡ˆ2ï¼šBitmapæ–¹å¼ï¼ˆæ¨èï¼‰  
sign:202401:1001 -> ä½å›¾ï¼ˆæ¯ä¸€ä½ä»£è¡¨å½“æœˆçš„ä¸€å¤©ï¼‰
ä½ç½®0 = 1æœˆ1æ—¥, ä½ç½®1 = 1æœˆ2æ—¥, ..., ä½ç½®30 = 1æœˆ31æ—¥
```

**ğŸ’» ç­¾åˆ°ç³»ç»Ÿå®ç°**
```python
class CheckInSystem:
    def __init__(self, redis_client):
        self.redis = redis_client
    
    def checkin(self, user_id, date=None):
        """ç”¨æˆ·ç­¾åˆ°"""
        if date is None:
            date = datetime.now()
        
        # ç”Ÿæˆkeyï¼šsign:å¹´æœˆ:ç”¨æˆ·ID
        key = f"sign:{date.strftime('%Y%m')}:{user_id}"
        # ç¬¬å‡ å¤©ï¼ˆ0-30ï¼‰
        day_offset = date.day - 1
        
        # è®¾ç½®å¯¹åº”ä½ä¸º1
        result = self.redis.setbit(key, day_offset, 1)
        
        # è®¾ç½®è¿‡æœŸæ—¶é—´ï¼ˆä¿å­˜3ä¸ªæœˆï¼‰
        self.redis.expire(key, 90 * 24 * 3600)
        
        return result == 0  # å¦‚æœä¹‹å‰æ˜¯0ï¼Œè¯´æ˜ä»Šå¤©ç¬¬ä¸€æ¬¡ç­¾åˆ°
    
    def check_signed(self, user_id, date):
        """æ£€æŸ¥æŸå¤©æ˜¯å¦ç­¾åˆ°"""
        key = f"sign:{date.strftime('%Y%m')}:{user_id}"
        day_offset = date.day - 1
        return self.redis.getbit(key, day_offset) == 1
    
    def get_month_checkin_count(self, user_id, year, month):
        """è·å–æŸæœˆç­¾åˆ°å¤©æ•°"""
        key = f"sign:{year:04d}{month:02d}:{user_id}"
        return self.redis.bitcount(key)
    
    def get_continuous_checkin_days(self, user_id):
        """è·å–è¿ç»­ç­¾åˆ°å¤©æ•°"""
        today = datetime.now()
        days = 0
        
        for i in range(365):  # æœ€å¤šæŸ¥ä¸€å¹´
            check_date = today - timedelta(days=i)
            if self.check_signed(user_id, check_date):
                days += 1
            else:
                break
                
        return days

# ä½¿ç”¨ç¤ºä¾‹
checkin_sys = CheckInSystem(redis_client)

# ç”¨æˆ·ç­¾åˆ°
is_first_today = checkin_sys.checkin(1001)
print(f"ä»Šæ—¥é¦–æ¬¡ç­¾åˆ°: {is_first_today}")

# æŸ¥çœ‹æœ¬æœˆç­¾åˆ°å¤©æ•°
month_days = checkin_sys.get_month_checkin_count(1001, 2024, 1)
print(f"æœ¬æœˆç­¾åˆ°å¤©æ•°: {month_days}")
```

### 2.3 æ´»è·ƒç”¨æˆ·ç»Ÿè®¡


**ğŸ“Š ç”¨æˆ·æ´»è·ƒåº¦åˆ†æ**
```python
class UserActivityAnalysis:
    def record_user_active(self, user_id, date=None):
        """è®°å½•ç”¨æˆ·æ´»è·ƒ"""
        if date is None:
            date = datetime.now()
            
        # æŒ‰æ—¥æœŸè®°å½•æ´»è·ƒç”¨æˆ·
        daily_key = f"active:daily:{date.strftime('%Y%m%d')}"
        self.redis.setbit(daily_key, user_id, 1)
        self.redis.expire(daily_key, 30 * 24 * 3600)  # 30å¤©è¿‡æœŸ
        
        # æŒ‰æœˆè®°å½•ï¼ˆç”¨äºæœˆåº¦ç»Ÿè®¡ï¼‰
        monthly_key = f"active:monthly:{date.strftime('%Y%m')}"
        self.redis.setbit(monthly_key, user_id, 1)
        self.redis.expire(monthly_key, 365 * 24 * 3600)  # 1å¹´è¿‡æœŸ
    
    def get_daily_active_users(self, date):
        """è·å–æ—¥æ´»è·ƒç”¨æˆ·æ•°"""
        key = f"active:daily:{date.strftime('%Y%m%d')}"
        return self.redis.bitcount(key)
    
    def get_weekly_active_users(self, end_date):
        """è·å–å‘¨æ´»è·ƒç”¨æˆ·æ•°ï¼ˆå»é‡ï¼‰"""
        # ç”Ÿæˆä¸€å‘¨çš„æ—¥æœŸkey
        keys = []
        for i in range(7):
            date = end_date - timedelta(days=i)
            key = f"active:daily:{date.strftime('%Y%m%d')}"
            keys.append(key)
        
        # ä½¿ç”¨ä½è¿ç®—ORæ“ä½œï¼Œåˆå¹¶ä¸€å‘¨çš„æ´»è·ƒç”¨æˆ·
        result_key = f"temp:weekly_active:{end_date.strftime('%Y%m%d')}"
        self.redis.bitop('OR', result_key, *keys)
        
        count = self.redis.bitcount(result_key)
        self.redis.expire(result_key, 3600)  # 1å°æ—¶åæ¸…ç†ä¸´æ—¶key
        
        return count
    
    def analyze_user_retention(self, base_date, retention_days):
        """åˆ†æç”¨æˆ·ç•™å­˜ç‡"""
        base_key = f"active:daily:{base_date.strftime('%Y%m%d')}"
        retention_stats = {}
        
        for day in retention_days:
            target_date = base_date + timedelta(days=day)
            target_key = f"active:daily:{target_date.strftime('%Y%m%d')}"
            
            # è®¡ç®—ç•™å­˜ç”¨æˆ·ï¼ˆä¸¤å¤©éƒ½æ´»è·ƒçš„ç”¨æˆ·ï¼‰
            temp_key = f"temp:retention_{base_date.strftime('%Y%m%d')}_{day}"
            self.redis.bitop('AND', temp_key, base_key, target_key)
            
            retention_count = self.redis.bitcount(temp_key)
            base_count = self.redis.bitcount(base_key)
            
            retention_rate = retention_count / base_count if base_count > 0 else 0
            retention_stats[f"{day}æ—¥ç•™å­˜"] = {
                "ç•™å­˜ç”¨æˆ·æ•°": retention_count,
                "ç•™å­˜ç‡": f"{retention_rate:.2%}"
            }
            
            self.redis.expire(temp_key, 3600)
            
        return retention_stats

# ä½¿ç”¨ç¤ºä¾‹
activity = UserActivityAnalysis(redis_client)

# è®°å½•ç”¨æˆ·æ´»è·ƒ
activity.record_user_active(1001)
activity.record_user_active(1002)

# åˆ†æç•™å­˜ç‡
retention = activity.analyze_user_retention(
    datetime(2024, 1, 1), 
    [1, 3, 7, 14, 30]  # 1æ—¥ã€3æ—¥ã€7æ—¥ã€14æ—¥ã€30æ—¥ç•™å­˜
)
print("ç•™å­˜åˆ†æ:", retention)
```

### 2.4 Bitmapé«˜çº§åº”ç”¨


**ğŸ”¬ ä½è¿ç®—çš„å¼ºå¤§åŠŸèƒ½**
```python
class AdvancedBitmapAnalysis:
    def user_behavior_analysis(self, date_range):
        """ç”¨æˆ·è¡Œä¸ºåˆ†æ"""
        
        behaviors = {
            "ç™»å½•": "login",
            "æµè§ˆ": "browse", 
            "è´­ä¹°": "purchase",
            "åˆ†äº«": "share"
        }
        
        analysis = {}
        
        for behavior_name, behavior_key in behaviors.items():
            # ç»Ÿè®¡å„è¡Œä¸ºçš„ç”¨æˆ·æ•°
            keys = [f"{behavior_key}:{date.strftime('%Y%m%d')}" 
                   for date in date_range]
            
            # åˆå¹¶æ‰€æœ‰æ—¥æœŸçš„æ•°æ®
            temp_key = f"temp:analysis_{behavior_key}"
            if keys:
                self.redis.bitop('OR', temp_key, *keys)
                count = self.redis.bitcount(temp_key)
                analysis[behavior_name] = count
                self.redis.expire(temp_key, 3600)
            
        return analysis
    
    def find_high_value_users(self, date):
        """æ‰¾å‡ºé«˜ä»·å€¼ç”¨æˆ·ï¼ˆåŒæ—¶æœ‰ç™»å½•ã€æµè§ˆã€è´­ä¹°è¡Œä¸ºï¼‰"""
        
        login_key = f"login:{date.strftime('%Y%m%d')}"
        browse_key = f"browse:{date.strftime('%Y%m%d')}"  
        purchase_key = f"purchase:{date.strftime('%Y%m%d')}"
        
        # ä½¿ç”¨ANDè¿ç®—æ‰¾å‡ºåŒæ—¶æ»¡è¶³ä¸‰ä¸ªæ¡ä»¶çš„ç”¨æˆ·
        result_key = f"temp:high_value_users_{date.strftime('%Y%m%d')}"
        self.redis.bitop('AND', result_key, login_key, browse_key, purchase_key)
        
        # è·å–å…·ä½“çš„ç”¨æˆ·ID
        high_value_users = []
        bitmap_length = self.redis.bitcount(result_key)
        
        if bitmap_length > 0:
            # éå†bitmapæ‰¾å‡ºå€¼ä¸º1çš„ä½ç½®
            for user_id in range(0, 100000):  # å‡è®¾ç”¨æˆ·IDèŒƒå›´
                if self.redis.getbit(result_key, user_id):
                    high_value_users.append(user_id)
                    
        self.redis.expire(result_key, 3600)
        return high_value_users

# åˆ›æ„åº”ç”¨ï¼šåœ¨çº¿çŠ¶æ€ç®¡ç†
def manage_online_status():
    """ç®¡ç†ç”¨æˆ·åœ¨çº¿çŠ¶æ€"""
    
    def set_user_online(user_id):
        """è®¾ç½®ç”¨æˆ·åœ¨çº¿"""
        redis_client.setbit("users:online", user_id, 1)
        # è®¾ç½®è¿‡æœŸè‡ªåŠ¨æ¸…ç†ï¼ˆç”¨æˆ·æ— æ“ä½œ5åˆ†é’Ÿåè‡ªåŠ¨ç¦»çº¿ï¼‰
        redis_client.expire("users:online", 300)
    
    def set_user_offline(user_id):
        """è®¾ç½®ç”¨æˆ·ç¦»çº¿"""
        redis_client.setbit("users:online", user_id, 0)
    
    def get_online_count():
        """è·å–åœ¨çº¿ç”¨æˆ·æ€»æ•°"""
        return redis_client.bitcount("users:online")
    
    def is_user_online(user_id):
        """æ£€æŸ¥ç”¨æˆ·æ˜¯å¦åœ¨çº¿"""
        return redis_client.getbit("users:online", user_id) == 1
```

---

## 3. ğŸ“Š HyperLogLogåŸºæ•°ç»Ÿè®¡


### 3.1 HyperLogLogæ˜¯ä»€ä¹ˆï¼Ÿ


**ğŸ’¡ é€šä¿—ç†è§£**ï¼šå°±åƒ**æ™ºèƒ½äººæ•°ç»Ÿè®¡å™¨**
```
ä¼ ç»Ÿæ–¹å¼ç»Ÿè®¡ç½‘ç«™è®¿é—®é‡ï¼š
æ–¹å¼1ï¼šç”¨Setå­˜å‚¨æ‰€æœ‰è®¿é—®ç”¨æˆ·
é—®é¢˜ï¼š100ä¸‡ç”¨æˆ· Ã— å‡è®¾10å­—èŠ‚/ç”¨æˆ· = 10MBå†…å­˜

æ–¹å¼2ï¼šç”¨æ•°æ®åº“è®°å½•
é—®é¢˜ï¼šæŸ¥è¯¢æ…¢ï¼Œæ•°æ®åº“å‹åŠ›å¤§

HyperLogLogæ–¹å¼ï¼š
ç”¨æ³•ï¼šåªéœ€12KBå†…å­˜ï¼Œå¯ä»¥ç»Ÿè®¡2^64ä¸ªä¸åŒå…ƒç´ 
ç²¾åº¦ï¼šè¯¯å·®ç‡çº¦0.81%ï¼Œå¯¹äºå¤§æ•°æ®ç»Ÿè®¡å®Œå…¨å¯æ¥å—
```

**ğŸ”¸ HyperLogLogç‰¹ç‚¹**
- **å†…å­˜æçœ**ï¼šå›ºå®š12KBå†…å­˜ï¼Œæ— è®ºç»Ÿè®¡å¤šå°‘æ•°æ®
- **è®¡ç®—å¿«é€Ÿ**ï¼šæ·»åŠ å’Œç»Ÿè®¡éƒ½æ˜¯O(1)æ—¶é—´å¤æ‚åº¦
- **è‡ªåŠ¨å»é‡**ï¼šé‡å¤å…ƒç´ ä¸ä¼šè¢«é‡å¤è®¡ç®—
- **è¿‘ä¼¼è®¡ç®—**ï¼šç»“æœæ˜¯ä¼°ç®—å€¼ï¼Œæœ‰å°å¹…è¯¯å·®

### 3.2 ç½‘ç«™UVç»Ÿè®¡


**ğŸ“ˆ ç‹¬ç«‹è®¿å®¢ç»Ÿè®¡ç³»ç»Ÿ**
```python
class UVStatistics:
    def __init__(self, redis_client):
        self.redis = redis_client
    
    def record_user_visit(self, user_id, date=None):
        """è®°å½•ç”¨æˆ·è®¿é—®"""
        if date is None:
            date = datetime.now()
            
        # æ—¥UVç»Ÿè®¡
        daily_key = f"uv:daily:{date.strftime('%Y%m%d')}"
        self.redis.pfadd(daily_key, user_id)
        self.redis.expire(daily_key, 90 * 24 * 3600)  # ä¿å­˜90å¤©
        
        # æœˆUVç»Ÿè®¡  
        monthly_key = f"uv:monthly:{date.strftime('%Y%m')}"
        self.redis.pfadd(monthly_key, user_id)
        self.redis.expire(monthly_key, 365 * 24 * 3600)  # ä¿å­˜1å¹´
        
        # å¹´UVç»Ÿè®¡
        yearly_key = f"uv:yearly:{date.year}"
        self.redis.pfadd(yearly_key, user_id)
        self.redis.expire(yearly_key, 5 * 365 * 24 * 3600)  # ä¿å­˜5å¹´
    
    def get_daily_uv(self, date):
        """è·å–æ—¥UV"""
        key = f"uv:daily:{date.strftime('%Y%m%d')}"
        return self.redis.pfcount(key)
    
    def get_period_uv(self, start_date, end_date):
        """è·å–æŒ‡å®šæ—¶é—´æ®µçš„UVï¼ˆå»é‡ï¼‰"""
        keys = []
        current_date = start_date
        
        while current_date <= end_date:
            key = f"uv:daily:{current_date.strftime('%Y%m%d')}"
            keys.append(key)
            current_date += timedelta(days=1)
        
        if not keys:
            return 0
            
        # åˆå¹¶å¤šå¤©çš„UVæ•°æ®
        temp_key = f"temp:period_uv_{start_date.strftime('%Y%m%d')}_{end_date.strftime('%Y%m%d')}"
        self.redis.pfmerge(temp_key, *keys)
        
        count = self.redis.pfcount(temp_key)
        self.redis.expire(temp_key, 3600)  # 1å°æ—¶åæ¸…ç†
        
        return count
    
    def get_uv_trend(self, days=30):
        """è·å–UVè¶‹åŠ¿æ•°æ®"""
        today = datetime.now()
        trend_data = []
        
        for i in range(days):
            date = today - timedelta(days=days-1-i)
            uv = self.get_daily_uv(date)
            trend_data.append({
                "date": date.strftime('%Y-%m-%d'),
                "uv": uv
            })
            
        return trend_data

# ä½¿ç”¨ç¤ºä¾‹
uv_stats = UVStatistics(redis_client)

# è®°å½•ç”¨æˆ·è®¿é—®
uv_stats.record_user_visit("user_1001")
uv_stats.record_user_visit("user_1002")
uv_stats.record_user_visit("user_1001")  # é‡å¤è®¿é—®ä¸ä¼šé‡å¤è®¡æ•°

# æŸ¥çœ‹ä»Šæ—¥UV
today_uv = uv_stats.get_daily_uv(datetime.now())
print(f"ä»Šæ—¥UV: {today_uv}")

# æŸ¥çœ‹æœ€è¿‘7å¤©UV
week_uv = uv_stats.get_period_uv(
    datetime.now() - timedelta(days=6),
    datetime.now()
)
print(f"æœ€è¿‘7å¤©UV: {week_uv}")
```

### 3.3 å¤šç»´åº¦ç»Ÿè®¡åˆ†æ


**ğŸ” å¤šè§’åº¦æ•°æ®åˆ†æ**
```python
class MultiDimensionAnalysis:
    def record_multi_dimension_data(self, user_id, page_id, channel, device):
        """è®°å½•å¤šç»´åº¦è®¿é—®æ•°æ®"""
        today = datetime.now().strftime('%Y%m%d')
        
        # æŒ‰é¡µé¢ç»Ÿè®¡UV
        self.redis.pfadd(f"uv:page:{page_id}:{today}", user_id)
        
        # æŒ‰æ¸ é“ç»Ÿè®¡UV
        self.redis.pfadd(f"uv:channel:{channel}:{today}", user_id)
        
        # æŒ‰è®¾å¤‡ç»Ÿè®¡UV
        self.redis.pfadd(f"uv:device:{device}:{today}", user_id)
        
        # è®¾ç½®è¿‡æœŸæ—¶é—´
        for key_pattern in ["uv:page:", "uv:channel:", "uv:device:"]:
            keys = self.redis.keys(f"{key_pattern}*:{today}")
            for key in keys:
                self.redis.expire(key, 90 * 24 * 3600)
    
    def analyze_page_popularity(self, date, page_ids):
        """åˆ†æé¡µé¢çƒ­åº¦"""
        date_str = date.strftime('%Y%m%d')
        page_stats = {}
        
        for page_id in page_ids:
            key = f"uv:page:{page_id}:{date_str}"
            uv = self.redis.pfcount(key)
            page_stats[page_id] = uv
            
        # æŒ‰UVæ’åº
        return sorted(page_stats.items(), key=lambda x: x[1], reverse=True)
    
    def compare_channel_effectiveness(self, date, channels):
        """æ¯”è¾ƒæ¸ é“æ•ˆæœ"""
        date_str = date.strftime('%Y%m%d')
        channel_stats = {}
        
        for channel in channels:
            key = f"uv:channel:{channel}:{date_str}"
            uv = self.redis.pfcount(key)
            channel_stats[channel] = uv
            
        return channel_stats
    
    def calculate_overlap_users(self, dimension1, value1, dimension2, value2, date):
        """è®¡ç®—ä¸¤ä¸ªç»´åº¦çš„é‡å ç”¨æˆ·æ•°"""
        date_str = date.strftime('%Y%m%d')
        
        key1 = f"uv:{dimension1}:{value1}:{date_str}"
        key2 = f"uv:{dimension2}:{value2}:{date_str}"
        
        # æ³¨æ„ï¼šHyperLogLogä¸èƒ½ç›´æ¥è®¡ç®—äº¤é›†
        # è¿™æ˜¯ä¸€ä¸ªè¿‘ä¼¼è®¡ç®—æ–¹æ³•
        total1 = self.redis.pfcount(key1)
        total2 = self.redis.pfcount(key2)
        
        # åˆå¹¶ä¸¤ä¸ªé›†åˆ
        temp_key = f"temp:merge_{dimension1}_{value1}_{dimension2}_{value2}_{date_str}"
        self.redis.pfmerge(temp_key, key1, key2)
        merged_count = self.redis.pfcount(temp_key)
        
        # ä½¿ç”¨åŒ…å«æ’é™¤åŸç†ä¼°ç®—äº¤é›†
        # |A âˆª B| = |A| + |B| - |A âˆ© B|
        # æ‰€ä»¥ |A âˆ© B| = |A| + |B| - |A âˆª B|
        overlap_estimate = total1 + total2 - merged_count
        
        self.redis.expire(temp_key, 3600)
        
        return {
            f"{dimension1}_{value1}_ç”¨æˆ·æ•°": total1,
            f"{dimension2}_{value2}_ç”¨æˆ·æ•°": total2,
            "åˆå¹¶åç”¨æˆ·æ•°": merged_count,
            "ä¼°ç®—é‡å ç”¨æˆ·æ•°": max(0, overlap_estimate)  # ç¡®ä¿ä¸ä¸ºè´Ÿæ•°
        }

# ä½¿ç”¨ç¤ºä¾‹
multi_analysis = MultiDimensionAnalysis()

# è®°å½•å¤šç»´åº¦æ•°æ®
multi_analysis.record_multi_dimension_data(
    user_id="user_1001",
    page_id="homepage", 
    channel="search_engine",
    device="mobile"
)

# åˆ†æé¡µé¢çƒ­åº¦
page_popularity = multi_analysis.analyze_page_popularity(
    datetime.now(),
    ["homepage", "product_page", "about_page"]
)
print("é¡µé¢çƒ­åº¦æ’è¡Œ:", page_popularity)
```

### 3.4 å®æ—¶ç»Ÿè®¡ä»ªè¡¨æ¿


**ğŸ“Š å®æ—¶æ•°æ®ä»ªè¡¨æ¿**
```python
class RealTimeDashboard:
    def get_realtime_stats(self):
        """è·å–å®æ—¶ç»Ÿè®¡æ•°æ®"""
        today = datetime.now()
        today_str = today.strftime('%Y%m%d')
        yesterday = today - timedelta(days=1)
        yesterday_str = yesterday.strftime('%Y%m%d')
        
        stats = {
            "ä»Šæ—¥UV": self.redis.pfcount(f"uv:daily:{today_str}"),
            "æ˜¨æ—¥UV": self.redis.pfcount(f"uv:daily:{yesterday_str}"),
            "æœ¬æœˆUV": self.redis.pfcount(f"uv:monthly:{today.strftime('%Y%m')}"),
            "æœ¬å¹´UV": self.redis.pfcount(f"uv:yearly:{today.year}")
        }
        
        # è®¡ç®—å¢é•¿ç‡
        if stats["æ˜¨æ—¥UV"] > 0:
            growth_rate = (stats["ä»Šæ—¥UV"] - stats["æ˜¨æ—¥UV"]) / stats["æ˜¨æ—¥UV"] * 100
            stats["æ—¥å¢é•¿ç‡"] = f"{growth_rate:.2f}%"
        
        return stats
    
    def export_hourly_uv(self, date):
        """å¯¼å‡ºå°æ—¶çº§UVæ•°æ®"""
        hourly_data = []
        
        for hour in range(24):
            key = f"uv:hourly:{date.strftime('%Y%m%d')}:{hour:02d}"
            uv = self.redis.pfcount(key)
            hourly_data.append({
                "hour": f"{hour:02d}:00",
                "uv": uv
            })
            
        return hourly_data

# æ€§èƒ½æµ‹è¯•å·¥å…·
class HLLPerformanceTest:
    def test_hll_vs_set(self, test_data_size=1000000):
        """æµ‹è¯•HyperLogLogä¸Setçš„æ€§èƒ½å·®å¼‚"""
        import time
        import random
        
        # ç”Ÿæˆæµ‹è¯•æ•°æ®
        test_users = [f"user_{i}" for i in range(test_data_size)]
        
        # æµ‹è¯•HyperLogLog
        start_time = time.time()
        hll_key = "test:hll"
        for user in test_users:
            self.redis.pfadd(hll_key, user)
        hll_time = time.time() - start_time
        hll_count = self.redis.pfcount(hll_key)
        hll_memory = self.redis.memory_usage(hll_key)
        
        # æµ‹è¯•Set
        start_time = time.time()
        set_key = "test:set"
        for user in test_users:
            self.redis.sadd(set_key, user)
        set_time = time.time() - start_time
        set_count = self.redis.scard(set_key)
        set_memory = self.redis.memory_usage(set_key)
        
        # æ¸…ç†æµ‹è¯•æ•°æ®
        self.redis.delete(hll_key, set_key)
        
        return {
            "æ•°æ®é‡": test_data_size,
            "HyperLogLog": {
                "è€—æ—¶": f"{hll_time:.2f}ç§’",
                "ç»Ÿè®¡ç»“æœ": hll_count,
                "å†…å­˜ä½¿ç”¨": f"{hll_memory / 1024:.2f}KB",
                "è¯¯å·®ç‡": f"{abs(hll_count - test_data_size) / test_data_size * 100:.2f}%"
            },
            "Set": {
                "è€—æ—¶": f"{set_time:.2f}ç§’", 
                "ç»Ÿè®¡ç»“æœ": set_count,
                "å†…å­˜ä½¿ç”¨": f"{set_memory / 1024:.2f}KB",
                "è¯¯å·®ç‡": "0%"
            },
            "æ€§èƒ½å¯¹æ¯”": {
                "å†…å­˜èŠ‚çœ": f"{(set_memory - hll_memory) / set_memory * 100:.1f}%",
                "é€Ÿåº¦å¯¹æ¯”": f"HLLæ¯”Set{'å¿«' if hll_time < set_time else 'æ…¢'}{abs(hll_time - set_time) / max(hll_time, set_time) * 100:.1f}%"
            }
        }
```

---

## 4. ğŸ“ åœ°ç†ä½ç½®GEO


### 4.1 GEOæ˜¯ä»€ä¹ˆï¼Ÿ


**ğŸ’¡ ç”Ÿæ´»åŒ–ç†è§£**ï¼šå°±åƒ**æ™ºèƒ½åœ°å›¾ç³»ç»Ÿ**
```
ç°å®åœºæ™¯ï¼š
ğŸ“± æ‰‹æœºåœ°å›¾ï¼šæœç´¢é™„è¿‘çš„é¤å…ã€åŠ æ²¹ç«™  
ğŸš— æ‰“è½¦è½¯ä»¶ï¼šæ‰¾é™„è¿‘çš„å¸æœºã€è®¡ç®—è·ç¦»
ğŸª å¤–å–å¹³å°ï¼šæ‰¾é™„è¿‘çš„å•†å®¶ã€é…é€èŒƒå›´

ä¼ ç»Ÿå®ç°é—®é¢˜ï¼š
âŒ å¤æ‚çš„ç»çº¬åº¦è®¡ç®—å…¬å¼
âŒ éœ€è¦ä¸“é—¨çš„åœ°ç†ä¿¡æ¯æ•°æ®åº“
âŒ è·ç¦»è®¡ç®—æ€§èƒ½å¼€é”€å¤§

Redis GEOè§£å†³ï¼š
âœ… å†…ç½®åœ°ç†ä½ç½®å­˜å‚¨å’Œè®¡ç®—
âœ… é«˜æ•ˆçš„è·ç¦»è®¡ç®—å’ŒèŒƒå›´æŸ¥è¯¢
âœ… ç®€å•çš„APIï¼Œå¼€ç®±å³ç”¨
```

**ğŸ”¸ GEOæ ¸å¿ƒåŠŸèƒ½**
- **ä½ç½®å­˜å‚¨**ï¼šå­˜å‚¨ç»çº¬åº¦åæ ‡
- **è·ç¦»è®¡ç®—**ï¼šè®¡ç®—ä¸¤ç‚¹é—´è·ç¦»
- **èŒƒå›´æŸ¥è¯¢**ï¼šæŸ¥æ‰¾æŒ‡å®šèŒƒå›´å†…çš„ä½ç½®ç‚¹
- **æ‰¹é‡æ“ä½œ**ï¼šä¸€æ¬¡å¤„ç†å¤šä¸ªä½ç½®ç‚¹

### 4.2 é™„è¿‘çš„äººåŠŸèƒ½


**ğŸ‘¥ ç¤¾äº¤åº”ç”¨ä½ç½®æœåŠ¡**
```python
class NearbyPeopleService:
    def __init__(self, redis_client):
        self.redis = redis_client
        self.location_key = "locations:users"
    
    def update_user_location(self, user_id, longitude, latitude, user_info=None):
        """æ›´æ–°ç”¨æˆ·ä½ç½®"""
        # æ·»åŠ ä½ç½®åˆ°GEOé›†åˆ
        result = self.redis.geoadd(
            self.location_key, 
            longitude, latitude, user_id
        )
        
        # å­˜å‚¨ç”¨æˆ·è¯¦ç»†ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
        if user_info:
            user_info_key = f"user:info:{user_id}"
            self.redis.hset(user_info_key, mapping=user_info)
            self.redis.expire(user_info_key, 24 * 3600)  # 24å°æ—¶è¿‡æœŸ
        
        # ä½ç½®ä¿¡æ¯1å°æ—¶è¿‡æœŸï¼ˆç”¨æˆ·ä¸æ´»è·ƒå°±ä¸æ˜¾ç¤ºï¼‰
        self.redis.expire(self.location_key, 3600)
        
        return result == 1  # 1è¡¨ç¤ºæ–°ä½ç½®ï¼Œ0è¡¨ç¤ºæ›´æ–°ä½ç½®
    
    def find_nearby_users(self, user_id, radius_km=5, count=20):
        """æŸ¥æ‰¾é™„è¿‘çš„ç”¨æˆ·"""
        # è·å–æŒ‡å®šç”¨æˆ·é™„è¿‘çš„å…¶ä»–ç”¨æˆ·
        nearby = self.redis.georadius(
            self.location_key,
            user_id,              # ä¸­å¿ƒç”¨æˆ·
            radius_km,            # èŒƒå›´ï¼ˆå…¬é‡Œï¼‰
            unit='km',
            withdist=True,        # è¿”å›è·ç¦»
            withcoord=True,       # è¿”å›åæ ‡
            count=count,          # æœ€å¤šè¿”å›æ•°é‡
            sort='ASC'            # æŒ‰è·ç¦»å‡åº
        )
        
        # æ’é™¤è‡ªå·±ï¼Œæ ¼å¼åŒ–ç»“æœ
        result = []
        for item in nearby:
            nearby_user_id = item[0].decode() if isinstance(item[0], bytes) else item[0]
            if nearby_user_id != str(user_id):
                distance = float(item[1])
                longitude, latitude = item[2]
                
                # è·å–ç”¨æˆ·ä¿¡æ¯
                user_info_key = f"user:info:{nearby_user_id}"
                user_info = self.redis.hgetall(user_info_key)
                
                result.append({
                    "user_id": nearby_user_id,
                    "distance": f"{distance:.2f}km",
                    "longitude": longitude,
                    "latitude": latitude,
                    "user_info": user_info
                })
                
        return result
    
    def find_nearby_by_coordinate(self, longitude, latitude, radius_km=5):
        """æ ¹æ®åæ ‡æŸ¥æ‰¾é™„è¿‘ç”¨æˆ·"""
        nearby = self.redis.georadius(
            self.location_key,
            longitude, latitude,  # æŒ‡å®šåæ ‡
            radius_km,
            unit='km', 
            withdist=True,
            count=50
        )
        
        result = []
        for item in nearby:
            user_id = item[0].decode() if isinstance(item[0], bytes) else item[0]
            distance = float(item[1])
            result.append({
                "user_id": user_id,
                "distance": f"{distance:.2f}km"
            })
            
        return result
    
    def calculate_distance_between_users(self, user1_id, user2_id):
        """è®¡ç®—ä¸¤ä¸ªç”¨æˆ·é—´çš„è·ç¦»"""
        distance = self.redis.geodist(
            self.location_key,
            user1_id, user2_id,
            unit='km'
        )
        
        return float(distance) if distance else None

# ä½¿ç”¨ç¤ºä¾‹
nearby_service = NearbyPeopleService(redis_client)

# æ›´æ–°ç”¨æˆ·ä½ç½®
nearby_service.update_user_location(
    user_id=1001,
    longitude=116.404, latitude=39.915,  # åŒ—äº¬å¤©å®‰é—¨åæ ‡
    user_info={
        "nickname": "å¼ ä¸‰",
        "age": "25", 
        "avatar": "http://example.com/avatar1.jpg"
    }
)

# æŸ¥æ‰¾é™„è¿‘5å…¬é‡Œå†…çš„ç”¨æˆ·
nearby_users = nearby_service.find_nearby_users(
    user_id=1001,
    radius_km=5,
    count=10
)
print("é™„è¿‘çš„ç”¨æˆ·:", nearby_users)
```

### 4.3 å•†å®¶é…é€èŒƒå›´


**ğŸ›ï¸ å¤–å–é…é€ç³»ç»Ÿ**
```python
class DeliveryService:
    def __init__(self, redis_client):
        self.redis = redis_client
        self.stores_key = "locations:stores"
        
    def register_store(self, store_id, longitude, latitude, delivery_radius, store_info):
        """æ³¨å†Œå•†å®¶"""
        # æ·»åŠ å•†å®¶ä½ç½®
        self.redis.geoadd(self.stores_key, longitude, latitude, store_id)
        
        # å­˜å‚¨å•†å®¶ä¿¡æ¯å’Œé…é€èŒƒå›´
        store_info_key = f"store:info:{store_id}"
        store_data = {
            **store_info,
            "delivery_radius": delivery_radius,  # é…é€åŠå¾„ï¼ˆå…¬é‡Œï¼‰
            "longitude": longitude,
            "latitude": latitude
        }
        self.redis.hset(store_info_key, mapping=store_data)
        
    def find_available_stores(self, customer_longitude, customer_latitude):
        """æŸ¥æ‰¾å¯é…é€çš„å•†å®¶"""
        # å…ˆæ‰¾å‡ºé™„è¿‘10å…¬é‡Œå†…çš„æ‰€æœ‰å•†å®¶ï¼ˆæ‰©å¤§æœç´¢èŒƒå›´ï¼‰
        nearby_stores = self.redis.georadius(
            self.stores_key,
            customer_longitude, customer_latitude,
            10,  # æœç´¢èŒƒå›´10å…¬é‡Œ
            unit='km',
            withdist=True,
            sort='ASC'
        )
        
        available_stores = []
        
        for item in nearby_stores:
            store_id = item[0].decode() if isinstance(item[0], bytes) else item[0]
            distance_to_store = float(item[1])
            
            # è·å–å•†å®¶é…é€èŒƒå›´
            store_info_key = f"store:info:{store_id}"
            store_info = self.redis.hgetall(store_info_key)
            
            if store_info:
                delivery_radius = float(store_info.get('delivery_radius', 0))
                
                # åˆ¤æ–­æ˜¯å¦åœ¨é…é€èŒƒå›´å†…
                if distance_to_store <= delivery_radius:
                    available_stores.append({
                        "store_id": store_id,
                        "distance": f"{distance_to_store:.2f}km",
                        "store_name": store_info.get('name', ''),
                        "delivery_radius": f"{delivery_radius}km",
                        "store_info": store_info
                    })
                    
        return available_stores
    
    def calculate_delivery_fee(self, store_id, customer_longitude, customer_latitude):
        """è®¡ç®—é…é€è´¹"""
        # è®¡ç®—è·ç¦»
        distance = self.redis.geodist(
            self.stores_key,
            store_id,
            f"temp:{customer_longitude}:{customer_latitude}",
            unit='km'
        )
        
        if distance is None:
            # å¦‚æœæ— æ³•è®¡ç®—è·ç¦»ï¼Œä¸´æ—¶æ·»åŠ å®¢æˆ·ä½ç½®
            temp_customer_id = f"temp_customer_{int(datetime.now().timestamp())}"
            self.redis.geoadd(self.stores_key, customer_longitude, customer_latitude, temp_customer_id)
            
            distance = self.redis.geodist(
                self.stores_key,
                store_id, temp_customer_id,
                unit='km'
            )
            
            # æ¸…ç†ä¸´æ—¶æ•°æ®
            self.redis.zrem(self.stores_key, temp_customer_id)
        
        distance_km = float(distance) if distance else 0
        
        # é…é€è´¹è®¡ç®—è§„åˆ™
        if distance_km <= 2:
            fee = 3  # 2å…¬é‡Œå†…èµ·æ­¥ä»·3å…ƒ
        elif distance_km <= 5:
            fee = 5  # 2-5å…¬é‡Œ5å…ƒ
        else:
            fee = 8  # è¶…è¿‡5å…¬é‡Œ8å…ƒ
            
        return {
            "distance": f"{distance_km:.2f}km",
            "delivery_fee": fee,
            "estimated_time": f"{max(20, int(distance_km * 8))}åˆ†é’Ÿ"  # ä¼°ç®—é…é€æ—¶é—´
        }

# ä½¿ç”¨ç¤ºä¾‹  
delivery = DeliveryService(redis_client)

# æ³¨å†Œå•†å®¶
delivery.register_store(
    store_id="store_001",
    longitude=116.404, latitude=39.915,
    delivery_radius=3,  # é…é€åŠå¾„3å…¬é‡Œ
    store_info={
        "name": "éº¦å½“åŠ³å¤©å®‰é—¨åº—",
        "phone": "010-12345678",
        "category": "å¿«é¤"
    }
)

# æŸ¥æ‰¾å¯é…é€å•†å®¶
available = delivery.find_available_stores(116.407, 39.918)  # å®¢æˆ·ä½ç½®
print("å¯é…é€å•†å®¶:", available)

# è®¡ç®—é…é€è´¹
fee_info = delivery.calculate_delivery_fee("store_001", 116.407, 39.918)
print("é…é€ä¿¡æ¯:", fee_info)
```

### 4.4 ä½ç½®æ•°æ®åˆ†æ


**ğŸ“Š åœ°ç†æ•°æ®åˆ†æ**
```python
class LocationAnalytics:
    def analyze_user_distribution(self, center_longitude, center_latitude, radius_km):
        """åˆ†æåŒºåŸŸå†…ç”¨æˆ·åˆ†å¸ƒ"""
        users_in_area = self.redis.georadius(
            "locations:users",
            center_longitude, center_latitude,
            radius_km,
            unit='km',
            withdist=True,
            withcoord=True
        )
        
        # ç»Ÿè®¡åˆ†æ
        total_users = len(users_in_area)
        distances = [float(item[1]) for item in users_in_area]
        
        if distances:
            avg_distance = sum(distances) / len(distances)
            max_distance = max(distances)
            min_distance = min(distances)
        else:
            avg_distance = max_distance = min_distance = 0
            
        return {
            "åŒºåŸŸä¸­å¿ƒ": f"({center_longitude}, {center_latitude})",
            "æœç´¢åŠå¾„": f"{radius_km}km",
            "ç”¨æˆ·æ€»æ•°": total_users,
            "å¹³å‡è·ç¦»": f"{avg_distance:.2f}km",
            "æœ€è¿œè·ç¦»": f"{max_distance:.2f}km", 
            "æœ€è¿‘è·ç¦»": f"{min_distance:.2f}km"
        }
    
    def find_popular_areas(self, grid_size=0.01):
        """æ‰¾å‡ºçƒ­é—¨åŒºåŸŸï¼ˆç”¨æˆ·å¯†é›†åŒºåŸŸï¼‰"""
        # è·å–æ‰€æœ‰ç”¨æˆ·ä½ç½®
        all_positions = self.redis.geopos("locations:users", 
                                         *self.redis.zrange("locations:users", 0, -1))
        
        # ç®€å•çš„ç½‘æ ¼ç»Ÿè®¡ï¼ˆå®é™…åº”ç”¨ä¸­å¯èƒ½éœ€è¦æ›´å¤æ‚çš„èšç±»ç®—æ³•ï¼‰
        grid_counts = {}
        
        for pos in all_positions:
            if pos:
                lon, lat = pos
                # å°†ä½ç½®å½’å…¥ç½‘æ ¼
                grid_lon = round(lon / grid_size) * grid_size
                grid_lat = round(lat / grid_size) * grid_size
                grid_key = f"{grid_lon},{grid_lat}"
                
                grid_counts[grid_key] = grid_counts.get(grid_key, 0) + 1
        
        # æŒ‰ç”¨æˆ·æ•°é‡æ’åº
        popular_areas = sorted(grid_counts.items(), 
                             key=lambda x: x[1], reverse=True)[:10]
        
        result = []
        for grid_pos, user_count in popular_areas:
            lon, lat = map(float, grid_pos.split(','))
            result.append({
                "ä¸­å¿ƒåæ ‡": f"({lon}, {lat})",
                "ç”¨æˆ·æ•°é‡": user_count,
                "å¯†åº¦ç­‰çº§": "é«˜" if user_count > 10 else "ä¸­" if user_count > 5 else "ä½"
            })
            
        return result
```

---

## 5. ğŸŒŠ Streamsæµå¼æ•°æ®


### 5.1 Streamsæ˜¯ä»€ä¹ˆï¼Ÿ


**ğŸ’¡ ç”Ÿæ´»åŒ–ç†è§£**ï¼šå°±åƒ**æ™ºèƒ½æ¶ˆæ¯æµæ°´çº¿**
```
ä¼ ç»Ÿæ¶ˆæ¯é˜Ÿåˆ—é—®é¢˜ï¼š
âŒ éœ€è¦å•ç‹¬éƒ¨ç½²ï¼ˆå¦‚RabbitMQã€Kafkaï¼‰
âŒ é…ç½®å¤æ‚ï¼Œå­¦ä¹ æˆæœ¬é«˜
âŒ æ— æ³•å›æº¯å†å²æ¶ˆæ¯

Redis Streamsè§£å†³ï¼š
âœ… Rediså†…ç½®æ¶ˆæ¯é˜Ÿåˆ—åŠŸèƒ½
âœ… æ”¯æŒæ¶ˆæ¯æŒä¹…åŒ–å’Œå›æº¯
âœ… æ”¯æŒæ¶ˆè´¹è€…ç»„ï¼Œè´Ÿè½½å‡è¡¡
âœ… è‡ªåŠ¨ç”Ÿæˆæ¶ˆæ¯IDï¼Œä¿è¯é¡ºåº

åƒæ²³æµä¸€æ ·ï¼š
æ¶ˆæ¯æºå¤´ â†’ æ¶ˆæ¯æµ â†’ å¤šä¸ªæ¶ˆè´¹è€…
       â†“
   [msg1][msg2][msg3][msg4][msg5]...
       â†“
æ¶ˆè´¹è€…ç»„A: å¤„ç†è®¢å•æ¶ˆæ¯
æ¶ˆè´¹è€…ç»„B: å‘é€é€šçŸ¥æ¶ˆæ¯  
æ¶ˆè´¹è€…ç»„C: è®°å½•æ—¥å¿—æ¶ˆæ¯
```

**ğŸ”¸ Streamsæ ¸å¿ƒç‰¹æ€§**
- **æ¶ˆæ¯æŒä¹…åŒ–**ï¼šæ¶ˆæ¯ä¸ä¼šä¸¢å¤±ï¼Œå¯ä»¥å›æº¯
- **æ¶ˆè´¹è€…ç»„**ï¼šæ”¯æŒå¤šæ¶ˆè´¹è€…è´Ÿè½½å‡è¡¡
- **è‡ªåŠ¨ID**ï¼šæ—¶é—´æˆ³+åºå·ï¼Œä¿è¯å”¯ä¸€æ€§å’Œé¡ºåº
- **é˜»å¡è¯»å–**ï¼šå¯ä»¥ç­‰å¾…æ–°æ¶ˆæ¯åˆ°è¾¾

### 5.2 æ—¥å¿—æ”¶é›†ç³»ç»Ÿ


**ğŸ“ åº”ç”¨æ—¥å¿—å¤„ç†**
```python
class LogCollectionSystem:
    def __init__(self, redis_client):
        self.redis = redis_client
        self.stream_key = "logs:application"
        
    def write_log(self, level, message, module="", extra_fields=None):
        """å†™å…¥æ—¥å¿—"""
        log_data = {
            "timestamp": datetime.now().isoformat(),
            "level": level,
            "message": message,
            "module": module,
            "host": self.get_hostname()
        }
        
        # æ·»åŠ é¢å¤–å­—æ®µ
        if extra_fields:
            log_data.update(extra_fields)
            
        # å†™å…¥Stream
        message_id = self.redis.xadd(self.stream_key, log_data)
        
        return message_id
    
    def get_hostname(self):
        import socket
        return socket.gethostname()
    
    def read_logs(self, start_id="0", count=100):
        """è¯»å–æ—¥å¿—"""
        logs = self.redis.xrange(self.stream_key, start_id, count=count)
        
        formatted_logs = []
        for log_id, fields in logs:
            log_entry = {
                "id": log_id.decode(),
                "timestamp": fields.get(b'timestamp', b'').decode(),
                "level": fields.get(b'level', b'').decode(),
                "message": fields.get(b'message', b'').decode(),
                "module": fields.get(b'module', b'').decode(),
                "host": fields.get(b'host', b'').decode()
            }
            formatted_logs.append(log_entry)
            
        return formatted_logs
    
    def create_log_consumer_group(self, group_name, consumer_name):
        """åˆ›å»ºæ—¥å¿—æ¶ˆè´¹è€…ç»„"""
        try:
            # åˆ›å»ºæ¶ˆè´¹è€…ç»„ï¼Œä»æœ€æ–°æ¶ˆæ¯å¼€å§‹
            self.redis.xgroup_create(self.stream_key, group_name, id="$", mkstream=True)
        except Exception as e:
            # å¦‚æœç»„å·²å­˜åœ¨ï¼Œå¿½ç•¥é”™è¯¯
            if "BUSYGROUP" not in str(e):
                raise e
                
        return True
    
    def consume_logs(self, group_name, consumer_name, count=10, block_ms=1000):
        """æ¶ˆè´¹æ—¥å¿—"""
        try:
            # ä»æ¶ˆè´¹è€…ç»„è¯»å–æ¶ˆæ¯
            messages = self.redis.xreadgroup(
                group_name, consumer_name,
                {self.stream_key: ">"},  # > è¡¨ç¤ºè¯»å–æœªè¢«æ¶ˆè´¹çš„æ¶ˆæ¯
                count=count,
                block=block_ms
            )
            
            processed_logs = []
            
            for stream_name, stream_messages in messages:
                for message_id, fields in stream_messages:
                    log_data = {
                        "message_id": message_id.decode(),
                        "stream": stream_name.decode(),
                        "fields": {k.decode(): v.decode() for k, v in fields.items()}
                    }
                    processed_logs.append(log_data)
                    
                    # å¤„ç†å®Œæˆåç¡®è®¤æ¶ˆæ¯
                    self.redis.xack(self.stream_key, group_name, message_id)
                    
            return processed_logs
            
        except Exception as e:
            print(f"æ¶ˆè´¹æ—¥å¿—æ—¶å‡ºé”™: {e}")
            return []

# ä½¿ç”¨ç¤ºä¾‹
log_system = LogCollectionSystem(redis_client)

# å†™å…¥ä¸åŒçº§åˆ«çš„æ—¥å¿—
log_system.write_log("INFO", "ç”¨æˆ·ç™»å½•æˆåŠŸ", "auth", {"user_id": "1001", "ip": "192.168.1.100"})
log_system.write_log("ERROR", "æ•°æ®åº“è¿æ¥å¤±è´¥", "database", {"error_code": "DB001"})
log_system.write_log("WARNING", "å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜", "monitor", {"memory_usage": "85%"})

# åˆ›å»ºæ¶ˆè´¹è€…ç»„
log_system.create_log_consumer_group("log_processors", "processor_1")

# æ¶ˆè´¹æ—¥å¿—
consumed = log_system.consume_logs("log_processors", "processor_1", count=5)
print("æ¶ˆè´¹åˆ°çš„æ—¥å¿—:", consumed)
```

### 5.3 å®æ—¶æ¶ˆæ¯ç³»ç»Ÿ


**ğŸ’¬ å®æ—¶é€šä¿¡åº”ç”¨**
```python
class RealTimeMessageSystem:
    def __init__(self, redis_client):
        self.redis = redis_client
        
    def send_message(self, room_id, user_id, message_type="text", content="", extra_data=None):
        """å‘é€æ¶ˆæ¯åˆ°æˆ¿é—´"""
        stream_key = f"messages:room:{room_id}"
        
        message_data = {
            "user_id": user_id,
            "message_type": message_type,
            "content": content,
            "timestamp": datetime.now().isoformat(),
            "room_id": room_id
        }
        
        if extra_data:
            message_data.update(extra_data)
            
        message_id = self.redis.xadd(stream_key, message_data)
        
        # è®¾ç½®Streamè¿‡æœŸæ—¶é—´ï¼ˆä¿ç•™7å¤©æ¶ˆæ¯ï¼‰
        self.redis.expire(stream_key, 7 * 24 * 3600)
        
        return message_id
    
    def join_room(self, room_id, user_id):
        """ç”¨æˆ·åŠ å…¥æˆ¿é—´ï¼ˆåˆ›å»ºæ¶ˆè´¹è€…ï¼‰"""
        stream_key = f"messages:room:{room_id}"
        consumer_group = f"room_{room_id}_users"
        consumer_name = f"user_{user_id}"
        
        try:
            # åˆ›å»ºæ¶ˆè´¹è€…ç»„ï¼ˆä»å½“å‰æ—¶é—´å¼€å§‹æ¥æ”¶æ¶ˆæ¯ï¼‰
            self.redis.xgroup_create(stream_key, consumer_group, id="$", mkstream=True)
        except:
            pass  # å¦‚æœç»„å·²å­˜åœ¨ï¼Œå¿½ç•¥é”™è¯¯
            
        return {"room_id": room_id, "user_id": user_id, "status": "joined"}
    
    def get_room_messages(self, room_id, user_id, count=50, block_ms=5000):
        """è·å–æˆ¿é—´æ¶ˆæ¯"""
        stream_key = f"messages:room:{room_id}"
        consumer_group = f"room_{room_id}_users"
        consumer_name = f"user_{user_id}"
        
        try:
            # è¯»å–æ¶ˆæ¯
            messages = self.redis.xreadgroup(
                consumer_group, consumer_name,
                {stream_key: ">"},
                count=count,
                block=block_ms
            )
            
            formatted_messages = []
            
            for stream_name, stream_messages in messages:
                for message_id, fields in stream_messages:
                    msg_data = {
                        "message_id": message_id.decode(),
                        "user_id": fields.get(b'user_id', b'').decode(),
                        "message_type": fields.get(b'message_type', b'').decode(), 
                        "content": fields.get(b'content', b'').decode(),
                        "timestamp": fields.get(b'timestamp', b'').decode(),
                    }
                    formatted_messages.append(msg_data)
                    
                    # ç¡®è®¤æ¶ˆæ¯å·²å¤„ç†
                    self.redis.xack(stream_key, consumer_group, message_id)
                    
            return formatted_messages
            
        except Exception as e:
            print(f"è·å–æ¶ˆæ¯æ—¶å‡ºé”™: {e}")
            return []
    
    def get_message_history(self, room_id, start_time=None, end_time=None, count=100):
        """è·å–æ¶ˆæ¯å†å²è®°å½•"""
        stream_key = f"messages:room:{room_id}"
        
        # æ ¹æ®æ—¶é—´èŒƒå›´æ„å»ºæŸ¥è¯¢ID
        start_id = "0" if start_time is None else f"{int(start_time.timestamp() * 1000)}-0"
        end_id = "+" if end_time is None else f"{int(end_time.timestamp() * 1000)}-0"
        
        messages = self.redis.xrange(stream_key, start_id, end_id, count=count)
        
        history = []
        for message_id, fields in messages:
            msg = {
                "id": message_id.decode(),
                "user_id": fields.get(b'user_id', b'').decode(),
                "content": fields.get(b'content', b'').decode(),
                "timestamp": fields.get(b'timestamp', b'').decode(),
                "type": fields.get(b'message_type', b'').decode()
            }
            history.append(msg)
            
        return history

# èŠå¤©å®¤åº”ç”¨ç¤ºä¾‹
chat_system = RealTimeMessageSystem(redis_client)

# ç”¨æˆ·åŠ å…¥æˆ¿é—´
chat_system.join_room("room_001", "user_1001")
chat_system.join_room("room_001", "user_1002")

# å‘é€æ¶ˆæ¯
chat_system.send_message("room_001", "user_1001", "text", "å¤§å®¶å¥½ï¼")
chat_system.send_message("room_001", "user_1002", "text", "ä½ å¥½ï¼")
chat_system.send_message("room_001", "user_1001", "image", "", {"image_url": "http://example.com/pic.jpg"})

# è·å–æ¶ˆæ¯
messages = chat_system.get_room_messages("room_001", "user_1002", count=10)
print("æ¥æ”¶åˆ°çš„æ¶ˆæ¯:", messages)
```

### 5.4 äº‹ä»¶é©±åŠ¨æ¶æ„


**âš¡ äº‹ä»¶å¤„ç†ç³»ç»Ÿ**
```python
class EventDrivenSystem:
    def __init__(self, redis_client):
        self.redis = redis_client
        self.events_stream = "events:system"
        
    def publish_event(self, event_type, event_data, source="system"):
        """å‘å¸ƒäº‹ä»¶"""
        event = {
            "event_type": event_type,
            "source": source,
            "timestamp": datetime.now().isoformat(),
            "data": json.dumps(event_data) if isinstance(event_data, dict) else str(event_data)
        }
        
        event_id = self.redis.xadd(self.events_stream, event)
        print(f"äº‹ä»¶å·²å‘å¸ƒ: {event_type} - {event_id}")
        return event_id
    
    def create_event_processor(self, processor_name, event_types=None):
        """åˆ›å»ºäº‹ä»¶å¤„ç†å™¨"""
        consumer_group = f"processors_{processor_name}"
        
        try:
            self.redis.xgroup_create(self.events_stream, consumer_group, id="0", mkstream=True)
            print(f"äº‹ä»¶å¤„ç†å™¨ {processor_name} åˆ›å»ºæˆåŠŸ")
        except:
            print(f"äº‹ä»¶å¤„ç†å™¨ {processor_name} å·²å­˜åœ¨")
            
        return EventProcessor(self.redis, self.events_stream, consumer_group, processor_name, event_types)

class EventProcessor:
    def __init__(self, redis_client, stream_key, consumer_group, processor_name, event_types=None):
        self.redis = redis_client
        self.stream_key = stream_key
        self.consumer_group = consumer_group
        self.processor_name = processor_name
        self.event_types = event_types or []
        
    def process_events(self, count=10, block_ms=2000):
        """å¤„ç†äº‹ä»¶"""
        try:
            messages = self.redis.xreadgroup(
                self.consumer_group, self.processor_name,
                {self.stream_key: ">"},
                count=count,
                block=block_ms
            )
            
            for stream_name, stream_messages in messages:
                for message_id, fields in stream_messages:
                    event_type = fields.get(b'event_type', b'').decode()
                    
                    # å¦‚æœæŒ‡å®šäº†å¤„ç†çš„äº‹ä»¶ç±»å‹ï¼Œåˆ™è¿‡æ»¤
                    if self.event_types and event_type not in self.event_types:
                        self.redis.xack(self.stream_key, self.consumer_group, message_id)
                        continue
                    
                    # å¤„ç†äº‹ä»¶
                    self.handle_event(message_id, fields)
                    
                    # ç¡®è®¤å¤„ç†å®Œæˆ
                    self.redis.xack(self.stream_key, self.consumer_group, message_id)
                    
        except Exception as e:
            print(f"å¤„ç†äº‹ä»¶æ—¶å‡ºé”™: {e}")
    
    def handle_event(self, message_id, fields):
        """å…·ä½“äº‹ä»¶å¤„ç†é€»è¾‘ï¼ˆéœ€è¦å­ç±»å®ç°ï¼‰"""
        event_type = fields.get(b'event_type', b'').decode()
        event_data = fields.get(b'data', b'').decode()
        timestamp = fields.get(b'timestamp', b'').decode()
        
        print(f"[{self.processor_name}] å¤„ç†äº‹ä»¶: {event_type} | æ•°æ®: {event_data} | æ—¶é—´: {timestamp}")

# å…·ä½“äº‹ä»¶å¤„ç†å™¨å®ç°
class OrderEventProcessor(EventProcessor):
    def handle_event(self, message_id, fields):
        event_type = fields.get(b'event_type', b'').decode()
        event_data = json.loads(fields.get(b'data', b'{}').decode())
        
        if event_type == "order_created":
            self.handle_order_created(event_data)
        elif event_type == "order_paid":
            self.handle_order_paid(event_data)
        elif event_type == "order_shipped":
            self.handle_order_shipped(event_data)
            
    def handle_order_created(self, data):
        print(f"å¤„ç†è®¢å•åˆ›å»ºäº‹ä»¶: è®¢å•ID {data.get('order_id')}")
        # å®é™…å¤„ç†ï¼šå‘é€ç¡®è®¤é‚®ä»¶ã€æ›´æ–°åº“å­˜ç­‰
        
    def handle_order_paid(self, data):
        print(f"å¤„ç†è®¢å•æ”¯ä»˜äº‹ä»¶: è®¢å•ID {data.get('order_id')}")
        # å®é™…å¤„ç†ï¼šé€šçŸ¥å‘è´§ã€æ›´æ–°è´¢åŠ¡è®°å½•ç­‰
        
    def handle_order_shipped(self, data):
        print(f"å¤„ç†è®¢å•å‘è´§äº‹ä»¶: è®¢å•ID {data.get('order_id')}")
        # å®é™…å¤„ç†ï¼šå‘é€ç‰©æµé€šçŸ¥ã€æ›´æ–°è®¢å•çŠ¶æ€ç­‰

# ä½¿ç”¨ç¤ºä¾‹
event_system = EventDrivenSystem(redis_client)

# åˆ›å»ºè®¢å•äº‹ä»¶å¤„ç†å™¨
order_processor = event_system.create_event_processor(
    "order_handler", 
    ["order_created", "order_paid", "order_shipped"]
)

# å‘å¸ƒäº‹ä»¶
event_system.publish_event("order_created", {
    "order_id": "ORDER_001",
    "user_id": "1001",
    "amount": 99.99,
    "products": ["product_1", "product_2"]
})

event_system.publish_event("order_paid", {
    "order_id": "ORDER_001", 
    "payment_method": "alipay",
    "paid_amount": 99.99
})

# å¤„ç†äº‹ä»¶ï¼ˆé€šå¸¸åœ¨åå°å¾ªç¯è¿è¡Œï¼‰
order_processor.process_events(count=5)
```

---

## 6. âš–ï¸ æ€§èƒ½å¯¹æ¯”ä¸é€‰æ‹©


### 6.1 æ•°æ®ç»“æ„æ€§èƒ½å¯¹æ¯”


| æ•°æ®ç»“æ„ | **å†…å­˜æ•ˆç‡** | **æŸ¥è¯¢é€Ÿåº¦** | **é€‚ç”¨æ•°æ®é‡** | **åŠŸèƒ½å¤æ‚åº¦** |
|---------|------------|-------------|-------------|-------------|
| ğŸ”¢ **Bitmap** | `â­â­â­â­â­` | `â­â­â­â­â­` | `åƒä¸‡çº§ä»¥ä¸Š` | `â­â­` |
| ğŸ“Š **HyperLogLog** | `â­â­â­â­â­` | `â­â­â­â­â­` | `äº¿çº§ç»Ÿè®¡` | `â­â­` |
| ğŸ“ **GEO** | `â­â­â­â­` | `â­â­â­â­` | `ç™¾ä¸‡çº§ä½ç½®` | `â­â­â­â­` |
| ğŸŒŠ **Streams** | `â­â­â­` | `â­â­â­` | `åƒä¸‡çº§æ¶ˆæ¯` | `â­â­â­â­â­` |

### 6.2 åœºæ™¯é€‰æ‹©æŒ‡å—


**ğŸ¯ é€‰æ‹©å†³ç­–æ ‘**
```
éœ€è¦ç»Ÿè®¡å¤§é‡å¸ƒå°”çŠ¶æ€ï¼Ÿ
â”œâ”€ YES â†’ Bitmap
â”‚   â””â”€ ç”¨æˆ·ç­¾åˆ°ã€æ´»è·ƒç»Ÿè®¡ã€çŠ¶æ€æ ‡è®°
â”‚
éœ€è¦å¤§æ•°æ®å»é‡è®¡æ•°ï¼Ÿ 
â”œâ”€ YES â†’ HyperLogLog
â”‚   â””â”€ UVç»Ÿè®¡ã€ç”¨æˆ·å»é‡ã€åŸºæ•°ç»Ÿè®¡
â”‚
éœ€è¦åœ°ç†ä½ç½®åŠŸèƒ½ï¼Ÿ
â”œâ”€ YES â†’ GEO  
â”‚   â””â”€ LBSåº”ç”¨ã€è·ç¦»è®¡ç®—ã€èŒƒå›´æŸ¥è¯¢
â”‚
éœ€è¦æ¶ˆæ¯é˜Ÿåˆ—åŠŸèƒ½ï¼Ÿ
â””â”€ YES â†’ Streams
    â””â”€ æ—¥å¿—ç³»ç»Ÿã€å®æ—¶æ¶ˆæ¯ã€äº‹ä»¶é©±åŠ¨
```

### 6.3 æ€§èƒ½æµ‹è¯•å¯¹æ¯”


**ğŸ“Š å®é™…æ€§èƒ½æµ‹è¯•**
```python
class PerformanceComparison:
    def compare_user_status_storage(self, user_count=1000000):
        """å¯¹æ¯”ç”¨æˆ·çŠ¶æ€å­˜å‚¨æ–¹æ¡ˆ"""
        import time
        
        print(f"æµ‹è¯• {user_count} ä¸ªç”¨æˆ·çš„çŠ¶æ€å­˜å‚¨...")
        
        # æ–¹æ¡ˆ1: ä½¿ç”¨Stringå­˜å‚¨
        start_time = time.time()
        string_keys = []
        for user_id in range(user_count):
            if user_id % 2 == 0:  # æ¨¡æ‹Ÿ50%ç”¨æˆ·ç­¾åˆ°
                key = f"checkin:string:{user_id}"
                self.redis.set(key, "1", ex=3600)
                string_keys.append(key)
        string_time = time.time() - start_time
        string_memory = sum(self.redis.memory_usage(key) for key in string_keys[:100]) * len(string_keys) // 100
        
        # æ–¹æ¡ˆ2: ä½¿ç”¨Bitmapå­˜å‚¨
        start_time = time.time()
        bitmap_key = "checkin:bitmap"
        for user_id in range(user_count):
            if user_id % 2 == 0:  # æ¨¡æ‹Ÿ50%ç”¨æˆ·ç­¾åˆ°
                self.redis.setbit(bitmap_key, user_id, 1)
        bitmap_time = time.time() - start_time
        bitmap_memory = self.redis.memory_usage(bitmap_key)
        
        # æ¸…ç†æµ‹è¯•æ•°æ®
        self.redis.delete(*string_keys)
        self.redis.delete(bitmap_key)
        
        return {
            "æµ‹è¯•æ•°æ®é‡": user_count,
            "Stringæ–¹å¼": {
                "è€—æ—¶": f"{string_time:.2f}ç§’",
                "å†…å­˜ä½¿ç”¨": f"{string_memory / 1024 / 1024:.2f}MB"
            },
            "Bitmapæ–¹å¼": {
                "è€—æ—¶": f"{bitmap_time:.2f}ç§’", 
                "å†…å­˜ä½¿ç”¨": f"{bitmap_memory / 1024 / 1024:.2f}MB"
            },
            "æ€§èƒ½æå‡": {
                "å†…å­˜èŠ‚çœ": f"{(string_memory - bitmap_memory) / string_memory * 100:.1f}%",
                "é€Ÿåº¦æå‡": f"{(string_time - bitmap_time) / string_time * 100:.1f}%"
            }
        }
    
    def test_uv_counting_methods(self, unique_users=5000000):
        """å¯¹æ¯”UVè®¡æ•°æ–¹æ³•"""
        import random
        
        # ç”Ÿæˆæµ‹è¯•ç”¨æˆ·ï¼ˆæ¨¡æ‹Ÿé‡å¤è®¿é—®ï¼‰
        test_visits = []
        for _ in range(unique_users * 2):  # æ¨¡æ‹Ÿæ¯ç”¨æˆ·å¹³å‡è®¿é—®2æ¬¡
            user_id = f"user_{random.randint(1, unique_users)}"
            test_visits.append(user_id)
            
        # æ–¹æ¡ˆ1: Setå­˜å‚¨
        start_time = time.time()
        set_key = "test:uv_set"
        for user_id in test_visits:
            self.redis.sadd(set_key, user_id)
        set_time = time.time() - start_time
        set_count = self.redis.scard(set_key)
        set_memory = self.redis.memory_usage(set_key)
        
        # æ–¹æ¡ˆ2: HyperLogLogå­˜å‚¨
        start_time = time.time()
        hll_key = "test:uv_hll" 
        for user_id in test_visits:
            self.redis.pfadd(hll_key, user_id)
        hll_time = time.time() - start_time
        hll_count = self.redis.pfcount(hll_key)
        hll_memory = self.redis.memory_usage(hll_key)
        
        # æ¸…ç†æµ‹è¯•æ•°æ®
        self.redis.delete(set_key, hll_key)
        
        error_rate = abs(hll_count - set_count) / set_count * 100
        
        return {
            "æµ‹è¯•è®¿é—®é‡": len(test_visits),
            "å®é™…ç‹¬ç«‹ç”¨æˆ·": unique_users,
            "Setæ–¹å¼": {
                "è€—æ—¶": f"{set_time:.2f}ç§’",
                "ç»Ÿè®¡ç»“æœ": set_count,
                "å†…å­˜ä½¿ç”¨": f"{set_memory / 1024 / 1024:.2f}MB"
            },
            "HyperLogLogæ–¹å¼": {
                "è€—æ—¶": f"{hll_time:.2f}ç§’",
                "ç»Ÿè®¡ç»“æœ": hll_count, 
                "å†…å­˜ä½¿ç”¨": f"{hll_memory / 1024:.2f}KB",
                "è¯¯å·®ç‡": f"{error_rate:.3f}%"
            },
            "æ•ˆç‡å¯¹æ¯”": {
                "å†…å­˜èŠ‚çœ": f"{(set_memory - hll_memory) / set_memory * 100:.1f}%",
                "ç²¾åº¦æŸå¤±": f"{error_rate:.3f}%"
            }
        }

# ç»¼åˆæ€§èƒ½æµ‹è¯•
def run_performance_tests():
    """è¿è¡Œç»¼åˆæ€§èƒ½æµ‹è¯•"""
    perf_test = PerformanceComparison()
    
    print("=== Bitmap vs String æ€§èƒ½æµ‹è¯• ===")
    bitmap_result = perf_test.compare_user_status_storage(100000)
    for key, value in bitmap_result.items():
        print(f"{key}: {value}")
    
    print("\n=== HyperLogLog vs Set æ€§èƒ½æµ‹è¯• ===")  
    hll_result = perf_test.test_uv_counting_methods(500000)
    for key, value in hll_result.items():
        print(f"{key}: {value}")
```

### 6.4 é€‰æ‹©å»ºè®®ä¸æœ€ä½³å®è·µ


**ğŸ’¡ å®é™…é¡¹ç›®é€‰æ‹©æŒ‡å—**
```
ğŸ“Š ç»Ÿè®¡ç±»åœºæ™¯ï¼š
â€¢ ç”¨æˆ·çŠ¶æ€ï¼ˆç­¾åˆ°ã€æ´»è·ƒï¼‰â†’ Bitmap
â€¢ ç”¨æˆ·å»é‡è®¡æ•°ï¼ˆUVã€PVå»é‡ï¼‰â†’ HyperLogLog  
â€¢ ç²¾ç¡®å°è§„æ¨¡è®¡æ•° â†’ Set
â€¢ å¤§è§„æ¨¡è¿‘ä¼¼è®¡æ•° â†’ HyperLogLog

ğŸ—ºï¸ åœ°ç†ä½ç½®åœºæ™¯ï¼š
â€¢ é™„è¿‘çš„äºº/å•†å®¶ â†’ GEO
â€¢ é…é€èŒƒå›´è®¡ç®— â†’ GEO
â€¢ è½¨è¿¹è®°å½• â†’ ç»“åˆGEO + Streams
â€¢ çƒ­é—¨åŒºåŸŸåˆ†æ â†’ GEO

ğŸ“¨ æ¶ˆæ¯å¤„ç†åœºæ™¯ï¼š
â€¢ ç®€å•é˜Ÿåˆ— â†’ List (LPUSH/RPOP)
â€¢ å¯é æ¶ˆæ¯é˜Ÿåˆ— â†’ Streams
â€¢ å®æ—¶èŠå¤© â†’ Streams
â€¢ äº‹ä»¶é©±åŠ¨æ¶æ„ â†’ Streams
â€¢ æ—¥å¿—æ”¶é›† â†’ Streams

âš¡ æ€§èƒ½è¦æ±‚åœºæ™¯ï¼š
â€¢ æ¯«ç§’çº§å“åº” â†’ Bitmap/HyperLogLog
â€¢ é«˜å¹¶å‘è¯»å†™ â†’ æ‰€æœ‰é«˜çº§ç»“æ„éƒ½æ”¯æŒ
â€¢ å¤§æ•°æ®é‡ â†’ HyperLogLog
â€¢ å¤æ‚æŸ¥è¯¢ â†’ ç»„åˆä½¿ç”¨å¤šç§ç»“æ„
```

---

## 7. ğŸ“‹ æ ¸å¿ƒè¦ç‚¹æ€»ç»“


### 7.1 å››å¤§é«˜çº§ç»“æ„æ ¸å¿ƒè¦ç‚¹


**ğŸ”¢ Bitmap - ä½å›¾å­˜å‚¨**
```
æ ¸å¿ƒå‘½ä»¤ï¼šSETBIT key offset value / GETBIT key offset / BITCOUNT key
é€‚ç”¨åœºæ™¯ï¼šç”¨æˆ·ç­¾åˆ°ã€æ´»è·ƒç»Ÿè®¡ã€çŠ¶æ€è®°å½•
æ ¸å¿ƒä¼˜åŠ¿ï¼š1bit = 1ä¸ªçŠ¶æ€ï¼Œå†…å­˜æ•ˆç‡æé«˜
è®°å¿†è¦ç‚¹ï¼šä½ç½®å¯¹åº”IDï¼Œ1è¡¨ç¤ºå­˜åœ¨/æ´»è·ƒï¼Œ0è¡¨ç¤ºä¸å­˜åœ¨/ä¸æ´»è·ƒ
```

**ğŸ“Š HyperLogLog - åŸºæ•°ç»Ÿè®¡**
```  
æ ¸å¿ƒå‘½ä»¤ï¼šPFADD key element / PFCOUNT key / PFMERGE destkey sourcekey
é€‚ç”¨åœºæ™¯ï¼šUVç»Ÿè®¡ã€å»é‡è®¡æ•°ã€å¤§æ•°æ®åŸºæ•°ä¼°ç®—
æ ¸å¿ƒä¼˜åŠ¿ï¼šå›ºå®š12KBå†…å­˜ç»Ÿè®¡2^64ä¸ªå…ƒç´ ï¼Œè¯¯å·®0.81%
è®°å¿†è¦ç‚¹ï¼šåªå…³å¿ƒæœ‰å¤šå°‘ä¸ªä¸åŒå…ƒç´ ï¼Œä¸å…³å¿ƒå…·ä½“æ˜¯å“ªäº›å…ƒç´ 
```

**ğŸ“ GEO - åœ°ç†ä½ç½®**
```
æ ¸å¿ƒå‘½ä»¤ï¼šGEOADD key longitude latitude member / GEODIST / GEORADIUS
é€‚ç”¨åœºæ™¯ï¼šLBSåº”ç”¨ã€é™„è¿‘æŸ¥æ‰¾ã€è·ç¦»è®¡ç®—
æ ¸å¿ƒä¼˜åŠ¿ï¼šå†…ç½®åœ°ç†è®¡ç®—ï¼Œæ”¯æŒå¤æ‚ç©ºé—´æŸ¥è¯¢
è®°å¿†è¦ç‚¹ï¼šç»åº¦åœ¨å‰çº¬åº¦åœ¨åï¼Œå•ä½æ”¯æŒm/km/mi/ft
```

**ğŸŒŠ Streams - æµå¼æ•°æ®**
```
æ ¸å¿ƒå‘½ä»¤ï¼šXADD stream ID field value / XREAD / XGROUP
é€‚ç”¨åœºæ™¯ï¼šæ¶ˆæ¯é˜Ÿåˆ—ã€æ—¥å¿—ç³»ç»Ÿã€äº‹ä»¶é©±åŠ¨
æ ¸å¿ƒä¼˜åŠ¿ï¼šæ¶ˆæ¯æŒä¹…åŒ–ã€æ¶ˆè´¹è€…ç»„ã€é¡ºåºä¿è¯  
è®°å¿†è¦ç‚¹ï¼šæ¶ˆæ¯IDè‡ªåŠ¨ç”Ÿæˆï¼Œæ”¯æŒå›æº¯å’Œé‡å¤æ¶ˆè´¹
```

### 7.2 åº”ç”¨åœºæ™¯è®°å¿†è¡¨


| ä¸šåŠ¡éœ€æ±‚ | **æ¨èç»“æ„** | **æ ¸å¿ƒåŸå› ** | **æ›¿ä»£æ–¹æ¡ˆå¯¹æ¯”** |
|---------|------------|-------------|---------------|
| ğŸ¯ **ç”¨æˆ·ç­¾åˆ°** | `Bitmap` | `1bit/ç”¨æˆ·ï¼Œå†…å­˜æçœ` | `String: å†…å­˜å¤§100å€` |
| ğŸ“ˆ **ç½‘ç«™UVç»Ÿè®¡** | `HyperLogLog` | `12KBç»Ÿè®¡äº¿çº§æ•°æ®` | `Set: å†…å­˜å¤§1000å€` |  
| ğŸ” **é™„è¿‘çš„äºº** | `GEO` | `å†…ç½®è·ç¦»è®¡ç®—` | `è‡ªç®—: å¤æ‚åº¦é«˜` |
| ğŸ’¬ **å®æ—¶æ¶ˆæ¯** | `Streams` | `æ¶ˆæ¯æŒä¹…åŒ–+æ¶ˆè´¹ç»„` | `List: åŠŸèƒ½å—é™` |
| ğŸ·ï¸ **ç”¨æˆ·æ ‡ç­¾** | `Set` | `å»é‡+é›†åˆè¿ç®—` | `Array: é‡å¤+æ…¢` |
| ğŸ”’ **æƒé™ç®¡ç†** | `Set` | `å¿«é€Ÿæˆå‘˜æ£€æŸ¥` | `æ•°ç»„: æŸ¥æ‰¾æ…¢` |

### 7.3 æ€§èƒ½ä¼˜åŒ–å»ºè®®


**âš¡ é€šç”¨ä¼˜åŒ–åŸåˆ™**
```
å†…å­˜ä¼˜åŒ–ï¼š
â€¢ Bitmap: ç”¨æˆ·IDè¿ç»­ç¼–æ’ï¼Œé¿å…ç¨€ç–
â€¢ HyperLogLog: åˆå¹¶ç›¸åŒç±»å‹çš„ç»Ÿè®¡  
â€¢ GEO: åŠæ—¶æ¸…ç†è¿‡æœŸä½ç½®æ•°æ®
â€¢ Streams: è®¾ç½®åˆç†çš„æ¶ˆæ¯ä¿ç•™ç­–ç•¥

æŸ¥è¯¢ä¼˜åŒ–ï¼š
â€¢ Bitmap: ä½¿ç”¨BITOPæ‰¹é‡è¿ç®—
â€¢ HyperLogLog: é¢„å…ˆåˆå¹¶å¸¸æŸ¥è¯¢çš„ç»„åˆ
â€¢ GEO: åˆç†è®¾ç½®æœç´¢åŠå¾„
â€¢ Streams: ä½¿ç”¨æ¶ˆè´¹è€…ç»„å¹¶è¡Œå¤„ç†

è¿‡æœŸç­–ç•¥ï¼š
â€¢ æ‰€æœ‰ç»“æ„éƒ½åº”è®¾ç½®åˆç†çš„TTL
â€¢ æ ¹æ®ä¸šåŠ¡éœ€æ±‚å†³å®šæ•°æ®ä¿ç•™æ—¶é—´
â€¢ å®šæœŸæ¸…ç†æ— ç”¨çš„ä¸´æ—¶key
```

**ğŸ¯ å®é™…åº”ç”¨æœ€ä½³å®è·µ**
```
è®¾è®¡åŸåˆ™ï¼š
1. æ ¹æ®æ•°æ®ç‰¹å¾é€‰æ‹©ç»“æ„ï¼ˆå¤§å°ã€ç±»å‹ã€è®¿é—®æ¨¡å¼ï¼‰
2. è€ƒè™‘æœªæ¥æ‰©å±•æ€§ï¼ˆæ•°æ®é‡å¢é•¿ã€åŠŸèƒ½éœ€æ±‚å˜åŒ–ï¼‰
3. å¹³è¡¡ç²¾åº¦ä¸æ€§èƒ½ï¼ˆHyperLogLogçš„è¯¯å·®æ˜¯å¦å¯æ¥å—ï¼‰
4. åˆç†è®¾ç½®è¿‡æœŸæ—¶é—´ï¼ˆé¿å…å†…å­˜æ³„æ¼ï¼‰

ç›‘æ§è¦ç‚¹ï¼š
1. å†…å­˜ä½¿ç”¨æƒ…å†µ
2. æŸ¥è¯¢å“åº”æ—¶é—´  
3. è¯¯å·®ç‡ç»Ÿè®¡ï¼ˆå¯¹äºHyperLogLogï¼‰
4. æ•°æ®å¢é•¿è¶‹åŠ¿
```

### 7.4 æ ¸å¿ƒè®°å¿†å£è¯€


```
é«˜çº§ç»“æ„å››å¤§å°†ï¼š
Bitmapä½å›¾çœå†…å­˜ï¼Œç­¾åˆ°ç»Ÿè®¡æ•ˆç‡é«˜
HyperLogLogä¼°åŸºæ•°ï¼ŒUVè®¡æ•°è¯¯å·®å°  
GEOåœ°ç†ç®—è·ç¦»ï¼Œé™„è¿‘æŸ¥æ‰¾å¾ˆæ–¹ä¾¿
Streamsæ¶ˆæ¯èƒ½æŒä¹…ï¼Œé˜Ÿåˆ—æ—¥å¿—å…¨éƒ½è¡Œ

é€‰æ‹©è¦é¢†è®°å¿ƒä¸­ï¼š
çŠ¶æ€å¸ƒå°”ç”¨Bitmapï¼Œå»é‡ç»Ÿè®¡HyperLogLog
ä½ç½®ç›¸å…³å¿…ç”¨GEOï¼Œæ¶ˆæ¯æµæ°´Streamså¦™
```

**ğŸ’¼ é¡¹ç›®å®æˆ˜å»ºè®®**
- **ç”¨æˆ·ç³»ç»Ÿ**ï¼šBitmapè®°å½•ç­¾åˆ° + Setå­˜å‚¨æ ‡ç­¾ + GEOè®°å½•ä½ç½®
- **æ•°æ®åˆ†æ**ï¼šHyperLogLogç»Ÿè®¡UV + Bitmapåˆ†ææ´»è·ƒåº¦  
- **ç”µå•†å¹³å°**ï¼šGEOå•†å®¶å®šä½ + Streamsè®¢å•äº‹ä»¶ + Bitmapç”¨æˆ·è¡Œä¸º
- **ç¤¾äº¤åº”ç”¨**ï¼šGEOé™„è¿‘çš„äºº + Streamså®æ—¶æ¶ˆæ¯ + Setå¥½å‹å…³ç³»

è®°ä½ï¼š**é«˜çº§æ•°æ®ç»“æ„ä¸æ˜¯ä¸‡èƒ½çš„ï¼Œè¦æ ¹æ®å…·ä½“åœºæ™¯é€‰æ‹©æœ€åˆé€‚çš„å·¥å…·ã€‚ç»„åˆä½¿ç”¨å¾€å¾€èƒ½å‘æŒ¥æ›´å¤§å¨åŠ›ï¼**