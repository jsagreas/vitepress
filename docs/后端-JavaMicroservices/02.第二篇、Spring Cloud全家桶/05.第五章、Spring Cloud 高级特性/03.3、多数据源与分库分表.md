---
title: 3、多数据源与分库分表
---
## 📚 目录

1. [什么是多数据源](#1-什么是多数据源)
2. [多数据源配置实战](#2-多数据源配置实战)
3. [读写分离原理与实现](#3-读写分离原理与实现)
4. [分库分表核心概念](#4-分库分表核心概念)
5. [ShardingSphere实战应用](#5-ShardingSphere实战应用)
6. [分布式主键策略](#6-分布式主键策略)
7. [数据同步与迁移](#7-数据同步与迁移)
8. [跨库事务处理](#8-跨库事务处理)
9. [核心要点总结](#9-核心要点总结)

---

## 1. 🎯 什么是多数据源


### 1.1 生活中的类比理解


**🏪 想象一个连锁超市的管理**
```
单店模式（单数据源）：
只有一家店 → 所有商品都在这里 → 顾客多了就排长队

连锁模式（多数据源）：
多家分店 → 商品分散存放 → 顾客就近购物，分流压力
```

**💡 这就是多数据源的本质**：把数据分散到多个数据库中，就像把商品分散到多个店铺一样，减轻单个数据库的压力。

### 1.2 为什么需要多数据源


**🔸 业务发展带来的挑战**
```
用户量增长：
100人使用 → 1个数据库够用 ✓
10万人使用 → 1个数据库开始吃力 ⚠️
100万人使用 → 1个数据库崩溃 ❌

数据量爆炸：
1万条记录 → 查询很快
100万条记录 → 查询变慢
1000万条记录 → 查询超时
```

**🎯 解决思路**
- **水平扩展**：增加更多数据库分担压力
- **垂直拆分**：不同业务用不同数据库
- **读写分离**：读操作和写操作分开处理

### 1.3 多数据源的典型场景


**📊 实际应用场景**
```
电商系统的数据分布：
┌─────────────┐  ┌─────────────┐  ┌─────────────┐
│   用户库    │  │   商品库    │  │   订单库    │
│  user_db    │  │ product_db  │  │  order_db   │
│ 用户信息    │  │ 商品信息    │  │ 订单数据    │
│ 登录记录    │  │ 库存数据    │  │ 支付记录    │
└─────────────┘  └─────────────┘  └─────────────┘
```

**🔄 读写分离场景**
```
主从架构：
写操作 → 主数据库（Master）
读操作 → 从数据库（Slave）

比例关系：
读操作：写操作 = 7:3 或 8:2（大部分系统）
```

---

## 2. ⚙️ 多数据源配置实战


### 2.1 Spring Boot多数据源基础配置


**🔧 配置文件设置**
```yaml
# application.yml
spring:
  datasource:
    # 主数据库（用户相关）
    primary:
      driver-class-name: com.mysql.cj.jdbc.Driver
      url: jdbc:mysql://localhost:3306/user_db
      username: root
      password: 123456
      
    # 从数据库（商品相关）
    secondary:
      driver-class-name: com.mysql.cj.jdbc.Driver
      url: jdbc:mysql://localhost:3306/product_db
      username: root
      password: 123456
```

**💡 为什么这样配置？**
- `primary`：主要的数据源，通常是核心业务数据
- `secondary`：次要数据源，可以是其他业务模块的数据
- 分开配置让系统知道哪些数据去哪个库查

### 2.2 数据源配置类编写


```java
@Configuration
public class DataSourceConfig {
    
    // 主数据源配置
    @Bean(name = "primaryDataSource")
    @ConfigurationProperties("spring.datasource.primary")
    @Primary  // 标记为主数据源
    public DataSource primaryDataSource() {
        return DataSourceBuilder.create().build();
    }
    
    // 从数据源配置  
    @Bean(name = "secondaryDataSource")
    @ConfigurationProperties("spring.datasource.secondary")
    public DataSource secondaryDataSource() {
        return DataSourceBuilder.create().build();
    }
}
```

**🔸 关键注解说明**
- `@Primary`：告诉Spring当有多个相同类型Bean时优先使用这个
- `@ConfigurationProperties`：自动从配置文件读取对应的配置项

### 2.3 不同数据源的使用方式


**方式一：通过不同的Repository**
```java
// 用户相关的Repository使用主数据源
@Repository
public interface UserRepository extends JpaRepository<User, Long> {
    // 自动使用primary数据源
}

// 商品相关的Repository使用从数据源
@Repository
@Qualifier("secondaryDataSource")
public interface ProductRepository extends JpaRepository<Product, Long> {
    // 使用secondary数据源
}
```

**方式二：动态切换数据源**
```java
@Service
public class OrderService {
    
    @DataSource("primary")  // 自定义注解
    public void saveOrder(Order order) {
        // 这个方法使用primary数据源
    }
    
    @DataSource("secondary")
    public Product getProduct(Long id) {
        // 这个方法使用secondary数据源
    }
}
```

---

## 3. 🔄 读写分离原理与实现


### 3.1 读写分离的核心思想


**📖 生活中的例子**
```
图书馆管理系统：
写操作（还书、借书登记）→ 管理员专用系统（主库）
读操作（查询图书信息）→ 公共查询终端（从库）

好处：
• 管理员工作不被打断
• 查询速度更快
• 系统更稳定
```

**💡 技术实现原理**
```
数据流向：
应用程序 → 读写分离中间件 → 判断操作类型
                ↓
        写操作 → 主数据库
        读操作 → 从数据库（可能有多个）
```

### 3.2 读写分离配置实现


**🔧 动态数据源切换**
```java
@Component
public class DynamicDataSource extends AbstractRoutingDataSource {
    
    @Override
    protected Object determineCurrentLookupKey() {
        // 根据当前操作类型返回对应的数据源key
        return DataSourceContextHolder.getDataSourceType();
    }
}

// 数据源上下文管理
public class DataSourceContextHolder {
    private static final ThreadLocal<String> CONTEXT = new ThreadLocal<>();
    
    public static void setMaster() {
        CONTEXT.set("master");
    }
    
    public static void setSlave() {
        CONTEXT.set("slave");
    }
    
    public static String getDataSourceType() {
        return CONTEXT.get();
    }
}
```

**🎯 自动切换实现**
```java
@Aspect
@Component
public class DataSourceAspect {
    
    @Before("@annotation(readOnly)")
    public void setReadDataSource(ReadOnly readOnly) {
        DataSourceContextHolder.setSlave();
    }
    
    @Before("execution(* *.save*(..)) || execution(* *.update*(..))")
    public void setWriteDataSource() {
        DataSourceContextHolder.setMaster();
    }
}
```

### 3.3 读写分离的注意事项


**⚠️ 数据一致性问题**
```
场景：用户刚注册完立即登录
问题：注册数据写入主库，登录查询从库，可能查不到

解决方案：
1. 强制读主库：重要操作后的查询走主库
2. 延迟读取：等待数据同步完成再查询  
3. 缓存策略：重要数据同时写入缓存
```

**📊 性能监控要点**
```
监控指标：
• 主从延迟时间：通常控制在1秒内
• 读写比例：正常应该是7:3或8:2
• 数据库连接数：避免连接池耗尽
```

---

## 4. 🔀 分库分表核心概念


### 4.1 什么是分库分表


**🏢 办公楼类比理解**
```
单体架构（单库单表）：
所有员工都在一间办公室 → 太拥挤，效率低

分库（垂直拆分）：
不同部门有自己的办公楼
• 技术部 → A栋
• 销售部 → B栋  
• 财务部 → C栋

分表（水平拆分）：
同一部门内部按组分办公室
• 技术部1组 → A101
• 技术部2组 → A102
• 技术部3组 → A103
```

### 4.2 分库分表的策略选择


**🎯 垂直拆分（按业务模块）**
```
原来：一个大系统
┌─────────────────────┐
│    monolith_db      │
│ users, products,    │
│ orders, payments    │
└─────────────────────┘

拆分后：多个专业数据库
┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐
│ user_db │ │prod_db  │ │order_db │ │pay_db   │
│ 用户相关│ │ 商品相关│ │ 订单相关│ │ 支付相关│
└─────────┘ └─────────┘ └─────────┘ └─────────┘
```

**🔄 水平拆分（按数据量）**
```
用户表数据太多：1000万用户

按用户ID取模分表：
user_0: ID % 4 = 0 的用户 (250万)
user_1: ID % 4 = 1 的用户 (250万)  
user_2: ID % 4 = 2 的用户 (250万)
user_3: ID % 4 = 3 的用户 (250万)
```

### 4.3 分片策略详解


| 策略类型 | **适用场景** | **优点** | **缺点** |
|---------|-------------|---------|---------|
| 🔢 **取模分片** | `用户ID、订单ID等数值型` | `分布均匀，实现简单` | `扩容困难，需要重新分布数据` |
| 📅 **时间分片** | `日志数据、历史订单` | `自然增长，便于归档` | `热点数据集中，分布不均` |
| 🌍 **地域分片** | `用户地理位置相关` | `就近访问，延迟低` | `数据倾斜，维护复杂` |
| 📊 **范围分片** | `连续查询较多的场景` | `范围查询效率高` | `数据分布可能不均` |

---

## 5. ⚡ ShardingSphere实战应用


### 5.1 什么是ShardingSphere


**🔧 ShardingSphere简介**
> ShardingSphere是Apache的分库分表中间件，就像一个智能的"数据交通指挥官"，帮你把数据请求分发到正确的数据库和表中。

**💡 核心功能**
```
数据分片：自动将数据分散到多个库表
读写分离：自动识别读写操作并路由
分布式事务：保证跨库操作的一致性
数据治理：提供监控、配置管理等功能
```

### 5.2 ShardingSphere-JDBC配置


**📦 依赖引入**
```xml
<dependency>
    <groupId>org.apache.shardingsphere</groupId>
    <artifactId>shardingsphere-jdbc-core-spring-boot-starter</artifactId>
    <version>5.2.1</version>
</dependency>
```

**⚙️ 分库分表配置**
```yaml
spring:
  shardingsphere:
    # 数据源配置
    datasource:
      names: ds0,ds1
      ds0:
        type: com.zaxxer.hikari.HikariDataSource
        driver-class-name: com.mysql.cj.jdbc.Driver
        jdbc-url: jdbc:mysql://localhost:3306/order_db_0
        username: root
        password: 123456
      ds1:
        type: com.zaxxer.hikari.HikariDataSource  
        driver-class-name: com.mysql.cj.jdbc.Driver
        jdbc-url: jdbc:mysql://localhost:3306/order_db_1
        username: root
        password: 123456
    
    # 分片规则配置
    rules:
      sharding:
        tables:
          t_order:  # 要分片的表
            actual-data-nodes: ds$->{0..1}.t_order_$->{0..3}
            # 分库策略
            database-strategy:
              standard:
                sharding-column: user_id
                sharding-algorithm-name: database-inline
            # 分表策略  
            table-strategy:
              standard:
                sharding-column: order_id
                sharding-algorithm-name: table-inline
        
        # 分片算法配置
        sharding-algorithms:
          database-inline:
            type: INLINE
            props:
              algorithm-expression: ds$->{user_id % 2}
          table-inline:
            type: INLINE  
            props:
              algorithm-expression: t_order_$->{order_id % 4}
```

**🎯 配置解读**
```
actual-data-nodes: ds$->{0..1}.t_order_$->{0..3}
含义：
• ds0库：t_order_0, t_order_1, t_order_2, t_order_3
• ds1库：t_order_0, t_order_1, t_order_2, t_order_3
• 总共8张表分布在2个库中

分片逻辑：
• user_id % 2 → 决定使用哪个库
• order_id % 4 → 决定使用库中的哪张表
```

### 5.3 代码中的使用


```java
@Service
public class OrderService {
    
    @Autowired
    private OrderRepository orderRepository;
    
    // 保存订单（自动分库分表）
    public void saveOrder(Order order) {
        // ShardingSphere会自动根据user_id和order_id
        // 计算出应该存储在哪个库的哪张表
        orderRepository.save(order);
    }
    
    // 查询订单（自动路由）
    public Order findOrder(Long orderId, Long userId) {
        // 根据分片键自动路由到正确的库表
        return orderRepository.findByOrderIdAndUserId(orderId, userId);
    }
}
```

---

## 6. 🔑 分布式主键策略


### 6.1 为什么需要分布式主键


**🤔 单库自增ID的问题**
```
单库情况：
用户表：1, 2, 3, 4, 5... ✓ (连续递增)

分库情况：
库1用户表：1, 2, 3...
库2用户表：1, 2, 3...  ❌ (ID冲突!)

问题：每个库都从1开始自增，会产生重复ID
```

### 6.2 主流分布式ID生成策略


**🎯 UUID策略**
```java
// 优点：简单、唯一性强、无需协调
// 缺点：太长(32位)、无序、性能一般
String id = UUID.randomUUID().toString().replace("-", "");
// 示例：a1b2c3d4e5f6g7h8i9j0k1l2m3n4o5p6
```

**⚡ 雪花算法（Snowflake）**
```
ID结构（64位）：
┌─┬───────────────────┬──────┬──────┬──────────────┐
│0│    时间戳(41位)    │机器ID│序列号│  保留位(1位) │
└─┴───────────────────┴──────┴──────┴──────────────┘
 1        41           5     5        12

特点：
• 全局唯一
• 趋势递增  
• 高性能
• 包含时间信息
```

**🔧 ShardingSphere雪花算法配置**
```yaml
spring:
  shardingsphere:
    rules:
      sharding:
        key-generators:
          snowflake:
            type: SNOWFLAKE
            props:
              worker-id: 1
        tables:
          t_order:
            key-generate-strategy:
              column: order_id
              key-generator-name: snowflake
```

### 6.3 分布式ID选择指南


| 策略 | **性能** | **存储空间** | **有序性** | **适用场景** |
|-----|---------|-------------|-----------|-------------|
| 🔤 **UUID** | `中等` | `大(32字符)` | `无序` | `对性能要求不高的场景` |
| ❄️ **雪花算法** | `高` | `小(8字节)` | `趋势递增` | `高并发、对性能要求高` |
| 🎯 **号段模式** | `高` | `小` | `局部递增` | `数据库友好，范围查询多` |

---

## 7. 🔄 数据同步与迁移


### 7.1 数据同步的重要性


**💡 为什么需要数据同步**
```
业务场景：
• 系统升级：从单库迁移到分库分表
• 容灾备份：主从数据库保持同步
• 数据分析：业务库同步到分析库
• 缓存更新：数据库变化时更新缓存
```

### 7.2 常见同步方案


**📊 同步方案对比**
```
方案选择：
实时性要求高 → Canal + Kafka
数据量大批量 → DataX
简单场景 → 定时任务
复杂ETL → Apache NiFi
```

**🔧 Canal实时同步原理**
```
MySQL binlog → Canal Server → Kafka → 业务系统

工作流程：
1. Canal监听MySQL的binlog
2. 解析binlog获取数据变化  
3. 发送到消息队列
4. 下游系统消费处理
```

### 7.3 数据迁移策略


**📋 迁移步骤规划**
```
第一阶段：双写阶段
新数据 → 同时写入老库和新库
老数据 → 继续从老库读取

第二阶段：数据同步阶段  
历史数据 → 批量同步到新库
数据校验 → 确保数据一致性

第三阶段：切流阶段
读操作 → 逐步切换到新库
写操作 → 完全切换到新库

第四阶段：清理阶段
老库下线 → 清理旧的数据和代码
```

**⚠️ 迁移风险控制**
- **灰度切换**：先切换部分流量测试
- **回滚预案**：出问题能快速回到老库
- **数据校验**：定期对比新老库数据
- **监控告警**：实时监控切换过程

---

## 8. 🔄 跨库事务处理


### 8.1 分布式事务的挑战


**🤔 跨库操作的问题**
```
单库事务（简单）：
转账操作在同一个库 → 要么全成功，要么全失败 ✓

跨库事务（复杂）：
A用户在库1，B用户在库2
A向B转账 → 涉及两个库的操作
如果库1成功，库2失败 → 数据不一致 ❌
```

**💡 ACID在分布式环境的挑战**
- **原子性**：多个库的操作如何保证同时成功或失败？
- **一致性**：跨库的数据状态如何保持一致？
- **隔离性**：分布式环境下的并发控制？
- **持久性**：网络故障时如何确保数据不丢失？

### 8.2 分布式事务解决方案


**🔧 两阶段提交（2PC）**
```
第一阶段：准备阶段
事务协调器 → 问所有数据库："能否提交事务？"
各数据库 → 回答："可以" 或 "不可以"

第二阶段：提交阶段  
如果都回答可以 → 协调器发送"提交"指令
如果有回答不可以 → 协调器发送"回滚"指令
```

**⚡ Seata分布式事务**
```java
@Service
public class OrderService {
    
    @GlobalTransactional  // Seata全局事务注解
    public void createOrder(OrderInfo orderInfo) {
        // 1. 创建订单（可能在订单库）
        orderRepository.save(orderInfo.getOrder());
        
        // 2. 扣减库存（可能在商品库）
        productService.reduceStock(orderInfo.getProductId(), orderInfo.getQuantity());
        
        // 3. 扣减账户余额（可能在用户库）
        accountService.deductBalance(orderInfo.getUserId(), orderInfo.getAmount());
        
        // 任何一步失败，整个事务都会回滚
    }
}
```

### 8.3 事务一致性策略选择


**📊 方案对比与选择**

| 方案 | **一致性** | **性能** | **复杂度** | **适用场景** |
|-----|-----------|---------|-----------|-------------|
| 🔒 **强一致性(2PC)** | `强` | `低` | `高` | `金融支付等严格场景` |
| ⚡ **最终一致性(Saga)** | `最终` | `高` | `中` | `大部分业务场景` |
| 🚫 **无事务(补偿)** | `弱` | `最高` | `低` | `对一致性要求不高` |

**💡 选择建议**
```
金融支付 → 选择强一致性方案
电商下单 → 选择最终一致性方案  
日志记录 → 可以无事务处理
```

---

## 9. 📋 核心要点总结


### 9.1 必须掌握的核心概念


```
🔸 多数据源：将数据分散到多个数据库，减轻单库压力
🔸 读写分离：读操作走从库，写操作走主库，提升性能
🔸 分库分表：垂直拆分按业务，水平拆分按数据量
🔸 分布式主键：解决分库后的ID唯一性问题
🔸 数据同步：保证多个数据库之间的数据一致性
🔸 跨库事务：处理分布式环境下的数据一致性
```

### 9.2 技术选型指导


**🎯 场景驱动的选择**
```
数据量不大(<100万) → 单库足够，无需分库分表
读多写少 → 优先考虑读写分离
数据量爆炸(>1000万) → 必须考虑分库分表  
强一致性要求 → 谨慎使用分布式方案
```

**⚖️ 技术方案权衡**
```
简单 vs 复杂：
单库 < 读写分离 < 分库分表 < 分布式事务

性能 vs 一致性：
性能要求高 → 可以牺牲一致性
一致性要求高 → 可能要牺牲性能

成本 vs 收益：
增加的复杂度 是否 值得 获得的性能提升？
```

### 9.3 实际应用建议


**🚀 渐进式架构演进**
```
第一步：单库单表
↓ 用户量增长
第二步：读写分离
↓ 数据量爆炸
第三步：分库分表
↓ 业务复杂化
第四步：微服务化
```

**⚠️ 常见陷阱避免**
```
过度设计：
• 不要一开始就分库分表
• 根据实际需求逐步演进

数据倾斜：
• 选择合适的分片键
• 监控数据分布情况

事务复杂化：
• 尽量避免跨库事务
• 设计时考虑事务边界
```

**核心记忆口诀**：
- 单库不够用时想多库，读写分离性能好
- 数据太多要分表，合理分片是关键
- 跨库事务需谨慎，最终一致性为先
- 架构演进要渐进，过度设计是大忌