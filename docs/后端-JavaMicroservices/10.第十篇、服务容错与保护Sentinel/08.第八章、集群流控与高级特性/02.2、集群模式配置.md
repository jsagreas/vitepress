---
title: 2、集群模式配置
---
## 📚 目录

1. [集群流控基础概念](#1-集群流控基础概念)
2. [集群模式详解](#2-集群模式详解)
3. [集群规则配置](#3-集群规则配置)
4. [Token管理机制](#4-Token管理机制)
5. [故障转移与高可用](#5-故障转移与高可用)
6. [核心要点总结](#6-核心要点总结)

---

## 1. 🌐 集群流控基础概念


### 1.1 什么是集群流控


**🎯 生活场景类比**
```
想象一个大型商场的限流：

单机限流（普通做法）：
🏬 商场A：限制100人
🏬 商场B：限制100人  
🏬 商场C：限制100人
总共：300人同时进入

集群限流（更合理）：
🏢 整个商场品牌：总共限制150人
   ├─ A入口：50人
   ├─ B入口：60人
   └─ C入口：40人
总共：严格控制150人

核心区别：
- 单机：每个实例各管各的
- 集群：所有实例统一协调管理
```

**📋 专业定义**
```
集群流控：
将多个微服务实例作为一个整体来限流，
统一分配流量配额，避免资源浪费和保护不足。

为什么需要集群流控？
❌ 单机问题：
   - 每个实例独立限流
   - 配额可能浪费或不足
   - 无法应对流量倾斜

✅ 集群优势：
   - 全局统一限流
   - 配额动态分配
   - 精确流量控制
```

### 1.2 集群流控的核心价值


**💡 解决的核心问题**
```
问题场景：秒杀系统

假设：后端数据库只能承受1000QPS

单机限流方案：
服务实例数：10个
每个实例限流：100QPS
理论总流量：1000QPS ✓

实际问题：
┌──────────────────────────────┐
│ 流量分布不均匀：             │
│ 实例1：50QPS  (配额浪费)     │
│ 实例2：150QPS (超过限制❌)    │
│ 实例3：80QPS  (配额浪费)     │
│ ...                          │
│ 总计：可能超过1000QPS!       │
└──────────────────────────────┘

集群流控方案：
┌──────────────────────────────┐
│ 全局统一管理：               │
│ Token Server：1000个令牌/秒  │
│ 各实例按需获取令牌           │
│ 精确控制不超过1000QPS ✓      │
└──────────────────────────────┘
```

**🔥 应用场景**
```
⭐⭐⭐ 必须使用场景：
- 秒杀活动：严格控制总流量
- API网关：统一限流所有请求
- 数据库保护：精确控制DB压力
- 第三方调用：避免超过配额

⭐⭐ 推荐使用场景：
- 微服务集群：多实例协同限流
- 热点资源：防止资源被打爆
- 成本控制：精确控制资源使用

⭐ 可选场景：
- 流量相对均匀的服务
- 对精确度要求不高的场景
```

### 1.3 集群流控工作原理


**🔧 基本工作流程**
```
客户端请求流程：

步骤1：请求到达服务实例
   ↓
步骤2：检查是否集群流控规则
   ↓
步骤3：向Token Server申请令牌
   ↓
步骤4：Token Server判断是否有配额
   ├─ 有配额 → 返回令牌 → 通过请求
   └─ 无配额 → 拒绝 → 返回限流

流程图示：
客户端                服务实例            Token Server
  |                      |                    |
  |---[1]请求----------->|                    |
  |                      |---[2]申请令牌----->|
  |                      |                    |[3]检查配额
  |                      |<--[4]返回结果------|
  |                      |                    |
  |<--[5]响应------------|                    |
```

**🎯 核心组件**
```
集群流控三大角色：

🔹 Token Client（令牌客户端）
- 运行在普通服务实例上
- 负责向Token Server申请令牌
- 处理具体的业务请求

🔹 Token Server（令牌服务器）
- 负责管理全局令牌池
- 统一分配流量配额
- 可以是独立服务或嵌入模式

🔹 规则中心
- 存储集群流控规则
- 同步规则到各个节点
- 支持动态更新
```

---

## 2. 🏗️ 集群模式详解


### 2.1 嵌入模式（Embedded Mode）


**📖 什么是嵌入模式**
```
定义：
Token Server和普通服务实例运行在一起，
某个服务实例既是Token Server，也是Token Client。

通俗理解：
就像班级选班长，某个同学既是班长（管理者），
也是普通学生（参与者）。

架构示意：
┌─────────────────────────────────────┐
│            服务集群                  │
│                                     │
│  ┌─────────────┐  ┌──────────────┐ │
│  │  实例1      │  │  实例2       │ │
│  │ ┌─────────┐ │  │ ┌──────────┐ │ │
│  │ │ Token   │ │  │ │ Token    │ │ │
│  │ │ Server  │ │  │ │ Client   │ │ │
│  │ └─────────┘ │  │ └──────────┘ │ │
│  │ ┌─────────┐ │  │ ┌──────────┐ │ │
│  │ │ Token   │ │  │ │ Business │ │ │
│  │ │ Client  │ │  │ │ Service  │ │ │
│  │ └─────────┘ │  │ └──────────┘ │ │
│  └─────────────┘  └──────────────┘ │
│        ↑                            │
│   其他实例都连接这个Token Server     │
└─────────────────────────────────────┘
```

**⚙️ 嵌入模式配置**
```java
// 指定某个实例为Token Server
ClusterServerConfigManager.loadGlobalTransportConfig(
    new ServerTransportConfig()
        .setIdleSeconds(600)        // 空闲超时时间
        .setPort(18730)             // Token Server端口
);

// 设置为Token Server
ClusterServerConfigManager.setMode(ClusterStateManager.CLUSTER_SERVER);

// 其他实例配置为Token Client
ClusterClientConfigManager.applyNewConfig(
    new ClusterClientConfig()
        .setRequestTimeout(20)      // 请求超时20ms
        .setServerHost("token-server-ip")
        .setServerPort(18730)
);

// 注册命名空间集合（哪些应用使用这个Token Server）
Set<String> namespaceSet = new HashSet<>();
namespaceSet.add("order-service");
namespaceSet.add("product-service");
ClusterServerConfigManager.loadServerNamespaceSet(namespaceSet);
```

**✅ 嵌入模式优势**
```
优点：
🔸 部署简单：不需要额外的独立服务
🔸 资源节约：复用已有服务实例
🔸 快速启动：配置后立即生效
🔸 适合小规模：实例数量不多时很方便

缺点：
🔸 可用性：Token Server实例挂了影响全局
🔸 性能影响：Token Server会消耗额外资源
🔸 职责混乱：一个实例承担多重角色
```

**💡 使用建议**
```
适用场景：
⭐⭐⭐ 开发测试环境
⭐⭐⭐ 小规模集群（<10个实例）
⭐⭐ 对可用性要求不高的场景

不推荐场景：
❌ 生产环境大规模集群
❌ 高可用要求的核心服务
❌ 实例频繁扩缩容的场景
```

### 2.2 独立模式（Standalone Mode）


**📖 什么是独立模式**
```
定义：
Token Server作为独立的服务部署，
专门负责令牌管理，不处理业务请求。

通俗理解：
就像专门的保安室，只负责管理出入证，
不参与公司的具体业务。

架构示意：
┌─────────────────────────────────────┐
│                                     │
│     ┌─────────────────┐             │
│     │  Token Server   │             │
│     │  (独立部署)     │◄───┐        │
│     └─────────────────┘    │        │
│              ▲             │        │
│      令牌申请│             │        │
│              │             │        │
│  ┌───────────┴──────┬──────┴─────┐ │
│  │                  │            │ │
│  │  ┌────────────┐  │ ┌────────┐ │ │
│  │  │ 服务实例1  │  │ │ 实例2  │ │ │
│  │  │ Token      │  │ │ Token  │ │ │
│  │  │ Client     │  │ │ Client │ │ │
│  │  └────────────┘  │ └────────┘ │ │
│  └──────────────────┴────────────┘ │
└─────────────────────────────────────┘
```

**⚙️ 独立模式部署**
```java
// Token Server独立部署配置
public class TokenServerApplication {
    
    public static void main(String[] args) {
        // 1. 加载Token Server配置
        ClusterServerConfigManager.loadGlobalTransportConfig(
            new ServerTransportConfig()
                .setIdleSeconds(600)
                .setPort(18730)
        );
        
        // 2. 加载命名空间配置
        Set<String> namespaceSet = new HashSet<>();
        namespaceSet.add("order-service");
        namespaceSet.add("product-service");
        namespaceSet.add("user-service");
        ClusterServerConfigManager.loadServerNamespaceSet(namespaceSet);
        
        // 3. 启动Token Server
        ClusterTokenServer tokenServer = new ClusterTokenServer();
        tokenServer.start();
        
        System.out.println("Token Server started on port 18730");
    }
}

// 业务服务配置（Token Client）
ClusterClientConfigManager.applyNewConfig(
    new ClusterClientConfig()
        .setRequestTimeout(20)
        .setServerHost("token-server.internal")  // Token Server地址
        .setServerPort(18730)
);
```

**✅ 独立模式优势**
```
优点：
🔸 高可用：Token Server可以集群部署
🔸 性能好：专门的服务，性能有保证
🔸 职责清晰：专注于令牌管理
🔸 易扩展：独立扩缩容

缺点：
🔸 部署复杂：需要额外的部署资源
🔸 运维成本：多一个服务需要维护
🔸 网络延迟：多一次网络调用
```

**💡 使用建议**
```
适用场景：
⭐⭐⭐ 生产环境
⭐⭐⭐ 大规模集群（>10个实例）
⭐⭐⭐ 高可用要求的核心服务
⭐⭐⭐ 多个应用共享集群流控

推荐配置：
- Token Server部署2-3个实例（高可用）
- 使用负载均衡分发请求
- 配置健康检查和自动故障转移
```

### 2.3 模式对比与选择


**📊 模式对比表**

| 对比维度 | **嵌入模式** | **独立模式** |
|---------|------------|-------------|
| 🏗️ **部署复杂度** | `简单，无需额外部署` | `复杂，需要独立部署` |
| 💰 **资源成本** | `低，复用现有实例` | `中，需要额外资源` |
| 🚀 **性能影响** | `Token Server会影响业务实例` | `互不影响，性能好` |
| 🔧 **可用性** | `单点故障风险高` | `可集群部署，高可用` |
| 📈 **扩展性** | `受限于业务实例` | `独立扩展，灵活` |
| 👥 **适用规模** | `<10个实例` | `任意规模` |
| 🎯 **适用场景** | `开发测试、小规模` | `生产环境、大规模` |

**🎯 选择建议**
```
选择嵌入模式的条件：
✅ 开发或测试环境
✅ 实例数量少（<10个）
✅ 对可用性要求不高
✅ 希望快速部署验证

选择独立模式的条件：
✅ 生产环境
✅ 实例数量多（>10个）
✅ 高可用要求
✅ 多个应用需要共享
✅ 有足够的运维资源
```

---

## 3. 📋 集群规则配置


### 3.1 集群规则基本结构


**📖 规则组成**
```
集群流控规则 = 普通流控规则 + 集群配置

普通流控规则：
- 资源名称
- 限流阈值
- 限流模式
- 流控效果

集群特有配置：
- 是否集群模式
- 阈值类型（全局/单机）
- fallback到本地
- 流控应用名
```

**🔧 规则配置示例**
```java
// 创建集群流控规则
FlowRule rule = new FlowRule();

// 1. 基础配置（和普通规则一样）
rule.setResource("createOrder");     // 资源名称
rule.setCount(100);                  // 限流阈值
rule.setGrade(RuleConstant.FLOW_GRADE_QPS);  // QPS模式

// 2. 集群模式配置（重点）
rule.setClusterMode(true);          // 开启集群模式

// 3. 集群配置详情
ClusterFlowConfig clusterConfig = new ClusterFlowConfig();

// 阈值类型：FLOW_THRESHOLD_GLOBAL（全局）
clusterConfig.setThresholdType(
    ClusterRuleConstant.FLOW_THRESHOLD_GLOBAL
);

// 允许fallback到本地限流
clusterConfig.setFallbackToLocalWhenFail(true);

// 设置集群配置
rule.setClusterConfig(clusterConfig);

// 4. 加载规则
FlowRuleManager.loadRules(Collections.singletonList(rule));
```

### 3.2 阈值类型详解


**🎯 全局阈值（GLOBAL）**
```
含义：
整个集群共享一个阈值总额

示例说明：
全局阈值 = 1000 QPS
实例数量 = 5个

工作方式：
┌─────────────────────────────┐
│ Token Server：1000个令牌/秒  │
├─────────────────────────────┤
│ 实例1：按需获取（如200个）   │
│ 实例2：按需获取（如300个）   │
│ 实例3：按需获取（如150个）   │
│ 实例4：按需获取（如200个）   │
│ 实例5：按需获取（如150个）   │
├─────────────────────────────┤
│ 总计：严格 = 1000 QPS       │
└─────────────────────────────┘

配置示例：
clusterConfig.setThresholdType(
    ClusterRuleConstant.FLOW_THRESHOLD_GLOBAL
);
clusterConfig.setCount(1000);  // 全局总计1000
```

**🎯 单机均摊阈值（AVG_LOCAL）**
```
含义：
总阈值平均分配给每个实例

示例说明：
总阈值 = 1000 QPS
实例数量 = 5个
每个实例 = 1000 / 5 = 200 QPS

工作方式：
┌─────────────────────────────┐
│ Token Server：动态计算        │
├─────────────────────────────┤
│ 实例1：最多200 QPS           │
│ 实例2：最多200 QPS           │
│ 实例3：最多200 QPS           │
│ 实例4：最多200 QPS           │
│ 实例5：最多200 QPS           │
├─────────────────────────────┤
│ 特点：动态适配实例数量        │
└─────────────────────────────┘

配置示例：
clusterConfig.setThresholdType(
    ClusterRuleConstant.FLOW_THRESHOLD_AVG_LOCAL
);
clusterConfig.setCount(1000);  // 总计1000，自动均摊
```

**💡 阈值类型选择**
```
选择全局阈值场景：
⭐⭐⭐ 严格控制总流量
⭐⭐⭐ 保护后端服务（如数据库）
⭐⭐⭐ 第三方接口调用限制
示例：数据库最多承受1000QPS，必须严格控制

选择均摊阈值场景：
⭐⭐⭐ 实例数量动态变化
⭐⭐⭐ 流量相对均匀分布
⭐⭐ 公平分配资源
示例：微服务自动扩缩容，需要动态分配配额
```

### 3.3 Fallback机制


**🔒 什么是Fallback**
```
定义：
当Token Server不可用时，自动降级到本地限流模式

通俗理解：
就像停电时，自动切换到备用发电机，
虽然功能有限，但至少能保证基本运转。

工作流程：
正常情况：
实例 → Token Server → 获取令牌 → 通过/拒绝

Token Server故障：
实例 → Token Server ❌ 
     → Fallback到本地规则
     → 本地限流 → 通过/拒绝
```

**⚙️ Fallback配置**
```java
ClusterFlowConfig config = new ClusterFlowConfig();

// 1. 开启Fallback（推荐开启）
config.setFallbackToLocalWhenFail(true);

// Fallback行为：
// - Token Server不可用时
// - 自动使用本地限流规则
// - 阈值为集群阈值/实例数

// 2. 关闭Fallback（不推荐）
config.setFallbackToLocalWhenFail(false);

// 不开启的风险：
// - Token Server故障 → 所有请求直接通过
// - 失去流控保护 → 可能打爆后端服务
```

**🎯 Fallback策略**
```
Fallback限流阈值计算：

全局阈值模式：
本地阈值 = 全局阈值 / 实例数量
示例：1000 / 5 = 200 QPS

均摊阈值模式：
本地阈值 = 配置的均摊值
示例：已经是200 QPS，保持不变

实际场景示例：
┌─────────────────────────────────┐
│ 正常情况（Token Server正常）     │
│ 全局：1000 QPS                  │
│ 精确控制，动态分配               │
└─────────────────────────────────┘
              ↓ Token Server故障
┌─────────────────────────────────┐
│ Fallback情况                    │
│ 每个实例：200 QPS（1000/5）      │
│ 各自限流，可能不够精确           │
│ 但至少有保护                    │
└─────────────────────────────────┘
```

### 3.4 完整配置示例


**🔧 实战配置**
```java
public class ClusterFlowRuleConfig {
    
    public static void configureClusterRule() {
        FlowRule rule = new FlowRule();
        
        // 基础配置
        rule.setResource("payment-api");
        rule.setGrade(RuleConstant.FLOW_GRADE_QPS);
        rule.setCount(500);  // 全局500 QPS
        
        // 集群配置
        rule.setClusterMode(true);
        
        ClusterFlowConfig clusterConfig = new ClusterFlowConfig();
        
        // 全局阈值模式
        clusterConfig.setThresholdType(
            ClusterRuleConstant.FLOW_THRESHOLD_GLOBAL
        );
        
        // 开启Fallback
        clusterConfig.setFallbackToLocalWhenFail(true);
        
        // 采样统计窗口（可选）
        clusterConfig.setSampleCount(10);
        clusterConfig.setWindowIntervalMs(1000);
        
        rule.setClusterConfig(clusterConfig);
        
        // 加载规则
        FlowRuleManager.loadRules(
            Collections.singletonList(rule)
        );
    }
}
```

---

## 4. 🎫 Token管理机制


### 4.1 Token Server工作原理


**🔧 Token分配机制**
```
Token Server = 令牌工厂

核心工作：
1. 维护令牌池
2. 响应令牌申请
3. 统计令牌使用
4. 定期刷新令牌

工作流程：
┌─────────────────────────────────┐
│        Token Server             │
│                                 │
│  ┌──────────────────────────┐  │
│  │   令牌池                  │  │
│  │   当前可用：800/1000      │  │
│  │   刷新周期：1秒           │  │
│  └──────────────────────────┘  │
│           ↓        ↑            │
│     分配令牌      定期刷新       │
└─────────────────────────────────┘
          ↓              ↑
    各个服务实例请求    统计上报
```

**⚙️ 令牌刷新策略**
```java
// Token Server内部实现（简化示意）
public class TokenBucket {
    private long capacity = 1000;      // 令牌总容量
    private long tokens = 1000;        // 当前令牌数
    private long lastRefillTime;       // 上次刷新时间
    
    // 定时刷新令牌
    public void refill() {
        long now = System.currentTimeMillis();
        long elapsed = now - lastRefillTime;
        
        // 每秒刷新一次
        if (elapsed >= 1000) {
            tokens = capacity;  // 重置为满额
            lastRefillTime = now;
        }
    }
    
    // 申请令牌
    public boolean tryAcquire(int count) {
        refill();  // 先刷新
        
        if (tokens >= count) {
            tokens -= count;
            return true;  // 申请成功
        }
        return false;  // 令牌不足
    }
}
```

**💡 令牌分配策略**
```
策略1：先到先得
- 谁先申请，谁先获得
- 简单公平，无额外计算
- 可能导致某些实例饥饿

策略2：按需分配
- 根据实例负载动态分配
- 公平性更好
- 实现复杂度高

策略3：预分配
- 提前给每个实例分配配额
- 减少网络请求
- 可能导致浪费

Sentinel默认：先到先得
原因：简单高效，满足大部分场景
```

### 4.2 Token Client工作机制


**🔧 客户端申请流程**
```
Token Client申请令牌的完整流程：

步骤1：接收业务请求
   ↓
步骤2：检查是否需要集群流控
   ├─ 不需要 → 本地限流
   └─ 需要 → 继续
   ↓
步骤3：构建令牌申请请求
   ↓
步骤4：发送到Token Server
   ↓
步骤5：等待响应（超时时间20ms）
   ├─ 响应成功 → 获得令牌
   ├─ 响应拒绝 → 限流
   └─ 超时/失败 → Fallback
   ↓
步骤6：执行业务逻辑或返回限流

时序图：
Client          Token Server
  |                  |
  |--申请令牌------->|
  |                  |[检查配额]
  |<-返回结果--------|
  |                  |
[处理业务]
```

**⚙️ 客户端配置**
```java
ClusterClientConfig config = new ClusterClientConfig();

// 1. Token Server地址
config.setServerHost("token-server.internal");
config.setServerPort(18730);

// 2. 请求超时配置（重要）
config.setRequestTimeout(20);  // 20ms超时

// 超时策略：
// - 20ms内未响应 → 触发Fallback
// - 太短：频繁Fallback
// - 太长：影响响应时间

// 3. 应用命名空间
config.setNamespace("order-service");

// 加载配置
ClusterClientConfigManager.applyNewConfig(config);
```

**💡 超时处理策略**
```
超时时间选择：

⏱️ 10-20ms（推荐）：
✅ 快速失败，用户体验好
✅ 及时Fallback，保护后端
⚠️ 对网络要求高

⏱️ 50-100ms：
✅ 网络抖动容忍度高
⚠️ 响应时间变长
⚠️ Fallback触发慢

⏱️ >100ms（不推荐）：
❌ 响应太慢
❌ 影响用户体验
❌ 失去限流保护的意义

建议：
生产环境：20ms
开发环境：50ms
测试环境：可以更长，方便调试
```

### 4.3 Token通信协议


**📡 通信方式**
```
Sentinel使用自定义的二进制协议，
基于Netty实现高性能通信。

协议特点：
✅ 二进制格式：比JSON/XML更高效
✅ 异步非阻塞：高并发性能好
✅ 长连接复用：减少连接开销
✅ 心跳保活：及时发现故障

请求格式（简化）：
┌────────────────────────┐
│ 消息头（Header）        │
│ - 消息类型              │
│ - 消息ID                │
│ - 命名空间              │
├────────────────────────┤
│ 消息体（Body）          │
│ - 资源名称              │
│ - 申请数量              │
│ - 优先级等              │
└────────────────────────┘

响应格式：
┌────────────────────────┐
│ 消息头                 │
│ - 响应状态码            │
│ - 消息ID（对应请求）    │
├────────────────────────┤
│ 消息体                 │
│ - 是否通过              │
│ - 剩余配额              │
│ - 等待时间等            │
└────────────────────────┘
```

**🔄 连接管理**
```
连接池策略：

初始连接数：1个
最大连接数：5个（可配置）
连接复用：长连接

连接状态：
┌──────────────────────────┐
│  Token Client            │
│                          │
│  连接池：                 │
│  ├─ 连接1：活跃           │
│  ├─ 连接2：空闲           │
│  └─ 连接3：空闲           │
│                          │
│  心跳：每5秒一次          │
│  重连：故障自动重连        │
└──────────────────────────┘
          ↕️
   Token Server
```

---

## 5. 🛡️ 故障转移与高可用


### 5.1 故障场景分析


**🚨 常见故障场景**
```
场景1：Token Server宕机
现象：所有实例无法获取令牌
影响：全局流控失效
应对：Fallback到本地限流

场景2：网络故障
现象：Token Server可用，但网络不通
影响：申请超时
应对：超时Fallback

场景3：Token Server过载
现象：响应变慢
影响：超时增多
应对：扩容Token Server

场景4：部分实例故障
现象：某些Client连接失败
影响：部分实例Fallback
应对：自动重连

故障影响评估：
┌─────────────────────────────┐
│ Token Server完全故障：       │
│ ├─ 开启Fallback：降级保护    │
│ └─ 未开启：流控失效 ❌       │
├─────────────────────────────┤
│ 网络抖动：                  │
│ ├─ 短暂超时：自动Fallback    │
│ └─ 持续超时：持续本地限流    │
├─────────────────────────────┤
│ 单个Client故障：             │
│ └─ 不影响其他实例           │
└─────────────────────────────┘
```

### 5.2 高可用架构设计


**🏗️ 多Token Server部署**
```
方案1：主从架构

┌──────────────────────────────┐
│    Load Balancer（可选）      │
└──────────┬───────────────────┘
           ↓
    ┌──────┴──────┐
    ↓             ↓
┌─────────┐  ┌─────────┐
│ Token   │  │ Token   │
│ Server1 │  │ Server2 │
│ (主)    │  │ (备)    │
└─────────┘  └─────────┘

工作方式：
- 正常：所有请求到主Server
- 主故障：切换到备Server
- 主恢复：再次切换回主

优点：简单可靠
缺点：备用资源闲置
```

**方案2：集群部署（推荐）**
```
架构示意：
┌──────────────────────────────┐
│        负载均衡器              │
└──────┬────────┬────────┬─────┘
       ↓        ↓        ↓
  ┌────────┬────────┬────────┐
  │ Token  │ Token  │ Token  │
  │Server1 │Server2 │Server3 │
  └────────┴────────┴────────┘
       ↑        ↑        ↑
   共享配置存储（如Redis/Nacos）

工作方式：
- 多个Token Server同时工作
- 负载均衡分发请求
- 共享规则配置
- 自动故障摘除

优点：
✅ 高可用：单点故障不影响
✅ 高性能：负载分担
✅ 易扩展：水平扩容

实现要点：
- 令牌池同步（Redis）
- 配置中心统一管理
- 健康检查机制
```

**⚙️ 高可用配置**
```java
// 配置多个Token Server地址
ClusterClientConfig config = new ClusterClientConfig();

// 方式1：负载均衡地址
config.setServerHost("token-cluster.internal");  
config.setServerPort(18730);

// 方式2：多地址配置（客户端轮询）
List<ServerAddress> servers = Arrays.asList(
    new ServerAddress("token-server1", 18730),
    new ServerAddress("token-server2", 18730),
    new ServerAddress("token-server3", 18730)
);
config.setServerAddressList(servers);

// 故障转移配置
config.setRequestTimeout(20);  // 快速失败
config.setConnectTimeout(3000);  // 连接超时3s
config.setMaxRetry(2);  // 最多重试2次

ClusterClientConfigManager.applyNewConfig(config);
```

### 5.3 Fallback机制深入


**🔄 Fallback触发条件**
```
触发场景：

1️⃣ Token Server不可达
   - 连接超时
   - 连接拒绝
   - 网络故障

2️⃣ 请求超时
   - 超过requestTimeout
   - 网络延迟高

3️⃣ Token Server返回错误
   - 服务内部错误
   - 规则配置错误

4️⃣ 其他异常
   - 序列化失败
   - 协议错误等

Fallback流程：
┌──────────────────────────┐
│ 1. 检测到Token Server故障 │
│ 2. 检查是否开启Fallback   │
│ 3. 计算本地限流阈值       │
│ 4. 使用本地规则限流       │
│ 5. 定期尝试恢复          │
└──────────────────────────┘
```

**⚙️ Fallback配置策略**
```java
// 1. 基础Fallback配置
ClusterFlowConfig config = new ClusterFlowConfig();
config.setFallbackToLocalWhenFail(true);

// 2. Fallback阈值计算
// 全局阈值1000，5个实例
// Fallback阈值 = 1000 / 5 = 200

// 3. 自定义Fallback策略（高级）
config.setStrategy(ClusterRuleConstant.FLOW_CLUSTER_STRATEGY_NORMAL);

// 策略选项：
// NORMAL：平均分配
// EAGER：更激进的限流
// GENTLE：更宽松的限流
```

**💡 Fallback最佳实践**
```
生产环境配置建议：

✅ 必须开启Fallback
原因：Token Server故障时保底保护

✅ 合理设置超时时间
建议：20-50ms
原因：快速失败，及时Fallback

✅ 监控Fallback频率
告警：Fallback率 > 10%
说明：Token Server可能有问题

✅ 定期演练故障切换
测试：定期关闭Token Server
验证：Fallback是否正常工作

配置示例：
┌─────────────────────────────┐
│ 生产环境配置：               │
│ ├─ Fallback：开启           │
│ ├─ 超时：20ms               │
│ ├─ 重试：1次                │
│ ├─ 告警：Fallback率>10%     │
│ └─ 演练：每月一次            │
└─────────────────────────────┘
```

### 5.4 监控与告警


**📊 关键监控指标**
```
Token Server监控：

性能指标：
┌──────────────────────────────┐
│ QPS：每秒处理请求数           │
│ 响应时间：P50/P95/P99        │
│ 令牌分配成功率               │
│ 连接数：当前活跃连接          │
└──────────────────────────────┘

健康指标：
┌──────────────────────────────┐
│ CPU使用率                    │
│ 内存使用率                   │
│ 网络IO                       │
│ 心跳状态                     │
└──────────────────────────────┘

Token Client监控：

业务指标：
┌──────────────────────────────┐
│ 令牌申请总数                 │
│ 申请成功率                   │
│ Fallback触发次数             │
│ 限流拒绝次数                 │
└──────────────────────────────┘
```

**🚨 告警规则设置**
```
关键告警：

🔴 P0级别（立即处理）：
- Token Server全部宕机
- Fallback率 > 50%
- 限流成功率 < 50%

🟡 P1级别（尽快处理）：
- Token Server单点故障
- Fallback率 > 10%
- 响应时间 > 100ms

🟢 P2级别（关注）：
- CPU使用率 > 80%
- 内存使用率 > 80%
- Fallback率 > 5%

告警配置示例：
if (fallbackRate > 0.5) {
    alert.send("Token Server集群故障", "P0");
} else if (fallbackRate > 0.1) {
    alert.send("Token Server部分故障", "P1");
}
```

---

## 6. 📋 核心要点总结


### 6.1 必须掌握的核心概念


**🔸 集群流控基础**
```
✅ 定义：多个实例作为整体统一限流
✅ 价值：精确控制全局流量，避免单机限流的不足
✅ 核心：Token Server统一管理令牌分配
✅ 适用：秒杀、API网关、数据库保护等场景
```

**🔸 两种部署模式**
```
嵌入模式：
- 某个实例同时作为Token Server
- 适合：开发测试、小规模集群
- 优点：部署简单
- 缺点：可用性差

独立模式：
- Token Server独立部署
- 适合：生产环境、大规模集群
- 优点：高可用、性能好
- 缺点：部署复杂
```

**🔸 关键配置项**
```
阈值类型：
- 全局阈值：严格控制总流量
- 均摊阈值：动态分配每个实例

Fallback机制：
- 必须开启
- Token Server故障时保底保护
- 降级到本地限流

超时配置：
- 推荐20ms
- 快速失败，及时Fallback
```

### 6.2 最佳实践建议


**🎯 部署建议**
```
开发环境：
✅ 使用嵌入模式
✅ 快速验证功能
✅ 无需复杂配置

测试环境：
✅ 使用独立模式
✅ 模拟生产架构
✅ 演练故障场景

生产环境：
✅ 独立部署Token Server
✅ 至少2-3个实例
✅ 配置负载均衡
✅ 开启监控告警
```

**🔧 配置建议**
```
基础配置：
┌─────────────────────────────┐
│ ✅ 开启集群模式              │
│ ✅ 配置全局/均摊阈值         │
│ ✅ 开启Fallback             │
│ ✅ 设置合理超时（20ms）      │
└─────────────────────────────┘

高级配置：
┌─────────────────────────────┐
│ ✅ 配置多Token Server        │
│ ✅ 启用负载均衡              │
│ ✅ 配置监控指标              │
│ ✅ 设置告警规则              │
└─────────────────────────────┘
```

**💡 运维建议**
```
日常运维：
- 监控Token Server健康状态
- 关注Fallback触发频率
- 定期检查限流效果
- 及时调整阈值配置

故障演练：
- 定期关闭Token Server测试
- 验证Fallback是否正常
- 检查告警是否及时
- 确认业务影响可控

性能优化：
- 根据QPS调整Token Server数量
- 优化超时时间设置
- 合理设置连接池大小
- 监控并优化网络延迟
```

### 6.3 常见问题解答


**❓ Q1：集群流控会增加多少延迟？**
```
A：正常情况下增加10-20ms

详细说明：
- Token申请：5-10ms（网络）
- Token Server处理：1-5ms
- 总计：10-20ms

优化方法：
- Token Server就近部署
- 使用高性能网络
- 合理设置超时时间
```

**❓ Q2：Token Server挂了怎么办？**
```
A：开启Fallback，降级到本地限流

降级效果：
- 每个实例独立限流
- 阈值 = 全局阈值/实例数
- 仍有保护，但不够精确

恢复方式：
- Token Server恢复后自动切回
- 无需手动干预
```

**❓ Q3：如何选择阈值类型？**
```
A：根据业务场景选择

选择全局阈值：
✅ 严格控制总流量
✅ 保护后端服务
✅ 第三方接口限制
示例：数据库承受1000QPS

选择均摊阈值：
✅ 实例数量动态变化
✅ 自动扩缩容场景
✅ 公平分配资源
示例：微服务自动扩容
```

**❓ Q4：生产环境如何部署？**
```
A：推荐独立模式 + 高可用架构

部署方案：
1. 独立部署Token Server（2-3个实例）
2. 配置负载均衡
3. 开启Fallback
4. 配置监控告警
5. 定期故障演练

这样可以确保：
✅ 高可用性
✅ 高性能
✅ 易扩展
✅ 可监控
```

### 6.4 学习路径建议


**📖 学习步骤**
```
第1步：理解集群流控原理
- 为什么需要集群流控
- Token Server的作用
- 令牌分配机制

第2步：掌握两种部署模式
- 嵌入模式使用场景
- 独立模式部署方法
- 如何选择合适的模式

第3步：配置实践
- 规则配置方法
- 阈值类型选择
- Fallback机制配置

第4步：高可用设计
- 多Token Server部署
- 故障转移机制
- 监控告警配置

第5步：生产实践
- 性能调优
- 故障演练
- 问题排查
```

**🎯 核心记忆**
```
集群流控三要素：
1. Token Server：统一管理令牌
2. 集群规则：全局阈值配置
3. Fallback：故障保底机制

部署选择两原则：
- 开发测试：嵌入模式
- 生产环境：独立模式

高可用三保障：
1. 多实例部署
2. 负载均衡
3. 监控告警

一句话总结：
集群流控通过Token Server统一管理流量配额，
配合Fallback机制，在保证精确限流的同时确保高可用。
```

---

**🎓 学习建议**

这份笔记涵盖了Sentinel集群流控的核心知识点，建议按以下方式学习：

1️⃣ **先理解概念**：为什么需要集群流控，解决什么问题
2️⃣ **再学配置**：如何配置集群规则，如何部署Token Server
3️⃣ **重点实践**：动手搭建环境，验证各种场景
4️⃣ **深入原理**：理解Token分配机制，故障转移原理
5️⃣ **生产应用**：掌握高可用部署，监控告警配置

记住：集群流控是Sentinel的高级特性，理解了单机限流再学习集群流控会更容易。实际使用时，根据业务场景选择合适的模式和配置，不要盲目追求复杂。