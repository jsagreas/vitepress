---
title: 3、生产环境实践
---
## 📚 目录

1. [环境隔离策略](#1-环境隔离策略)
2. [配置管理规范](#2-配置管理规范)
3. [版本发布流程](#3-版本发布流程)
4. [灰度发布策略](#4-灰度发布策略)
5. [回滚应急方案](#5-回滚应急方案)
6. [运维监控体系](#6-运维监控体系)
7. [问题排查流程](#7-问题排查流程)
8. [日志归档策略](#8-日志归档策略)
9. [核心要点总结](#9-核心要点总结)

---

## 1. 🏗️ 环境隔离策略


### 1.1 什么是环境隔离


**通俗理解**：就像我们生活中把"试验田"和"正式农田"分开一样，开发环境、测试环境和生产环境必须分开，避免互相干扰。

```
生活场景类比：
🧪 试验田(开发环境) → 可以随便试验，出错没关系
🔬 小麦田(测试环境) → 模拟真实种植，验证效果
🌾 正式农田(生产环境) → 真正服务用户，不能出错
```

### 1.2 环境分类与职责


| 环境类型 | 作用说明 | 数据来源 | 使用人员 | 稳定性要求 |
|---------|---------|---------|---------|-----------|
| **开发环境(DEV)** | `开发人员写代码、调试` | `假数据/少量真实数据` | `开发人员` | `可以不稳定` |
| **测试环境(TEST)** | `测试人员验证功能` | `模拟真实数据` | `测试+开发人员` | `基本稳定` |
| **预发环境(PRE)** | `上线前最后验证` | `生产数据副本` | `测试+运维人员` | `高度稳定` |
| **生产环境(PROD)** | `真实用户使用` | `真实业务数据` | `运维人员` | `必须稳定` |

### 1.3 XXL-JOB环境隔离实践


**🔸 调度中心隔离**

```
物理隔离方案：
┌─────────────────┐
│  开发调度中心    │ → 独立服务器 dev-xxljob.com:8080
│  (DEV)          │ → 独立数据库 xxl_job_dev
└─────────────────┘

┌─────────────────┐
│  测试调度中心    │ → 独立服务器 test-xxljob.com:8080
│  (TEST)         │ → 独立数据库 xxl_job_test
└─────────────────┘

┌─────────────────┐
│  生产调度中心    │ → 独立服务器 prod-xxljob.com:8080
│  (PROD)         │ → 独立数据库 xxl_job_prod
└─────────────────┘
```

**配置示例**：

```yaml
# 开发环境配置 application-dev.yml
xxl:
  job:
    admin:
      addresses: http://dev-xxljob.com:8080/xxl-job-admin
    executor:
      appname: user-service-dev
      port: 9999

# 生产环境配置 application-prod.yml
xxl:
  job:
    admin:
      addresses: http://prod-xxljob.com:8080/xxl-job-admin
    executor:
      appname: user-service-prod
      port: 9999
```

### 1.4 数据隔离要点


**🔸 核心原则**
```
原则1️⃣：开发/测试环境可以共用非敏感数据
原则2️⃣：生产环境数据严格保密，不得外泄
原则3️⃣：测试数据定期清理，避免污染
原则4️⃣：预发环境使用脱敏后的生产数据
```

> 💡 **新手提示**：环境隔离最容易犯的错误是"配置混用"，比如开发环境误连生产数据库，造成数据污染。务必在配置文件中明确标注环境名称！

---

## 2. 📋 配置管理规范


### 2.1 为什么需要配置管理


**问题场景**：
- 😰 配置散落各处，修改一个配置要改10个地方
- 😱 不知道哪个配置是正确的，测试环境和生产环境配置混乱
- 😭 配置改错了，系统崩溃，还不知道改了什么

**配置管理的价值**：就像整理房间，把东西分类放好，需要时能快速找到。

### 2.2 配置分层管理


```
配置分层金字塔：

        ┌──────────────┐
        │  敏感配置层   │ ← 数据库密码、密钥等
        │ (加密存储)   │
        └──────────────┘
             ↓
        ┌──────────────┐
        │  环境配置层   │ ← 各环境不同的配置
        │ (动态切换)   │
        └──────────────┘
             ↓
        ┌──────────────┐
        │  通用配置层   │ ← 所有环境共用配置
        │ (固定不变)   │
        └──────────────┘
```

**🔸 XXL-JOB配置分层示例**

```properties
# 通用配置 application.yml (所有环境共用)
xxl.job.executor.logpath: /data/applogs/xxl-job
xxl.job.executor.logretentiondays: 30

# 环境配置 application-{env}.yml (各环境不同)
# DEV环境
xxl.job.admin.addresses: http://dev-xxljob:8080/xxl-job-admin
xxl.job.executor.appname: ${spring.application.name}-dev

# PROD环境  
xxl.job.admin.addresses: http://prod-xxljob:8080/xxl-job-admin
xxl.job.executor.appname: ${spring.application.name}-prod

# 敏感配置 (Nacos/Apollo等配置中心)
spring.datasource.password: ${ENCRYPT:abc123}  # 加密后的密码
```

### 2.3 配置中心集成


**推荐使用配置中心**：Nacos、Apollo、Spring Cloud Config

**集成配置中心的好处**：
- ✅ 配置集中管理，一处修改多处生效
- ✅ 配置版本控制，可以回滚到历史版本
- ✅ 配置实时刷新，不需要重启服务
- ✅ 权限控制，敏感配置只有管理员能看

**Nacos配置示例**：

```yaml
# bootstrap.yml - 优先加载配置中心
spring:
  application:
    name: user-service
  cloud:
    nacos:
      config:
        server-addr: nacos.company.com:8848
        namespace: ${spring.profiles.active}  # 根据环境隔离
        group: XXL_JOB_GROUP
        file-extension: yml
```

### 2.4 配置规范checklist


```
配置管理规范检查表：

□ 敏感配置必须加密存储
□ 配置文件按环境分离
□ 配置项命名规范统一
□ 配置修改需要审批记录
□ 定期检查无用配置并清理
□ 生产配置变更必须备份
□ 配置中心设置访问权限
□ 重要配置设置变更通知
```

> ⚠️ **注意**：千万不要把密码、密钥等敏感信息直接写在代码或配置文件中！一定要用配置中心的加密功能或环境变量。

---

## 3. 🚀 版本发布流程


### 3.1 发布流程全景图


```
完整发布流程：

开发阶段          测试阶段          预发阶段          生产阶段
   ↓                ↓                ↓                ↓
┌─────┐         ┌─────┐         ┌─────┐         ┌─────┐
│代码 │ -----→  │功能 │ -----→  │回归 │ -----→  │正式│
│开发 │         │测试 │         │测试 │         │发布│
└─────┘         └─────┘         └─────┘         └─────┘
   ↓                ↓                ↓                ↓
代码评审        测试报告        发布审批        发布验证
```

### 3.2 发布前准备工作


**🔸 发布检查清单**

```
发布前必查项：

1️⃣ 代码检查
   □ 代码已合并到主分支
   □ 单元测试全部通过
   □ 代码评审已完成

2️⃣ 配置检查  
   □ 生产环境配置已确认
   □ 数据库脚本已备份
   □ 定时任务配置已检查

3️⃣ 依赖检查
   □ 第三方服务可用性确认
   □ 数据库连接正常
   □ 中间件版本兼容

4️⃣ 回滚准备
   □ 上一版本包已备份
   □ 回滚脚本已准备
   □ 应急联系人已通知
```

### 3.3 XXL-JOB任务发布步骤


**标准发布步骤**：

```
步骤1️⃣：停止旧版本任务
- 登录调度中心
- 找到需要更新的任务
- 点击"暂停"按钮停止调度

步骤2️⃣：发布新版本代码
- 通过Jenkins/GitLab CI构建新版本
- 部署到执行器服务器
- 确认服务启动成功

步骤3️⃣：验证执行器注册
- 检查调度中心"执行器管理"
- 确认新版本执行器已注册
- 查看在线机器列表

步骤4️⃣：启动任务调度
- 手动触发一次任务测试
- 确认执行成功
- 开启定时调度

步骤5️⃣：监控观察
- 观察任务执行日志
- 检查业务指标
- 关注告警信息
```

**操作示例**：

```bash
# Jenkins发布脚本示例
#!/bin/bash

APP_NAME="user-service"
VERSION="1.2.0"

echo "===== 开始发布 ${APP_NAME} ${VERSION} ====="

# 1. 备份旧版本
cp /app/${APP_NAME}.jar /app/backup/${APP_NAME}-$(date +%Y%m%d-%H%M%S).jar

# 2. 停止旧服务
sh /app/stop.sh

# 3. 部署新版本
cp /jenkins/workspace/${APP_NAME}.jar /app/${APP_NAME}.jar

# 4. 启动新服务
sh /app/start.sh

# 5. 健康检查
sleep 10
curl http://localhost:8080/actuator/health

echo "===== 发布完成 ====="
```

### 3.4 发布时间窗口规划


**最佳发布时间**：

| 时间段 | 适合发布 | 风险评估 | 建议 |
|-------|---------|---------|------|
| **工作日凌晨2-4点** | `⭐⭐⭐⭐⭐` | `低` | `大版本发布首选` |
| **工作日晚上22-24点** | `⭐⭐⭐⭐` | `中低` | `小版本发布可选` |
| **周五晚上** | `⭐⭐` | `中高` | `避免发布，周末无人值守` |
| **节假日前一天** | `⭐` | `高` | `禁止发布` |
| **业务高峰期** | `❌` | `极高` | `严禁发布` |

> 💡 **经验分享**：选择凌晨发布的原因是用户量少，即使出问题影响面也小。但要确保有人值守，随时准备回滚。

---

## 4. 🎯 灰度发布策略


### 4.1 什么是灰度发布


**通俗理解**：灰度发布就像"小范围试吃"，先让一小部分用户使用新版本，没问题再全量发布。

```
传统发布 vs 灰度发布：

传统发布（高风险）：
所有用户 → 新版本  (一旦出错，全部受影响)

灰度发布（低风险）：
10%用户 → 新版本  (观察无问题)
    ↓
50%用户 → 新版本  (继续观察)
    ↓
100%用户 → 新版本 (全量发布)
```

### 4.2 XXL-JOB灰度发布方案


**🔸 方案一：按执行器分组灰度**

```
灰度步骤：

阶段1️⃣：灰度组(10%流量)
┌──────────────┐
│ 执行器组A     │ → 2台机器运行新版本
│ (新版本)     │
└──────────────┘

阶段2️⃣：观察期(30分钟)
- 监控任务执行成功率
- 检查业务指标
- 收集错误日志

阶段3️⃣：扩大灰度(50%流量)  
┌──────────────┐
│ 执行器组A+B   │ → 5台机器运行新版本
│ (新版本)     │
└──────────────┘

阶段4️⃣：全量发布
┌──────────────┐
│ 所有执行器    │ → 10台机器全部新版本
└──────────────┘
```

**调度中心配置**：

```
1. 创建两个执行器：
   - user-service-gray  (灰度组，2台机器)
   - user-service-prod  (稳定组，8台机器)

2. 任务配置：
   - 路由策略选择"故障转移"
   - 优先调度灰度组
   
3. 灰度流程：
   - 新版本先部署到gray组
   - 观察30分钟无异常
   - 逐步部署到prod组
```

**🔸 方案二：按任务灰度**

```
灰度任务分组：

高风险任务(核心业务)：
- 订单结算任务  → 灰度1天后全量
- 用户积分任务  → 灰度2小时后全量

低风险任务(辅助功能)：
- 日志清理任务  → 直接全量发布
- 数据备份任务  → 灰度1小时后全量
```

### 4.3 灰度监控指标


**关键监控指标**：

| 监控项 | 正常标准 | 异常阈值 | 处理动作 |
|-------|---------|---------|---------|
| **任务成功率** | `>99%` | `<95%` | `立即回滚` |
| **平均执行时长** | `±10%波动` | `>30%增长` | `暂停灰度` |
| **内存使用率** | `<70%` | `>85%` | `检查内存泄漏` |
| **错误日志量** | `<10条/小时` | `>100条/小时` | `分析错误原因` |

### 4.4 灰度决策流程


```
灰度决策树：

开始灰度
   ↓
运行30分钟
   ↓
检查监控指标 ───→ 异常？ ───→ 是 ───→ 立即回滚
   ↓                             ↓
  正常                          记录问题
   ↓                             ↓
扩大灰度50%                    修复后重新灰度
   ↓
再运行1小时
   ↓
检查监控指标 ───→ 异常？ ───→ 是 ───→ 立即回滚
   ↓                             
  正常                          
   ↓                             
全量发布
```

> 💡 **新手建议**：首次灰度发布建议灰度比例设置为10%，观察时间不少于1小时。有经验后可以适当缩短观察时间。

---

## 5. 🔄 回滚应急方案


### 5.1 为什么需要回滚方案


**真实事故案例**：
```
❌ 某公司发布新版本后发现bug：
- 20:00 发布新版本
- 20:30 发现订单无法结算
- 21:00 紧急回滚，但找不到旧版本包
- 21:30 重新打包旧版本
- 22:00 才完成回滚，损失惨重

✅ 有回滚方案的情况：
- 20:00 发布新版本
- 20:05 发现异常
- 20:08 一键回滚到旧版本
- 20:10 业务恢复正常
```

### 5.2 回滚方案分类


**🔸 代码回滚**

```bash
# 保留最近3个版本
/app/
├── user-service.jar              # 当前版本
├── backup/
│   ├── user-service-v1.2.0.jar  # 上一版本
│   ├── user-service-v1.1.0.jar  # 上上版本
│   └── user-service-v1.0.0.jar  # 上上上版本

# 快速回滚脚本
#!/bin/bash
ROLLBACK_VERSION=$1

echo "开始回滚到版本: ${ROLLBACK_VERSION}"

# 1. 停止当前服务
sh /app/stop.sh

# 2. 替换为历史版本
cp /app/backup/user-service-${ROLLBACK_VERSION}.jar /app/user-service.jar

# 3. 启动服务
sh /app/start.sh

echo "回滚完成"
```

**🔸 数据库回滚**

```sql
-- 数据库变更必须提供回滚SQL

-- 正向SQL (升级)
ALTER TABLE xxl_job_info ADD COLUMN new_field VARCHAR(100);

-- 回滚SQL (降级)  
ALTER TABLE xxl_job_info DROP COLUMN new_field;
```

**🔸 配置回滚**

```
配置中心回滚步骤：

1️⃣ Nacos配置历史版本：
   - 进入配置管理
   - 点击"历史版本"
   - 选择需要回滚的版本
   - 点击"回滚"按钮

2️⃣ Apollo配置回滚：
   - 发布历史页面
   - 选择稳定版本
   - 一键回滚
```

### 5.3 回滚决策标准


**何时需要回滚**：

```
立即回滚场景：

🔴 严重级别(P0)：
- 核心业务功能不可用
- 数据丢失或数据错误
- 系统频繁崩溃重启
- 严重性能问题(响应超时)

🟡 重要级别(P1)：  
- 非核心功能异常
- 部分用户受影响
- 性能轻微下降
→ 可以尝试热修复，修复失败再回滚

🟢 一般级别(P2)：
- 界面显示问题
- 日志错误但不影响功能
→ 记录问题，下个版本修复
```

### 5.4 回滚操作手册


**完整回滚步骤**：

```
回滚操作清单：

□ 步骤1：确认回滚决策
  - 评估问题严重程度
  - 确定回滚版本号
  - 通知相关人员

□ 步骤2：停止问题版本
  - 调度中心暂停所有任务
  - 停止执行器服务

□ 步骤3：执行代码回滚
  - 运行回滚脚本
  - 替换为历史版本
  - 启动执行器服务

□ 步骤4：验证回滚结果
  - 检查服务健康状态
  - 手动触发任务测试
  - 确认业务功能正常

□ 步骤5：数据修复(如需要)
  - 执行数据回滚SQL
  - 修复异常数据
  - 验证数据一致性

□ 步骤6：恢复调度
  - 启动定时任务
  - 监控任务执行
  - 记录回滚原因
```

> ⚠️ **重要提示**：回滚前一定要备份当前版本，万一回滚后发现问题还能回滚回来！

---

## 6. 📊 运维监控体系


### 6.1 监控体系架构


```
XXL-JOB监控体系全景：

         用户层
           ↓
    ┌─────────────┐
    │ 监控大盘    │ ← Grafana可视化
    └─────────────┘
           ↓
    ┌─────────────┐
    │ 告警中心    │ ← 钉钉/邮件/短信
    └─────────────┘
           ↓
┌──────────────────────────┐
│      监控数据收集层        │
├──────────────────────────┤
│ Prometheus  │  ELK日志   │
│  指标监控    │   分析     │
└──────────────────────────┘
           ↓
┌──────────────────────────┐
│    XXL-JOB调度系统        │
├──────────────────────────┤
│ 调度中心  │   执行器集群  │
└──────────────────────────┘
```

### 6.2 核心监控指标


**🔸 调度中心监控**

| 监控指标 | 说明 | 正常范围 | 告警阈值 |
|---------|------|---------|---------|
| **调度成功率** | `成功次数/总次数` | `>99%` | `<95%` |
| **调度耗时** | `平均调度时长` | `<100ms` | `>500ms` |
| **线程池使用率** | `活跃线程/总线程` | `<80%` | `>90%` |
| **数据库连接数** | `当前连接数` | `<50` | `>80` |

**🔸 执行器监控**

| 监控指标 | 说明 | 正常范围 | 告警阈值 |
|---------|------|---------|---------|
| **任务执行成功率** | `成功任务/总任务` | `>99%` | `<95%` |
| **任务执行时长** | `平均执行时间` | `业务相关` | `超预期30%` |
| **JVM内存使用** | `堆内存使用率` | `<70%` | `>85%` |
| **CPU使用率** | `进程CPU占用` | `<60%` | `>80%` |

### 6.3 Prometheus监控配置


**暴露监控指标**：

```java
// 引入依赖
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-actuator</artifactId>
</dependency>
<dependency>
    <groupId>io.micrometer</groupId>
    <artifactId>micrometer-registry-prometheus</artifactId>
</dependency>

// 配置文件
management:
  endpoints:
    web:
      exposure:
        include: health,info,prometheus
  metrics:
    tags:
      application: ${spring.application.name}
      env: ${spring.profiles.active}
```

**Prometheus采集配置**：

```yaml
# prometheus.yml
scrape_configs:
  - job_name: 'xxl-job-executor'
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets: 
        - 'executor1:8080'
        - 'executor2:8080'
        - 'executor3:8080'
```

### 6.4 告警规则配置


**Prometheus告警规则**：

```yaml
# alert-rules.yml
groups:
  - name: xxl-job-alerts
    interval: 30s
    rules:
      # 任务失败率告警
      - alert: JobFailureRateHigh
        expr: |
          (sum(rate(xxl_job_fail_total[5m])) / 
           sum(rate(xxl_job_total[5m]))) > 0.05
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "XXL-JOB任务失败率过高"
          description: "5分钟内失败率超过5%"

      # 执行时长告警
      - alert: JobExecutionSlow
        expr: xxl_job_duration_seconds > 300
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "任务执行时长过长"
          description: "任务 {{ $labels.job }} 执行超过5分钟"
```

**告警通知配置**：

```yaml
# alertmanager.yml
receivers:
  - name: 'dingtalk'
    webhook_configs:
      - url: 'http://dingtalk-webhook/alert'
        send_resolved: true
  
  - name: 'email'
    email_configs:
      - to: 'ops@company.com'
        from: 'alert@company.com'
        smarthost: 'smtp.company.com:25'

route:
  group_by: ['alertname']
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 4h
  receiver: 'dingtalk'
  routes:
    - match:
        severity: critical
      receiver: 'email'
```

> 💡 **监控建议**：监控指标不是越多越好，要抓住核心指标。建议从"成功率、耗时、资源占用"这三个维度入手。

---

## 7. 🔍 问题排查流程


### 7.1 问题分类与定位


**常见问题分类**：

```
问题类型树状图：

                问题根源
                   ↓
        ┌──────────┴──────────┐
     调度问题              执行问题
        ↓                      ↓
  ┌─────┴─────┐          ┌─────┴─────┐
 配置   网络        代码   资源
 错误   故障        bug   不足
```

### 7.2 问题排查步骤


**🔸 标准排查流程**

```
问题排查五步法：

步骤1️⃣：现象确认
- 问题是什么？(任务失败/超时/未执行)
- 影响范围？(单个任务/所有任务)
- 发生时间？(什么时候开始的)

步骤2️⃣：日志分析
- 查看调度中心日志
- 查看执行器日志  
- 查看业务日志

步骤3️⃣：监控检查
- CPU/内存是否异常
- 网络是否通畅
- 数据库是否正常

步骤4️⃣：原因定位
- 是配置问题？
- 是代码问题？
- 是环境问题？

步骤5️⃣：问题解决
- 临时方案(快速恢复)
- 根本方案(彻底解决)
- 预防措施(避免复发)
```

### 7.3 典型问题排查案例


**案例1：任务一直不执行**

```
问题现象：
- 任务状态显示"运行中"
- 但执行日志一直没有记录

排查步骤：

1️⃣ 检查执行器注册状态
调度中心 → 执行器管理 → 查看在线机器

发现：执行器未注册

2️⃣ 检查执行器日志
tail -f /app/logs/xxl-job-executor.log

发现：连接调度中心超时

3️⃣ 检查网络连通性
ping admin-host
telnet admin-host 8080

发现：网络不通

解决方案：
- 检查防火墙规则
- 开放调度中心端口
- 重启执行器服务
```

**案例2：任务执行超时**

```
问题现象：
- 任务执行时间从1分钟变成10分钟
- 没有报错，但就是很慢

排查步骤：

1️⃣ 查看资源使用情况
top -p <pid>
jstat -gcutil <pid> 1000

发现：Full GC频繁，内存不足

2️⃣ 分析内存快照
jmap -dump:format=b,file=heap.bin <pid>
jhat heap.bin  # 或用MAT分析

发现：某个Map对象占用2GB内存

3️⃣ 定位代码问题
查看任务代码，发现数据没有分批处理

解决方案：
- 改为分批处理数据
- 增加JVM内存配置
- 优化SQL查询
```

**案例3：任务偶尔失败**

```
问题现象：
- 大部分时间正常
- 偶尔失败，重试后成功

排查步骤：

1️⃣ 统计失败规律
- 什么时间失败？(每天凌晨2点)
- 什么条件失败？(数据量大时)

2️⃣ 查看失败日志
grep "ERROR" /app/logs/job-*.log

发现：数据库连接超时

3️⃣ 检查数据库
show processlist;  # 查看数据库连接

发现：凌晨2点有备份任务，占用大量连接

解决方案：
- 调整任务执行时间，避开备份窗口
- 增加数据库连接池大小
- 优化SQL，减少执行时间
```

### 7.4 问题排查工具箱


**常用命令**：

```bash
# 查看Java进程
jps -l

# 查看线程堆栈
jstack <pid> > thread.dump

# 查看内存使用
jmap -heap <pid>

# 实时监控GC
jstat -gcutil <pid> 1000

# 查看网络连接
netstat -antp | grep <port>

# 查看日志
tail -f /app/logs/xxl-job.log
grep "ERROR" /app/logs/*.log | tail -100
```

> 💡 **排查技巧**：遇到问题不要慌，按照"现象→日志→监控→定位→解决"的顺序一步步来，80%的问题都能快速定位。

---

## 8. 📁 日志归档策略


### 8.1 为什么需要日志归档


**日志管理的痛点**：

```
没有归档的后果：

❌ 磁盘被日志占满，服务无法启动
❌ 日志文件太大，查询速度慢
❌ 历史日志找不到，无法追溯问题
❌ 敏感信息泄露，安全风险高
```

### 8.2 日志分类管理


**🔸 日志分类标准**

| 日志类型 | 保留时长 | 存储位置 | 归档方式 |
|---------|---------|---------|---------|
| **调度日志** | `30天` | `数据库+文件` | `自动归档到OSS` |
| **执行日志** | `7天` | `本地文件` | `定期清理` |
| **错误日志** | `90天` | `ELK集群` | `按月归档` |
| **审计日志** | `1年` | `独立数据库` | `冷备份` |

### 8.3 XXL-JOB日志配置


**调度中心日志配置**：

```properties
# application.properties

# 日志保留天数
xxl.job.logretentiondays=30

# 日志文件路径
xxl.job.executor.logpath=/data/applogs/xxl-job/jobhandler

# 日志文件大小限制(单个文件最大100MB)
logging.file.max-size=100MB

# 日志文件数量限制(最多保留30个文件)
logging.file.max-history=30
```

**执行器日志配置**：

```xml
<!-- logback-spring.xml -->
<configuration>
    <!-- 按天滚动 -->
    <appender name="FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>/app/logs/xxl-job-executor.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <!-- 日志文件名模式 -->
            <fileNamePattern>/app/logs/xxl-job-executor.%d{yyyy-MM-dd}.log</fileNamePattern>
            <!-- 保留30天 -->
            <maxHistory>30</maxHistory>
            <!-- 总大小限制10GB -->
            <totalSizeCap>10GB</totalSizeCap>
        </rollingPolicy>
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{50} - %msg%n</pattern>
        </encoder>
    </appender>
</configuration>
```

### 8.4 日志清理脚本


**自动清理脚本**：

```bash
#!/bin/bash
# clean-old-logs.sh

LOG_DIR="/app/logs"
ARCHIVE_DIR="/data/archive"
DAYS_TO_KEEP=7
DAYS_TO_ARCHIVE=30

echo "===== 开始日志清理 ====="

# 1. 归档7-30天的日志
find ${LOG_DIR} -name "*.log" -type f -mtime +${DAYS_TO_KEEP} -mtime -${DAYS_TO_ARCHIVE} | while read file
do
    echo "归档文件: ${file}"
    gzip ${file}
    mv ${file}.gz ${ARCHIVE_DIR}/
done

# 2. 删除30天以上的日志
find ${LOG_DIR} -name "*.log" -type f -mtime +${DAYS_TO_ARCHIVE} -delete
find ${ARCHIVE_DIR} -name "*.gz" -type f -mtime +${DAYS_TO_ARCHIVE} -delete

echo "===== 清理完成 ====="
```

**定时任务配置**：

```bash
# crontab -e
# 每天凌晨3点清理日志
0 3 * * * /app/scripts/clean-old-logs.sh >> /app/logs/clean.log 2>&1
```

### 8.5 日志查询优化


**🔸 使用ELK进行日志聚合**

```
日志收集流程：

执行器1 ─┐
执行器2 ─┼─→ Filebeat ─→ Logstash ─→ Elasticsearch ─→ Kibana
执行器3 ─┘              (收集)     (过滤)      (存储)       (展示)
```

**Filebeat配置示例**：

```yaml
# filebeat.yml
filebeat.inputs:
  - type: log
    enabled: true
    paths:
      - /app/logs/xxl-job-executor*.log
    fields:
      app: xxl-job-executor
      env: production

output.logstash:
  hosts: ["logstash:5044"]
```

**常用查询语句**：

```
# Kibana查询示例

# 查询最近1小时的错误日志
level: ERROR AND @timestamp:[now-1h TO now]

# 查询特定任务的执行日志
jobId: 123 AND message: "执行"

# 查询执行时长超过1分钟的任务
executionTime: >60000
```

> 💡 **日志管理建议**：日志不是越多越好，关键是要分类清晰、方便查询。建议核心日志保留时间长一些，普通日志可以短一些。

---

## 9. 📋 核心要点总结


### 9.1 必须掌握的核心概念


```
🔸 环境隔离：开发/测试/生产环境严格分离，避免配置混用
🔸 配置管理：使用配置中心集中管理，敏感配置加密存储
🔸 发布流程：遵循标准发布步骤，做好发布前检查
🔸 灰度发布：小范围验证后再全量，降低发布风险
🔸 回滚方案：提前准备回滚脚本，关键时刻能快速恢复
🔸 监控告警：关注核心指标，及时发现问题
🔸 问题排查：遵循标准流程，快速定位根因
🔸 日志归档：合理保留日志，方便问题追溯
```

### 9.2 生产环境最佳实践


**🔹 发布前准备**
```
准备清单：
✅ 配置检查(环境配置是否正确)
✅ 依赖检查(数据库/Redis/第三方服务)
✅ 备份准备(代码包/数据库/配置文件)
✅ 回滚预案(回滚脚本/应急联系人)
✅ 监控就位(告警规则/监控大盘)
```

**🔹 发布中控制**
```
发布原则：
1. 选择业务低峰期发布
2. 灰度发布降低风险
3. 实时监控关键指标
4. 发现异常立即回滚
5. 全程保持沟通
```

**🔹 发布后观察**
```
观察重点：
- 前30分钟：高度关注，随时准备回滚
- 1-2小时：密切观察，收集反馈
- 24小时内：持续监控，记录问题
- 3天后：总结经验，优化流程
```

### 9.3 常见错误避免


```
❌ 错误1：配置混用
教训：开发环境误连生产数据库
预防：配置文件明确标注环境，使用配置中心

❌ 错误2：无备份发布
教训：发布后无法回滚，只能硬着头皮修复
预防：发布前必须备份代码和配置

❌ 错误3：高峰期发布
教训：发布出问题影响大量用户
预防：选择凌晨或业务低峰期

❌ 错误4：无监控告警
教训：任务失败了好几个小时才发现
预防：建立完善的监控告警体系

❌ 错误5：日志不归档
教训：磁盘被日志占满，服务崩溃
预防：定期清理归档，设置日志保留策略
```

### 9.4 实战经验总结


**💼 运维经验分享**

```
经验1：宁可慢一点，不可错一点
- 发布前多检查几遍配置
- 灰度时多观察一会儿
- 遇到异常宁可回滚也不要硬撑

经验2：自动化是王道
- 发布流程自动化(Jenkins/GitLab CI)
- 监控告警自动化(Prometheus+AlertManager)  
- 日志归档自动化(定时脚本)

经验3：文档比记忆可靠
- 标准操作手册(SOP)
- 应急处理预案
- 问题解决记录

经验4：团队协作很重要
- 发布前通知相关人员
- 发布中保持沟通
- 发布后及时反馈
```

**🎯 核心记忆口诀**

```
生产发布记心间，
环境隔离是关键。
配置管理要规范，
灰度发布降风险。

监控告警不能少，
问题排查有步骤。
日志归档要及时，
回滚方案需准备。
```

> 🎓 **总结**：生产环境无小事，每一个细节都可能影响业务。建立规范、严格执行、持续优化，才能保证系统稳定运行。