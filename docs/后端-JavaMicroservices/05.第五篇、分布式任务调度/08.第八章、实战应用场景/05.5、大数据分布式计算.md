---
title: 5、大数据分布式计算
---
## 📚 目录

1. [大数据分布式计算概述](#1-大数据分布式计算概述)
2. [分布式任务切分原理](#2-分布式任务切分原理)
3. [批量数据计算实战](#3-批量数据计算实战)
4. [数据统计分析场景](#4-数据统计分析场景)
5. [大数据处理策略](#5-大数据处理策略)
6. [计算结果汇总机制](#6-计算结果汇总机制)
7. [分片计算协调详解](#7-分片计算协调详解)
8. [核心要点总结](#8-核心要点总结)

---

## 1. 🌐 大数据分布式计算概述


### 1.1 什么是大数据分布式计算


**通俗理解**：
想象你要统计一个城市100万用户的消费数据，一台电脑处理要好几个小时。但如果把任务分给10台电脑，每台处理10万条数据，最后把结果汇总，是不是就快多了？这就是分布式计算的核心思想。

**大数据分布式计算**就是：把一个**超大任务**拆分成若干**小任务**，分配给**多台机器**并行处理，最后把**结果汇总**的过程。

```
单机处理：
📦 100万数据 → [一台机器处理] → ⏱️ 需要10小时

分布式处理：
📦 100万数据 → 切分10份 → [10台机器并行] → ⏱️ 只需1小时
   ↓              ↓                ↓
 10万条         10万条           10万条
```

### 1.2 为什么需要分布式计算


**实际业务痛点**：

🔸 **数据量爆炸**
- 电商订单：每天千万级订单需要统计
- 用户行为：亿级用户行为日志需要分析
- 金融对账：海量交易数据需要核对

🔸 **单机瓶颈**
- CPU处理能力有限
- 内存容量不够
- 网络IO受限
- 磁盘读写速度慢

🔸 **时效性要求**
- 夜间批处理窗口期有限
- 实时数据分析需求
- 定时报表生成压力

**对比示例**：

| 场景 | 单机处理 | 分布式处理 | 优势 |
|------|---------|-----------|------|
| 统计100万订单 | 10小时 | 1小时(10台) | **速度提升10倍** |
| 处理10亿日志 | 内存溢出 | 正常运行 | **突破单机限制** |
| 月度财务报表 | 超时失败 | 按时完成 | **满足时效要求** |

### 1.3 XXL-JOB在大数据中的定位


**XXL-JOB的角色**：
- 🎯 **任务调度中枢**：统一调度分布式任务
- 🔄 **分片协调者**：自动分配任务片段
- 📊 **执行监控台**：实时监控计算进度
- 🔗 **结果汇总器**：收集并汇总计算结果

**工作流程**：
```
调度中心(XXL-JOB Admin)
         ↓
    触发定时任务
         ↓
    分配分片参数
    /    |    \
执行器1  执行器2  执行器3  (并行计算)
   ↓      ↓      ↓
 处理    处理    处理
 1-33万  34-66万 67-100万
   ↓      ↓      ↓
    \    |    /
    结果汇总存储
```

---

## 2. ✂️ 分布式任务切分原理


### 2.1 任务切分是什么


**生活类比**：
就像分蛋糕🎂，你要把一个大蛋糕平均分给10个人吃。你会先切成10块，每人拿一块。任务切分就是这个道理，把大任务切成小块，每个执行器处理一块。

**技术定义**：
把一个**完整的大数据集**按照某种**规则**拆分成多个**互不重复**的子集，让不同的执行器**各自处理**一部分数据。

### 2.2 分片参数详解


XXL-JOB提供了两个核心分片参数：

**📌 shardIndex（分片序号）**
- **含义**：当前执行器的编号，从0开始
- **作用**：标识"我是第几个执行器"
- **示例**：总共3台机器，序号分别是 0、1、2

**📌 shardTotal（分片总数）**
- **含义**：总共有多少个执行器
- **作用**：告诉执行器"总共几台机器在干活"
- **示例**：3台机器一起工作，shardTotal=3

**参数关系图**：
```
任务总数据：100万条订单

分片总数(shardTotal) = 3

执行器0(shardIndex=0) → 处理 订单ID % 3 = 0 的数据
执行器1(shardIndex=1) → 处理 订单ID % 3 = 1 的数据  
执行器2(shardIndex=2) → 处理 订单ID % 3 = 2 的数据
```

### 2.3 常见切分策略


**🔸 取模切分（最常用）**

**原理**：用数据ID对分片总数取模
```
数据ID % shardTotal == shardIndex
```

**实际应用**：
```java
// 查询属于当前分片的订单
SELECT * FROM t_order 
WHERE MOD(order_id, #{shardTotal}) = #{shardIndex}
```

**优点**：
- ✅ 数据分布均匀
- ✅ 实现简单
- ✅ 适合ID连续的场景

**🔸 范围切分**

**原理**：按数据范围划分
```
执行器0：处理 ID 1-33万
执行器1：处理 ID 34-66万
执行器2：处理 ID 67-100万
```

**实际应用**：
```java
// 计算当前分片的数据范围
int totalData = 1000000; // 100万
int pageSize = totalData / shardTotal;
int startId = shardIndex * pageSize + 1;
int endId = (shardIndex + 1) * pageSize;

SELECT * FROM t_order 
WHERE order_id BETWEEN #{startId} AND #{endId}
```

**优点**：
- ✅ 适合时间范围查询
- ✅ 容易理解
- ✅ 支持区间统计

**🔸 哈希切分**

**原理**：对关键字段哈希后分片
```java
// 按用户ID哈希分片
int shard = Math.abs(userId.hashCode()) % shardTotal;
if (shard == shardIndex) {
    // 处理该用户数据
}
```

**适用场景**：
- 按用户维度统计
- 数据倾斜严重时
- 非数值型主键

---

## 3. 📊 批量数据计算实战


### 3.1 批量计算的核心思路


**批量计算**就是：不要一条一条处理数据，而是**一批一批**处理，既能减少数据库连接次数，又能提高处理效率。

**批处理流程**：
```
1. 查询一批数据(如1000条)
   ↓
2. 在内存中批量计算
   ↓
3. 批量写入结果
   ↓
4. 继续下一批
   ↓
5. 直到处理完成
```

### 3.2 订单金额统计案例


**业务场景**：
每天凌晨统计前一天所有订单的销售额，订单表有500万条数据。

**分片计算代码**：
```java
@XxlJob("orderAmountStatJob")
public void calculateOrderAmount() {
    // 获取分片参数
    int shardIndex = XxlJobHelper.getShardIndex();
    int shardTotal = XxlJobHelper.getShardTotal();
    
    log.info("开始统计订单，分片[{}/{}]", shardIndex, shardTotal);
    
    // 批量处理配置
    int batchSize = 1000; // 每批1000条
    int offset = 0;
    BigDecimal totalAmount = BigDecimal.ZERO;
    
    while (true) {
        // 查询当前分片的一批订单
        List<Order> orders = orderMapper.selectByPage(
            shardIndex, shardTotal, offset, batchSize
        );
        
        if (orders.isEmpty()) {
            break; // 没有数据了，结束
        }
        
        // 批量计算金额
        BigDecimal batchAmount = orders.stream()
            .map(Order::getAmount)
            .reduce(BigDecimal.ZERO, BigDecimal::add);
        
        totalAmount = totalAmount.add(batchAmount);
        
        log.info("处理第{}批，本批金额:{}", offset/batchSize + 1, batchAmount);
        
        offset += batchSize;
    }
    
    // 保存统计结果
    saveStatResult(shardIndex, totalAmount);
    log.info("分片[{}]统计完成，总金额:{}", shardIndex, totalAmount);
}
```

**SQL查询实现**：
```sql
-- 按分片查询订单
SELECT * FROM t_order
WHERE MOD(order_id, #{shardTotal}) = #{shardIndex}
  AND order_date = CURDATE() - INTERVAL 1 DAY
LIMIT #{offset}, #{batchSize}
```

### 3.3 批量处理优化技巧


**💡 内存优化**

> **问题**：500万数据全部加载会内存溢出
> 
> **解决**：分批加载，处理完一批释放一批

```java
// ❌ 错误做法：一次性加载全部
List<Order> allOrders = orderMapper.selectAll(); // 内存爆了！

// ✅ 正确做法：分批处理
while (hasMore) {
    List<Order> batch = orderMapper.selectByPage(offset, 1000);
    processBatch(batch); // 处理完这批
    batch.clear(); // 释放内存
    offset += 1000;
}
```

**💡 数据库连接优化**

```java
// 使用批量操作减少数据库交互
List<StatResult> results = new ArrayList<>();

for (Order order : orders) {
    results.add(buildStatResult(order));
    
    // 每1000条批量插入一次
    if (results.size() >= 1000) {
        statMapper.batchInsert(results);
        results.clear();
    }
}

// 插入剩余数据
if (!results.isEmpty()) {
    statMapper.batchInsert(results);
}
```

---

## 4. 📈 数据统计分析场景


### 4.1 用户行为分析


**场景说明**：
分析1亿用户的行为数据，统计每个用户的活跃度、消费习惯等。

**分片策略**：按用户ID取模
```java
@XxlJob("userBehaviorAnalysisJob")
public void analyzeUserBehavior() {
    int shardIndex = XxlJobHelper.getShardIndex();
    int shardTotal = XxlJobHelper.getShardTotal();
    
    // 查询属于当前分片的用户
    List<Long> userIds = userMapper.selectUserIdsByMod(
        shardIndex, shardTotal
    );
    
    for (Long userId : userIds) {
        // 分析单个用户行为
        UserBehavior behavior = analyzeUser(userId);
        // 保存分析结果
        behaviorMapper.save(behavior);
    }
}
```

**查询SQL**：
```sql
-- 获取属于当前分片的用户ID
SELECT user_id FROM t_user
WHERE MOD(user_id, #{shardTotal}) = #{shardIndex}
```

### 4.2 商品销量排行


**场景说明**：
统计100万件商品的销量，生成TOP 1000排行榜。

**两阶段处理**：

**📌 阶段1：分片统计**
```java
// 每个分片统计自己负责的商品销量
@XxlJob("productSalesStatJob")
public void statProductSales() {
    int shardIndex = XxlJobHelper.getShardIndex();
    int shardTotal = XxlJobHelper.getShardTotal();
    
    // 统计当前分片的商品销量
    List<ProductSales> salesList = orderMapper.statByProduct(
        shardIndex, shardTotal
    );
    
    // 保存到临时表
    salesMapper.saveTempResult(shardIndex, salesList);
}
```

**📌 阶段2：结果汇总**
```java
// 最后一个分片负责汇总
@XxlJob("productSalesRankJob")  
public void rankProductSales() {
    // 从临时表汇总所有分片结果
    List<ProductSales> allSales = salesMapper.selectAllTempResult();
    
    // 排序取TOP 1000
    List<ProductSales> top1000 = allSales.stream()
        .sorted(Comparator.comparing(ProductSales::getSalesCount).reversed())
        .limit(1000)
        .collect(Collectors.toList());
    
    // 保存最终排行榜
    rankMapper.saveRank(top1000);
}
```

### 4.3 财务对账场景


**场景说明**：
每月1号对上个月所有交易进行对账，交易记录1000万条。

**对账流程**：
```
订单表          支付表
  ↓              ↓
数据分片        数据分片
  ↓              ↓
订单金额汇总 ←→ 支付金额汇总
  ↓              ↓
    比对差异
      ↓
  生成对账报告
```

**核心代码**：
```java
@XxlJob("accountCheckJob")
public void checkAccount() {
    int shardIndex = XxlJobHelper.getShardIndex();
    int shardTotal = XxlJobHelper.getShardTotal();
    
    // 统计订单金额
    BigDecimal orderAmount = orderMapper.sumAmountByMod(
        shardIndex, shardTotal, lastMonth
    );
    
    // 统计支付金额  
    BigDecimal payAmount = payMapper.sumAmountByMod(
        shardIndex, shardTotal, lastMonth
    );
    
    // 比对差异
    BigDecimal diff = orderAmount.subtract(payAmount);
    
    if (diff.compareTo(BigDecimal.ZERO) != 0) {
        log.warn("分片{}对账异常，差异金额:{}", shardIndex, diff);
        // 记录差异详情
        saveCheckDiff(shardIndex, diff);
    }
}
```

---

## 5. 🚀 大数据处理策略


### 5.1 数据量评估


**如何判断需要分布式处理？**

| 数据量级 | 处理建议 | 执行器数量 |
|---------|---------|-----------|
| < 10万 | 单机处理即可 | 1台 |
| 10-100万 | 考虑分布式 | 2-5台 |
| 100-1000万 | 必须分布式 | 5-10台 |
| > 1000万 | 大规模分布式 | 10-50台 |

**评估公式**：
```
执行器数量 = 数据总量 / 单机处理能力

示例：
- 数据总量：5000万条
- 单机处理：每小时100万条
- 时间窗口：2小时
- 需要执行器：5000万 / (100万 × 2) = 25台
```

### 5.2 分片数量优化


**分片太少的问题**：
- ❌ 无法充分利用资源
- ❌ 处理时间长
- ❌ 单点压力大

**分片太多的问题**：
- ❌ 调度开销大
- ❌ 数据库连接数暴增
- ❌ 任务管理复杂

**最佳实践**：
```
🎯 分片数 = 执行器数量 × 并发系数

并发系数建议：
- CPU密集型任务：1-2
- IO密集型任务：2-4
- 混合型任务：2-3

示例：
- 执行器：10台
- 并发系数：2（IO密集）
- 分片数：20个
```

### 5.3 数据倾斜处理


**什么是数据倾斜**：
某些分片处理的数据量远超其他分片，导致整体任务时间由最慢分片决定。

**倾斜场景**：
```
订单按地区分布：
北京：200万订单  
上海：180万订单
其他：20万订单

如果按地区分片会严重倾斜！
```

**解决方案**：

**🔸 方案1：二次分片**
```java
// 对热点数据再次分片
if (isHotArea(region)) {
    // 热点地区按订单ID再分片
    SELECT * FROM t_order
    WHERE region = #{region}
      AND MOD(order_id, 10) = #{subIndex}
} else {
    // 普通地区正常处理
    SELECT * FROM t_order
    WHERE region = #{region}
}
```

**🔸 方案2：动态分片**
```java
// 根据数据量动态调整分片
Map<Integer, Integer> shardWeights = new HashMap<>();
shardWeights.put(0, 40); // 北京权重40%
shardWeights.put(1, 35); // 上海权重35%  
shardWeights.put(2, 25); // 其他权重25%
```

---

## 6. 🔄 计算结果汇总机制


### 6.1 为什么需要结果汇总


**分片计算后的问题**：
```
执行器0 → 统计出销售额：100万
执行器1 → 统计出销售额：120万
执行器2 → 统计出销售额：80万

❓ 如何得到总销售额？需要汇总！
```

**汇总的作用**：
- 🎯 合并各分片计算结果
- 📊 生成最终统计报表
- ✅ 验证数据完整性

### 6.2 汇总策略详解


**🔸 策略1：数据库汇总（推荐）**

**原理**：各分片将结果写入临时表，最后一个分片汇总

```java
// 步骤1：各分片写入结果
@XxlJob("calculateJob")
public void calculate() {
    int shardIndex = XxlJobHelper.getShardIndex();
    
    // 计算结果
    BigDecimal amount = calculateAmount();
    
    // 写入临时表
    TempResult result = new TempResult();
    result.setShardIndex(shardIndex);
    result.setAmount(amount);
    result.setJobDate(LocalDate.now());
    tempResultMapper.insert(result);
}

// 步骤2：最后一个分片汇总
@XxlJob("summaryJob")
public void summary() {
    // 查询所有分片结果
    List<TempResult> results = tempResultMapper.selectByDate(
        LocalDate.now()
    );
    
    // 汇总计算
    BigDecimal total = results.stream()
        .map(TempResult::getAmount)
        .reduce(BigDecimal.ZERO, BigDecimal::add);
    
    // 保存最终结果
    saveFinalResult(total);
}
```

**优点**：
- ✅ 数据持久化，不怕重启
- ✅ 方便调试和追溯
- ✅ 支持断点续传

**🔸 策略2：Redis汇总**

**原理**：使用Redis的原子操作实时汇总

```java
@XxlJob("calculateJob")
public void calculate() {
    int shardIndex = XxlJobHelper.getShardIndex();
    int shardTotal = XxlJobHelper.getShardTotal();
    
    // 计算结果
    BigDecimal amount = calculateAmount();
    
    String key = "job:summary:" + LocalDate.now();
    
    // 原子累加
    redisTemplate.opsForValue().increment(key, amount.doubleValue());
    
    // 记录完成分片
    redisTemplate.opsForSet().add(key + ":finished", shardIndex);
    
    // 检查是否所有分片完成
    Long finishedCount = redisTemplate.opsForSet().size(key + ":finished");
    if (finishedCount == shardTotal) {
        // 获取最终结果
        Double total = redisTemplate.opsForValue().get(key);
        saveFinalResult(new BigDecimal(total));
    }
}
```

**优点**：
- ✅ 实时性好
- ✅ 性能高
- ✅ 自动判断完成

### 6.3 汇总结果验证


**数据完整性检查**：
```java
// 验证所有分片都完成了
boolean checkComplete() {
    int shardTotal = XxlJobHelper.getShardTotal();
    
    // 查询已完成分片数
    int finishedCount = tempResultMapper.countByDate(LocalDate.now());
    
    if (finishedCount < shardTotal) {
        log.warn("数据不完整！期望{}个分片，实际{}个", 
                 shardTotal, finishedCount);
        return false;
    }
    
    return true;
}
```

**结果准确性验证**：
```java
// 抽样验证结果准确性
void verifySummary(BigDecimal summary) {
    // 随机抽取10%数据重新计算
    BigDecimal sampleResult = calculateSample(0.1);
    BigDecimal expectedTotal = sampleResult.multiply(new BigDecimal("10"));
    
    // 误差率
    BigDecimal diff = summary.subtract(expectedTotal).abs();
    BigDecimal errorRate = diff.divide(summary, 4, RoundingMode.HALF_UP);
    
    if (errorRate.compareTo(new BigDecimal("0.01")) > 0) {
        log.error("汇总结果异常！误差率:{}", errorRate);
    }
}
```

---

## 7. 🤝 分片计算协调详解


### 7.1 分片协调的核心职责


**协调器要做的事**：
- 📋 **任务分配**：告诉每个执行器该处理哪部分数据
- 📊 **进度监控**：实时掌握各分片执行情况
- 🔄 **故障处理**：分片失败后的重试和补偿
- ✅ **结果校验**：确保所有分片正确完成

**协调流程图**：
```
调度中心
    ↓
[触发任务]
    ↓
┌─────────────────┐
│  计算分片参数    │
│ shardTotal=3    │
└─────────────────┘
         ↓
    ┌────┴────┐
    ↓    ↓    ↓
  执行器0 执行器1 执行器2
  (0,3)  (1,3)  (2,3)
    ↓    ↓    ↓
  [并行执行]
    ↓    ↓    ↓
  完成  完成  完成
    ↓    ↓    ↓
    └────┬────┘
         ↓
    [结果汇总]
```

### 7.2 分片失败重试机制


**问题场景**：
```
分片0 → ✅ 成功
分片1 → ❌ 失败（网络超时）
分片2 → ✅ 成功

如何保证分片1的数据被处理？
```

**解决方案1：XXL-JOB自动重试**
```java
@XxlJob("dataProcessJob")
public void processData() throws Exception {
    try {
        int shardIndex = XxlJobHelper.getShardIndex();
        // 处理逻辑
        processShardData(shardIndex);
        
    } catch (Exception e) {
        log.error("分片处理失败", e);
        // 抛出异常触发XXL-JOB重试
        throw e;
    }
}
```

**XXL-JOB配置**：
- 失败重试次数：3次
- 重试间隔：30秒
- 失败告警：开启

**解决方案2：手动补偿机制**
```java
// 记录失败分片
@XxlJob("dataProcessJob")
public void processData() {
    int shardIndex = XxlJobHelper.getShardIndex();
    
    try {
        processShardData(shardIndex);
        // 标记成功
        markSuccess(shardIndex);
        
    } catch (Exception e) {
        // 记录失败信息
        recordFailure(shardIndex, e.getMessage());
    }
}

// 补偿任务：处理失败的分片
@XxlJob("compensateJob")
public void compensate() {
    List<FailedShard> failures = getFailedShards();
    
    for (FailedShard shard : failures) {
        try {
            // 重新处理失败分片
            processShardData(shard.getShardIndex());
            markSuccess(shard.getShardIndex());
        } catch (Exception e) {
            log.error("补偿失败", e);
        }
    }
}
```

### 7.3 分片进度监控


**实时进度追踪**：
```java
@XxlJob("dataProcessJob")  
public void processData() {
    int shardIndex = XxlJobHelper.getShardIndex();
    int shardTotal = XxlJobHelper.getShardTotal();
    
    // 获取总数据量
    long totalCount = getTotalCount(shardIndex, shardTotal);
    long processedCount = 0;
    
    int batchSize = 1000;
    int offset = 0;
    
    while (true) {
        List<Data> batch = queryBatch(offset, batchSize);
        if (batch.isEmpty()) break;
        
        // 处理数据
        processBatch(batch);
        processedCount += batch.size();
        
        // 更新进度
        int progress = (int)((processedCount * 100) / totalCount);
        updateProgress(shardIndex, progress);
        
        log.info("分片[{}/{}]进度:{}%", shardIndex, shardTotal, progress);
        
        offset += batchSize;
    }
}
```

**进度展示**：
```
执行器0: ████████████████████ 100% (1000000/1000000)
执行器1: ████████████░░░░░░░░  60% (600000/1000000)
执行器2: ████████████████████ 100% (1000000/1000000)

总进度: 86.67% (2600000/3000000)
```

### 7.4 并发控制与限流


**防止资源耗尽**：
```java
// 使用信号量限制并发
private final Semaphore semaphore = new Semaphore(10);

@XxlJob("dataProcessJob")
public void processData() throws InterruptedException {
    int shardIndex = XxlJobHelper.getShardIndex();
    
    int offset = 0;
    while (true) {
        List<Data> batch = queryBatch(offset, 1000);
        if (batch.isEmpty()) break;
        
        // 获取许可（最多10个线程并行）
        semaphore.acquire();
        
        CompletableFuture.runAsync(() -> {
            try {
                processBatch(batch);
            } finally {
                semaphore.release();
            }
        });
        
        offset += 1000;
    }
}
```

**数据库连接池控制**：
```yaml
# 根据分片数调整连接池
spring:
  datasource:
    hikari:
      maximum-pool-size: 50  # 5个分片 × 10个并发
      minimum-idle: 10
```

---

## 8. 📋 核心要点总结


### 8.1 必须掌握的核心概念


```
🔸 分布式计算：把大任务拆成小任务，多台机器并行处理
🔸 任务切分：按规则把数据分片，避免重复和遗漏
🔸 分片参数：shardIndex标识当前执行器，shardTotal标识总数
🔸 批量处理：分批加载数据，避免内存溢出
🔸 结果汇总：合并各分片结果，生成最终数据
🔸 协调机制：监控进度、处理失败、控制并发
```

### 8.2 关键理解要点


**🔹 什么时候用分布式计算**
```
数据量评估：
- < 10万：单机够用
- 10-100万：考虑分布式
- > 100万：必须分布式

时效性要求：
- 实时：必须分布式
- 小时级：可以分布式
- 天级：单机可能够用
```

**🔹 分片数量如何确定**
```
公式：分片数 = 执行器数 × 并发系数

建议：
- CPU密集：并发系数1-2
- IO密集：并发系数2-4
- 混合型：并发系数2-3
```

**🔹 数据倾斜如何处理**
```
识别倾斜：某些分片耗时远超其他分片
解决方案：
1. 二次分片（热点数据再细分）
2. 动态分片（按数据量调整权重）
3. 预处理（提前均衡数据）
```

### 8.3 实战开发要点


**📌 代码规范**
```java
// ✅ 好的做法
@XxlJob("dataProcessJob")
public void process() {
    int shardIndex = XxlJobHelper.getShardIndex();
    int shardTotal = XxlJobHelper.getShardTotal();
    
    log.info("开始处理分片[{}/{}]", shardIndex, shardTotal);
    
    try {
        // 业务逻辑
        processData(shardIndex, shardTotal);
        log.info("分片[{}]处理成功", shardIndex);
        
    } catch (Exception e) {
        log.error("分片[{}]处理失败", shardIndex, e);
        throw e; // 触发重试
    }
}

// ❌ 不好的做法
@XxlJob("badJob")
public void badProcess() {
    // 没有日志
    // 没有异常处理
    // 没有分片参数
    processAllData(); // 单机处理全部数据
}
```

**📌 性能优化清单**
- ✅ 分批查询，避免一次加载全部数据
- ✅ 批量操作，减少数据库交互
- ✅ 并发控制，防止资源耗尽
- ✅ 索引优化，加速分片查询
- ✅ 连接池调优，匹配并发数

**📌 监控告警配置**
```
必须监控的指标：
- 任务执行时间
- 分片完成数量
- 失败重试次数
- 数据处理进度
- 资源使用率

告警规则：
- 执行超时：> 2小时
- 失败率：> 5%
- 数据倾斜：最慢分片超平均3倍
- 资源占用：CPU > 80%
```

### 8.4 常见问题与解决


**❓ 如何保证数据不重复不遗漏**
```
使用取模分片：MOD(id, shardTotal) = shardIndex
优点：数据天然互斥，不会重复
验证：sum(各分片数量) = 总数据量
```

**❓ 分片失败如何处理**
```
方案1：XXL-JOB自动重试（3次）
方案2：记录失败分片，单独补偿
方案3：重跑整个任务（小数据量）
```

**❓ 如何提高处理速度**
```
1. 增加执行器数量（横向扩展）
2. 提高单机并发（纵向优化）
3. 优化查询SQL（减少IO）
4. 使用批量操作（减少交互）
```

**核心记忆口诀**：
```
大数据处理找分布，
任务切分要清楚，
分片参数莫忘记，
批量处理效率高，
结果汇总要可靠，
监控告警保稳定！
```