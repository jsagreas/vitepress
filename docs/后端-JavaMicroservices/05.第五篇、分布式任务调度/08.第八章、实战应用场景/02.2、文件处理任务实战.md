---
title: 2、文件处理任务实战
---
## 📚 目录

1. [文件处理场景概述](#1-文件处理场景概述)
2. [文件上传处理任务](#2-文件上传处理任务)
3. [批量文件处理实战](#3-批量文件处理实战)
4. [文件压缩与清理任务](#4-文件压缩与清理任务)
5. [临时文件管理策略](#5-临时文件管理策略)
6. [文件状态监控与追踪](#6-文件状态监控与追踪)
7. [日志采集任务实战](#7-日志采集任务实战)
8. [核心要点总结](#8-核心要点总结)

---

## 1. 📂 文件处理场景概述


### 1.1 什么是文件处理任务


**通俗理解**：就像办公室里定期整理文件柜一样，文件处理任务就是让系统自动帮你处理各种文件工作。

```
日常场景类比：
办公室文件管理              系统文件处理任务
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
每天整理新文件      →     定时处理上传文件
定期压缩归档        →     批量压缩历史文件
清理过期文件        →     自动删除临时文件
统计文件数量        →     监控文件处理状态
```

### 1.2 为什么需要定时文件处理


**核心痛点**：
- ⏰ **时间问题**：手动处理文件太耗时，影响正常业务
- 💾 **空间问题**：临时文件堆积，占用服务器存储空间
- 🔄 **重复工作**：每天都要做相同的文件整理工作
- 📊 **统计困难**：不知道文件处理到什么程度了

**解决方案**：
```
使用XXL-JOB定时调度 = 设定好规则，让系统自动干活

优势对比：
手动处理：需要人盯着，容易出错，效率低
定时任务：设定一次，自动执行，省心省力
```

### 1.3 常见文件处理场景


| 场景类型 | **具体需求** | **执行频率** | **实际案例** |
|---------|------------|------------|------------|
| 📤 **文件上传** | `处理用户上传的文件` | `实时/准实时` | `电商平台商品图片处理` |
| 🗂️ **批量处理** | `批量转换、压缩文件` | `每天凌晨执行` | `将Word文档转PDF` |
| 🗜️ **文件压缩** | `压缩历史文件归档` | `每周执行` | `压缩上月的订单附件` |
| 🗑️ **文件清理** | `删除过期临时文件` | `每天执行` | `删除7天前的临时文件` |
| 📊 **状态监控** | `统计文件处理进度` | `每小时执行` | `监控导出任务完成度` |

---

## 2. 📤 文件上传处理任务


### 2.1 文件上传处理流程


**业务场景**：用户上传了图片/文档，系统需要自动处理这些文件

```
用户上传流程：
用户 → 上传文件 → 临时存储 → 定时任务处理 → 正式存储
 │                    │              │              │
 └─点击上传      └─暂存目录    └─XXL-JOB     └─OSS/CDN
```

**处理步骤解析**：
```
① 接收文件：用户上传文件到临时目录
② 入队等待：文件信息写入待处理表
③ 定时扫描：XXL-JOB每分钟扫描待处理文件
④ 执行处理：压缩、格式转换、生成缩略图
⑤ 上传存储：处理完的文件上传到OSS
⑥ 更新状态：标记文件处理完成
```

### 2.2 实战代码示例


**数据库表设计**：
```sql
-- 文件上传记录表
CREATE TABLE file_upload_record (
    id BIGINT PRIMARY KEY,
    file_name VARCHAR(255),      -- 文件名
    file_path VARCHAR(500),       -- 临时路径
    file_size BIGINT,             -- 文件大小
    process_status INT,           -- 0-待处理 1-处理中 2-完成 3-失败
    create_time DATETIME,         -- 上传时间
    process_time DATETIME         -- 处理时间
);
```

**任务处理器实现**：
```java
@XxlJob("fileUploadHandler")
public void handleUploadFiles() {
    // 1. 查询待处理文件（每次处理100个）
    List<FileRecord> files = fileMapper.selectUnprocessed(100);
    
    for (FileRecord file : files) {
        try {
            // 2. 更新状态为处理中
            fileMapper.updateStatus(file.getId(), 1);
            
            // 3. 执行文件处理
            if (file.isImage()) {
                // 图片处理：压缩 + 生成缩略图
                compressImage(file);
                generateThumbnail(file);
            } else if (file.isDocument()) {
                // 文档处理：转PDF
                convertToPdf(file);
            }
            
            // 4. 上传到OSS
            String ossUrl = ossClient.upload(file);
            
            // 5. 更新为完成状态
            fileMapper.updateComplete(file.getId(), ossUrl);
            
        } catch (Exception e) {
            // 6. 失败标记，记录错误原因
            fileMapper.updateFailed(file.getId(), e.getMessage());
        }
    }
}
```

### 2.3 关键技术点


> 💡 **批量处理策略**：每次处理100个文件，避免一次性处理太多导致内存溢出

> ⚠️ **状态管理**：
> - 待处理(0) → 防止重复处理
> - 处理中(1) → 标记正在执行
> - 完成(2) → 处理成功
> - 失败(3) → 可以重试或人工介入

> 🔄 **失败重试**：失败的文件可以在下次调度时重新处理，或设置最大重试次数

---

## 3. 🗂️ 批量文件处理实战


### 3.1 批量转换场景


**实际需求**：每天凌晨将用户上传的Word文档批量转成PDF

```
业务背景：
在线文档系统 → 用户上传Word → 系统自动转PDF → 方便在线预览

为什么用定时任务：
- 转换耗时长，不能让用户等待
- 凌晨处理不影响白天业务
- 集中处理提高效率
```

### 3.2 批处理任务实现


**任务配置**：
```
调度配置：
执行时间：0 0 2 * * ?  （每天凌晨2点）
路由策略：分片广播
任务参数：batchSize=500  （每批500个文件）
```

**核心处理逻辑**：
```java
@XxlJob("batchDocumentConverter")
public void convertDocuments() {
    // 获取分片参数
    int shardIndex = XxlJobHelper.getShardIndex();
    int shardTotal = XxlJobHelper.getShardTotal();
    
    // 分片查询：每台机器处理一部分
    List<Document> docs = documentMapper.selectBySharding(
        shardIndex, shardTotal, "WORD", "PENDING"
    );
    
    // 批量处理
    for (Document doc : docs) {
        // 1. 下载原始Word文件
        File wordFile = downloadFromOss(doc.getWordUrl());
        
        // 2. 转换为PDF（调用转换工具）
        File pdfFile = convertToPdf(wordFile);
        
        // 3. 上传PDF到OSS
        String pdfUrl = uploadToOss(pdfFile);
        
        // 4. 更新记录
        documentMapper.updatePdfUrl(doc.getId(), pdfUrl);
        
        // 5. 清理临时文件
        wordFile.delete();
        pdfFile.delete();
    }
}
```

### 3.3 性能优化技巧


**分片处理优势**：
```
场景：10000个文档需要转换

单机处理：
机器1处理10000个 → 耗时约5小时

分片处理（3台机器）：
机器1处理3333个 → 
机器2处理3333个 → 总耗时约1.7小时
机器3处理3334个 →

时间缩短3倍！
```

> 🚀 **性能优化要点**：
> - 使用**分片广播**，多机并行处理
> - 控制**每批数量**，避免内存溢出  
> - 及时**清理临时文件**，防止磁盘占满
> - 记录**处理日志**，方便问题排查

---

## 4. 🗜️ 文件压缩与清理任务


### 4.1 文件压缩归档


**业务场景**：订单附件每月压缩归档，节省存储空间

```
压缩归档流程：
历史附件 → 按月打包 → 压缩存储 → 删除原文件 → 释放空间
   │           │          │          │          │
  去年文件   zip打包    压缩率70%   原文件删除  空间节省
```

**实现示例**：
```java
@XxlJob("monthlyFileArchive")
public void archiveMonthlyFiles() {
    // 1. 获取上个月的日期范围
    LocalDate lastMonth = LocalDate.now().minusMonths(1);
    String month = lastMonth.format(DateTimeFormatter.ofPattern("yyyy-MM"));
    
    // 2. 查询需要归档的文件
    List<OrderFile> files = orderFileMapper.selectByMonth(month);
    
    // 3. 创建压缩包
    String zipFileName = "order_files_" + month + ".zip";
    ZipOutputStream zos = new ZipOutputStream(
        new FileOutputStream(zipFileName)
    );
    
    // 4. 添加文件到压缩包
    for (OrderFile file : files) {
        File sourceFile = new File(file.getFilePath());
        zos.putNextEntry(new ZipEntry(file.getFileName()));
        Files.copy(sourceFile.toPath(), zos);
        zos.closeEntry();
    }
    zos.close();
    
    // 5. 上传压缩包到归档存储
    String archiveUrl = archiveStorage.upload(zipFileName);
    
    // 6. 记录归档信息
    archiveMapper.insert(month, archiveUrl, files.size());
    
    // 7. 删除原始文件
    for (OrderFile file : files) {
        new File(file.getFilePath()).delete();
        orderFileMapper.updateArchived(file.getId(), archiveUrl);
    }
}
```

### 4.2 临时文件清理


**清理策略**：
```
文件清理规则：
┌─────────────────────────────────────┐
│  文件类型          保留时长          │
├─────────────────────────────────────┤
│  临时上传文件      24小时            │
│  导出Excel         7天               │
│  日志文件          30天              │
│  备份文件          90天              │
└─────────────────────────────────────┘
```

**清理任务实现**：
```java
@XxlJob("tempFileCleaner")
public void cleanTempFiles() {
    // 获取临时文件目录
    String tempDir = "/data/temp/";
    
    // 计算过期时间（24小时前）
    long expireTime = System.currentTimeMillis() - 24 * 60 * 60 * 1000;
    
    // 遍历目录
    File dir = new File(tempDir);
    File[] files = dir.listFiles();
    
    int deleteCount = 0;
    long freedSpace = 0;
    
    for (File file : files) {
        if (file.lastModified() < expireTime) {
            freedSpace += file.length();
            file.delete();
            deleteCount++;
        }
    }
    
    // 记录清理结果
    XxlJobHelper.log("清理文件数：{}, 释放空间：{}MB", 
        deleteCount, freedSpace / 1024 / 1024);
}
```

> 📝 **清理任务配置建议**：
> - 执行时间：`0 0 3 * * ?` （凌晨3点，业务低峰期）
> - 路由策略：轮询（每台机器清理自己的临时目录）
> - 告警阈值：如果清理失败，发送告警通知

---

## 5. 🗄️ 临时文件管理策略


### 5.1 临时文件生命周期


```
临时文件的一生：
创建 → 使用 → 标记过期 → 清理删除
 │      │         │           │
上传   下载/预览  时间到期    定时任务删除
```

**管理表设计**：
```sql
CREATE TABLE temp_file_record (
    id BIGINT PRIMARY KEY,
    file_key VARCHAR(100),        -- 文件唯一标识
    file_path VARCHAR(500),        -- 文件路径
    expire_time DATETIME,          -- 过期时间
    is_deleted TINYINT DEFAULT 0,  -- 是否已删除
    create_time DATETIME
);
```

### 5.2 智能清理策略


**多级清理机制**：
```
清理优先级：
🔴 高优先级：已过期 + 未使用的文件（立即清理）
🟡 中优先级：已过期 + 使用率低的文件（延迟清理）
🟢 低优先级：未过期但空间紧张时清理最早的文件
```

**实现逻辑**：
```java
@XxlJob("smartFileCleaner")
public void smartClean() {
    // 1. 检查磁盘使用率
    long usagePercent = getDiskUsagePercent();
    
    if (usagePercent > 80) {  // 超过80%启动清理
        // 2. 优先清理已过期文件
        cleanExpiredFiles();
        
        // 3. 如果还不够，清理访问频率低的文件
        if (getDiskUsagePercent() > 70) {
            cleanLowAccessFiles();
        }
    }
}

private void cleanExpiredFiles() {
    List<TempFile> files = tempFileMapper.selectExpired();
    for (TempFile file : files) {
        new File(file.getPath()).delete();
        tempFileMapper.markDeleted(file.getId());
    }
}
```

> ⚠️ **注意事项**：
> - 删除前检查文件是否正在使用（避免删除正在下载的文件）
> - 记录删除日志，方便问题排查
> - 重要文件删除前先备份

---

## 6. 📊 文件状态监控与追踪


### 6.1 处理进度追踪


**监控维度**：
```
文件处理监控仪表盘：
┌────────────────────────────────────┐
│  总文件数：10000                    │
│  ✅ 已完成：8500 (85%)              │
│  ⏳ 处理中：1200 (12%)              │
│  ❌ 失败：300 (3%)                  │
│  平均处理时长：2.5秒/个             │
└────────────────────────────────────┘
```

**监控任务实现**：
```java
@XxlJob("fileProcessMonitor")
public void monitorProgress() {
    // 统计各状态文件数量
    Map<String, Long> stats = fileMapper.countByStatus();
    
    long total = stats.values().stream().mapToLong(Long::longValue).sum();
    long completed = stats.getOrDefault("COMPLETED", 0L);
    long processing = stats.getOrDefault("PROCESSING", 0L);
    long failed = stats.getOrDefault("FAILED", 0L);
    
    // 计算完成率
    double completionRate = total > 0 ? (completed * 100.0 / total) : 0;
    
    // 记录监控日志
    XxlJobHelper.log("文件处理进度: {}% ({}/{})", 
        String.format("%.2f", completionRate), completed, total);
    
    // 如果失败率超过5%，发送告警
    if (failed * 100.0 / total > 5) {
        alertService.sendAlert("文件处理失败率过高：" + 
            (failed * 100.0 / total) + "%");
    }
}
```

### 6.2 异常文件处理


**异常检测规则**：
```
异常判定条件：
- 处理时间超过30分钟仍未完成 → 可能卡死
- 同一文件失败次数超过3次 → 文件损坏
- 文件大小超过100MB → 需要特殊处理
```

**异常处理流程**：
```java
@XxlJob("abnormalFileHandler")
public void handleAbnormalFiles() {
    // 1. 查询超时文件（处理中超过30分钟）
    List<FileRecord> timeoutFiles = fileMapper.selectTimeout(30);
    for (FileRecord file : timeoutFiles) {
        // 重置状态，等待重新处理
        fileMapper.resetStatus(file.getId());
    }
    
    // 2. 查询多次失败文件
    List<FileRecord> failedFiles = fileMapper.selectFailedMultiple(3);
    for (FileRecord file : failedFiles) {
        // 标记为需人工介入
        fileMapper.markManualCheck(file.getId());
        // 发送通知
        notifyAdmin("文件处理异常，需人工检查：" + file.getFileName());
    }
}
```

---

## 7. 📋 日志采集任务实战


### 7.1 日志采集场景


**业务需求**：每天定时采集各服务器的应用日志，统一存储分析

```
日志采集流程：
各服务器日志 → 定时采集 → 解析处理 → 存储ES → 可视化分析
     │              │          │         │          │
  应用日志      XXL-JOB      提取关键信息  检索   Kibana展示
```

### 7.2 日志采集实现


**采集任务代码**：
```java
@XxlJob("logCollector")
public void collectLogs() {
    // 获取分片信息（每台机器采集自己的日志）
    int shardIndex = XxlJobHelper.getShardIndex();
    
    // 1. 读取日志文件（最近1小时的日志）
    String logPath = "/var/log/app/app.log";
    List<String> logLines = readRecentLogs(logPath, 1);
    
    // 2. 解析日志
    List<LogEntry> entries = new ArrayList<>();
    for (String line : logLines) {
        LogEntry entry = parseLog(line);
        if (entry != null) {
            entry.setServerIndex(shardIndex);
            entries.add(entry);
        }
    }
    
    // 3. 批量写入ES
    elasticsearchService.bulkInsert("app-logs", entries);
    
    XxlJobHelper.log("采集日志{}条", entries.size());
}

// 解析日志行
private LogEntry parseLog(String line) {
    // 示例格式：2025-01-15 10:30:00 ERROR [OrderService] 订单创建失败
    String[] parts = line.split(" ", 5);
    if (parts.length < 5) return null;
    
    LogEntry entry = new LogEntry();
    entry.setTimestamp(parts[0] + " " + parts[1]);
    entry.setLevel(parts[2]);
    entry.setModule(parts[3]);
    entry.setMessage(parts[4]);
    return entry;
}
```

### 7.3 日志分析与告警


**关键指标监控**：
```java
@XxlJob("logAnalyzer")
public void analyzeLogs() {
    // 统计最近1小时的错误日志
    long errorCount = esService.countByLevel("ERROR", 1);
    
    // 如果错误数超过100，发送告警
    if (errorCount > 100) {
        String message = String.format(
            "最近1小时错误日志数量：%d，超过阈值100", 
            errorCount
        );
        alertService.sendAlert(message);
    }
    
    // 分析高频错误
    List<ErrorStats> topErrors = esService.topErrors(10);
    for (ErrorStats error : topErrors) {
        XxlJobHelper.log("高频错误: {} 出现{}次", 
            error.getMessage(), error.getCount());
    }
}
```

> 💡 **日志采集优化**：
> - **增量采集**：只采集新增日志，使用文件偏移量记录
> - **压缩传输**：日志压缩后传输，节省网络带宽
> - **异步写入**：采集和写入异步进行，提高效率

---

## 8. 📋 核心要点总结


### 8.1 文件处理任务关键点


```
🔸 批量处理：合理控制批次大小，避免内存溢出
🔸 状态管理：完善的状态流转，支持失败重试
🔸 分片处理：利用分片广播，多机并行提速
🔸 异常处理：完善的异常捕获和告警机制
🔸 资源清理：及时清理临时文件，防止磁盘占满
🔸 监控告警：实时监控处理进度，异常及时告警
```

### 8.2 实战经验总结


**任务调度配置**：
| 任务类型 | **执行频率** | **路由策略** | **超时时间** |
|---------|------------|------------|------------|
| 📤 文件上传处理 | `每1分钟` | `轮询` | `30秒` |
| 🗂️ 批量转换 | `每天凌晨2点` | `分片广播` | `2小时` |
| 🗜️ 文件压缩 | `每月1号凌晨` | `第一个` | `4小时` |
| 🗑️ 文件清理 | `每天凌晨3点` | `分片广播` | `30分钟` |
| 📊 状态监控 | `每小时` | `第一个` | `1分钟` |

**性能优化技巧**：
```
✅ 使用分片广播实现并行处理
✅ 控制单批处理数量（建议100-500）
✅ 及时清理临时文件和内存
✅ 使用连接池复用资源
✅ 异常文件单独处理，不影响正常流程
```

**监控告警建议**：
```
⚠️ 处理失败率 > 5% → 发送告警
⚠️ 单个文件处理超时30分钟 → 自动重置
⚠️ 磁盘使用率 > 80% → 启动清理任务
⚠️ 队列积压超过1000 → 扩容处理节点
```

### 8.3 常见问题与解决


**Q1：文件处理太慢怎么办？**
```
解决方案：
→ 使用分片广播，增加处理节点
→ 优化处理逻辑，减少IO操作
→ 异步处理，不阻塞主流程
```

**Q2：临时文件占满磁盘？**
```
解决方案：
→ 设置合理的过期时间
→ 增加磁盘空间监控
→ 处理完立即删除临时文件
```

**Q3：如何保证文件不丢失？**
```
解决方案：
→ 使用数据库记录文件状态
→ 失败自动重试（设置最大次数）
→ 重要文件备份后再删除
```

**核心记忆**：
- 文件处理任务要**分批处理**，避免一次性处理太多
- 使用**状态机管理**文件处理流程，支持失败重试
- **分片广播**是提速利器，多机并行效率高
- **监控告警**不可少，问题早发现早解决
- **临时文件**要及时清理，防止占满磁盘空间