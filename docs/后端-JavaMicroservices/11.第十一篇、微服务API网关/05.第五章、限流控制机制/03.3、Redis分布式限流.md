---
title: 3、Redis分布式限流
---
## 📚 目录

1. [什么是Redis分布式限流](#1-什么是Redis分布式限流)
2. [RequestRateLimiter配置详解](#2-RequestRateLimiter配置详解)
3. [RedisRateLimiter实现原理](#3-RedisRateLimiter实现原理)
4. [Lua脚本执行原理](#4-Lua脚本执行原理)
5. [Redis连接池配置](#5-Redis连接池配置)
6. [KeyResolver键生成策略](#6-KeyResolver键生成策略)
7. [分布式限流一致性保障](#7-分布式限流一致性保障)
8. [核心要点总结](#8-核心要点总结)

---

## 1. 🌐 什么是Redis分布式限流


### 1.1 为什么需要分布式限流


**场景理解**：想象一个电商网站的秒杀活动
```
单机限流问题：
用户请求 → 网关1(限流100/s) → 通过 ✅
用户请求 → 网关2(限流100/s) → 通过 ✅  
用户请求 → 网关3(限流100/s) → 通过 ✅

结果：实际通过了300/s，限流失效！
```

**🔸 核心问题**
- **多实例场景**：微服务架构下，网关通常部署多个实例
- **本地限流缺陷**：每个实例独立计数，无法全局控制
- **需要统一计数**：所有实例共享同一个计数器

**💡 解决方案**：使用Redis作为分布式计数器
```
所有网关实例 → 共享Redis计数器 → 全局限流准确

网关1 ↘
网关2 → Redis(统一计数) → 准确限流 ✅
网关3 ↗
```

### 1.2 Redis分布式限流的核心优势


| 优势特点 | **说明** | **对比本地限流** |
|---------|---------|-----------------|
| 🌍 **全局一致** | `所有实例共享同一限流规则` | `本地限流各自为政` |
| ⚡ **高性能** | `Redis内存操作，毫秒级响应` | `本地更快但不准确` |
| 🔄 **实时同步** | `计数实时更新，无延迟` | `多实例间无法同步` |
| 📊 **精准控制** | `精确到每秒/每分钟的请求数` | `多实例叠加超限` |

### 1.3 基本工作原理


**🔸 核心思路**
```
步骤1：请求到达网关
      ↓
步骤2：根据规则生成限流Key（如：user:123）
      ↓
步骤3：向Redis查询当前计数
      ↓
步骤4：判断是否超过限制
      ↓
步骤5：未超限 → 计数+1，放行请求
      超限   → 拒绝请求，返回429
```

**💭 通俗理解**
- Redis就像一个**公共计数器**，所有网关都来这里报数
- 每个用户/IP就像一个**独立的号码牌**
- 限流规则就是**规定时间内的配额**
- 超过配额就**暂停服务**

---

## 2. ⚙️ RequestRateLimiter配置详解


### 2.1 什么是RequestRateLimiter


**🔸 核心定义**
- **Gateway内置过滤器**：Spring Cloud Gateway提供的限流组件
- **基于令牌桶算法**：平滑的限流方式，允许突发流量
- **Redis支持**：默认使用Redis存储限流数据

**💡 通俗理解**
```
RequestRateLimiter = 请求速率限制器
就像高速公路收费站，控制车辆通过速度
```

### 2.2 基础配置方式


**📝 YAML配置示例**
```yaml
spring:
  cloud:
    gateway:
      routes:
        - id: user-service
          uri: lb://user-service
          predicates:
            - Path=/user/**
          filters:
            - name: RequestRateLimiter
              args:
                # 令牌桶填充速率（每秒放入多少令牌）
                redis-rate-limiter.replenishRate: 10
                # 令牌桶容量（最多存储多少令牌）
                redis-rate-limiter.burstCapacity: 20
                # 每次请求消耗的令牌数
                redis-rate-limiter.requestedTokens: 1
                # Key解析器（决定按什么维度限流）
                key-resolver: "#{@ipKeyResolver}"
```

### 2.3 核心参数详解


**🔹 replenishRate（补充速率）**
```
含义：每秒向令牌桶中添加多少个令牌
作用：控制平均请求速率
示例：replenishRate=10 → 每秒最多处理10个请求

理解：就像水龙头的流速，控制水流的快慢
```

**🔹 burstCapacity（突发容量）**
```
含义：令牌桶的最大容量
作用：允许短时间内的突发流量
示例：burstCapacity=20 → 最多允许20个请求同时通过

理解：就像水桶的大小，决定能存多少水
```

**🔹 requestedTokens（请求令牌数）**
```
含义：每个请求消耗的令牌数量
作用：控制单个请求的权重
示例：requestedTokens=1 → 普通请求消耗1个令牌
      requestedTokens=5 → 重要请求消耗5个令牌

理解：不同请求的"价格"不同
```

### 2.4 参数配置策略


**📊 常见配置场景**

| 场景 | **replenishRate** | **burstCapacity** | **说明** |
|-----|------------------|------------------|---------|
| 🔸 **严格限流** | `10` | `10` | `平均10/s，无突发允许` |
| 🔸 **允许突发** | `10` | `20` | `平均10/s，最高20/s` |
| 🔸 **宽松限流** | `100` | `200` | `平均100/s，峰值200/s` |
| 🔸 **动态限流** | `动态计算` | `动态计算` | `根据系统负载调整` |

**💡 配置建议**
```
✅ burstCapacity ≥ replenishRate（允许突发）
✅ 根据系统承载能力设置
✅ 预留20-30%的缓冲空间
✅ 监控实际流量，动态调整
```

---

## 3. 🔧 RedisRateLimiter实现原理


### 3.1 令牌桶算法核心思想


**🔸 令牌桶模型**
```
        令牌生成器
             |
             ↓ (replenishRate=10/s)
        ┌─────────┐
        │ 🪙🪙🪙🪙🪙 │ ← 令牌桶(burstCapacity=20)
        │ 🪙🪙🪙🪙🪙 │
        └─────────┘
             |
             ↓ (请求取令牌)
          请求通过

工作流程：
1. 令牌以恒定速率放入桶中
2. 桶满了，多余令牌丢弃
3. 请求来了，先取令牌
4. 有令牌→通过，无令牌→拒绝
```

**💭 生活类比**
```
令牌桶 = 游乐场的代币机
- 代币机每秒生产10个代币（replenishRate）
- 储币槽最多放20个代币（burstCapacity）
- 玩一次游戏需要1个代币（requestedTokens）
- 没代币了就得等新代币生成
```

### 3.2 RedisRateLimiter核心实现


**🔸 关键代码逻辑**
```java
public class RedisRateLimiter {
    
    // 核心限流方法
    public Mono<Response> isAllowed(String routeId, String id) {
        // 1. 生成Redis Key
        String prefix = "request_rate_limiter." + routeId;
        List<String> keys = Arrays.asList(
            prefix + "." + id + ".tokens",      // 令牌数Key
            prefix + "." + id + ".timestamp"    // 时间戳Key
        );
        
        // 2. 执行Lua脚本（原子操作）
        return redisTemplate.execute(script, keys, 
            replenishRate,    // 补充速率
            burstCapacity,    // 桶容量
            requestedTokens,  // 请求令牌数
            Instant.now().getEpochSecond()  // 当前时间
        );
    }
}
```

### 3.3 实现步骤详解


**步骤1：生成唯一Key**
```
Key组成：request_rate_limiter.{routeId}.{userId}

示例：
- request_rate_limiter.user-service.user123.tokens
- request_rate_limiter.user-service.user123.timestamp

作用：每个用户独立计数，互不干扰
```

**步骤2：计算可用令牌**
```java
// 伪代码逻辑
当前时间 - 上次请求时间 = 时间差
时间差 × 补充速率 = 新增令牌
当前令牌 + 新增令牌 = 总令牌（不超过桶容量）
```

**步骤3：判断是否放行**
```java
if (总令牌 >= 请求令牌数) {
    总令牌 -= 请求令牌数;
    更新Redis;
    return 允许通过;
} else {
    return 拒绝请求;
}
```

### 3.4 Redis数据结构


**🔸 存储内容**
```
Key: request_rate_limiter.user-service.user123.tokens
Value: 8.5（当前令牌数，可以是小数）

Key: request_rate_limiter.user-service.user123.timestamp  
Value: 1695456789（上次请求时间戳）

TTL: 自动过期时间（避免数据堆积）
```

**💡 为什么令牌数是小数？**
```
令牌补充是连续的，不是离散的
例如：0.5秒后，可能补充了5个令牌
计算更精确，避免误差累积
```

---

## 4. 📜 Lua脚本执行原理


### 4.1 为什么使用Lua脚本


**🔸 核心问题**：限流需要多步操作
```
传统方式的问题：
1. 读取当前令牌数   ← 步骤1
2. 计算新令牌数     ← 步骤2  
3. 判断是否超限     ← 步骤3
4. 更新令牌数       ← 步骤4

❌ 多步骤间可能被打断（并发问题）
❌ 两个请求同时读到相同令牌数
❌ 都以为可以通过，导致超限
```

**✅ Lua脚本的优势**
```
所有步骤作为一个整体执行
Redis保证Lua脚本的原子性
其他请求必须等待脚本执行完
完全避免并发问题
```

### 4.2 限流Lua脚本详解


**📝 完整Lua脚本**
```lua
-- KEYS[1]: 令牌数Key
-- KEYS[2]: 时间戳Key
-- ARGV[1]: 补充速率(replenishRate)
-- ARGV[2]: 桶容量(burstCapacity)  
-- ARGV[3]: 请求令牌数(requestedTokens)
-- ARGV[4]: 当前时间戳

local tokens_key = KEYS[1]
local timestamp_key = KEYS[2]

local rate = tonumber(ARGV[1])          -- 每秒补充速率
local capacity = tonumber(ARGV[2])      -- 令牌桶容量
local requested = tonumber(ARGV[3])     -- 需要的令牌数
local now = tonumber(ARGV[4])           -- 当前时间

-- 获取上次填充时间
local last_tokens = tonumber(redis.call("get", tokens_key))
if last_tokens == nil then
  last_tokens = capacity  -- 首次请求，桶是满的
end

local last_refreshed = tonumber(redis.call("get", timestamp_key))
if last_refreshed == nil then
  last_refreshed = now
end

-- 计算时间差和新增令牌
local delta = math.max(0, now - last_refreshed)
local filled_tokens = math.min(capacity, last_tokens + (delta * rate))

-- 判断令牌是否足够
local allowed = filled_tokens >= requested
local new_tokens = filled_tokens

if allowed then
  new_tokens = filled_tokens - requested  -- 扣除令牌
end

-- 更新Redis数据
redis.call("setex", tokens_key, 10, new_tokens)
redis.call("setex", timestamp_key, 10, now)

-- 返回结果
return { allowed, new_tokens }
```

### 4.3 脚本执行流程图示


```
请求到达
   |
   ↓
┌─────────────────┐
│ Lua脚本开始执行  │
│  (原子性保证)    │
└─────────────────┘
   |
   ↓
读取令牌数和时间戳
   |
   ↓
计算新增令牌数
filled = last + (now-last_time) × rate
   |
   ↓
判断令牌是否足够？
   |
   ├─ 是 → 扣除令牌 → 更新Redis → 返回允许
   |
   └─ 否 → 保持原样 → 返回拒绝
```

### 4.4 Lua脚本核心优势


**🔸 原子性保障**
```
整个限流逻辑作为一个事务执行
中间不会被其他请求打断
避免了竞态条件（Race Condition）
```

**🔸 性能优势**
```
✅ 减少网络往返：多个Redis操作合并成一次
✅ 服务端执行：计算在Redis服务器完成
✅ 内存操作：Redis内存速度极快
```

**🔸 一致性保证**
```
所有网关实例执行相同的Lua脚本
逻辑完全一致，不会出现差异
分布式环境下保证计数准确
```

---

## 5. 🔗 Redis连接池配置


### 5.1 为什么需要连接池


**🔸 问题场景**
```
没有连接池：
请求1 → 创建连接 → 执行 → 关闭连接
请求2 → 创建连接 → 执行 → 关闭连接
...

❌ 频繁创建/销毁连接，性能差
❌ 网络开销大
❌ Redis服务器压力大
```

**✅ 连接池方案**
```
连接池(8个连接)
┌─────────────┐
│ conn1  conn2│ ← 复用连接
│ conn3  conn4│
│ conn5  conn6│
│ conn7  conn8│
└─────────────┘
   ↑      ↑
   |      |
请求1  请求2（借用已有连接）
```

### 5.2 Lettuce连接池配置


**📝 依赖配置**
```xml
<!-- Spring Boot Redis Starter（默认使用Lettuce） -->
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-data-redis</artifactId>
</dependency>

<!-- 连接池依赖 -->
<dependency>
    <groupId>org.apache.commons</groupId>
    <artifactId>commons-pool2</artifactId>
</dependency>
```

**📝 YAML配置**
```yaml
spring:
  redis:
    host: 127.0.0.1
    port: 6379
    password: your_password
    database: 0
    timeout: 3000ms          # 连接超时时间
    
    lettuce:
      pool:
        # 最大连接数（峰值流量所需）
        max-active: 8
        # 最大空闲连接数
        max-idle: 8
        # 最小空闲连接数（保持常驻）
        min-idle: 2
        # 连接耗尽时最大等待时间
        max-wait: 3000ms
        # 空闲连接检测周期
        time-between-eviction-runs: 60000ms
```

### 5.3 核心参数详解


**🔹 max-active（最大活跃连接）**
```
含义：连接池允许的最大连接数
推荐：根据并发量设置
计算：预期QPS ÷ 单连接处理能力

示例：
- 1000 QPS，单连接1000次/s → max-active=2
- 高峰2000 QPS → max-active=4（预留缓冲）
```

**🔹 max-idle & min-idle（空闲连接数）**
```
max-idle：最大空闲连接（通常等于max-active）
min-idle：最小空闲连接（保持热备）

设置原则：
✅ max-idle = max-active（避免频繁创建/销毁）
✅ min-idle = 预期并发的30-50%（快速响应）
```

**🔹 max-wait（最大等待时间）**
```
含义：连接池满时，新请求最多等待多久
推荐：3-5秒
超时处理：返回503（服务暂时不可用）

示例：
max-wait=3000ms → 等待3秒获取不到连接就失败
```

### 5.4 连接池监控与调优


**📊 关键监控指标**
```
✅ 活跃连接数：当前正在使用的连接
✅ 空闲连接数：可用但未使用的连接
✅ 等待线程数：等待获取连接的请求
✅ 连接创建次数：频繁创建说明池太小
```

**🔧 调优建议**
```yaml
# 场景1：高并发、低延迟
max-active: 20      # 充足连接
min-idle: 10        # 保持热备
max-wait: 1000ms    # 快速失败

# 场景2：低并发、节省资源  
max-active: 5
min-idle: 2
max-wait: 5000ms

# 场景3：稳定流量
max-active: 10
min-idle: 5（保持50%空闲）
max-wait: 3000ms
```

---

## 6. 🔑 KeyResolver键生成策略


### 6.1 什么是KeyResolver


**🔸 核心作用**
```
KeyResolver = 限流维度决定器
决定按照什么规则生成限流的Key
不同Key代表不同的限流对象

通俗理解：
- Key就像"身份证号"
- 相同Key的请求共享限流配额
- 不同Key的请求独立计数
```

**💡 为什么需要KeyResolver**
```
场景问题：
- 按用户限流？user123和user456分开计数
- 按IP限流？192.168.1.1和192.168.1.2分开计数
- 按接口限流？/user和/order分开计数

KeyResolver就是用来区分这些维度的
```

### 6.2 常用KeyResolver实现


**🔹 按IP限流**
```java
@Bean
public KeyResolver ipKeyResolver() {
    return exchange -> {
        // 获取客户端IP地址
        String ip = exchange.getRequest()
            .getRemoteAddress()
            .getAddress()
            .getHostAddress();
        
        return Mono.just(ip);
    };
}

// 效果：
// 192.168.1.1 → 独立限流配额
// 192.168.1.2 → 独立限流配额
```

**🔹 按用户限流**
```java
@Bean
public KeyResolver userKeyResolver() {
    return exchange -> {
        // 从请求头获取用户ID
        String userId = exchange.getRequest()
            .getHeaders()
            .getFirst("X-User-Id");
        
        // 未登录用户使用IP
        if (userId == null) {
            return Mono.just(getIp(exchange));
        }
        
        return Mono.just(userId);
    };
}

// 效果：
// user123 → 每秒10次
// user456 → 每秒10次
```

**🔹 按接口路径限流**
```java
@Bean  
public KeyResolver pathKeyResolver() {
    return exchange -> {
        // 获取请求路径
        String path = exchange.getRequest()
            .getPath()
            .value();
        
        return Mono.just(path);
    };
}

// 效果：
// /user/** → 共享100/s配额
// /order/** → 共享50/s配额
```

**🔹 组合维度限流**
```java
@Bean
public KeyResolver compositeKeyResolver() {
    return exchange -> {
        String userId = getUserId(exchange);
        String path = getPath(exchange);
        
        // 组合Key：user123:/user/info
        String key = userId + ":" + path;
        return Mono.just(key);
    };
}

// 效果：
// user123访问/user → 独立配额
// user123访问/order → 独立配额  
// user456访问/user → 独立配额
```

### 6.3 KeyResolver配置使用


**📝 配置方式**
```yaml
spring:
  cloud:
    gateway:
      routes:
        - id: user-service
          filters:
            - name: RequestRateLimiter
              args:
                # 指定使用哪个KeyResolver
                key-resolver: "#{@ipKeyResolver}"
                
        - id: order-service  
          filters:
            - name: RequestRateLimiter
              args:
                key-resolver: "#{@userKeyResolver}"
```

### 6.4 KeyResolver选择策略


**📊 场景对比**

| 限流维度 | **KeyResolver** | **适用场景** | **优缺点** |
|---------|----------------|-------------|-----------|
| 🌐 **IP限流** | `ipKeyResolver` | `防止单个IP攻击` | `✅简单 ❌代理IP误伤` |
| 👤 **用户限流** | `userKeyResolver` | `会员分级限流` | `✅精准 ❌需要登录` |
| 📍 **路径限流** | `pathKeyResolver` | `接口级保护` | `✅灵活 ❌粒度粗` |
| 🔗 **组合限流** | `compositeKeyResolver` | `精细化控制` | `✅精确 ❌配置复杂` |

**🔧 选择建议**
```
✅ 公开接口：使用IP限流（防刷）
✅ 用户接口：使用用户限流（公平分配）
✅ 核心接口：组合限流（user+path）
✅ 内部接口：路径限流（接口保护）
```

---

## 7. ⚖️ 分布式限流一致性保障


### 7.1 一致性问题分析


**🔸 分布式环境的挑战**
```
网关集群场景：
网关1 ──┐
网关2 ──┼─→ Redis（共享计数器）
网关3 ──┘

潜在问题：
1. 时钟不同步 → 时间戳计算误差
2. 网络延迟 → 数据更新延迟
3. Redis主从延迟 → 读写不一致
```

### 7.2 Lua脚本保证原子性


**🔸 单机一致性**
```
问题：并发请求同时修改计数器

解决：Lua脚本原子执行
┌─────────────────┐
│  请求1  请求2    │
│    ↓     ↓      │
│  ┌─────────┐    │
│  │Lua脚本  │    │ ← 串行执行
│  │(原子)   │    │
│  └─────────┘    │
│    ↓            │
│  结果一致        │
└─────────────────┘

保证：同一时刻只有一个脚本在执行
```

### 7.3 时钟同步解决方案


**🔸 NTP时间同步**
```bash
# 配置NTP服务器
sudo apt-get install ntp
sudo systemctl enable ntp
sudo systemctl start ntp

# 验证时间同步
ntpq -p

# 确保所有网关节点时间误差<100ms
```

**🔸 使用Redis时间**
```lua
-- 不依赖本地时钟，使用Redis TIME命令
local redis_time = redis.call('TIME')
local now = tonumber(redis_time[1])  -- Redis服务器时间

-- 所有节点使用统一的Redis时间
-- 避免本地时钟差异
```

### 7.4 Redis主从一致性


**🔸 主从延迟问题**
```
写操作 → Redis主库 → 异步复制 → Redis从库
                           ↓
                      有延迟（ms级）

问题：
1. 网关1写入主库（限流计数+1）
2. 网关2读取从库（旧数据，未+1）
3. 可能导致超限放行
```

**✅ 解决方案**

**方案1：强制读主库**
```java
@Bean
public LettuceConnectionFactory redisConnectionFactory() {
    LettuceClientConfiguration clientConfig = 
        LettuceClientConfiguration.builder()
            .readFrom(ReadFrom.MASTER)  // 强制读主库
            .build();
    
    return new LettuceConnectionFactory(
        redisStandaloneConfiguration, clientConfig);
}

优点：数据强一致
缺点：主库压力大
```

**方案2：使用Redis Cluster**
```yaml
spring:
  redis:
    cluster:
      nodes:
        - 192.168.1.1:6379
        - 192.168.1.2:6379
        - 192.168.1.3:6379
      max-redirects: 3

优点：
- 数据分片，压力分散
- 去中心化，高可用
- 最终一致性可接受
```

**方案3：监控并告警**
```java
@Component
public class ReplicationMonitor {
    
    @Scheduled(fixedRate = 10000)
    public void checkReplicationLag() {
        // 检查主从延迟
        long lag = getReplicationLag();
        
        if (lag > 100) {  // 超过100ms
            // 告警：主从延迟过高
            alertService.send("Redis主从延迟: " + lag + "ms");
        }
    }
}
```

### 7.5 网络分区处理


**🔸 网络分区场景**
```
正常：
网关 ←→ Redis ✅

分区：
网关 ←X→ Redis ❌
  ↓
无法获取限流数据

处理策略？
```

**✅ 容错方案**
```java
public Mono<Response> isAllowed(String key) {
    return redisRateLimiter.isAllowed(key)
        .onErrorResume(throwable -> {
            // Redis不可用时的降级策略
            
            // 策略1：直接拒绝（保守）
            // return Mono.just(new Response(false, 0));
            
            // 策略2：直接放行（激进）
            // return Mono.just(new Response(true, 0));
            
            // 策略3：本地限流（折中）
            return localRateLimiter.isAllowed(key);
        });
}
```

**📊 降级策略选择**

| 策略 | **适用场景** | **优缺点** |
|-----|------------|-----------|
| 🚫 **直接拒绝** | `金融、支付系统` | `✅安全 ❌影响用户` |
| ✅ **直接放行** | `内容展示系统` | `✅体验好 ❌可能过载` |
| ⚖️ **本地限流** | `一般业务系统` | `✅平衡 ❌不够精确` |

### 7.6 一致性保障最佳实践


**🔧 核心实践清单**
```
✅ Lua脚本保证单机原子性
✅ NTP同步所有节点时钟
✅ 使用Redis TIME避免时钟差异
✅ 限流读写使用Redis主库
✅ 监控主从延迟并告警
✅ 设计合理的降级策略
✅ 定期压测验证一致性
```

**📈 一致性监控指标**
```yaml
监控项:
  - 主从延迟时间
  - 限流准确率（实际QPS vs 配置限制）
  - Redis连接失败率
  - Lua脚本执行时间
  - 降级策略触发次数

告警阈值:
  - 主从延迟 > 100ms
  - 限流超限 > 5%
  - Redis失败率 > 1%
```

---

## 8. 📋 核心要点总结


### 8.1 必须掌握的核心概念


**🔸 Redis分布式限流本质**
```
多实例共享Redis计数器
通过Lua脚本保证原子操作
实现全局精准的流量控制
```

**🔸 RequestRateLimiter三要素**
```
replenishRate：每秒补充速率（平均流量）
burstCapacity：令牌桶容量（峰值流量）
requestedTokens：单次消耗令牌（请求权重）
```

**🔸 Lua脚本的价值**
```
✅ 原子性：多步操作一次完成
✅ 性能：减少网络往返
✅ 一致性：避免并发问题
```

**🔸 KeyResolver的作用**
```
决定限流维度：IP、用户、路径、组合
不同Key独立计数
实现灵活的限流策略
```

### 8.2 关键理解要点


**🔹 令牌桶 vs 漏桶**
```
令牌桶（Token Bucket）：
- 允许突发流量
- 平滑限流
- Gateway默认实现

漏桶（Leaky Bucket）：
- 强制匀速
- 严格限流
- 需自行实现
```

**🔹 分布式一致性保障**
```
1. Lua脚本 → 单Redis原子性
2. 时钟同步 → 时间计算准确
3. 读主库 → 避免主从延迟
4. 降级策略 → 故障容错
```

**🔹 连接池的重要性**
```
复用连接 → 减少开销
合理配置 → 平衡性能与资源
实时监控 → 动态调优
```

### 8.3 实际应用价值


**🎯 应用场景**
- ✅ **API网关限流**：保护后端服务
- ✅ **防刷接口**：避免恶意请求
- ✅ **流量整形**：平滑突发流量
- ✅ **分级限流**：VIP用户更高配额

**🔧 配置建议**
```yaml
# 通用配置模板
spring:
  cloud:
    gateway:
      routes:
        - id: api-route
          filters:
            - name: RequestRateLimiter
              args:
                redis-rate-limiter.replenishRate: 100
                redis-rate-limiter.burstCapacity: 200
                key-resolver: "#{@userKeyResolver}"
  
  redis:
    lettuce:
      pool:
        max-active: 10
        min-idle: 5
        max-wait: 3000ms
```

**📊 监控要点**
```
实时监控：
- 限流触发次数
- Redis响应时间  
- 连接池使用率
- 限流准确率

定期检查：
- 配置是否合理
- 是否需要调整
- 降级策略是否有效
```

**核心记忆**：
- Redis分布式限流解决多实例计数问题
- Lua脚本保证原子性，避免并发冲突
- 令牌桶算法平滑限流，允许突发
- KeyResolver决定限流维度，灵活控制
- 连接池提升性能，一致性需多方保障