---
title: 3、性能优化方案
---
## 📚 目录

1. [性能优化概述](#1-性能优化概述)
2. [预编译SQL使用](#2-预编译SQL使用)
3. [批处理优化](#3-批处理优化)
4. [连接池配置](#4-连接池配置)
5. [索引使用意识](#5-索引使用意识)
6. [短事务原则](#6-短事务原则)
7. [其他性能优化技巧](#7-其他性能优化技巧)
8. [性能监控与调优](#8-性能监控与调优)
9. [核心要点总结](#9-核心要点总结)

---

## 1. 🚀 性能优化概述


### 1.1 什么是数据库性能优化


**简单理解**：就像汽车跑得快慢一样，数据库操作也有快慢之分。性能优化就是让数据库跑得更快、更省油。

```
常见的性能问题：
😫 查询速度慢 → 用户等待时间长
😫 内存消耗大 → 服务器压力大
😫 CPU占用高 → 影响其他程序运行
😫 连接数过多 → 数据库拒绝服务
```

### 1.2 性能优化的核心思路


**优化金字塔**：
```
              减少不必要操作
             ──────────────
           提高单次操作效率
          ──────────────────
        合理利用数据库资源
       ──────────────────────
     选择正确的技术和工具
    ────────────────────────

从上到下，影响越来越大
```

### 1.3 十大性能优化铁律一览


| 序号 | **优化铁律** | **核心思想** | **性能提升** |
|------|------------|------------|------------|
| 1️⃣ | **预编译SQL** | `一次编译，多次执行` | `10-50倍提升` |
| 2️⃣ | **批处理操作** | `批量处理，减少网络开销` | `5-20倍提升` |
| 3️⃣ | **连接池管理** | `复用连接，避免重复创建` | `3-10倍提升` |
| 4️⃣ | **合理使用索引** | `快速定位数据` | `100-1000倍提升` |
| 5️⃣ | **短事务原则** | `减少锁定时间` | `2-5倍提升` |
| 6️⃣ | **结果集控制** | `只查询需要的数据` | `2-10倍提升` |
| 7️⃣ | **缓存策略** | `避免重复查询` | `10-100倍提升` |
| 8️⃣ | **异步处理** | `不阻塞主线程` | `用户体验提升` |
| 9️⃣ | **数据库分页** | `减少内存消耗` | `内存节省90%+` |
| 🔟 | **监控调优** | `持续改进` | `整体性能提升` |

---

## 2. 🔧 预编译SQL使用


### 2.1 什么是预编译SQL


**生活类比**：就像做菜的流程
- **普通SQL**：每次做菜都要重新想菜谱、买菜、洗菜、切菜、炒菜
- **预编译SQL**：提前准备好菜谱和处理好的食材，每次只需要炒菜

```java
// ❌ 错误做法：每次都重新编译
String sql = "SELECT * FROM users WHERE name = '" + userName + "'";
Statement stmt = conn.createStatement();
ResultSet rs = stmt.executeQuery(sql);

// ✅ 正确做法：预编译，重复使用
String sql = "SELECT * FROM users WHERE name = ?";
PreparedStatement pstmt = conn.prepareStatement(sql);
pstmt.setString(1, userName);
ResultSet rs = pstmt.executeQuery();
```

### 2.2 预编译的工作原理


**SQL执行的完整流程**：
```
普通Statement执行过程：
用户请求 → SQL解析 → 编译优化 → 执行计划 → 执行 → 返回结果
   ↑         ↑        ↑         ↑
每次都要重复这些步骤，很浪费时间

PrepadStatement执行过程：
第一次：用户请求 → SQL解析 → 编译优化 → 执行计划 → 缓存
后续：用户请求 → 直接使用缓存的执行计划 → 执行 → 返回结果
```

**性能差异对比**：
```
测试场景：查询10000次用户信息

普通Statement：
- 第1次查询：20ms (解析+编译+执行)
- 第2次查询：20ms (重新解析+编译+执行)
- ...
- 总耗时：20ms × 10000 = 200秒

PreparedStatement：
- 第1次查询：20ms (解析+编译+执行+缓存)
- 第2次查询：2ms (直接执行)
- ...
- 总耗时：20ms + 2ms × 9999 ≈ 20秒

性能提升：200秒 → 20秒 = 10倍提升！
```

### 2.3 预编译最佳实践


**✅ 推荐做法**：
```java
public class UserDAO {
    // 在类级别定义SQL模板
    private static final String SELECT_USER = "SELECT * FROM users WHERE id = ?";
    private static final String UPDATE_USER = "UPDATE users SET name = ? WHERE id = ?";
    
    public User findById(int userId) {
        try (PreparedStatement pstmt = conn.prepareStatement(SELECT_USER)) {
            pstmt.setInt(1, userId);
            ResultSet rs = pstmt.executeQuery();
            // 处理结果...
        }
    }
}
```

**⚠️ 注意事项**：
- **参数化查询**：所有用户输入都用`?`占位符
- **防SQL注入**：预编译天然防止SQL注入攻击
- **类型安全**：`setInt()`、`setString()`等方法确保类型正确

---

## 3. 🚄 批处理优化


### 3.1 什么是批处理


**快递类比**：
- **普通做法**：每个包裹单独送一趟 → 送100个包裹要跑100趟
- **批处理**：把包裹装满一车再送 → 送100个包裹可能只需要5趟

```java
// ❌ 效率低下：一个一个插入
for (User user : userList) {
    String sql = "INSERT INTO users (name, email) VALUES (?, ?)";
    PreparedStatement pstmt = conn.prepareStatement(sql);
    pstmt.setString(1, user.getName());
    pstmt.setString(2, user.getEmail());
    pstmt.executeUpdate(); // 每次都发送到数据库
}

// ✅ 高效批处理：打包一起发送
String sql = "INSERT INTO users (name, email) VALUES (?, ?)";
PreparedStatement pstmt = conn.prepareStatement(sql);

for (User user : userList) {
    pstmt.setString(1, user.getName());
    pstmt.setString(2, user.getEmail());
    pstmt.addBatch(); // 添加到批次中
}
pstmt.executeBatch(); // 一次性执行所有操作
```

### 3.2 批处理的性能优势


**网络开销对比**：
```
插入1000条记录的对比：

单条插入：
客户端 ←→ 数据库 (往返1000次)
- 网络延迟：1ms × 1000 = 1000ms
- 数据传输时间：每次很少
- 总耗时：很长

批处理插入：
客户端 ←→ 数据库 (往返1次)
- 网络延迟：1ms × 1 = 1ms  
- 数据传输时间：一次性传输所有
- 总耗时：大大缩短
```

### 3.3 批处理实战技巧


**智能分批处理**：
```java
public void batchInsertUsers(List<User> users) {
    final int BATCH_SIZE = 1000; // 批次大小
    String sql = "INSERT INTO users (name, email, age) VALUES (?, ?, ?)";
    
    try (PreparedStatement pstmt = conn.prepareStatement(sql)) {
        int count = 0;
        
        for (User user : users) {
            pstmt.setString(1, user.getName());
            pstmt.setString(2, user.getEmail());
            pstmt.setInt(3, user.getAge());
            pstmt.addBatch();
            
            count++;
            // 达到批次大小时执行一次
            if (count % BATCH_SIZE == 0) {
                pstmt.executeBatch();
                pstmt.clearBatch(); // 清空当前批次
            }
        }
        
        // 处理最后不满一批的数据
        if (count % BATCH_SIZE != 0) {
            pstmt.executeBatch();
        }
    }
}
```

**批处理适用场景**：
- ✅ **批量插入**：导入大量数据
- ✅ **批量更新**：修改多条记录
- ✅ **批量删除**：清理过期数据
- ❌ **查询操作**：批处理对查询无效

---

## 4. 🏊‍♂️ 连接池配置


### 4.1 为什么需要连接池


**游泳池类比**：
- **没有连接池**：每次游泳都要挖一个新池子，游完就填埋 → 浪费时间和资源
- **有连接池**：提前准备好几个池子，大家轮流使用 → 高效利用资源

```
数据库连接的创建过程：
1. 建立TCP连接 ────────→ 耗时100-200ms
2. 用户身份验证 ────────→ 耗时50-100ms  
3. 设置连接参数 ────────→ 耗时20-50ms
4. 准备就绪可以使用 ──→ 总计200-350ms

如果每次操作都创建新连接：
- 执行SQL：5ms
- 创建连接：300ms
- 总耗时：305ms (98%的时间在创建连接！)
```

### 4.2 连接池工作原理


**连接池生命周期**：
```
系统启动阶段：
┌─────────────────────────────┐
│ 连接池初始化                  │
│ ├─ 创建5个初始连接            │
│ ├─ 放入连接池中               │
│ └─ 等待应用程序使用           │
└─────────────────────────────┘

运行阶段：
应用请求 → 从池中获取连接 → 执行SQL → 归还连接到池中
  ↑                                      ↓
  └──────── 连接复用，避免重复创建 ←─────────┘

关闭阶段：
连接池关闭 → 逐个关闭所有连接 → 释放资源
```

### 4.3 连接池配置实战


**HikariCP配置示例**（目前最快的连接池）：
```properties
# 数据库连接配置
spring.datasource.url=jdbc:mysql://localhost:3306/testdb
spring.datasource.username=root
spring.datasource.password=123456

# HikariCP连接池配置
spring.datasource.hikari.minimum-idle=5          # 最小空闲连接数
spring.datasource.hikari.maximum-pool-size=20    # 最大连接数
spring.datasource.hikari.idle-timeout=300000     # 空闲超时时间(5分钟)
spring.datasource.hikari.max-lifetime=1200000    # 连接最大生存时间(20分钟)
spring.datasource.hikari.connection-timeout=20000 # 获取连接超时时间(20秒)
```

**连接池大小如何设置**：
```
经验公式：
连接池大小 = CPU核数 × 2 + 磁盘数量

例如：4核CPU + 1个磁盘 = 4 × 2 + 1 = 9个连接

实际考虑因素：
- 🔸 并发用户数：100个用户同时访问可能需要10-20个连接
- 🔸 业务复杂度：复杂查询耗时长，需要更多连接
- 🔸 数据库性能：数据库越快，需要连接越少
- 🔸 应用服务器：多个服务器要分摊连接数

推荐设置：
- 小型应用：5-10个连接
- 中型应用：10-50个连接  
- 大型应用：50-200个连接
```

---

## 5. 📊 索引使用意识


### 5.1 什么是数据库索引


**图书馆类比**：
- **没有索引**：要找一本书，只能从第一排书架开始，一本一本翻 → 可能找几个小时
- **有索引**：就像图书馆的目录卡片，直接告诉你书在哪个书架 → 几分钟就能找到

```
假设用户表有100万条记录：

没有索引的查询：
SELECT * FROM users WHERE email = 'john@example.com';
↓
数据库从第1条记录开始，逐条检查email字段
可能需要检查50万条记录才能找到 (平均情况)
耗时：5-10秒

有索引的查询：
CREATE INDEX idx_email ON users(email);
SELECT * FROM users WHERE email = 'john@example.com';
↓  
数据库直接定位到email='john@example.com'的记录
只需要检查1-3条记录
耗时：0.01秒

性能提升：500-1000倍！
```

### 5.2 索引的类型和用法


**主要索引类型**：

| 索引类型 | **适用场景** | **优势** | **注意事项** |
|---------|------------|---------|------------|
| **主键索引** | `id字段` | `查询最快，唯一性` | `每个表只能有一个` |
| **唯一索引** | `email、手机号` | `保证唯一性，查询快` | `不能有重复值` |
| **普通索引** | `姓名、状态字段` | `提升查询速度` | `可以有重复值` |
| **复合索引** | `多字段查询` | `多条件查询优化` | `字段顺序很重要` |

**索引创建示例**：
```sql
-- 为经常查询的字段创建索引
CREATE INDEX idx_user_name ON users(name);           -- 姓名索引
CREATE INDEX idx_user_email ON users(email);         -- 邮箱索引
CREATE INDEX idx_user_status ON users(status);       -- 状态索引

-- 复合索引：按姓名和年龄查询
CREATE INDEX idx_name_age ON users(name, age);

-- 使用索引的查询
SELECT * FROM users WHERE name = '张三';              -- 走idx_user_name索引
SELECT * FROM users WHERE email = 'test@qq.com';     -- 走idx_user_email索引
SELECT * FROM users WHERE name = '张三' AND age = 25; -- 走idx_name_age索引
```

### 5.3 索引使用的黄金法则


**✅ 应该创建索引的情况**：
```sql
-- 1. 经常用作查询条件的字段
WHERE name = '张三'           → 给name字段加索引
WHERE email = 'xx@qq.com'    → 给email字段加索引

-- 2. 经常用于排序的字段
ORDER BY create_time         → 给create_time字段加索引

-- 3. 经常用于连接查询的字段
FROM users u JOIN orders o ON u.id = o.user_id  → 给user_id加索引
```

**❌ 不应该创建索引的情况**：
- **很少查询的字段**：创建了也用不上，浪费空间
- **数据变化频繁的字段**：每次更新都要维护索引，影响性能
- **数据重复度很高的字段**：比如性别字段只有男/女两个值

---

## 6. ⏱️ 短事务原则


### 6.1 什么是数据库事务


**银行转账类比**：
```
张三给李四转账1000元：
1. 检查张三账户余额是否足够
2. 从张三账户扣除1000元  
3. 给李四账户增加1000元
4. 记录转账日志

这4个步骤必须要么全部成功，要么全部失败
这就是一个事务！
```

**事务的四大特性（ACID）**：
- **原子性（A）**：要么全做，要么全不做
- **一致性（C）**：数据始终保持正确状态
- **隔离性（I）**：不同事务之间互不干扰
- **持久性（D）**：提交后的数据永久保存

### 6.2 为什么要保持事务简短


**餐厅包间类比**：
- **长事务**：一个客人包了个包间，从中午12点坐到晚上10点，期间其他客人都用不了
- **短事务**：客人吃完就走，包间可以接待更多客人

```java
// ❌ 长事务示例：容易造成死锁
@Transactional
public void badExample(Long userId) {
    // 开始事务
    User user = userService.findById(userId);
    
    // 复杂业务逻辑，耗时很长
    Thread.sleep(10000); // 模拟复杂计算
    
    // 调用外部API，网络延迟不确定
    String result = callExternalAPI();
    
    // 大量数据处理
    processLargeDataSet();
    
    // 更新用户信息
    userService.update(user);
    // 提交事务
}

// ✅ 短事务示例：快进快出
public void goodExample(Long userId) {
    // 事务外完成复杂计算
    User user = userService.findById(userId);
    String result = callExternalAPI();
    processLargeDataSet();
    
    // 只在必要时开启事务
    @Transactional
    userService.update(user);
}
```

### 6.3 短事务最佳实践


**事务范围控制**：
```java
@Service
public class OrderService {
    
    // ✅ 正确：事务只包含数据库操作
    @Transactional
    public void createOrder(Order order) {
        orderDAO.insert(order);                    // 插入订单
        productDAO.updateStock(order.getProductId()); // 更新库存
        // 事务结束，快速释放数据库锁
    }
    
    // 复杂的业务逻辑在事务外处理
    public void processOrder(Order order) {
        // 验证订单信息
        validateOrder(order);
        
        // 计算价格（复杂逻辑）
        calculatePrice(order);
        
        // 发送短信通知（外部调用）
        sendSmsNotification(order);
        
        // 最后才开启事务保存数据
        createOrder(order);
    }
}
```

**事务粒度建议**：
- **微事务**：单表操作，耗时 < 10ms
- **小事务**：2-3个表操作，耗时 < 100ms  
- **中事务**：复杂业务，耗时 < 1s
- **避免大事务**：耗时 > 5s的操作要拆分

---

## 7. 🔧 其他性能优化技巧


### 7.1 结果集控制


**只查询需要的数据**：
```java
// ❌ 查询所有字段：浪费网络带宽和内存
SELECT * FROM users WHERE status = 'active';

// ✅ 只查询需要的字段
SELECT id, name, email FROM users WHERE status = 'active';

// ❌ 查询所有数据：可能返回百万条记录
SELECT * FROM orders;

// ✅ 分页查询：每次只查20条
SELECT * FROM orders ORDER BY create_time DESC LIMIT 0, 20;
```

**合理使用分页**：
```java
public class OrderService {
    
    // 分页查询实现
    public PageResult<Order> getOrders(int pageNum, int pageSize) {
        int offset = (pageNum - 1) * pageSize;
        
        // 查询总数
        int totalCount = orderDAO.countOrders();
        
        // 查询当前页数据
        List<Order> orders = orderDAO.findOrders(offset, pageSize);
        
        return new PageResult<>(orders, totalCount, pageNum, pageSize);
    }
}
```

### 7.2 适当使用缓存


**缓存策略**：
```java
@Service  
public class UserService {
    
    @Autowired
    private RedisTemplate redisTemplate;
    
    public User getUserById(Long userId) {
        // 1. 先查缓存
        String cacheKey = "user:" + userId;
        User user = (User) redisTemplate.opsForValue().get(cacheKey);
        
        if (user != null) {
            return user; // 缓存命中，直接返回
        }
        
        // 2. 缓存未命中，查数据库
        user = userDAO.findById(userId);
        
        // 3. 放入缓存，设置过期时间
        if (user != null) {
            redisTemplate.opsForValue().set(cacheKey, user, 300, TimeUnit.SECONDS);
        }
        
        return user;
    }
}
```

### 7.3 异步处理非关键操作


```java
@Service
public class OrderService {
    
    @Async  // 异步执行
    public void processOrderAsync(Order order) {
        // 发送邮件通知（耗时操作）
        emailService.sendOrderConfirmation(order);
        
        // 更新统计信息（非关键操作）
        statisticsService.updateOrderStats(order);
        
        // 同步到其他系统（外部调用）
        syncToExternalSystem(order);
    }
    
    public void createOrder(Order order) {
        // 核心操作：同步执行
        orderDAO.insert(order);
        
        // 非关键操作：异步执行
        processOrderAsync(order);
        
        // 用户立即得到响应，体验更好
    }
}
```

---

## 8. 📈 性能监控与调优


### 8.1 关键性能指标


**数据库性能监控指标**：

| 指标类型 | **关键指标** | **正常范围** | **异常警告** |
|---------|------------|------------|------------|
| **响应时间** | `平均查询时间` | `< 100ms` | `> 1000ms` |
| **并发性能** | `每秒查询数(QPS)` | `根据业务` | `突然下降50%+` |
| **资源使用** | `CPU使用率` | `< 70%` | `> 90%` |
| **资源使用** | `内存使用率` | `< 80%` | `> 95%` |
| **连接状态** | `活跃连接数` | `< 最大连接数80%` | `接近最大值` |

### 8.2 慢查询日志分析


**MySQL慢查询配置**：
```sql
-- 开启慢查询日志
SET GLOBAL slow_query_log = 'ON';

-- 设置慢查询阈值（超过1秒的查询会被记录）
SET GLOBAL long_query_time = 1;

-- 查看慢查询日志文件位置
SHOW VARIABLES LIKE 'slow_query_log_file';
```

**慢查询优化步骤**：
```
1. 识别慢查询
   ↓
2. 分析执行计划（EXPLAIN）
   ↓  
3. 检查是否缺少索引
   ↓
4. 优化SQL语句
   ↓
5. 验证优化效果
   ↓
6. 持续监控
```

### 8.3 实战调优案例


**案例：用户查询优化**
```sql
-- 原始慢查询（耗时3秒）
SELECT * FROM users 
WHERE create_time > '2024-01-01' 
AND status = 'active' 
ORDER BY create_time DESC;

-- 问题分析：
-- 1. 没有索引，全表扫描
-- 2. 查询了所有字段
-- 3. 排序耗时

-- 优化步骤：
-- 1. 创建复合索引
CREATE INDEX idx_status_createtime ON users(status, create_time);

-- 2. 只查询必要字段
SELECT id, name, email, create_time 
FROM users 
WHERE create_time > '2024-01-01' 
AND status = 'active' 
ORDER BY create_time DESC
LIMIT 50;

-- 优化结果：耗时从3秒降低到0.05秒，性能提升60倍！
```

---

## 9. 📋 核心要点总结


### 9.1 必须掌握的核心概念


```
🔸 预编译SQL：一次编译，多次执行，防止SQL注入
🔸 批处理操作：减少网络往返，提升大批量操作性能
🔸 连接池管理：复用数据库连接，避免重复创建开销
🔸 索引意识：为查询条件、排序字段创建合适索引
🔸 短事务原则：快进快出，减少数据库锁定时间
```

### 9.2 关键理解要点


**🔹 性能优化的本质**
```
核心思想：
- 减少不必要的操作 → 批处理、缓存
- 提高单次操作效率 → 索引、预编译
- 合理利用系统资源 → 连接池、异步处理

优化策略：
- 先解决最明显的性能瓶颈
- 数据驱动，通过监控找问题
- 循序渐进，避免过度优化
```

**🔹 开发中的实际应用**
```
日常开发checklist：
✅ 查询语句是否使用了PreparedStatement？
✅ 大批量操作是否使用了批处理？
✅ 频繁查询的字段是否有索引？
✅ 事务是否保持简短？
✅ 是否只查询必要的数据？
✅ 非关键操作是否异步处理？
```

### 9.3 实际应用价值


**💼 业务场景应用**
- **电商系统**：订单查询用索引，批量导入用批处理
- **用户系统**：登录验证用缓存，用户信息查询用预编译
- **报表系统**：大数据查询用分页，复杂统计用异步
- **内容管理**：文章搜索用索引，批量发布用事务

**🎯 性能提升效果**
- **查询速度**：通过索引提升10-1000倍
- **批处理**：大批量操作提升5-20倍
- **连接池**：减少连接创建开销90%+
- **缓存策略**：热点数据查询提升10-100倍

**核心记忆口诀**：
- 预编译防注入，批处理减网络
- 连接池要配好，索引不能少  
- 事务要简短，查询要精准
- 缓存来加速，异步提体验
- 监控找问题，优化无止境

**🔧 工程实践建议**
- **开发阶段**：养成性能意识，编写高质量SQL
- **测试阶段**：进行压力测试，识别性能瓶颈
- **生产阶段**：持续监控，及时调优
- **维护阶段**：定期分析慢查询，优化索引