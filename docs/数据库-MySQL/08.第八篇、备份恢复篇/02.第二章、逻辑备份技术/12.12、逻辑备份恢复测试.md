---
title: 12ã€é€»è¾‘å¤‡ä»½æ¢å¤æµ‹è¯•
---
## ğŸ“š ç›®å½•

1. [é€»è¾‘å¤‡ä»½æ¢å¤æµ‹è¯•æ¦‚è¿°](#1-é€»è¾‘å¤‡ä»½æ¢å¤æµ‹è¯•æ¦‚è¿°)
2. [æ¢å¤æ¼”ç»ƒæµç¨‹è®¾è®¡](#2-æ¢å¤æ¼”ç»ƒæµç¨‹è®¾è®¡)
3. [æµ‹è¯•ç¯å¢ƒå‡†å¤‡](#3-æµ‹è¯•ç¯å¢ƒå‡†å¤‡)
4. [æ¢å¤æ—¶é—´æµ‹é‡ä¸åˆ†æ](#4-æ¢å¤æ—¶é—´æµ‹é‡ä¸åˆ†æ)
5. [æ•°æ®ä¸€è‡´æ€§éªŒè¯](#5-æ•°æ®ä¸€è‡´æ€§éªŒè¯)
6. [ä¸šåŠ¡åŠŸèƒ½æµ‹è¯•](#6-ä¸šåŠ¡åŠŸèƒ½æµ‹è¯•)
7. [æ€§èƒ½å½±å“è¯„ä¼°](#7-æ€§èƒ½å½±å“è¯„ä¼°)
8. [è‡ªåŠ¨åŒ–æ¢å¤æµ‹è¯•](#8-è‡ªåŠ¨åŒ–æ¢å¤æµ‹è¯•)
9. [A/Bæ¢å¤å¯¹æ¯”æµ‹è¯•](#9-ABæ¢å¤å¯¹æ¯”æµ‹è¯•)
10. [æ¢å¤æµ‹è¯•å¹³å°å»ºè®¾](#10-æ¢å¤æµ‹è¯•å¹³å°å»ºè®¾)
11. [æ ¸å¿ƒè¦ç‚¹æ€»ç»“](#11-æ ¸å¿ƒè¦ç‚¹æ€»ç»“)

---

## 1. ğŸ¯ é€»è¾‘å¤‡ä»½æ¢å¤æµ‹è¯•æ¦‚è¿°


### 1.1 ä»€ä¹ˆæ˜¯æ¢å¤æµ‹è¯•


æ¢å¤æµ‹è¯•å°±æ˜¯å®šæœŸæ£€éªŒå¤‡ä»½æ–‡ä»¶èƒ½å¦çœŸæ­£æ¢å¤æ•°æ®åº“çš„è¿‡ç¨‹ã€‚ç®€å•è¯´ï¼Œå°±æ˜¯**éªŒè¯å¤‡ä»½ä¸æ˜¯æ‘†è®¾ï¼Œå…³é”®æ—¶åˆ»çœŸèƒ½æ•‘å‘½**ã€‚

```
ä¸ºä»€ä¹ˆè¦åšæ¢å¤æµ‹è¯•ï¼Ÿ

çœŸå®åœºæ™¯ï¼š
ç”Ÿäº§ç¯å¢ƒæ•°æ®ä¸¢å¤± â†’ ç´§æ€¥æ¢å¤ â†’ å‘ç°å¤‡ä»½æ–‡ä»¶æŸå
ç»“æœï¼šé›ªä¸ŠåŠ éœœï¼ŒæŸå¤±æƒ¨é‡

é¢„é˜²æªæ–½ï¼š
å®šæœŸæ¢å¤æ¼”ç»ƒ â†’ æå‰å‘ç°é—®é¢˜ â†’ ç¡®ä¿å¤‡ä»½å¯ç”¨
ç»“æœï¼šæœ‰å¤‡æ— æ‚£ï¼Œå¿ƒä¸­æœ‰åº•
```

**æ¢å¤æµ‹è¯•çš„æ ¸å¿ƒç›®æ ‡**ï¼š
- **éªŒè¯å¤‡ä»½å®Œæ•´æ€§**ï¼šç¡®ä¿å¤‡ä»½æ–‡ä»¶æ²¡æœ‰æŸå
- **æµ‹è¯•æ¢å¤æµç¨‹**ï¼šç¡®ä¿è¿ç»´äººå‘˜ç†Ÿç»ƒæŒæ¡æ¢å¤æ­¥éª¤
- **è¯„ä¼°æ¢å¤æ—¶é—´**ï¼šäº†è§£çœŸå®çš„æ¢å¤è€—æ—¶
- **æ£€æŸ¥æ•°æ®å®Œæ•´æ€§**ï¼šç¡®ä¿æ¢å¤åæ•°æ®æ­£ç¡®æ— è¯¯

### 1.2 æ¢å¤æµ‹è¯•çš„é‡è¦æ€§


```
å¤‡ä»½ä¸‰åŸåˆ™ï¼š
1. å¤‡ä»½ä¸ç­‰äºæ¢å¤
2. æ²¡æœ‰æµ‹è¯•è¿‡çš„å¤‡ä»½ä¸æ˜¯å¤‡ä»½
3. æ¢å¤èƒ½åŠ›å†³å®šå¤‡ä»½ä»·å€¼
```

**å¸¸è§çš„å¤‡ä»½é™·é˜±**ï¼š
- **å¤‡ä»½æˆåŠŸä½†æ¢å¤å¤±è´¥**ï¼šæ–‡ä»¶æŸåã€æƒé™é—®é¢˜
- **æ¢å¤æ—¶é—´è¿‡é•¿**ï¼šå½±å“ä¸šåŠ¡è¿ç»­æ€§
- **æ•°æ®ä¸å®Œæ•´**ï¼šéƒ¨åˆ†è¡¨æˆ–ç´¢å¼•ä¸¢å¤±
- **æ“ä½œä¸ç†Ÿç»ƒ**ï¼šå…³é”®æ—¶åˆ»æ‰‹å¿™è„šä¹±

---

## 2. ğŸ“‹ æ¢å¤æ¼”ç»ƒæµç¨‹è®¾è®¡


### 2.1 æ ‡å‡†æ¢å¤æ¼”ç»ƒæµç¨‹


æ¢å¤æ¼”ç»ƒéœ€è¦æŒ‰ç…§æ ‡å‡†åŒ–æµç¨‹æ‰§è¡Œï¼Œç¡®ä¿æ¯æ¬¡æµ‹è¯•éƒ½èƒ½å¾—åˆ°å¯é çš„ç»“æœã€‚

```
æ ‡å‡†æ¼”ç»ƒæµç¨‹ï¼š

é˜¶æ®µ1ï¼šå‡†å¤‡é˜¶æ®µ
â”œâ”€â”€ ç¡®å®šæµ‹è¯•æ—¶é—´çª—å£
â”œâ”€â”€ å‡†å¤‡æµ‹è¯•ç¯å¢ƒ
â”œâ”€â”€ æ£€æŸ¥å¤‡ä»½æ–‡ä»¶çŠ¶æ€
â””â”€â”€ é€šçŸ¥ç›¸å…³äººå‘˜

é˜¶æ®µ2ï¼šæ‰§è¡Œé˜¶æ®µ  
â”œâ”€â”€ è®°å½•å¼€å§‹æ—¶é—´
â”œâ”€â”€ æ‰§è¡Œæ¢å¤æ“ä½œ
â”œâ”€â”€ ç›‘æ§æ¢å¤è¿›åº¦
â””â”€â”€ è®°å½•å®Œæˆæ—¶é—´

é˜¶æ®µ3ï¼šéªŒè¯é˜¶æ®µ
â”œâ”€â”€ æ•°æ®å®Œæ•´æ€§æ£€æŸ¥
â”œâ”€â”€ ä¸šåŠ¡åŠŸèƒ½æµ‹è¯•
â”œâ”€â”€ æ€§èƒ½åŸºå‡†æµ‹è¯•
â””â”€â”€ é—®é¢˜è®°å½•æ•´ç†

é˜¶æ®µ4ï¼šæ€»ç»“é˜¶æ®µ
â”œâ”€â”€ æ›´æ–°æ¢å¤æ–‡æ¡£
â”œâ”€â”€ ä¼˜åŒ–æ¢å¤æµç¨‹
â”œâ”€â”€ åŸ¹è®­è¿ç»´äººå‘˜
â””â”€â”€ åˆ¶å®šæ”¹è¿›è®¡åˆ’
```

### 2.2 æ¼”ç»ƒé¢‘ç‡ä¸æ—¶æœº


**æ¼”ç»ƒé¢‘ç‡å»ºè®®**ï¼š
- **æ ¸å¿ƒä¸šåŠ¡æ•°æ®åº“**ï¼šæ¯æœˆä¸€æ¬¡
- **é‡è¦ä¸šåŠ¡æ•°æ®åº“**ï¼šæ¯å­£åº¦ä¸€æ¬¡  
- **ä¸€èˆ¬ä¸šåŠ¡æ•°æ®åº“**ï¼šæ¯åŠå¹´ä¸€æ¬¡
- **å¼€å‘æµ‹è¯•æ•°æ®åº“**ï¼šæ¯å¹´ä¸€æ¬¡

**æœ€ä½³æ¼”ç»ƒæ—¶æœº**ï¼š
```sql
-- ç¤ºä¾‹ï¼šå‘¨æœ«å‡Œæ™¨æ‰§è¡Œæ¢å¤æµ‹è¯•
-- 1. é€‰æ‹©ä¸šåŠ¡ä½å³°æœŸ
-- 2. ç¡®ä¿è¶³å¤Ÿçš„æ—¶é—´çª—å£
-- 3. æœ‰æŠ€æœ¯äººå‘˜å€¼ç­

SELECT 
    CASE DAYOFWEEK(NOW())
        WHEN 1 THEN 'å‘¨æ—¥å‡Œæ™¨2-6ç‚¹'
        WHEN 7 THEN 'å‘¨å…­å‡Œæ™¨2-6ç‚¹'
        ELSE 'å·¥ä½œæ—¥ä¸å»ºè®®'
    END AS recommended_time;
```

---

## 3. ğŸ› ï¸ æµ‹è¯•ç¯å¢ƒå‡†å¤‡


### 3.1 æµ‹è¯•ç¯å¢ƒè¦æ±‚


æµ‹è¯•ç¯å¢ƒè¦å°½é‡æ¨¡æ‹Ÿç”Ÿäº§ç¯å¢ƒï¼Œä½†åˆè¦ä¸ç”Ÿäº§ç¯å¢ƒå®Œå…¨éš”ç¦»ã€‚

**ç¯å¢ƒé…ç½®åŸåˆ™**ï¼š
```
ç¡¬ä»¶é…ç½®ï¼š
âœ… CPU/å†…å­˜ï¼šç”Ÿäº§ç¯å¢ƒçš„50-70%
âœ… ç£ç›˜IOï¼šä¸ç”Ÿäº§ç¯å¢ƒç›¸è¿‘
âœ… ç½‘ç»œå¸¦å®½ï¼šæ»¡è¶³æ•°æ®ä¼ è¾“éœ€æ±‚

è½¯ä»¶é…ç½®ï¼š
âœ… MySQLç‰ˆæœ¬ï¼šä¸ç”Ÿäº§å®Œå…¨ä¸€è‡´  
âœ… æ“ä½œç³»ç»Ÿï¼šä¸ç”Ÿäº§ä¿æŒä¸€è‡´
âœ… ç›¸å…³ä¾èµ–ï¼šç‰ˆæœ¬å·ä¸¥æ ¼åŒ¹é…
```

### 3.2 ç¯å¢ƒæ­å»ºæ­¥éª¤


```bash
# 1. åˆ›å»ºæµ‹è¯•å®ä¾‹
docker run --name mysql-recovery-test \
  -e MYSQL_ROOT_PASSWORD=test123 \
  -p 3307:3306 \
  -v /data/mysql-test:/var/lib/mysql \
  mysql:8.0.35

# 2. é…ç½®æµ‹è¯•å‚æ•°
cat > /etc/mysql/recovery-test.cnf << EOF
[mysqld]
innodb_buffer_pool_size = 2G
innodb_log_file_size = 512M
max_connections = 500
EOF

# 3. å¯åŠ¨æµ‹è¯•å®ä¾‹
systemctl start mysql-recovery-test
```

### 3.3 ç½‘ç»œéš”ç¦»é…ç½®


ç¡®ä¿æµ‹è¯•ç¯å¢ƒä¸ä¼šå½±å“ç”Ÿäº§ç¯å¢ƒï¼š

```bash
# åˆ›å»ºç‹¬ç«‹çš„æµ‹è¯•ç½‘ç»œ
docker network create recovery-test-net

# æµ‹è¯•å®¹å™¨åŠ å…¥éš”ç¦»ç½‘ç»œ
docker run --network recovery-test-net \
  --name mysql-test mysql:8.0.35
```

---

## 4. â±ï¸ æ¢å¤æ—¶é—´æµ‹é‡ä¸åˆ†æ


### 4.1 æ¢å¤æ—¶é—´çš„æ„æˆ


æ¢å¤æ—¶é—´ä¸åªæ˜¯å¯¼å…¥æ•°æ®çš„æ—¶é—´ï¼Œè¿˜åŒ…æ‹¬æ•´ä¸ªæ¢å¤æµç¨‹çš„è€—æ—¶ã€‚

```
å®Œæ•´æ¢å¤æ—¶é—´ = å‡†å¤‡æ—¶é—´ + ä¼ è¾“æ—¶é—´ + å¯¼å…¥æ—¶é—´ + éªŒè¯æ—¶é—´

å‡†å¤‡æ—¶é—´ï¼š
â”œâ”€â”€ ç¯å¢ƒæ£€æŸ¥ï¼š5-10åˆ†é’Ÿ
â”œâ”€â”€ æƒé™é…ç½®ï¼š2-5åˆ†é’Ÿ  
â””â”€â”€ æœåŠ¡åœæ­¢ï¼š1-2åˆ†é’Ÿ

ä¼ è¾“æ—¶é—´ï¼š
â”œâ”€â”€ æ–‡ä»¶ä¸‹è½½ï¼šå–å†³äºå¤‡ä»½å¤§å°å’Œç½‘ç»œå¸¦å®½
â”œâ”€â”€ æ–‡ä»¶è§£å‹ï¼šå–å†³äºå‹ç¼©æ¯”å’ŒCPUæ€§èƒ½
â””â”€â”€ æ–‡ä»¶æ ¡éªŒï¼š1-5åˆ†é’Ÿ

å¯¼å…¥æ—¶é—´ï¼š
â”œâ”€â”€ è¡¨ç»“æ„åˆ›å»ºï¼šé€šå¸¸å¾ˆå¿«
â”œâ”€â”€ æ•°æ®å¯¼å…¥ï¼šä¸»è¦è€—æ—¶éƒ¨åˆ†
â””â”€â”€ ç´¢å¼•é‡å»ºï¼šå¯èƒ½å¾ˆè€—æ—¶

éªŒè¯æ—¶é—´ï¼š
â”œâ”€â”€ æ•°æ®å®Œæ•´æ€§æ£€æŸ¥ï¼š10-30åˆ†é’Ÿ
â”œâ”€â”€ ä¸šåŠ¡åŠŸèƒ½æµ‹è¯•ï¼š20-60åˆ†é’Ÿ
â””â”€â”€ æ€§èƒ½åŸºå‡†æµ‹è¯•ï¼š10-20åˆ†é’Ÿ
```

### 4.2 æ—¶é—´æµ‹é‡è„šæœ¬


```bash
#!/bin/bash
# recovery_time_test.sh - æ¢å¤æ—¶é—´æµ‹é‡è„šæœ¬

# è®°å½•å¼€å§‹æ—¶é—´
start_time=$(date +%s)
echo "å¼€å§‹æ¢å¤æµ‹è¯•: $(date)"

# é˜¶æ®µ1ï¼šå‡†å¤‡é˜¶æ®µ
phase1_start=$(date +%s)
echo "1. å‡†å¤‡æµ‹è¯•ç¯å¢ƒ..."
# å®é™…çš„ç¯å¢ƒå‡†å¤‡å‘½ä»¤
phase1_end=$(date +%s)
echo "å‡†å¤‡é˜¶æ®µè€—æ—¶: $((phase1_end - phase1_start))ç§’"

# é˜¶æ®µ2ï¼šæ•°æ®æ¢å¤
phase2_start=$(date +%s)
echo "2. æ‰§è¡Œæ•°æ®æ¢å¤..."
mysql -u root -p < backup_file.sql
phase2_end=$(date +%s)
echo "æ•°æ®æ¢å¤è€—æ—¶: $((phase2_end - phase2_start))ç§’"

# é˜¶æ®µ3ï¼šéªŒè¯æ£€æŸ¥
phase3_start=$(date +%s)
echo "3. æ•°æ®éªŒè¯æ£€æŸ¥..."
# éªŒè¯è„šæœ¬
phase3_end=$(date +%s)
echo "éªŒè¯é˜¶æ®µè€—æ—¶: $((phase3_end - phase3_start))ç§’"

# æ€»è®¡æ—¶é—´
total_time=$((phase3_end - start_time))
echo "æ€»æ¢å¤æ—¶é—´: ${total_time}ç§’ ($(($total_time/60))åˆ†é’Ÿ)"
```

### 4.3 æ€§èƒ½å½±å“å› ç´ åˆ†æ


```sql
-- åˆ†æå½±å“æ¢å¤é€Ÿåº¦çš„ä¸»è¦å› ç´ 
SELECT 
    'æ•°æ®é‡å¤§å°' as factor,
    ROUND(SUM(data_length + index_length)/1024/1024, 2) as size_mb
FROM information_schema.tables 
WHERE table_schema = 'your_database'

UNION ALL

SELECT 
    'ç´¢å¼•æ•°é‡' as factor,
    COUNT(*) as count
FROM information_schema.statistics 
WHERE table_schema = 'your_database'

UNION ALL

SELECT 
    'å¤–é”®çº¦æŸ' as factor,
    COUNT(*) as count
FROM information_schema.key_column_usage 
WHERE referenced_table_schema = 'your_database';
```

---

## 5. âœ… æ•°æ®ä¸€è‡´æ€§éªŒè¯


### 5.1 æ•°æ®å®Œæ•´æ€§æ£€æŸ¥


æ•°æ®ä¸€è‡´æ€§éªŒè¯æ˜¯æ¢å¤æµ‹è¯•çš„æ ¸å¿ƒç¯èŠ‚ï¼Œè¦ç¡®ä¿æ¢å¤åçš„æ•°æ®ä¸åŸå§‹æ•°æ®å®Œå…¨ä¸€è‡´ã€‚

**åŸºæœ¬æ£€æŸ¥é¡¹ç›®**ï¼š
```sql
-- 1. è¡¨æ•°é‡æ£€æŸ¥
SELECT 
    'åŸå§‹ç¯å¢ƒ' as env,
    COUNT(*) as table_count
FROM information_schema.tables 
WHERE table_schema = 'production_db'

UNION ALL

SELECT 
    'æ¢å¤ç¯å¢ƒ' as env,
    COUNT(*) as table_count
FROM information_schema.tables 
WHERE table_schema = 'recovery_test_db';

-- 2. æ•°æ®è¡Œæ•°æ£€æŸ¥
SELECT 
    table_name,
    table_rows as estimated_rows
FROM information_schema.tables 
WHERE table_schema = 'recovery_test_db'
  AND table_type = 'BASE TABLE'
ORDER BY table_name;

-- 3. æ•°æ®æ ¡éªŒå’Œæ£€æŸ¥
SELECT 
    table_name,
    CHECKSUM TABLE recovery_test_db.table_name
FROM information_schema.tables 
WHERE table_schema = 'recovery_test_db';
```

### 5.2 ä¸šåŠ¡æ•°æ®éªŒè¯


é™¤äº†åŸºç¡€çš„æ•°æ®å®Œæ•´æ€§ï¼Œè¿˜è¦éªŒè¯å…³é”®ä¸šåŠ¡æ•°æ®çš„æ­£ç¡®æ€§ï¼š

```sql
-- å…³é”®ä¸šåŠ¡æŒ‡æ ‡éªŒè¯
-- ç¤ºä¾‹ï¼šç”µå•†è®¢å•æ•°æ®éªŒè¯

-- 1. è®¢å•æ€»æ•°æ£€æŸ¥
SELECT 
    DATE(created_at) as order_date,
    COUNT(*) as order_count,
    SUM(total_amount) as total_revenue
FROM orders 
WHERE created_at >= '2024-01-01'
GROUP BY DATE(created_at)
ORDER BY order_date DESC
LIMIT 7;

-- 2. ç”¨æˆ·æ•°æ®å®Œæ•´æ€§
SELECT 
    'æ€»ç”¨æˆ·æ•°' as metric,
    COUNT(*) as value
FROM users

UNION ALL

SELECT 
    'æ´»è·ƒç”¨æˆ·æ•°' as metric,
    COUNT(*) as value
FROM users 
WHERE last_login_at >= DATE_SUB(NOW(), INTERVAL 30 DAY);

-- 3. æ•°æ®å…³è”æ€§æ£€æŸ¥
SELECT 
    'å­¤å„¿è®¢å•æ•°' as issue,
    COUNT(*) as count
FROM orders o
LEFT JOIN users u ON o.user_id = u.id
WHERE u.id IS NULL;
```

### 5.3 è‡ªåŠ¨åŒ–éªŒè¯è„šæœ¬


```python
#!/usr/bin/env python3
# data_verification.py - æ•°æ®éªŒè¯è‡ªåŠ¨åŒ–è„šæœ¬

import mysql.connector
import hashlib
import logging

def verify_table_data(prod_config, test_config, table_name):
    """éªŒè¯è¡¨æ•°æ®ä¸€è‡´æ€§"""
    
    # è¿æ¥ç”Ÿäº§å’Œæµ‹è¯•æ•°æ®åº“
    prod_conn = mysql.connector.connect(**prod_config)
    test_conn = mysql.connector.connect(**test_config)
    
    try:
        # è·å–è¡¨çš„è¡Œæ•°
        prod_count = get_table_count(prod_conn, table_name)
        test_count = get_table_count(test_conn, table_name)
        
        if prod_count != test_count:
            logging.error(f"{table_name}: è¡Œæ•°ä¸åŒ¹é… (ç”Ÿäº§:{prod_count}, æµ‹è¯•:{test_count})")
            return False
            
        # éªŒè¯æ•°æ®æ ¡éªŒå’Œ
        prod_checksum = get_table_checksum(prod_conn, table_name)
        test_checksum = get_table_checksum(test_conn, table_name)
        
        if prod_checksum != test_checksum:
            logging.error(f"{table_name}: æ•°æ®æ ¡éªŒå’Œä¸åŒ¹é…")
            return False
            
        logging.info(f"{table_name}: éªŒè¯é€šè¿‡")
        return True
        
    finally:
        prod_conn.close()
        test_conn.close()

def get_table_count(conn, table_name):
    """è·å–è¡¨è¡Œæ•°"""
    cursor = conn.cursor()
    cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
    return cursor.fetchone()[0]

def get_table_checksum(conn, table_name):
    """è·å–è¡¨æ ¡éªŒå’Œ"""
    cursor = conn.cursor()
    cursor.execute(f"CHECKSUM TABLE {table_name}")
    return cursor.fetchone()[1]

# é…ç½®ä¿¡æ¯
prod_config = {
    'host': 'prod-mysql.example.com',
    'user': 'readonly_user',
    'password': 'password',
    'database': 'production_db'
}

test_config = {
    'host': 'test-mysql.example.com', 
    'user': 'test_user',
    'password': 'password',
    'database': 'recovery_test_db'
}

# æ‰§è¡ŒéªŒè¯
tables_to_verify = ['users', 'orders', 'products']
for table in tables_to_verify:
    verify_table_data(prod_config, test_config, table)
```

---

## 6. ğŸ”§ ä¸šåŠ¡åŠŸèƒ½æµ‹è¯•


### 6.1 å…³é”®ä¸šåŠ¡æµç¨‹æµ‹è¯•


æ¢å¤åä¸ä»…è¦éªŒè¯æ•°æ®ï¼Œè¿˜è¦æµ‹è¯•å…³é”®ä¸šåŠ¡åŠŸèƒ½æ˜¯å¦æ­£å¸¸ã€‚

**æ ¸å¿ƒæµ‹è¯•åœºæ™¯**ï¼š
```
ç”¨æˆ·è®¤è¯æµç¨‹ï¼š
â”œâ”€â”€ ç”¨æˆ·ç™»å½•éªŒè¯
â”œâ”€â”€ æƒé™æ£€æŸ¥
â”œâ”€â”€ ä¼šè¯ç®¡ç†
â””â”€â”€ å¯†ç é‡ç½®

è®¢å•å¤„ç†æµç¨‹ï¼š
â”œâ”€â”€ å•†å“æŸ¥è¯¢
â”œâ”€â”€ è´­ç‰©è½¦æ“ä½œ  
â”œâ”€â”€ è®¢å•åˆ›å»º
â”œâ”€â”€ æ”¯ä»˜å¤„ç†
â””â”€â”€ åº“å­˜æ›´æ–°

æ•°æ®æŸ¥è¯¢æ€§èƒ½ï¼š
â”œâ”€â”€ å¤æ‚æŸ¥è¯¢å“åº”æ—¶é—´
â”œâ”€â”€ å¤§æ•°æ®é‡åˆ†é¡µæŸ¥è¯¢
â”œâ”€â”€ ç»Ÿè®¡æŠ¥è¡¨ç”Ÿæˆ
â””â”€â”€ ç´¢å¼•ä½¿ç”¨æ•ˆç‡
```

### 6.2 åŠŸèƒ½æµ‹è¯•è„šæœ¬


```python
#!/usr/bin/env python3
# business_function_test.py - ä¸šåŠ¡åŠŸèƒ½æµ‹è¯•

import requests
import mysql.connector
import time
import logging

class BusinessFunctionTest:
    def __init__(self, db_config, api_base_url):
        self.db_config = db_config
        self.api_base_url = api_base_url
        
    def test_user_authentication(self):
        """æµ‹è¯•ç”¨æˆ·è®¤è¯åŠŸèƒ½"""
        try:
            # æµ‹è¯•ç”¨æˆ·ç™»å½•
            login_data = {
                'username': 'test_user',
                'password': 'test_password'
            }
            
            response = requests.post(
                f"{self.api_base_url}/login", 
                json=login_data
            )
            
            if response.status_code == 200:
                logging.info("ç”¨æˆ·ç™»å½•æµ‹è¯•: é€šè¿‡")
                return True
            else:
                logging.error(f"ç”¨æˆ·ç™»å½•æµ‹è¯•: å¤±è´¥ ({response.status_code})")
                return False
                
        except Exception as e:
            logging.error(f"ç”¨æˆ·ç™»å½•æµ‹è¯•å¼‚å¸¸: {e}")
            return False
    
    def test_order_creation(self):
        """æµ‹è¯•è®¢å•åˆ›å»ºåŠŸèƒ½"""
        try:
            # åˆ›å»ºæµ‹è¯•è®¢å•
            order_data = {
                'user_id': 1001,
                'product_id': 2001,
                'quantity': 2,
                'price': 99.99
            }
            
            # APIæµ‹è¯•
            response = requests.post(
                f"{self.api_base_url}/orders",
                json=order_data
            )
            
            if response.status_code == 201:
                order_id = response.json().get('order_id')
                
                # æ•°æ®åº“éªŒè¯
                if self.verify_order_in_db(order_id):
                    logging.info("è®¢å•åˆ›å»ºæµ‹è¯•: é€šè¿‡")
                    return True
                    
            logging.error("è®¢å•åˆ›å»ºæµ‹è¯•: å¤±è´¥")
            return False
            
        except Exception as e:
            logging.error(f"è®¢å•åˆ›å»ºæµ‹è¯•å¼‚å¸¸: {e}")
            return False
    
    def verify_order_in_db(self, order_id):
        """éªŒè¯è®¢å•æ˜¯å¦æ­£ç¡®å†™å…¥æ•°æ®åº“"""
        conn = mysql.connector.connect(**self.db_config)
        try:
            cursor = conn.cursor()
            cursor.execute(
                "SELECT id, status FROM orders WHERE id = %s",
                (order_id,)
            )
            result = cursor.fetchone()
            return result is not None
        finally:
            conn.close()

# æµ‹è¯•æ‰§è¡Œ
test_config = {
    'host': 'test-mysql.example.com',
    'user': 'test_user', 
    'password': 'password',
    'database': 'recovery_test_db'
}

tester = BusinessFunctionTest(test_config, 'http://test-api.example.com')
tester.test_user_authentication()
tester.test_order_creation()
```

### 6.3 æ€§èƒ½åŸºå‡†æµ‹è¯•


```sql
-- å…³é”®æŸ¥è¯¢æ€§èƒ½æµ‹è¯•
-- æµ‹è¯•å¤æ‚æŸ¥è¯¢çš„å“åº”æ—¶é—´

-- 1. ç”¨æˆ·è®¢å•ç»Ÿè®¡æŸ¥è¯¢
SET @start_time = NOW(6);

SELECT 
    u.username,
    COUNT(o.id) as order_count,
    SUM(o.total_amount) as total_spent
FROM users u
LEFT JOIN orders o ON u.id = o.user_id
WHERE u.created_at >= '2024-01-01'
GROUP BY u.id, u.username
HAVING order_count > 0
ORDER BY total_spent DESC
LIMIT 100;

SET @end_time = NOW(6);
SELECT TIMESTAMPDIFF(MICROSECOND, @start_time, @end_time) / 1000 as query_time_ms;

-- 2. å•†å“é”€å”®æ’è¡ŒæŸ¥è¯¢  
SET @start_time = NOW(6);

SELECT 
    p.product_name,
    SUM(oi.quantity) as total_sold,
    SUM(oi.price * oi.quantity) as total_revenue
FROM products p
JOIN order_items oi ON p.id = oi.product_id
JOIN orders o ON oi.order_id = o.id
WHERE o.created_at >= DATE_SUB(NOW(), INTERVAL 30 DAY)
GROUP BY p.id, p.product_name
ORDER BY total_revenue DESC
LIMIT 50;

SET @end_time = NOW(6);
SELECT TIMESTAMPDIFF(MICROSECOND, @start_time, @end_time) / 1000 as query_time_ms;
```

---

## 7. ğŸ“Š æ€§èƒ½å½±å“è¯„ä¼°


### 7.1 æ¢å¤è¿‡ç¨‹å¯¹ç³»ç»Ÿçš„å½±å“


æ¢å¤æµ‹è¯•è¿‡ç¨‹ä¸­è¦ç›‘æ§å¯¹ç³»ç»Ÿèµ„æºçš„å½±å“ï¼Œé¿å…å½±å“å…¶ä»–ä¸šåŠ¡ã€‚

**ç›‘æ§æŒ‡æ ‡**ï¼š
```bash
# 1. CPUä½¿ç”¨ç‡ç›‘æ§
top -p $(pgrep mysqld) -d 5

# 2. å†…å­˜ä½¿ç”¨ç›‘æ§  
free -m -s 5

# 3. ç£ç›˜IOç›‘æ§
iostat -x 5

# 4. ç½‘ç»œå¸¦å®½ç›‘æ§
iftop -i eth0

# 5. MySQLè¿›ç¨‹çŠ¶æ€
mysql -e "SHOW PROCESSLIST" | grep -v Sleep
```

### 7.2 æ€§èƒ½å½±å“æµ‹é‡


```sql
-- æ¢å¤æœŸé—´çš„æ€§èƒ½æŒ‡æ ‡ç›‘æ§

-- 1. è¿æ¥æ•°ç›‘æ§
SELECT 
    variable_name,
    variable_value
FROM performance_schema.global_status 
WHERE variable_name IN (
    'Threads_connected',
    'Threads_running',
    'Max_used_connections'
);

-- 2. æŸ¥è¯¢æ€§èƒ½ç›‘æ§
SELECT 
    count_star as query_count,
    avg_timer_wait/1000000000 as avg_query_time_sec,
    sum_timer_wait/1000000000 as total_time_sec
FROM performance_schema.events_statements_summary_global_by_event_name
WHERE event_name = 'statement/sql/select';

-- 3. InnoDBçŠ¶æ€ç›‘æ§
SELECT 
    variable_name,
    variable_value  
FROM performance_schema.global_status
WHERE variable_name LIKE 'Innodb_%'
  AND variable_name IN (
    'Innodb_buffer_pool_reads',
    'Innodb_buffer_pool_read_requests', 
    'Innodb_rows_read',
    'Innodb_rows_inserted'
);
```

### 7.3 èµ„æºä½¿ç”¨ä¼˜åŒ–


```bash
#!/bin/bash
# resource_monitor.sh - èµ„æºä½¿ç”¨ç›‘æ§è„šæœ¬

LOG_FILE="/var/log/recovery_test_monitor.log"

while true; do
    timestamp=$(date '+%Y-%m-%d %H:%M:%S')
    
    # CPUä½¿ç”¨ç‡
    cpu_usage=$(top -bn1 | grep "Cpu(s)" | awk '{print $2}' | cut -d'%' -f1)
    
    # å†…å­˜ä½¿ç”¨ç‡
    mem_usage=$(free | grep Mem | awk '{printf "%.1f", ($3/$2) * 100.0}')
    
    # ç£ç›˜IOç­‰å¾…
    io_wait=$(iostat -c 1 2 | tail -1 | awk '{print $4}')
    
    # MySQLè¿æ¥æ•°
    mysql_conn=$(mysql -e "SHOW STATUS LIKE 'Threads_connected'" | tail -1 | awk '{print $2}')
    
    echo "$timestamp,CPU:${cpu_usage}%,MEM:${mem_usage}%,IO:${io_wait}%,CONN:${mysql_conn}" >> $LOG_FILE
    
    sleep 30
done
```

---

## 8. ğŸ¤– è‡ªåŠ¨åŒ–æ¢å¤æµ‹è¯•


### 8.1 è‡ªåŠ¨åŒ–æµ‹è¯•çš„å¿…è¦æ€§


æ‰‹å·¥æ¢å¤æµ‹è¯•è´¹æ—¶è´¹åŠ›ï¼Œè€Œä¸”å®¹æ˜“å‡ºé”™ã€‚è‡ªåŠ¨åŒ–å¯ä»¥æé«˜æµ‹è¯•é¢‘ç‡å’Œå‡†ç¡®æ€§ã€‚

**è‡ªåŠ¨åŒ–çš„å¥½å¤„**ï¼š
- **æé«˜æµ‹è¯•é¢‘ç‡**ï¼šå¯ä»¥æ¯å¤©è‡ªåŠ¨æ‰§è¡Œ
- **å‡å°‘äººä¸ºé”™è¯¯**ï¼šæ ‡å‡†åŒ–çš„æµ‹è¯•æµç¨‹
- **è¯¦ç»†çš„æµ‹è¯•æŠ¥å‘Š**ï¼šå®Œæ•´è®°å½•æµ‹è¯•è¿‡ç¨‹å’Œç»“æœ
- **åŠæ—¶å‘ç°é—®é¢˜**ï¼šå¼‚å¸¸æ—¶è‡ªåŠ¨å‘Šè­¦

### 8.2 è‡ªåŠ¨åŒ–æµ‹è¯•æ¡†æ¶


```python
#!/usr/bin/env python3
# automated_recovery_test.py - è‡ªåŠ¨åŒ–æ¢å¤æµ‹è¯•æ¡†æ¶

import os
import subprocess
import mysql.connector
import logging
import smtplib
from datetime import datetime
from email.mime.text import MIMEText

class AutomatedRecoveryTest:
    def __init__(self, config):
        self.config = config
        self.test_results = []
        self.setup_logging()
    
    def setup_logging(self):
        """é…ç½®æ—¥å¿—"""
        log_format = '%(asctime)s - %(levelname)s - %(message)s'
        logging.basicConfig(
            level=logging.INFO,
            format=log_format,
            handlers=[
                logging.FileHandler(f"recovery_test_{datetime.now().strftime('%Y%m%d')}.log"),
                logging.StreamHandler()
            ]
        )
    
    def run_full_test(self):
        """æ‰§è¡Œå®Œæ•´çš„æ¢å¤æµ‹è¯•"""
        try:
            logging.info("å¼€å§‹è‡ªåŠ¨åŒ–æ¢å¤æµ‹è¯•")
            
            # 1. ç¯å¢ƒå‡†å¤‡
            if not self.prepare_environment():
                return False
            
            # 2. æ‰§è¡Œæ¢å¤
            if not self.execute_recovery():
                return False
                
            # 3. æ•°æ®éªŒè¯
            if not self.verify_data():
                return False
                
            # 4. åŠŸèƒ½æµ‹è¯•
            if not self.test_business_functions():
                return False
                
            # 5. ç”ŸæˆæŠ¥å‘Š
            self.generate_report()
            
            logging.info("è‡ªåŠ¨åŒ–æ¢å¤æµ‹è¯•å®Œæˆ")
            return True
            
        except Exception as e:
            logging.error(f"æµ‹è¯•è¿‡ç¨‹å¼‚å¸¸: {e}")
            self.send_alert(f"æ¢å¤æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def prepare_environment(self):
        """å‡†å¤‡æµ‹è¯•ç¯å¢ƒ"""
        try:
            logging.info("å‡†å¤‡æµ‹è¯•ç¯å¢ƒ...")
            
            # åœæ­¢æµ‹è¯•æ•°æ®åº“
            subprocess.run(['systemctl', 'stop', 'mysql-test'], check=True)
            
            # æ¸…ç†æ—§æ•°æ®
            subprocess.run(['rm', '-rf', '/data/mysql-test/*'], shell=True)
            
            # å¯åŠ¨æµ‹è¯•æ•°æ®åº“
            subprocess.run(['systemctl', 'start', 'mysql-test'], check=True)
            
            # ç­‰å¾…æ•°æ®åº“å¯åŠ¨
            time.sleep(30)
            
            logging.info("æµ‹è¯•ç¯å¢ƒå‡†å¤‡å®Œæˆ")
            return True
            
        except Exception as e:
            logging.error(f"ç¯å¢ƒå‡†å¤‡å¤±è´¥: {e}")
            return False
    
    def execute_recovery(self):
        """æ‰§è¡Œæ•°æ®æ¢å¤"""
        try:
            logging.info("å¼€å§‹æ•°æ®æ¢å¤...")
            start_time = datetime.now()
            
            # è·å–æœ€æ–°å¤‡ä»½æ–‡ä»¶
            backup_file = self.get_latest_backup()
            if not backup_file:
                raise Exception("æœªæ‰¾åˆ°å¯ç”¨çš„å¤‡ä»½æ–‡ä»¶")
            
            # æ‰§è¡Œæ¢å¤
            cmd = f"mysql -h {self.config['test_host']} -u root -p{self.config['password']} < {backup_file}"
            result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
            
            if result.returncode != 0:
                raise Exception(f"æ¢å¤å‘½ä»¤æ‰§è¡Œå¤±è´¥: {result.stderr}")
            
            end_time = datetime.now()
            recovery_time = (end_time - start_time).total_seconds()
            
            logging.info(f"æ•°æ®æ¢å¤å®Œæˆï¼Œè€—æ—¶: {recovery_time:.2f}ç§’")
            self.test_results.append(('recovery_time', recovery_time))
            
            return True
            
        except Exception as e:
            logging.error(f"æ•°æ®æ¢å¤å¤±è´¥: {e}")
            return False
    
    def verify_data(self):
        """éªŒè¯æ•°æ®å®Œæ•´æ€§"""
        try:
            logging.info("å¼€å§‹æ•°æ®éªŒè¯...")
            
            conn = mysql.connector.connect(
                host=self.config['test_host'],
                user=self.config['user'],
                password=self.config['password'],
                database=self.config['database']
            )
            
            cursor = conn.cursor()
            
            # æ£€æŸ¥è¡¨æ•°é‡
            cursor.execute("SELECT COUNT(*) FROM information_schema.tables WHERE table_schema = %s", 
                         (self.config['database'],))
            table_count = cursor.fetchone()[0]
            
            if table_count < self.config['expected_table_count']:
                raise Exception(f"è¡¨æ•°é‡ä¸è¶³ï¼ŒæœŸæœ›: {self.config['expected_table_count']}, å®é™…: {table_count}")
            
            # æ£€æŸ¥å…³é”®è¡¨çš„æ•°æ®é‡
            for table_name, min_rows in self.config['critical_tables'].items():
                cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
                actual_rows = cursor.fetchone()[0]
                
                if actual_rows < min_rows:
                    raise Exception(f"è¡¨ {table_name} æ•°æ®é‡ä¸è¶³ï¼ŒæœŸæœ›: {min_rows}, å®é™…: {actual_rows}")
            
            logging.info("æ•°æ®éªŒè¯é€šè¿‡")
            self.test_results.append(('data_verification', 'PASS'))
            
            return True
            
        except Exception as e:
            logging.error(f"æ•°æ®éªŒè¯å¤±è´¥: {e}")
            self.test_results.append(('data_verification', f'FAIL: {e}'))
            return False
        finally:
            if 'conn' in locals():
                conn.close()
    
    def generate_report(self):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        report = f"""
è‡ªåŠ¨åŒ–æ¢å¤æµ‹è¯•æŠ¥å‘Š
==================

æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
æµ‹è¯•ç»“æœ: {'é€šè¿‡' if all(result[1] != 'FAIL' for result in self.test_results if isinstance(result[1], str)) else 'å¤±è´¥'}

è¯¦ç»†ç»“æœ:
"""
        for test_name, result in self.test_results:
            report += f"- {test_name}: {result}\n"
        
        # ä¿å­˜æŠ¥å‘Š
        with open(f"recovery_test_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt", 'w') as f:
            f.write(report)
        
        logging.info("æµ‹è¯•æŠ¥å‘Šå·²ç”Ÿæˆ")
        
        # å‘é€é‚®ä»¶é€šçŸ¥
        self.send_report_email(report)

# é…ç½®ç¤ºä¾‹
config = {
    'test_host': 'test-mysql.example.com',
    'user': 'test_user',
    'password': 'test_password',
    'database': 'test_db',
    'expected_table_count': 50,
    'critical_tables': {
        'users': 10000,
        'orders': 50000,
        'products': 1000
    }
}

# æ‰§è¡Œè‡ªåŠ¨åŒ–æµ‹è¯•
if __name__ == '__main__':
    tester = AutomatedRecoveryTest(config)
    tester.run_full_test()
```

### 8.3 æµ‹è¯•è°ƒåº¦ä¸ç›‘æ§


```bash
#!/bin/bash
# schedule_recovery_test.sh - æµ‹è¯•è°ƒåº¦è„šæœ¬

# æ·»åŠ åˆ°crontabï¼Œæ¯å‘¨æ‰§è¡Œä¸€æ¬¡
# 0 2 * * 0 /opt/scripts/schedule_recovery_test.sh

SCRIPT_DIR="/opt/recovery-test"
LOG_DIR="/var/log/recovery-test"
LOCK_FILE="/tmp/recovery_test.lock"

# æ£€æŸ¥æ˜¯å¦å·²æœ‰æµ‹è¯•åœ¨è¿è¡Œ
if [ -f "$LOCK_FILE" ]; then
    echo "æ¢å¤æµ‹è¯•å·²åœ¨è¿è¡Œä¸­"
    exit 1
fi

# åˆ›å»ºé”æ–‡ä»¶
touch "$LOCK_FILE"

# ç¡®ä¿é€€å‡ºæ—¶æ¸…ç†é”æ–‡ä»¶
trap "rm -f $LOCK_FILE" EXIT

# æ‰§è¡Œæµ‹è¯•
cd "$SCRIPT_DIR"
python3 automated_recovery_test.py > "$LOG_DIR/test_$(date +%Y%m%d_%H%M%S).log" 2>&1

# æ£€æŸ¥æµ‹è¯•ç»“æœ
if [ $? -eq 0 ]; then
    echo "æ¢å¤æµ‹è¯•æˆåŠŸå®Œæˆ"
else
    echo "æ¢å¤æµ‹è¯•å¤±è´¥" | mail -s "æ¢å¤æµ‹è¯•å‘Šè­¦" admin@example.com
fi
```

---

## 9. ğŸ”„ A/Bæ¢å¤å¯¹æ¯”æµ‹è¯•


### 9.1 A/Bæµ‹è¯•çš„ç›®çš„


A/Bæ¢å¤å¯¹æ¯”æµ‹è¯•æ˜¯æŒ‡åŒæ—¶ä½¿ç”¨ä¸¤ç§ä¸åŒçš„æ¢å¤æ–¹æ³•ï¼Œå¯¹æ¯”å…¶æ•ˆæœå’Œæ€§èƒ½å·®å¼‚ã€‚

**å¯¹æ¯”ç»´åº¦**ï¼š
```
æ¢å¤æ—¶é—´å¯¹æ¯”ï¼š
â”œâ”€â”€ æ–¹æ³•Aï¼šä¼ ç»Ÿmysqldumpæ¢å¤
â”œâ”€â”€ æ–¹æ³•Bï¼šäºŒè¿›åˆ¶æ—¥å¿—å¢é‡æ¢å¤
â””â”€â”€ ç»“æœï¼šæ‰¾å‡ºæœ€å¿«çš„æ¢å¤æ–¹æ¡ˆ

æ•°æ®å®Œæ•´æ€§å¯¹æ¯”ï¼š
â”œâ”€â”€ æ–¹æ³•Aï¼šå…¨é‡å¤‡ä»½æ¢å¤
â”œâ”€â”€ æ–¹æ³•Bï¼šå¢é‡å¤‡ä»½é“¾æ¢å¤  
â””â”€â”€ ç»“æœï¼šéªŒè¯ä¸åŒæ–¹æ³•çš„å¯é æ€§

èµ„æºæ¶ˆè€—å¯¹æ¯”ï¼š
â”œâ”€â”€ æ–¹æ³•Aï¼šCPU/å†…å­˜/ç£ç›˜ä½¿ç”¨
â”œâ”€â”€ æ–¹æ³•Bï¼šCPU/å†…å­˜/ç£ç›˜ä½¿ç”¨
â””â”€â”€ ç»“æœï¼šé€‰æ‹©èµ„æºå‹å¥½çš„æ–¹æ¡ˆ
```

### 9.2 A/Bæµ‹è¯•å®æ–½


```python
#!/usr/bin/env python3
# ab_recovery_comparison.py - A/Bæ¢å¤å¯¹æ¯”æµ‹è¯•

import threading
import time
import mysql.connector
from datetime import datetime

class ABRecoveryTest:
    def __init__(self):
        self.results = {
            'method_a': {},
            'method_b': {}
        }
    
    def run_parallel_test(self):
        """å¹¶è¡Œæ‰§è¡ŒA/Bæµ‹è¯•"""
        
        # åˆ›å»ºä¸¤ä¸ªæµ‹è¯•çº¿ç¨‹
        thread_a = threading.Thread(target=self.test_method_a, name="MethodA")
        thread_b = threading.Thread(target=self.test_method_b, name="MethodB")
        
        # åŒæ—¶å¯åŠ¨æµ‹è¯•
        start_time = datetime.now()
        thread_a.start()
        thread_b.start()
        
        # ç­‰å¾…ä¸¤ä¸ªæµ‹è¯•å®Œæˆ
        thread_a.join()
        thread_b.join()
        
        end_time = datetime.now()
        
        # è¾“å‡ºå¯¹æ¯”ç»“æœ
        self.compare_results()
    
    def test_method_a(self):
        """æµ‹è¯•æ–¹æ³•Aï¼šå…¨é‡mysqldumpæ¢å¤"""
        try:
            start_time = time.time()
            
            # æ‰§è¡Œå…¨é‡æ¢å¤
            self.execute_full_restore('test_db_a')
            
            end_time = time.time()
            
            # éªŒè¯æ•°æ®
            data_integrity = self.verify_data_integrity('test_db_a')
            
            self.results['method_a'] = {
                'restore_time': end_time - start_time,
                'data_integrity': data_integrity,
                'method_type': 'å…¨é‡mysqldumpæ¢å¤'
            }
            
        except Exception as e:
            self.results['method_a'] = {
                'error': str(e),
                'method_type': 'å…¨é‡mysqldumpæ¢å¤'
            }
    
    def test_method_b(self):
        """æµ‹è¯•æ–¹æ³•Bï¼šå¢é‡binlogæ¢å¤"""  
        try:
            start_time = time.time()
            
            # æ‰§è¡Œå¢é‡æ¢å¤
            self.execute_incremental_restore('test_db_b')
            
            end_time = time.time()
            
            # éªŒè¯æ•°æ®
            data_integrity = self.verify_data_integrity('test_db_b')
            
            self.results['method_b'] = {
                'restore_time': end_time - start_time,
                'data_integrity': data_integrity,
                'method_type': 'å¢é‡binlogæ¢å¤'
            }
            
        except Exception as e:
            self.results['method_b'] = {
                'error': str(e),
                'method_type': 'å¢é‡binlogæ¢å¤'
            }
    
    def execute_full_restore(self, db_name):
        """æ‰§è¡Œå…¨é‡æ¢å¤"""
        import subprocess
        
        cmd = f"mysql -u root -ppassword -e 'CREATE DATABASE {db_name}'"
        subprocess.run(cmd, shell=True, check=True)
        
        cmd = f"mysql -u root -ppassword {db_name} < /backup/full_backup.sql"
        subprocess.run(cmd, shell=True, check=True)
    
    def execute_incremental_restore(self, db_name):
        """æ‰§è¡Œå¢é‡æ¢å¤"""
        import subprocess
        
        # 1. å…ˆæ¢å¤åŸºç¡€å¤‡ä»½
        cmd = f"mysql -u root -ppassword -e 'CREATE DATABASE {db_name}'"
        subprocess.run(cmd, shell=True, check=True)
        
        cmd = f"mysql -u root -ppassword {db_name} < /backup/base_backup.sql"
        subprocess.run(cmd, shell=True, check=True)
        
        # 2. åº”ç”¨å¢é‡binlog
        cmd = f"mysqlbinlog /backup/incremental/*.binlog | mysql -u root -ppassword {db_name}"
        subprocess.run(cmd, shell=True, check=True)
    
    def verify_data_integrity(self, db_name):
        """éªŒè¯æ•°æ®å®Œæ•´æ€§"""
        try:
            conn = mysql.connector.connect(
                host='localhost',
                user='root',
                password='password',
                database=db_name
            )
            
            cursor = conn.cursor()
            
            # æ£€æŸ¥å…³é”®è¡¨çš„æ•°æ®
            cursor.execute("SELECT COUNT(*) FROM users")
            user_count = cursor.fetchone()[0]
            
            cursor.execute("SELECT COUNT(*) FROM orders")
            order_count = cursor.fetchone()[0]
            
            # ç®€å•çš„å®Œæ•´æ€§æ£€æŸ¥
            if user_count > 0 and order_count > 0:
                return True
            else:
                return False
                
        except Exception as e:
            return False
        finally:
            if 'conn' in locals():
                conn.close()
    
    def compare_results(self):
        """å¯¹æ¯”æµ‹è¯•ç»“æœ"""
        print("\n" + "="*50)
        print("A/B æ¢å¤å¯¹æ¯”æµ‹è¯•ç»“æœ")
        print("="*50)
        
        for method, result in self.results.items():
            print(f"\n{method.upper()} ({result.get('method_type', 'Unknown')}):")
            
            if 'error' in result:
                print(f"  çŠ¶æ€: å¤±è´¥")
                print(f"  é”™è¯¯: {result['error']}")
            else:
                print(f"  çŠ¶æ€: æˆåŠŸ")
                print(f"  æ¢å¤æ—¶é—´: {result['restore_time']:.2f} ç§’")
                print(f"  æ•°æ®å®Œæ•´æ€§: {'é€šè¿‡' if result['data_integrity'] else 'å¤±è´¥'}")
        
        # æ¨èæœ€ä¼˜æ–¹æ¡ˆ
        if all('error' not in result for result in self.results.values()):
            faster_method = min(self.results.keys(), 
                              key=lambda k: self.results[k]['restore_time'])
            print(f"\næ¨èæ–¹æ¡ˆ: {faster_method.upper()} (æ¢å¤æ—¶é—´æ›´çŸ­)")

# æ‰§è¡ŒA/Bæµ‹è¯•
if __name__ == '__main__':
    ab_test = ABRecoveryTest()
    ab_test.run_parallel_test()
```

### 9.3 æ€§èƒ½å¯¹æ¯”åˆ†æ


```sql
-- ä¸åŒæ¢å¤æ–¹æ³•çš„æ€§èƒ½å¯¹æ¯”åˆ†æ

-- åˆ›å»ºæ€§èƒ½å¯¹æ¯”è¡¨
CREATE TABLE recovery_performance_comparison (
    test_id INT AUTO_INCREMENT PRIMARY KEY,
    test_date DATE,
    method_name VARCHAR(100),
    data_size_gb DECIMAL(10,2),
    recovery_time_minutes DECIMAL(10,2),
    cpu_usage_percent DECIMAL(5,2),
    memory_usage_gb DECIMAL(10,2),
    disk_io_rate_mbps DECIMAL(10,2),
    success_rate_percent DECIMAL(5,2)
);

-- æ’å…¥æµ‹è¯•æ•°æ®
INSERT INTO recovery_performance_comparison VALUES
(1, '2024-01-15', 'mysqldumpå…¨é‡æ¢å¤', 50.0, 120.5, 85.2, 4.2, 45.8, 100.0),
(2, '2024-01-15', 'binlogå¢é‡æ¢å¤', 50.0, 85.3, 65.4, 2.8, 32.1, 98.5),
(3, '2024-01-16', 'xtrabackupæ¢å¤', 50.0, 45.2, 45.6, 1.5, 78.9, 99.8);

-- æ€§èƒ½å¯¹æ¯”æŸ¥è¯¢
SELECT 
    method_name,
    AVG(recovery_time_minutes) as avg_recovery_time,
    AVG(cpu_usage_percent) as avg_cpu_usage,
    AVG(memory_usage_gb) as avg_memory_usage,
    AVG(success_rate_percent) as avg_success_rate
FROM recovery_performance_comparison
GROUP BY method_name
ORDER BY avg_recovery_time;
```

---

## 10. ğŸ—ï¸ æ¢å¤æµ‹è¯•å¹³å°å»ºè®¾


### 10.1 æµ‹è¯•å¹³å°æ¶æ„


æ„å»ºç»Ÿä¸€çš„æ¢å¤æµ‹è¯•å¹³å°ï¼Œå¯ä»¥æé«˜æµ‹è¯•æ•ˆç‡å’Œç®¡ç†æ°´å¹³ã€‚

```
æ¢å¤æµ‹è¯•å¹³å°æ¶æ„ï¼š

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Webæ§åˆ¶å°     â”‚    â”‚   APIæœåŠ¡å±‚     â”‚    â”‚   æµ‹è¯•æ‰§è¡Œå™¨    â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â”œâ”€æµ‹è¯•ä»»åŠ¡ç®¡ç†  â”‚    â”‚ â”œâ”€ä»»åŠ¡è°ƒåº¦API   â”‚    â”‚ â”œâ”€ç¯å¢ƒç®¡ç†      â”‚
â”‚ â”œâ”€ç»“æœæŸ¥çœ‹     â”‚â—„â”€â”€â”€â”¤ â”œâ”€ç»“æœæŸ¥è¯¢API   â”‚â—„â”€â”€â”€â”¤ â”œâ”€æ¢å¤æ‰§è¡Œ      â”‚
â”‚ â”œâ”€æŠ¥å‘Šç”Ÿæˆ     â”‚    â”‚ â”œâ”€é…ç½®ç®¡ç†API   â”‚    â”‚ â”œâ”€æ•°æ®éªŒè¯      â”‚
â”‚ â””â”€å‘Šè­¦é€šçŸ¥     â”‚    â”‚ â””â”€ç›‘æ§ç»Ÿè®¡API   â”‚    â”‚ â””â”€ç»“æœä¸ŠæŠ¥      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â”‚                       â”‚                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ç”¨æˆ·ç•Œé¢      â”‚    â”‚   æ¶ˆæ¯é˜Ÿåˆ—      â”‚    â”‚   æ•°æ®å­˜å‚¨      â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â”œâ”€ä»»åŠ¡åˆ›å»º     â”‚    â”‚ â”œâ”€æµ‹è¯•ä»»åŠ¡é˜Ÿåˆ—  â”‚    â”‚ â”œâ”€é…ç½®æ•°æ®åº“    â”‚
â”‚ â”œâ”€è¿›åº¦ç›‘æ§     â”‚    â”‚ â”œâ”€ç»“æœé€šçŸ¥é˜Ÿåˆ—  â”‚    â”‚ â”œâ”€æµ‹è¯•ç»“æœåº“    â”‚
â”‚ â”œâ”€å†å²æŸ¥è¯¢     â”‚    â”‚ â”œâ”€å‘Šè­¦æ¶ˆæ¯é˜Ÿåˆ—  â”‚    â”‚ â”œâ”€æ—¥å¿—å­˜å‚¨      â”‚
â”‚ â””â”€ç»Ÿè®¡åˆ†æ     â”‚    â”‚ â””â”€è°ƒåº¦ä»»åŠ¡é˜Ÿåˆ—  â”‚    â”‚ â””â”€æ–‡ä»¶å­˜å‚¨      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 10.2 å¹³å°æ ¸å¿ƒåŠŸèƒ½


**æµ‹è¯•ä»»åŠ¡ç®¡ç†**ï¼š
```python
#!/usr/bin/env python3
# recovery_test_platform.py - æ¢å¤æµ‹è¯•å¹³å°æ ¸å¿ƒæ¨¡å—

from flask import Flask, request, jsonify
from celery import Celery
import mysql.connector
import json
from datetime import datetime

app = Flask(__name__)

# é…ç½®Celeryä»»åŠ¡é˜Ÿåˆ—
celery = Celery('recovery_test_platform', 
                broker='redis://localhost:6379/0',
                backend='redis://localhost:6379/0')

class RecoveryTestPlatform:
    def __init__(self, db_config):
        self.db_config = db_config
        
    def create_test_task(self, test_config):
        """åˆ›å»ºæ¢å¤æµ‹è¯•ä»»åŠ¡"""
        try:
            # éªŒè¯é…ç½®
            if not self.validate_test_config(test_config):
                return {'status': 'error', 'message': 'é…ç½®éªŒè¯å¤±è´¥'}
            
            # åˆ›å»ºä»»åŠ¡è®°å½•
            task_id = self.save_test_task(test_config)
            
            # æäº¤åˆ°ä»»åŠ¡é˜Ÿåˆ—
            execute_recovery_test.delay(task_id, test_config)
            
            return {
                'status': 'success',
                'task_id': task_id,
                'message': 'æµ‹è¯•ä»»åŠ¡å·²åˆ›å»º'
            }
            
        except Exception as e:
            return {'status': 'error', 'message': f'åˆ›å»ºä»»åŠ¡å¤±è´¥: {e}'}
    
    def get_test_status(self, task_id):
        """è·å–æµ‹è¯•ä»»åŠ¡çŠ¶æ€"""
        conn = mysql.connector.connect(**self.db_config)
        try:
            cursor = conn.cursor(dictionary=True)
            cursor.execute("""
                SELECT 
                    task_id,
                    test_name,
                    status,
                    created_at,
                    started_at,
                    completed_at,
                    test_result
                FROM recovery_test_tasks 
                WHERE task_id = %s
            """, (task_id,))
            
            return cursor.fetchone()
            
        finally:
            conn.close()
    
    def get_test_history(self, limit=50):
        """è·å–æµ‹è¯•å†å²"""
        conn = mysql.connector.connect(**self.db_config)
        try:
            cursor = conn.cursor(dictionary=True)
            cursor.execute("""
                SELECT 
                    task_id,
                    test_name,
                    status,
                    created_at,
                    completed_at,
                    recovery_time_seconds,
                    success_rate
                FROM recovery_test_tasks 
                ORDER BY created_at DESC 
                LIMIT %s
            """, (limit,))
            
            return cursor.fetchall()
            
        finally:
            conn.close()

# Celeryå¼‚æ­¥ä»»åŠ¡
@celery.task
def execute_recovery_test(task_id, test_config):
    """æ‰§è¡Œæ¢å¤æµ‹è¯•çš„å¼‚æ­¥ä»»åŠ¡"""
    try:
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºè¿›è¡Œä¸­
        update_task_status(task_id, 'running', started_at=datetime.now())
        
        # æ‰§è¡Œå®é™…çš„æ¢å¤æµ‹è¯•
        test_executor = RecoveryTestExecutor(test_config)
        result = test_executor.run_test()
        
        # ä¿å­˜æµ‹è¯•ç»“æœ
        update_task_status(task_id, 'completed', 
                          completed_at=datetime.now(),
                          test_result=json.dumps(result))
        
        # å‘é€é€šçŸ¥
        send_test_notification(task_id, result)
        
    except Exception as e:
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤±è´¥
        update_task_status(task_id, 'failed',
                          completed_at=datetime.now(),
                          error_message=str(e))

# Web APIæ¥å£
@app.route('/api/recovery-test', methods=['POST'])
def create_recovery_test():
    """åˆ›å»ºæ¢å¤æµ‹è¯•API"""
    test_config = request.json
    platform = RecoveryTestPlatform(app.config['DB_CONFIG'])
    result = platform.create_test_task(test_config)
    return jsonify(result)

@app.route('/api/recovery-test/<task_id>', methods=['GET'])
def get_recovery_test_status(task_id):
    """è·å–æµ‹è¯•çŠ¶æ€API"""
    platform = RecoveryTestPlatform(app.config['DB_CONFIG'])
    result = platform.get_test_status(task_id)
    return jsonify(result)

@app.route('/api/recovery-test/history', methods=['GET'])
def get_recovery_test_history():
    """è·å–æµ‹è¯•å†å²API"""
    limit = request.args.get('limit', 50, type=int)
    platform = RecoveryTestPlatform(app.config['DB_CONFIG'])
    result = platform.get_test_history(limit)
    return jsonify(result)

if __name__ == '__main__':
    app.run(debug=True, port=5000)
```

### 10.3 æµ‹è¯•ç”¨ä¾‹è®¾è®¡


```python
#!/usr/bin/env python3
# test_case_designer.py - æ¢å¤æµ‹è¯•ç”¨ä¾‹è®¾è®¡å™¨

class RecoveryTestCaseDesigner:
    def __init__(self):
        self.test_cases = []
    
    def design_basic_test_cases(self):
        """è®¾è®¡åŸºç¡€æµ‹è¯•ç”¨ä¾‹"""
        
        # 1. å…¨é‡å¤‡ä»½æ¢å¤æµ‹è¯•
        full_backup_test = {
            'name': 'å…¨é‡å¤‡ä»½æ¢å¤æµ‹è¯•',
            'description': 'éªŒè¯mysqldumpå…¨é‡å¤‡ä»½çš„æ¢å¤èƒ½åŠ›',
            'backup_type': 'full',
            'backup_method': 'mysqldump',
            'test_scenarios': [
                {
                    'scenario': 'æ­£å¸¸æ¢å¤',
                    'backup_size': 'small',  # < 1GB
                    'expected_time': 300,    # 5åˆ†é’Ÿ
                    'validation_rules': [
                        'table_count_match',
                        'row_count_match', 
                        'data_integrity_check'
                    ]
                },
                {
                    'scenario': 'å¤§æ•°æ®é‡æ¢å¤',
                    'backup_size': 'large',  # > 10GB
                    'expected_time': 3600,   # 1å°æ—¶
                    'validation_rules': [
                        'table_count_match',
                        'sample_data_check',
                        'performance_check'
                    ]
                }
            ]
        }
        
        # 2. å¢é‡å¤‡ä»½æ¢å¤æµ‹è¯•
        incremental_test = {
            'name': 'å¢é‡å¤‡ä»½æ¢å¤æµ‹è¯•',
            'description': 'éªŒè¯binlogå¢é‡å¤‡ä»½çš„æ¢å¤èƒ½åŠ›',
            'backup_type': 'incremental',
            'backup_method': 'binlog',
            'test_scenarios': [
                {
                    'scenario': 'å•ä¸ªbinlogæ¢å¤',
                    'binlog_count': 1,
                    'expected_time': 120,
                    'validation_rules': [
                        'transaction_consistency',
                        'data_timeline_check'
                    ]
                },
                {
                    'scenario': 'å¤šä¸ªbinlogæ¢å¤',
                    'binlog_count': 10,
                    'expected_time': 600,
                    'validation_rules': [
                        'transaction_consistency', 
                        'data_timeline_check',
                        'performance_check'
                    ]
                }
            ]
        }
        
        # 3. ç‚¹æ—¶é—´æ¢å¤æµ‹è¯•
        point_in_time_test = {
            'name': 'ç‚¹æ—¶é—´æ¢å¤æµ‹è¯•',
            'description': 'éªŒè¯æ¢å¤åˆ°æŒ‡å®šæ—¶é—´ç‚¹çš„èƒ½åŠ›',
            'backup_type': 'point_in_time',
            'backup_method': 'binlog',
            'test_scenarios': [
                {
                    'scenario': 'æ¢å¤åˆ°1å°æ—¶å‰',
                    'time_offset': 3600,
                    'validation_rules': [
                        'timestamp_accuracy',
                        'data_state_check'
                    ]
                },
                {
                    'scenario': 'æ¢å¤åˆ°æŒ‡å®šäº‹åŠ¡',
                    'target_position': 'specified',
                    'validation_rules': [
                        'transaction_position_check',
                        'data_consistency_check'
                    ]
                }
            ]
        }
        
        self.test_cases = [full_backup_test, incremental_test, point_in_time_test]
        return self.test_cases
    
    def generate_test_plan(self, database_profile):
        """æ ¹æ®æ•°æ®åº“ç‰¹å¾ç”Ÿæˆæµ‹è¯•è®¡åˆ’"""
        
        test_plan = {
            'database_info': database_profile,
            'test_frequency': self.calculate_test_frequency(database_profile),
            'test_cases': [],
            'resource_requirements': self.estimate_resources(database_profile)
        }
        
        # æ ¹æ®æ•°æ®åº“é‡è¦æ€§é€‰æ‹©æµ‹è¯•ç”¨ä¾‹
        if database_profile['criticality'] == 'high':
            test_plan['test_cases'] = self.test_cases  # æ‰€æœ‰æµ‹è¯•ç”¨ä¾‹
        elif database_profile['criticality'] == 'medium':
            test_plan['test_cases'] = self.test_cases[:2]  # åŸºç¡€æµ‹è¯•ç”¨ä¾‹
        else:
            test_plan['test_cases'] = self.test_cases[:1]  # æœ€å°æµ‹è¯•ç”¨ä¾‹
        
        return test_plan
    
    def calculate_test_frequency(self, profile):
        """è®¡ç®—æµ‹è¯•é¢‘ç‡"""
        criticality_mapping = {
            'high': 'weekly',
            'medium': 'monthly', 
            'low': 'quarterly'
        }
        return criticality_mapping.get(profile['criticality'], 'monthly')
    
    def estimate_resources(self, profile):
        """è¯„ä¼°èµ„æºéœ€æ±‚"""
        data_size_gb = profile['data_size_gb']
        
        if data_size_gb < 10:
            return {'cpu_cores': 2, 'memory_gb': 4, 'disk_gb': data_size_gb * 2}
        elif data_size_gb < 100:
            return {'cpu_cores': 4, 'memory_gb': 8, 'disk_gb': data_size_gb * 1.5}
        else:
            return {'cpu_cores': 8, 'memory_gb': 16, 'disk_gb': data_size_gb * 1.2}

# ä½¿ç”¨ç¤ºä¾‹
designer = RecoveryTestCaseDesigner()
test_cases = designer.design_basic_test_cases()

# ç”Ÿæˆå…·ä½“æ•°æ®åº“çš„æµ‹è¯•è®¡åˆ’
db_profile = {
    'name': 'ecommerce_db',
    'criticality': 'high',
    'data_size_gb': 50,
    'backup_frequency': 'daily'
}

test_plan = designer.generate_test_plan(db_profile)
```

---

## 11. ğŸ“‹ æ ¸å¿ƒè¦ç‚¹æ€»ç»“


### 11.1 å¿…é¡»æŒæ¡çš„æ ¸å¿ƒæ¦‚å¿µ


```
ğŸ”¸ æ¢å¤æµ‹è¯•æœ¬è´¨ï¼šéªŒè¯å¤‡ä»½æ–‡ä»¶çš„å¯ç”¨æ€§å’Œæ¢å¤æµç¨‹çš„æœ‰æ•ˆæ€§
ğŸ”¸ æµ‹è¯•ç›®æ ‡ï¼šç¡®ä¿å…³é”®æ—¶åˆ»èƒ½å¤Ÿå¿«é€Ÿã€å‡†ç¡®åœ°æ¢å¤æ•°æ®
ğŸ”¸ æ ¸å¿ƒæµç¨‹ï¼šç¯å¢ƒå‡†å¤‡ â†’ æ‰§è¡Œæ¢å¤ â†’ æ•°æ®éªŒè¯ â†’ åŠŸèƒ½æµ‹è¯•
ğŸ”¸ å…³é”®æŒ‡æ ‡ï¼šæ¢å¤æ—¶é—´ã€æ•°æ®å®Œæ•´æ€§ã€ä¸šåŠ¡åŠŸèƒ½ã€æ€§èƒ½å½±å“
ğŸ”¸ è‡ªåŠ¨åŒ–ä»·å€¼ï¼šæé«˜æµ‹è¯•é¢‘ç‡ã€å‡å°‘äººä¸ºé”™è¯¯ã€åŠæ—¶å‘ç°é—®é¢˜
```

### 11.2 å…³é”®ç†è§£è¦ç‚¹


**ğŸ”¹ ä¸ºä»€ä¹ˆæ¢å¤æµ‹è¯•å¦‚æ­¤é‡è¦**ï¼š
```
ç°å®æ•™è®­ï¼š
- å¤‡ä»½æˆåŠŸ â‰  æ¢å¤æˆåŠŸ
- æœªç»æµ‹è¯•çš„å¤‡ä»½ = æ²¡æœ‰å¤‡ä»½
- æ¢å¤èƒ½åŠ›å†³å®šä¸šåŠ¡è¿ç»­æ€§

é¢„é˜²ä»·å€¼ï¼š
- æå‰å‘ç°å¤‡ä»½é—®é¢˜
- éªŒè¯æ¢å¤æµç¨‹æ­£ç¡®æ€§
- è¯„ä¼°çœŸå®æ¢å¤æ—¶é—´
- è®­ç»ƒè¿ç»´äººå‘˜ç†Ÿç»ƒåº¦
```

**ğŸ”¹ æ¢å¤æµ‹è¯•çš„å®Œæ•´æ€§è¦æ±‚**ï¼š
```
ä¸ä»…è¦æµ‹è¯•æ•°æ®æ¢å¤ï¼š
âœ… æ•°æ®å®Œæ•´æ€§ï¼šè¡¨ç»“æ„ã€æ•°æ®å†…å®¹ã€ç´¢å¼•å…³ç³»
âœ… ä¸šåŠ¡åŠŸèƒ½ï¼šå…³é”®ä¸šåŠ¡æµç¨‹æ˜¯å¦æ­£å¸¸
âœ… æ€§èƒ½è¡¨ç°ï¼šæŸ¥è¯¢å“åº”æ—¶é—´æ˜¯å¦æ­£å¸¸
âœ… ç³»ç»Ÿç¨³å®šæ€§ï¼šæ˜¯å¦å­˜åœ¨éšè—é—®é¢˜

è¿˜è¦è€ƒè™‘æ¢å¤è¿‡ç¨‹ï¼š
âœ… æ¢å¤æ—¶é—´ï¼šæ˜¯å¦åœ¨å¯æ¥å—èŒƒå›´å†…
âœ… èµ„æºæ¶ˆè€—ï¼šå¯¹ç³»ç»Ÿçš„å½±å“ç¨‹åº¦
âœ… æ“ä½œéš¾åº¦ï¼šè¿ç»´äººå‘˜æ˜¯å¦ç†Ÿç»ƒ
âœ… æ–‡æ¡£å®Œæ•´æ€§ï¼šæ¢å¤æ­¥éª¤æ˜¯å¦æ¸…æ™°
```

**ğŸ”¹ è‡ªåŠ¨åŒ–vsæ‰‹å·¥æµ‹è¯•çš„å¹³è¡¡**ï¼š
```
è‡ªåŠ¨åŒ–æµ‹è¯•ä¼˜åŠ¿ï¼š
- æ‰§è¡Œé¢‘ç‡é«˜ï¼Œè¦†ç›–é¢å¹¿
- æ ‡å‡†åŒ–æµç¨‹ï¼Œå‡å°‘é”™è¯¯
- æŒç»­ç›‘æ§ï¼ŒåŠæ—¶å‘ç°é—®é¢˜

æ‰‹å·¥æµ‹è¯•ä»·å€¼ï¼š
- çµæ´»å¤„ç†å¤æ‚åœºæ™¯
- éªŒè¯å¼‚å¸¸æƒ…å†µå¤„ç†
- è®­ç»ƒäººå‘˜åº”æ€¥èƒ½åŠ›

æœ€ä½³å®è·µï¼š
åŸºç¡€æµ‹è¯•è‡ªåŠ¨åŒ– + å¤æ‚åœºæ™¯æ‰‹å·¥éªŒè¯
```

### 11.3 å®é™…åº”ç”¨æŒ‡å¯¼


**æµ‹è¯•é¢‘ç‡å»ºè®®**ï¼š
```
æ ¸å¿ƒä¸šåŠ¡æ•°æ®åº“ï¼š
âœ… è‡ªåŠ¨åŒ–æµ‹è¯•ï¼šæ¯å‘¨æ‰§è¡Œ
âœ… å®Œæ•´æµ‹è¯•ï¼šæ¯æœˆæ‰§è¡Œ
âœ… åº”æ€¥æ¼”ç»ƒï¼šæ¯å­£åº¦æ‰§è¡Œ

ä¸€èˆ¬ä¸šåŠ¡æ•°æ®åº“ï¼š
âœ… è‡ªåŠ¨åŒ–æµ‹è¯•ï¼šæ¯æœˆæ‰§è¡Œ
âœ… å®Œæ•´æµ‹è¯•ï¼šæ¯å­£åº¦æ‰§è¡Œ
âœ… åº”æ€¥æ¼”ç»ƒï¼šæ¯åŠå¹´æ‰§è¡Œ
```

**æµ‹è¯•ç¯å¢ƒè¦æ±‚**ï¼š
```
ç¡¬ä»¶é…ç½®ï¼š
- CPU/å†…å­˜ï¼šç”Ÿäº§ç¯å¢ƒçš„50-70%
- ç£ç›˜IOï¼šä¸ç”Ÿäº§ç¯å¢ƒç›¸è¿‘
- ç½‘ç»œéš”ç¦»ï¼šé¿å…å½±å“ç”Ÿäº§ç¯å¢ƒ

è½¯ä»¶é…ç½®ï¼š
- MySQLç‰ˆæœ¬å®Œå…¨ä¸€è‡´
- æ“ä½œç³»ç»Ÿç‰ˆæœ¬ä¸€è‡´
- ç›¸å…³ä¾èµ–ç‰ˆæœ¬åŒ¹é…
```

**å¸¸è§é—®é¢˜é¢„é˜²**ï¼š
```
å¤‡ä»½æ–‡ä»¶é—®é¢˜ï¼š
âŒ æ–‡ä»¶æŸåï¼šå®šæœŸæ ¡éªŒå¤‡ä»½æ–‡ä»¶
âŒ æƒé™ä¸è¶³ï¼šç¡®ä¿æ¢å¤ç”¨æˆ·æƒé™
âŒ ç©ºé—´ä¸å¤Ÿï¼šé¢„ç•™è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´

æ¢å¤æµç¨‹é—®é¢˜ï¼š
âŒ æ­¥éª¤é—æ¼ï¼šå»ºç«‹æ ‡å‡†æ“ä½œæ‰‹å†Œ
âŒ æ“ä½œé”™è¯¯ï¼šå®šæœŸåŸ¹è®­è¿ç»´äººå‘˜
âŒ æ—¶é—´ä¼°ç®—ï¼šå‡†ç¡®æµ‹é‡æ¢å¤æ—¶é—´

éªŒè¯ä¸å……åˆ†ï¼š
âŒ æ•°æ®é—æ¼ï¼šå»ºç«‹å®Œæ•´éªŒè¯æ¸…å•
âŒ åŠŸèƒ½å¼‚å¸¸ï¼šæµ‹è¯•å…³é”®ä¸šåŠ¡æµç¨‹
âŒ æ€§èƒ½ä¸‹é™ï¼šå¯¹æ¯”æ€§èƒ½åŸºå‡†æŒ‡æ ‡
```

### 11.4 è¿›é˜¶ä¼˜åŒ–å»ºè®®


**æµ‹è¯•å¹³å°å»ºè®¾**ï¼š
```
å¹³å°åŒ–ç®¡ç†ï¼š
- ç»Ÿä¸€çš„æµ‹è¯•è°ƒåº¦å¹³å°
- æ ‡å‡†åŒ–çš„æµ‹è¯•æµç¨‹
- è‡ªåŠ¨åŒ–çš„ç»“æœåˆ†æ
- å¯è§†åŒ–çš„ç›‘æ§æŠ¥å‘Š

æŒç»­æ”¹è¿›ï¼š
- æ”¶é›†æµ‹è¯•æŒ‡æ ‡æ•°æ®
- åˆ†ææ€§èƒ½è¶‹åŠ¿å˜åŒ–
- ä¼˜åŒ–æ¢å¤æµç¨‹æ­¥éª¤
- æ›´æ–°æµ‹è¯•ç”¨ä¾‹è¦†ç›–
```

**å›¢é˜Ÿèƒ½åŠ›å»ºè®¾**ï¼š
```
æŠ€èƒ½åŸ¹è®­ï¼š
- å®šæœŸæ¢å¤æ¼”ç»ƒ
- åº”æ€¥å“åº”åŸ¹è®­
- æ•…éšœå¤„ç†æ¨¡æ‹Ÿ
- æ–°æŠ€æœ¯å­¦ä¹ 

æ–‡æ¡£ç»´æŠ¤ï¼š
- æ›´æ–°æ“ä½œæ‰‹å†Œ
- è®°å½•ç»éªŒæ•™è®­
- åˆ†äº«æœ€ä½³å®è·µ
- å»ºç«‹çŸ¥è¯†åº“
```

**æ ¸å¿ƒè®°å¿†è¦ç‚¹**ï¼š
- æ¢å¤æµ‹è¯•æ˜¯å¤‡ä»½ç­–ç•¥çš„é‡è¦ç»„æˆéƒ¨åˆ†
- è‡ªåŠ¨åŒ–æµ‹è¯•æé«˜æ•ˆç‡ï¼Œæ‰‹å·¥éªŒè¯ç¡®ä¿è´¨é‡
- å®Œæ•´çš„æµ‹è¯•åŒ…æ‹¬æ•°æ®ã€åŠŸèƒ½ã€æ€§èƒ½ä¸‰ä¸ªç»´åº¦
- å®šæœŸæ¼”ç»ƒæ˜¯ä¿éšœä¸šåŠ¡è¿ç»­æ€§çš„å…³é”®æªæ–½