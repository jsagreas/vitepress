---
title: 9ã€æ•°æ®è¿ç§»ä¸æ‰©å®¹ç­–ç•¥
---
## ğŸ“š ç›®å½•

1. [æ•°æ®è¿ç§»åŸºç¡€æ¦‚å¿µ](#1-æ•°æ®è¿ç§»åŸºç¡€æ¦‚å¿µ)
2. [æ•°æ®å¹³æ»‘è¿ç§»æŠ€æœ¯](#2-æ•°æ®å¹³æ»‘è¿ç§»æŠ€æœ¯)
3. [åœ¨çº¿æ‰©å®¹æ–¹æ¡ˆ](#3-åœ¨çº¿æ‰©å®¹æ–¹æ¡ˆ)
4. [åŒå†™ç­–ç•¥å®ç°](#4-åŒå†™ç­–ç•¥å®ç°)
5. [æ•°æ®ä¸€è‡´æ€§ä¿éšœ](#5-æ•°æ®ä¸€è‡´æ€§ä¿éšœ)
6. [é›¶åœæœºè¿ç§»æ–¹æ¡ˆ](#6-é›¶åœæœºè¿ç§»æ–¹æ¡ˆ)
7. [å¢é‡æ•°æ®åŒæ­¥ç­–ç•¥](#7-å¢é‡æ•°æ®åŒæ­¥ç­–ç•¥)
8. [è¿ç§»æ€§èƒ½ä¼˜åŒ–](#8-è¿ç§»æ€§èƒ½ä¼˜åŒ–)
9. [ç›‘æ§ä¸å¼‚å¸¸å¤„ç†](#9-ç›‘æ§ä¸å¼‚å¸¸å¤„ç†)
10. [é£é™©æ§åˆ¶ä¸å›æ»š](#10-é£é™©æ§åˆ¶ä¸å›æ»š)
11. [æ ¸å¿ƒè¦ç‚¹æ€»ç»“](#11-æ ¸å¿ƒè¦ç‚¹æ€»ç»“)

---

## 1. ğŸ¯ æ•°æ®è¿ç§»åŸºç¡€æ¦‚å¿µ


### 1.1 ä»€ä¹ˆæ˜¯æ•°æ®è¿ç§»


**ğŸ”¸ æ ¸å¿ƒå®šä¹‰**
æ•°æ®è¿ç§»å°±æ˜¯æŠŠæ•°æ®ä»ä¸€ä¸ªåœ°æ–¹"æ¬å®¶"åˆ°å¦ä¸€ä¸ªåœ°æ–¹çš„è¿‡ç¨‹ã€‚åœ¨åˆ†åº“åˆ†è¡¨åœºæ™¯ä¸‹ï¼Œä¸»è¦æ˜¯ä¸ºäº†è§£å†³å•åº“å•è¡¨å®¹é‡ç“¶é¢ˆï¼Œéœ€è¦å°†æ•°æ®é‡æ–°åˆ†å¸ƒåˆ°å¤šä¸ªåº“è¡¨ä¸­ã€‚

```
ç®€å•ç†è§£ï¼š
åŸæ¥ï¼šä¸€ä¸ªå¤§ä»“åº“è£…ä¸ä¸‹æ‰€æœ‰è´§ç‰©äº†
ç°åœ¨ï¼šéœ€è¦åˆ†æˆå¤šä¸ªå°ä»“åº“ï¼ŒæŠŠè´§ç‰©é‡æ–°åˆ†é…

æŠ€æœ¯å±‚é¢ï¼š
åŸæ¥ï¼šuserè¡¨æœ‰1000ä¸‡æ•°æ®åœ¨db1
ç°åœ¨ï¼šéœ€è¦åˆ†æˆuser_0, user_1åˆ†åˆ«åœ¨db1, db2
```

### 1.2 è¿ç§»çš„åŸºæœ¬ç±»å‹


**ğŸ“‹ è¿ç§»åœºæ™¯åˆ†ç±»**

| è¿ç§»ç±»å‹ | **è¯´æ˜** | **é€‚ç”¨åœºæ™¯** | **å¤æ‚åº¦** |
|---------|---------|-------------|-----------|
| ğŸ”„ **æ°´å¹³è¿ç§»** | `åŒä¸€å¼ è¡¨æ‹†åˆ†åˆ°å¤šä¸ªåº“è¡¨` | `å•è¡¨æ•°æ®é‡è¿‡å¤§` | `â­â­â­â­` |
| ğŸ“ **å‚ç›´è¿ç§»** | `ä¸åŒè¡¨è¿ç§»åˆ°ä¸åŒåº“` | `ä¸šåŠ¡æ¨¡å—åˆ†ç¦»` | `â­â­â­` |
| ğŸ—ï¸ **æ¶æ„è¿ç§»** | `ä»å•åº“åˆ°åˆ†åº“åˆ†è¡¨` | `ç³»ç»Ÿæ¶æ„å‡çº§` | `â­â­â­â­â­` |
| ğŸš€ **å®¹é‡æ‰©å®¹** | `å¢åŠ åˆ†ç‰‡æ•°é‡` | `ç°æœ‰åˆ†ç‰‡å®¹é‡ä¸è¶³` | `â­â­â­â­` |

### 1.3 è¿ç§»çš„åŸºæœ¬æµç¨‹


```
æ•°æ®è¿ç§»æ ‡å‡†æµç¨‹ï¼š

ç¬¬ä¸€æ­¥ï¼šç¯å¢ƒå‡†å¤‡
â”œâ”€â”€ æ–°ç¯å¢ƒæ­å»º
â”œâ”€â”€ æ•°æ®åº“åˆ›å»º
â”œâ”€â”€ è¡¨ç»“æ„åŒæ­¥
â””â”€â”€ ç´¢å¼•åˆ›å»º

ç¬¬äºŒæ­¥ï¼šæ•°æ®åŒæ­¥
â”œâ”€â”€ å†å²æ•°æ®è¿ç§»ï¼ˆå…¨é‡ï¼‰
â”œâ”€â”€ å¢é‡æ•°æ®åŒæ­¥
â”œâ”€â”€ æ•°æ®ä¸€è‡´æ€§æ ¡éªŒ
â””â”€â”€ ä¸šåŠ¡æµ‹è¯•éªŒè¯

ç¬¬ä¸‰æ­¥ï¼šæµé‡åˆ‡æ¢
â”œâ”€â”€ åŒå†™æ¨¡å¼å¯åŠ¨
â”œâ”€â”€ è¯»æµé‡é€æ­¥åˆ‡æ¢
â”œâ”€â”€ å†™æµé‡åˆ‡æ¢
â””â”€â”€ æ—§ç¯å¢ƒä¸‹çº¿

ç¬¬å››æ­¥ï¼šåç»­ä¼˜åŒ–
â”œâ”€â”€ æ€§èƒ½ç›‘æ§è°ƒä¼˜
â”œâ”€â”€ æ•°æ®æ¸…ç†
â”œâ”€â”€ èµ„æºå›æ”¶
â””â”€â”€ æ–‡æ¡£æ›´æ–°
```

> ğŸ’¡ **å…³é”®ç†è§£**ï¼šæ•°æ®è¿ç§»ä¸æ˜¯ç®€å•çš„æ•°æ®å¤åˆ¶ï¼Œè€Œæ˜¯ä¸€ä¸ªæ¶‰åŠä¸šåŠ¡è¿ç»­æ€§ã€æ•°æ®ä¸€è‡´æ€§ã€æ€§èƒ½ä¼˜åŒ–çš„ç³»ç»Ÿå·¥ç¨‹ã€‚

---

## 2. ğŸ”„ æ•°æ®å¹³æ»‘è¿ç§»æŠ€æœ¯


### 2.1 ä»€ä¹ˆæ˜¯å¹³æ»‘è¿ç§»


**å¹³æ»‘è¿ç§»**å°±æ˜¯åœ¨ä¸å½±å“ä¸šåŠ¡æ­£å¸¸è¿è¡Œçš„æƒ…å†µä¸‹ï¼Œé€æ­¥å°†æ•°æ®ä»æºåº“è¿ç§»åˆ°ç›®æ ‡åº“çš„è¿‡ç¨‹ã€‚å°±åƒç»™è¡Œé©¶ä¸­çš„æ±½è½¦æ¢è½®èƒä¸€æ ·ã€‚

### 2.2 å¹³æ»‘è¿ç§»çš„æ ¸å¿ƒåŸç†


**ğŸ”¸ åˆ†é˜¶æ®µè¿ç§»ç­–ç•¥**
```
é˜¶æ®µä¸€ï¼šåªè¯»æ—§åº“
åº”ç”¨ â”€â”€è¯»å†™â”€â”€> æ—§åº“

é˜¶æ®µäºŒï¼šåŒå†™æ¨¡å¼  
åº”ç”¨ â”€â”€å†™â”€â”€> æ—§åº“
     â””â”€â”€å†™â”€â”€> æ–°åº“
     â”€â”€è¯»â”€â”€> æ—§åº“

é˜¶æ®µä¸‰ï¼šè¯»å†™åˆ†ç¦»
åº”ç”¨ â”€â”€å†™â”€â”€> æ–°åº“
     â”€â”€è¯»â”€â”€> æ—§åº“ï¼ˆå†å²æ•°æ®ï¼‰
     â”€â”€è¯»â”€â”€> æ–°åº“ï¼ˆæ–°æ•°æ®ï¼‰

é˜¶æ®µå››ï¼šå®Œå…¨åˆ‡æ¢
åº”ç”¨ â”€â”€è¯»å†™â”€â”€> æ–°åº“
```

### 2.3 åˆ†æ‰¹è¿ç§»å®ç°


**æ•°æ®åˆ†æ‰¹ç­–ç•¥**
```sql
-- æŒ‰æ—¶é—´åˆ†æ‰¹è¿ç§»ï¼ˆæ¨èï¼‰
SELECT * FROM user_table 
WHERE create_time >= '2024-01-01' 
  AND create_time < '2024-02-01'
ORDER BY id LIMIT 10000;

-- æŒ‰ä¸»é”®åˆ†æ‰¹è¿ç§»
SELECT * FROM user_table 
WHERE id >= 1000000 AND id < 1010000
ORDER BY id;

-- æŒ‰ä¸šåŠ¡é€»è¾‘åˆ†æ‰¹
SELECT * FROM user_table 
WHERE status = 'active' 
  AND region = 'north'
LIMIT 5000;
```

**ğŸ”§ åˆ†æ‰¹è¿ç§»è„šæœ¬ç¤ºä¾‹**
```python
def batch_migrate_data():
    """åˆ†æ‰¹è¿ç§»æ•°æ®çš„åŸºæœ¬å®ç°"""
    batch_size = 10000
    offset = 0
    
    while True:
        # æŸ¥è¯¢ä¸€æ‰¹æ•°æ®
        sql = f"""
        SELECT * FROM source_table 
        ORDER BY id 
        LIMIT {batch_size} OFFSET {offset}
        """
        
        rows = source_db.execute(sql)
        if not rows:
            break
            
        # æ’å…¥ç›®æ ‡åº“
        for row in rows:
            target_shard = calculate_shard(row['user_id'])
            target_db = get_target_db(target_shard)
            target_db.insert('target_table', row)
            
        offset += batch_size
        time.sleep(0.1)  # é¿å…å¯¹æ•°æ®åº“é€ æˆå‹åŠ›
```

> âš ï¸ **æ³¨æ„äº‹é¡¹**ï¼šåˆ†æ‰¹å¤§å°è¦æ ¹æ®æ•°æ®åº“æ€§èƒ½å’Œä¸šåŠ¡æƒ…å†µè°ƒæ•´ï¼Œä¸€èˆ¬å»ºè®®1000-10000æ¡è®°å½•ä¸ºä¸€æ‰¹ã€‚

---

## 3. ğŸš€ åœ¨çº¿æ‰©å®¹æ–¹æ¡ˆ


### 3.1 æ‰©å®¹çš„åŸºæœ¬æ¦‚å¿µ


**åœ¨çº¿æ‰©å®¹**æ˜¯æŒ‡åœ¨ç³»ç»Ÿæ­£å¸¸æä¾›æœåŠ¡çš„æƒ…å†µä¸‹ï¼Œå¢åŠ æ•°æ®åº“åˆ†ç‰‡æ•°é‡ä»¥æå‡æ•´ä½“å®¹é‡å’Œæ€§èƒ½çš„è¿‡ç¨‹ã€‚

### 3.2 æ‰©å®¹ç­–ç•¥é€‰æ‹©


**ğŸ“Š å¸¸è§æ‰©å®¹æ–¹æ¡ˆå¯¹æ¯”**

| æ‰©å®¹æ–¹å¼ | **æ“ä½œå¤æ‚åº¦** | **æ•°æ®è¿ç§»é‡** | **ä¸šåŠ¡å½±å“** | **é€‚ç”¨åœºæ™¯** |
|---------|---------------|---------------|-------------|-------------|
| ğŸ”¢ **å€æ•°æ‰©å®¹** | `ä½` | `50%` | `å°` | `å®¹é‡ç¿»å€éœ€æ±‚` |
| ğŸ“ˆ **å¹³æ»‘æ‰©å®¹** | `é«˜` | `å˜åŠ¨å¤§` | `æå°` | `ç²¾ç¡®å®¹é‡æ§åˆ¶` |
| ğŸ¯ **çƒ­ç‚¹æ‰©å®¹** | `ä¸­` | `å±€éƒ¨æ•°æ®` | `ä¸­` | `å•åˆ†ç‰‡å‹åŠ›å¤§` |

### 3.3 å€æ•°æ‰©å®¹å®ç°


**2å€æ‰©å®¹ç¤ºä¾‹**
```
åŸæ¥åˆ†ç‰‡åˆ†å¸ƒï¼š
shard_0: user_id % 2 = 0 çš„æ•°æ®
shard_1: user_id % 2 = 1 çš„æ•°æ®

æ‰©å®¹ååˆ†ç‰‡åˆ†å¸ƒï¼š
shard_0: user_id % 4 = 0 çš„æ•°æ®
shard_1: user_id % 4 = 1 çš„æ•°æ®  
shard_2: user_id % 4 = 2 çš„æ•°æ®ï¼ˆä»shard_0è¿ç§»ï¼‰
shard_3: user_id % 4 = 3 çš„æ•°æ®ï¼ˆä»shard_1è¿ç§»ï¼‰

æ•°æ®è¿ç§»é‡ï¼šæ¯ä¸ªåŸåˆ†ç‰‡50%çš„æ•°æ®éœ€è¦è¿ç§»
```

**ğŸ”§ æ‰©å®¹è„šæœ¬æ ¸å¿ƒé€»è¾‘**
```python
def expand_shards_double():
    """2å€æ‰©å®¹å®ç°"""
    old_shard_count = 2
    new_shard_count = 4
    
    for old_shard_id in range(old_shard_count):
        # æ‰¾å‡ºéœ€è¦è¿ç§»çš„æ•°æ®
        migrate_data = []
        
        # æŸ¥è¯¢å½“å‰åˆ†ç‰‡æ‰€æœ‰æ•°æ®
        for row in get_shard_data(old_shard_id):
            user_id = row['user_id']
            new_shard_id = user_id % new_shard_count
            
            # å¦‚æœæ–°åˆ†ç‰‡IDä¸ç­‰äºæ—§åˆ†ç‰‡IDï¼Œéœ€è¦è¿ç§»
            if new_shard_id != old_shard_id:
                migrate_data.append((row, new_shard_id))
        
        # æ‰§è¡Œæ•°æ®è¿ç§»
        for row, target_shard in migrate_data:
            insert_to_shard(target_shard, row)
            delete_from_shard(old_shard_id, row['id'])
```

> ğŸ’¡ **æ‰©å®¹å»ºè®®**ï¼šä¼˜å…ˆé€‰æ‹©å€æ•°æ‰©å®¹ï¼Œå› ä¸ºæ•°æ®è¿ç§»è§„å¾‹æ€§å¼ºï¼Œå‡ºé”™æ¦‚ç‡ä½ã€‚

---

## 4. âœï¸ åŒå†™ç­–ç•¥å®ç°


### 4.1 åŒå†™ç­–ç•¥åŸç†


**åŒå†™**å°±æ˜¯åœ¨æ•°æ®è¿ç§»è¿‡ç¨‹ä¸­ï¼Œæ–°çš„å†™æ“ä½œåŒæ—¶å†™å…¥åˆ°æ–°æ—§ä¸¤å¥—ç³»ç»Ÿä¸­ï¼Œç¡®ä¿æ•°æ®ä¸ä¸¢å¤±ã€‚

```
åŒå†™æµç¨‹ç¤ºæ„ï¼š
           å†™è¯·æ±‚
             â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   åº”ç”¨ç¨‹åº       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚        â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”€â”
    â”‚ æ—§åº“   â”‚ â”‚ æ–°åº“  â”‚
    â”‚ (ä¸»)   â”‚ â”‚ (ä»)  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 åŒå†™å®ç°æ–¹å¼


**ğŸ”¸ åŒæ­¥åŒå†™**
```java
@Transactional
public void syncDoubleWrite(User user) {
    try {
        // å…ˆå†™ä¸»åº“ï¼ˆæ—§åº“ï¼‰
        oldDatabaseService.insert(user);
        
        // å†å†™ä»åº“ï¼ˆæ–°åº“ï¼‰
        newDatabaseService.insert(user);
        
    } catch (Exception e) {
        // ä»»ä¸€å¤±è´¥éƒ½è¦å›æ»š
        throw new RuntimeException("åŒå†™å¤±è´¥", e);
    }
}
```

**ğŸ”¸ å¼‚æ­¥åŒå†™**
```java
public void asyncDoubleWrite(User user) {
    // å…ˆå†™ä¸»åº“ï¼ˆä¿è¯ä¸šåŠ¡ä¸å—å½±å“ï¼‰
    oldDatabaseService.insert(user);
    
    // å¼‚æ­¥å†™ä»åº“
    CompletableFuture.supplyAsync(() -> {
        try {
            newDatabaseService.insert(user);
            return true;
        } catch (Exception e) {
            // è®°å½•å¤±è´¥æ—¥å¿—ï¼Œåç»­è¡¥å¿
            logger.error("æ–°åº“å†™å…¥å¤±è´¥", e);
            return false;
        }
    });
}
```

### 4.3 åŒå†™ä¸€è‡´æ€§ä¿éšœ


**æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥æœºåˆ¶**
```python
def check_double_write_consistency():
    """æ£€æŸ¥åŒå†™æ•°æ®ä¸€è‡´æ€§"""
    inconsistent_records = []
    
    # æŒ‰æ‰¹æ¬¡æ£€æŸ¥æ•°æ®
    for batch in get_data_batches():
        for record_id in batch:
            old_data = old_db.get(record_id)
            new_data = new_db.get(record_id)
            
            if old_data != new_data:
                inconsistent_records.append({
                    'id': record_id,
                    'old_data': old_data,
                    'new_data': new_data
                })
    
    # å¤„ç†ä¸ä¸€è‡´æ•°æ®
    fix_inconsistent_data(inconsistent_records)
```

> âš ï¸ **é‡è¦æé†’**ï¼šåŒå†™æœŸé—´è¦å¯†åˆ‡ç›‘æ§ä¸¤è¾¹æ•°æ®çš„ä¸€è‡´æ€§ï¼ŒåŠæ—¶å‘ç°å’Œä¿®å¤æ•°æ®å·®å¼‚ã€‚

---

## 5. âœ… æ•°æ®ä¸€è‡´æ€§ä¿éšœ


### 5.1 ä¸€è‡´æ€§æ£€éªŒçš„é‡è¦æ€§


åœ¨æ•°æ®è¿ç§»è¿‡ç¨‹ä¸­ï¼Œç¡®ä¿æ•°æ®ä¸€è‡´æ€§æ˜¯æœ€å…³é”®çš„ä»»åŠ¡ã€‚å°±åƒæ¬å®¶æ—¶è¦ç¡®ä¿æ‰€æœ‰ç‰©å“éƒ½å®Œæ•´æ— æŸåœ°åˆ°è¾¾æ–°å®¶ä¸€æ ·ã€‚

### 5.2 ä¸€è‡´æ€§æ ¡éªŒæ–¹æ³•


**ğŸ”¸ æ•°é‡æ ¡éªŒ**
```sql
-- æ£€æŸ¥è®°å½•æ€»æ•°æ˜¯å¦ä¸€è‡´
SELECT COUNT(*) FROM source_table;
SELECT COUNT(*) FROM target_table;

-- æ£€æŸ¥å„çŠ¶æ€æ•°æ®é‡
SELECT status, COUNT(*) FROM source_table GROUP BY status;
SELECT status, COUNT(*) FROM target_table GROUP BY status;
```

**ğŸ”¸ æŠ½æ ·æ ¡éªŒ**
```python
def sample_data_verification():
    """æŠ½æ ·æ•°æ®æ ¡éªŒ"""
    sample_size = 10000
    
    # éšæœºæŠ½å–æ ·æœ¬
    sample_ids = random.sample(all_record_ids, sample_size)
    
    mismatch_count = 0
    for record_id in sample_ids:
        source_data = source_db.get(record_id)
        target_data = target_db.get(record_id)
        
        if not data_equals(source_data, target_data):
            mismatch_count += 1
            log_data_mismatch(record_id, source_data, target_data)
    
    error_rate = mismatch_count / sample_size
    return error_rate < 0.001  # é”™è¯¯ç‡å°äº0.1%è®¤ä¸ºåˆæ ¼
```

**ğŸ”¸ å“ˆå¸Œæ ¡éªŒ**
```sql
-- ä½¿ç”¨MD5æ ¡éªŒæ•°æ®å®Œæ•´æ€§
SELECT MD5(CONCAT(id, name, email, created_at)) as checksum 
FROM user_table 
WHERE id BETWEEN 1000000 AND 1100000;
```

### 5.3 ä¸€è‡´æ€§ä¿®å¤æœºåˆ¶


**æ•°æ®å·®å¼‚ä¿®å¤æµç¨‹**
```
å‘ç°æ•°æ®ä¸ä¸€è‡´
        â”‚
        â–¼
   ç¡®å®šæ•°æ®æºæƒå¨æ€§
        â”‚
        â–¼
    æ‰§è¡Œæ•°æ®ä¿®å¤
        â”‚
        â–¼
    é‡æ–°æ ¡éªŒç¡®è®¤
        â”‚
        â–¼
    è®°å½•ä¿®å¤æ—¥å¿—
```

**ğŸ”§ è‡ªåŠ¨ä¿®å¤è„šæœ¬**
```python
def auto_fix_inconsistent_data():
    """è‡ªåŠ¨ä¿®å¤ä¸ä¸€è‡´æ•°æ®"""
    inconsistent_list = find_inconsistent_records()
    
    for record in inconsistent_list:
        record_id = record['id']
        
        # ä»¥æºåº“æ•°æ®ä¸ºå‡†è¿›è¡Œä¿®å¤
        source_data = source_db.get(record_id)
        
        if source_data:
            # æ›´æ–°ç›®æ ‡åº“
            target_db.update(record_id, source_data)
        else:
            # æºåº“æ²¡æœ‰åˆ™åˆ é™¤ç›®æ ‡åº“è®°å½•
            target_db.delete(record_id)
            
        logger.info(f"ä¿®å¤è®°å½•: {record_id}")
```

---

## 6. ğŸ”„ é›¶åœæœºè¿ç§»æ–¹æ¡ˆ


### 6.1 é›¶åœæœºè¿ç§»çš„æ ¸å¿ƒæ€æƒ³


**é›¶åœæœºè¿ç§»**æ˜¯æŒ‡åœ¨æ•´ä¸ªè¿ç§»è¿‡ç¨‹ä¸­ï¼Œä¸šåŠ¡ç³»ç»Ÿå§‹ç»ˆå¯ä»¥æ­£å¸¸æä¾›æœåŠ¡ï¼Œç”¨æˆ·æ„Ÿå—ä¸åˆ°ä»»ä½•ä¸­æ–­ã€‚

### 6.2 é›¶åœæœºè¿ç§»æ¶æ„


```
é›¶åœæœºè¿ç§»æ¶æ„å›¾ï¼š

    ç”¨æˆ·è¯·æ±‚
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   è´Ÿè½½å‡è¡¡å™¨   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    æ•°æ®åŒæ­¥    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   åº”ç”¨æœåŠ¡A    â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚   åº”ç”¨æœåŠ¡B    â”‚
â”‚   (è¿æ¥æ—§åº“)   â”‚                â”‚   (è¿æ¥æ–°åº“)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                                â”‚
        â–¼                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     æ—§åº“      â”‚                â”‚     æ–°åº“      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6.3 ç°åº¦è¿ç§»ç­–ç•¥


**ğŸ”¸ æŒ‰ç”¨æˆ·åˆ†ç»„è¿ç§»**
```python
def get_user_migration_group(user_id):
    """æ ¹æ®ç”¨æˆ·IDç¡®å®šè¿ç§»åˆ†ç»„"""
    # 1%ç”¨æˆ·å…ˆè¿ç§»åˆ°æ–°ç³»ç»Ÿ
    if user_id % 100 < 1:
        return 'new_system'
    else:
        return 'old_system'

def route_user_request(user_id, request):
    """æ ¹æ®ç”¨æˆ·åˆ†ç»„è·¯ç”±è¯·æ±‚"""
    group = get_user_migration_group(user_id)
    
    if group == 'new_system':
        return new_system_handler(request)
    else:
        return old_system_handler(request)
```

**ğŸ”¸ æŒ‰åŠŸèƒ½æ¨¡å—è¿ç§»**
```
ç¬¬ä¸€é˜¶æ®µï¼šåªè¿ç§»æŸ¥è¯¢åŠŸèƒ½
ç¬¬äºŒé˜¶æ®µï¼šè¿ç§»éæ ¸å¿ƒå†™åŠŸèƒ½  
ç¬¬ä¸‰é˜¶æ®µï¼šè¿ç§»æ ¸å¿ƒå†™åŠŸèƒ½
ç¬¬å››é˜¶æ®µï¼šè¿ç§»å…¨éƒ¨åŠŸèƒ½
```

### 6.4 æµé‡åˆ‡æ¢ç­–ç•¥


**æ¸è¿›å¼æµé‡åˆ‡æ¢**
```
æ—¶é—´è½´    æ–°ç³»ç»Ÿæµé‡å æ¯”    åˆ‡æ¢ç­–ç•¥
Week 1        1%          å°æµé‡éªŒè¯
Week 2        5%          åŠŸèƒ½éªŒè¯
Week 3       10%          æ€§èƒ½éªŒè¯
Week 4       25%          ç¨³å®šæ€§éªŒè¯
Week 5       50%          å¤§æµé‡éªŒè¯  
Week 6       75%          å‡†å¤‡å…¨é‡
Week 7      100%          å®Œæˆåˆ‡æ¢
```

> ğŸ’¡ **é›¶åœæœºå…³é”®**ï¼šé€šè¿‡ç°åº¦å‘å¸ƒå’Œæ¸è¿›å¼åˆ‡æ¢ï¼Œå¯ä»¥åœ¨å‘ç°é—®é¢˜æ—¶å¿«é€Ÿå›æ»šï¼Œç¡®ä¿ä¸šåŠ¡è¿ç»­æ€§ã€‚

---

## 7. ğŸ“ˆ å¢é‡æ•°æ®åŒæ­¥ç­–ç•¥


### 7.1 å¢é‡åŒæ­¥çš„å¿…è¦æ€§


åœ¨æ•°æ®è¿ç§»è¿‡ç¨‹ä¸­ï¼Œå†å²æ•°æ®è¿ç§»å¾€å¾€éœ€è¦è¾ƒé•¿æ—¶é—´ï¼ŒæœŸé—´æ–°äº§ç”Ÿçš„æ•°æ®å°±æ˜¯å¢é‡æ•°æ®ï¼Œå¿…é¡»å®æ—¶åŒæ­¥ä»¥ä¿è¯æ•°æ®å®Œæ•´æ€§ã€‚

### 7.2 å¢é‡åŒæ­¥å®ç°æ–¹æ¡ˆ


**ğŸ”¸ åŸºäºæ—¶é—´æˆ³çš„å¢é‡åŒæ­¥**
```sql
-- æŸ¥è¯¢å¢é‡æ•°æ®
SELECT * FROM user_table 
WHERE updated_at > :last_sync_time
ORDER BY updated_at;

-- æ›´æ–°åŒæ­¥æ—¶é—´ç‚¹
UPDATE sync_config 
SET last_sync_time = NOW() 
WHERE table_name = 'user_table';
```

**ğŸ”¸ åŸºäºbinlogçš„å®æ—¶åŒæ­¥**
```python
def binlog_sync_handler():
    """åŸºäºbinlogçš„å®æ—¶æ•°æ®åŒæ­¥"""
    
    def handle_insert(event):
        """å¤„ç†æ’å…¥äº‹ä»¶"""
        table = event.table
        data = event.after_values
        
        # è®¡ç®—ç›®æ ‡åˆ†ç‰‡
        shard_id = calculate_shard(data['user_id'])
        target_db = get_target_db(shard_id)
        
        # æ’å…¥åˆ°ç›®æ ‡åº“
        target_db.insert(table, data)
    
    def handle_update(event):
        """å¤„ç†æ›´æ–°äº‹ä»¶"""
        # å¯èƒ½æ¶‰åŠåˆ†ç‰‡å˜æ›´
        old_data = event.before_values
        new_data = event.after_values
        
        old_shard = calculate_shard(old_data['user_id'])
        new_shard = calculate_shard(new_data['user_id'])
        
        if old_shard == new_shard:
            # åŒåˆ†ç‰‡æ›´æ–°
            get_target_db(new_shard).update(event.table, new_data)
        else:
            # è·¨åˆ†ç‰‡æ›´æ–°ï¼ˆåˆ é™¤+æ’å…¥ï¼‰
            get_target_db(old_shard).delete(event.table, old_data['id'])
            get_target_db(new_shard).insert(event.table, new_data)
    
    # å¯åŠ¨binlogç›‘å¬
    binlog_stream = BinLogStreamReader(
        connection_settings=mysql_settings,
        server_id=100,
        only_events=[WriteRowsEvent, UpdateRowsEvent, DeleteRowsEvent]
    )
    
    for binlog_event in binlog_stream:
        if isinstance(binlog_event, WriteRowsEvent):
            handle_insert(binlog_event)
        elif isinstance(binlog_event, UpdateRowsEvent):
            handle_update(binlog_event)
```

### 7.3 å¢é‡åŒæ­¥çš„å»¶è¿Ÿæ§åˆ¶


**ç›‘æ§åŒæ­¥å»¶è¿Ÿ**
```python
def monitor_sync_delay():
    """ç›‘æ§å¢é‡åŒæ­¥å»¶è¿Ÿ"""
    
    # è·å–æºåº“æœ€æ–°æ•°æ®æ—¶é—´
    source_latest = source_db.execute(
        "SELECT MAX(updated_at) FROM user_table"
    )[0][0]
    
    # è·å–ç›®æ ‡åº“æœ€æ–°åŒæ­¥æ—¶é—´
    target_latest = target_db.execute(
        "SELECT MAX(updated_at) FROM user_table"
    )[0][0]
    
    delay_seconds = (source_latest - target_latest).total_seconds()
    
    if delay_seconds > 60:  # å»¶è¿Ÿè¶…è¿‡1åˆ†é’ŸæŠ¥è­¦
        alert_manager.send_alert(f"æ•°æ®åŒæ­¥å»¶è¿Ÿ: {delay_seconds}ç§’")
    
    return delay_seconds
```

> âš ï¸ **æ³¨æ„**ï¼šå¢é‡åŒæ­¥çš„å»¶è¿Ÿç›´æ¥å½±å“æ•°æ®ä¸€è‡´æ€§ï¼Œå¿…é¡»ä¸¥æ ¼ç›‘æ§å’Œæ§åˆ¶åœ¨å¯æ¥å—èŒƒå›´å†…ã€‚

---

## 8. âš¡ è¿ç§»æ€§èƒ½ä¼˜åŒ–


### 8.1 æ€§èƒ½ä¼˜åŒ–çš„å…³é”®ç‚¹


æ•°æ®è¿ç§»æ€§èƒ½ç›´æ¥å½±å“è¿ç§»æ—¶é—´å’Œå¯¹ä¸šåŠ¡çš„å½±å“ç¨‹åº¦ï¼Œéœ€è¦ä»å¤šä¸ªç»´åº¦è¿›è¡Œä¼˜åŒ–ã€‚

### 8.2 I/Oæ€§èƒ½ä¼˜åŒ–


**ğŸ”¸ æ‰¹é‡æ“ä½œä¼˜åŒ–**
```python
# âŒ ä½æ•ˆçš„å•æ¡æ’å…¥
for record in records:
    target_db.execute("INSERT INTO table VALUES (...)", record)

# âœ… é«˜æ•ˆçš„æ‰¹é‡æ’å…¥  
def batch_insert_optimized(records, batch_size=1000):
    """ä¼˜åŒ–çš„æ‰¹é‡æ’å…¥"""
    
    for i in range(0, len(records), batch_size):
        batch = records[i:i + batch_size]
        
        # æ„å»ºæ‰¹é‡æ’å…¥SQL
        values_list = []
        params = []
        
        for record in batch:
            values_list.append("(%s, %s, %s)")
            params.extend([record['id'], record['name'], record['email']])
        
        sql = f"INSERT INTO user_table (id, name, email) VALUES {','.join(values_list)}"
        target_db.execute(sql, params)
```

**ğŸ”¸ å¹¶è¡Œå¤„ç†ä¼˜åŒ–**
```python
def parallel_migration():
    """å¹¶è¡Œæ•°æ®è¿ç§»"""
    import concurrent.futures
    
    # æŒ‰IDèŒƒå›´åˆ†å‰²ä»»åŠ¡
    def migrate_range(start_id, end_id):
        records = source_db.execute(
            "SELECT * FROM user_table WHERE id >= %s AND id < %s",
            [start_id, end_id]
        )
        batch_insert_optimized(records)
    
    # åˆ›å»ºå¹¶è¡Œä»»åŠ¡
    ranges = [(i, i + 100000) for i in range(0, 10000000, 100000)]
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
        futures = [executor.submit(migrate_range, start, end) for start, end in ranges]
        
        for future in concurrent.futures.as_completed(futures):
            try:
                future.result()
            except Exception as e:
                logger.error(f"è¿ç§»ä»»åŠ¡å¤±è´¥: {e}")
```

### 8.3 æ•°æ®åº“å‚æ•°ä¼˜åŒ–


**MySQLå‚æ•°è°ƒä¼˜**
```sql
-- è¿ç§»æœŸé—´çš„ä¸´æ—¶ä¼˜åŒ–å‚æ•°
SET GLOBAL innodb_buffer_pool_size = 8G;          -- å¢å¤§ç¼“å†²æ± 
SET GLOBAL innodb_log_file_size = 2G;             -- å¢å¤§æ—¥å¿—æ–‡ä»¶
SET GLOBAL innodb_flush_log_at_trx_commit = 2;    -- æ”¾å®½æ—¥å¿—åˆ·ç›˜ç­–ç•¥
SET GLOBAL sync_binlog = 100;                     -- å‡å°‘binlogåˆ·ç›˜é¢‘ç‡
SET GLOBAL innodb_io_capacity = 2000;             -- æé«˜IOèƒ½åŠ›

-- ç›®æ ‡è¡¨ä¼˜åŒ–
ALTER TABLE target_table DISABLE KEYS;            -- ç¦ç”¨ç´¢å¼•æ›´æ–°
-- æ‰§è¡Œæ•°æ®è¿ç§»
ALTER TABLE target_table ENABLE KEYS;             -- é‡æ–°å¯ç”¨ç´¢å¼•
```

### 8.4 ç½‘ç»œä¼ è¾“ä¼˜åŒ–


**æ•°æ®å‹ç¼©ä¼ è¾“**
```python
def compressed_data_transfer():
    """å‹ç¼©æ•°æ®ä¼ è¾“"""
    import gzip
    import json
    
    # æ•°æ®åºåˆ—åŒ–å¹¶å‹ç¼©
    def compress_data(data):
        json_str = json.dumps(data, ensure_ascii=False)
        compressed = gzip.compress(json_str.encode('utf-8'))
        return compressed
    
    # ä¼ è¾“è§£å‹
    def decompress_data(compressed_data):
        decompressed = gzip.decompress(compressed_data)
        return json.loads(decompressed.decode('utf-8'))
```

**ğŸ”¸ æ€§èƒ½ç›‘æ§æŒ‡æ ‡**

| æŒ‡æ ‡ç±»å‹ | **ç›‘æ§é¡¹** | **æ­£å¸¸èŒƒå›´** | **ä¼˜åŒ–å»ºè®®** |
|---------|-----------|-------------|-------------|
| ğŸ“Š **ååé‡** | `records/second` | `>1000` | `å¢åŠ å¹¶å‘åº¦` |
| â±ï¸ **å»¶è¿Ÿ** | `avg_latency` | `<100ms` | `ä¼˜åŒ–SQLå’Œç´¢å¼•` |
| ğŸ’¾ **èµ„æº** | `CPU/Memory` | `<80%` | `è°ƒæ•´æ‰¹æ¬¡å¤§å°` |
| ğŸŒ **ç½‘ç»œ** | `bandwidth` | `å……åˆ†åˆ©ç”¨` | `æ•°æ®å‹ç¼©ä¼ è¾“` |

---

## 9. ğŸ“Š ç›‘æ§ä¸å¼‚å¸¸å¤„ç†


### 9.1 è¿ç§»è¿‡ç¨‹ç›‘æ§ä½“ç³»


**å®Œæ•´çš„ç›‘æ§ä½“ç³»**åŒ…æ‹¬è¿›åº¦ç›‘æ§ã€æ€§èƒ½ç›‘æ§ã€å¼‚å¸¸ç›‘æ§å’Œä¸šåŠ¡å½±å“ç›‘æ§ã€‚

### 9.2 è¿›åº¦ç›‘æ§å®ç°


**ğŸ”¸ è¿ç§»è¿›åº¦å¯è§†åŒ–**
```python
class MigrationProgressMonitor:
    """è¿ç§»è¿›åº¦ç›‘æ§å™¨"""
    
    def __init__(self):
        self.total_records = 0
        self.migrated_records = 0
        self.start_time = None
        
    def start_monitoring(self, total_count):
        """å¼€å§‹ç›‘æ§"""
        self.total_records = total_count
        self.start_time = datetime.now()
        
    def update_progress(self, migrated_count):
        """æ›´æ–°è¿›åº¦"""
        self.migrated_records = migrated_count
        
        # è®¡ç®—è¿›åº¦ç™¾åˆ†æ¯”
        progress_percent = (migrated_count / self.total_records) * 100
        
        # ä¼°ç®—å‰©ä½™æ—¶é—´
        elapsed_time = datetime.now() - self.start_time
        if migrated_count > 0:
            estimated_total_time = elapsed_time * (self.total_records / migrated_count)
            remaining_time = estimated_total_time - elapsed_time
        else:
            remaining_time = "æœªçŸ¥"
            
        # è¾“å‡ºè¿›åº¦ä¿¡æ¯
        logger.info(f"""
        è¿ç§»è¿›åº¦: {progress_percent:.2f}%
        å·²è¿ç§»: {migrated_count:,} / {self.total_records:,}
        å·²ç”¨æ—¶é—´: {elapsed_time}
        é¢„è®¡å‰©ä½™: {remaining_time}
        """)
```

### 9.3 å¼‚å¸¸æ£€æµ‹ä¸å¤„ç†


**ğŸ”¸ å¸¸è§å¼‚å¸¸ç±»å‹åŠå¤„ç†**
```python
class MigrationExceptionHandler:
    """è¿ç§»å¼‚å¸¸å¤„ç†å™¨"""
    
    def handle_connection_error(self, error):
        """å¤„ç†è¿æ¥å¼‚å¸¸"""
        logger.error(f"æ•°æ®åº“è¿æ¥å¼‚å¸¸: {error}")
        
        # é‡è¯•æœºåˆ¶
        for retry_count in range(3):
            try:
                time.sleep(2 ** retry_count)  # æŒ‡æ•°é€€é¿
                self.reconnect_database()
                return True
            except Exception as e:
                logger.warning(f"é‡è¿å¤±è´¥ #{retry_count + 1}: {e}")
        
        # é‡è¯•å¤±è´¥ï¼Œå‘é€å‘Šè­¦
        self.send_alert("æ•°æ®åº“è¿æ¥æŒç»­å¤±è´¥ï¼Œè¿ç§»æš‚åœ")
        return False
    
    def handle_data_inconsistency(self, record_id, source_data, target_data):
        """å¤„ç†æ•°æ®ä¸ä¸€è‡´"""
        logger.error(f"æ•°æ®ä¸ä¸€è‡´: ID={record_id}")
        
        # è®°å½•åˆ°å¼‚å¸¸è¡¨
        self.log_inconsistency(record_id, source_data, target_data)
        
        # è‡ªåŠ¨ä¿®å¤å°è¯•
        try:
            self.fix_inconsistent_record(record_id, source_data)
            logger.info(f"è‡ªåŠ¨ä¿®å¤æˆåŠŸ: ID={record_id}")
        except Exception as e:
            logger.error(f"è‡ªåŠ¨ä¿®å¤å¤±è´¥: ID={record_id}, Error={e}")
            self.send_alert(f"æ•°æ®ä¿®å¤å¤±è´¥ï¼Œéœ€è¦äººå·¥ä»‹å…¥: {record_id}")
    
    def handle_performance_degradation(self, current_speed, threshold_speed):
        """å¤„ç†æ€§èƒ½ä¸‹é™"""
        if current_speed < threshold_speed * 0.5:
            logger.warning("è¿ç§»é€Ÿåº¦ä¸¥é‡ä¸‹é™ï¼Œè°ƒæ•´ç­–ç•¥")
            
            # å‡å°‘å¹¶å‘åº¦
            self.reduce_concurrency()
            
            # å¢åŠ æ‰¹æ¬¡é—´éš”
            self.increase_batch_interval()
            
            # æ£€æŸ¥ç³»ç»Ÿèµ„æº
            self.check_system_resources()
```

### 9.4 ç›‘æ§å‘Šè­¦é…ç½®


**ğŸ”¸ å‘Šè­¦è§„åˆ™é…ç½®**
```yaml
# ç›‘æ§å‘Šè­¦é…ç½®
migration_alerts:
  progress_alerts:
    - condition: "progress_speed < 1000 records/minute"
      level: "warning"
      message: "è¿ç§»é€Ÿåº¦è¿‡æ…¢"
      
    - condition: "no_progress_for > 5 minutes"
      level: "critical"
      message: "è¿ç§»è¿›ç¨‹åœæ»"
      
  data_quality_alerts:
    - condition: "data_inconsistency_rate > 0.1%"
      level: "error"
      message: "æ•°æ®ä¸ä¸€è‡´ç‡è¿‡é«˜"
      
    - condition: "missing_records > 0"
      level: "critical"
      message: "å‘ç°æ•°æ®ä¸¢å¤±"
      
  system_alerts:
    - condition: "cpu_usage > 90%"
      level: "warning"
      message: "CPUä½¿ç”¨ç‡è¿‡é«˜"
      
    - condition: "disk_space < 10%"
      level: "critical"
      message: "ç£ç›˜ç©ºé—´ä¸è¶³"
```

---

## 10. ğŸ”’ é£é™©æ§åˆ¶ä¸å›æ»š


### 10.1 è¿ç§»é£é™©è¯„ä¼°


**é£é™©è¯„ä¼°çŸ©é˜µ**

| é£é™©ç±»å‹ | **å‘ç”Ÿæ¦‚ç‡** | **å½±å“ç¨‹åº¦** | **é£é™©ç­‰çº§** | **åº”å¯¹ç­–ç•¥** |
|---------|-------------|-------------|-------------|-------------|
| ğŸ”¥ **æ•°æ®ä¸¢å¤±** | `ä½` | `æé«˜` | `é«˜é£é™©` | `å¤šé‡å¤‡ä»½+æ ¡éªŒ` |
| âš ï¸ **æ€§èƒ½å½±å“** | `ä¸­` | `ä¸­` | `ä¸­é£é™©` | `é™æµ+ç›‘æ§` |
| ğŸš« **æœåŠ¡ä¸­æ–­** | `ä½` | `é«˜` | `ä¸­é£é™©` | `ç°åº¦å‘å¸ƒ+å¿«é€Ÿå›æ»š` |
| ğŸ“‰ **æ•°æ®ä¸ä¸€è‡´** | `ä¸­` | `é«˜` | `é«˜é£é™©` | `å®æ—¶æ ¡éªŒ+è‡ªåŠ¨ä¿®å¤` |

### 10.2 å›æ»šæ–¹æ¡ˆè®¾è®¡


**ğŸ”¸ å¿«é€Ÿå›æ»šæœºåˆ¶**
```python
class MigrationRollbackManager:
    """è¿ç§»å›æ»šç®¡ç†å™¨"""
    
    def __init__(self):
        self.rollback_points = []  # å›æ»šç‚¹åˆ—è¡¨
        self.rollback_scripts = []  # å›æ»šè„šæœ¬
        
    def create_rollback_point(self, point_name):
        """åˆ›å»ºå›æ»šç‚¹"""
        rollback_point = {
            'name': point_name,
            'timestamp': datetime.now(),
            'database_state': self.capture_database_state(),
            'config_state': self.capture_config_state()
        }
        self.rollback_points.append(rollback_point)
        
    def execute_rollback(self, target_point):
        """æ‰§è¡Œå›æ»š"""
        logger.info(f"å¼€å§‹å›æ»šåˆ°: {target_point}")
        
        try:
            # 1. åœæ­¢å½“å‰è¿ç§»è¿›ç¨‹
            self.stop_migration_process()
            
            # 2. åˆ‡æ¢æµé‡åˆ°æ—§ç³»ç»Ÿ
            self.switch_traffic_to_old_system()
            
            # 3. æ¢å¤æ•°æ®åº“çŠ¶æ€
            self.restore_database_state(target_point)
            
            # 4. æ¢å¤é…ç½®çŠ¶æ€
            self.restore_config_state(target_point)
            
            # 5. éªŒè¯å›æ»šç»“æœ
            if self.validate_rollback():
                logger.info("å›æ»šæˆåŠŸå®Œæˆ")
                return True
            else:
                logger.error("å›æ»šéªŒè¯å¤±è´¥")
                return False
                
        except Exception as e:
            logger.error(f"å›æ»šè¿‡ç¨‹å‡ºé”™: {e}")
            self.emergency_rollback()
            return False
    
    def emergency_rollback(self):
        """ç´§æ€¥å›æ»š"""
        # ç«‹å³åˆ‡æ¢åˆ°å¤‡ç”¨ç³»ç»Ÿ
        self.switch_to_backup_system()
        
        # å‘é€ç´§æ€¥å‘Šè­¦
        self.send_emergency_alert("è¿ç§»å›æ»šå¤±è´¥ï¼Œå·²åˆ‡æ¢åˆ°å¤‡ç”¨ç³»ç»Ÿ")
```

### 10.3 æ•°æ®å®‰å…¨ä¿éšœ


**ğŸ”¸ å¤šé‡æ•°æ®å¤‡ä»½**
```bash
# è¿ç§»å‰å®Œæ•´å¤‡ä»½
mysqldump --single-transaction --routines --triggers \
  --master-data=2 database_name > backup_$(date +%Y%m%d_%H%M%S).sql

# å¢é‡å¤‡ä»½è„šæœ¬
#!/bin/bash
BACKUP_DIR="/backup/incremental"
LAST_BACKUP=$(cat /backup/last_backup_position.txt)

mysqldump --single-transaction --flush-logs \
  --master-data=2 --where="updated_at > '$LAST_BACKUP'" \
  database_name > $BACKUP_DIR/incremental_$(date +%Y%m%d_%H%M%S).sql
```

**ğŸ”¸ æ•°æ®éªŒè¯æ£€æŸ¥ç‚¹**
```python
def migration_checkpoint_validation():
    """è¿ç§»æ£€æŸ¥ç‚¹éªŒè¯"""
    
    checkpoints = [
        ("æ•°æ®æ€»é‡æ£€æŸ¥", validate_total_count),
        ("å…³é”®æ•°æ®æŠ½æ ·", validate_sample_data),  
        ("ä¸šåŠ¡é€»è¾‘éªŒè¯", validate_business_logic),
        ("æ€§èƒ½åŸºå‡†æµ‹è¯•", validate_performance),
        ("æ•°æ®å®Œæ•´æ€§æ ¡éªŒ", validate_data_integrity)
    ]
    
    for checkpoint_name, validator in checkpoints:
        logger.info(f"æ‰§è¡Œæ£€æŸ¥ç‚¹: {checkpoint_name}")
        
        if not validator():
            logger.error(f"æ£€æŸ¥ç‚¹å¤±è´¥: {checkpoint_name}")
            return False
            
        logger.info(f"æ£€æŸ¥ç‚¹é€šè¿‡: {checkpoint_name}")
    
    return True
```

> ğŸ”’ **å®‰å…¨åŸåˆ™**ï¼šæ¯ä¸ªå…³é”®æ“ä½œéƒ½è¦æœ‰å¯¹åº”çš„å›æ»šæ–¹æ¡ˆï¼Œç¡®ä¿åœ¨ä»»ä½•æƒ…å†µä¸‹éƒ½èƒ½å¿«é€Ÿæ¢å¤ä¸šåŠ¡ã€‚

---

## 11. ğŸ“‹ æ ¸å¿ƒè¦ç‚¹æ€»ç»“


### 11.1 æ•°æ®è¿ç§»çš„æ ¸å¿ƒåŸåˆ™


```
ğŸ¯ ä¸šåŠ¡è¿ç»­æ€§ä¼˜å…ˆï¼šè¿ç§»è¿‡ç¨‹ä¸èƒ½å½±å“æ­£å¸¸ä¸šåŠ¡
ğŸ”’ æ•°æ®å®‰å…¨æ€§ä¿éšœï¼šå¤šé‡å¤‡ä»½ï¼Œä¸¥æ ¼æ ¡éªŒï¼Œå¿«é€Ÿå›æ»š
âš¡ æ€§èƒ½å½±å“æœ€å°åŒ–ï¼šåˆ†æ‰¹å¤„ç†ï¼Œé”™å³°æ‰§è¡Œï¼Œèµ„æºæ§åˆ¶
ğŸ“Š è¿‡ç¨‹å¯ç›‘æ§å¯æ§ï¼šå®æ—¶ç›‘æ§ï¼Œå¼‚å¸¸å‘Šè­¦ï¼Œè¿›åº¦è·Ÿè¸ª
```

### 11.2 å…³é”®æŠ€æœ¯è¦ç‚¹


**ğŸ”¹ å¹³æ»‘è¿ç§»ä¸‰é˜¶æ®µ**
```
é˜¶æ®µä¸€ï¼šå†å²æ•°æ®æ‰¹é‡è¿ç§»
- åˆ†æ‰¹æ¬¡ï¼Œæ§åˆ¶å½±å“
- é”™å³°æ‰§è¡Œï¼Œé¿å…é«˜å³°
- å¤šé‡æ ¡éªŒï¼Œç¡®ä¿æ­£ç¡®

é˜¶æ®µäºŒï¼šåŒå†™æ¨¡å¼è¿‡æ¸¡
- æ–°æ•°æ®åŒæ—¶å†™å…¥æ–°æ—§ç³»ç»Ÿ
- å¢é‡åŒæ­¥ï¼Œä¿æŒä¸€è‡´
- å®æ—¶ç›‘æ§ï¼ŒåŠæ—¶ä¿®å¤

é˜¶æ®µä¸‰ï¼šæµé‡åˆ‡æ¢å®Œæˆ
- ç°åº¦å‘å¸ƒï¼Œé€æ­¥åˆ‡æ¢
- æ€§èƒ½éªŒè¯ï¼Œç¨³å®šæ€§æµ‹è¯•
- å®Œå…¨åˆ‡æ¢ï¼Œä¸‹çº¿æ—§ç³»ç»Ÿ
```

**ğŸ”¹ æ€§èƒ½ä¼˜åŒ–å…³é”®ç‚¹**
```
æ•°æ®ä¼ è¾“ä¼˜åŒ–ï¼š
âœ… æ‰¹é‡æ“ä½œä»£æ›¿å•æ¡æ“ä½œ
âœ… å¹¶è¡Œå¤„ç†æå‡æ•ˆç‡
âœ… æ•°æ®å‹ç¼©å‡å°‘ä¼ è¾“é‡
âœ… åˆç†æ§åˆ¶å¹¶å‘åº¦

æ•°æ®åº“ä¼˜åŒ–ï¼š
âœ… ä¸´æ—¶è°ƒæ•´æ•°æ®åº“å‚æ•°
âœ… ç¦ç”¨éå¿…è¦ç´¢å¼•æ›´æ–°
âœ… ä¼˜åŒ–æŸ¥è¯¢å’Œæ’å…¥è¯­å¥
âœ… é€‰æ‹©åˆé€‚çš„äº‹åŠ¡éš”ç¦»çº§åˆ«
```

### 11.3 å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ


**â“ è¿ç§»é€Ÿåº¦å¤ªæ…¢æ€ä¹ˆåŠï¼Ÿ**
- å¢åŠ å¹¶è¡Œåº¦ï¼Œä½†æ³¨æ„èµ„æºé™åˆ¶
- ä¼˜åŒ–SQLè¯­å¥å’Œç´¢å¼•
- è°ƒæ•´æ‰¹æ¬¡å¤§å°å’Œé—´éš”æ—¶é—´
- å‡çº§ç¡¬ä»¶é…ç½®ï¼ˆä¸´æ—¶ï¼‰

**â“ æ•°æ®ä¸ä¸€è‡´æ€ä¹ˆå¤„ç†ï¼Ÿ**
- ç«‹å³åœæ­¢è¿ç§»ï¼Œå®šä½åŸå› 
- åŸºäºæƒå¨æ•°æ®æºè¿›è¡Œä¿®å¤
- åŠ å¼ºæ ¡éªŒæœºåˆ¶ï¼Œé˜²æ­¢å†æ¬¡å‘ç”Ÿ
- å¿…è¦æ—¶å›æ»šåˆ°å®‰å…¨çŠ¶æ€

**â“ å¦‚ä½•ä¿è¯é›¶åœæœºï¼Ÿ**
- ä½¿ç”¨åŒå†™ç­–ç•¥è¿‡æ¸¡
- å®æ–½ç°åº¦å‘å¸ƒæ–¹æ¡ˆ
- å‡†å¤‡å¿«é€Ÿå›æ»šæœºåˆ¶
- å……åˆ†çš„æµ‹è¯•å’Œæ¼”ç»ƒ

### 11.4 æœ€ä½³å®è·µå»ºè®®


> ğŸ’¡ **æ ¸å¿ƒå»ºè®®**
> 
> 1. **å……åˆ†å‡†å¤‡**ï¼šåˆ¶å®šè¯¦ç»†çš„è¿ç§»è®¡åˆ’ï¼ŒåŒ…æ‹¬æ—¶é—´å®‰æ’ã€äººå‘˜åˆ†å·¥ã€åº”æ€¥é¢„æ¡ˆ
> 2. **å°æ­¥å¿«è·‘**ï¼šé‡‡ç”¨æ¸è¿›å¼è¿ç§»ï¼Œæ¯ä¸ªé˜¶æ®µéƒ½è¦éªŒè¯æˆåŠŸåå†è¿›è¡Œä¸‹ä¸€æ­¥
> 3. **å®æ—¶ç›‘æ§**ï¼šå»ºç«‹å®Œå–„çš„ç›‘æ§ä½“ç³»ï¼ŒåŠæ—¶å‘ç°å’Œå¤„ç†é—®é¢˜
> 4. **å¤šé‡æ ¡éªŒ**ï¼šä»æ•°é‡ã€å†…å®¹ã€ä¸šåŠ¡é€»è¾‘ç­‰å¤šä¸ªç»´åº¦éªŒè¯æ•°æ®æ­£ç¡®æ€§
> 5. **æ¼”ç»ƒéªŒè¯**ï¼šåœ¨ç”Ÿäº§ç¯å¢ƒæ“ä½œå‰ï¼ŒåŠ¡å¿…åœ¨æµ‹è¯•ç¯å¢ƒå®Œæ•´æ¼”ç»ƒ

**æ ¸å¿ƒè®°å¿†è¦ç‚¹**ï¼š
- æ•°æ®è¿ç§»æ˜¯ç³»ç»Ÿå·¥ç¨‹ï¼Œéœ€è¦ç»Ÿç­¹è§„åˆ’
- å¹³æ»‘è¿ç§»é€šè¿‡åŒå†™ç­–ç•¥å®ç°ä¸šåŠ¡è¿ç»­æ€§
- æ€§èƒ½ä¼˜åŒ–è¦ä»å¤šä¸ªç»´åº¦ç»¼åˆè€ƒè™‘
- ç›‘æ§å’Œå¼‚å¸¸å¤„ç†æ˜¯æˆåŠŸçš„é‡è¦ä¿éšœ
- å›æ»šæ–¹æ¡ˆæ˜¯æœ€åçš„å®‰å…¨é˜²çº¿ï¼Œå¿…é¡»å‡†å¤‡å……åˆ†