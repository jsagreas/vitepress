---
title: 3、表碎片管理与空间回收
---
## 📚 目录

1. [表碎片产生原因与机制](#1-表碎片产生原因与机制)
2. [碎片类型识别与诊断](#2-碎片类型识别与诊断)
3. [碎片空间统计与计算](#3-碎片空间统计与计算)
4. [碎片整理策略与方案](#4-碎片整理策略与方案)
5. [空间回收实战操作](#5-空间回收实战操作)
6. [碎片监控与自动化](#6-碎片监控与自动化)
7. [核心要点总结](#7-核心要点总结)

---

## 1. 🔍 表碎片产生原因与机制


### 1.1 什么是表碎片


**通俗理解**：表碎片就像是一本书的页面被撕散了，页码不连续了

```
正常的表数据布局：
┌─────┬─────┬─────┬─────┬─────┐
│ 页1 │ 页2 │ 页3 │ 页4 │ 页5 │  ← 数据连续存储
└─────┴─────┴─────┴─────┴─────┘

产生碎片后的布局：
┌─────┬─────┬─────┬─────┬─────┐
│ 页1 │空洞 │ 页3 │空洞 │ 页5 │  ← 中间有很多空隙
└─────┴─────┴─────┴─────┴─────┘
```

**碎片的本质**：
- **数据存储不连续**：原本紧密排列的数据变得分散
- **空间浪费**：删除数据后留下的空洞没有被重新利用
- **性能影响**：查询时需要跳过更多的空间，效率下降

### 1.2 碎片产生的根本原因


**🔸 频繁的DELETE操作**
```sql
-- 例如：删除过期订单记录
DELETE FROM orders WHERE create_time < '2023-01-01';

-- 结果：表中留下很多空洞
数据页状态：
[数据][数据][空洞][数据][空洞][空洞][数据]
```

**🔸 大量的UPDATE操作**
```sql
-- 更新用户信息，可能导致行长度变化
UPDATE users SET description = '很长很长的描述信息...' WHERE id = 100;

-- 如果新数据更长，可能需要移动到其他页面
原位置变成空洞，新位置占用额外空间
```

**🔸 INSERT和DELETE的混合操作**
```
时间线演示：
T1: 插入数据 [1][2][3][4][5]
T2: 删除部分 [1][ ][3][ ][5]  ← 产生空洞
T3: 再次插入 [1][6][3][7][5]  ← 新数据可能不连续
```

### 1.3 MySQL存储引擎与碎片


**InnoDB存储引擎**：
- **页面结构**：数据以16KB的页面为单位存储
- **碎片特点**：删除记录后，页面内部产生空隙
- **空间回收**：同一页面内的空间可以重复利用

**MyISAM存储引擎**：
- **文件结构**：数据存储在.MYD文件中
- **碎片特点**：更容易产生文件级别的碎片
- **空间浪费**：删除数据后空间不容易回收

> 💡 **新手提示**
> 
> 现代MySQL主要使用InnoDB，所以我们重点关注InnoDB的碎片问题

---

## 2. 🔬 碎片类型识别与诊断


### 2.1 碎片的分类


**📊 按影响范围分类**

```
页面内碎片 (Page-level Fragmentation)
├─ 页面内部有空洞
├─ 记录删除后留下的空隙
└─ 影响：单页查询效率降低

表级碎片 (Table-level Fragmentation)  
├─ 数据页面分布不连续
├─ 逻辑顺序与物理顺序不匹配
└─ 影响：全表扫描效率降低
```

**🔸 页面内碎片示例**
```
一个数据页的内部结构：
┌─────────────────────────────────────┐
│ 页头 │记录1│空洞│记录3│空洞│记录5│ 页尾 │
└─────────────────────────────────────┘
       ↑删除记录2  ↑删除记录4

虽然页面还有空间，但不连续，影响查询效率
```

**🔸 表级碎片示例**
```
表的逻辑结构：ID按顺序 1,2,3,4,5
物理存储位置：分散在不同磁盘位置

逻辑顺序：[1] → [2] → [3] → [4] → [5]
物理位置：磁盘A  磁盘C  磁盘B  磁盘A  磁盘C
结果：查询时需要在磁盘间跳转，性能下降
```

### 2.2 碎片诊断SQL命令


**🔍 查看表的基本信息**
```sql
-- 查看指定表的碎片信息
SELECT 
    TABLE_NAME,
    ENGINE,
    TABLE_ROWS,
    DATA_LENGTH,
    INDEX_LENGTH,
    DATA_FREE
FROM information_schema.TABLES 
WHERE TABLE_SCHEMA = 'your_database' 
AND TABLE_NAME = 'your_table';
```

**📋 字段含义解释**
```
TABLE_ROWS   : 表中的行数（估算值）
DATA_LENGTH  : 数据文件大小（字节）
INDEX_LENGTH : 索引文件大小（字节）  
DATA_FREE    : 碎片空间大小（字节）← 重点关注
```

**🔍 批量检查数据库中的碎片情况**
```sql
-- 查看所有表的碎片情况，按碎片大小排序
SELECT 
    TABLE_SCHEMA AS '数据库',
    TABLE_NAME AS '表名',
    ENGINE AS '存储引擎',
    ROUND(DATA_LENGTH/1024/1024, 2) AS '数据大小(MB)',
    ROUND(INDEX_LENGTH/1024/1024, 2) AS '索引大小(MB)',
    ROUND(DATA_FREE/1024/1024, 2) AS '碎片大小(MB)',
    ROUND(DATA_FREE/(DATA_LENGTH+INDEX_LENGTH)*100, 2) AS '碎片率(%)'
FROM information_schema.TABLES 
WHERE TABLE_SCHEMA NOT IN ('information_schema', 'mysql', 'performance_schema', 'sys')
AND DATA_FREE > 0
ORDER BY DATA_FREE DESC;
```

> ⚠️ **注意**
> 
> `DATA_FREE`只有在InnoDB存储引擎中才有意义，MyISAM中该值通常为0

---

## 3. 📊 碎片空间统计与计算


### 3.1 碎片率计算公式


**🧮 标准碎片率公式**
```
碎片率 = 碎片空间 / (数据空间 + 索引空间) × 100%

具体计算：
碎片率(%) = DATA_FREE / (DATA_LENGTH + INDEX_LENGTH) × 100
```

**📈 碎片率等级判断**
```
碎片率分级：
🟢  0-5%    : 健康状态，无需处理
🟡  5-15%   : 轻度碎片，可考虑整理
🟠  15-30%  : 中度碎片，建议整理  
🔴  30%以上  : 严重碎片，必须整理
```

### 3.2 实际计算示例


**🔸 示例数据**
```sql
-- 假设查询结果：
TABLE_NAME: user_orders
DATA_LENGTH: 104857600    -- 100MB
INDEX_LENGTH: 52428800    -- 50MB  
DATA_FREE: 31457280       -- 30MB

计算过程：
总空间 = 100MB + 50MB = 150MB
碎片空间 = 30MB
碎片率 = 30MB / 150MB × 100% = 20%

结论：中度碎片，建议进行整理
```

**🔧 自动化计算脚本**
```sql
-- 创建碎片分析视图
CREATE VIEW v_table_fragmentation AS
SELECT 
    TABLE_SCHEMA,
    TABLE_NAME,
    ENGINE,
    TABLE_ROWS,
    ROUND(DATA_LENGTH/1024/1024, 2) AS data_size_mb,
    ROUND(INDEX_LENGTH/1024/1024, 2) AS index_size_mb,
    ROUND(DATA_FREE/1024/1024, 2) AS free_size_mb,
    ROUND(DATA_FREE/(DATA_LENGTH+INDEX_LENGTH)*100, 2) AS fragmentation_rate,
    CASE 
        WHEN DATA_FREE/(DATA_LENGTH+INDEX_LENGTH)*100 < 5 THEN '🟢 健康'
        WHEN DATA_FREE/(DATA_LENGTH+INDEX_LENGTH)*100 < 15 THEN '🟡 轻度'
        WHEN DATA_FREE/(DATA_LENGTH+INDEX_LENGTH)*100 < 30 THEN '🟠 中度'
        ELSE '🔴 严重'
    END AS fragmentation_level
FROM information_schema.TABLES 
WHERE TABLE_SCHEMA NOT IN ('information_schema', 'mysql', 'performance_schema', 'sys')
AND ENGINE = 'InnoDB'
AND DATA_FREE > 0;

-- 使用视图查询
SELECT * FROM v_table_fragmentation ORDER BY fragmentation_rate DESC;
```

### 3.3 碎片监控阈值设置


**📏 监控阈值建议**

| 表类型 | 碎片率阈值 | 处理策略 | 检查频率 |
|---------|-----------|----------|----------|
| **核心业务表** | `>10%` | 立即整理 | 每天 |
| **普通业务表** | `>20%` | 计划整理 | 每周 |
| **日志表** | `>30%` | 定期整理 | 每月 |
| **归档表** | `>50%` | 选择性整理 | 每季度 |

**🔔 告警设置示例**
```sql
-- 查找需要立即处理的高碎片表
SELECT 
    CONCAT('⚠️ 表 ', TABLE_SCHEMA, '.', TABLE_NAME, ' 碎片率过高: ', 
           ROUND(DATA_FREE/(DATA_LENGTH+INDEX_LENGTH)*100, 2), '%') AS alert_message
FROM information_schema.TABLES 
WHERE TABLE_SCHEMA NOT IN ('information_schema', 'mysql', 'performance_schema', 'sys')
AND DATA_FREE/(DATA_LENGTH+INDEX_LENGTH) > 0.30  -- 30%阈值
AND DATA_FREE > 10*1024*1024;  -- 碎片空间超过10MB
```

---

## 4. 🛠️ 碎片整理策略与方案


### 4.1 碎片整理策略选择


**📋 策略对比表**

| 整理方法 | 优点 | 缺点 | 适用场景 |
|----------|------|------|----------|
| **OPTIMIZE TABLE** | `简单易用` | `锁表时间长` | 小表或维护窗口 |
| **ALTER TABLE** | `功能强大` | `资源消耗大` | 中大型表重构 |
| **导出导入** | `彻底整理` | `操作复杂` | 超大表或严重碎片 |
| **在线工具** | `不锁表` | `需要额外工具` | 生产环境 |

### 4.2 OPTIMIZE TABLE方法


**🔸 基本语法**
```sql
-- 整理单个表
OPTIMIZE TABLE table_name;

-- 整理多个表
OPTIMIZE TABLE table1, table2, table3;

-- 查看执行结果
OPTIMIZE TABLE user_orders;
```

**📊 执行结果解读**
```
+------------------+---------+----------+----------+
| Table            | Op      | Msg_type | Msg_text |
+------------------+---------+----------+----------+
| db.user_orders   | optimize| status   | OK       |
+------------------+---------+----------+----------+

状态说明：
- OK        : 整理成功
- Table is already up to date : 表已经是最优状态
- The storage engine does not support optimize : 存储引擎不支持
```

**⚠️ 使用注意事项**
```
OPTIMIZE TABLE的限制：
1. 会锁表，影响正常业务访问
2. 对于大表，执行时间可能很长
3. 需要足够的磁盘空间（临时空间）
4. InnoDB中实际执行的是 ALTER TABLE ... ENGINE=InnoDB
```

### 4.3 ALTER TABLE重建方法


**🔸 表重建语法**
```sql
-- 重建表结构（InnoDB推荐方法）
ALTER TABLE table_name ENGINE=InnoDB;

-- 或者使用（效果相同）
ALTER TABLE table_name FORCE;
```

**🔄 重建过程示意**
```
重建过程：
原表 → 创建临时表 → 复制数据 → 重命名 → 删除原表

步骤详解：
1. 创建新的临时表结构
2. 逐行复制数据到临时表
3. 将临时表重命名为原表名
4. 删除原始表

优势：数据重新紧密排列，彻底消除碎片
```

### 4.4 大表碎片整理方案


**🎯 在线整理策略**

对于大表（>1GB），推荐使用在线工具：

**方案一：pt-online-schema-change**
```bash
# 使用Percona工具包进行在线整理
pt-online-schema-change \
  --alter "ENGINE=InnoDB" \
  --execute \
  D=database_name,t=table_name \
  --host=localhost \
  --user=root \
  --ask-pass

# 优势：
# - 不锁表，业务可正常访问
# - 支持进度监控
# - 可以随时取消操作
```

**方案二：分批处理策略**
```sql
-- 对于超大表，可以分批删除然后整理
-- 1. 分批删除过期数据
DELETE FROM large_table 
WHERE create_time < '2023-01-01' 
LIMIT 10000;

-- 2. 定期进行小规模整理
-- 选择业务低峰期执行

-- 3. 使用事件调度器自动化
CREATE EVENT optimize_large_table
ON SCHEDULE EVERY 1 WEEK
STARTS '2024-01-01 02:00:00'
DO
  OPTIMIZE TABLE large_table;
```

### 4.5 碎片整理时间窗口规划


**⏰ 时间窗口选择原则**

```
业务影响评估：
┌─────────────┬─────────────────┬─────────────────┐
│   时间段    │    业务负载     │    整理建议     │
├─────────────┼─────────────────┼─────────────────┤
│ 02:00-05:00 │      最低       │  ✅ 大表整理    │
│ 05:00-08:00 │      较低       │  ✅ 中表整理    │  
│ 08:00-18:00 │      很高       │  ❌ 避免整理    │
│ 18:00-22:00 │      高峰       │  ❌ 避免整理    │
│ 22:00-02:00 │      中等       │  ⚠️ 小表可考虑  │
└─────────────┴─────────────────┴─────────────────┘
```

**📅 整理计划模板**
```sql
-- 创建整理计划表
CREATE TABLE fragmentation_schedule (
    id INT AUTO_INCREMENT PRIMARY KEY,
    table_name VARCHAR(100),
    fragmentation_rate DECIMAL(5,2),
    priority ENUM('high', 'medium', 'low'),
    scheduled_time DATETIME,
    status ENUM('pending', 'running', 'completed', 'failed'),
    execution_time INT COMMENT '执行时间(秒)',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 插入整理计划
INSERT INTO fragmentation_schedule 
(table_name, fragmentation_rate, priority, scheduled_time) 
VALUES 
('user_orders', 25.5, 'high', '2024-01-15 02:00:00'),
('product_logs', 15.2, 'medium', '2024-01-16 02:30:00');
```

---

## 5. 🔧 空间回收实战操作


### 5.1 空间回收前的准备工作


**✅ 操作前检查清单**

- [ ] **备份数据**：确保有完整的数据备份
- [ ] **评估空间**：确认有足够的临时空间
- [ ] **检查负载**：选择业务低峰期执行
- [ ] **通知相关方**：告知可能的业务影响
- [ ] **准备回滚方案**：制定紧急回滚计划

**🔍 预检查脚本**
```sql
-- 检查表空间使用情况
SELECT 
    table_name,
    ROUND((data_length + index_length) / 1024 / 1024, 2) AS total_size_mb,
    ROUND(data_free / 1024 / 1024, 2) AS free_space_mb,
    ROUND(data_free / (data_length + index_length) * 100, 2) AS fragmentation_pct
FROM information_schema.tables
WHERE table_schema = 'your_database'
AND table_name = 'target_table';

-- 检查磁盘空间
SHOW VARIABLES LIKE 'datadir';
-- 然后在操作系统中检查磁盘空间：df -h /var/lib/mysql
```

### 5.2 空间回收操作步骤


**🚀 标准操作流程**

**步骤 1️⃣：记录操作前状态**
```sql
-- 记录整理前的状态
CREATE TEMPORARY TABLE before_optimize AS
SELECT 
    NOW() as check_time,
    'before' as status,
    table_rows,
    data_length,
    index_length,
    data_free
FROM information_schema.tables 
WHERE table_schema = 'your_db' AND table_name = 'your_table';
```

**步骤 2️⃣：执行空间回收**
```sql
-- 执行表优化
SET @start_time = NOW();
OPTIMIZE TABLE your_table;
SET @end_time = NOW();

-- 记录执行时间
SELECT TIMEDIFF(@end_time, @start_time) as execution_time;
```

**步骤 3️⃣：验证整理效果**
```sql
-- 记录整理后的状态
INSERT INTO before_optimize
SELECT 
    NOW() as check_time,
    'after' as status,
    table_rows,
    data_length,
    index_length,
    data_free
FROM information_schema.tables 
WHERE table_schema = 'your_db' AND table_name = 'your_table';

-- 对比前后效果
SELECT 
    status,
    ROUND(data_length/1024/1024, 2) as data_mb,
    ROUND(data_free/1024/1024, 2) as free_mb,
    ROUND(data_free/(data_length+index_length)*100, 2) as frag_pct
FROM before_optimize;
```

### 5.3 碎片整理性能开销


**📊 性能影响评估**

```
资源消耗分析：
┌─────────────┬─────────────┬─────────────┬─────────────┐
│   资源类型  │   消耗程度  │   影响时间  │   缓解措施  │
├─────────────┼─────────────┼─────────────┼─────────────┤
│    CPU      │    中等     │   整理期间  │ 选择低峰期  │
│   内存      │    较高     │   整理期间  │ 调整缓冲区  │
│   磁盘IO    │    很高     │   整理期间  │ 使用SSD硬盘 │
│   磁盘空间  │    临时翻倍 │   整理期间  │ 预留足够空间│
│   表锁定    │    完全锁定 │   整理期间  │ 使用在线工具│
└─────────────┴─────────────┴─────────────┴─────────────┘
```

**⏱️ 执行时间估算**
```sql
-- 根据表大小估算整理时间
-- 经验公式（仅供参考）：
-- 小表（<100MB）：1-5分钟
-- 中表（100MB-1GB）：5-30分钟  
-- 大表（1GB-10GB）：30分钟-2小时
-- 超大表（>10GB）：数小时

-- 实际测试脚本
SELECT 
    table_name,
    ROUND((data_length + index_length) / 1024 / 1024, 2) AS size_mb,
    CASE 
        WHEN (data_length + index_length) < 100*1024*1024 THEN '1-5分钟'
        WHEN (data_length + index_length) < 1024*1024*1024 THEN '5-30分钟'
        WHEN (data_length + index_length) < 10*1024*1024*1024 THEN '30分钟-2小时'
        ELSE '数小时'
    END AS estimated_time
FROM information_schema.tables
WHERE table_schema = 'your_database';
```

### 5.4 碎片整理效果验证


**✅ 效果验证指标**

```sql
-- 完整的效果验证报告
SELECT 
    '整理效果报告' as report_type,
    CONCAT('数据大小变化: ', 
           before_data_mb, 'MB → ', after_data_mb, 'MB') as data_change,
    CONCAT('碎片空间变化: ', 
           before_free_mb, 'MB → ', after_free_mb, 'MB') as free_change,
    CONCAT('碎片率变化: ', 
           before_frag_pct, '% → ', after_frag_pct, '%') as fragmentation_change,
    CONCAT('空间节省: ', 
           ROUND(before_free_mb - after_free_mb, 2), 'MB') as space_saved
FROM (
    SELECT 
        MAX(CASE WHEN status = 'before' THEN ROUND(data_length/1024/1024, 2) END) as before_data_mb,
        MAX(CASE WHEN status = 'after' THEN ROUND(data_length/1024/1024, 2) END) as after_data_mb,
        MAX(CASE WHEN status = 'before' THEN ROUND(data_free/1024/1024, 2) END) as before_free_mb,
        MAX(CASE WHEN status = 'after' THEN ROUND(data_free/1024/1024, 2) END) as after_free_mb,
        MAX(CASE WHEN status = 'before' THEN ROUND(data_free/(data_length+index_length)*100, 2) END) as before_frag_pct,
        MAX(CASE WHEN status = 'after' THEN ROUND(data_free/(data_length+index_length)*100, 2) END) as after_frag_pct
    FROM before_optimize
) summary;
```

---

## 6. 📡 碎片监控与自动化


### 6.1 碎片监控系统设计


**🔧 监控表结构设计**
```sql
-- 创建碎片监控历史表
CREATE TABLE fragmentation_monitor (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    database_name VARCHAR(64),
    table_name VARCHAR(64),
    check_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    table_rows BIGINT,
    data_length BIGINT,
    index_length BIGINT,
    data_free BIGINT,
    fragmentation_rate DECIMAL(5,2),
    fragmentation_level ENUM('healthy', 'light', 'medium', 'severe'),
    alert_sent BOOLEAN DEFAULT FALSE,
    INDEX idx_table_time (database_name, table_name, check_time),
    INDEX idx_check_time (check_time),
    INDEX idx_fragmentation_rate (fragmentation_rate)
);
```

**📊 自动化监控脚本**
```sql
-- 创建监控数据收集存储过程
DELIMITER $$
CREATE PROCEDURE sp_collect_fragmentation_data()
BEGIN
    DECLARE done INT DEFAULT FALSE;
    DECLARE v_schema VARCHAR(64);
    DECLARE v_table VARCHAR(64);
    DECLARE v_rows BIGINT;
    DECLARE v_data_length BIGINT;
    DECLARE v_index_length BIGINT;
    DECLARE v_data_free BIGINT;
    DECLARE v_frag_rate DECIMAL(5,2);
    DECLARE v_frag_level VARCHAR(10);
    
    DECLARE cur CURSOR FOR 
        SELECT TABLE_SCHEMA, TABLE_NAME, TABLE_ROWS, 
               DATA_LENGTH, INDEX_LENGTH, DATA_FREE
        FROM information_schema.TABLES 
        WHERE TABLE_SCHEMA NOT IN ('information_schema', 'mysql', 'performance_schema', 'sys')
        AND ENGINE = 'InnoDB'
        AND DATA_FREE > 0;
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    OPEN cur;
    
    read_loop: LOOP
        FETCH cur INTO v_schema, v_table, v_rows, v_data_length, v_index_length, v_data_free;
        IF done THEN
            LEAVE read_loop;
        END IF;
        
        -- 计算碎片率
        SET v_frag_rate = ROUND(v_data_free / (v_data_length + v_index_length) * 100, 2);
        
        -- 确定碎片等级
        SET v_frag_level = CASE 
            WHEN v_frag_rate < 5 THEN 'healthy'
            WHEN v_frag_rate < 15 THEN 'light'
            WHEN v_frag_rate < 30 THEN 'medium'
            ELSE 'severe'
        END;
        
        -- 插入监控数据
        INSERT INTO fragmentation_monitor 
        (database_name, table_name, table_rows, data_length, index_length, 
         data_free, fragmentation_rate, fragmentation_level)
        VALUES 
        (v_schema, v_table, v_rows, v_data_length, v_index_length, 
         v_data_free, v_frag_rate, v_frag_level);
         
    END LOOP;
    
    CLOSE cur;
END$$
DELIMITER ;
```

### 6.2 碎片整理自动化脚本


**🤖 自动化整理脚本**
```sql
-- 创建自动整理存储过程
DELIMITER $$
CREATE PROCEDURE sp_auto_optimize_tables()
BEGIN
    DECLARE done INT DEFAULT FALSE;
    DECLARE v_schema VARCHAR(64);
    DECLARE v_table VARCHAR(64);
    DECLARE v_frag_rate DECIMAL(5,2);
    DECLARE v_sql TEXT;
    DECLARE v_start_time TIMESTAMP;
    DECLARE v_end_time TIMESTAMP;
    
    DECLARE cur CURSOR FOR 
        SELECT database_name, table_name, fragmentation_rate
        FROM fragmentation_monitor 
        WHERE check_time >= CURDATE() 
        AND fragmentation_level IN ('medium', 'severe')
        AND alert_sent = FALSE
        ORDER BY fragmentation_rate DESC;
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    DECLARE CONTINUE HANDLER FOR SQLEXCEPTION 
    BEGIN
        ROLLBACK;
        GET DIAGNOSTICS CONDITION 1
            @errno = MYSQL_ERRNO, @text = MESSAGE_TEXT;
        INSERT INTO optimize_log (table_name, status, error_message) 
        VALUES (CONCAT(v_schema, '.', v_table), 'FAILED', @text);
    END;
    
    OPEN cur;
    
    optimize_loop: LOOP
        FETCH cur INTO v_schema, v_table, v_frag_rate;
        IF done THEN
            LEAVE optimize_loop;
        END IF;
        
        -- 记录开始时间
        SET v_start_time = NOW();
        
        -- 构建优化SQL
        SET v_sql = CONCAT('OPTIMIZE TABLE ', v_schema, '.', v_table);
        
        -- 执行优化（注意：这里需要动态SQL）
        SET @sql = v_sql;
        PREPARE stmt FROM @sql;
        EXECUTE stmt;
        DEALLOCATE PREPARE stmt;
        
        -- 记录结束时间
        SET v_end_time = NOW();
        
        -- 记录优化日志
        INSERT INTO optimize_log 
        (table_name, fragmentation_before, start_time, end_time, status) 
        VALUES 
        (CONCAT(v_schema, '.', v_table), v_frag_rate, v_start_time, v_end_time, 'SUCCESS');
        
    END LOOP;
    
    CLOSE cur;
END$$
DELIMITER ;
```

**📋 优化日志表**
```sql
-- 创建优化操作日志表
CREATE TABLE optimize_log (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    table_name VARCHAR(128),
    fragmentation_before DECIMAL(5,2),
    fragmentation_after DECIMAL(5,2),
    start_time TIMESTAMP,
    end_time TIMESTAMP,
    execution_seconds INT,
    status ENUM('SUCCESS', 'FAILED', 'TIMEOUT'),
    error_message TEXT,
    space_saved_mb DECIMAL(10,2),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_table_name (table_name),
    INDEX idx_start_time (start_time)
);
```

### 6.3 定时任务配置


**⏰ 事件调度器配置**
```sql
-- 开启事件调度器
SET GLOBAL event_scheduler = ON;

-- 创建每日碎片检查任务
CREATE EVENT ev_daily_fragmentation_check
ON SCHEDULE EVERY 1 DAY
STARTS '2024-01-01 01:00:00'
COMMENT '每日碎片检查任务'
DO
  CALL sp_collect_fragmentation_data();

-- 创建每周自动优化任务
CREATE EVENT ev_weekly_auto_optimize
ON SCHEDULE EVERY 1 WEEK
STARTS '2024-01-01 02:00:00'
COMMENT '每周自动优化任务'
DO
  CALL sp_auto_optimize_tables();

-- 查看事件状态
SHOW EVENTS;

-- 禁用/启用事件
-- ALTER EVENT ev_daily_fragmentation_check DISABLE;
-- ALTER EVENT ev_daily_fragmentation_check ENABLE;
```

**🐧 Cron任务配置（Linux）**
```bash
# 编辑crontab
crontab -e

# 添加定时任务
# 每天凌晨1点执行碎片检查
0 1 * * * /usr/bin/mysql -u monitor -p'password' -e "CALL your_db.sp_collect_fragmentation_data();"

# 每周日凌晨2点执行自动优化
0 2 * * 0 /usr/bin/mysql -u admin -p'password' -e "CALL your_db.sp_auto_optimize_tables();"

# 每月第一天生成碎片报告
0 3 1 * * /path/to/fragmentation_report.sh
```

### 6.4 告警通知机制


**📧 告警通知脚本**
```sql
-- 创建告警配置表
CREATE TABLE alert_config (
    id INT AUTO_INCREMENT PRIMARY KEY,
    alert_type ENUM('email', 'sms', 'webhook'),
    alert_level ENUM('medium', 'severe'),
    threshold_pct DECIMAL(5,2),
    recipient VARCHAR(255),
    is_active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 插入告警配置
INSERT INTO alert_config (alert_type, alert_level, threshold_pct, recipient) VALUES
('email', 'medium', 20.00, 'dba@company.com'),
('email', 'severe', 30.00, 'emergency@company.com'),
('webhook', 'severe', 40.00, 'http://monitor.company.com/webhook');

-- 查询需要告警的表
SELECT 
    CONCAT('🚨 碎片告警: 表 ', database_name, '.', table_name, 
           ' 碎片率达到 ', fragmentation_rate, '%') as alert_message,
    fragmentation_level,
    check_time
FROM fragmentation_monitor fm
JOIN alert_config ac ON (
    (fm.fragmentation_level = 'medium' AND ac.alert_level = 'medium' AND fm.fragmentation_rate >= ac.threshold_pct)
    OR (fm.fragmentation_level = 'severe' AND ac.alert_level = 'severe' AND fm.fragmentation_rate >= ac.threshold_pct)
)
WHERE fm.check_time >= CURDATE() 
AND fm.alert_sent = FALSE
AND ac.is_active = TRUE;
```

---

## 7. 📋 核心要点总结


### 7.1 必须掌握的核心概念


```
🔸 表碎片本质：数据存储不连续，空间浪费，性能下降
🔸 碎片产生原因：频繁DELETE、UPDATE、INSERT混合操作
🔸 碎片类型：页面内碎片和表级碎片两种
🔸 碎片计算：碎片率 = DATA_FREE / (DATA_LENGTH + INDEX_LENGTH) × 100%
🔸 整理策略：OPTIMIZE TABLE、ALTER TABLE、导出导入、在线工具
🔸 监控自动化：定期检查、自动整理、告警通知
```

### 7.2 关键理解要点


**🔹 为什么会产生碎片**
```
根本原因：MySQL的数据存储机制
- 数据以页面为单位存储（16KB）
- 删除记录后页面内产生空洞
- 新插入数据可能无法完全填满空洞
- 随时间推移碎片逐渐累积
```

**🔹 碎片的实际影响**
```
性能影响：
- 查询效率下降：需要读取更多页面
- 存储空间浪费：实际可用空间减少
- 备份时间增长：备份文件包含碎片空间
- 内存效率降低：缓存命中率下降
```

**🔹 何时需要整理碎片**
```
整理时机判断：
✅ 碎片率 > 20% 且碎片空间 > 100MB
✅ 查询性能明显下降
✅ 有计划的维护窗口
✅ 磁盘空间不足时

❌ 避免整理的情况：
❌ 业务高峰期
❌ 磁盘空间不足（少于表大小的2倍）
❌ 表正在被大量访问
❌ 没有完整备份
```

### 7.3 实际应用价值


**📊 业务价值**
- **性能提升**：查询速度提高20-50%
- **空间节省**：回收10-40%的存储空间  
- **成本降低**：减少存储和备份成本
- **稳定性增强**：减少因空间问题导致的故障

**🔧 运维价值**
- **自动化管理**：减少人工干预
- **预防性维护**：避免问题积累
- **监控体系**：及时发现和处理问题
- **标准化流程**：建立规范的操作流程

### 7.4 最佳实践建议


**🎯 日常管理建议**
```
预防策略：
1. 合理设计表结构，避免频繁的大字段更新
2. 定期清理历史数据，采用分批删除方式
3. 使用分区表技术，分散碎片影响
4. 监控磁盘空间，保持充足的空间余量

维护策略：
1. 建立定期的碎片检查机制
2. 制定分级的整理策略
3. 选择合适的维护时间窗口
4. 做好操作前的备份和验证

监控策略：
1. 设置合理的告警阈值
2. 建立碎片趋势分析
3. 关注业务影响指标
4. 定期评估整理效果
```

**🚀 进阶优化方向**
```
技术提升：
- 学习MySQL 8.0的新特性
- 研究更高效的在线整理工具
- 掌握分区表的碎片管理
- 了解云数据库的自动化特性

工具整合：
- 集成监控系统（如Prometheus + Grafana）
- 开发自定义的管理脚本
- 建立完整的运维平台
- 实现智能化的决策支持
```

**核心记忆口诀**：
- 碎片产生删改频，空间浪费性能低
- 定期检查算比率，超标及时做整理  
- 选择工具看场景，维护窗口很重要
- 自动监控加告警，预防胜过来补救