---
title: 6、执行计划稳定性控制
---
## 📚 目录

1. [执行计划稳定性基础](#1-执行计划稳定性基础)
2. [计划缓存机制原理](#2-计划缓存机制原理)
3. [统计信息对计划的影响](#3-统计信息对计划的影响)
4. [参数敏感性分析](#4-参数敏感性分析)
5. [计划选择策略](#5-计划选择策略)
6. [自适应优化机制](#6-自适应优化机制)
7. [核心要点总结](#7-核心要点总结)

---

## 1. 🎯 执行计划稳定性基础


### 1.1 什么是执行计划稳定性


> **💡 核心概念**
> 
> 执行计划稳定性是指在相似的数据库环境和查询条件下，数据库优化器能够生成一致的、可预测的执行计划，避免因为微小变化导致性能大幅波动的能力。

**为什么执行计划稳定性很重要？**

在生产环境中，执行计划的突然变化可能导致：
- **性能急剧下降**：原本快速的查询突然变慢
- **资源消耗激增**：CPU、内存、IO使用量突然增加  
- **系统不稳定**：连锁反应影响整个数据库性能
- **用户体验恶化**：响应时间不可预测

```
典型问题场景：
生产环境查询：SELECT * FROM orders WHERE date > '2024-01-01'
昨天执行：0.5秒完成，使用索引扫描
今天执行：50秒完成，使用全表扫描
问题根源：统计信息更新后，优化器改变了计划选择
```

### 1.2 影响计划稳定性的因素


**📊 主要影响因素**

| 影响因素 | **变化类型** | **影响程度** | **控制难度** |
|---------|-------------|-------------|-------------|
| **统计信息** | `数据分布变化` | `🔴 极高` | `🟡 中等` |
| **数据量变化** | `表大小增长` | `🔴 极高` | `🟢 较低` |
| **参数值** | `查询条件变化` | `🟡 中高` | `🟢 较低` |
| **系统资源** | `内存、CPU可用性` | `🟡 中等` | `🔴 困难` |
| **配置参数** | `优化器设置` | `🟡 中等` | `🟢 容易` |
| **数据库版本** | `升级变更` | `🔴 极高` | `🔴 困难` |

### 1.3 计划不稳定的典型表现


**🚨 不稳定表现症状**

```sql
-- 症状1：相同查询性能波动
-- 查询A在不同时间的执行情况：
-- 时间1：Index Scan, 0.5s
-- 时间2：Seq Scan, 45s
-- 时间3：Index Scan, 0.6s

-- 症状2：参数微调导致计划巨变
-- 原查询：WHERE user_id = 1000 (使用索引)
-- 微调后：WHERE user_id = 1001 (全表扫描)

-- 症状3：统计信息更新后性能下降
-- 更新前：嵌套循环连接，2s
-- 更新后：哈希连接，30s
```

**🔍 识别不稳定计划的方法**
```sql
-- PostgreSQL: 查看查询执行计划变化
SELECT 
    queryid,
    query,
    calls,
    min_time,
    max_time,
    mean_time,
    stddev_time,
    -- 计算变异系数，识别不稳定查询
    CASE WHEN mean_time > 0 
         THEN ROUND((stddev_time / mean_time * 100)::numeric, 2)
         ELSE 0 
    END as cv_percent
FROM pg_stat_statements 
WHERE calls > 10  -- 足够的样本数
ORDER BY cv_percent DESC
LIMIT 20;

-- 变异系数 > 50% 的查询可能存在计划不稳定问题
```

---

## 2. 🗄️ 计划缓存机制原理


### 2.1 计划缓存的工作原理


**什么是计划缓存？**

计划缓存是数据库将编译好的执行计划存储在内存中，当相同或相似的查询再次执行时，可以直接重用已有计划，避免重复编译的过程。

> **💡 理解要点**
>
> 想象计划缓存就像是"查询的记忆"。数据库记住了之前遇到过的查询是怎么执行的，下次遇到相同查询时就可以直接"回忆"起来，不用重新思考。

**📋 缓存机制流程**
```
查询执行流程：
1. 接收SQL查询
   ↓
2. 生成查询唯一标识(查询指纹)
   ↓
3. 检查计划缓存
   ├─ 命中：直接使用缓存计划
   └─ 未命中：进入优化器生成新计划
       ↓
4. 执行计划
   ↓
5. 将新计划加入缓存(如果符合条件)
```

### 2.2 不同数据库的缓存实现


**PostgreSQL计划缓存**
```sql
-- PostgreSQL使用prepared statement实现计划缓存
-- 第一次执行：生成并缓存计划
PREPARE user_query (int) AS 
SELECT * FROM users WHERE user_id = $1;

-- 后续执行：重用缓存计划
EXECUTE user_query(1000);
EXECUTE user_query(2000);

-- 查看计划缓存统计
SELECT 
    schemaname,
    tablename, 
    attname,
    n_distinct,
    correlation
FROM pg_stats 
WHERE tablename = 'users';
```

**MySQL查询缓存**
```sql
-- MySQL的查询缓存机制(8.0之前版本)
-- 查看缓存状态
SHOW VARIABLES LIKE 'query_cache%';

-- 查看缓存使用情况
SHOW STATUS LIKE 'Qcache%';

-- 手动清理缓存
FLUSH QUERY CACHE;
RESET QUERY CACHE;
```

**SQL Server计划缓存**
```sql
-- SQL Server计划缓存查询
SELECT 
    p.query_id,
    q.query_sql_text,
    p.plan_id,
    p.avg_duration,
    p.last_execution_time,
    p.execution_count
FROM sys.query_store_plan p
JOIN sys.query_store_query q ON p.query_id = q.query_id
ORDER BY p.avg_duration DESC;

-- 强制使用特定计划
EXEC sp_query_store_force_plan @query_id = 1, @plan_id = 1;
```

### 2.3 计划重用条件判断


**🔍 计划重用的判断条件**

计划能否重用取决于多个因素的综合判断：

```sql
-- 示例：PostgreSQL计划重用条件检查
-- 条件1：查询文本必须完全相同
SELECT * FROM users WHERE user_id = 1000;  -- 查询A
SELECT * FROM users WHERE user_id = 2000;  -- 查询B(不同参数值)

-- 条件2：模式对象版本必须一致
-- 如果表结构发生变化，缓存计划会失效

-- 条件3：统计信息版本检查
-- 统计信息更新后，可能导致计划重新编译

-- 条件4：配置参数一致性
-- work_mem、random_page_cost等参数变化会影响计划重用
```

**📊 重用条件详细分析**

| 重用条件 | **检查内容** | **失效场景** | **影响程度** |
|---------|-------------|-------------|-------------|
| **查询标识** | `SQL文本哈希值` | `查询语句任何字符变化` | `🔴 严重` |
| **模式版本** | `表、索引结构版本` | `DDL操作后` | `🔴 严重` |
| **统计版本** | `统计信息时间戳` | `ANALYZE后` | `🟡 中等` |
| **参数设置** | `优化器相关参数` | `参数调整后` | `🟡 中等` |
| **权限检查** | `用户访问权限` | `权限变更后` | `🟢 较低` |

### 2.4 缓存失效场景分析


**🚨 常见缓存失效场景**

```sql
-- 场景1：统计信息更新导致失效
-- 更新统计信息
ANALYZE users;

-- 检查计划缓存状态
SELECT 
    schemaname, tablename, 
    last_analyze, 
    n_tup_ins, n_tup_upd, n_tup_del
FROM pg_stat_user_tables 
WHERE tablename = 'users';

-- 场景2：表结构变更导致失效
ALTER TABLE users ADD COLUMN email VARCHAR(255);
-- 所有涉及users表的缓存计划都会失效

-- 场景3：索引变更导致失效  
CREATE INDEX idx_users_email ON users(email);
-- 可能导致相关查询计划重新生成

-- 场景4：配置参数变更
SET work_mem = '256MB';  -- 从128MB调整到256MB
-- 可能影响哈希连接、排序等操作的计划选择
```

**🔧 缓存失效监控**
```sql
-- 创建缓存失效监控函数
CREATE OR REPLACE FUNCTION monitor_plan_cache_hits()
RETURNS TABLE (
    database_name TEXT,
    cache_hit_ratio NUMERIC,
    plan_invalidations BIGINT,
    recommendation TEXT
) AS $$
BEGIN
    RETURN QUERY
    WITH cache_stats AS (
        SELECT 
            datname,
            SUM(blks_hit) as total_hits,
            SUM(blks_read) as total_reads
        FROM pg_stat_database
        GROUP BY datname
    )
    SELECT 
        cs.datname::TEXT,
        ROUND(
            (cs.total_hits::NUMERIC / NULLIF(cs.total_hits + cs.total_reads, 0)) * 100, 
            2
        ) as hit_ratio,
        -- 简化的失效计数（实际实现需要更复杂的逻辑）
        cs.total_reads as invalidations,
        CASE 
            WHEN cs.total_hits::NUMERIC / NULLIF(cs.total_hits + cs.total_reads, 0) < 0.95 
            THEN '建议检查统计信息更新频率和缓存配置'
            WHEN cs.total_hits::NUMERIC / NULLIF(cs.total_hits + cs.total_reads, 0) < 0.98 
            THEN '缓存命中率良好，继续监控'
            ELSE '缓存命中率优秀'
        END
    FROM cache_stats cs;
END;
$$ LANGUAGE plpgsql;

-- 执行监控
SELECT * FROM monitor_plan_cache_hits();
```

---

## 3. 📊 统计信息对计划的影响


### 3.1 统计信息的作用机制


**统计信息如何影响执行计划？**

统计信息是优化器做出计划选择的"眼睛"，它告诉优化器数据的分布情况、表的大小、列值的唯一性等关键信息。

> **💡 形象理解**
>
> 统计信息就像是数据库的"体检报告"。优化器根据这个报告来判断使用哪种查询方法最有效，就像医生根据体检报告来制定治疗方案一样。

**📋 核心统计信息类型**
```sql
-- PostgreSQL统计信息查看
SELECT 
    schemaname,
    tablename,
    attname as column_name,
    n_distinct,      -- 唯一值数量估计
    correlation,     -- 物理存储与逻辑顺序的相关性
    most_common_vals, -- 最常见的值
    most_common_freqs, -- 最常见值的频率
    histogram_bounds   -- 直方图边界
FROM pg_stats 
WHERE tablename = 'orders'
ORDER BY attname;
```

### 3.2 统计信息更新对计划的影响


**📈 统计信息变化的影响分析**

```sql
-- 示例：订单表的统计信息变化分析
-- 创建测试数据
CREATE TABLE order_analysis AS
SELECT 
    generate_series(1, 100000) as order_id,
    (random() * 1000)::int as customer_id,
    CURRENT_DATE - (random() * 365)::int as order_date,
    (random() * 1000 + 10)::numeric(10,2) as amount
;

-- 创建索引
CREATE INDEX idx_order_customer ON order_analysis(customer_id);
CREATE INDEX idx_order_date ON order_analysis(order_date);

-- 第一次统计信息收集
ANALYZE order_analysis;

-- 查看初始执行计划
EXPLAIN (ANALYZE, BUFFERS) 
SELECT * FROM order_analysis 
WHERE customer_id = 500;

-- 模拟数据增长：插入大量新数据
INSERT INTO order_analysis 
SELECT 
    generate_series(100001, 500000) as order_id,
    (random() * 2000)::int as customer_id,  -- 扩大客户ID范围
    CURRENT_DATE - (random() * 30)::int as order_date,  -- 集中在最近30天
    (random() * 2000 + 10)::numeric(10,2) as amount
;

-- 数据变化后，未更新统计信息的计划
EXPLAIN (ANALYZE, BUFFERS) 
SELECT * FROM order_analysis 
WHERE customer_id = 500;

-- 更新统计信息
ANALYZE order_analysis;

-- 统计信息更新后的计划
EXPLAIN (ANALYZE, BUFFERS) 
SELECT * FROM order_analysis 
WHERE customer_id = 500;
```

**📊 统计信息变化前后对比**
```
数据变化前(10万行)：
- customer_id=500 预估行数：100行
- 选择策略：Index Scan
- 执行时间：2ms

数据变化后，统计信息未更新：
- customer_id=500 预估行数：100行 (错误估计)
- 选择策略：Index Scan (可能不是最优)
- 执行时间：15ms

统计信息更新后(50万行)：
- customer_id=500 预估行数：250行 (正确估计)
- 选择策略：根据新统计信息选择
- 执行时间：5ms
```

### 3.3 统计信息质量评估


**🔍 统计信息准确性检查**
```sql
-- 创建统计信息质量评估函数
CREATE OR REPLACE FUNCTION assess_statistics_quality(
    table_name TEXT,
    column_name TEXT
) RETURNS TABLE (
    stat_type TEXT,
    estimated_value NUMERIC,
    actual_value NUMERIC,
    accuracy_percent NUMERIC,
    quality_rating TEXT
) AS $$
DECLARE
    actual_distinct BIGINT;
    estimated_distinct NUMERIC;
    actual_nulls BIGINT;
    estimated_nulls NUMERIC;
    total_rows BIGINT;
BEGIN
    -- 获取实际统计数据
    EXECUTE format('SELECT COUNT(DISTINCT %I) FROM %I', column_name, table_name) 
    INTO actual_distinct;
    
    EXECUTE format('SELECT COUNT(*) FROM %I WHERE %I IS NULL', table_name, column_name) 
    INTO actual_nulls;
    
    EXECUTE format('SELECT COUNT(*) FROM %I', table_name) 
    INTO total_rows;
    
    -- 获取估计统计数据
    SELECT n_distinct INTO estimated_distinct 
    FROM pg_stats 
    WHERE tablename = table_name AND attname = column_name;
    
    -- 计算唯一值准确性
    stat_type := '唯一值数量';
    estimated_value := estimated_distinct;
    actual_value := actual_distinct;
    
    IF estimated_distinct > 0 THEN
        accuracy_percent := ROUND(
            (1 - ABS(actual_distinct - estimated_distinct) / actual_distinct::NUMERIC) * 100, 
            2
        );
    ELSE
        accuracy_percent := 0;
    END IF;
    
    quality_rating := CASE 
        WHEN accuracy_percent >= 95 THEN '🟢 优秀'
        WHEN accuracy_percent >= 85 THEN '🟡 良好' 
        WHEN accuracy_percent >= 70 THEN '🟠 一般'
        ELSE '🔴 较差'
    END;
    
    RETURN NEXT;
    
    -- 可以继续添加其他统计信息的评估...
END;
$$ LANGUAGE plpgsql;

-- 使用示例
SELECT * FROM assess_statistics_quality('order_analysis', 'customer_id');
```

### 3.4 统计信息更新策略


**⚱️ 智能统计信息更新**
```sql
-- 创建自动统计信息更新策略
CREATE OR REPLACE FUNCTION auto_analyze_strategy()
RETURNS TABLE (
    schema_name TEXT,
    table_name TEXT,
    last_analyze TIMESTAMP,
    rows_changed_percent NUMERIC,
    recommendation TEXT,
    priority INT
) AS $$
BEGIN
    RETURN QUERY
    WITH table_stats AS (
        SELECT 
            schemaname,
            tablename,
            last_analyze,
            n_tup_ins + n_tup_upd + n_tup_del as changes,
            n_live_tup + n_dead_tup as total_rows
        FROM pg_stat_user_tables
    ),
    change_analysis AS (
        SELECT 
            schemaname,
            tablename, 
            last_analyze,
            CASE WHEN total_rows > 0 
                 THEN ROUND((changes::NUMERIC / total_rows) * 100, 2)
                 ELSE 0 
            END as change_percent
        FROM table_stats
    )
    SELECT 
        ca.schemaname::TEXT,
        ca.tablename::TEXT,
        ca.last_analyze,
        ca.change_percent,
        CASE 
            WHEN ca.change_percent > 20 THEN '🔴 立即更新统计信息'
            WHEN ca.change_percent > 10 THEN '🟡 建议更新统计信息'
            WHEN ca.last_analyze < CURRENT_DATE - INTERVAL '7 days' THEN '🟠 定期更新'
            ELSE '🟢 暂无需更新'
        END as rec,
        CASE 
            WHEN ca.change_percent > 20 THEN 1
            WHEN ca.change_percent > 10 THEN 2
            WHEN ca.last_analyze < CURRENT_DATE - INTERVAL '7 days' THEN 3
            ELSE 4
        END as pri
    FROM change_analysis ca
    ORDER BY pri, ca.change_percent DESC;
END;
$$ LANGUAGE plpgsql;

-- 执行分析
SELECT * FROM auto_analyze_strategy();
```

---

## 4. 🎛️ 参数敏感性分析


### 4.1 什么是参数敏感性


**参数敏感性的定义**

参数敏感性是指查询的执行计划对输入参数值变化的敏感程度。某些查询在参数值发生微小变化时，可能会选择完全不同的执行路径。

> **💡 理解要点**
>
> 想象参数敏感性就像是"蝴蝶效应"。一个很小的参数值变化，可能导致优化器选择完全不同的执行策略，从而产生巨大的性能差异。

**🔍 参数敏感性示例**
```sql
-- 敏感性查询示例：根据日期范围查询订单
-- 参数值1：查询1天的数据
SELECT * FROM orders 
WHERE order_date BETWEEN '2024-01-01' AND '2024-01-01';
-- 预期：使用索引扫描，返回100行，执行时间1ms

-- 参数值2：查询30天的数据  
SELECT * FROM orders 
WHERE order_date BETWEEN '2024-01-01' AND '2024-01-30';
-- 预期：可能使用索引扫描，返回3000行，执行时间30ms

-- 参数值3：查询1年的数据
SELECT * FROM orders 
WHERE order_date BETWEEN '2024-01-01' AND '2024-12-31';
-- 预期：可能改用全表扫描，返回100万行，执行时间5s
```

### 4.2 参数敏感性检测方法


**🧪 敏感性检测工具**
```sql
-- 创建参数敏感性检测函数
CREATE OR REPLACE FUNCTION detect_parameter_sensitivity(
    base_query TEXT,
    param_column TEXT,
    test_values TEXT[]
) RETURNS TABLE (
    test_value TEXT,
    execution_plan_hash TEXT,
    estimated_cost NUMERIC,
    estimated_rows BIGINT,
    execution_time_ms NUMERIC,
    plan_changed BOOLEAN
) AS $$
DECLARE
    test_val TEXT;
    query_text TEXT;
    plan_result TEXT;
    prev_plan_hash TEXT := '';
    start_time TIMESTAMP;
    end_time TIMESTAMP;
BEGIN
    FOREACH test_val IN ARRAY test_values
    LOOP
        -- 构建测试查询
        query_text := REPLACE(base_query, '$PARAM$', test_val);
        
        -- 获取执行计划
        start_time := clock_timestamp();
        
        EXECUTE 'EXPLAIN (ANALYZE, FORMAT JSON) ' || query_text INTO plan_result;
        
        end_time := clock_timestamp();
        
        -- 简化处理：提取计划关键信息
        test_value := test_val;
        execution_plan_hash := MD5(plan_result);
        -- 这里简化了成本和行数的提取逻辑
        estimated_cost := 1000 + random() * 5000;  -- 实际应从plan_result中解析
        estimated_rows := 100 + (random() * 10000)::bigint;
        execution_time_ms := EXTRACT(EPOCH FROM (end_time - start_time)) * 1000;
        plan_changed := (execution_plan_hash != prev_plan_hash) AND (prev_plan_hash != '');
        
        prev_plan_hash := execution_plan_hash;
        
        RETURN NEXT;
    END LOOP;
END;
$$ LANGUAGE plpgsql;

-- 使用示例：测试日期范围敏感性
SELECT * FROM detect_parameter_sensitivity(
    'SELECT * FROM orders WHERE order_date >= ''2024-01-01'' AND order_date <= ''$PARAM$''',
    'order_date',
    ARRAY['2024-01-01', '2024-01-07', '2024-01-30', '2024-06-30', '2024-12-31']
);
```

### 4.3 常见的参数敏感性场景


**📋 典型敏感性场景分析**

| 场景类型 | **敏感参数** | **计划变化** | **影响程度** |
|---------|-------------|-------------|-------------|
| **日期范围查询** | `日期范围大小` | `索引扫描 ↔ 全表扫描` | `🔴 极高` |
| **用户ID查询** | `用户活跃度` | `嵌套循环 ↔ 哈希连接` | `🟡 中高` |
| **状态过滤** | `状态分布` | `索引扫描 ↔ 位图扫描` | `🟡 中等` |
| **数值范围** | `范围选择性` | `索引范围 ↔ 全表扫描` | `🔴 高` |
| **文本匹配** | `模糊匹配度` | `索引扫描 ↔ 全文检索` | `🟡 中等` |

**🔧 敏感性缓解策略**
```sql
-- 策略1：使用参数化查询减少敏感性
-- 不敏感的查询设计
PREPARE stable_date_query (date, date) AS
SELECT order_id, customer_id, order_date, amount
FROM orders 
WHERE order_date BETWEEN $1 AND $2
AND amount > 100  -- 添加额外过滤条件提高选择性
ORDER BY order_date
LIMIT 1000;       -- 限制返回行数

-- 策略2：使用查询提示强制计划
-- PostgreSQL中通过扩展实现提示
/*+ IndexScan(orders idx_orders_date) */
SELECT * FROM orders WHERE order_date BETWEEN $1 AND $2;

-- 策略3：条件分支查询
CREATE OR REPLACE FUNCTION smart_order_query(
    start_date DATE,
    end_date DATE
) RETURNS TABLE (
    order_id BIGINT,
    customer_id INT,
    order_date DATE,
    amount NUMERIC
) AS $$
DECLARE
    date_diff INT;
BEGIN
    date_diff := end_date - start_date;
    
    IF date_diff <= 7 THEN
        -- 短期查询：使用索引优化路径
        RETURN QUERY
        SELECT o.order_id, o.customer_id, o.order_date, o.amount
        FROM orders o
        WHERE o.order_date BETWEEN start_date AND end_date
        ORDER BY o.order_date;
    ELSIF date_diff <= 90 THEN
        -- 中期查询：使用分区优化
        RETURN QUERY  
        SELECT o.order_id, o.customer_id, o.order_date, o.amount
        FROM orders o
        WHERE o.order_date BETWEEN start_date AND end_date
        AND o.amount > 0  -- 添加过滤条件
        ORDER BY o.order_date;
    ELSE
        -- 长期查询：使用聚合预计算
        RETURN QUERY
        SELECT o.order_id, o.customer_id, o.order_date, o.amount  
        FROM order_summary o  -- 使用预聚合表
        WHERE o.order_date BETWEEN start_date AND end_date;
    END IF;
END;
$$ LANGUAGE plpgsql;
```

### 4.4 参数敏感性监控


**📊 实时敏感性监控**
```sql
-- 创建参数敏感性监控视图
CREATE OR REPLACE VIEW parameter_sensitivity_monitor AS
WITH query_variations AS (
    SELECT 
        queryid,
        query,
        calls,
        min_time,
        max_time,
        mean_time,
        stddev_time,
        -- 计算时间变异系数
        CASE WHEN mean_time > 0 
             THEN stddev_time / mean_time 
             ELSE 0 
        END as time_cv
    FROM pg_stat_statements
    WHERE calls >= 10
),
sensitivity_analysis AS (
    SELECT 
        queryid,
        LEFT(query, 100) as query_preview,
        calls,
        ROUND(mean_time::numeric, 2) as avg_time_ms,
        ROUND((max_time - min_time)::numeric, 2) as time_range_ms,
        ROUND((time_cv * 100)::numeric, 2) as time_cv_percent,
        CASE 
            WHEN time_cv > 1.0 THEN '🔴 高度敏感'
            WHEN time_cv > 0.5 THEN '🟡 中度敏感'
            WHEN time_cv > 0.2 THEN '🟠 轻度敏感'
            ELSE '🟢 稳定'
        END as sensitivity_level
    FROM query_variations
)
SELECT * FROM sensitivity_analysis
ORDER BY time_cv_percent DESC;

-- 查看监控结果
SELECT * FROM parameter_sensitivity_monitor 
WHERE sensitivity_level IN ('🔴 高度敏感', '🟡 中度敏感');
```

---

## 5. 🎯 计划选择策略


### 5.1 优化器计划选择机制


**计划选择的基本流程**

优化器在生成执行计划时，会考虑多种可能的执行路径，并根据成本估算选择最优方案。

> **💡 理解要点**
>
> 优化器就像是一个"路线规划系统"。给定起点和终点，它会计算多条可能的路线，比较每条路线的"成本"（时间、资源消耗），然后选择最优路线。

**📋 计划选择考虑因素**
```
成本计算模型：
总成本 = CPU成本 + IO成本 + 网络成本

CPU成本：
- 行处理成本：cpu_tuple_cost × 处理行数
- 操作成本：cpu_operator_cost × 操作次数  
- 索引成本：cpu_index_tuple_cost × 索引扫描行数

IO成本：
- 顺序页成本：seq_page_cost × 页数
- 随机页成本：random_page_cost × 随机页数
- 索引页成本：索引页读取的加权成本

连接成本：
- 嵌套循环：外表行数 × 内表查找成本
- 哈希连接：建立哈希表成本 + 探测成本
- 排序合并：排序成本 + 合并成本
```

### 5.2 不同连接策略的选择


**🔗 连接策略选择分析**
```sql
-- 演示不同连接策略的选择
-- 创建测试表
CREATE TABLE customers_test (
    customer_id INT PRIMARY KEY,
    customer_name VARCHAR(100),
    city VARCHAR(50)
);

CREATE TABLE orders_test (
    order_id INT PRIMARY KEY,
    customer_id INT,
    order_date DATE,
    amount NUMERIC(10,2)
);

-- 插入测试数据
INSERT INTO customers_test 
SELECT generate_series(1, 10000), 
       'Customer_' || generate_series(1, 10000),
       'City_' || (random() * 100)::int;

INSERT INTO orders_test
SELECT generate_series(1, 100000),
       (random() * 10000)::int + 1,
       CURRENT_DATE - (random() * 365)::int,
       (random() * 1000 + 10)::numeric(10,2);

-- 创建索引
CREATE INDEX idx_orders_customer ON orders_test(customer_id);

-- 场景1：小表驱动大表（嵌套循环连接）
EXPLAIN (ANALYZE, BUFFERS) 
SELECT c.customer_name, o.order_date, o.amount
FROM customers_test c
JOIN orders_test o ON c.customer_id = o.customer_id  
WHERE c.city = 'City_1';  -- 选择性很高，只有约100个客户

-- 场景2：大表连接（哈希连接）
EXPLAIN (ANALYZE, BUFFERS)
SELECT c.customer_name, COUNT(*) as order_count
FROM customers_test c
JOIN orders_test o ON c.customer_id = o.customer_id
GROUP BY c.customer_id, c.customer_name;

-- 场景3：有序数据连接（排序合并连接）
EXPLAIN (ANALYZE, BUFFERS)
SELECT c.customer_name, o.order_date, o.amount
FROM customers_test c
JOIN orders_test o ON c.customer_id = o.customer_id
ORDER BY c.customer_id, o.order_date;
```

**📊 连接策略选择矩阵**

| 外表大小 | **内表大小** | **连接条件** | **优选策略** | **原因** |
|---------|-------------|-------------|-------------|---------|
| 小 | 小 | `等值连接` | `嵌套循环` | `启动成本低` |
| 小 | 大 | `有索引` | `嵌套循环` | `索引查找效率高` |
| 大 | 小 | `等值连接` | `哈希连接` | `建立哈希表成本低` |
| 大 | 大 | `等值连接` | `哈希连接` | `线性时间复杂度` |
| 大 | 大 | `范围连接` | `排序合并` | `利用排序特性` |

### 5.3 索引选择策略


**🔍 索引选择决策树**
```sql
-- 索引选择策略演示
-- 创建多个索引的测试表
CREATE TABLE product_sales (
    sale_id BIGINT PRIMARY KEY,
    product_id INT,
    customer_id INT,
    sale_date DATE,
    category VARCHAR(50),
    amount NUMERIC(10,2),
    quantity INT
);

-- 创建多种索引
CREATE INDEX idx_product_sales_product ON product_sales(product_id);
CREATE INDEX idx_product_sales_customer ON product_sales(customer_id);  
CREATE INDEX idx_product_sales_date ON product_sales(sale_date);
CREATE INDEX idx_product_sales_category ON product_sales(category);
CREATE INDEX idx_product_sales_amount ON product_sales(amount);

-- 复合索引
CREATE INDEX idx_product_sales_comp1 ON product_sales(product_id, sale_date);
CREATE INDEX idx_product_sales_comp2 ON product_sales(customer_id, sale_date, amount);
CREATE INDEX idx_product_sales_comp3 ON product_sales(category, sale_date);

-- 插入测试数据
INSERT INTO product_sales
SELECT 
    generate_series(1, 1000000) as sale_id,
    (random() * 1000)::int + 1 as product_id,
    (random() * 10000)::int + 1 as customer_id,
    CURRENT_DATE - (random() * 365)::int as sale_date,
    'Category_' || (random() * 20)::int as category,
    (random() * 1000 + 10)::numeric(10,2) as amount,
    (random() * 10)::int + 1 as quantity;

ANALYZE product_sales;

-- 测试不同查询的索引选择
-- 查询1：单列精确匹配
EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM product_sales WHERE product_id = 500;

-- 查询2：复合条件查询  
EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM product_sales 
WHERE product_id = 500 AND sale_date >= '2024-01-01';

-- 查询3：范围查询
EXPLAIN (ANALYZE, BUFFERS) 
SELECT * FROM product_sales
WHERE sale_date BETWEEN '2024-01-01' AND '2024-01-31'
AND amount > 500;

-- 查询4：排序查询
EXPLAIN (ANALYZE, BUFFERS)
SELECT customer_id, sale_date, amount
FROM product_sales
WHERE customer_id = 1000
ORDER BY sale_date DESC, amount DESC;
```

### 5.4 计划选择优化技巧


**🔧 计划选择调优方法**
```sql
-- 技巧1：使用统计信息引导优化器
-- 更新表的统计信息采样率
ALTER TABLE product_sales ALTER COLUMN category SET STATISTICS 1000;
ANALYZE product_sales;

-- 技巧2：调整成本参数影响选择
-- 降低随机页成本，鼓励使用索引
SET random_page_cost = 1.1;  -- 默认值通常是4.0

-- 增加CPU成本，减少CPU密集型操作
SET cpu_tuple_cost = 0.01;    -- 默认值是0.01
SET cpu_operator_cost = 0.0025;  -- 默认值是0.0025

-- 技巧3：使用表达式索引优化复杂查询
CREATE INDEX idx_product_sales_month 
ON product_sales (EXTRACT(YEAR FROM sale_date), EXTRACT(MONTH FROM sale_date));

-- 验证表达式索引使用
EXPLAIN (ANALYZE, BUFFERS)
SELECT SUM(amount) 
FROM product_sales 
WHERE EXTRACT(YEAR FROM sale_date) = 2024 
  AND EXTRACT(MONTH FROM sale_date) = 6;

-- 技巧4：部分索引减少索引大小
CREATE INDEX idx_recent_sales 
ON product_sales (customer_id, sale_date)
WHERE sale_date >= '2024-01-01';  -- 只索引最近的数据

-- 技巧5：创建覆盖索引避免表查找
CREATE INDEX idx_sales_covering
ON product_sales (customer_id, sale_date) 
INCLUDE (amount, quantity);  -- PostgreSQL 11+语法

-- 验证覆盖索引效果
EXPLAIN (ANALYZE, BUFFERS)
SELECT customer_id, sale_date, amount, quantity
FROM product_sales
WHERE customer_id = 1000 
  AND sale_date >= '2024-01-01'
ORDER BY sale_date;
```

---

## 6. 🤖 自适应优化机制


### 6.1 自适应优化的工作原理


**什么是自适应优化？**

自适应优化是现代数据库系统的一项高级功能，它能够根据查询的实际执行情况，动态调整和优化执行计划，使数据库能够"学习"并适应工作负载的变化。

> **💡 理解要点**
>
> 自适应优化就像是一个"会学习的导航系统"。初次行驶时可能选择预计最优的路线，但如果发现实际通行情况与预期不符，系统会记录这个信息，下次遇到类似情况时选择更好的路线。

**🧠 自适应优化的核心机制**
```
自适应优化流程：
1. 执行计划生成
   ↓
2. 实际执行监控  
   ↓
3. 性能反馈收集
   ↓
4. 计划质量评估
   ↓  
5. 优化策略调整
   ↓
6. 更新计划缓存
```

### 6.2 SQL Server自适应查询处理


**📊 SQL Server的自适应功能**
```sql
-- SQL Server 2017+自适应查询处理示例
-- 查看自适应查询处理状态
SELECT 
    name,
    value,
    value_for_secondary
FROM sys.database_scoped_configurations
WHERE name LIKE '%ADAPTIVE%';

-- 启用自适应查询处理
ALTER DATABASE SCOPED CONFIGURATION 
SET BATCH_MODE_ADAPTIVE_JOINS = ON;

ALTER DATABASE SCOPED CONFIGURATION 
SET BATCH_MODE_MEMORY_GRANT_FEEDBACK = ON;

-- 监控自适应连接决策
SELECT 
    q.query_id,
    p.plan_id,
    qsrs.avg_duration,
    qsrs.avg_logical_io_reads,
    -- 查看是否使用了自适应连接
    CASE WHEN p.query_plan.value('declare namespace qplan="http://schemas.microsoft.com/sqlserver/2004/07/showplan";
                                  count(//qplan:AdaptiveJoin)', 'int') > 0 
         THEN 'Adaptive Join Used'
         ELSE 'Standard Join'
    END as join_type
FROM sys.query_store_query q
JOIN sys.query_store_plan p ON q.query_id = p.query_id  
JOIN sys.query_store_runtime_stats qsrs ON p.plan_id = qsrs.plan_id
WHERE q.query_sql_text LIKE '%JOIN%'
ORDER BY qsrs.avg_duration DESC;
```

### 6.3 PostgreSQL自适应特性


**🔧 PostgreSQL的自适应机制**
```sql
-- PostgreSQL中的自适应特性
-- 1. 自适应工作内存调整
SET work_mem = '64MB';

-- 查看工作内存使用统计
SELECT 
    query,
    calls,
    mean_time,
    -- 检查是否出现磁盘排序（性能问题指标）
    CASE WHEN query LIKE '%sort%' OR query LIKE '%hash%'
         THEN '可能需要调整work_mem'
         ELSE '内存使用正常'
    END as memory_recommendation
FROM pg_stat_statements 
WHERE calls > 10
ORDER BY mean_time DESC;

-- 2. 自适应统计信息收集
-- 创建自适应统计信息更新函数
CREATE OR REPLACE FUNCTION adaptive_analyze()
RETURNS VOID AS $$
DECLARE
    table_record RECORD;
    change_threshold NUMERIC := 0.1;  -- 10%变化阈值
BEGIN
    FOR table_record IN 
        SELECT 
            schemaname,
            tablename,
            n_tup_ins + n_tup_upd + n_tup_del as total_changes,
            n_live_tup + n_dead_tup as total_rows,
            last_analyze
        FROM pg_stat_user_tables
        WHERE (n_tup_ins + n_tup_upd + n_tup_del)::numeric / 
              NULLIF(n_live_tup + n_dead_tup, 0) > change_threshold
           OR last_analyze < CURRENT_TIMESTAMP - INTERVAL '1 day'
    LOOP
        EXECUTE format('ANALYZE %I.%I', table_record.schemaname, table_record.tablename);
        RAISE NOTICE '自适应更新统计信息: %.%', table_record.schemaname, table_record.tablename;
    END LOOP;
END;
$$ LANGUAGE plpgsql;

-- 3. 自适应索引建议
CREATE OR REPLACE FUNCTION adaptive_index_recommendations()
RETURNS TABLE (
    schema_name TEXT,
    table_name TEXT,
    recommended_index TEXT,
    reason TEXT,
    expected_benefit TEXT
) AS $$
BEGIN
    RETURN QUERY
    WITH missing_indexes AS (
        -- 分析慢查询中的WHERE条件
        SELECT 
            'public' as schema_name,
            'orders' as table_name,  -- 简化示例
            'CREATE INDEX idx_orders_date_status ON orders(order_date, status)' as recommended_index,
            '频繁的日期和状态组合查询' as reason,
            '预计提升查询性能50-80%' as expected_benefit
        -- 实际实现需要分析pg_stat_statements中的查询模式
    )
    SELECT * FROM missing_indexes;
END;
$$ LANGUAGE plpgsql;

-- 执行自适应建议
SELECT * FROM adaptive_index_recommendations();
```

### 6.4 自适应优化监控


**📈 自适应优化效果监控**
```sql
-- 创建自适应优化监控仪表板
CREATE OR REPLACE VIEW adaptive_optimization_dashboard AS
WITH optimization_metrics AS (
    SELECT 
        'plan_cache_hit_ratio' as metric_name,
        ROUND(
            (SUM(blks_hit)::NUMERIC / NULLIF(SUM(blks_hit + blks_read), 0)) * 100, 
            2
        ) as metric_value,
        '%' as unit,
        CASE WHEN (SUM(blks_hit)::NUMERIC / NULLIF(SUM(blks_hit + blks_read), 0)) > 0.95 
             THEN '🟢 优秀'
             ELSE '🟡 需关注' 
        END as status
    FROM pg_stat_database
    
    UNION ALL
    
    SELECT 
        'query_performance_stability' as metric_name,
        ROUND(AVG(
            CASE WHEN mean_time > 0 THEN stddev_time / mean_time ELSE 0 END
        ) * 100, 2) as metric_value,
        '变异系数%' as unit,
        CASE WHEN AVG(CASE WHEN mean_time > 0 THEN stddev_time / mean_time ELSE 0 END) < 0.2
             THEN '🟢 稳定'
             ELSE '🔴 不稳定'
        END as status
    FROM pg_stat_statements
    WHERE calls > 10
    
    UNION ALL
    
    SELECT 
        'index_usage_ratio' as metric_name,
        ROUND(
            (SUM(idx_scan)::NUMERIC / NULLIF(SUM(seq_scan + idx_scan), 0)) * 100,
            2
        ) as metric_value,
        '%' as unit,
        CASE WHEN (SUM(idx_scan)::NUMERIC / NULLIF(SUM(seq_scan + idx_scan), 0)) > 0.8
             THEN '🟢 良好'
             ELSE '🟡 可优化'
        END as status
    FROM pg_stat_user_tables
)
SELECT 
    metric_name as "监控指标",
    metric_value as "当前值", 
    unit as "单位",
    status as "状态评估"
FROM optimization_metrics;

-- 查看监控面板
SELECT * FROM adaptive_optimization_dashboard;
```

---

## 7. 📋 核心要点总结


### 7.1 必须掌握的核心概念


```
🔸 执行计划稳定性：避免相同查询产生不同计划的能力
🔸 计划缓存机制：重用已编译计划，提高查询效率
🔸 统计信息影响：数据分布变化导致计划选择改变
🔸 参数敏感性：查询参数微小变化引起计划巨变
🔸 自适应优化：数据库根据执行反馈动态调整策略
```

### 7.2 关键理解要点


**🔹 稳定性的重要性**
```
理解要点：
- 计划不稳定会导致性能的不可预测性
- 生产环境需要可靠、一致的查询性能
- 微小的环境变化不应该引起巨大的性能差异
```

**🔹 影响因素的权重**
```
影响程度排序：
1. 统计信息变化（最高影响）
2. 数据量显著增长
3. 参数值选择性差异
4. 系统资源变化
5. 配置参数调整
```

**🔹 监控与诊断思路**
```
诊断流程：
数据层面：检查统计信息是否及时更新
查询层面：分析参数敏感性问题
系统层面：监控资源使用和配置变化
应用层面：评估查询设计的合理性
```

### 7.3 实际应用价值


**🎯 性能管理**
- **预防性能问题**：通过监控提前发现不稳定查询
- **根因分析**：快速定位性能波动的真实原因
- **容量规划**：基于稳定的性能基准制定扩容计划
- **SLA保障**：确保关键业务查询的响应时间可控

**🔧 运维实践**
- **统计信息管理**：建立合理的统计信息更新策略
- **参数调优**：根据工作负载特征调整优化器参数
- **查询优化**：识别和重写不稳定的查询模式
- **监控告警**：建立计划稳定性的监控体系

### 7.4 最佳实践建议


**🏆 稳定性管理策略**
- **渐进式优化**：避免一次性大幅调整系统参数
- **基准测试**：为重要查询建立性能基准和监控
- **版本控制**：追踪统计信息和配置参数的变更历史
- **应急预案**：为计划异常变化准备快速恢复方案

**💡 预防措施**
- **定期维护**：建立统计信息更新的例行维护窗口
- **变更管控**：对影响优化器的配置变更进行严格管控
- **测试验证**：在生产环境应用前充分测试查询稳定性
- **文档记录**：记录重要查询的预期执行计划和性能指标


**核心记忆**：
- 执行计划稳定性是数据库性能可预测性的基础
- 统计信息是影响计划稳定性的最关键因素
- 参数敏感性问题需要通过查询设计来预防
- 监控和诊断是维护稳定性的重要手段
- 自适应优化代表了数据库智能化的发展方向