---
title: 18、查询优化器调试与问题定位
---
## 📚 目录

1. [优化器调试概述](#1-优化器调试概述)
2. [核心调试工具详解](#2-核心调试工具详解)
3. [问题定位方法论](#3-问题定位方法论)
4. [调试信息解读技巧](#4-调试信息解读技巧)
5. [问题重现与验证](#5-问题重现与验证)
6. [智能调试工具集](#6-智能调试工具集)
7. [调试效率优化技术](#7-调试效率优化技术)
8. [核心要点总结](#8-核心要点总结)

---

## 1. 🔍 优化器调试概述


### 1.1 什么是优化器调试


**简单理解**：优化器调试就像是给MySQL的"大脑"做体检，看看它在处理SQL查询时的"思考过程"是否正常。

```
SQL查询执行过程：
用户SQL → 语法解析 → 优化器分析 → 执行计划 → 结果返回
                     ↑
                   这里是调试重点
            "为什么选择这个执行计划？"
            "有没有更好的方案？"
            "哪里出现了问题？"
```

**🔸 为什么需要优化器调试**

- 🐌 **性能问题**：查询突然变慢，需要找出原因
- 🎯 **执行计划异常**：优化器选择了错误的执行路径
- 📊 **统计信息过时**：数据变化导致优化器判断失误
- 🔄 **版本升级问题**：MySQL升级后查询行为改变

### 1.2 优化器调试的核心目标


```
调试目标层次图：

问题发现
├── 🔍 识别慢查询
├── 📈 监控性能指标
└── ⚠️ 捕获异常行为

问题分析
├── 🧠 理解优化器决策
├── 📊 分析统计信息
└── 🎯 定位性能瓶颈

问题解决
├── 🛠️ 调整配置参数
├── 📝 优化SQL语句
└── ✅ 验证修复效果
```

### 1.3 调试工作流程


```
标准调试流程：

步骤1: 问题识别
└── 发现查询性能异常

步骤2: 信息收集  
├── 执行计划分析
├── 系统状态检查
└── 历史数据对比

步骤3: 深度分析
├── 优化器trace分析
├── 统计信息检查
└── 索引使用情况

步骤4: 问题定位
└── 确定根本原因

步骤5: 解决验证
├── 实施修复方案
└── 验证效果
```

---

## 2. 🛠️ 核心调试工具详解


### 2.1 EXPLAIN详细分析工具


**🔸 EXPLAIN的深度使用**

EXPLAIN不仅能看执行计划，还能深入分析优化器的选择逻辑：

```sql
-- 基础执行计划分析
EXPLAIN SELECT * FROM users WHERE age > 25;

-- 详细的成本分析
EXPLAIN FORMAT=JSON SELECT * FROM users WHERE age > 25;

-- 显示实际执行统计
EXPLAIN ANALYZE SELECT * FROM users WHERE age > 25;
```

**🔹 EXPLAIN输出关键信息解读**

| 字段 | 含义 | 调试价值 |
|------|------|----------|
| `select_type` | 查询类型 | 判断是否有子查询优化问题 |
| `type` | 访问方式 | **最重要**：index_merge、ref、range等 |
| `possible_keys` | 可能用到的索引 | 看优化器考虑了哪些索引 |
| `key` | 实际使用的索引 | 对比possible_keys找问题 |
| `rows` | 预计扫描行数 | 与实际数据量对比 |
| `Extra` | 额外信息 | Using temporary、Using filesort等警告 |

**💡 实战调试示例**

```sql
-- 问题SQL：查询很慢
SELECT u.name, COUNT(o.id) 
FROM users u 
LEFT JOIN orders o ON u.id = o.user_id 
WHERE u.age > 25 
GROUP BY u.id;

-- 第一步：看执行计划
EXPLAIN FORMAT=JSON SELECT u.name, COUNT(o.id) 
FROM users u 
LEFT JOIN orders o ON u.id = o.user_id 
WHERE u.age > 25 
GROUP BY u.id\G

-- 关注点：
-- 1. JOIN的顺序是否合理？
-- 2. WHERE条件是否用到了索引？
-- 3. GROUP BY是否需要临时表？
```

### 2.2 优化器Trace分析


**🔸 什么是优化器Trace**

优化器Trace就像是MySQL优化器的"思考录音"，记录了它做决策的整个过程。

```sql
-- 开启optimizer trace
SET optimizer_trace="enabled=on";

-- 执行要调试的SQL
SELECT * FROM users WHERE age > 25 AND city = 'Beijing';

-- 查看优化器的思考过程
SELECT * FROM information_schema.OPTIMIZER_TRACE\G

-- 关闭optimizer trace（重要！）
SET optimizer_trace="enabled=off";
```

**🔹 Trace信息结构解析**

```json
{
  "steps": [
    {
      "join_preparation": {
        "select_id": 1,
        "steps": [
          {
            "transformations_to_nested_joins": {
              "transformations": ["JOIN_condition_to_WHERE"]
            }
          }
        ]
      }
    },
    {
      "join_optimization": {
        "select_id": 1,
        "steps": [
          {
            "condition_processing": {
              "condition": "WHERE",
              "original_condition": "(users.age > 25) AND (users.city = 'Beijing')",
              "steps": [...]
            }
          },
          {
            "table_dependencies": [...],
            "ref_optimizer_key_uses": [...],
            "rows_estimation": [...]
          }
        ]
      }
    }
  ]
}
```

**💡 Trace分析重点**

```sql
-- 关注这些关键部分：
-- 1. condition_processing：条件如何处理
-- 2. rows_estimation：行数估算是否准确
-- 3. considered_execution_plans：考虑了哪些执行计划
-- 4. chosen_execution_plan：最终选择的计划及原因
```

### 2.3 慢查询日志分析


**🔸 慢查询日志配置**

```sql
-- 启用慢查询日志
SET GLOBAL slow_query_log = ON;

-- 设置慢查询阈值（秒）
SET GLOBAL long_query_time = 1;

-- 记录未使用索引的查询
SET GLOBAL log_queries_not_using_indexes = ON;

-- 查看日志文件位置
SHOW VARIABLES LIKE 'slow_query_log_file';
```

**🔹 慢查询日志分析工具**

```bash
# 使用mysqldumpslow分析
mysqldumpslow -s t -t 10 /var/log/mysql/slow.log

# 参数说明：
# -s t  按时间排序
# -s c  按出现次数排序  
# -s r  按记录数排序
# -t 10 显示前10条

# 使用pt-query-digest（推荐）
pt-query-digest /var/log/mysql/slow.log > slow_analysis.txt
```

### 2.4 Performance Schema监控


**🔸 实时性能监控**

Performance Schema提供了优化器运行时的详细信息：

```sql
-- 查看语句执行统计
SELECT * FROM performance_schema.events_statements_summary_by_digest
WHERE DIGEST_TEXT LIKE '%users%'
ORDER BY AVG_TIMER_WAIT DESC LIMIT 10;

-- 查看索引使用情况  
SELECT * FROM performance_schema.table_io_waits_summary_by_index_usage
WHERE OBJECT_SCHEMA = 'myapp' AND OBJECT_NAME = 'users';

-- 查看等待事件统计
SELECT * FROM performance_schema.events_waits_summary_global_by_event_name
WHERE EVENT_NAME LIKE 'wait/io/table%'
ORDER BY SUM_TIMER_WAIT DESC;
```

---

## 3. 📋 问题定位方法论


### 3.1 系统化问题定位流程


**🔸 五步问题定位法**

```
问题定位标准流程：

第1步：现象观察
├── 📊 收集性能数据
├── 🔍 识别异常查询  
└── 📈 建立基准线

第2步：信息搜集
├── 🗂️ 执行计划分析
├── 📋 系统配置检查
└── 📚 历史数据对比

第3步：假设验证  
├── 🧪 构造测试案例
├── 🔬 隔离变量因素
└── 📊 量化影响程度

第4步：根因分析
├── 🎯 定位核心问题
├── 🔗 分析影响链条
└── 💡 制定解决方案

第5步：效果验证
├── ✅ 实施修复措施
├── 📈 监控效果数据
└── 📋 总结经验教训
```

### 3.2 常见问题分类与定位


**🔹 索引选择问题**

```sql
-- 问题现象：优化器选择了错误的索引
-- 定位方法：

-- 1. 查看可选索引
SHOW INDEX FROM users WHERE Key_name LIKE '%age%';

-- 2. 强制使用不同索引对比
SELECT * FROM users FORCE INDEX(idx_age) WHERE age > 25;
SELECT * FROM users FORCE INDEX(idx_age_city) WHERE age > 25;

-- 3. 分析索引选择性
SELECT 
    COUNT(DISTINCT age) / COUNT(*) as age_selectivity,
    COUNT(DISTINCT city) / COUNT(*) as city_selectivity
FROM users;
```

**🔹 统计信息过时问题**

```sql
-- 问题现象：执行计划中的rows估算严重不准
-- 定位方法：

-- 1. 检查表统计信息更新时间
SELECT 
    TABLE_NAME,
    UPDATE_TIME,
    TABLE_ROWS
FROM information_schema.TABLES 
WHERE TABLE_SCHEMA = 'myapp';

-- 2. 手动更新统计信息
ANALYZE TABLE users;

-- 3. 对比更新前后的执行计划
EXPLAIN SELECT * FROM users WHERE age > 25;
```

**🔹 JOIN顺序问题**

```sql
-- 问题现象：多表JOIN时顺序不合理
-- 定位方法：

-- 1. 查看JOIN条件选择性
SELECT 
    COUNT(*) as total_users,
    COUNT(DISTINCT city) as distinct_cities,
    COUNT(*) / COUNT(DISTINCT city) as avg_users_per_city
FROM users;

-- 2. 使用STRAIGHT_JOIN强制顺序
SELECT /*+ STRAIGHT_JOIN */ u.name, o.total
FROM users u
JOIN orders o ON u.id = o.user_id
WHERE u.city = 'Beijing';
```

### 3.3 问题重现方法


**🔸 构建稳定的重现环境**

```sql
-- 1. 保存问题SQL和执行环境
CREATE TABLE debug_queries (
    id INT AUTO_INCREMENT PRIMARY KEY,
    query_text TEXT,
    execution_plan JSON,
    system_variables JSON,
    table_stats JSON,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 2. 记录执行上下文
INSERT INTO debug_queries (query_text, execution_plan, system_variables)
VALUES (
    'SELECT * FROM users WHERE age > 25',
    (SELECT JSON_OBJECT('plan', 'EXPLAIN output here')),
    (SELECT JSON_OBJECT('key_buffer_size', $$key_buffer_size))
);
```

**🔹 数据一致性保证**

```sql
-- 创建测试数据快照
CREATE TABLE users_debug AS SELECT * FROM users;

-- 保存索引信息
CREATE TABLE index_debug AS 
SELECT * FROM information_schema.STATISTICS 
WHERE TABLE_SCHEMA = 'myapp';
```

---

## 4. 📖 调试信息解读技巧


### 4.1 执行计划深度解读


**🔸 关键指标判断标准**

```sql
-- 执行计划健康度评估标准

-- 1. 扫描行数评估
-- rows < 1000        → 良好
-- 1000 < rows < 10000 → 需要关注  
-- rows > 10000       → 需要优化

-- 2. 访问类型评估
-- const, eq_ref     → 最优
-- ref, range        → 良好
-- index, ALL        → 需要优化

-- 3. Extra信息警告
-- Using filesort    → 排序未用索引
-- Using temporary   → 使用了临时表
-- Using where       → WHERE条件未完全用索引
```

**🔹 成本分析技巧**

```sql
-- 使用EXPLAIN FORMAT=JSON查看详细成本
EXPLAIN FORMAT=JSON 
SELECT * FROM users u 
JOIN orders o ON u.id = o.user_id 
WHERE u.age > 25\G

-- 关注这些成本指标：
-- "read_cost": 读取数据的IO成本
-- "eval_cost": CPU计算成本  
-- "prefix_cost": 到当前步骤的累计成本
-- "data_read_per_join": 每次JOIN读取的数据量
```

### 4.2 优化器Trace深度分析


**🔸 Trace信息重点关注区域**

```json
{
  "join_optimization": {
    "select_id": 1,
    "steps": [
      {
        "rows_estimation": [
          {
            "table": "users",
            "range_analysis": {
              "table_scan": {
                "rows": 10000,
                "cost": 2037.25
              },
              "potential_range_indexes": [
                {
                  "index": "idx_age",
                  "usable": true,
                  "key_parts": ["age"]
                }
              ],
              "best_covering_index_scan": {
                "index": "idx_age",
                "cost": 1108.61,
                "chosen": true
              }
            }
          }
        ]
      }
    ]
  }
}
```

**💡 关键分析要点**：
- **rows_estimation**：行数估算是否合理
- **range_analysis**：范围查询分析
- **best_covering_index_scan**：最佳索引选择
- **chosen**: true/false 看选择原因

### 4.3 性能指标解读


**🔸 关键性能指标体系**

```sql
-- 查询执行效率指标
SELECT 
    SCHEMA_NAME,
    SUM_TIMER_WAIT/1000000000 as total_time_sec,
    COUNT_STAR as execution_count,
    AVG_TIMER_WAIT/1000000000 as avg_time_sec,
    SUM_ROWS_EXAMINED/SUM_ROWS_SENT as efficiency_ratio
FROM performance_schema.events_statements_summary_by_digest
WHERE SCHEMA_NAME IS NOT NULL
ORDER BY total_time_sec DESC LIMIT 10;
```

**🔹 指标解读标准**

| 指标 | 优秀 | 良好 | 需优化 |
|------|------|------|--------|
| 平均执行时间 | <0.01s | <0.1s | >0.1s |
| 扫描效率比 | >0.1 | >0.01 | <0.01 |
| 索引命中率 | >95% | >80% | <80% |

---

## 5. 🧪 问题重现与验证


### 5.1 测试环境构建


**🔸 隔离测试环境**

```sql
-- 创建专门的调试数据库
CREATE DATABASE optimizer_debug;

-- 复制生产表结构
CREATE TABLE optimizer_debug.users LIKE production.users;

-- 复制部分数据用于测试
INSERT INTO optimizer_debug.users 
SELECT * FROM production.users LIMIT 10000;

-- 复制索引结构
SHOW CREATE TABLE production.users;
-- 然后在debug库中创建相同索引
```

**🔹 测试数据准备**

```sql
-- 创建不同数据分布的测试场景
-- 场景1：数据均匀分布
INSERT INTO optimizer_debug.users (age, city) 
SELECT 
    FLOOR(RAND() * 50) + 18 as age,
    CASE FLOOR(RAND() * 5)
        WHEN 0 THEN 'Beijing'
        WHEN 1 THEN 'Shanghai' 
        WHEN 2 THEN 'Guangzhou'
        WHEN 3 THEN 'Shenzhen'
        ELSE 'Other'
    END as city
FROM (SELECT 1 UNION SELECT 2 UNION SELECT 3) t1,
     (SELECT 1 UNION SELECT 2 UNION SELECT 3) t2,
     (SELECT 1 UNION SELECT 2 UNION SELECT 3) t3;

-- 场景2：数据倾斜分布  
INSERT INTO optimizer_debug.users (age, city)
SELECT 
    25 as age,  -- 大部分用户都是25岁
    'Beijing' as city  -- 大部分用户都在北京
FROM (SELECT 1 UNION SELECT 2 UNION SELECT 3) t1,
     (SELECT 1 UNION SELECT 2 UNION SELECT 3) t2;
```

### 5.2 A/B测试验证


**🔸 对比测试方法**

```sql
-- 测试不同优化方案的效果

-- 方案A：使用原始SQL
SET @start_time = NOW(6);
SELECT SQL_NO_CACHE * FROM users WHERE age > 25 AND city = 'Beijing';
SET @end_time = NOW(6);
SELECT TIMESTAMPDIFF(MICROSECOND, @start_time, @end_time) as plan_a_microsec;

-- 方案B：使用强制索引
SET @start_time = NOW(6);
SELECT SQL_NO_CACHE * FROM users FORCE INDEX(idx_age_city) 
WHERE age > 25 AND city = 'Beijing';
SET @end_time = NOW(6);
SELECT TIMESTAMPDIFF(MICROSECOND, @start_time, @end_time) as plan_b_microsec;
```

**🔹 自动化测试脚本**

```sql
-- 创建测试结果记录表
CREATE TABLE optimization_test_results (
    test_id INT AUTO_INCREMENT PRIMARY KEY,
    test_name VARCHAR(100),
    sql_text TEXT,
    execution_time_ms DECIMAL(10,3),
    rows_examined INT,
    rows_returned INT,
    test_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 测试存储过程
DELIMITER //
CREATE PROCEDURE run_optimization_test(
    IN test_name VARCHAR(100),
    IN sql_text TEXT
)
BEGIN
    DECLARE start_time DATETIME(6);
    DECLARE end_time DATETIME(6);
    DECLARE execution_time DECIMAL(10,3);
    
    SET start_time = NOW(6);
    SET @sql = sql_text;
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    DEALLOCATE PREPARE stmt;
    SET end_time = NOW(6);
    
    SET execution_time = TIMESTAMPDIFF(MICROSECOND, start_time, end_time) / 1000;
    
    INSERT INTO optimization_test_results (test_name, sql_text, execution_time_ms)
    VALUES (test_name, sql_text, execution_time);
END //
DELIMITER ;
```

### 5.3 修复效果验证


**🔸 效果量化评估**

```sql
-- 优化前后效果对比
WITH before_optimization AS (
    SELECT AVG(execution_time_ms) as avg_time,
           MAX(execution_time_ms) as max_time,
           MIN(execution_time_ms) as min_time
    FROM optimization_test_results 
    WHERE test_name = 'original_query'
),
after_optimization AS (
    SELECT AVG(execution_time_ms) as avg_time,
           MAX(execution_time_ms) as max_time, 
           MIN(execution_time_ms) as min_time
    FROM optimization_test_results 
    WHERE test_name = 'optimized_query'
)
SELECT 
    b.avg_time as before_avg_ms,
    a.avg_time as after_avg_ms,
    ROUND((b.avg_time - a.avg_time) / b.avg_time * 100, 2) as improvement_pct
FROM before_optimization b, after_optimization a;
```

---

## 6. 🤖 智能调试工具集


### 6.1 自动化问题检测


**🔸 智能慢查询检测**

```sql
-- 创建自动化监控视图
CREATE VIEW slow_query_monitor AS
SELECT 
    DIGEST_TEXT,
    COUNT_STAR as execution_count,
    AVG_TIMER_WAIT/1000000000 as avg_seconds,
    SUM_TIMER_WAIT/1000000000 as total_seconds,
    SUM_ROWS_EXAMINED/SUM_ROWS_SENT as scan_efficiency,
    CASE 
        WHEN AVG_TIMER_WAIT/1000000000 > 1 THEN 'CRITICAL'
        WHEN AVG_TIMER_WAIT/1000000000 > 0.1 THEN 'WARNING'
        ELSE 'OK'
    END as status
FROM performance_schema.events_statements_summary_by_digest
WHERE SCHEMA_NAME IS NOT NULL
ORDER BY total_seconds DESC;

-- 自动化告警查询
SELECT * FROM slow_query_monitor WHERE status IN ('CRITICAL', 'WARNING');
```

**🔹 智能索引建议**

```sql
-- 分析缺失索引的查询
SELECT 
    OBJECT_SCHEMA,
    OBJECT_NAME,
    COUNT_READ,
    COUNT_WRITE,
    SUM_TIMER_WAIT/1000000000 as total_wait_time,
    'Missing Index Suggestion' as recommendation
FROM performance_schema.table_io_waits_summary_by_table
WHERE COUNT_READ > 1000 
AND OBJECT_SCHEMA NOT IN ('mysql', 'information_schema', 'performance_schema')
ORDER BY total_wait_time DESC;
```

### 6.2 问题自动定位算法


**🔸 异常检测算法**

```sql
-- 基于历史数据的异常检测
WITH query_baseline AS (
    SELECT 
        DIGEST_TEXT,
        AVG(AVG_TIMER_WAIT) as baseline_avg,
        STDDEV(AVG_TIMER_WAIT) as baseline_stddev
    FROM performance_schema.events_statements_summary_by_digest_history
    GROUP BY DIGEST_TEXT
),
current_performance AS (
    SELECT 
        DIGEST_TEXT,
        AVG_TIMER_WAIT as current_avg
    FROM performance_schema.events_statements_summary_by_digest
)
SELECT 
    c.DIGEST_TEXT,
    c.current_avg/1000000000 as current_seconds,
    b.baseline_avg/1000000000 as baseline_seconds,
    CASE 
        WHEN c.current_avg > b.baseline_avg + 2 * b.baseline_stddev 
        THEN 'PERFORMANCE_DEGRADED'
        WHEN c.current_avg < b.baseline_avg - 2 * b.baseline_stddev
        THEN 'PERFORMANCE_IMPROVED'
        ELSE 'NORMAL'
    END as anomaly_status
FROM current_performance c
JOIN query_baseline b ON c.DIGEST_TEXT = b.DIGEST_TEXT
WHERE ABS(c.current_avg - b.baseline_avg) > b.baseline_stddev;
```

### 6.3 调试效率优化技术


**🔸 批量调试工具**

```sql
-- 批量执行计划分析存储过程
DELIMITER //
CREATE PROCEDURE batch_explain_analysis()
BEGIN
    DECLARE done INT DEFAULT FALSE;
    DECLARE sql_text TEXT;
    DECLARE cur CURSOR FOR 
        SELECT DIGEST_TEXT FROM performance_schema.events_statements_summary_by_digest
        WHERE AVG_TIMER_WAIT > 100000000 -- 超过0.1秒的查询
        LIMIT 10;
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    OPEN cur;
    read_loop: LOOP
        FETCH cur INTO sql_text;
        IF done THEN
            LEAVE read_loop;
        END IF;
        
        -- 执行EXPLAIN分析
        SET @explain_sql = CONCAT('EXPLAIN FORMAT=JSON ', sql_text);
        PREPARE stmt FROM @explain_sql;
        EXECUTE stmt;
        DEALLOCATE PREPARE stmt;
        
    END LOOP;
    CLOSE cur;
END //
DELIMITER ;
```

**🔹 智能诊断报告生成**

```sql
-- 生成综合诊断报告
SELECT 
    '=== MySQL查询优化器诊断报告 ===' as report_section
UNION ALL
SELECT CONCAT('生成时间: ', NOW())
UNION ALL  
SELECT '=== 慢查询TOP 5 ==='
UNION ALL
SELECT CONCAT(
    'SQL: ', LEFT(DIGEST_TEXT, 50), 
    ', 平均耗时: ', ROUND(AVG_TIMER_WAIT/1000000000, 3), 's'
)
FROM performance_schema.events_statements_summary_by_digest
ORDER BY AVG_TIMER_WAIT DESC LIMIT 5

UNION ALL
SELECT '=== 索引使用情况 ==='
UNION ALL
SELECT CONCAT(
    '表: ', OBJECT_SCHEMA, '.', OBJECT_NAME,
    ', 索引: ', IFNULL(INDEX_NAME, 'PRIMARY'),
    ', 读取次数: ', COUNT_READ
)
FROM performance_schema.table_io_waits_summary_by_index_usage
WHERE OBJECT_SCHEMA NOT IN ('mysql', 'information_schema', 'performance_schema')
AND COUNT_READ > 0
ORDER BY COUNT_READ DESC LIMIT 10;
```

---

## 7. ⚡ 调试效率优化技术


### 7.1 调试环境优化


**🔸 专用调试配置**

```sql
-- 优化调试环境的MySQL配置
-- 在my.cnf中添加：

[mysqld]
# 启用详细的性能监控
performance_schema = ON
performance_schema_consumer_events_statements_history = ON
performance_schema_consumer_events_statements_history_long = ON

# 启用慢查询日志
slow_query_log = ON
long_query_time = 0.1
log_queries_not_using_indexes = ON

# 优化器trace相关
optimizer_trace_max_mem_size = 1048576
optimizer_trace_features = "greedy_search=on,range_optimizer=on"
```

**🔹 调试工具脚本化**

```bash
#!/bin/bash
# 自动化调试脚本 debug_optimizer.sh

echo "MySQL优化器调试工具启动..."

# 1. 检查慢查询
echo "=== 检查慢查询 ==="
mysql -u root -p -e "
SELECT 
    ROUND(AVG_TIMER_WAIT/1000000000, 3) as avg_seconds,
    COUNT_STAR as count,
    LEFT(DIGEST_TEXT, 80) as query
FROM performance_schema.events_statements_summary_by_digest 
WHERE AVG_TIMER_WAIT > 100000000 
ORDER BY AVG_TIMER_WAIT DESC LIMIT 5;"

# 2. 检查索引使用率
echo "=== 检查索引使用率 ==="
mysql -u root -p -e "
SELECT 
    OBJECT_SCHEMA,
    OBJECT_NAME,
    INDEX_NAME,
    COUNT_READ,
    COUNT_WRITE
FROM performance_schema.table_io_waits_summary_by_index_usage 
WHERE OBJECT_SCHEMA NOT IN ('mysql','information_schema','performance_schema')
AND COUNT_READ > 0
ORDER BY COUNT_READ DESC LIMIT 10;"

echo "调试信息收集完成！"
```

### 7.2 调试数据管理


**🔸 调试信息存档**

```sql
-- 创建调试信息存档表
CREATE TABLE debug_archive (
    id INT AUTO_INCREMENT PRIMARY KEY,
    debug_date DATE,
    slow_queries JSON,
    index_usage JSON,  
    system_status JSON,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 定期存档调试信息
INSERT INTO debug_archive (debug_date, slow_queries, index_usage)
SELECT 
    CURDATE(),
    JSON_ARRAYAGG(
        JSON_OBJECT(
            'query', LEFT(DIGEST_TEXT, 100),
            'avg_time', AVG_TIMER_WAIT/1000000000,
            'count', COUNT_STAR
        )
    ) as slow_queries,
    (SELECT JSON_ARRAYAGG(
        JSON_OBJECT(
            'table', CONCAT(OBJECT_SCHEMA, '.', OBJECT_NAME),
            'index', INDEX_NAME,
            'reads', COUNT_READ
        )
    ) FROM performance_schema.table_io_waits_summary_by_index_usage
     WHERE COUNT_READ > 0) as index_usage
FROM performance_schema.events_statements_summary_by_digest
WHERE AVG_TIMER_WAIT > 50000000;
```

### 7.3 调试效果跟踪


**🔸 调试效果量化**

```sql
-- 创建优化效果跟踪表
CREATE TABLE optimization_tracking (
    id INT AUTO_INCREMENT PRIMARY KEY,
    optimization_date DATE,
    query_hash VARCHAR(64),
    before_avg_time DECIMAL(10,4),
    after_avg_time DECIMAL(10,4),
    improvement_pct DECIMAL(5,2),
    optimization_method VARCHAR(200),
    notes TEXT
);

-- 记录优化效果
INSERT INTO optimization_tracking 
(optimization_date, query_hash, before_avg_time, after_avg_time, improvement_pct, optimization_method)
VALUES 
('2025-01-20', 'abc123', 1.250, 0.089, 92.88, '添加复合索引idx_age_city');
```

---

## 8. 📋 核心要点总结


### 8.1 必须掌握的调试工具


```
🔸 EXPLAIN详细分析：最基础的执行计划查看工具，必须熟练掌握
🔸 优化器Trace：深度了解优化器决策过程的核心工具
🔸 慢查询日志：发现性能问题的重要数据源
🔸 Performance Schema：实时监控系统性能的宝库
🔸 调试脚本：自动化调试流程，提高效率
```

### 8.2 关键调试思路


**🔹 系统化问题定位**
```
问题定位三步法：
1. 现象识别：通过监控发现异常
2. 深度分析：使用trace分析优化器逻辑
3. 验证修复：A/B测试确认优化效果
```

**🔹 调试信息解读要点**
```
执行计划分析重点：
- type字段：关注是否使用了合适的访问方式
- rows字段：预估行数是否与实际相符
- Extra字段：是否有Using filesort、Using temporary等警告
- 成本分析：read_cost和eval_cost的合理性
```

**🔹 智能调试策略**
```
自动化调试体系：
- 基线建立：收集正常情况下的性能指标
- 异常检测：基于统计学方法识别异常查询
- 自动建议：根据分析结果给出优化建议
- 效果跟踪：量化优化效果，建立知识库
```

### 8.3 实际应用价值


**💼 日常开发应用**
- **开发阶段**：使用EXPLAIN检查SQL执行计划
- **测试阶段**：通过慢查询日志发现性能问题
- **上线前**：使用optimizer trace深度分析关键查询
- **生产环境**：Performance Schema实时监控系统状态

**🎯 问题处理流程**
1. **问题发现**：监控告警或用户反馈
2. **信息收集**：EXPLAIN + 慢查询日志 + trace分析
3. **问题定位**：对比分析找出根本原因
4. **方案制定**：索引优化、SQL改写、参数调整
5. **效果验证**：A/B测试确认优化效果

**核心记忆要点**：
- 调试是发现问题、分析问题、解决问题的系统工程
- 工具只是手段，思路方法更重要
- 问题定位要有体系化的流程和方法
- 优化效果要量化评估，避免主观判断
- 调试经验需要积累和总结，形成知识库