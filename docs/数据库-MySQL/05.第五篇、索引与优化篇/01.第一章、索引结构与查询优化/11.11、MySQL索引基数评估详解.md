---
title: 11、MySQL索引基数评估详解
---
## 📚 目录

1. [索引基数概念与意义](#1-索引基数概念与意义)
2. [基数统计核心算法](#2-基数统计核心算法)
3. [InnoDB采样统计机制](#3-InnoDB采样统计机制)
4. [统计信息管理机制](#4-统计信息管理机制)
5. [基数评估准确性优化](#5-基数评估准确性优化)
6. [大表基数统计策略](#6-大表基数统计策略)
7. [核心要点总结](#7-核心要点总结)

---

## 1. 📊 索引基数概念与意义


### 1.1 什么是索引基数


**💡 通俗理解**：基数(Cardinality)就是索引列的"独特值数量"
```
想象一个学生表：
学生ID列：10000个学生，10000个不同值 → 基数 = 10000 (高选择性)
性别列：10000个学生，只有2个值(男/女) → 基数 = 2 (低选择性)
班级列：10000个学生，50个班级 → 基数 = 50 (中等选择性)

基数越高 = 索引越有用
基数越低 = 索引效果越差
```

### 1.2 基数对查询性能的影响


**🔸 选择性决定索引效果**
```
高选择性索引(基数大)：
SELECT * FROM students WHERE student_id = 12345;
↓
基数10000，选择性 = 10000/10000 = 1.0
平均每次查询只返回1行数据 → 索引效果极佳

低选择性索引(基数小)：
SELECT * FROM students WHERE gender = '男';
↓  
基数2，选择性 = 2/10000 = 0.0002
平均每次查询返回5000行数据 → 索引效果很差
```

**📈 选择性计算公式**
```sql
选择性 = 基数(Cardinality) / 总行数(Total Rows)
选择性越接近1，索引效果越好
选择性越接近0，索引效果越差

一般经验：
选择性 > 0.1  → 建议创建索引
选择性 < 0.01 → 不建议创建索引
```

### 1.3 MySQL中的基数统计


**🔍 查看基数统计信息**
```sql
-- 查看表的基数统计
SHOW INDEX FROM students;
+----------+--------+----------+--------------+-------------+
| Table    | Key_name | Column_name | Cardinality |
+----------+--------+----------+--------------+-------------+
| students | PRIMARY  | student_id  | 9950        | ← 基数统计
| students | idx_name | name       | 8234        |
| students | idx_gender| gender     | 2           |
+----------+--------+----------+--------------+-------------+

-- 查看详细统计信息
SELECT 
    table_name,
    column_name,
    cardinality,
    cardinality/table_rows as selectivity
FROM information_schema.statistics 
WHERE table_name = 'students';
```

---

## 2. 🧮 基数统计核心算法


### 2.1 基数计算核心公式


**🔥 Cardinality计算公式**
```
基本公式：
Cardinality = (采样页面数 × 每页平均不重复值) × (总页面数 / 采样页面数)

详细计算：
1. 随机采样N个数据页面
2. 统计每个页面的不重复值数量
3. 计算平均值：avg_unique_per_page
4. 估算总基数：avg_unique_per_page × 总页面数

数学表达：
C = Σ(unique_values_in_page_i) / N × total_pages
```

**💻 伪代码实现**
```cpp
// 基数估算算法
int estimate_cardinality(Table table, Index index) {
    int sample_pages = min(20, table.total_pages);  // 采样页面数
    int total_unique = 0;
    
    // 随机采样页面
    for (int i = 0; i < sample_pages; i++) {
        Page page = get_random_page(table, index);
        int unique_in_page = count_unique_values(page, index);
        total_unique += unique_in_page;
    }
    
    // 计算估算基数
    double avg_unique_per_page = total_unique / sample_pages;
    int estimated_cardinality = avg_unique_per_page * table.total_pages;
    
    return estimated_cardinality;
}
```

### 2.2 采样统计方法对比


**📋 不同采样方法优缺点**

| 方法类型 | **优点** | **缺点** | **适用场景** |
|---------|---------|---------|-------------|
| 🎲 **随机采样** | `简单高效` | 可能采样到数据分布不均区域 | 数据分布较均匀的表 |
| 📏 **等间隔采样** | `覆盖全表` | 可能错过局部热点数据 | 大表全面统计 |
| 🎯 **分层采样** | `精确度高` | 计算复杂，资源消耗大 | 数据分布复杂的表 |
| ⚡ **自适应采样** | `平衡精度和性能` | 算法实现复杂 | 生产环境推荐 |

### 2.3 基数估算误差分析


**📊 误差来源分析**
```
误差产生的原因：

1️⃣ 采样不充分：
采样页面太少 → 无法代表整体数据分布
解决：增加采样页面数量

2️⃣ 数据分布不均：
数据在表中分布不均匀 → 采样结果偏差
解决：使用分层采样策略  

3️⃣ 数据更新频繁：
统计信息滞后于实际数据变化
解决：提高统计信息更新频率

4️⃣ 页面填充率差异：
不同页面的数据密度不同
解决：考虑页面填充率权重
```

**📈 误差控制策略**
```sql
-- MySQL 8.0 基数统计相关参数
SET GLOBAL innodb_stats_persistent = ON;           -- 持久化统计
SET GLOBAL innodb_stats_auto_recalc = ON;          -- 自动重计算
SET GLOBAL innodb_stats_persistent_sample_pages = 20;  -- 采样页面数
SET GLOBAL innodb_stats_transient_sample_pages = 8;    -- 临时采样数

-- 手动触发统计更新
ANALYZE TABLE students;
```

---

## 3. 🔬 InnoDB采样统计机制


### 3.1 页面采样策略详解


**🔥 页面采样策略**
```
InnoDB采样机制：

采样对象：B+树的叶子节点页面
采样方法：随机选择 + 权重考虑
采样范围：整个索引树的叶子层

采样流程：
1. 定位到索引B+树的叶子层
2. 随机选择N个叶子页面进行采样  
3. 统计每个页面中的唯一值数量
4. 计算加权平均值
5. 根据总页面数推算全表基数
```

**📊 采样页面选择图示**
```
B+树索引结构：
                    [根节点]
                   /    |    \
            [内部节点1] [内部节点2] [内部节点3]
           /  |  |  \   /  |  \     /  |  \
         [叶1][叶2][叶3][叶4][叶5][叶6][叶7][叶8]
          ↑    ↑         ↑         ↑    ↑
         采样  采样       采样       采样  采样
         
采样策略：
• 随机选择叶子页面，不是连续选择
• 避免数据热点区域影响统计结果  
• 考虑页面数据密度的权重
```

### 3.2 自适应采样算法


**🔥 自适应采样算法**
```cpp
// 自适应采样算法伪代码
class AdaptiveSampling {
private:
    int base_sample_pages = 8;      // 基础采样页面数
    int max_sample_pages = 20;      // 最大采样页面数
    double target_accuracy = 0.95;  // 目标准确度
    
public:
    int calculate_sample_size(Table table) {
        int total_pages = table.get_page_count();
        
        // 小表：采样更多页面提高精度
        if (total_pages < 100) {
            return min(total_pages, max_sample_pages);
        }
        
        // 大表：根据变异度调整采样数
        double data_variance = estimate_variance(table);
        int adaptive_pages = base_sample_pages;
        
        if (data_variance > 0.5) {
            adaptive_pages = min(base_sample_pages * 2, max_sample_pages);
        }
        
        return adaptive_pages;
    }
};
```

### 3.3 统计信息缓存机制


**🔥 统计信息缓存机制**
```
缓存层次结构：

1️⃣ 内存缓存（第一层）：
• 存储位置：InnoDB数据字典缓存
• 缓存内容：最近计算的基数统计
• 有效期：直到下次ANALYZE或自动更新

2️⃣ 系统表缓存（第二层）：  
• 存储位置：mysql.innodb_table_stats
• 持久化：统计信息写入磁盘
• 恢复：重启后从系统表恢复统计

3️⃣ 查询缓存（第三层）：
• 基于统计信息的执行计划缓存
• 统计信息变化时失效重新生成
```

**💾 统计信息存储表**
```sql
-- 查看统计信息存储表
SELECT * FROM mysql.innodb_table_stats WHERE table_name = 'students';
+---------------+------------+---------------------+--------+----------------------+
| database_name | table_name | last_update         | n_rows | clustered_index_size |
+---------------+------------+---------------------+--------+----------------------+
| testdb        | students   | 2024-09-04 10:30:15| 9950   | 145                  |
+---------------+------------+---------------------+--------+----------------------+

-- 查看索引统计信息
SELECT * FROM mysql.innodb_index_stats WHERE table_name = 'students';
+----------+------------+-----------+---------------------+-----------+--------+
|database_name|table_name|index_name | last_update         | stat_name | stat_value |
+----------+------------+-----------+---------------------+-----------+--------+
| testdb   | students   | PRIMARY   | 2024-09-04 10:30:15| n_diff_pfx01| 9950    |
| testdb   | students   | idx_name  | 2024-09-04 10:30:15| n_diff_pfx01| 8234    |
+----------+------------+-----------+---------------------+-----------+--------+
```

---

## 4. ⚙️ 统计信息管理机制


### 4.1 统计更新触发机制


**🔸 自动触发条件**
```
InnoDB自动统计更新触发条件：

1️⃣ 数据变化阈值触发：
• 表数据变化超过10%时自动触发
• 计算公式：changed_rows / total_rows > 0.1

2️⃣ 时间间隔触发：
• 距离上次统计超过指定时间
• 可配置参数控制间隔时间

3️⃣ 索引操作触发：
• CREATE INDEX 或 DROP INDEX 后
• ALTER TABLE 修改表结构后

4️⃣ 手动触发：
• ANALYZE TABLE 命令
• 重启MySQL服务
```

**⚡ 触发参数配置**
```sql
-- 统计更新相关参数
SHOW VARIABLES LIKE '%innodb_stats%';
+--------------------------------------+-------+
| Variable_name                        | Value |
+--------------------------------------+-------+
| innodb_stats_auto_recalc            | ON    | ← 自动重计算开关
| innodb_stats_persistent             | ON    | ← 持久化统计信息
| innodb_stats_persistent_sample_pages| 20    | ← 持久化统计采样页面数
| innodb_stats_transient_sample_pages | 8     | ← 临时统计采样页面数
| innodb_stats_method                 | nulls_equal | ← 统计方法
+--------------------------------------+-------+

-- 调整统计参数
SET GLOBAL innodb_stats_persistent_sample_pages = 50;  -- 提高采样精度
SET GLOBAL innodb_stats_auto_recalc = OFF;            -- 关闭自动统计
```

### 4.2 统计信息持久化


**💾 持久化存储机制**
```
统计信息持久化流程：

计算统计 → 内存缓存 → 写入系统表 → 磁盘持久化

持久化的优势：
✅ 重启后统计信息不丢失
✅ 避免重复计算节省资源
✅ 统计历史可追溯
✅ 跨实例统计信息共享

持久化的配置：
• innodb_stats_persistent = ON
• 统计信息存储在mysql库的系统表中
• 支持手动导入导出统计信息
```

### 4.3 性能监控指标


**📊 关键监控指标**
```sql
-- 监控统计信息状态
SELECT 
    table_schema,
    table_name,
    ROUND(data_length/1024/1024,2) AS data_mb,
    table_rows,
    avg_row_length,
    update_time
FROM information_schema.tables 
WHERE table_schema = 'your_database'
ORDER BY data_length DESC;

-- 监控索引基数准确性
SELECT 
    table_name,
    index_name,
    cardinality,
    ROUND(cardinality/table_rows, 4) AS selectivity
FROM information_schema.statistics s
JOIN information_schema.tables t ON s.table_name = t.table_name
WHERE s.table_schema = 'your_database'
AND cardinality > 0
ORDER BY selectivity DESC;
```

**⚠️ 预警指标设置**
```
需要关注的异常指标：

🔴 基数为0：
• 可能原因：统计信息过期或损坏
• 影响：优化器无法正确评估成本
• 解决：执行ANALYZE TABLE更新统计

🟡 基数异常波动：
• 可能原因：数据分布发生重大变化
• 影响：执行计划可能不再optimal
• 解决：检查数据变化原因，重新统计

🟠 选择性过低：
• 可能原因：索引列重复值太多
• 影响：索引效果差，查询性能差
• 解决：考虑删除低选择性索引
```

---

## 5. 🎯 基数评估准确性优化


### 5.1 基数估算误差控制


**🔥 基数估算误差控制策略**
```
误差控制的多层次方法：

1️⃣ 算法层面控制：
• 增加采样页面数量
• 使用分层采样减少偏差
• 引入数据分布权重

2️⃣ 参数层面调优：
• innodb_stats_persistent_sample_pages 调大
• 减少innodb_stats_auto_recalc触发频率
• 手动控制统计更新时机

3️⃣ 应用层面优化：
• 定期执行ANALYZE TABLE
• 监控基数变化趋势  
• 结合业务特点调整策略
```

**📊 误差评估方法**
```sql
-- 评估基数统计准确性
WITH actual_cardinality AS (
    SELECT 
        'students' as table_name,
        'gender' as column_name,
        COUNT(DISTINCT gender) as actual_count
    FROM students
),
estimated_cardinality AS (
    SELECT 
        table_name,
        column_name, 
        cardinality as estimated_count
    FROM information_schema.statistics
    WHERE table_name = 'students' 
    AND column_name = 'gender'
)
SELECT 
    a.table_name,
    a.column_name,
    a.actual_count,
    e.estimated_count,
    ROUND(ABS(a.actual_count - e.estimated_count) / a.actual_count * 100, 2) as error_rate
FROM actual_cardinality a
JOIN estimated_cardinality e ON a.table_name = e.table_name;
```

### 5.2 针对性优化策略


**🔸 不同场景的优化策略**

| 场景类型 | **优化策略** | **具体方法** |
|---------|-------------|-------------|
| 🏢 **小表(< 1万行)** | `全量统计` | 设置采样页面数=总页面数 |
| 📊 **大表(> 100万行)** | `智能采样` | 使用自适应采样算法 |
| 🔄 **高频更新表** | `增量统计` | 缩短统计更新间隔 |
| 📈 **数据倾斜表** | `分层采样` | 按数据分布分层统计 |
| ⚡ **实时查询表** | `缓存优化` | 延长统计信息缓存时间 |

### 5.3 基数变化监控预警


**🔔 监控预警机制**
```sql
-- 创建基数监控视图
CREATE VIEW cardinality_monitor AS
SELECT 
    table_schema,
    table_name,
    index_name,
    column_name,
    cardinality,
    ROUND(cardinality / (
        SELECT table_rows 
        FROM information_schema.tables t 
        WHERE t.table_name = s.table_name 
        AND t.table_schema = s.table_schema
    ), 4) as selectivity,
    NOW() as check_time
FROM information_schema.statistics s
WHERE cardinality > 0;

-- 基数异常检测查询
SELECT *
FROM cardinality_monitor
WHERE selectivity < 0.01    -- 选择性过低
   OR selectivity > 1.5     -- 基数异常(可能统计错误)
   OR cardinality = 0;      -- 统计信息丢失
```

---

## 6. 🏗️ 大表基数统计策略


### 6.1 大表统计挑战与解决方案


**💡 大表统计面临的挑战**
```
挑战1：统计耗时过长
• 表数据量：几亿到几十亿行
• 统计时间：可能需要数小时
• 影响：锁表时间长，影响业务

挑战2：资源消耗巨大  
• CPU消耗：大量页面扫描计算
• IO消耗：读取大量数据页面
• 内存消耗：缓存采样数据

挑战3：统计准确性难保证
• 采样比例小：无法代表整体分布
• 数据倾斜：热点数据影响统计
• 实时性差：统计信息滞后
```

**🔥 大表基数统计优化策略**
```
策略1：分时段统计
• 在业务低峰期执行ANALYZE
• 分批次处理多个表的统计
• 避开主要业务时间窗口

策略2：增量统计更新
• 只对变化的数据区域重新统计
• 结合分区表特性进行局部统计
• 减少全表扫描的频率

策略3：智能采样优化
• 根据表大小动态调整采样比例
• 使用分层采样处理数据倾斜
• 结合业务特点优化采样策略

策略4：资源控制
• 限制统计过程的资源使用
• 使用并行统计提高效率
• 合理配置innodb_io_capacity
```

### 6.2 分区表统计优化


**🗂️ 分区表基数统计**
```sql
-- 分区表的统计策略
-- 1. 查看分区表统计信息
SELECT 
    partition_name,
    table_rows,
    data_length,
    index_length
FROM information_schema.partitions 
WHERE table_name = 'large_orders' 
AND partition_name IS NOT NULL;

-- 2. 分区级别的统计更新
ALTER TABLE large_orders ANALYZE PARTITION p_2024_01;
ALTER TABLE large_orders ANALYZE PARTITION p_2024_02; 

-- 3. 批量更新所有分区
SELECT CONCAT(
    'ALTER TABLE ', table_name, 
    ' ANALYZE PARTITION ', partition_name, ';'
) as analyze_sql
FROM information_schema.partitions 
WHERE table_name = 'large_orders'
AND partition_name IS NOT NULL;
```

### 6.3 基数统计资源消耗控制


**⚙️ 资源消耗控制配置**
```sql
-- 控制统计过程资源使用
SET SESSION innodb_stats_persistent_sample_pages = 10;  -- 减少采样页面
SET SESSION long_query_time = 3600;                     -- 增加慢查询阈值
SET SESSION innodb_lock_wait_timeout = 300;             -- 设置锁等待超时

-- 在业务低峰期执行统计
-- 创建统计任务脚本
SELECT 
    CONCAT(
        'ANALYZE TABLE ', table_schema, '.', table_name, 
        '; -- Estimated time: ', 
        ROUND(data_length/1024/1024/100, 1), ' minutes'
    ) as analyze_command
FROM information_schema.tables
WHERE table_schema = 'your_database'
AND engine = 'InnoDB'
AND table_rows > 1000000  -- 只统计大表
ORDER BY data_length DESC;
```

**📊 资源监控脚本**
```sql
-- 监控统计过程资源使用
SELECT 
    processlist_id,
    processlist_user,
    processlist_host,
    processlist_command,
    processlist_time,
    processlist_info
FROM performance_schema.threads 
WHERE processlist_info LIKE '%ANALYZE%'
   OR processlist_command = 'Statistics';

-- 监控IO使用情况
SELECT 
    file_name,
    event_name,
    count_read,
    count_write,
    sum_timer_read/1000000000 as read_time_sec,
    sum_timer_write/1000000000 as write_time_sec
FROM performance_schema.file_summary_by_instance
WHERE file_name LIKE '%your_table%'
ORDER BY sum_timer_read DESC;
```

---

## 7. 📋 核心要点总结


### 7.1 必须掌握的核心概念


```
🔸 基数(Cardinality) = 索引列中不重复值的数量
🔸 选择性 = 基数/总行数，决定索引的使用价值
🔸 采样统计 = 通过部分数据估算整体基数的方法
🔸 统计信息 = MySQL优化器制定执行计划的重要依据
🔸 持久化统计 = 将统计信息保存到系统表中
🔸 自适应采样 = 根据表特点动态调整采样策略
```

### 7.2 关键理解要点


**🔹 为什么基数统计如此重要**
```
查询优化器的决策依据：
• 基数高 → 索引选择性好 → 优先使用索引
• 基数低 → 索引选择性差 → 可能选择全表扫描
• 基数错误 → 执行计划不optimal → 查询性能差

实际影响：
错误的基数统计可能导致：
- 本该用索引的查询走了全表扫描
- 本该全表扫描的查询强制走索引
- JOIN顺序选择错误
- 临时表使用策略错误
```

**🔹 采样统计的权衡**
```
精度 vs 性能的平衡：
• 采样页面多 → 统计准确 → 耗时长
• 采样页面少 → 统计快速 → 可能不准

最佳实践：
- 小表：可以全量统计
- 中等表：适度采样(10-20页)
- 大表：智能采样+分时统计
- 特殊表：根据数据特点定制策略
```

**🔹 何时需要手动干预**
```
需要手动ANALYZE的场景：
✅ 批量数据导入后
✅ 删除大量数据后
✅ 数据分布发生重大变化
✅ 查询计划明显不合理
✅ 新建索引后统计异常

自动统计的局限：
❌ 可能在业务高峰期触发
❌ 采样可能不充分
❌ 无法识别特殊数据分布
❌ 参数配置可能不optimal
```

### 7.3 实际应用价值


**💼 业务场景应用**
- **电商系统**：商品表基数统计影响搜索性能
- **用户系统**：用户表索引基数决定查询策略
- **订单系统**：时间范围查询的基数评估很关键
- **日志系统**：大表的增量统计策略很重要

**🔧 运维实践**
- **监控体系**：建立基数统计的监控和预警
- **优化流程**：制定统计信息的更新和维护流程
- **故障处理**：识别和修复统计信息相关的性能问题
- **容量规划**：根据基数趋势进行索引和分区规划

**核心记忆**：
- 基数统计是查询优化器的"眼睛"
- 准确的统计信息是高效查询的前提
- 采样统计在精度和性能间寻求平衡
- 大表统计需要专门的策略和资源控制
- 定期监控和维护统计信息是运维的重要工作