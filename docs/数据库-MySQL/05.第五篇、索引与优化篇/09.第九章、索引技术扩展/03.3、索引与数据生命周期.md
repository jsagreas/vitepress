---
title: 3、索引与数据生命周期
---
## 📚 目录

1. [数据生命周期概述](#1-数据生命周期概述)
2. [数据归档索引策略](#2-数据归档索引策略)
3. [历史数据索引管理](#3-历史数据索引管理)
4. [数据老化索引处理](#4-数据老化索引处理)
5. [索引生命周期管理](#5-索引生命周期管理)
6. [数据分层索引设计](#6-数据分层索引设计)
7. [自动化索引清理](#7-自动化索引清理)
8. [核心要点总结](#8-核心要点总结)

---

## 1. 🌊 数据生命周期概述


### 1.1 什么是数据生命周期


**数据生命周期定义**：
数据生命周期是指数据从创建、使用到最终销毁的完整过程。就像人的生命一样，数据也会经历不同的阶段，每个阶段的价值和使用频率都不相同。

```
数据价值随时间变化曲线:
价值 ↑
    │ ████████╗
    │         ║ 热数据 (频繁访问)
    │         ╟─────╖  
    │               ║ 温数据 (偶尔访问)
    │               ╟──────╖
    │                     ║ 冷数据 (很少访问)
    │                     ╟────────╖
    │                             ║ 历史数据 (归档)
    └─────────────────────────────╨──────────→ 时间
    创建    1个月   6个月    1年     3年以上
```

**🔄 数据生命周期四个阶段**：

| 阶段 | **特征** | **访问频率** | **存储要求** | **索引策略** |
|------|---------|-------------|-------------|-------------|
| **🔥 热数据** | `活跃使用` | `高频访问` | `高性能存储` | 完整索引覆盖 |
| **🌡️ 温数据** | `偶尔使用` | `中频访问` | `平衡性存储` | 核心索引保留 |
| **❄️ 冷数据** | `很少使用` | `低频访问` | `低成本存储` | 最小化索引 |
| **📦 归档数据** | `合规保存` | `极少访问` | `归档存储` | 必要索引only |

### 1.2 数据生命周期管理的重要性


**为什么需要数据生命周期管理**：

> 💡 **核心问题**
> 
> 随着业务发展，数据量呈指数级增长。如果不进行生命周期管理，会导致：
> - 存储成本急剧上升
> - 查询性能持续下降
> - 备份时间越来越长
> - 索引维护开销巨大

**📊 数据增长的现实挑战**：

```
典型电商系统数据增长:
订单表数据量
100万 ────→ 1000万 ────→ 1亿 ────→ 10亿
6个月      1年        2年       3年

索引大小变化:
500MB ────→ 5GB ────→ 50GB ────→ 500GB
查询时间:
50ms ────→ 200ms ────→ 2s ────→ 20s+
```

### 1.3 数据分层存储架构


**🏗️ 现代数据分层架构**：

```
数据分层存储架构图:

应用层查询
    ↓
┌─────────────────────────────────────┐
│ 统一查询接口 (Query Router)           │
└─────────────────┬───────────────────┘
                  ↓
    ┌─────────────┼─────────────┐
    ↓             ↓             ↓
┌─────────┐  ┌─────────┐  ┌─────────┐
│ 热数据   │  │ 温数据   │  │ 冷数据   │
│ 高性能   │  │ 平衡型   │  │ 低成本   │
│ SSD存储  │  │ 混合存储 │  │ HDD存储  │
│ 完整索引 │  │ 核心索引 │  │ 稀疏索引 │
└─────────┘  └─────────┘  └─────────┘
      ↓             ↓             ↓
   即时查询      秒级查询      分钟级查询
```

---

## 2. 📦 数据归档索引策略


### 2.1 数据归档的基本概念


**什么是数据归档**：
数据归档是将不再频繁使用的历史数据从主要存储系统迁移到成本更低的长期存储系统的过程。这就像把旧照片从相册移到储物箱一样。

**🎯 归档的核心目标**：
- **降低存储成本** - 使用便宜的存储介质
- **提升查询性能** - 减少主表数据量
- **简化备份恢复** - 缩短备份时间
- **满足合规要求** - 长期保存重要数据

### 2.2 归档数据识别策略


**📅 基于时间的归档策略**：

```sql
-- 典型的归档数据识别规则
-- 订单表：2年以上的已完成订单
SELECT COUNT(*) as archive_count, 
       SUM(data_length + index_length)/1024/1024 as size_mb
FROM information_schema.tables t
JOIN orders o ON 1=1
WHERE o.created_time < DATE_SUB(NOW(), INTERVAL 2 YEAR)
  AND o.status = 'completed';

-- 日志表：6个月以上的访问日志
SELECT DATE(created_time) as log_date,
       COUNT(*) as record_count
FROM access_logs 
WHERE created_time < DATE_SUB(NOW(), INTERVAL 6 MONTH)
GROUP BY DATE(created_time)
ORDER BY log_date;
```

**🏷️ 基于状态的归档策略**：

| 业务场景 | **归档条件** | **保留索引** | **归档周期** |
|---------|-------------|-------------|-------------|
| **订单数据** | `已完成且>1年` | 订单号、用户ID | 每月执行 |
| **用户行为日志** | `>6个月` | 时间戳、用户ID | 每周执行 |
| **交易记录** | `已结算且>2年` | 交易号、时间 | 每季度执行 |
| **系统日志** | `>3个月` | 时间戳、级别 | 每日执行 |

### 2.3 归档索引设计原则


**🔧 归档表索引设计要点**：

```sql
-- 归档表索引设计示例
CREATE TABLE orders_archive (
    order_id BIGINT PRIMARY KEY,
    user_id INT NOT NULL,
    created_time DATETIME NOT NULL,
    total_amount DECIMAL(10,2),
    status VARCHAR(20),
    -- 归档时间字段
    archived_time DATETIME DEFAULT CURRENT_TIMESTAMP
) PARTITION BY RANGE (YEAR(created_time)) (
    PARTITION p2020 VALUES LESS THAN (2021),
    PARTITION p2021 VALUES LESS THAN (2022),
    PARTITION p2022 VALUES LESS THAN (2023),
    PARTITION p2023 VALUES LESS THAN (2024)
);

-- 归档表关键索引
CREATE INDEX idx_archive_user_time ON orders_archive (user_id, created_time);
CREATE INDEX idx_archive_time ON orders_archive (created_time);
CREATE INDEX idx_archive_status ON orders_archive (status, created_time);
```

**⚖️ 归档索引权衡原则**：

> ⚠️ **重要平衡**
> 
> 归档数据的索引设计需要在查询性能和存储成本之间找到平衡点：
> - **必要索引**：业务查询必需的核心索引
> - **删除冗余**：移除使用频率极低的索引
> - **合并索引**：将多个单列索引合并为复合索引

### 2.4 归档过程索引管理


**🔄 归档操作流程**：

```sql
-- 步骤1: 创建归档表结构(如果不存在)
DELIMITER //
CREATE PROCEDURE create_archive_table()
BEGIN
    -- 检查归档表是否存在
    IF NOT EXISTS (
        SELECT 1 FROM information_schema.tables 
        WHERE table_name = 'orders_archive'
    ) THEN
        -- 创建归档表结构
        CREATE TABLE orders_archive LIKE orders;
        
        -- 添加归档时间字段
        ALTER TABLE orders_archive 
        ADD COLUMN archived_time DATETIME DEFAULT CURRENT_TIMESTAMP;
        
        -- 创建必要索引
        CREATE INDEX idx_archived_time ON orders_archive (archived_time);
    END IF;
END //
DELIMITER ;

-- 步骤2: 批量归档数据
DELIMITER //
CREATE PROCEDURE archive_old_orders()
BEGIN
    DECLARE done INT DEFAULT FALSE;
    DECLARE batch_size INT DEFAULT 10000;
    DECLARE total_archived INT DEFAULT 0;
    
    -- 开始归档事务
    START TRANSACTION;
    
    -- 批量迁移数据
    WHILE done = FALSE DO
        -- 插入到归档表
        INSERT INTO orders_archive 
        SELECT *, NOW() as archived_time
        FROM orders 
        WHERE created_time < DATE_SUB(NOW(), INTERVAL 2 YEAR)
          AND status = 'completed'
        LIMIT batch_size;
        
        -- 获取影响行数
        SET total_archived = total_archived + ROW_COUNT();
        
        -- 如果处理行数小于批次大小，说明处理完成
        IF ROW_COUNT() < batch_size THEN
            SET done = TRUE;
        END IF;
        
        -- 删除原表数据
        DELETE FROM orders 
        WHERE created_time < DATE_SUB(NOW(), INTERVAL 2 YEAR)
          AND status = 'completed'
        LIMIT batch_size;
        
    END WHILE;
    
    COMMIT;
    
    -- 输出归档统计
    SELECT CONCAT('成功归档 ', total_archived, ' 条记录') as result;
END //
DELIMITER ;
```

---

## 3. 📚 历史数据索引管理


### 3.1 历史数据的特点


**历史数据访问模式**：
历史数据有着独特的访问特征，这决定了它需要不同的索引策略。

```
历史数据访问特征:
┌─────────────────────────────────────┐
│ 写入特征: 一次写入，很少更新         │
│ 查询特征: 以时间范围查询为主         │
│ 频率特征: 随时间推移访问频率降低     │
│ 范围特征: 通常查询较大时间范围       │
└─────────────────────────────────────┘

查询模式分析:
• 按时间范围: 70% (查询某个月的数据)
• 按用户历史: 20% (查询用户所有历史)
• 按条件统计: 8% (历史数据统计分析)
• 精确查找: 2% (查找特定历史记录)
```

### 3.2 历史数据分区策略


**📅 时间分区设计**：

```sql
-- 按年分区的历史数据表
CREATE TABLE user_activity_history (
    id BIGINT AUTO_INCREMENT,
    user_id INT NOT NULL,
    activity_type VARCHAR(50),
    activity_time DATETIME NOT NULL,
    details JSON,
    PRIMARY KEY (id, activity_time)
) PARTITION BY RANGE (YEAR(activity_time)) (
    PARTITION p2020 VALUES LESS THAN (2021),
    PARTITION p2021 VALUES LESS THAN (2022),
    PARTITION p2022 VALUES LESS THAN (2023),
    PARTITION p2023 VALUES LESS THAN (2024),
    PARTITION p2024 VALUES LESS THAN (2025),
    PARTITION p_future VALUES LESS THAN MAXVALUE
);
```

**🔧 分区索引优化**：

```sql
-- 每个分区的本地索引
-- 自动在每个分区创建以下索引

-- 主要查询索引
CREATE INDEX idx_user_time ON user_activity_history (user_id, activity_time);

-- 按类型查询索引  
CREATE INDEX idx_type_time ON user_activity_history (activity_type, activity_time);

-- 时间范围查询索引
CREATE INDEX idx_time_only ON user_activity_history (activity_time);
```

### 3.3 历史数据压缩索引


**💾 索引压缩技术**：

历史数据由于访问频率低，可以采用压缩索引来节省存储空间。

```sql
-- 启用索引压缩
ALTER TABLE user_activity_history 
MODIFY COLUMN details JSON COMPRESSED;

-- 压缩索引创建
CREATE INDEX idx_compressed_user 
ON user_activity_history (user_id) 
USING BTREE 
KEY_BLOCK_SIZE=8;  -- 压缩块大小

-- 查看压缩效果
SELECT 
    table_name,
    ROUND(data_length/1024/1024, 2) as data_mb,
    ROUND(index_length/1024/1024, 2) as index_mb,
    ROUND((data_length + index_length)/1024/1024, 2) as total_mb,
    table_rows
FROM information_schema.tables 
WHERE table_name LIKE '%_history%';
```

**📊 压缩效果对比**：

| 表大小 | **普通索引** | **压缩索引** | **节省空间** | **查询性能** |
|--------|-------------|-------------|-------------|-------------|
| **1GB数据** | `200MB索引` | `120MB索引` | `40%↓` | `微降5%` |
| **10GB数据** | `2GB索引` | `1.1GB索引` | `45%↓` | `微降8%` |
| **100GB数据** | `20GB索引` | `10GB索引` | `50%↓` | `微降10%` |

### 3.4 历史数据查询优化


**🔍 优化查询策略**：

```sql
-- 历史数据查询优化示例

-- 优化前：全表扫描
SELECT * FROM user_activity_history 
WHERE user_id = 12345 
ORDER BY activity_time DESC;

-- 优化后：分区剪枝 + 索引优化
SELECT * FROM user_activity_history 
WHERE user_id = 12345 
  AND activity_time >= '2023-01-01'
  AND activity_time < '2024-01-01'
ORDER BY activity_time DESC;

-- 使用分区查询统计
SELECT 
    YEAR(activity_time) as year,
    COUNT(*) as activity_count,
    COUNT(DISTINCT user_id) as active_users
FROM user_activity_history 
WHERE activity_time >= '2020-01-01'
GROUP BY YEAR(activity_time);
```

---

## 4. ❄️ 数据老化索引处理


### 4.1 数据老化的定义


**什么是数据老化**：
数据老化是指随着时间推移，数据的业务价值和访问频率逐渐降低的过程。就像食物会过期一样，数据也会"过期"，但不是丢弃，而是要降级处理。

**🕐 数据老化阶段划分**：

```
数据老化时间轴:
创建 ────→ 1个月 ────→ 6个月 ────→ 1年 ────→ 3年+
 │           │           │          │         │
热数据      温数据       冷数据     归档数据   销毁数据
完整索引    核心索引     稀疏索引   最小索引   无索引

访问频率: 
████████  ██████    ████      ██        ∅
100%      60%       30%       5%        0%
```

### 4.2 索引老化处理策略


**🔄 索引渐进式删除**：

```sql
-- 定期检查并处理老化索引
DELIMITER //
CREATE PROCEDURE handle_aging_indexes()
BEGIN
    DECLARE table_age INT;
    
    -- 获取表的数据分布
    SELECT 
        DATEDIFF(NOW(), MIN(created_time)) as min_age,
        DATEDIFF(NOW(), MAX(created_time)) as max_age
    INTO @min_age, @max_age
    FROM orders;
    
    -- 根据数据年龄调整索引策略
    IF @min_age > 365 THEN  -- 超过1年的数据
        -- 删除非核心索引
        SET @sql = 'DROP INDEX idx_optional_field ON orders';
        PREPARE stmt FROM @sql;
        EXECUTE stmt;
        DEALLOCATE PREPARE stmt;
        
        -- 保留核心业务索引
        SELECT 'Dropped optional indexes for aging data' as result;
    END IF;
    
    IF @min_age > 1095 THEN  -- 超过3年的数据
        -- 考虑迁移到归档表
        CALL archive_old_orders();
    END IF;
    
END //
DELIMITER ;
```

**📊 索引老化检测**：

```sql
-- 监控索引使用情况
SELECT 
    t.table_name,
    s.index_name,
    s.rows_read,
    s.rows_examined,
    ROUND(s.rows_read/s.rows_examined*100, 2) as efficiency_pct,
    CASE 
        WHEN s.rows_read = 0 THEN '未使用'
        WHEN s.rows_read < 1000 THEN '很少使用'
        WHEN s.rows_read < 10000 THEN '偶尔使用'
        ELSE '经常使用'
    END as usage_level
FROM information_schema.tables t
JOIN information_schema.statistics s ON t.table_name = s.table_name
WHERE t.table_schema = DATABASE()
  AND s.index_name != 'PRIMARY'
ORDER BY s.rows_read ASC;
```

### 4.3 冷数据索引精简


**🎯 冷数据索引策略**：

冷数据由于访问频率很低，需要采用精简的索引策略以节省存储空间。

```sql
-- 冷数据表索引精简示例
CREATE TABLE orders_cold (
    order_id BIGINT PRIMARY KEY,
    user_id INT NOT NULL,
    created_time DATETIME NOT NULL,
    total_amount DECIMAL(10,2),
    status VARCHAR(20),
    cold_date DATETIME DEFAULT CURRENT_TIMESTAMP,
    
    -- 只保留最必要的索引
    INDEX idx_cold_user (user_id),           -- 用户查询
    INDEX idx_cold_time (created_time),      -- 时间查询
    INDEX idx_cold_composite (user_id, created_time)  -- 复合查询
    
    -- 删除的索引：
    -- INDEX idx_status (status)            -- 状态查询较少
    -- INDEX idx_amount (total_amount)      -- 金额查询很少
    -- INDEX idx_complex (status, amount)   -- 复杂查询极少
);
```

**📈 索引精简效果**：

| 索引精简项目 | **精简前** | **精简后** | **节省** | **影响** |
|-------------|-----------|-----------|---------|----------|
| **索引数量** | `8个索引` | `3个索引` | `62.5%↓` | 查询种类受限 |
| **索引大小** | `2.5GB` | `800MB` | `68%↓` | 存储成本降低 |
| **维护开销** | `高` | `低` | `70%↓` | 写入性能提升 |
| **查询性能** | `优秀` | `良好` | `轻微下降` | 可接受范围 |

---

## 5. 🔄 索引生命周期管理


### 5.1 索引生命周期概念


**索引的生命周期**：
索引也有自己的生命周期，从创建、优化、维护到最终删除。合理管理索引生命周期可以显著提升数据库性能和降低成本。

```
索引生命周期阶段:
创建阶段 ────→ 活跃阶段 ────→ 老化阶段 ────→ 废弃阶段
   │             │             │             │
  规划设计       监控优化       评估精简       清理删除
  性能测试       使用统计       压缩合并       空间回收
```

### 5.2 索引创建管理


**📋 索引创建流程规范**：

```sql
-- 索引创建标准流程
DELIMITER //
CREATE PROCEDURE create_index_with_lifecycle(
    IN table_name VARCHAR(64),
    IN index_name VARCHAR(64), 
    IN index_columns VARCHAR(255),
    IN index_type VARCHAR(20)
)
BEGIN
    DECLARE index_exists INT DEFAULT 0;
    
    -- 检查索引是否已存在
    SELECT COUNT(*) INTO index_exists
    FROM information_schema.statistics 
    WHERE table_name = table_name 
      AND index_name = index_name;
    
    IF index_exists = 0 THEN
        -- 创建索引
        SET @sql = CONCAT('CREATE INDEX ', index_name, 
                         ' ON ', table_name, ' (', index_columns, ')');
        
        -- 记录索引元信息
        INSERT INTO index_lifecycle_log (
            table_name, index_name, index_columns,
            creation_time, status, notes
        ) VALUES (
            table_name, index_name, index_columns,
            NOW(), 'created', 
            CONCAT('Index created by lifecycle management')
        );
        
        PREPARE stmt FROM @sql;
        EXECUTE stmt;
        DEALLOCATE PREPARE stmt;
        
        SELECT CONCAT('索引 ', index_name, ' 创建成功') as result;
    ELSE
        SELECT CONCAT('索引 ', index_name, ' 已存在') as result;
    END IF;
END //
DELIMITER ;
```

**📊 索引元数据管理**：

```sql
-- 索引生命周期跟踪表
CREATE TABLE index_lifecycle_log (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    table_name VARCHAR(64) NOT NULL,
    index_name VARCHAR(64) NOT NULL,
    index_columns VARCHAR(255),
    creation_time DATETIME,
    last_used_time DATETIME,
    usage_count BIGINT DEFAULT 0,
    status ENUM('created', 'active', 'aging', 'deprecated', 'dropped'),
    notes TEXT,
    
    INDEX idx_table_index (table_name, index_name),
    INDEX idx_status_time (status, last_used_time)
);
```

### 5.3 索引监控与评估


**📈 索引使用情况监控**：

```sql
-- 索引使用统计分析
CREATE VIEW v_index_usage_stats AS
SELECT 
    t.table_name,
    s.index_name,
    s.cardinality,
    ROUND(stat.rows_read/1000, 2) as reads_k,
    ROUND(stat.rows_examined/1000, 2) as examined_k,
    CASE 
        WHEN stat.rows_read = 0 THEN 0
        ELSE ROUND(stat.rows_read/stat.rows_examined*100, 2)
    END as selectivity_pct,
    ROUND((s.stat_value * $$innodb_page_size)/1024/1024, 2) as size_mb,
    CASE 
        WHEN stat.rows_read = 0 THEN '未使用'
        WHEN stat.rows_read < 1000 THEN '低频'
        WHEN stat.rows_read < 100000 THEN '中频'
        ELSE '高频'
    END as usage_level
FROM information_schema.tables t
JOIN information_schema.statistics s ON t.table_name = s.table_name
LEFT JOIN information_schema.innodb_index_stats stat 
    ON s.table_name = stat.table_name AND s.index_name = stat.index_name
WHERE t.table_schema = DATABASE()
  AND s.index_name != 'PRIMARY';
```

### 5.4 索引自动化维护


**🤖 自动化索引维护策略**：

```sql
-- 自动化索引维护存储过程
DELIMITER //
CREATE PROCEDURE automated_index_maintenance()
BEGIN
    DECLARE done INT DEFAULT FALSE;
    DECLARE v_table_name VARCHAR(64);
    DECLARE v_index_name VARCHAR(64);
    DECLARE v_usage_count BIGINT;
    
    -- 游标定义
    DECLARE index_cursor CURSOR FOR 
        SELECT table_name, index_name, usage_count 
        FROM v_index_usage_stats 
        WHERE usage_level = '未使用' 
          AND size_mb > 100;  -- 大于100MB的未使用索引
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    -- 开始维护流程
    OPEN index_cursor;
    
    maintenance_loop: LOOP
        FETCH index_cursor INTO v_table_name, v_index_name, v_usage_count;
        
        IF done THEN
            LEAVE maintenance_loop;
        END IF;
        
        -- 检查索引是否长期未使用
        IF v_usage_count = 0 THEN
            -- 标记为待删除
            UPDATE index_lifecycle_log 
            SET status = 'deprecated',
                notes = CONCAT(notes, '; Auto-marked for deletion at ', NOW())
            WHERE table_name = v_table_name 
              AND index_name = v_index_name;
              
            -- 记录维护日志
            INSERT INTO index_maintenance_log (
                table_name, index_name, action, 
                action_time, reason
            ) VALUES (
                v_table_name, v_index_name, 'marked_deprecated',
                NOW(), 'Long-term unused large index'
            );
        END IF;
        
    END LOOP;
    
    CLOSE index_cursor;
    
    SELECT '索引自动维护完成' as result;
END //
DELIMITER ;
```

---

## 6. 🏗️ 数据分层索引设计


### 6.1 分层存储架构


**分层存储的核心思想**：
根据数据的访问频率和重要性，将数据存储在不同性能和成本的存储层中，每一层都有相应的索引策略。

```
数据分层存储架构:

┌─────────────────────────────────────────────────┐
│                应用查询层                        │
└─────────────────┬───────────────────────────────┘
                  │
      ┌───────────┼───────────┐
      ↓           ↓           ↓
┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐
│热数据层  │ │温数据层  │ │冷数据层  │ │归档层   │
│         │ │         │ │         │ │        │
│SSD存储  │ │SAS存储  │ │SATA存储 │ │磁带/云  │
│完整索引 │ │核心索引 │ │精简索引 │ │基础索引 │
│<1ms     │ │<10ms    │ │<100ms   │ │<1s     │
└─────────┘ └─────────┘ └─────────┘ └─────────┘
```

### 6.2 热数据索引设计


**🔥 热数据层索引特点**：

热数据需要最高的查询性能，因此索引设计要全面而精细。

```sql
-- 热数据表索引设计示例
CREATE TABLE orders_hot (
    order_id BIGINT PRIMARY KEY,
    user_id INT NOT NULL,
    status VARCHAR(20) NOT NULL,
    created_time DATETIME NOT NULL,
    updated_time DATETIME,
    total_amount DECIMAL(10,2),
    payment_method VARCHAR(20),
    
    -- 热数据完整索引覆盖
    INDEX idx_user_status (user_id, status),
    INDEX idx_status_time (status, created_time),
    INDEX idx_time_amount (created_time, total_amount),
    INDEX idx_payment_time (payment_method, created_time),
    INDEX idx_amount_desc (total_amount DESC),
    INDEX idx_updated_time (updated_time),
    
    -- 覆盖索引优化
    INDEX idx_user_cover (user_id, status, created_time, total_amount)
) ENGINE=InnoDB 
  ROW_FORMAT=COMPRESSED 
  KEY_BLOCK_SIZE=8;
```

**⚡ 热数据索引优化策略**：

| 优化策略 | **实现方法** | **性能提升** | **适用场景** |
|---------|-------------|-------------|-------------|
| **覆盖索引** | `包含所有查询字段` | `50-90%↑` | 频繁的SELECT查询 |
| **前缀索引** | `VARCHAR字段前缀` | `30-50%↑` | 长字符串字段 |
| **复合索引** | `多字段组合` | `40-80%↑` | 多条件查询 |
| **分区索引** | `按时间分区` | `60-200%↑` | 时间范围查询 |

### 6.3 温数据索引设计


**🌡️ 温数据层索引特点**：

温数据访问频率中等，需要在性能和存储之间找到平衡。

```sql
-- 温数据表索引设计
CREATE TABLE orders_warm (
    order_id BIGINT PRIMARY KEY,
    user_id INT NOT NULL,
    status VARCHAR(20),
    created_time DATETIME NOT NULL,
    total_amount DECIMAL(10,2),
    
    -- 保留核心索引
    INDEX idx_user_time (user_id, created_time),
    INDEX idx_status_time (status, created_time),
    INDEX idx_time_only (created_time),
    
    -- 删除低频索引
    -- INDEX idx_amount (total_amount)  -- 金额查询频率低
    -- INDEX idx_complex_query (status, total_amount, created_time)  -- 复杂查询少
    
) ENGINE=InnoDB 
  ROW_FORMAT=COMPRESSED;
```

### 6.4 冷数据索引设计


**❄️ 冷数据层索引特点**：

冷数据很少被访问，索引设计以节省空间为主要目标。

```sql
-- 冷数据表索引设计
CREATE TABLE orders_cold (
    order_id BIGINT PRIMARY KEY,
    user_id INT NOT NULL,
    created_time DATETIME NOT NULL,
    data_blob LONGBLOB,  -- 压缩存储详细数据
    
    -- 最小化索引
    INDEX idx_user (user_id),
    INDEX idx_time (created_time)
    
    -- 其他索引都被删除以节省空间
) ENGINE=InnoDB 
  ROW_FORMAT=COMPRESSED 
  KEY_BLOCK_SIZE=16;  -- 更高压缩比
```

### 6.5 跨层查询实现


**🔍 统一查询接口**：

```sql
-- 跨层数据查询视图
CREATE VIEW v_orders_unified AS
SELECT 'hot' as data_layer, order_id, user_id, status, created_time, total_amount
FROM orders_hot
UNION ALL
SELECT 'warm' as data_layer, order_id, user_id, status, created_time, total_amount  
FROM orders_warm
UNION ALL
SELECT 'cold' as data_layer, order_id, user_id, NULL as status, created_time, NULL as total_amount
FROM orders_cold;

-- 智能查询函数
DELIMITER //
CREATE FUNCTION smart_order_query(p_user_id INT, p_days_back INT)
RETURNS JSON
READS SQL DATA
BEGIN
    DECLARE result JSON;
    
    IF p_days_back <= 30 THEN
        -- 查询热数据
        SELECT JSON_ARRAYAGG(
            JSON_OBJECT('order_id', order_id, 'total', total_amount, 'layer', 'hot')
        ) INTO result
        FROM orders_hot 
        WHERE user_id = p_user_id 
          AND created_time >= DATE_SUB(NOW(), INTERVAL p_days_back DAY);
          
    ELSEIF p_days_back <= 365 THEN
        -- 查询温数据
        SELECT JSON_ARRAYAGG(
            JSON_OBJECT('order_id', order_id, 'total', total_amount, 'layer', 'warm')
        ) INTO result
        FROM orders_warm
        WHERE user_id = p_user_id 
          AND created_time >= DATE_SUB(NOW(), INTERVAL p_days_back DAY);
          
    ELSE
        -- 查询冷数据
        SELECT JSON_ARRAYAGG(
            JSON_OBJECT('order_id', order_id, 'layer', 'cold')
        ) INTO result
        FROM orders_cold
        WHERE user_id = p_user_id 
          AND created_time >= DATE_SUB(NOW(), INTERVAL p_days_back DAY);
    END IF;
    
    RETURN COALESCE(result, JSON_ARRAY());
END //
DELIMITER ;
```

---

## 7. 🤖 自动化索引清理


### 7.1 自动化清理的必要性


**为什么需要自动化索引清理**：

随着业务发展，很多索引会变得不再有用，但手动清理既耗时又容易出错。自动化索引清理就像给数据库配了一个"自动清洁工"。

> 💡 **实际问题**
> 
> 在实际项目中，经常遇到这些问题：
> - 开发时创建了大量测试索引忘记删除
> - 业务变更后某些查询不再使用，相关索引成为死索引
> - 索引数量过多影响写入性能
> - 存储空间浪费严重

### 7.2 索引使用情况分析


**📊 索引使用统计收集**：

```sql
-- 创建索引使用统计表
CREATE TABLE index_usage_stats (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    table_name VARCHAR(64),
    index_name VARCHAR(64),
    reads_count BIGINT DEFAULT 0,
    writes_count BIGINT DEFAULT 0,
    last_access_time DATETIME,
    size_mb DECIMAL(10,2),
    collection_time DATETIME DEFAULT CURRENT_TIMESTAMP,
    
    UNIQUE KEY uk_table_index_time (table_name, index_name, collection_time),
    INDEX idx_last_access (last_access_time),
    INDEX idx_reads_count (reads_count)
);

-- 收集索引使用统计的存储过程
DELIMITER //
CREATE PROCEDURE collect_index_stats()
BEGIN
    INSERT INTO index_usage_stats (
        table_name, index_name, reads_count, 
        size_mb, collection_time
    )
    SELECT 
        t.table_name,
        s.index_name,
        COALESCE(stat.rows_read, 0) as reads_count,
        ROUND(
            (SELECT SUM(stat_value * $$innodb_page_size)
             FROM information_schema.innodb_index_stats ist 
             WHERE ist.table_name = t.table_name 
               AND ist.index_name = s.index_name
               AND ist.stat_name = 'size'
            ) / 1024 / 1024, 2
        ) as size_mb,
        NOW()
    FROM information_schema.tables t
    JOIN information_schema.statistics s ON t.table_name = s.table_name
    LEFT JOIN information_schema.index_statistics stat 
        ON t.table_name = stat.table_name 
        AND s.index_name = stat.index_name
    WHERE t.table_schema = DATABASE()
      AND s.index_name != 'PRIMARY'
    ON DUPLICATE KEY UPDATE
        reads_count = VALUES(reads_count),
        size_mb = VALUES(size_mb),
        collection_time = VALUES(collection_time);
        
    SELECT '索引统计收集完成' as result;
END //
DELIMITER ;
```

### 7.3 自动清理策略


**🎯 清理规则定义**：

```sql
-- 索引清理规则配置表
CREATE TABLE index_cleanup_rules (
    id INT AUTO_INCREMENT PRIMARY KEY,
    rule_name VARCHAR(100),
    table_pattern VARCHAR(100),  -- 表名模式
    index_pattern VARCHAR(100),  -- 索引名模式
    min_unused_days INT,         -- 最少未使用天数
    min_size_mb DECIMAL(10,2),   -- 最小大小(MB)
    max_reads_per_day DECIMAL(10,2),  -- 每天最大读取次数
    action_type ENUM('mark', 'drop') DEFAULT 'mark',
    is_enabled TINYINT(1) DEFAULT 1,
    created_time DATETIME DEFAULT CURRENT_TIMESTAMP
);

-- 插入默认清理规则
INSERT INTO index_cleanup_rules (
    rule_name, table_pattern, index_pattern, 
    min_unused_days, min_size_mb, max_reads_per_day, action_type
) VALUES 
('大型未使用索引', '%', '%', 30, 100, 0, 'mark'),
('临时测试索引', '%', 'tmp_%', 7, 0, 10, 'drop'),
('历史表冗余索引', '%_history', '%', 90, 50, 5, 'mark'),
('日志表过期索引', '%_log', '%', 60, 20, 2, 'drop');
```

**🔄 自动清理执行引擎**：

```sql
-- 自动索引清理主程序
DELIMITER //
CREATE PROCEDURE auto_cleanup_indexes()
BEGIN
    DECLARE done INT DEFAULT FALSE;
    DECLARE v_rule_id INT;
    DECLARE v_rule_name VARCHAR(100);
    DECLARE v_table_pattern VARCHAR(100);
    DECLARE v_index_pattern VARCHAR(100);
    DECLARE v_min_unused_days INT;
    DECLARE v_min_size_mb DECIMAL(10,2);
    DECLARE v_max_reads_per_day DECIMAL(10,2);
    DECLARE v_action_type VARCHAR(10);
    
    -- 游标定义
    DECLARE rule_cursor CURSOR FOR 
        SELECT id, rule_name, table_pattern, index_pattern,
               min_unused_days, min_size_mb, max_reads_per_day, action_type
        FROM index_cleanup_rules 
        WHERE is_enabled = 1;
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    -- 创建临时表存储候选索引
    CREATE TEMPORARY TABLE temp_cleanup_candidates (
        table_name VARCHAR(64),
        index_name VARCHAR(64),
        rule_name VARCHAR(100),
        action_type VARCHAR(10),
        reason TEXT
    );
    
    OPEN rule_cursor;
    
    cleanup_loop: LOOP
        FETCH rule_cursor INTO v_rule_id, v_rule_name, v_table_pattern, 
                              v_index_pattern, v_min_unused_days, 
                              v_min_size_mb, v_max_reads_per_day, v_action_type;
        
        IF done THEN
            LEAVE cleanup_loop;
        END IF;
        
        -- 查找符合规则的索引
        INSERT INTO temp_cleanup_candidates
        SELECT DISTINCT
            ius.table_name,
            ius.index_name,
            v_rule_name,
            v_action_type,
            CONCAT('未使用天数: ', 
                   DATEDIFF(NOW(), COALESCE(ius.last_access_time, ius.collection_time)),
                   ', 大小: ', ius.size_mb, 'MB',
                   ', 日均读取: ', COALESCE(ius.reads_count/30, 0)) as reason
        FROM index_usage_stats ius
        WHERE ius.table_name LIKE v_table_pattern
          AND ius.index_name LIKE v_index_pattern
          AND DATEDIFF(NOW(), COALESCE(ius.last_access_time, ius.collection_time)) >= v_min_unused_days
          AND ius.size_mb >= v_min_size_mb
          AND COALESCE(ius.reads_count/30, 0) <= v_max_reads_per_day;
          
    END LOOP;
    
    CLOSE rule_cursor;
    
    -- 执行清理操作
    CALL execute_cleanup_actions();
    
    -- 显示清理结果
    SELECT * FROM temp_cleanup_candidates;
    
    DROP TEMPORARY TABLE temp_cleanup_candidates;
END //
DELIMITER ;
```

### 7.4 清理操作执行


**⚡ 安全的清理执行**：

```sql
-- 执行清理操作
DELIMITER //
CREATE PROCEDURE execute_cleanup_actions()
BEGIN
    DECLARE done INT DEFAULT FALSE;
    DECLARE v_table_name VARCHAR(64);
    DECLARE v_index_name VARCHAR(64);
    DECLARE v_action_type VARCHAR(10);
    DECLARE v_reason TEXT;
    
    DECLARE cleanup_cursor CURSOR FOR 
        SELECT table_name, index_name, action_type, reason
        FROM temp_cleanup_candidates;
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    OPEN cleanup_cursor;
    
    execute_loop: LOOP
        FETCH cleanup_cursor INTO v_table_name, v_index_name, v_action_type, v_reason;
        
        IF done THEN
            LEAVE execute_loop;
        END IF;
        
        IF v_action_type = 'drop' THEN
            -- 删除索引
            SET @sql = CONCAT('DROP INDEX ', v_index_name, ' ON ', v_table_name);
            PREPARE stmt FROM @sql;
            EXECUTE stmt;
            DEALLOCATE PREPARE stmt;
            
            -- 记录删除日志
            INSERT INTO index_cleanup_log (
                table_name, index_name, action, reason, action_time
            ) VALUES (
                v_table_name, v_index_name, 'dropped', v_reason, NOW()
            );
            
        ELSEIF v_action_type = 'mark' THEN
            -- 标记为待删除
            INSERT INTO index_cleanup_log (
                table_name, index_name, action, reason, action_time
            ) VALUES (
                v_table_name, v_index_name, 'marked_for_deletion', v_reason, NOW()
            );
        END IF;
        
    END LOOP;
    
    CLOSE cleanup_cursor;
END //
DELIMITER ;
```

### 7.5 清理监控与回滚


**📊 清理操作监控**：

```sql
-- 索引清理日志表
CREATE TABLE index_cleanup_log (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    table_name VARCHAR(64),
    index_name VARCHAR(64),
    action ENUM('marked_for_deletion', 'dropped', 'restored'),
    reason TEXT,
    action_time DATETIME,
    operator VARCHAR(50) DEFAULT USER(),
    
    INDEX idx_action_time (action, action_time),
    INDEX idx_table_index (table_name, index_name)
);

-- 清理效果统计视图
CREATE VIEW v_cleanup_stats AS
SELECT 
    DATE(action_time) as cleanup_date,
    action,
    COUNT(*) as action_count,
    GROUP_CONCAT(DISTINCT table_name) as affected_tables
FROM index_cleanup_log
WHERE action_time >= DATE_SUB(NOW(), INTERVAL 30 DAY)
GROUP BY DATE(action_time), action
ORDER BY cleanup_date DESC;
```

**🔄 索引恢复机制**：

```sql
-- 索引恢复存储过程
DELIMITER //
CREATE PROCEDURE restore_dropped_index(
    IN p_table_name VARCHAR(64),
    IN p_index_name VARCHAR(64)
)
BEGIN
    DECLARE v_index_definition TEXT;
    
    -- 从备份中获取索引定义
    SELECT index_definition INTO v_index_definition
    FROM index_backup_definitions
    WHERE table_name = p_table_name 
      AND index_name = p_index_name;
    
    IF v_index_definition IS NOT NULL THEN
        -- 重建索引
        SET @sql = v_index_definition;
        PREPARE stmt FROM @sql;
        EXECUTE stmt;
        DEALLOCATE PREPARE stmt;
        
        -- 记录恢复日志
        INSERT INTO index_cleanup_log (
            table_name, index_name, action, reason, action_time
        ) VALUES (
            p_table_name, p_index_name, 'restored', 
            'Manually restored from backup', NOW()
        );
        
        SELECT CONCAT('索引 ', p_index_name, ' 已成功恢复') as result;
    ELSE
        SELECT CONCAT('未找到索引 ', p_index_name, ' 的备份定义') as result;
    END IF;
END //
DELIMITER ;
```

---

## 8. 📋 核心要点总结


### 8.1 必须掌握的核心概念


```
🔸 数据生命周期：热→温→冷→归档四个阶段，每个阶段有不同的访问特征
🔸 索引策略适配：根据数据生命周期阶段调整索引数量和复杂度
🔸 分层存储设计：不同层级使用不同的存储介质和索引策略
🔸 自动化管理：通过程序自动监控、评估和清理索引
🔸 成本效益平衡：在查询性能和存储成本之间找到最佳平衡点
```

### 8.2 关键理解要点


**🔹 数据价值衰减规律**
```
理解要点：
- 数据价值随时间递减，但衰减速度因业务而异
- 热数据需要快速响应，冷数据可以接受较慢查询
- 索引策略要随数据价值变化而调整
- 合理的生命周期管理能显著降低总成本
```

**🔹 索引生命周期管理**
```
管理原则：
- 定期评估索引使用情况
- 及时删除无用索引减少维护开销
- 保留备份定义以便必要时恢复
- 自动化比手工管理更可靠
```

**🔹 分层架构的优势**
```
架构价值：
- 根据访问模式优化存储成本
- 提升整体系统性能
- 简化数据管理复杂度
- 便于扩展和维护
```

### 8.3 实际应用价值


**💡 业务场景应用**

```markdown
📋 **电商订单系统**
• 近30天订单：热数据层，完整索引，SSD存储
• 3-12月订单：温数据层，核心索引，混合存储  
• 1-3年订单：冷数据层，基础索引，HDD存储
• 3年以上：归档层，最小索引，便宜存储

📊 **日志分析系统**  
• 近7天日志：实时分析，全量索引
• 7-30天日志：定期分析，重要索引
• 1-6月日志：历史查询，时间索引
• 6月以上：合规保存，压缩存储

🏦 **金融交易系统**
• 当日交易：极速查询，内存+SSD
• 当月交易：快速查询，SSD存储
• 历史交易：报表查询，磁盘存储  
• 长期记录：审计查询，归档存储
```

**🎯 实施建议**

> 💡 **最佳实践**
> 
> 1. **渐进式实施**：从最简单的时间分层开始，逐步完善
> 2. **监控驱动**：基于实际使用数据制定策略，而非理论假设
> 3. **自动化优先**：人工管理容易出错，自动化更可靠
> 4. **备份保险**：重要索引删除前要备份定义
> 5. **成本核算**：定期评估策略效果，调整优化方向

**🚀 发展趋势**

```markdown
🔮 **技术发展方向**
• AI驱动的智能索引管理
• 更细粒度的自动化分层
• 云原生的弹性存储架构
• 更高效的压缩和编码技术
```

**核心记忆**：
- 数据有生命周期，索引策略要相应调整
- 热数据全索引，冷数据精简索引，归档数据最小索引
- 分层存储降成本，自动化管理提效率
- 监控评估是基础，持续优化是关键
- 平衡性能与成本，找到最适合的策略