---
title: 11、优化器成本模型分析
---
## 📚 目录

1. [成本模型基本概念](#1-成本模型基本概念)
2. [成本计算公式与原理](#2-成本计算公式与原理)
3. [统计信息依赖与管理](#3-统计信息依赖与管理)
4. [选择性评估与基数估算](#4-选择性评估与基数估算)
5. [Cost Model配置调优](#5-cost-model配置调优)
6. [优化器跟踪与诊断](#6-优化器跟踪与诊断)
7. [统计信息更新策略](#7-统计信息更新策略)
8. [核心要点总结](#8-核心要点总结)

---

## 1. 🎯 成本模型基本概念


### 1.1 什么是成本模型


**通俗理解**：成本模型就像超市购物时的"价格计算器"

```
想象你去超市买东西：
🛒 商品A：5块钱，需要走10步
🛒 商品B：3块钱，需要走50步  
🛒 商品C：4块钱，需要走20步

你会怎么选择？要考虑：价格 + 时间 + 体力
数据库优化器也是一样！
```

**🔸 成本模型的本质**
```
定义：数据库优化器用来估算不同执行计划"代价"的数学模型
目的：帮助数据库选择最"便宜"的查询执行方案
原理：把各种资源消耗（CPU、IO、内存）转换成统一的"成本值"
```

> 💡 **关键理解**：成本模型不是绝对准确的，而是帮助数据库做"相对比较"的工具

### 1.2 成本模型的组成要素


**🔧 核心组成部分**
```
┌─────────────────┐
│   查询执行计划   │
├─────────────────┤
│ CPU成本 ←→ IO成本 │  ← 两大主要成本
├─────────────────┤
│   内存成本      │  ← 辅助成本
├─────────────────┤
│   网络成本      │  ← 分布式环境
└─────────────────┘
```

**成本类型详解**：

**CPU成本**：
- **含义**：处理数据时消耗的CPU时间
- **场景**：排序、分组、计算、条件判断
- **举例**：`SELECT * FROM users WHERE age > 25` 中的条件判断

**IO成本**：
- **含义**：从磁盘读取数据的成本
- **场景**：表扫描、索引读取、临时文件操作
- **举例**：全表扫描vs索引查找的磁盘访问次数

**内存成本**：
- **含义**：使用内存缓存的成本
- **场景**：数据缓存、排序缓冲区、连接缓存
- **举例**：数据已在内存中，IO成本大幅降低

### 1.3 成本模型的工作流程


```
查询请求
    ↓
解析SQL语句
    ↓
生成多个候选执行计划
    ↓
┌─── 计划A ────┐  ┌─── 计划B ────┐  ┌─── 计划C ────┐
│成本：100单位 │  │成本：80单位  │  │成本：120单位 │
└─────────────┘  └─────────────┘  └─────────────┘
         ↓              ↓              ↓
         └──────── 选择最小成本 ──────────┘
                        ↓
                  执行计划B（80单位）
```

---

## 2. 📊 成本计算公式与原理


### 2.1 基础成本计算公式


**🔸 总成本计算公式**
```
总成本 = CPU成本 + IO成本 + 网络成本
```

**详细分解公式**：
```sql
-- 表扫描成本计算
扫描成本 = (页数 × PAGE_COST) + (行数 × CPU_TUPLE_COST)

-- 索引扫描成本计算  
索引成本 = (索引页数 × INDEX_PAGE_COST) + 
          (返回行数 × CPU_INDEX_TUPLE_COST) +
          (随机页访问数 × RANDOM_PAGE_COST)

-- 排序成本计算
排序成本 = (输入行数 × CPU_OPERATOR_COST × log(输入行数)) +
          (临时存储页数 × TEMP_PAGE_COST)
```

### 2.2 成本常数详解


**🔧 MySQL成本常数（默认值）**
```sql
-- 查看当前成本常数
SELECT * FROM mysql.server_cost;
SELECT * FROM mysql.engine_cost;

常用成本常数：
- row_evaluate_cost: 0.2    # 评估一行的CPU成本
- key_compare_cost: 0.1     # 键值比较的CPU成本  
- memory_temptable_create_cost: 2.0  # 内存临时表创建成本
- disk_temptable_create_cost: 40.0   # 磁盘临时表创建成本
- io_block_read_cost: 1.0   # 读取一个数据块的IO成本
```

**📈 成本计算实例**
```sql
-- 假设查询：SELECT * FROM users WHERE age > 25;
-- 表信息：100万行，1000页，age字段有索引

方案A：全表扫描
扫描成本 = 1000页 × 1.0 + 1000000行 × 0.2 = 201000单位

方案B：索引扫描（假设返回10万行）
索引成本 = 100索引页 × 1.0 + 100000行 × 0.2 + 500随机访问 × 4.0 
        = 100 + 20000 + 2000 = 22100单位

结果：优化器选择方案B（索引扫描）
```

### 2.3 连接操作成本计算


**🔗 不同连接方式的成本模型**

```sql
-- 嵌套循环连接（Nested Loop Join）
NL成本 = 外表扫描成本 + (外表行数 × 内表访问成本)

-- 哈希连接（Hash Join）  
Hash成本 = 构建表扫描成本 + 哈希表构建成本 + 探测表扫描成本

-- 排序合并连接（Sort Merge Join）
SM成本 = 左表排序成本 + 右表排序成本 + 合并扫描成本
```

**实际例子**：
```sql
-- 查询两个表连接
SELECT u.name, o.amount 
FROM users u JOIN orders o ON u.id = o.user_id 
WHERE u.age > 30;

-- users表：10000行，orders表：50000行
-- 满足条件的users：2000行

方案对比：
┌─────────────────┬─────────────┬─────────────────┐
│   连接方式      │    成本     │    适用场景     │
├─────────────────┼─────────────┼─────────────────┤
│ Nested Loop     │   8000      │ 小表驱动大表    │
│ Hash Join       │   6500      │ 内存充足时      │
│ Sort Merge      │   7200      │ 数据已排序时    │
└─────────────────┴─────────────┴─────────────────┘
```

---

## 3. 📋 统计信息依赖与管理


### 3.1 统计信息的重要性


**🎯 为什么统计信息如此关键？**

> 💡 **形象比喻**：统计信息就像地图上的距离标注，没有准确距离，GPS就无法规划最优路线

```
场景对比：

❌ 缺少统计信息：
优化器：这个表有多少行？不知道...
优化器：这个条件能过滤掉多少数据？猜一下...
结果：可能选择全表扫描而不是索引

✅ 有准确统计信息：
优化器：表有100万行，WHERE age>30能过滤到2万行
优化器：使用age索引，成本最低
结果：选择最优执行计划
```

### 3.2 统计信息的类型


**📊 表级统计信息**
```sql
-- MySQL查看表统计信息
SHOW TABLE STATUS LIKE 'users';

重要字段：
- Rows：表的行数估算
- Avg_row_length：平均行长度
- Data_length：数据文件大小
- Index_length：索引文件大小
- Update_time：最后更新时间
```

**🔍 列级统计信息**
```sql
-- 查看列的统计信息
SELECT * FROM information_schema.COLUMN_STATISTICS;

包含信息：
- COLUMN_NAME：列名
- HISTOGRAM：直方图信息（数据分布）
- NULL_VALUES：空值比例
- DISTINCT_VALUES：不重复值个数
```

**索引统计信息**
```sql
-- 查看索引统计
SHOW INDEX FROM users;

关键指标：
- Cardinality：索引基数（不重复值数量）
- Sub_part：部分索引长度
- Packed：索引是否压缩
- Null：是否包含NULL值
```

### 3.3 统计信息收集机制


**🔄 自动收集vs手动收集**

```sql
-- MySQL自动统计信息更新配置
SHOW VARIABLES LIKE 'innodb_stats%';

重要参数：
- innodb_stats_auto_recalc: ON    # 自动重算统计信息
- innodb_stats_persistent: ON     # 持久化统计信息
- innodb_stats_sample_pages: 20   # 采样页数
```

**手动更新统计信息**：
```sql
-- 分析表，更新统计信息
ANALYZE TABLE users;

-- 查看分析结果
SHOW WARNINGS;

-- 更新索引统计信息
ALTER TABLE users STATS_SAMPLE_PAGES = 50;
ANALYZE TABLE users;
```

### 3.4 统计信息失效的影响


**⚠️ 统计信息过期的后果**

```sql
-- 模拟场景：用户表快速增长
初始状态：users表 10万行，age索引选择性高
统计信息：Cardinality = 8000 (选择性 = 8000/100000 = 8%)

-- 3个月后：用户增长到500万行，但统计信息未更新
实际情况：500万行，age分布更均匀，选择性变低
过期统计：仍然认为只有10万行，选择性高

-- 查询：SELECT * FROM users WHERE age = 25;
优化器判断：基于旧统计信息，认为返回 100000/8000 = 12.5行
实际情况：可能返回 5000000/20 = 25万行

结果：选择了错误的执行计划！
```

**诊断统计信息问题**：
```sql
-- 检查表的最后分析时间
SELECT TABLE_NAME, UPDATE_TIME 
FROM information_schema.TABLES 
WHERE TABLE_SCHEMA = 'your_database';

-- 检查统计信息是否过期
SELECT TABLE_NAME, 
       TABLE_ROWS,
       (DATA_LENGTH + INDEX_LENGTH) / 1024 / 1024 as SIZE_MB,
       UPDATE_TIME,
       DATEDIFF(NOW(), UPDATE_TIME) as DAYS_OLD
FROM information_schema.TABLES 
WHERE TABLE_SCHEMA = 'your_database'
AND DATEDIFF(NOW(), UPDATE_TIME) > 7;  -- 超过7天未更新
```

---

## 4. 🎯 选择性评估与基数估算


### 4.1 选择性的概念


**🔸 什么是选择性（Selectivity）？**

> 💡 **通俗解释**：选择性就是"筛选效果"，告诉我们一个条件能过滤掉多少数据

```
形象比喻：筛沙子

高选择性条件：细筛网，过滤掉99%的沙子，留下1%
WHERE user_id = 12345  (唯一值，选择性 ≈ 1/总行数)

低选择性条件：粗筛网，只过滤掉10%的沙子，留下90%  
WHERE gender = 'male'  (只有两个值，选择性 ≈ 0.5)
```

**📊 选择性计算公式**
```sql
选择性 = 满足条件的行数 / 表的总行数

例如：
- 表总行数：100万
- WHERE age > 30 满足条件：60万行
- 选择性 = 60万 / 100万 = 0.6 = 60%

选择性越低，条件越"挑剔"，过滤效果越好！
```

### 4.2 基数估算原理


**🔢 基数（Cardinality）的含义**
```
基数 = 某列中不重复值的数量

示例理解：
用户表100万行：
- user_id列：100万个不重复值，基数=1000000（高基数）
- gender列：2个不重复值（男/女），基数=2（低基数）  
- age列：100个不重复值（0-99岁），基数=100（中基数）
- city列：300个不重复值，基数=300（中基数）

基数越高，选择性越好，越适合建索引！
```

**估算方法**：
```sql
-- 精确计算基数（性能开销大）
SELECT COUNT(DISTINCT column_name) FROM table_name;

-- 数据库内部采用采样估算
-- HyperLogLog算法：用很小内存估算大数据集的基数
-- 误差范围：通常在2%以内

-- MySQL查看估算的基数
SHOW INDEX FROM users;
-- Cardinality列显示估算值
```

### 4.3 复合条件的选择性计算


**🔗 多个条件组合的估算**

```sql
-- 单个条件选择性
WHERE age > 30        -- 选择性：0.6
WHERE city = 'Beijing' -- 选择性：0.1  
WHERE gender = 'male'  -- 选择性：0.5

-- 复合条件选择性估算
WHERE age > 30 AND city = 'Beijing'
估算选择性 = 0.6 × 0.1 = 0.06 = 6%

-- 但这个假设各条件独立，实际可能不准确！
-- 实际：北京可能年轻人更多，真实选择性可能是4%
```

**⚠️ 条件相关性问题**
```sql
-- 问题场景：条件之间存在相关性
SELECT * FROM orders 
WHERE order_date > '2023-01-01' 
AND status = 'completed';

假设独立：选择性 = 0.8 × 0.7 = 0.56
实际情况：新订单完成率更高，真实选择性可能是0.65

-- 数据库解决方案：
1. 多列统计信息收集
2. 直方图记录数据分布
3. 机器学习辅助估算
```

### 4.4 直方图在选择性评估中的作用


**📊 什么是直方图？**

```
直方图：记录数据分布的"条形图"

年龄分布示例：
   |
30k|█████
   |     █████
20k|     █████ ████
   |     █████ ████ ███
10k|     █████ ████ ███ ██
   |_____________________|
    18-25 26-35 36-45 46-55  (年龄段)

从直方图可以看出：
- 26-35岁用户最多（30k人）
- 46-55岁用户最少（10k人）
- WHERE age BETWEEN 26 AND 35 选择性更低
```

**MySQL直方图使用**：
```sql
-- 创建直方图统计信息
ANALYZE TABLE users UPDATE HISTOGRAM ON age, city WITH 100 BUCKETS;

-- 查看直方图信息
SELECT * FROM information_schema.COLUMN_STATISTICS 
WHERE TABLE_NAME = 'users' AND COLUMN_NAME = 'age';

-- 删除直方图
ANALYZE TABLE users DROP HISTOGRAM ON age;
```

---

## 5. 🔥 Cost Model配置调优


### 5.1 成本模型参数配置


**🔧 MySQL成本模型配置表**

```sql
-- 查看服务器级成本配置
SELECT * FROM mysql.server_cost;
┌─────────────────────────────────┬──────────────┐
│           cost_name             │ cost_value   │
├─────────────────────────────────┼──────────────┤
│ row_evaluate_cost               │ 0.2          │
│ key_compare_cost                │ 0.1          │ 
│ memory_temptable_create_cost    │ 2.0          │
│ disk_temptable_create_cost      │ 40.0         │
│ memory_temptable_row_cost       │ 0.2          │
│ disk_temptable_row_cost         │ 1.0          │
└─────────────────────────────────┴──────────────┘

-- 查看存储引擎级成本配置  
SELECT * FROM mysql.engine_cost;
┌─────────────────────┬──────────────┬──────────────┐
│    cost_name        │ cost_value   │ engine_name  │
├─────────────────────┼──────────────┼──────────────┤
│ io_block_read_cost  │ 1.0          │ default      │
│ memory_block_read_cost │ 0.25      │ default      │  
└─────────────────────┴──────────────┴──────────────┘
```

### 5.2 关键参数调优策略


**📈 CPU密集型vs IO密集型调优**

```sql
-- 场景1：SSD存储，IO很快，CPU相对昂贵
-- 降低IO成本，提高CPU成本，鼓励用IO换CPU
UPDATE mysql.engine_cost 
SET cost_value = 0.5    -- 降低IO成本  
WHERE cost_name = 'io_block_read_cost';

UPDATE mysql.server_cost 
SET cost_value = 0.3    -- 提高CPU成本
WHERE cost_name = 'row_evaluate_cost';

-- 场景2：传统机械硬盘，IO较慢
-- 提高IO成本，降低CPU成本，鼓励用CPU换IO
UPDATE mysql.engine_cost 
SET cost_value = 2.0    -- 提高IO成本
WHERE cost_name = 'io_block_read_cost';

UPDATE mysql.server_cost 
SET cost_value = 0.1    -- 降低CPU成本  
WHERE cost_name = 'row_evaluate_cost';

-- 使配置生效
FLUSH OPTIMIZER_COSTS;
```

**🎯 内存配置调优**
```sql
-- 场景：内存充足，希望多使用内存临时表
UPDATE mysql.server_cost 
SET cost_value = 1.0    -- 降低内存临时表成本
WHERE cost_name = 'memory_temptable_create_cost';

UPDATE mysql.server_cost 
SET cost_value = 100.0  -- 大幅提高磁盘临时表成本  
WHERE cost_name = 'disk_temptable_create_cost';

-- 场景：内存紧张，限制内存临时表使用
UPDATE mysql.server_cost 
SET cost_value = 10.0   -- 提高内存临时表成本
WHERE cost_name = 'memory_temptable_create_cost';
```

### 5.3 针对特定硬件的调优


**💾 不同存储介质的成本配置**

```sql
-- NVMe SSD配置（超快IO）
UPDATE mysql.engine_cost 
SET cost_value = 0.1    -- 极低IO成本
WHERE cost_name = 'io_block_read_cost';

-- SATA SSD配置（快速IO）
UPDATE mysql.engine_cost 
SET cost_value = 0.5    -- 较低IO成本
WHERE cost_name = 'io_block_read_cost';

-- 机械硬盘配置（慢IO）
UPDATE mysql.engine_cost 
SET cost_value = 4.0    -- 较高IO成本
WHERE cost_name = 'io_block_read_cost';

-- 网络存储配置（更慢IO）
UPDATE mysql.engine_cost 
SET cost_value = 8.0    -- 高IO成本
WHERE cost_name = 'io_block_read_cost';
```

### 5.4 调优效果验证


**📊 调优前后对比测试**

```sql
-- 创建测试查询
SET @test_sql = 'SELECT u.name, COUNT(o.id) 
                 FROM users u 
                 LEFT JOIN orders o ON u.id = o.user_id 
                 WHERE u.created_at > "2023-01-01" 
                 GROUP BY u.id';

-- 查看调优前的执行计划
EXPLAIN FORMAT=JSON @test_sql;

-- 应用成本模型调优
UPDATE mysql.server_cost SET cost_value = 0.1 WHERE cost_name = 'row_evaluate_cost';
UPDATE mysql.engine_cost SET cost_value = 0.3 WHERE cost_name = 'io_block_read_cost';
FLUSH OPTIMIZER_COSTS;

-- 查看调优后的执行计划  
EXPLAIN FORMAT=JSON @test_sql;

-- 对比关键指标：
-- 1. 是否改变了连接方式（nested loop vs hash join）
-- 2. 是否改变了访问路径（全表扫描 vs 索引扫描）
-- 3. 总成本是否更合理
```

**实际性能验证**：
```sql
-- 执行性能测试
SET profiling = 1;
SELECT SQL_NO_CACHE ... -- 执行测试查询
SHOW PROFILE FOR QUERY 1;

-- 关键指标对比：
-- - Query_time: 查询总时间
-- - Rows_examined: 检查的行数  
-- - Rows_sent: 返回的行数
-- - Created_tmp_tables: 临时表创建次数
```

---

## 6. 🔍 优化器跟踪与诊断


### 6.1 优化器跟踪功能


**🕵️ 什么是优化器跟踪？**

> 💡 **形象比喻**：优化器跟踪就像"破案过程录像"，记录优化器如何一步步选择执行计划

```sql
-- 开启优化器跟踪
SET optimizer_trace="enabled=on";

-- 执行目标查询
SELECT u.name, o.amount 
FROM users u 
JOIN orders o ON u.id = o.user_id 
WHERE u.age > 30 AND o.status = 'completed';

-- 查看跟踪结果
SELECT * FROM information_schema.optimizer_trace\G
```

### 6.2 跟踪信息解读


**📋 跟踪信息的主要部分**

```json
{
  "steps": [
    {
      "join_preparation": {
        "select_id": 1,
        "steps": [
          {
            "transformations": {
              "transformation": "equality_propagation",
              "resulting_condition": "((u.age > 30) and (o.status = 'completed'))"
            }
          }
        ]
      }
    },
    {
      "join_optimization": {
        "select_id": 1,
        "steps": [
          {
            "table_dependencies": [
              {
                "table": "users u",
                "row_may_be_null": false,
                "map_bit": 0,
                "depends_on_map_bits": []
              }
            ]
          },
          {
            "rows_estimation": [
              {
                "table": "users",
                "range_analysis": {
                  "table_scan": {
                    "rows": 1000000,
                    "cost": 201000
                  },
                  "potential_range_indices": [
                    {
                      "index": "idx_age",
                      "usable": true,
                      "key_parts": ["age"]
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    }
  ]
}
```

**🔍 关键信息解读**

```
1. transformations（转换阶段）：
   - 条件重写和优化
   - 常量折叠
   - 谓词下推

2. table_dependencies（表依赖分析）：
   - 确定表的连接顺序
   - 识别外连接的空值处理

3. rows_estimation（行数估算）：
   - 各种访问路径的成本比较
   - range_analysis：范围查询分析
   - table_scan：全表扫描成本
   - potential_range_indices：可能的索引

4. considered_execution_plans（执行计划对比）：
   - 不同计划的成本对比
   - 最终选择的原因
```

### 6.3 常见优化器决策分析


**🎯 全表扫描vs索引扫描的决策**

```sql
-- 查询示例
SELECT * FROM users WHERE age > 25;

-- 跟踪信息显示：
{
  "range_analysis": {
    "table_scan": {
      "rows": 1000000,      -- 全表扫描：100万行
      "cost": 201000        -- 成本：20.1万
    },
    "range_scan_alternatives": [
      {
        "index": "idx_age",
        "ranges": ["25 < age"],
        "index_dives_for_eq_ranges": true,
        "rowid_ordered": false,
        "using_mrr": false,
        "index_only": false,
        "rows": 750000,       -- 索引扫描：75万行
        "cost": 900150,       -- 成本：90万（包含回表）
        "chosen": false       -- 未选择
      }
    ]
  }
}

-- 分析：为什么选择全表扫描？
-- age > 25 选择性太差（75%的数据），索引回表成本太高
```

**🔗 连接顺序的决策分析**
```sql
-- 三表连接查询
SELECT u.name, o.amount, p.name as product_name
FROM users u
JOIN orders o ON u.id = o.user_id  
JOIN products p ON o.product_id = p.id
WHERE u.age > 30 AND o.status = 'completed';

-- 跟踪信息显示可能的连接顺序：
{
  "considered_execution_plans": [
    {
      "plan_prefix": ["users", "orders", "products"],
      "table": "products",
      "best_access_path": {
        "considered_access_paths": [
          {
            "access_type": "eq_ref",
            "index": "PRIMARY", 
            "rows": 1,
            "cost": 0.35,
            "chosen": true
          }
        ]
      },
      "cost_for_plan": 15234.5,
      "rows_for_plan": 50000,
      "chosen": true    -- 选择这个连接顺序
    }
  ]
}
```

### 6.4 跟踪信息的实用技巧


**⚡ 快速定位优化问题**

```sql
-- 1. 检查是否使用了预期的索引
-- 在跟踪信息中查找：
"chosen_range_access_summary": {
  "range_access_plan": {
    "type": "range_scan",
    "index": "idx_age_status",  -- 确认使用了复合索引
    "rows": 1000,
    "ranges": ["30 < age AND status = 'active'"]
  }
}

-- 2. 检查连接类型是否最优
"best_access_path": {
  "access_type": "eq_ref",  -- 最优：每个连接只返回一行
  "index": "PRIMARY", 
  "rows": 1,
  "cost": 0.35
}
-- 其他类型：ref, range, index, ALL（性能依次降低）

-- 3. 检查是否创建了临时表
"temporary_table": {
  "table": "intermediate_tmp_table",
  "column_count": 3,
  "row_count": 50000,
  "row_size": 128  -- 临时表大小，影响内存使用
}
```

**🛠️ 优化器跟踪的最佳实践**
```sql
-- 只在需要时开启，避免性能影响
SET optimizer_trace="enabled=on,one_line=off";

-- 执行具体查询
SELECT ...;

-- 查看跟踪结果
SELECT QUERY, TRACE, MISSING_BYTES_BEYOND_MAX_MEM_SIZE 
FROM information_schema.optimizer_trace;

-- 及时关闭跟踪
SET optimizer_trace="enabled=off";

-- 增加跟踪内存（如果输出被截断）
SET optimizer_trace_max_mem_size = 1048576;  -- 1MB
```

---

## 7. 📅 统计信息更新策略


### 7.1 自动更新策略配置


**🔄 InnoDB统计信息自动更新机制**

```sql
-- 查看当前配置
SHOW VARIABLES LIKE 'innodb_stats%';
┌─────────────────────────────────┬─────────┐
│         Variable_name           │ Value   │
├─────────────────────────────────┼─────────┤
│ innodb_stats_auto_recalc        │ ON      │ -- 自动重新计算
│ innodb_stats_persistent         │ ON      │ -- 持久化存储
│ innodb_stats_sample_pages       │ 20      │ -- 采样页数
│ innodb_stats_transient_sample_pages │ 8  │ -- 临时采样页数
│ innodb_stats_on_metadata        │ OFF     │ -- 元数据访问时更新
└─────────────────────────────────┴─────────┘
```

**触发自动更新的条件**：
```sql
-- 统计信息自动更新触发条件
当满足以下条件时，会自动更新统计信息：

1. 表数据变化达到阈值：
   - 变化行数 > 表总行数的10% + 2000行
   - 或者表是新建的且行数 > 0

2. 示例计算：
   - 1万行表：变化超过 10000×0.1+2000 = 3000行 触发更新
   - 100万行表：变化超过 1000000×0.1+2000 = 102000行 触发更新
   - 10万行表：变化超过 10000×0.1+2000 = 12000行 触发更新
```

### 7.2 手动更新策略


**🔧 定期维护脚本**

```sql
-- 1. 识别需要更新统计信息的表
-- 查找数据变化较大的表
SELECT 
    TABLE_SCHEMA,
    TABLE_NAME,
    TABLE_ROWS,
    (DATA_LENGTH + INDEX_LENGTH) / 1024 / 1024 as SIZE_MB,
    UPDATE_TIME,
    DATEDIFF(NOW(), UPDATE_TIME) as DAYS_OLD
FROM information_schema.TABLES 
WHERE TABLE_SCHEMA NOT IN ('mysql', 'information_schema', 'performance_schema', 'sys')
AND DATEDIFF(NOW(), UPDATE_TIME) > 3  -- 超过3天未更新
ORDER BY TABLE_ROWS DESC;

-- 2. 批量更新统计信息
-- 对重要的大表进行分析
ANALYZE TABLE users, orders, products, user_profiles;

-- 3. 验证更新效果
-- 检查关键索引的基数是否合理
SHOW INDEX FROM users WHERE Key_name = 'idx_age_status';
```

**🕐 基于业务周期的更新策略**

```sql
-- 每日维护任务（适合OLTP系统）
-- 在业务低峰期（如凌晨2点）执行

DELIMITER //
CREATE EVENT daily_stats_maintenance
ON SCHEDULE EVERY 1 DAY 
STARTS '2025-09-02 02:00:00'
DO
BEGIN
    -- 更新活跃表的统计信息
    ANALYZE TABLE users, orders, order_items;
    
    -- 记录维护日志
    INSERT INTO maintenance_log(operation, table_names, created_at)
    VALUES('ANALYZE_TABLES', 'users,orders,order_items', NOW());
END //
DELIMITER ;

-- 每周深度维护（适合数据仓库）
CREATE EVENT weekly_full_stats_maintenance
ON SCHEDULE EVERY 1 WEEK
STARTS '2025-09-02 01:00:00'
DO
BEGIN
    -- 更新所有用户表的统计信息
    DECLARE done INT DEFAULT FALSE;
    DECLARE table_name VARCHAR(64);
    DECLARE cur CURSOR FOR 
        SELECT TABLE_NAME FROM information_schema.TABLES 
        WHERE TABLE_SCHEMA = DATABASE()
        AND TABLE_TYPE = 'BASE TABLE';
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    OPEN cur;
    read_loop: LOOP
        FETCH cur INTO table_name;
        IF done THEN
            LEAVE read_loop;
        END IF;
        
        SET @sql = CONCAT('ANALYZE TABLE ', table_name);
        PREPARE stmt FROM @sql;
        EXECUTE stmt;
        DEALLOCATE PREPARE stmt;
    END LOOP;
    CLOSE cur;
END //
```

### 7.3 监控统计信息质量


**📊 统计信息准确性检查**

```sql
-- 创建统计信息质量监控视图
CREATE VIEW stats_quality_check AS
SELECT 
    t.TABLE_SCHEMA,
    t.TABLE_NAME,
    t.TABLE_ROWS as ESTIMATED_ROWS,
    
    -- 实际行数（采样估算，避免全表扫描）
    (SELECT table_rows 
     FROM information_schema.TABLES 
     WHERE table_schema = t.TABLE_SCHEMA 
     AND table_name = t.TABLE_NAME) as CURRENT_ESTIMATED_ROWS,
     
    -- 统计信息年龄
    DATEDIFF(NOW(), t.UPDATE_TIME) as STATS_AGE_DAYS,
    
    -- 表大小变化
    ROUND((t.DATA_LENGTH + t.INDEX_LENGTH) / 1024 / 1024, 2) as SIZE_MB,
    
    -- 质量评分（0-100）
    CASE 
        WHEN DATEDIFF(NOW(), t.UPDATE_TIME) > 30 THEN 'POOR'
        WHEN DATEDIFF(NOW(), t.UPDATE_TIME) > 7 THEN 'FAIR' 
        WHEN DATEDIFF(NOW(), t.UPDATE_TIME) > 3 THEN 'GOOD'
        ELSE 'EXCELLENT'
    END as QUALITY_SCORE
    
FROM information_schema.TABLES t
WHERE t.TABLE_SCHEMA NOT IN ('mysql', 'information_schema', 'performance_schema', 'sys')
AND t.TABLE_TYPE = 'BASE TABLE';

-- 查询统计信息质量报告
SELECT * FROM stats_quality_check 
WHERE QUALITY_SCORE IN ('POOR', 'FAIR')
ORDER BY SIZE_MB DESC;
```

**⚠️ 统计信息异常告警**

```sql
-- 检查索引基数异常的情况
SELECT 
    TABLE_SCHEMA,
    TABLE_NAME,
    INDEX_NAME,
    CARDINALITY,
    -- 基数为0通常表示统计信息有问题
    CASE 
        WHEN CARDINALITY = 0 THEN 'WARNING: Zero cardinality'
        WHEN CARDINALITY = 1 THEN 'INFO: Very low cardinality'
        ELSE 'OK'
    END as STATUS
FROM information_schema.STATISTICS 
WHERE TABLE_SCHEMA NOT IN ('mysql', 'information_schema', 'performance_schema', 'sys')
AND (CARDINALITY = 0 OR CARDINALITY = 1)
ORDER BY TABLE_NAME, INDEX_NAME;

-- 检查表行数估算异常
SELECT 
    TABLE_NAME,
    TABLE_ROWS,
    ROUND((DATA_LENGTH + INDEX_LENGTH) / 1024 / 1024, 2) as SIZE_MB,
    -- 行数为0但表有数据大小，可能统计信息有问题
    CASE 
        WHEN TABLE_ROWS = 0 AND (DATA_LENGTH + INDEX_LENGTH) > 16384 
        THEN 'WARNING: Zero rows but table has data'
        ELSE 'OK'
    END as STATUS
FROM information_schema.TABLES
WHERE TABLE_SCHEMA = DATABASE()
AND TABLE_TYPE = 'BASE TABLE';
```

### 7.4 特殊场景的统计信息策略


**🚀 高并发写入场景**

```sql
-- 对于高频写入的表，设置更精确的采样
ALTER TABLE high_volume_table STATS_SAMPLE_PAGES = 100;

-- 关闭自动统计信息更新，改为定时批量更新
ALTER TABLE high_volume_table STATS_AUTO_RECALC = 0;

-- 在业务低峰期手动更新
-- 业务代码中的定时任务
-- 每小时检查一次，如果写入量大则更新统计信息
```

**📊 数据仓库场景**
```sql
-- ETL完成后立即更新统计信息
-- 在ETL脚本末尾添加：
ANALYZE TABLE fact_sales, dim_product, dim_customer;

-- 为大表创建直方图统计信息
ANALYZE TABLE fact_sales 
UPDATE HISTOGRAM ON order_date, customer_segment, product_category 
WITH 50 BUCKETS;

-- 验证直方图创建成功
SELECT SCHEMA_NAME, TABLE_NAME, COLUMN_NAME, 
       JSON_EXTRACT(HISTOGRAM, '$.buckets[0]') as FIRST_BUCKET
FROM information_schema.COLUMN_STATISTICS;
```

---

## 8. 📋 核心要点总结


### 8.1 必须掌握的核心概念


```
🔸 成本模型本质：数据库优化器的"价格计算器"，帮助选择最优执行计划
🔸 统计信息重要性：成本计算的基础数据，准确性直接影响计划选择
🔸 选择性概念：条件的"筛选效果"，决定是否使用索引的关键指标  
🔸 基数估算：列的不重复值数量，影响索引选择和连接顺序
🔸 成本常数配置：根据硬件特性调整，优化成本模型准确性
```

### 8.2 关键理解要点


**🔹 成本模型的局限性**
```
理解要点：
- 成本模型是"估算"不是"精确计算"
- 基于统计信息，统计信息过期会影响准确性
- 无法完美预测实际执行情况（缓存、并发等因素）
- 需要结合实际性能测试验证

实际意义：
- 不要盲目信任执行计划的成本估算
- 定期更新统计信息保证模型准确性
- 根据实际硬件环境调整成本参数
```

**🔹 统计信息维护策略**
```
核心原则：
- 自动更新 + 手动维护相结合
- 重要表优先，大表重点关注
- 业务低峰期执行维护任务
- 监控统计信息质量，及时发现问题

实践技巧：
- 设置合理的采样页数平衡准确性和性能
- 为重要查询条件创建直方图统计信息
- 建立统计信息质量监控和告警机制
```

**🔹 选择性评估的实用价值**
```
应用场景：
- 索引设计：高选择性列适合建索引
- 复合索引：选择性高的列放在前面
- 查询优化：理解优化器为什么选择某个计划
- 性能诊断：分析为什么查询性能差

判断技巧：
- 选择性 < 0.1：通常适合建索引
- 选择性 > 0.5：索引效果有限
- 复合条件选择性：注意条件间的相关性
```

### 8.3 实际应用指导


**🎯 成本模型调优步骤**
```
第1步：了解硬件环境
- SSD vs 机械硬盘：调整IO成本
- 内存大小：调整临时表成本  
- CPU性能：调整CPU相关成本

第2步：收集性能基线
- 记录关键查询的当前性能
- 分析执行计划和成本估算
- 识别明显的成本模型偏差

第3步：渐进式调整
- 一次只调整一个参数
- 观察执行计划变化
- 验证实际性能改善

第4步：持续监控优化
- 建立执行计划监控
- 定期review成本参数
- 根据业务变化调整策略
```

**🔧 问题诊断技巧**
```
查询性能差时的检查清单：

□ 统计信息是否过期？
  - 检查UPDATE_TIME
  - 对比估算行数和实际行数

□ 选择性估算是否准确？  
  - 查看WHERE条件的选择性
  - 检查是否需要直方图统计

□ 成本模型是否合理？
  - 开启优化器跟踪分析决策过程
  - 对比不同执行计划的成本

□ 索引是否被正确使用？
  - 检查访问路径选择
  - 分析索引覆盖情况
```

**🚀 最佳实践建议**
```
日常维护：
- 建立统计信息更新计划（日/周/月）
- 监控重要查询的执行计划变化
- 定期review成本模型配置

性能优化：
- 先保证统计信息准确，再调整成本模型
- 重点关注高频查询和慢查询
- 结合业务特点制定优化策略

故障处理：
- 性能突然下降，首先检查统计信息
- 执行计划改变，分析成本估算变化  
- 建立回滚机制，避免调优带来新问题
```

**核心记忆**：
- 成本模型是优化器大脑，统计信息是其眼睛
- 准确的统计信息胜过复杂的调优技巧
- 理解选择性评估，掌握索引设计精髓
- 成本模型调优需谨慎，渐进式调整最安全
- 监控和维护是长期性能稳定的关键