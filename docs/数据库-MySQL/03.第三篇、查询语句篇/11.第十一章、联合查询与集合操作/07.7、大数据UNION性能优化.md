---
title: 7、大数据UNION性能优化
---
## 📚 目录

1. [大数据UNION基础概念](#1-大数据UNION基础概念)
2. [UNION内存管理机制](#2-UNION内存管理机制)
3. [分批UNION处理策略](#3-分批UNION处理策略)
4. [UNION并行处理技术](#4-UNION并行处理技术)
5. [磁盘溢出处理方案](#5-磁盘溢出处理方案)
6. [大结果集优化技巧](#6-大结果集优化技巧)
7. [核心要点总结](#7-核心要点总结)

---

## 1. 📊 大数据UNION基础概念


### 1.1 什么是大数据场景下的UNION


**🔸 大数据UNION的定义**
```
大数据UNION：在处理百万、千万甚至亿级数据时使用UNION操作
核心挑战：内存限制、IO性能、处理时间
实际场景：日志合并、历史数据汇总、多表数据统一查询
```

**💡 为什么大数据UNION这么复杂？**

想象一下，你要把10个装满书的大仓库里的所有书籍合并到一个新仓库：
```
传统做法（小数据）：
直接搬运 → 一次性处理 → 快速完成

大数据场景：
仓库太大 → 内存装不下 → 需要分批处理 → 避免系统崩溃
```

**🎯 大数据UNION的核心挑战**

| 挑战类型 | 具体问题 | 影响 | 解决思路 |
|---------|----------|------|----------|
| **内存压力** | 数据量超过可用内存 | 系统OOM崩溃 | 分批处理、流式处理 |
| **IO瓶颈** | 大量磁盘读写操作 | 查询极慢 | 优化读取策略、并行IO |
| **去重复杂** | UNION需要去重处理 | CPU和内存双重压力 | 索引优化、分区去重 |
| **网络传输** | 结果集传输耗时 | 客户端等待时间长 | 流式传输、压缩 |

### 1.2 大数据UNION的典型应用场景


**📈 日志数据合并场景**
```sql
-- 合并一年的访问日志（每月千万级记录）
SELECT user_id, access_time, page_url FROM access_log_202401
UNION ALL
SELECT user_id, access_time, page_url FROM access_log_202402
UNION ALL
-- ... 12个月的数据
SELECT user_id, access_time, page_url FROM access_log_202412;

-- 挑战：可能涉及数亿条记录
```

**🏢 多系统数据整合场景**
```sql
-- 整合多个分公司的销售数据
SELECT customer_id, order_date, amount FROM sales_beijing    -- 500万记录
UNION ALL
SELECT customer_id, order_date, amount FROM sales_shanghai  -- 800万记录  
UNION ALL
SELECT customer_id, order_date, amount FROM sales_guangzhou -- 600万记录;

-- 挑战：近2000万记录的合并和去重
```

### 1.3 大数据UNION的性能影响因素


**⚡ 影响性能的关键因素**

```
数据量级影响分析：
┌─────────────┬─────────────┬─────────────┬─────────────┐
│   数据量    │   内存需求   │   处理时间   │   优化策略   │
├─────────────┼─────────────┼─────────────┼─────────────┤
│  < 10万行   │    < 100MB   │    < 1秒    │   直接处理   │
├─────────────┼─────────────┼─────────────┼─────────────┤
│  10万-100万 │   100MB-1GB  │   1-10秒    │   索引优化   │
├─────────────┼─────────────┼─────────────┼─────────────┤
│ 100万-1000万│   1GB-10GB   │  10秒-5分钟 │   分批处理   │
├─────────────┼─────────────┼─────────────┼─────────────┤
│   > 1000万  │    > 10GB    │   > 5分钟   │  流式+并行   │
└─────────────┴─────────────┴─────────────┴─────────────┘
```

**🔧 性能瓶颈识别**
```sql
-- 查看UNION查询的执行计划
EXPLAIN FORMAT=JSON
SELECT * FROM large_table1 
UNION 
SELECT * FROM large_table2;

-- 关注这些关键指标：
-- 1. rows_examined：扫描的行数
-- 2. Using temporary：是否使用临时表
-- 3. Using filesort：是否使用文件排序
-- 4. Memory usage：内存使用情况
```

---

## 2. 💾 UNION内存管理机制


### 2.1 MySQL中UNION的内存使用原理


**🔸 UNION内存处理流程**

```
UNION内存处理步骤：
第一步：读取第一个SELECT结果 → 存入内存临时表
第二步：读取第二个SELECT结果 → 与临时表合并
第三步：去重处理（UNION）→ 消耗额外内存
第四步：排序输出 → 可能触发磁盘排序
```

**💡 内存管理的生活类比**

就像整理两个书架上的书：
```
内存充足时：
书架A的书 → 搬到桌子上整理
书架B的书 → 也搬到桌子上，去掉重复的
最后：桌子上就是去重后的全部书籍

内存不足时：
桌子放不下 → 先整理一部分
剩余的书 → 暂时放到地上（磁盘）
分批处理 → 最后再合并整理
```

### 2.2 内存相关参数配置


**⚙️ 关键内存参数**

| 参数名称 | 默认值 | 作用 | 大数据场景建议值 |
|---------|--------|------|------------------|
| `tmp_table_size` | 16MB | 内存临时表最大值 | 512MB - 2GB |
| `max_heap_table_size` | 16MB | MEMORY引擎表上限 | 与tmp_table_size相同 |
| `sort_buffer_size` | 256KB | 排序缓冲区大小 | 2MB - 8MB |
| `join_buffer_size` | 256KB | 连接操作缓冲区 | 1MB - 4MB |

**🔧 实际配置示例**
```sql
-- 针对大数据UNION的内存优化配置
SET SESSION tmp_table_size = 1073741824;        -- 1GB临时表空间
SET SESSION max_heap_table_size = 1073741824;   -- 1GB堆表空间  
SET SESSION sort_buffer_size = 4194304;         -- 4MB排序缓冲
SET SESSION join_buffer_size = 2097152;         -- 2MB连接缓冲

-- 验证配置是否生效
SHOW VARIABLES LIKE '%tmp_table_size%';
SHOW VARIABLES LIKE '%heap_table_size%';
```

### 2.3 内存使用监控


**📊 内存使用状态监控**
```sql
-- 查看临时表使用情况
SHOW STATUS LIKE 'Created_tmp%';

-- 关键指标解读：
-- Created_tmp_disk_tables：磁盘临时表创建次数（越少越好）
-- Created_tmp_tables：总临时表创建次数
-- 磁盘临时表比例 = Created_tmp_disk_tables / Created_tmp_tables

-- 理想情况：磁盘临时表比例 < 10%
```

**⚠️ 内存溢出预警机制**
```sql
-- 监控内存使用的查询
SELECT 
    ROUND(Created_tmp_disk_tables * 100.0 / Created_tmp_tables, 2) AS disk_tmp_pct,
    Created_tmp_tables,
    Created_tmp_disk_tables,
    CASE 
        WHEN Created_tmp_disk_tables * 100.0 / Created_tmp_tables > 25 THEN '需要优化'
        WHEN Created_tmp_disk_tables * 100.0 / Created_tmp_tables > 10 THEN '建议关注'
        ELSE '状态良好'
    END AS status
FROM 
    (SELECT VARIABLE_VALUE AS Created_tmp_tables FROM INFORMATION_SCHEMA.SESSION_STATUS WHERE VARIABLE_NAME = 'Created_tmp_tables') t1,
    (SELECT VARIABLE_VALUE AS Created_tmp_disk_tables FROM INFORMATION_SCHEMA.SESSION_STATUS WHERE VARIABLE_NAME = 'Created_tmp_disk_tables') t2;
```

---

## 3. 📦 分批UNION处理策略


### 3.1 为什么需要分批处理


**🔸 分批处理的核心思想**

想象你要清点10个仓库的所有货物：
```
一次性方式：
打开所有仓库 → 把所有货物拉出来 → 一起清点
问题：空间不够，乱成一团

分批方式：  
先处理仓库1和2 → 得到结果A
再处理仓库3和4 → 得到结果B
结果A和结果B合并 → 最终结果
优势：每次只处理少量数据，可控可管理
```

### 3.2 基于数据量的分批策略


**📊 动态分批算法**
```sql
-- 第一步：评估数据量
SELECT 
    table_name,
    table_rows,
    ROUND((data_length + index_length) / 1024 / 1024, 2) AS size_mb
FROM information_schema.tables 
WHERE table_schema = 'your_database'
AND table_name IN ('table1', 'table2', 'table3');

-- 第二步：根据数据量制定分批策略
-- 策略1：按表大小分批（小表优先合并）
```

**🎯 实际分批处理示例**
```sql
-- 场景：合并12个月的交易数据，每月500万记录
-- 传统方式（可能导致内存溢出）：
SELECT * FROM transaction_202401 
UNION ALL SELECT * FROM transaction_202402
-- ... 12个UNION ALL

-- 分批优化方式：
-- 第1批：合并前3个月
CREATE TEMPORARY TABLE temp_q1 AS
SELECT * FROM transaction_202401 
UNION ALL 
SELECT * FROM transaction_202402
UNION ALL 
SELECT * FROM transaction_202403;

-- 第2批：合并接下来3个月  
CREATE TEMPORARY TABLE temp_q2 AS
SELECT * FROM transaction_202404
UNION ALL 
SELECT * FROM transaction_202405
UNION ALL 
SELECT * FROM transaction_202406;

-- 第3批和第4批类似...

-- 最终合并：
SELECT * FROM temp_q1
UNION ALL SELECT * FROM temp_q2  
UNION ALL SELECT * FROM temp_q3
UNION ALL SELECT * FROM temp_q4;
```

### 3.3 基于时间窗口的分批策略


**⏰ 时间窗口分批处理**
```sql
-- 按时间段分批处理大表UNION
-- 优势：充分利用时间分区索引

-- 分批处理存储过程示例
DELIMITER //
CREATE PROCEDURE BatchUnionByTime(
    IN start_date DATE,
    IN end_date DATE,
    IN batch_days INT
)
BEGIN
    DECLARE current_start DATE DEFAULT start_date;
    DECLARE current_end DATE;
    DECLARE batch_count INT DEFAULT 0;
    
    -- 创建最终结果表
    DROP TEMPORARY TABLE IF EXISTS final_result;
    CREATE TEMPORARY TABLE final_result (
        id INT,
        transaction_date DATE,
        amount DECIMAL(10,2),
        KEY idx_date (transaction_date)
    );
    
    WHILE current_start <= end_date DO
        SET current_end = DATE_ADD(current_start, INTERVAL batch_days-1 DAY);
        SET batch_count = batch_count + 1;
        
        -- 处理当前时间窗口
        INSERT INTO final_result
        SELECT id, transaction_date, amount 
        FROM transaction_history 
        WHERE transaction_date BETWEEN current_start AND current_end
        UNION ALL
        SELECT id, transaction_date, amount 
        FROM transaction_backup
        WHERE transaction_date BETWEEN current_start AND current_end;
        
        -- 移动到下一个时间窗口
        SET current_start = DATE_ADD(current_end, INTERVAL 1 DAY);
        
        -- 定期提交，避免事务过大
        IF batch_count % 10 = 0 THEN
            COMMIT;
        END IF;
    END WHILE;
    
    SELECT * FROM final_result ORDER BY transaction_date;
END //
DELIMITER ;

-- 使用示例：按7天为一批处理一年的数据
CALL BatchUnionByTime('2024-01-01', '2024-12-31', 7);
```

### 3.4 智能分批大小计算


**🧮 动态分批大小算法**
```sql
-- 根据可用内存动态计算分批大小
-- 创建分批计算函数

DELIMITER //
CREATE FUNCTION CalcOptimalBatchSize(
    total_rows BIGINT,
    avg_row_size INT,
    available_memory BIGINT
) RETURNS INT
READS SQL DATA
DETERMINISTIC
BEGIN
    DECLARE optimal_batch_size INT;
    DECLARE memory_per_batch BIGINT;
    
    -- 预留30%内存给系统其他操作
    SET available_memory = available_memory * 0.7;
    
    -- 计算单批次最大行数（考虑UNION去重开销，乘以2的安全系数）
    SET optimal_batch_size = available_memory / (avg_row_size * 2);
    
    -- 限制批次大小在合理范围内
    IF optimal_batch_size > 1000000 THEN
        SET optimal_batch_size = 1000000;  -- 最大100万行/批
    ELSEIF optimal_batch_size < 10000 THEN
        SET optimal_batch_size = 10000;    -- 最小1万行/批
    END IF;
    
    RETURN optimal_batch_size;
END //
DELIMITER ;

-- 使用示例
SELECT CalcOptimalBatchSize(50000000, 200, 2147483648) AS recommended_batch_size;
-- 参数：5000万总行数，平均200字节/行，2GB可用内存
```

---

## 4. ⚡ UNION并行处理技术


### 4.1 并行处理的基本概念


**🔸 什么是UNION并行处理**

传统串行处理就像一个人搬家：
```
串行方式：
搬完客厅 → 再搬卧室 → 再搬厨房 → 最后整理
时间：1小时 + 1小时 + 1小时 + 1小时 = 4小时

并行方式：
4个人同时工作：
人A搬客厅，人B搬卧室，人C搬厨房，人D整理
时间：1小时（同时进行）
```

在UNION场景中：
```
串行UNION：
查询表1 → 查询表2 → 查询表3 → 合并结果

并行UNION：
同时查询表1、表2、表3 → 并行合并结果
```

### 4.2 基于连接池的并行UNION


**🔧 多连接并行处理架构**

```sql
-- 并行UNION处理的伪代码逻辑
-- 主线程：协调和汇总
-- 工作线程：并行执行查询

-- 线程1执行：
SELECT customer_id, order_date, amount 
FROM orders_2024_q1 
WHERE order_date >= '2024-01-01';

-- 线程2执行：
SELECT customer_id, order_date, amount 
FROM orders_2024_q2 
WHERE order_date >= '2024-04-01';

-- 线程3执行：
SELECT customer_id, order_date, amount 
FROM orders_2024_q3 
WHERE order_date >= '2024-07-01';

-- 线程4执行：
SELECT customer_id, order_date, amount 
FROM orders_2024_q4 
WHERE order_date >= '2024-10-01';

-- 主线程汇总：所有子结果UNION
```

**💻 Python并行UNION实现示例**
```python
import mysql.connector
from concurrent.futures import ThreadPoolExecutor, as_completed
import pandas as pd

class ParallelUnionProcessor:
    def __init__(self, db_config, max_workers=4):
        self.db_config = db_config
        self.max_workers = max_workers
    
    def execute_query(self, sql_query, thread_id):
        """执行单个查询的工作线程"""
        try:
            conn = mysql.connector.connect(**self.db_config)
            cursor = conn.cursor()
            
            print(f"线程{thread_id}开始执行查询...")
            cursor.execute(sql_query)
            results = cursor.fetchall()
            
            print(f"线程{thread_id}查询完成，返回{len(results)}条记录")
            return results
            
        except Exception as e:
            print(f"线程{thread_id}执行失败: {e}")
            return []
        finally:
            if cursor:
                cursor.close()
            if conn:
                conn.close()
    
    def parallel_union(self, query_list):
        """并行执行多个查询并合并结果"""
        all_results = []
        
        # 使用线程池并行执行查询
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # 提交所有查询任务
            future_to_query = {
                executor.submit(self.execute_query, query, i): i 
                for i, query in enumerate(query_list)
            }
            
            # 收集所有结果
            for future in as_completed(future_to_query):
                thread_id = future_to_query[future]
                try:
                    result = future.result()
                    all_results.extend(result)
                except Exception as e:
                    print(f"线程{thread_id}结果收集失败: {e}")
        
        # 去重处理（模拟UNION效果）
        unique_results = list(set(all_results))
        print(f"并行UNION完成：总记录数{len(unique_results)}")
        
        return unique_results

# 使用示例
if __name__ == "__main__":
    # 数据库配置
    db_config = {
        'host': 'localhost',
        'user': 'your_user',
        'password': 'your_password',
        'database': 'your_database'
    }
    
    # 要并行执行的查询列表
    queries = [
        "SELECT * FROM sales_data WHERE region = 'North'",
        "SELECT * FROM sales_data WHERE region = 'South'", 
        "SELECT * FROM sales_data WHERE region = 'East'",
        "SELECT * FROM sales_data WHERE region = 'West'"
    ]
    
    processor = ParallelUnionProcessor(db_config, max_workers=4)
    result = processor.parallel_union(queries)
```

### 4.3 分区表并行UNION优化


**📊 分区表并行策略**
```sql
-- 创建按年月分区的大表
CREATE TABLE large_transactions (
    id BIGINT AUTO_INCREMENT,
    transaction_date DATE NOT NULL,
    amount DECIMAL(10,2),
    customer_id INT,
    PRIMARY KEY (id, transaction_date)
) 
PARTITION BY RANGE (YEAR(transaction_date) * 100 + MONTH(transaction_date)) (
    PARTITION p202401 VALUES LESS THAN (202402),
    PARTITION p202402 VALUES LESS THAN (202403),
    PARTITION p202403 VALUES LESS THAN (202404),
    -- ... 更多分区
    PARTITION p202412 VALUES LESS THAN (202501)
);

-- 并行查询不同分区，MySQL会自动优化
-- 这个查询会并行访问多个分区
SELECT customer_id, SUM(amount) as total_amount
FROM large_transactions 
WHERE transaction_date BETWEEN '2024-01-01' AND '2024-12-31'
GROUP BY customer_id

UNION ALL

SELECT customer_id, SUM(amount) as total_amount  
FROM archived_transactions
WHERE transaction_date BETWEEN '2024-01-01' AND '2024-12-31'
GROUP BY customer_id;

-- 查看分区执行情况
EXPLAIN PARTITIONS
SELECT * FROM large_transactions 
WHERE transaction_date BETWEEN '2024-06-01' AND '2024-08-31';
```

### 4.4 并行度控制和调优


**⚙️ 并行度参数调优**

| 参数 | 作用 | 建议值 | 说明 |
|------|------|--------|------|
| `max_connections` | 最大连接数 | 200-500 | 根据并行度设置 |
| `thread_cache_size` | 线程缓存 | 50-100 | 减少线程创建开销 |
| `innodb_thread_concurrency` | InnoDB并发线程 | 0(无限制) | 让系统自动调节 |
| `innodb_read_io_threads` | 读IO线程数 | 4-16 | 根据磁盘性能调整 |

```sql
-- 查看当前并行相关配置
SHOW VARIABLES LIKE '%thread%';
SHOW VARIABLES LIKE '%connection%';

-- 优化并行处理的配置
SET GLOBAL max_connections = 300;
SET GLOBAL thread_cache_size = 100;
SET GLOBAL innodb_read_io_threads = 8;
```

**📈 并行效果监控**
```sql
-- 监控并行查询效果
SELECT 
    COUNT(*) as active_connections,
    state,
    command
FROM information_schema.processlist 
WHERE command != 'Sleep'
GROUP BY state, command
ORDER BY active_connections DESC;

-- 监控线程使用情况
SHOW STATUS LIKE 'Threads%';
-- Threads_connected：当前连接的线程数
-- Threads_running：当前活跃的线程数
-- Threads_cached：缓存中的线程数
```

---

## 5. 💿 磁盘溢出处理方案


### 5.1 磁盘溢出产生的原因


**🔸 什么时候会发生磁盘溢出**

想象你的桌子（内存）只能放100本书，但你要整理1000本书：
```
正常情况（内存充足）：
桌子够大 → 所有书都放桌子上 → 直接整理 → 效率高

溢出情况（内存不足）：
桌子太小 → 只能放100本在桌子上
剩余900本 → 暂时放地上（磁盘）
分批整理 → 效率降低，但仍能完成工作
```

**⚠️ 磁盘溢出的触发条件**
```sql
-- 溢出触发条件：
-- 1. 临时表大小 > tmp_table_size
-- 2. 临时表大小 > max_heap_table_size  
-- 3. 临时表包含BLOB/TEXT字段
-- 4. 结果集去重处理内存不足

-- 检查当前内存限制
SHOW VARIABLES LIKE 'tmp_table_size';          -- 通常16MB
SHOW VARIABLES LIKE 'max_heap_table_size';     -- 通常16MB

-- 如果UNION结果集 > 16MB，就会溢出到磁盘
```

### 5.2 磁盘溢出检测方法


**🔍 溢出检测SQL**
```sql
-- 重置状态计数器
FLUSH STATUS;

-- 执行可能溢出的UNION查询
SELECT * FROM large_table1 
UNION 
SELECT * FROM large_table2;

-- 检查溢出情况
SELECT 
    VARIABLE_NAME,
    VARIABLE_VALUE,
    CASE VARIABLE_NAME
        WHEN 'Created_tmp_disk_tables' THEN 
            CONCAT('磁盘临时表: ', VARIABLE_VALUE, '个')
        WHEN 'Created_tmp_tables' THEN 
            CONCAT('总临时表: ', VARIABLE_VALUE, '个')
    END as description
FROM INFORMATION_SCHEMA.SESSION_STATUS 
WHERE VARIABLE_NAME IN ('Created_tmp_disk_tables', 'Created_tmp_tables');

-- 计算溢出比例
SELECT 
    disk.VARIABLE_VALUE as disk_tables,
    total.VARIABLE_VALUE as total_tables,
    ROUND(disk.VARIABLE_VALUE * 100.0 / total.VARIABLE_VALUE, 2) as overflow_percentage
FROM 
    (SELECT VARIABLE_VALUE FROM INFORMATION_SCHEMA.SESSION_STATUS WHERE VARIABLE_NAME = 'Created_tmp_disk_tables') disk,
    (SELECT VARIABLE_VALUE FROM INFORMATION_SCHEMA.SESSION_STATUS WHERE VARIABLE_NAME = 'Created_tmp_tables') total;
```

**📊 磁盘溢出影响评估**
```sql
-- 创建溢出监控表
CREATE TABLE disk_overflow_monitor (
    query_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    query_sql TEXT,
    execution_time_ms INT,
    disk_tables_created INT,
    total_tables_created INT,
    overflow_percentage DECIMAL(5,2),
    INDEX idx_query_time (query_time)
);

-- 监控存储过程
DELIMITER //
CREATE PROCEDURE MonitorDiskOverflow(IN sql_query TEXT)
BEGIN
    DECLARE start_time BIGINT;
    DECLARE end_time BIGINT;
    DECLARE execution_time INT;
    DECLARE disk_tables INT DEFAULT 0;
    DECLARE total_tables INT DEFAULT 0;
    
    -- 重置计数器
    FLUSH STATUS;
    
    -- 记录开始时间
    SET start_time = UNIX_TIMESTAMP(NOW(3)) * 1000;
    
    -- 执行查询（这里需要动态SQL，实际使用时需要PREPARE STATEMENT）
    -- SET @sql = sql_query;
    -- PREPARE stmt FROM @sql;
    -- EXECUTE stmt;
    -- DEALLOCATE PREPARE stmt;
    
    -- 记录结束时间
    SET end_time = UNIX_TIMESTAMP(NOW(3)) * 1000;
    SET execution_time = end_time - start_time;
    
    -- 获取临时表创建情况
    SELECT VARIABLE_VALUE INTO disk_tables 
    FROM INFORMATION_SCHEMA.SESSION_STATUS 
    WHERE VARIABLE_NAME = 'Created_tmp_disk_tables';
    
    SELECT VARIABLE_VALUE INTO total_tables 
    FROM INFORMATION_SCHEMA.SESSION_STATUS 
    WHERE VARIABLE_NAME = 'Created_tmp_tables';
    
    -- 记录监控结果
    INSERT INTO disk_overflow_monitor 
    (query_sql, execution_time_ms, disk_tables_created, total_tables_created, overflow_percentage)
    VALUES 
    (sql_query, execution_time, disk_tables, total_tables, 
     CASE WHEN total_tables > 0 THEN disk_tables * 100.0 / total_tables ELSE 0 END);
    
END //
DELIMITER ;
```

### 5.3 磁盘溢出优化策略


**🚀 策略1：增加内存分配**
```sql
-- 针对当前会话增加内存限制
SET SESSION tmp_table_size = 1024 * 1024 * 1024;        -- 1GB
SET SESSION max_heap_table_size = 1024 * 1024 * 1024;   -- 1GB

-- 验证设置是否成功
SELECT 
    $$SESSION.tmp_table_size / 1024 / 1024 as tmp_table_size_mb,
    $$SESSION.max_heap_table_size / 1024 / 1024 as max_heap_table_size_mb;

-- 重新执行查询，观察溢出情况
FLUSH STATUS;
SELECT * FROM large_table1 UNION SELECT * FROM large_table2;

-- 检查优化效果
SELECT 
    VARIABLE_NAME, VARIABLE_VALUE
FROM INFORMATION_SCHEMA.SESSION_STATUS 
WHERE VARIABLE_NAME IN ('Created_tmp_disk_tables', 'Created_tmp_tables');
```

**🚀 策略2：查询重写避免溢出**
```sql
-- 原始查询（容易溢出）
SELECT customer_id, order_date, SUM(amount) as total
FROM orders_2023 
GROUP BY customer_id, order_date
UNION
SELECT customer_id, order_date, SUM(amount) as total
FROM orders_2024
GROUP BY customer_id, order_date;

-- 优化后查询（减少中间结果集）
SELECT customer_id, order_date, SUM(amount) as total
FROM (
    SELECT customer_id, order_date, amount FROM orders_2023
    UNION ALL  -- 使用UNION ALL避免去重开销
    SELECT customer_id, order_date, amount FROM orders_2024
) combined_orders
GROUP BY customer_id, order_date;
```

**🚀 策略3：分步骤处理**
```sql
-- 第一步：创建中间结果表
CREATE TEMPORARY TABLE temp_union_result (
    customer_id INT,
    order_date DATE,
    total_amount DECIMAL(10,2),
    KEY idx_customer_date (customer_id, order_date)
);

-- 第二步：分批插入数据
INSERT INTO temp_union_result
SELECT customer_id, order_date, SUM(amount)
FROM orders_2023 
GROUP BY customer_id, order_date;

INSERT INTO temp_union_result  
SELECT customer_id, order_date, SUM(amount)
FROM orders_2024 
GROUP BY customer_id, order_date;

-- 第三步：最终去重和汇总
SELECT customer_id, order_date, SUM(total_amount) as final_total
FROM temp_union_result
GROUP BY customer_id, order_date;
```

### 5.4 磁盘溢出性能对比


**📈 性能测试对比**
```sql
-- 创建性能测试表
CREATE TABLE performance_test_log (
    test_name VARCHAR(100),
    execution_time_seconds DECIMAL(10,3),
    memory_overflow_count INT,
    result_rows INT,
    test_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 测试1：直接UNION（可能溢出）
SET @start_time = NOW(3);
FLUSH STATUS;

SELECT * FROM large_table1 UNION SELECT * FROM large_table2;

SET @end_time = NOW(3);
SET @execution_time = TIMESTAMPDIFF(MICROSECOND, @start_time, @end_time) / 1000000.0;

-- 记录测试结果
INSERT INTO performance_test_log (test_name, execution_time_seconds, memory_overflow_count)
SELECT 'Direct_UNION', @execution_time, VARIABLE_VALUE
FROM INFORMATION_SCHEMA.SESSION_STATUS 
WHERE VARIABLE_NAME = 'Created_tmp_disk_tables';

-- 测试2：优化内存后UNION
SET SESSION tmp_table_size = 1024 * 1024 * 1024;
-- 重复相同测试...

-- 查看性能对比结果
SELECT 
    test_name,
    execution_time_seconds,
    memory_overflow_count,
    test_timestamp
FROM performance_test_log 
ORDER BY test_timestamp;
```

---

## 6. 🎯 大结果集优化技巧


### 6.1 大结果集的挑战


**🔸 什么是大结果集问题**

想象你在网上购物，搜索结果有100万个商品：
```
传统做法：
一次性加载100万商品 → 页面卡死 → 用户体验极差

优化做法：
分页显示：每页20个商品 → 用户翻页浏览 → 流畅体验
按需加载：滚动到底部 → 加载下一批 → 无缝体验
```

在SQL中：
```
大结果集问题：
UNION查询返回1000万行 → 内存占用巨大 → 传输时间长
客户端处理困难 → 可能导致应用崩溃

优化思路：
分页返回、流式处理、压缩传输、索引优化
```

### 6.2 分页处理大结果集


**📄 智能分页策略**
```sql
-- 基础分页查询
SELECT * FROM (
    SELECT customer_id, order_date, amount FROM orders_2023
    UNION ALL
    SELECT customer_id, order_date, amount FROM orders_2024  
) combined_result
ORDER BY order_date DESC
LIMIT 1000 OFFSET 0;  -- 第一页，每页1000条

-- 游标分页（性能更好，适合大偏移量）
-- 第一页
SELECT * FROM (
    SELECT customer_id, order_date, amount FROM orders_2023
    UNION ALL
    SELECT customer_id, order_date, amount FROM orders_2024
) combined_result
WHERE order_date <= '2024-12-31'
ORDER BY order_date DESC, customer_id DESC
LIMIT 1000;

-- 后续页面（使用上一页最后一条记录作为游标）
SELECT * FROM (
    SELECT customer_id, order_date, amount FROM orders_2023
    UNION ALL
    SELECT customer_id, order_date, amount FROM orders_2024
) combined_result
WHERE order_date < '2024-10-15'  -- 上一页最后的order_date
   OR (order_date = '2024-10-15' AND customer_id < 12345)  -- 处理相同日期
ORDER BY order_date DESC, customer_id DESC
LIMIT 1000;
```

**🔄 动态分页大小调整**
```sql
-- 根据系统负载动态调整页面大小
DELIMITER //
CREATE PROCEDURE DynamicPaging(
    IN base_page_size INT,
    IN max_page_size INT,
    IN current_page INT
)
BEGIN
    DECLARE actual_page_size INT;
    DECLARE system_load DECIMAL(3,2);
    DECLARE offset_value INT;
    
    -- 简单的负载检测（可以根据实际情况优化）
    SELECT (
        SELECT COUNT(*) FROM information_schema.processlist WHERE state != 'Sleep'
    ) * 1.0 / $$max_connections INTO system_load;
    
    -- 根据系统负载调整页面大小
    IF system_load > 0.8 THEN
        SET actual_page_size = base_page_size / 2;  -- 高负载时减小页面
    ELSEIF system_load < 0.3 THEN  
        SET actual_page_size = LEAST(base_page_size * 2, max_page_size);  -- 低负载时增大页面
    ELSE
        SET actual_page_size = base_page_size;  -- 正常负载
    END IF;
    
    SET offset_value = (current_page - 1) * actual_page_size;
    
    -- 执行分页查询
    SET @sql = CONCAT(
        'SELECT * FROM (',
        'SELECT customer_id, order_date, amount FROM orders_2023 ',
        'UNION ALL ',
        'SELECT customer_id, order_date, amount FROM orders_2024',
        ') combined_result ORDER BY order_date DESC LIMIT ',
        actual_page_size, ' OFFSET ', offset_value
    );
    
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    DEALLOCATE PREPARE stmt;
    
    -- 返回分页信息
    SELECT 
        actual_page_size as page_size,
        current_page as page_number,
        system_load as current_load,
        'Dynamic paging executed' as status;
        
END //
DELIMITER ;

-- 使用示例
CALL DynamicPaging(1000, 5000, 1);  -- 基础1000条/页，最大5000条/页，第1页
```

### 6.3 流式结果处理


**🌊 流式处理概念**
```python
# Python流式处理UNION查询大结果集
import mysql.connector
from mysql.connector import cursor
import json

class StreamUnionProcessor:
    def __init__(self, db_config):
        self.db_config = db_config
        
    def stream_union_results(self, union_query, batch_size=1000):
        """
        流式处理UNION查询结果
        batch_size: 每批处理的记录数
        """
        connection = None
        cursor_obj = None
        
        try:
            # 建立数据库连接
            connection = mysql.connector.connect(**self.db_config)
            
            # 使用服务器端游标，避免一次性加载所有结果到内存
            cursor_obj = connection.cursor(buffered=False)
            
            print(f"开始执行流式UNION查询...")
            cursor_obj.execute(union_query)
            
            batch_count = 0
            total_processed = 0
            
            while True:
                # 批量获取结果
                batch_results = cursor_obj.fetchmany(batch_size)
                
                if not batch_results:
                    break  # 没有更多结果
                
                batch_count += 1
                total_processed += len(batch_results)
                
                # 处理当前批次（这里可以替换为实际业务逻辑）
                self.process_batch(batch_results, batch_count)
                
                print(f"已处理批次 {batch_count}，本批 {len(batch_results)} 条，累计 {total_processed} 条")
                
                # 内存管理：定期释放
                if batch_count % 100 == 0:
                    print(f"已处理 {batch_count} 批次，进行内存清理...")
                    
            print(f"流式处理完成！总计处理 {total_processed} 条记录，{batch_count} 个批次")
                    
        except Exception as e:
            print(f"流式处理出错: {e}")
        finally:
            if cursor_obj:
                cursor_obj.close()
            if connection:
                connection.close()
    
    def process_batch(self, batch_data, batch_number):
        """处理单个批次的数据"""
        # 这里可以实现具体的业务逻辑
        # 例如：写入文件、发送到消息队列、进行数据转换等
        
        # 示例：将批次数据写入JSON文件
        filename = f"batch_{batch_number:06d}.json"
        
        batch_json = []
        for row in batch_data:
            # 假设查询返回的列是：customer_id, order_date, amount
            batch_json.append({
                'customer_id': row[0],
                'order_date': str(row[1]) if row[1] else None,
                'amount': float(row[2]) if row[2] else 0.0
            })
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(batch_json, f, ensure_ascii=False, indent=2)

# 使用示例
if __name__ == "__main__":
    db_config = {
        'host': 'localhost',
        'user': 'your_user', 
        'password': 'your_password',
        'database': 'your_database',
        'use_unicode': True,
        'charset': 'utf8mb4'
    }
    
    # 大结果集UNION查询
    large_union_query = """
    SELECT customer_id, order_date, amount FROM orders_2022
    WHERE amount > 100
    UNION ALL
    SELECT customer_id, order_date, amount FROM orders_2023  
    WHERE amount > 100
    UNION ALL
    SELECT customer_id, order_date, amount FROM orders_2024
    WHERE amount > 100
    ORDER BY order_date DESC
    """
    
    processor = StreamUnionProcessor(db_config)
    processor.stream_union_results(large_union_query, batch_size=5000)
```

### 6.4 结果集压缩和传输优化


**🗜️ 压缩传输策略**
```sql
-- SQL层面的数据压缩技巧

-- 1. 只选择必要的列（减少传输量）
-- 原始查询（传输所有列）
SELECT * FROM large_table1 UNION SELECT * FROM large_table2;

-- 优化查询（只传输需要的列）
SELECT id, customer_id, amount FROM large_table1 
UNION 
SELECT id, customer_id, amount FROM large_table2;

-- 2. 数据类型优化
-- 原始：使用VARCHAR(255)存储状态
-- 优化：使用ENUM或小整数代替
SELECT 
    id,
    customer_id,
    CASE status 
        WHEN 'PENDING' THEN 1
        WHEN 'COMPLETED' THEN 2  
        WHEN 'CANCELLED' THEN 3
        ELSE 0
    END as status_code
FROM orders_table1
UNION ALL
SELECT 
    id, 
    customer_id,
    CASE status
        WHEN 'PENDING' THEN 1
        WHEN 'COMPLETED' THEN 2
        WHEN 'CANCELLED' THEN 3  
        ELSE 0
    END as status_code
FROM orders_table2;

-- 3. 聚合减少行数
-- 原始：返回每个订单明细
SELECT customer_id, order_date, amount FROM orders_2023
UNION ALL  
SELECT customer_id, order_date, amount FROM orders_2024;

-- 优化：按客户聚合
SELECT customer_id, COUNT(*) as order_count, SUM(amount) as total_amount
FROM (
    SELECT customer_id, amount FROM orders_2023
    UNION ALL
    SELECT customer_id, amount FROM orders_2024
) combined
GROUP BY customer_id;
```

**📊 传输效率监控**
```sql
-- 创建传输效率监控表
CREATE TABLE query_transmission_stats (
    id INT AUTO_INCREMENT PRIMARY KEY,
    query_type VARCHAR(100),
    result_rows BIGINT,
    data_size_bytes BIGINT,
    execution_time_ms INT,
    compression_ratio DECIMAL(5,2),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_query_type_time (query_type, created_at)
);

-- 监控存储过程
DELIMITER //
CREATE PROCEDURE MonitorTransmissionEfficiency(
    IN query_description VARCHAR(100),
    IN sql_query TEXT
)
BEGIN
    DECLARE start_time BIGINT;
    DECLARE end_time BIGINT;
    DECLARE execution_time INT;
    DECLARE result_count BIGINT DEFAULT 0;
    
    -- 记录开始时间
    SET start_time = UNIX_TIMESTAMP(NOW(3)) * 1000;
    
    -- 执行查询并计算结果行数
    -- 注意：实际使用时需要用PREPARE STATEMENT动态执行
    
    -- 这里模拟查询结果统计
    SET result_count = 1000000;  -- 实际应该通过ROW_COUNT()获取
    
    -- 记录结束时间
    SET end_time = UNIX_TIMESTAMP(NOW(3)) * 1000;
    SET execution_time = end_time - start_time;
    
    -- 估算数据大小（基于行数和平均行大小）
    INSERT INTO query_transmission_stats 
    (query_type, result_rows, data_size_bytes, execution_time_ms, compression_ratio)
    VALUES 
    (query_description, result_count, result_count * 200, execution_time, 1.0);
    
    SELECT 
        CONCAT('查询完成: ', query_description) as status,
        result_count as rows_returned,
        execution_time as time_ms,
        ROUND(result_count * 200 / 1024 / 1024, 2) as estimated_mb;
        
END //
DELIMITER ;

-- 使用示例
CALL MonitorTransmissionEfficiency(
    'Large_UNION_Query',
    'SELECT * FROM table1 UNION SELECT * FROM table2'
);

-- 查看传输效率报告
SELECT 
    query_type,
    AVG(result_rows) as avg_rows,
    AVG(data_size_bytes / 1024 / 1024) as avg_mb,
    AVG(execution_time_ms) as avg_time_ms,
    AVG(result_rows * 1000.0 / execution_time_ms) as avg_rows_per_second
FROM query_transmission_stats
WHERE created_at >= DATE_SUB(NOW(), INTERVAL 1 DAY)
GROUP BY query_type;
```

### 6.5 索引优化提升大结果集性能


**🔍 针对UNION的索引策略**
```sql
-- 为UNION查询创建优化索引

-- 1. 覆盖索引：避免回表查询
-- UNION查询经常使用的列
CREATE INDEX idx_orders_union_cover ON orders_2023 (customer_id, order_date, amount, status);
CREATE INDEX idx_orders_union_cover ON orders_2024 (customer_id, order_date, amount, status);

-- 验证覆盖索引效果
EXPLAIN 
SELECT customer_id, order_date, amount 
FROM orders_2023 WHERE customer_id BETWEEN 1000 AND 2000
UNION
SELECT customer_id, order_date, amount  
FROM orders_2024 WHERE customer_id BETWEEN 1000 AND 2000;

-- 2. 分区索引：提高并行度
-- 按时间分区，每个分区建立独立索引
ALTER TABLE orders_history 
PARTITION BY RANGE (YEAR(order_date)) (
    PARTITION p2022 VALUES LESS THAN (2023),
    PARTITION p2023 VALUES LESS THAN (2024),
    PARTITION p2024 VALUES LESS THAN (2025),
    PARTITION p2025 VALUES LESS THAN (2026)
);

-- 每个分区自动创建独立的索引
CREATE INDEX idx_partition_customer ON orders_history (customer_id);

-- 3. 函数索引：优化复杂条件
-- 如果UNION中经常使用日期函数
CREATE INDEX idx_orders_year_month ON orders_2023 ((YEAR(order_date) * 100 + MONTH(order_date)));
CREATE INDEX idx_orders_year_month ON orders_2024 ((YEAR(order_date) * 100 + MONTH(order_date)));

-- 使用函数索引的查询
SELECT customer_id, order_date, amount
FROM orders_2023 
WHERE YEAR(order_date) * 100 + MONTH(order_date) = 202312
UNION
SELECT customer_id, order_date, amount
FROM orders_2024
WHERE YEAR(order_date) * 100 + MONTH(order_date) = 202401;
```

---

## 7. 📋 核心要点总结


### 7.1 必须掌握的基本概念


```markdown
🔸 大数据UNION挑战：内存限制、IO瓶颈、去重复杂、传输耗时
🔸 内存管理：tmp_table_size、max_heap_table_size参数调优  
🔸 分批处理：按数据量、时间窗口、智能大小分批
🔸 并行处理：多线程查询、分区并行、连接池管理
🔸 磁盘溢出：检测方法、优化策略、性能监控
🔸 大结果集：分页处理、流式传输、压缩优化
```

### 7.2 关键理解要点


**🔹 为什么大数据UNION这么困难**
```
数据量问题：
• 小数据：内存够用，一次性处理
• 大数据：内存不足，需要分批、并行、优化

性能瓶颈：  
• CPU：去重计算密集
• 内存：临时表空间限制
• 磁盘：溢出后IO成为瓶颈
• 网络：大结果集传输延迟
```

**🔹 优化策略的核心思想**
```
分而治之：
• 大问题分解成小问题
• 分批处理降低内存压力
• 并行处理提升整体效率

资源合理利用：
• 内存：适当增加但不过度
• CPU：并行充分利用多核
• 磁盘：优化读写模式
• 网络：压缩和分页传输
```

**🔹 什么时候需要这些技术**
```
触发条件：
✅ 单表数据量 > 100万行
✅ UNION涉及多个大表  
✅ 结果集 > 可用内存的50%
✅ 查询时间 > 30秒
✅ 出现磁盘临时表

不需要的情况：
❌ 数据量小（< 10万行）
❌ 内存充足的简单查询
❌ 实时性要求不高的离线处理
```

### 7.3 实际应用指导


**🎯 场景选择策略**

| 数据量级 | 优先策略 | 适用技术 | 预期效果 |
|---------|----------|----------|----------|
| **< 100万行** | 参数调优 | 增加tmp_table_size | 避免磁盘溢出 |
| **100万-1000万** | 分批处理 | 时间窗口分批 | 控制内存使用 |
| **1000万-1亿** | 并行+分批 | 多线程+分区 | 显著提升速度 |
| **> 1亿行** | 流式处理 | 分页+压缩传输 | 稳定可控处理 |

**🔧 实施优先级**
```
第一优先级（必须做）：
1. 监控磁盘溢出情况
2. 适当调整内存参数  
3. 添加必要的索引

第二优先级（性能要求高）：
1. 实施分批处理策略
2. 优化查询结构
3. 考虑分页返回

第三优先级（海量数据）：
1. 实施并行处理
2. 流式结果处理
3. 压缩传输优化
```

**⚠️ 常见误区避免**
```
误区1：盲目增加内存
• 错误：无限制增大tmp_table_size
• 正确：根据系统总内存合理分配

误区2：过度并行化
• 错误：开启大量并发线程
• 正确：根据CPU核心数和IO能力调整

误区3：忽视网络传输
• 错误：只关注查询性能，忽视结果传输
• 正确：结合分页、压缩、流式处理

误区4：一刀切的优化
• 错误：所有UNION都使用相同策略
• 正确：根据具体数据量和场景选择策略
```

### 7.4 监控和运维建议


**📊 关键监控指标**
```
性能指标：
• Created_tmp_disk_tables：磁盘溢出次数
• Query_time：查询执行时间
• Rows_examined：扫描行数  
• Memory_usage：内存使用量

业务指标：
• 查询成功率：避免超时失败
• 用户等待时间：提升体验
• 系统资源使用：避免影响其他业务
• 数据准确性：确保结果正确
```

**🔧 运维最佳实践**
```
日常运维：
1. 定期检查磁盘溢出比例
2. 监控大查询的执行时间
3. 评估内存参数设置的合理性
4. 关注系统整体资源使用

应急处理：
1. 查询超时：启用分批处理
2. 内存不足：临时增加参数或重启服务
3. 磁盘空间不足：清理临时文件
4. 系统负载过高：限制并发或延期处理
```

**核心记忆**：
- 大数据UNION的本质是资源管理问题
- 分批、并行、流式是三大核心策略  
- 监控磁盘溢出是优化的第一步
- 根据数据量级选择合适的优化策略
- 平衡性能和资源使用，避免过度优化