---
title: 6、窗口函数性能优化
---
## 📚 目录

1. [窗口函数性能基础](#1-窗口函数性能基础)
2. [执行计划分析详解](#2-执行计划分析详解)
3. [排序内存管理](#3-排序内存管理)
4. [分区策略优化](#4-分区策略优化)
5. [索引利用优化](#5-索引利用优化)
6. [大数据集处理策略](#6-大数据集处理策略)
7. [窗口函数物化技术](#7-窗口函数物化技术)
8. [性能调优实战指南](#8-性能调优实战指南)
9. [核心要点总结](#9-核心要点总结)

---

## 1. ⚡ 窗口函数性能基础


### 1.1 窗口函数性能特点


**🔸 什么决定窗口函数性能**
窗口函数的性能就像工厂的流水线效率，主要取决于几个关键因素：

> 💡 **形象比喻**  
> 想象你要对1万个学生按班级排名。传统方法需要先按班级分组，再对每个班级排序。窗口函数就像聪明的老师，可以一次性处理所有班级的排名，但需要足够的内存和合理的组织方式。

```sql
-- 性能差异对比示例
-- ❌ 传统分组方式（多次查询）
SELECT class_id, student_name, score,
  (SELECT COUNT(*) FROM students s2 
   WHERE s2.class_id = s1.class_id 
   AND s2.score >= s1.score) as rank
FROM students s1;

-- ✅ 窗口函数方式（一次查询）
SELECT class_id, student_name, score,
  ROW_NUMBER() OVER(PARTITION BY class_id ORDER BY score DESC) as rank
FROM students;
```

### 1.2 影响性能的关键因素


| 因素类别 | **具体因素** | **性能影响** | **优化方向** |
|---------|-------------|-------------|-------------|
| 📊 **数据量** | `分区数量、每分区记录数` | `直接影响内存使用` | `合理分区设计` |
| 🔄 **排序复杂度** | `ORDER BY列数和类型` | `影响排序效率` | `优化排序字段` |
| 💾 **内存配置** | `sort_buffer_size等` | `决定内存排序能力` | `调整内存参数` |
| 🗂️ **索引支持** | `排序字段索引` | `减少排序开销` | `创建合适索引` |

### 1.3 窗口函数执行阶段


**🔸 执行阶段详解**

```
窗口函数执行流程：
数据读取 ──▶ 分区分组 ──▶ 排序处理 ──▶ 窗口计算 ──▶ 结果输出
    │           │           │           │           │
    ▼           ▼           ▼           ▼           ▼
  IO操作     内存分配     CPU密集     函数计算    网络传输
 磁盘读取   分区缓存     排序算法     聚合运算    结果返回
```

> ⚠️ **性能关键点**  
> 排序阶段通常是性能瓶颈，因为需要对整个分区的数据进行排序。如果内存不足，会使用磁盘临时文件，导致性能急剧下降。

---

## 2. 🔍 执行计划分析详解


### 2.1 窗口函数执行计划解读


**🔸 如何查看执行计划**

```sql
-- 分析窗口函数执行计划
EXPLAIN FORMAT=JSON
SELECT department, salary,
  ROW_NUMBER() OVER(PARTITION BY department ORDER BY salary DESC) as rn,
  AVG(salary) OVER(PARTITION BY department) as avg_salary
FROM employees;
```

**🔸 执行计划关键信息**

```json
{
  "query_block": {
    "select_id": 1,
    "cost_info": {
      "query_cost": "156.25"
    },
    "windowing": {
      "windows": [
        {
          "name": "<unnamed window>",
          "definition": "PARTITION BY department ORDER BY salary DESC",
          "uses_temporary_table": true,
          "sorting_cost": "45.67"
        }
      ],
      "filesort": {
        "sort_key": "department, salary desc",
        "temporary_table": true,
        "cost_info": {
          "sort_cost": "45.67"
        }
      }
    }
  }
}
```

### 2.2 性能指标解读


**🔸 关键性能指标**

| 指标 | **含义** | **影响** | **优化建议** |
|------|---------|---------|-------------|
| 📊 **query_cost** | `总查询成本` | `整体性能评估` | `降低总成本` |
| 🔄 **sorting_cost** | `排序成本` | `排序操作开销` | `利用索引减少排序` |
| 💾 **uses_temporary_table** | `是否使用临时表` | `内存/磁盘使用` | `调整内存配置` |
| 🗂️ **filesort** | `是否文件排序` | `排序算法选择` | `创建排序索引` |

**🔸 执行计划优化示例**

```sql
-- ❌ 性能较差的查询
SELECT employee_id, department, hire_date, salary,
  RANK() OVER(PARTITION BY department ORDER BY hire_date, salary DESC) as rank
FROM employees
WHERE salary > 5000;

-- 分析结果显示：
-- 1. 全表扫描
-- 2. 复杂排序（两个字段）
-- 3. 大量临时存储
```

**🔸 优化后的查询**

```sql
-- ✅ 优化后的查询
-- 1. 添加复合索引
CREATE INDEX idx_emp_dept_hire_salary 
ON employees(department, hire_date, salary DESC);

-- 2. 优化查询
SELECT employee_id, department, hire_date, salary,
  RANK() OVER(PARTITION BY department ORDER BY hire_date, salary DESC) as rank
FROM employees
WHERE salary > 5000;

-- 优化效果：
-- 1. 利用索引避免排序
-- 2. 减少临时表使用
-- 3. 提升整体性能3-5倍
```

---

## 3. 💾 排序内存管理


### 3.1 排序内存参数配置


**🔸 核心内存参数**

```sql
-- 查看当前排序内存配置
SHOW VARIABLES LIKE '%sort%';
SHOW VARIABLES LIKE '%tmp%';

-- 关键参数说明：
-- sort_buffer_size: 每个连接的排序缓冲区大小
-- max_length_for_sort_data: 排序时单行最大长度
-- tmp_table_size: 内存临时表大小限制
-- max_heap_table_size: MEMORY引擎表最大大小
```

### 3.2 内存使用策略


**🔸 排序内存分配机制**

```
内存排序决策流程：
数据大小 ≤ sort_buffer_size ──Yes──▶ 内存排序（快速）
    │                               ↓
    │                        QuickSort算法
    │                               ↓
    └──No──▶ 磁盘排序（慢速） ──▶ 临时文件 ──▶ 归并排序
                 ↓                    ↓
          分块处理              多路归并算法
```

> 🚨 **重要提醒**  
> sort_buffer_size不是越大越好！过大的缓冲区可能导致内存不足，反而触发磁盘排序。推荐值：256KB-2MB。

**🔸 内存优化配置**

```sql
-- 针对窗口函数优化的内存配置
SET SESSION sort_buffer_size = 2097152;    -- 2MB排序缓冲
SET SESSION tmp_table_size = 67108864;     -- 64MB临时表
SET SESSION max_heap_table_size = 67108864; -- 64MB堆表

-- 监控内存使用情况
SHOW STATUS LIKE 'Sort_merge_passes';  -- 归并排序次数
SHOW STATUS LIKE 'Sort_scan';          -- 排序扫描次数
SHOW STATUS LIKE 'Created_tmp_tables'; -- 创建临时表数量
```

### 3.3 大数据集内存管理


**🔸 分批处理策略**

```sql
-- ❌ 一次性处理大数据集
SELECT customer_id, order_date, amount,
  SUM(amount) OVER(PARTITION BY customer_id ORDER BY order_date 
                   ROWS UNBOUNDED PRECEDING) as running_total
FROM orders  -- 假设1000万条记录
ORDER BY customer_id, order_date;

-- ✅ 分批处理优化
WITH customer_batch AS (
  SELECT customer_id, order_date, amount
  FROM orders 
  WHERE customer_id BETWEEN 1 AND 10000  -- 分批处理
)
SELECT customer_id, order_date, amount,
  SUM(amount) OVER(PARTITION BY customer_id ORDER BY order_date 
                   ROWS UNBOUNDED PRECEDING) as running_total
FROM customer_batch
ORDER BY customer_id, order_date;
```

---

## 4. 🎯 分区策略优化


### 4.1 分区设计原则


**🔸 什么是好的分区策略**
分区就像把学生按班级分组排队，好的分区策略应该：

> 💡 **分区优化目标**  
> - **均匀分布**：每个分区大小相近，避免数据倾斜
> - **减少跨分区**：相关数据尽量在同一分区
> - **利用索引**：分区字段有索引支持

**🔸 分区大小对性能的影响**

| 分区大小 | **性能特点** | **适用场景** | **注意事项** |
|---------|-------------|-------------|-------------|
| 🔸 **小分区(<1000行)** | `快速处理，低内存` | `实时查询` | `可能过度分区` |
| 🔸 **中分区(1000-10万行)** | `平衡性能和内存` | `常规分析` | `最佳实践范围` |
| 🔸 **大分区(>10万行)** | `高内存需求` | `批处理任务` | `需要大内存配置` |

### 4.2 分区优化实例


**🔸 时间分区优化**

```sql
-- ❌ 不合理的时间分区
SELECT user_id, login_time, session_duration,
  AVG(session_duration) OVER(
    PARTITION BY DATE(login_time)  -- 按天分区，可能数据倾斜
    ORDER BY login_time
    ROWS BETWEEN 10 PRECEDING AND CURRENT ROW
  ) as avg_duration
FROM user_sessions
WHERE login_time >= '2024-01-01';

-- ✅ 优化后的时间分区
SELECT user_id, login_time, session_duration,
  AVG(session_duration) OVER(
    PARTITION BY user_id, DATE(login_time)  -- 按用户+天分区
    ORDER BY login_time
    ROWS BETWEEN 10 PRECEDING AND CURRENT ROW
  ) as avg_duration
FROM user_sessions
WHERE login_time >= '2024-01-01'
  AND user_id BETWEEN 1 AND 1000;  -- 限制数据量
```

**🔸 业务逻辑分区优化**

```sql
-- 优化前：单一分区字段
SELECT product_id, sale_date, quantity, price,
  SUM(quantity * price) OVER(
    PARTITION BY product_id  -- 可能导致某些热门商品分区过大
    ORDER BY sale_date
  ) as cumulative_revenue
FROM sales;

-- 优化后：多字段分区
SELECT product_id, sale_date, quantity, price,
  SUM(quantity * price) OVER(
    PARTITION BY category_id, YEAR(sale_date), QUARTER(sale_date)
    ORDER BY sale_date
  ) as quarterly_cumulative_revenue
FROM sales s
JOIN products p ON s.product_id = p.product_id;
```

### 4.3 分区数据倾斜处理


**🔸 识别数据倾斜**

```sql
-- 检查分区数据分布
SELECT department, COUNT(*) as record_count,
  ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM employees), 2) as percentage
FROM employees
GROUP BY department
ORDER BY record_count DESC;

-- 结果示例：
-- IT部门: 50000条 (50%)  -- 数据倾斜严重
-- 销售部: 20000条 (20%)
-- 财务部: 15000条 (15%)
-- 其他部门: 各5000条以下
```

**🔸 数据倾斜解决方案**

```sql
-- ✅ 解决方案1：多级分区
SELECT employee_id, department, hire_year, salary,
  DENSE_RANK() OVER(
    PARTITION BY department, hire_year  -- 增加时间维度分区
    ORDER BY salary DESC
  ) as dept_year_rank
FROM employees;

-- ✅ 解决方案2：采样分区
WITH sampled_data AS (
  SELECT * FROM employees
  WHERE department = 'IT' 
    AND employee_id % 10 = 0  -- 对大分区进行采样
  UNION ALL
  SELECT * FROM employees
  WHERE department != 'IT'
)
SELECT department, salary,
  PERCENTILE_CONT(0.5) OVER(PARTITION BY department) as median_salary
FROM sampled_data;
```

---

## 5. 🗂️ 索引利用优化


### 5.1 窗口函数索引设计


**🔸 索引对窗口函数的作用**
索引对窗口函数就像图书馆的分类目录，可以大大减少"查找和排序"的工作量：

```sql
-- 窗口函数的索引需求分析
SELECT department, employee_id, salary,
  ROW_NUMBER() OVER(
    PARTITION BY department    -- 需要department索引
    ORDER BY salary DESC      -- 需要salary索引  
  ) as salary_rank
FROM employees
WHERE hire_date > '2020-01-01';  -- 需要hire_date索引
```

**🔸 复合索引设计策略**

```sql
-- ✅ 最优索引设计
CREATE INDEX idx_emp_optimal 
ON employees(department, salary DESC, hire_date);

-- 索引字段顺序说明：
-- 1. department: 分区字段，第一优先级
-- 2. salary DESC: 排序字段，第二优先级  
-- 3. hire_date: WHERE条件，第三优先级
```

### 5.2 索引覆盖优化


**🔸 什么是索引覆盖**
索引覆盖就像把需要的所有信息都写在书的目录上，不用翻到正文页面：

```sql
-- ❌ 未覆盖索引（需要回表）
SELECT employee_id, department, salary, bonus,  -- bonus不在索引中
  SUM(salary + bonus) OVER(PARTITION BY department) as total_comp
FROM employees;

-- ✅ 覆盖索引优化
CREATE INDEX idx_emp_covering 
ON employees(department, salary, bonus, employee_id);

-- 现在查询完全使用索引，无需回表
```

**🔸 覆盖索引性能对比**

| 索引类型 | **回表次数** | **IO成本** | **性能提升** |
|---------|-------------|-----------|-------------|
| 🔸 **普通索引** | `每行都回表` | `2倍以上IO` | `基准性能` |
| 🔸 **覆盖索引** | `无需回表` | `仅索引IO` | `2-5倍提升` |

### 5.3 排序索引优化


**🔸 排序索引匹配规则**

```sql
-- ✅ 完全匹配排序索引
CREATE INDEX idx_sales_sort ON sales(region, product_type, sale_date DESC);

SELECT region, product_type, sale_date, amount,
  SUM(amount) OVER(
    PARTITION BY region, product_type  -- 匹配索引前缀
    ORDER BY sale_date DESC           -- 匹配索引排序
  ) as cumulative_sales
FROM sales;

-- 执行计划显示：Using index; Using temporary
-- 说明：使用了索引，但仍需临时表处理窗口函数
```

**🔸 部分匹配的性能影响**

```sql
-- ❌ 部分匹配索引（性能较差）
SELECT region, product_type, sale_date, amount,
  SUM(amount) OVER(
    PARTITION BY region              -- 只匹配索引第一列
    ORDER BY amount DESC            -- 未匹配索引排序字段
  ) as cumulative_sales
FROM sales;

-- 执行计划：Using index condition; Using filesort
-- 说明：需要额外的文件排序操作
```

---

## 6. 📊 大数据集处理策略


### 6.1 数据量分级处理


**🔸 按数据量级选择策略**

| 数据量级 | **处理策略** | **技术要点** | **性能预期** |
|---------|-------------|-------------|-------------|
| 🟢 **小数据(<10万)** | `直接处理` | `标准窗口函数` | `秒级响应` |
| 🟡 **中数据(10万-100万)** | `分批优化` | `增大内存配置` | `分钟级完成` |
| 🔴 **大数据(>100万)** | `分段处理` | `分区+物化` | `小时级批处理` |

### 6.2 分段处理技术


**🔸 时间窗口分段**

```sql
-- 大数据集分段处理示例
-- 处理一年的销售数据，按月分段

-- 创建月度汇总函数
DELIMITER $$
CREATE PROCEDURE ProcessMonthlyWindow(IN target_month VARCHAR(7))
BEGIN
  -- 处理指定月份的窗口计算
  INSERT INTO monthly_sales_analysis
  SELECT 
    DATE_FORMAT(sale_date, '%Y-%m') as month,
    product_id, 
    customer_id,
    sale_amount,
    SUM(sale_amount) OVER(
      PARTITION BY product_id 
      ORDER BY sale_date 
      ROWS UNBOUNDED PRECEDING
    ) as product_cumulative,
    AVG(sale_amount) OVER(
      PARTITION BY customer_id 
      ORDER BY sale_date 
      ROWS BETWEEN 30 PRECEDING AND CURRENT ROW
    ) as customer_30day_avg
  FROM sales 
  WHERE DATE_FORMAT(sale_date, '%Y-%m') = target_month;
END$$
DELIMITER ;

-- 批量执行
CALL ProcessMonthlyWindow('2024-01');
CALL ProcessMonthlyWindow('2024-02');
-- ... 继续处理其他月份
```

### 6.3 并行处理优化


**🔸 并行处理架构**

```
并行窗口处理架构：
          主查询
             │
    ┌────────┼────────┐
    │        │        │
 分区1    分区2    分区3
(线程1)  (线程2)  (线程3)
    │        │        │
    └────────┼────────┘
           结果汇总
```

**🔸 实现并行处理**

```sql
-- 方案1：使用分区表并行
CREATE TABLE sales_partitioned (
  sale_id INT,
  sale_date DATE,
  product_id INT,
  amount DECIMAL(10,2)
) PARTITION BY RANGE(YEAR(sale_date)) (
  PARTITION p2022 VALUES LESS THAN (2023),
  PARTITION p2023 VALUES LESS THAN (2024),
  PARTITION p2024 VALUES LESS THAN (2025)
);

-- 方案2：使用UNION ALL并行处理
SELECT * FROM (
  SELECT product_id, sale_date, amount,
    ROW_NUMBER() OVER(PARTITION BY product_id ORDER BY sale_date) as rn
  FROM sales WHERE YEAR(sale_date) = 2022
  
  UNION ALL
  
  SELECT product_id, sale_date, amount,
    ROW_NUMBER() OVER(PARTITION BY product_id ORDER BY sale_date) as rn
  FROM sales WHERE YEAR(sale_date) = 2023
  
  UNION ALL
  
  SELECT product_id, sale_date, amount,
    ROW_NUMBER() OVER(PARTITION BY product_id ORDER BY sale_date) as rn
  FROM sales WHERE YEAR(sale_date) = 2024
) combined_results
ORDER BY product_id, sale_date;
```

---

## 7. 🔄 窗口函数物化技术


### 7.1 什么是窗口函数物化


**🔸 物化概念理解**
窗口函数物化就像提前做好的"半成品菜"，把复杂的窗口计算结果先存储起来，需要时直接使用：

> 💡 **物化的好处**  
> - **减少重复计算**：一次计算，多次使用
> - **提升查询速度**：避免实时复杂运算  
> - **降低系统负载**：减少CPU和内存消耗

### 7.2 物化视图实现


**🔸 创建物化窗口计算**

```sql
-- 创建物化表存储窗口函数结果
CREATE TABLE employee_rankings AS
SELECT 
  employee_id,
  department,
  salary,
  hire_date,
  -- 预计算各种排名
  ROW_NUMBER() OVER(PARTITION BY department ORDER BY salary DESC) as salary_rank,
  DENSE_RANK() OVER(PARTITION BY department ORDER BY salary DESC) as salary_dense_rank,
  PERCENT_RANK() OVER(PARTITION BY department ORDER BY salary DESC) as salary_percentile,
  -- 预计算移动平均
  AVG(salary) OVER(
    PARTITION BY department 
    ORDER BY hire_date 
    ROWS BETWEEN 5 PRECEDING AND CURRENT ROW
  ) as salary_moving_avg,
  -- 预计算累计统计
  SUM(salary) OVER(PARTITION BY department ORDER BY hire_date) as dept_cumulative_salary,
  created_at = NOW()
FROM employees;

-- 创建索引提升查询性能
CREATE INDEX idx_emp_rank_dept_rank ON employee_rankings(department, salary_rank);
CREATE INDEX idx_emp_rank_updated ON employee_rankings(created_at);
```

**🔸 物化表维护策略**

```sql
-- 增量更新策略
DELIMITER $$
CREATE PROCEDURE RefreshEmployeeRankings()
BEGIN
  DECLARE last_update DATETIME;
  
  -- 获取上次更新时间
  SELECT MAX(created_at) INTO last_update FROM employee_rankings;
  
  -- 删除变更相关的记录
  DELETE FROM employee_rankings 
  WHERE department IN (
    SELECT DISTINCT department 
    FROM employees 
    WHERE updated_at > last_update
  );
  
  -- 重新计算变更部门的排名
  INSERT INTO employee_rankings
  SELECT 
    employee_id, department, salary, hire_date,
    ROW_NUMBER() OVER(PARTITION BY department ORDER BY salary DESC) as salary_rank,
    -- ... 其他窗口函数计算
    NOW() as created_at
  FROM employees 
  WHERE department IN (
    SELECT DISTINCT department 
    FROM employees 
    WHERE updated_at > last_update
  );
END$$
DELIMITER ;

-- 定期执行更新（通过定时任务）
-- 每天凌晨2点更新
-- 0 2 * * * mysql -u user -p database -e "CALL RefreshEmployeeRankings();"
```

### 7.3 临时物化策略


**🔸 会话级临时物化**

```sql
-- 创建临时表进行物化
CREATE TEMPORARY TABLE temp_sales_analysis AS
SELECT 
  customer_id,
  order_date,
  order_amount,
  -- 复杂窗口计算一次完成
  SUM(order_amount) OVER(
    PARTITION BY customer_id 
    ORDER BY order_date 
    ROWS UNBOUNDED PRECEDING
  ) as customer_lifetime_value,
  AVG(order_amount) OVER(
    PARTITION BY customer_id 
    ORDER BY order_date 
    ROWS BETWEEN 12 PRECEDING AND CURRENT ROW
  ) as customer_avg_12_orders
FROM orders 
WHERE order_date >= DATE_SUB(CURDATE(), INTERVAL 2 YEAR);

-- 后续查询直接使用物化结果
SELECT customer_id, 
  MAX(customer_lifetime_value) as ltv,
  AVG(customer_avg_12_orders) as avg_order_value
FROM temp_sales_analysis 
WHERE customer_lifetime_value > 10000
GROUP BY customer_id;
```

---

## 8. 🚀 性能调优实战指南


### 8.1 窗口函数性能调优核心策略


**🔸 调优决策流程**

```
性能问题诊断流程：
查询执行时间过长
         │
    ┌────▼────┐
    │执行计划分析│
    └────┬────┘
         │
    ┌────▼────┐
    │瓶颈点识别│  ──▶ 排序瓶颈 ──▶ 优化索引/增大内存
    └────┬────┘  ──▶ IO瓶颈   ──▶ 分区策略/物化
         │        ──▶ 内存瓶颈 ──▶ 调整配置/分批处理
    ┌────▼────┐
    │优化方案实施│
    └────┬────┘
         │
    ┌────▼────┐
    │效果验证│
    └─────────┘
```

### 8.2 大数据窗口查询优化


**🔸 综合优化案例**

```sql
-- 原始查询（性能较差）
SELECT 
  customer_id,
  order_id, 
  order_date,
  amount,
  -- 计算客户累计消费（可能涉及百万级数据）
  SUM(amount) OVER(
    PARTITION BY customer_id 
    ORDER BY order_date 
    ROWS UNBOUNDED PRECEDING
  ) as cumulative_amount,
  -- 计算3个月移动平均
  AVG(amount) OVER(
    PARTITION BY customer_id 
    ORDER BY order_date 
    RANGE BETWEEN INTERVAL '3' MONTH PRECEDING AND CURRENT ROW
  ) as moving_avg_3month
FROM orders 
WHERE order_date >= '2020-01-01'
ORDER BY customer_id, order_date;
```

**🔸 分步优化实现**

```sql
-- 步骤1：创建优化索引
CREATE INDEX idx_orders_optimized 
ON orders(customer_id, order_date, amount, order_id);

-- 步骤2：分区处理大数据
-- 2.1 创建年度汇总表
CREATE TABLE customer_annual_summary (
  customer_id INT,
  year INT,
  total_orders INT,
  total_amount DECIMAL(15,2),
  avg_order_amount DECIMAL(10,2),
  PRIMARY KEY (customer_id, year)
);

-- 2.2 按年度预计算基础数据
INSERT INTO customer_annual_summary
SELECT 
  customer_id,
  YEAR(order_date) as year,
  COUNT(*) as total_orders,
  SUM(amount) as total_amount,
  AVG(amount) as avg_order_amount
FROM orders 
GROUP BY customer_id, YEAR(order_date);

-- 步骤3：优化的增量查询
WITH customer_monthly AS (
  -- 只查询最近一年的详细数据
  SELECT 
    customer_id,
    order_id,
    order_date,
    amount,
    YEAR(order_date) as order_year,
    MONTH(order_date) as order_month
  FROM orders 
  WHERE order_date >= DATE_SUB(CURDATE(), INTERVAL 12 MONTH)
),
historical_totals AS (
  -- 获取历史累计金额
  SELECT 
    customer_id,
    SUM(total_amount) as historical_total
  FROM customer_annual_summary
  WHERE year < YEAR(CURDATE())
  GROUP BY customer_id
)
SELECT 
  cm.customer_id,
  cm.order_id,
  cm.order_date,
  cm.amount,
  -- 结合历史数据计算累计金额
  COALESCE(ht.historical_total, 0) + 
  SUM(cm.amount) OVER(
    PARTITION BY cm.customer_id 
    ORDER BY cm.order_date 
    ROWS UNBOUNDED PRECEDING
  ) as cumulative_amount,
  -- 移动平均计算
  AVG(cm.amount) OVER(
    PARTITION BY cm.customer_id 
    ORDER BY cm.order_date 
    ROWS BETWEEN 10 PRECEDING AND CURRENT ROW
  ) as moving_avg_10orders
FROM customer_monthly cm
LEFT JOIN historical_totals ht ON cm.customer_id = ht.customer_id
ORDER BY cm.customer_id, cm.order_date;
```

### 8.3 性能监控与调优


**🔸 关键监控指标**

```sql
-- 监控窗口函数性能的关键指标
-- 1. 查询执行时间监控
SELECT 
  DIGEST_TEXT,
  COUNT_STAR as exec_count,
  AVG_TIMER_WAIT/1000000000 as avg_exec_time_sec,
  MAX_TIMER_WAIT/1000000000 as max_exec_time_sec
FROM performance_schema.events_statements_summary_by_digest
WHERE DIGEST_TEXT LIKE '%OVER%'
ORDER BY avg_exec_time_sec DESC
LIMIT 10;

-- 2. 临时表使用监控
SHOW STATUS LIKE 'Created_tmp%';

-- 3. 排序操作监控  
SHOW STATUS LIKE 'Sort_%';

-- 4. 内存使用监控
SELECT 
  EVENT_NAME,
  CURRENT_NUMBER_OF_BYTES_USED/1024/1024 as memory_mb
FROM performance_schema.memory_summary_global_by_event_name
WHERE EVENT_NAME LIKE '%sort%' OR EVENT_NAME LIKE '%tmp%'
ORDER BY CURRENT_NUMBER_OF_BYTES_USED DESC;
```

**🔸 自动优化建议脚本**

```sql
DELIMITER $$
CREATE PROCEDURE AnalyzeWindowPerformance()
BEGIN
  DECLARE done INT DEFAULT FALSE;
  DECLARE slow_query TEXT;
  DECLARE exec_time DECIMAL(10,2);
  
  -- 声明游标查找慢窗口查询
  DECLARE cur CURSOR FOR 
    SELECT DIGEST_TEXT, AVG_TIMER_WAIT/1000000000
    FROM performance_schema.events_statements_summary_by_digest
    WHERE DIGEST_TEXT LIKE '%OVER%' 
      AND AVG_TIMER_WAIT/1000000000 > 5.0
    ORDER BY AVG_TIMER_WAIT DESC;
    
  DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
  
  -- 创建建议表
  CREATE TEMPORARY TABLE IF NOT EXISTS optimization_suggestions (
    query_digest TEXT,
    execution_time DECIMAL(10,2),
    suggestion TEXT
  );
  
  OPEN cur;
  read_loop: LOOP
    FETCH cur INTO slow_query, exec_time;
    IF done THEN
      LEAVE read_loop;
    END IF;
    
    -- 根据查询特征给出优化建议
    INSERT INTO optimization_suggestions VALUES (
      slow_query,
      exec_time,
      CASE 
        WHEN slow_query LIKE '%PARTITION BY%ORDER BY%' THEN
          '建议：创建包含分区和排序字段的复合索引'
        WHEN slow_query LIKE '%ROWS BETWEEN%PRECEDING%' THEN
          '建议：考虑增加sort_buffer_size或使用物化视图'
        WHEN slow_query LIKE '%SUM%OVER%' OR slow_query LIKE '%AVG%OVER%' THEN
          '建议：考虑预计算聚合结果并定期更新'
        ELSE
          '建议：分析执行计划，考虑分区或分批处理'
      END
    );
  END LOOP;
  
  CLOSE cur;
  
  -- 输出优化建议
  SELECT * FROM optimization_suggestions;
END$$
DELIMITER ;

-- 执行性能分析
CALL AnalyzeWindowPerformance();
```

---

## 9. 📋 核心要点总结


### 9.1 性能优化要点梳理


**🔑 窗口函数性能优化核心策略**

> 💡 **优化思维模式**  
> 窗口函数优化就像优化工厂流水线：先找到瓶颈环节，然后针对性改进。通常瓶颈在排序和内存使用上。

| 优化层面 | **关键策略** | **实施要点** | **预期效果** |
|---------|-------------|-------------|-------------|
| 🔍 **执行计划** | `分析瓶颈点` | `EXPLAIN查看排序成本` | `定位问题根源` |
| 💾 **内存管理** | `优化缓冲区配置` | `调整sort_buffer_size` | `减少磁盘排序` |
| 🗂️ **索引策略** | `创建复合索引` | `分区+排序字段组合` | `避免文件排序` |
| 📊 **分区设计** | `均衡数据分布` | `避免热点分区` | `提升并行度` |
| 🔄 **物化技术** | `预计算结果` | `定期更新策略` | `大幅提升查询速度` |

### 9.2 大数据处理最佳实践


**🔸 数据量级处理指导**

```
小数据(<10万行)：
├── 直接使用标准窗口函数
├── 创建基础索引支持
└── 监控执行时间即可

中等数据(10万-100万行)：  
├── 优化内存配置参数
├── 创建复合索引
├── 考虑分区策略
└── 监控临时表使用

大数据(>100万行)：
├── 必须使用分区处理
├── 实施物化策略
├── 分批处理机制
└── 并行处理架构
```

### 9.3 性能调优检查清单


**🔸 优化实施检查表**

- [x] **执行计划分析**: 检查是否有不必要的排序操作
- [x] **索引优化**: 确保分区和排序字段有合适索引
- [x] **内存配置**: 根据数据量调整相关内存参数
- [x] **分区策略**: 避免数据倾斜，保持分区均衡
- [x] **物化应用**: 对于重复查询考虑物化技术
- [ ] **并行处理**: 大数据集考虑并行处理架构
- [ ] **监控体系**: 建立性能监控和自动优化机制

### 9.4 实战应用指导


**🔸 优化决策树**

```
窗口查询性能问题
         │
    执行时间 > 10秒？
    ├─No─▶ 轻微优化(索引+配置)
    └─Yes
         │
    数据量 > 100万？
    ├─No─▶ 中等优化(分区+内存)  
    └─Yes
         │
    重复查询？
    ├─Yes─▶ 物化优化
    └─No─▶ 分批+并行处理
```

**🚀 下一步学习建议**

- **深入学习**: MySQL执行引擎原理和查询优化器机制
- **实践项目**: 在实际业务中应用窗口函数优化技术
- **监控工具**: 掌握performance_schema性能监控
- **架构设计**: 学习分布式数据库中的窗口函数处理

---

**💡 核心记忆要点**：
- 窗口函数性能瓶颈主要在排序和内存使用
- 合理的分区策略是性能优化的基础  
- 索引设计要同时考虑分区字段和排序字段
- 大数据集处理必须采用分段和物化策略
- 性能监控和持续优化是长期任务