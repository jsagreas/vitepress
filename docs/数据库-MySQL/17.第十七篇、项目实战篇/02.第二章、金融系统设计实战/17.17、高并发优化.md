---
title: 17、高并发优化
---
## 📚 目录

1. [高并发优化概述](#1-高并发优化概述)
2. [数据库分片策略](#2-数据库分片策略)
3. [读写分离架构](#3-读写分离架构)
4. [缓存系统设计](#4-缓存系统设计)
5. [连接池优化](#5-连接池优化)
6. [SQL查询优化](#6-sql查询优化)
7. [热点数据处理](#7-热点数据处理)
8. [微服务架构优化](#8-微服务架构优化)
9. [消息队列异步处理](#9-消息队列异步处理)
10. [限流降级策略](#10-限流降级策略)
11. [并发控制与锁优化](#11-并发控制与锁优化)
12. [性能监控体系](#12-性能监控体系)
13. [核心要点总结](#13-核心要点总结)

---

## 1. 🚀 高并发优化概述


### 1.1 什么是高并发


💭 **思考一下**：想象一下双11购物节，几千万用户同时抢购商品，这就是典型的高并发场景。

**🏷️ 专业术语**：`高并发` = 大量用户在短时间内同时访问系统

```
现实场景对比：
平时商场：100人/小时 → 轻松应对
双11抢购：10000人/秒 → 系统压力巨大

数据库表现：
正常情况：100 QPS (每秒查询数)
高并发：10000+ QPS → 需要特殊处理
```

### 1.2 高并发带来的挑战


**🔍 深入理解**：高并发不只是访问量大，更是对系统各个环节的极限测试

| **挑战类型** | **具体表现** | **影响结果** |
|-------------|-------------|-------------|
| **数据库压力** | `连接数爆满、查询慢` | 用户等待超时 |
| **内存不足** | `缓存失效、频繁GC` | 响应时间增加 |
| **网络拥塞** | `带宽占满、丢包` | 请求失败 |
| **CPU瓶颈** | `处理能力不足` | 系统假死 |

**🌰 举个例子**：
```
12306抢票系统的痛点：
• 春运期间：亿级用户同时抢票
• 数据库压力：每秒几万次查询
• 结果：系统崩溃，用户体验极差
```

### 1.3 优化的核心思路


**📋 知识清单**：
- ✅ **分流**：把大量请求分散到多个服务器
- ✅ **缓存**：把热点数据放在内存中快速读取  
- ✅ **异步**：耗时操作放到后台处理
- ✅ **限流**：控制同时处理的请求数量

---

## 2. 🔄 数据库分片策略


### 2.1 什么是数据库分片


**🔄 换句话说**：分片就像把一个大餐厅拆成几个小餐厅，每个餐厅服务一部分客户。

```
单库场景：
所有数据 → [MySQL数据库] → 压力集中

分片场景：
用户1-1000万  → [分片1] 
用户1000万-2000万 → [分片2]  
用户2000万-3000万 → [分片3]
```

### 2.2 水平分片策略


**🎯 学习目标**：掌握如何按数据特征进行分片

**📊 常用分片方式**：

**按用户ID分片（推荐）**：
```sql
-- 分片规则：user_id % 4
-- 用户123456 → 123456 % 4 = 0 → 分片0
-- 用户123457 → 123457 % 4 = 1 → 分片1

CREATE TABLE user_info_0 (
    user_id BIGINT PRIMARY KEY,
    username VARCHAR(50),
    email VARCHAR(100)
);

CREATE TABLE user_info_1 (
    user_id BIGINT PRIMARY KEY, 
    username VARCHAR(50),
    email VARCHAR(100)
);
```

**按时间分片**：
```sql
-- 按月分表，适合订单、日志等数据
CREATE TABLE orders_202501 (
    order_id BIGINT PRIMARY KEY,
    user_id BIGINT,
    create_time DATETIME
);

CREATE TABLE orders_202502 (
    order_id BIGINT PRIMARY KEY,
    user_id BIGINT, 
    create_time DATETIME
);
```

### 2.3 分片中间件选择


| **中间件** | **优点** | **缺点** | **适用场景** |
|-----------|---------|---------|-------------|
| **ShardingSphere** | `功能全面、社区活跃` | 学习成本较高 | 复杂业务系统 |
| **MyCat** | `配置简单、性能好` | 功能相对基础 | 中小型项目 |
| **应用层分片** | `灵活可控` | 开发工作量大 | 定制化需求 |

**💡 实际应用**：
```java
// 简单的应用层分片逻辑
public String getShardTable(Long userId) {
    int shard = (int)(userId % 4);
    return "user_info_" + shard;
}

// 动态SQL执行
String tableName = getShardTable(userId);
String sql = "SELECT * FROM " + tableName + " WHERE user_id = ?";
```

---

## 3. ⚖️ 读写分离架构


### 3.1 读写分离的核心原理


**🤔 为什么这样**：大多数系统都是读多写少（比如新闻网站：1次发布，万次阅读）

```
传统架构：
应用 → [主数据库] ← 读写压力都在这里

读写分离：
应用 → [主库-写] → 同步数据 → [从库-读]
      ↓写操作              ↗读操作
    压力分散
```

### 3.2 主从复制配置


**🛠️ 工具推荐**：MySQL自带的主从复制功能

**主库配置**：
```ini
# my.cnf 主库配置
[mysqld]
server-id = 1                # 唯一标识
log-bin = mysql-bin         # 开启二进制日志
binlog-do-db = finance_db   # 指定同步的数据库
```

**从库配置**：
```ini
# my.cnf 从库配置  
[mysqld]
server-id = 2               # 唯一标识，不能重复
relay-log = relay-bin       # 中继日志
read-only = 1              # 只读模式
```

### 3.3 应用层读写分离


**🔧 解决方案**：通过代码控制读写请求的路由

```java
@Service
public class UserService {
    
    @Autowired
    private DataSource masterDataSource;  // 主库
    
    @Autowired  
    private DataSource slaveDataSource;   // 从库
    
    // 写操作-使用主库
    public void createUser(User user) {
        JdbcTemplate master = new JdbcTemplate(masterDataSource);
        master.update("INSERT INTO users VALUES (?,?)", 
                     user.getId(), user.getName());
    }
    
    // 读操作-使用从库
    public User getUser(Long id) {
        JdbcTemplate slave = new JdbcTemplate(slaveDataSource);
        return slave.queryForObject("SELECT * FROM users WHERE id = ?",
                                   User.class, id);
    }
}
```

**⚠️ 重要提醒**：主从延迟问题
```
问题场景：
1. 用户注册 → 写入主库
2. 立即跳转个人页面 → 从从库读取  
3. 如果主从同步延迟 → 读不到刚写入的数据

解决方案：
• 重要操作后短时间内强制读主库
• 使用缓存缓冲延迟
• 业务上容忍短暂的数据不一致
```

---

## 4. 💾 缓存系统设计


### 4.1 缓存的作用机制


**🌰 举个例子**：缓存就像餐厅的备菜台，热门菜品提前准备好，客人点菜时立即提供。

```
无缓存流程：
用户请求 → 查数据库 → 返回结果 (100ms)

有缓存流程：  
用户请求 → 查缓存 → 命中返回 (1ms)
          ↓未命中
         查数据库 → 写缓存 → 返回 (100ms，但下次1ms)
```

### 4.2 多级缓存架构


**🏗️ 知识架构**：
```
[ 应用服务器 ]
       ↓
   [本地缓存]     ← 1级：最快，容量小
       ↓
   [Redis集群]    ← 2级：较快，容量中等  
       ↓
   [MySQL数据库]  ← 3级：最慢，容量大
```

**代码实现**：
```java
@Service
public class CacheService {
    
    private Map<String, Object> localCache = new ConcurrentHashMap<>();
    
    @Autowired
    private RedisTemplate<String, Object> redisTemplate;
    
    public Object getData(String key) {
        // 1. 先查本地缓存
        Object data = localCache.get(key);
        if (data != null) {
            return data;  // 1ms
        }
        
        // 2. 查Redis缓存
        data = redisTemplate.opsForValue().get(key);
        if (data != null) {
            localCache.put(key, data);  // 回写本地缓存
            return data;  // 5ms
        }
        
        // 3. 查数据库
        data = queryFromDatabase(key);
        
        // 4. 写入缓存
        redisTemplate.opsForValue().set(key, data, 3600, TimeUnit.SECONDS);
        localCache.put(key, data);
        
        return data;  // 100ms
    }
}
```

### 4.3 缓存更新策略


| **策略** | **说明** | **优点** | **缺点** | **适用场景** |
|---------|---------|---------|---------|-------------|
| **Cache Aside** | `应用负责缓存更新` | 逻辑清晰 | 代码复杂 | 一般业务 |
| **Write Through** | `写数据库同时写缓存` | 数据一致性好 | 写入变慢 | 强一致性需求 |
| **Write Behind** | `异步写入数据库` | 写入快速 | 可能丢数据 | 高性能需求 |

**🎯 最佳实践**：
```java
// 更新用户信息的缓存策略
public void updateUser(User user) {
    // 1. 先删除缓存(避免脏数据)
    redisTemplate.delete("user:" + user.getId());
    
    // 2. 更新数据库
    userDao.update(user);
    
    // 3. 不立即写缓存，等下次查询时再写入
    // 这样避免了缓存写入失败的问题
}
```

---

## 5. 🔗 连接池优化


### 5.1 连接池的重要性


**💭 思考一下**：如果每次数据库操作都要重新建立连接，就像每次打电话都要重新拨号一样低效。

**数据库连接过程**：
```
无连接池：
请求 → 建立连接(50ms) → 执行SQL(10ms) → 关闭连接(20ms) = 80ms

有连接池：
请求 → 从池中获取连接(1ms) → 执行SQL(10ms) → 归还连接(1ms) = 12ms
```

### 5.2 连接池关键参数


**📋 重要配置参数**：

```properties
# HikariCP 连接池配置（Spring Boot默认）
spring.datasource.hikari.minimum-idle=10          # 最小空闲连接
spring.datasource.hikari.maximum-pool-size=20     # 最大连接数  
spring.datasource.hikari.idle-timeout=300000      # 空闲超时(5分钟)
spring.datasource.hikari.max-lifetime=1800000     # 连接最大存活时间(30分钟)
spring.datasource.hikari.connection-timeout=20000 # 获取连接超时(20秒)
```

**🔍 参数调优指南**：
- **最大连接数**：`CPU核心数 × 2` 是一个好的起点
- **最小空闲连接数**：保持一定数量避免频繁创建
- **超时时间**：根据业务SQL执行时间调整

### 5.3 连接池监控


```java
@Component
public class DataSourceMonitor {
    
    @Autowired
    private HikariDataSource dataSource;
    
    @Scheduled(fixedRate = 60000)  // 每分钟检查
    public void monitorConnections() {
        HikariPoolMXBean poolBean = dataSource.getHikariPoolMXBean();
        
        int active = poolBean.getActiveConnections();      // 活跃连接
        int idle = poolBean.getIdleConnections();          // 空闲连接
        int total = poolBean.getTotalConnections();        // 总连接数
        
        logger.info("连接池状态 - 活跃:{} 空闲:{} 总计:{}", active, idle, total);
        
        // 连接池告警
        if (active > total * 0.8) {
            logger.warn("连接池使用率超过80%，需要关注！");
        }
    }
}
```

---

## 6. ⚡ SQL查询优化


### 6.1 慢查询识别


**🚨 重要提醒**：慢查询是系统性能的隐形杀手，必须重点关注。

**开启慢查询日志**：
```sql
-- 查看慢查询配置
SHOW VARIABLES LIKE '%slow_query%';

-- 开启慢查询日志
SET GLOBAL slow_query_log = 'ON';
SET GLOBAL long_query_time = 2;  -- 超过2秒的查询记录
```

**分析慢查询**：
```sql
-- 查看慢查询统计
SHOW STATUS LIKE '%slow_queries%';

-- 使用EXPLAIN分析查询计划
EXPLAIN SELECT * FROM orders o 
JOIN users u ON o.user_id = u.user_id 
WHERE o.create_time > '2024-01-01';
```

### 6.2 索引优化策略


**🎓 学习建议**：索引就像书的目录，帮助快速找到需要的内容。

**索引创建原则**：
```sql
-- 1. 单列索引：经常出现在WHERE条件的列
CREATE INDEX idx_user_email ON users(email);

-- 2. 复合索引：多个条件同时查询的列  
CREATE INDEX idx_order_user_time ON orders(user_id, create_time);

-- 3. 覆盖索引：SELECT的列都包含在索引中
CREATE INDEX idx_order_cover ON orders(user_id, create_time, amount);
```

**❌ 常见误解**：索引越多越好
**✅ 正确理解**：索引提高查询速度，但会降低写入速度

### 6.3 查询语句优化


**🔧 常用优化技巧**：

```sql
-- 优化前：SELECT *  
SELECT * FROM orders WHERE user_id = 123;

-- 优化后：只查询需要的列
SELECT order_id, amount, create_time 
FROM orders WHERE user_id = 123;

-- 优化前：使用函数
SELECT * FROM orders WHERE DATE(create_time) = '2024-01-01';

-- 优化后：范围查询
SELECT * FROM orders 
WHERE create_time >= '2024-01-01 00:00:00' 
  AND create_time < '2024-01-02 00:00:00';
```

**分页查询优化**：
```sql  
-- 传统分页（大偏移量慢）
SELECT * FROM orders ORDER BY id LIMIT 100000, 20;

-- 优化方案：基于ID的分页
SELECT * FROM orders WHERE id > 100000 ORDER BY id LIMIT 20;
```

---

## 7. 🔥 热点数据处理


### 7.1 热点数据识别


**🌰 举个例子**：双11期间，某个爆款商品被疯狂查询，成为热点数据。

**热点数据特征**：
```
正常商品：100次/分钟查询
热点商品：10000次/分钟查询 ← 需要特殊处理
```

**识别方法**：
```java
@Component
public class HotDataDetector {
    
    private Map<String, AtomicLong> accessCount = new ConcurrentHashMap<>();
    
    public void recordAccess(String key) {
        accessCount.computeIfAbsent(key, k -> new AtomicLong(0))
                   .incrementAndGet();
    }
    
    @Scheduled(fixedRate = 60000)  // 每分钟统计
    public void detectHotData() {
        accessCount.entrySet().stream()
                   .filter(entry -> entry.getValue().get() > 1000)  // 超过1000次
                   .forEach(entry -> {
                       logger.info("检测到热点数据: {}, 访问次数: {}", 
                                 entry.getKey(), entry.getValue().get());
                       handleHotData(entry.getKey());
                   });
        
        accessCount.clear();  // 清空计数器
    }
}
```

### 7.2 热点数据处理方案


**📊 处理策略对比**：

| **方案** | **实现方式** | **适用场景** | **效果** |
|---------|-------------|-------------|---------|
| **本地缓存** | `Caffeine、Guava` | 单机应用 | 最快访问 |
| **分布式缓存** | `Redis Cluster` | 分布式系统 | 快速访问 |
| **CDN缓存** | `阿里云CDN` | 静态内容 | 全球加速 |
| **读写分离** | `多个从库` | 数据库层面 | 分散压力 |

**代码实现**：
```java
@Service
public class HotDataService {
    
    // 本地缓存处理热点数据
    private final LoadingCache<String, Object> hotDataCache = 
        Caffeine.newBuilder()
               .maximumSize(1000)
               .expireAfterWrite(5, TimeUnit.MINUTES)
               .build(key -> loadFromDatabase(key));
    
    public Object getHotData(String key) {
        return hotDataCache.get(key);  // 自动加载数据
    }
    
    // 异步预热热点数据
    @Async
    public void preloadHotData(List<String> hotKeys) {
        hotKeys.forEach(key -> {
            try {
                hotDataCache.get(key);  // 触发加载
                Thread.sleep(10);       // 避免瞬间压力
            } catch (Exception e) {
                logger.error("预热数据失败: {}", key, e);
            }
        });
    }
}
```

---

## 8. 🏗️ 微服务架构优化


### 8.1 服务拆分原则


**🤔 为什么这样**：微服务就像把一个大工厂拆分成多个专业车间，每个车间专注做自己擅长的事。

**拆分维度**：
```
单体应用：
[用户-订单-支付-商品] ← 全部功能耦合在一起

微服务拆分：
[用户服务] - 处理用户信息
[订单服务] - 处理订单逻辑  
[支付服务] - 处理支付流程
[商品服务] - 处理商品信息
```

### 8.2 服务间通信优化


**选择合适的通信方式**：

| **通信方式** | **延迟** | **可靠性** | **适用场景** |
|------------|---------|-----------|-------------|
| **HTTP REST** | `中等` | 较好 | 一般业务调用 |
| **RPC调用** | `低` | 好 | 高频内部调用 |
| **消息队列** | `高` | 很好 | 异步处理 |

```java
// RPC调用示例（使用Feign）
@FeignClient("user-service")
public interface UserClient {
    
    @GetMapping("/users/{id}")
    User getUser(@PathVariable Long id);
}

@Service  
public class OrderService {
    
    @Autowired
    private UserClient userClient;
    
    public Order createOrder(Long userId, String product) {
        // RPC调用获取用户信息
        User user = userClient.getUser(userId);
        
        // 创建订单
        Order order = new Order();
        order.setUserId(userId);
        order.setUserName(user.getName());
        
        return orderDao.save(order);
    }
}
```

### 8.3 服务治理策略


**🎯 服务治理要点**：
- **服务注册与发现**：Nacos、Eureka
- **负载均衡**：Ribbon、LoadBalancer  
- **熔断降级**：Hystrix、Sentinel
- **链路追踪**：SkyWalking、Zipkin

---

## 9. 📨 消息队列异步处理


### 9.1 异步处理的价值


**🔄 换句话说**：异步处理就像餐厅的取号机制，点完餐拿号码牌等待，不用一直站在柜台前。

```
同步处理：
用户下单 → 扣库存 → 生成订单 → 发送邮件 → 返回结果 (2秒)

异步处理：  
用户下单 → 扣库存 → 生成订单 → 返回结果 (200ms)
                              ↓
                         [消息队列] → 发送邮件
```

### 9.2 消息队列选型


**📊 主流MQ对比**：

| **MQ类型** | **性能** | **可靠性** | **适用场景** |
|-----------|---------|-----------|-------------|
| **Redis** | `极高` | 一般 | 简单异步任务 |
| **RabbitMQ** | `高` | 很好 | 复杂业务流程 |
| **RocketMQ** | `很高` | 很好 | 大规模系统 |
| **Kafka** | `极高` | 好 | 大数据处理 |

### 9.3 异步处理实现


```java
// 订单服务 - 发送异步消息
@Service
public class OrderService {
    
    @Autowired  
    private RabbitTemplate rabbitTemplate;
    
    public Order createOrder(OrderDTO orderDTO) {
        // 1. 核心业务：创建订单
        Order order = new Order();
        order.setUserId(orderDTO.getUserId());
        order = orderDao.save(order);
        
        // 2. 异步任务：发送消息
        OrderMessage message = new OrderMessage();
        message.setOrderId(order.getId());
        message.setUserId(order.getUserId());
        
        rabbitTemplate.convertAndSend("order.created", message);
        
        return order;  // 立即返回，不等待邮件发送
    }
}

// 邮件服务 - 处理异步消息
@Component
public class EmailConsumer {
    
    @RabbitListener(queues = "order.created")
    public void handleOrderCreated(OrderMessage message) {
        try {
            // 发送确认邮件
            sendOrderConfirmEmail(message.getUserId(), message.getOrderId());
            
            // 发送短信通知
            sendSMSNotification(message.getUserId());
            
        } catch (Exception e) {
            logger.error("处理订单消息失败: {}", message, e);
            // 可以重试或记录到死信队列
        }
    }
}
```

---

## 10. 🛡️ 限流降级策略


### 10.1 限流的必要性


**🚨 重要提醒**：不限流的系统在高并发下就像没有闸门的水库，容易决堤。

**限流效果对比**：
```
无限流：
1000个请求同时到达 → 系统崩溃 → 0个请求成功

有限流：
1000个请求同时到达 → 处理100个 → 100个请求成功
                   ↓拒绝900个 → 系统稳定
```

### 10.2 限流算法选择


| **算法** | **原理** | **优点** | **缺点** | **适用场景** |
|---------|---------|---------|---------|-------------|
| **计数器** | `固定时间窗口计数` | 简单易懂 | 有突刺问题 | 简单限流 |
| **滑动窗口** | `多个时间片统计` | 平滑限流 | 内存占用大 | 精确限流 |  
| **令牌桶** | `定速生成令牌` | 允许突发 | 实现复杂 | 突发场景 |
| **漏桶** | `固定速率处理` | 流量平滑 | 不够灵活 | 流量整形 |

### 10.3 限流实现


```java
@RestController
public class OrderController {
    
    // 使用Redis实现分布式限流
    @Autowired
    private RedisTemplate<String, String> redisTemplate;
    
    @PostMapping("/orders")
    @RateLimiter(permits = 100, window = 60)  // 每分钟100个请求
    public Result createOrder(@RequestBody OrderDTO orderDTO) {
        
        String key = "limit:order:create:" + getClientIP();
        String script = 
            "local current = redis.call('incr', KEYS[1]) " +
            "if current == 1 then " +
            "    redis.call('expire', KEYS[1], ARGV[1]) " +
            "end " +
            "if current > tonumber(ARGV[2]) then " +
            "    return 0 " +
            "else " +
            "    return 1 " +
            "end";
        
        Long result = redisTemplate.execute(
            RedisScript.of(script, Long.class), 
            Arrays.asList(key), "60", "100"
        );
        
        if (result == 0) {
            return Result.error("请求过于频繁，请稍后再试");
        }
        
        // 处理订单创建
        return orderService.createOrder(orderDTO);
    }
}
```

### 10.4 降级策略


**🔧 降级方案设计**：
```java
@Service
public class ProductService {
    
    @HystrixCommand(fallbackMethod = "getProductFallback")
    public Product getProduct(Long productId) {
        // 正常调用商品服务
        return productClient.getProduct(productId);
    }
    
    // 降级方法：返回缓存数据或默认值
    public Product getProductFallback(Long productId) {
        // 1. 从缓存获取
        Product product = cacheService.getProduct(productId);
        if (product != null) {
            return product;
        }
        
        // 2. 返回默认商品信息
        Product defaultProduct = new Product();
        defaultProduct.setId(productId);
        defaultProduct.setName("商品暂时不可用");
        defaultProduct.setStatus("UNAVAILABLE");
        
        return defaultProduct;
    }
}
```

---

## 11. 🔒 并发控制与锁优化


### 11.1 并发控制的重要性


**🌰 举个例子**：想象银行取款，如果没有并发控制，可能出现账户余额变成负数的情况。

```
并发问题示例：
线程A：余额1000 → 取款800 → 余额200
线程B：余额1000 → 取款600 → 余额400  

没有锁：最终余额可能是200或400（数据不一致）
有锁：最终余额是-400（正确结果，但需要业务判断）
```

### 11.2 MySQL锁机制


**行级锁vs表级锁**：
```sql
-- 行级锁：只锁定特定记录
SELECT * FROM accounts WHERE id = 123 FOR UPDATE;

-- 表级锁：锁定整张表
LOCK TABLES accounts WRITE;
```

**🎯 最佳实践**：
```sql
-- 秒杀场景的库存扣减
BEGIN;
SELECT stock FROM products WHERE id = 100 FOR UPDATE;  -- 行锁

-- 检查库存
UPDATE products SET stock = stock - 1 
WHERE id = 100 AND stock > 0;

-- 检查受影响行数判断是否成功
COMMIT;
```

### 11.3 分布式锁实现


```java
@Service
public class DistributedLockService {
    
    @Autowired
    private RedisTemplate<String, String> redisTemplate;
    
    // Redis分布式锁
    public boolean tryLock(String lockKey, String requestId, int expireTime) {
        String script = "if redis.call('get', KEYS[1]) == ARGV[1] then " +
                       "return redis.call('del', KEYS[1]) " +
                       "else return 0 end";
        
        Boolean result = redisTemplate.execute(
            RedisScript.of("return redis.call('set', KEYS[1], ARGV[1], 'NX', 'PX', ARGV[2])", Boolean.class),
            Collections.singletonList(lockKey),
            requestId, String.valueOf(expireTime)
        );
        
        return Boolean.TRUE.equals(result);
    }
    
    // 使用分布式锁的业务方法
    public void processOrderWithLock(Long orderId) {
        String lockKey = "order:lock:" + orderId;
        String requestId = UUID.randomUUID().toString();
        
        try {
            if (tryLock(lockKey, requestId, 5000)) {  // 5秒超时
                // 执行业务逻辑
                processOrder(orderId);
            } else {
                throw new BusinessException("系统繁忙，请稍后重试");
            }
        } finally {
            releaseLock(lockKey, requestId);
        }
    }
}
```

---

## 12. 📊 性能监控体系


### 12.1 关键监控指标


**🔍 核心监控维度**：

| **类别** | **监控指标** | **告警阈值** | **说明** |
|---------|-------------|-------------|---------|
| **数据库** | `QPS、TPS、连接数` | QPS>5000 | 查询和事务性能 |
| **应用** | `响应时间、错误率` | 响应>500ms | 用户体验指标 |
| **系统** | `CPU、内存、磁盘` | CPU>80% | 资源使用情况 |
| **网络** | `带宽、延迟、丢包` | 延迟>100ms | 网络质量 |

### 12.2 监控工具集成


```java
@Component
public class PerformanceMonitor {
    
    private final MeterRegistry meterRegistry;
    
    // 自定义业务指标
    @EventListener
    public void handleOrderCreated(OrderCreatedEvent event) {
        // 订单创建计数
        meterRegistry.counter("orders.created").increment();
        
        // 订单金额统计
        meterRegistry.gauge("orders.amount", event.getOrder().getAmount());
    }
    
    // 数据库性能监控
    @Around("@annotation(MonitorDB)")
    public Object monitorDatabaseAccess(ProceedingJoinPoint joinPoint) throws Throwable {
        Timer.Sample sample = Timer.start(meterRegistry);
        
        try {
            Object result = joinPoint.proceed();
            
            // 记录成功调用
            meterRegistry.counter("db.calls.success").increment();
            
            return result;
        } catch (Exception e) {
            // 记录失败调用
            meterRegistry.counter("db.calls.error").increment();
            throw e;
        } finally {
            // 记录响应时间
            sample.stop(Timer.builder("db.calls.duration").register(meterRegistry));
        }
    }
}
```

### 12.3 告警机制设计


```yaml
# Prometheus告警规则
groups:
- name: mysql-high-concurrency
  rules:
  - alert: MySQLConnectionsHigh
    expr: mysql_global_status_threads_connected > 80
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "MySQL连接数过高"
      description: "MySQL连接数已达到 {{ $value }}，超过告警阈值"
      
  - alert: SlowQueryIncreasing  
    expr: rate(mysql_global_status_slow_queries[5m]) > 10
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "慢查询数量激增"
      description: "过去5分钟慢查询增长率: {{ $value }}/min"
```

---

## 13. 📋 核心要点总结


### 13.1 必须掌握的优化策略


```
🔸 数据库层面：分库分表、读写分离、索引优化
🔸 缓存层面：多级缓存、热点数据处理、缓存更新策略  
🔸 应用层面：连接池优化、异步处理、服务拆分
🔸 系统层面：限流降级、并发控制、性能监控
```

### 13.2 高并发优化核心思路


**🎯 优化三板斧**：
1. **分**：分库分表分流量，化整为零降压力
2. **缓**：多级缓存提速度，热点数据特别处理
3. **控**：限流降级保稳定，监控告警早发现

### 13.3 实践应用指导


**📈 容量规划建议**：
- **数据库**：单库数据量不超过500GB
- **缓存**：热点数据缓存命中率>95%
- **连接池**：最大连接数=CPU核心数×2
- **限流**：预留30%系统容量作为缓冲

**⚡ 性能优化步骤**：
1. **监控先行**：建立完善的监控体系
2. **找出瓶颈**：通过压测找到系统瓶颈点
3. **针对优化**：根据瓶颈选择合适的优化方案
4. **验证效果**：通过监控数据验证优化效果
5. **持续改进**：建立优化的闭环流程

**🛠️ 工具推荐**：
- **压测工具**：JMeter、wrk、ab
- **监控工具**：Prometheus + Grafana
- **APM工具**：SkyWalking、Pinpoint
- **数据库工具**：pt-toolkit、mysqldumpslow

**核心记忆**：
- 高并发优化是系统工程，需要多层面协同
- 没有银弹，要根据业务特点选择合适方案
- 监控和压测是优化的基础，不可或缺
- 预防胜于治疗，提前规划比事后补救更重要