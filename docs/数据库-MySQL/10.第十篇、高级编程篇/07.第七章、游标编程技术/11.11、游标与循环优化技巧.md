---
title: 11、游标与循环优化技巧
---
## 📚 目录

1. [游标循环性能问题分析](#1-游标循环性能问题分析)
2. [循环结构优化策略](#2-循环结构优化策略)
3. [批处理结合技术](#3-批处理结合技术)
4. [索引利用优化](#4-索引利用优化)
5. [临时表辅助优化](#5-临时表辅助优化)
6. [执行计划优化分析](#6-执行计划优化分析)
7. [算法改进策略](#7-算法改进策略)
8. [高效实现模式](#8-高效实现模式)
9. [循环展开优化](#9-循环展开优化)
10. [核心要点总结](#10-核心要点总结)

---

## 1. 🔍 游标循环性能问题分析


### 1.1 什么是游标循环性能问题


**游标循环**就是在存储过程中使用游标一条一条地处理数据，这种方式最大的问题就是**效率低下**。

```
简单理解：
游标循环 = 一条一条地处理数据
批处理 = 一次处理一批数据

就像搬砖：
游标循环：一次搬一块砖，来回跑1000次
批处理：一次搬10块砖，来回跑100次
```

### 1.2 性能问题的根本原因


**🔸 主要问题**：
- **网络开销**：每条记录都要与数据库交互一次
- **上下文切换**：频繁的SQL解析和执行
- **锁竞争**：长时间持有锁资源
- **内存碎片**：频繁的内存分配和释放

### 1.3 典型的低效游标示例


```sql
-- ❌ 低效的游标循环处理
DELIMITER $$
CREATE PROCEDURE update_salary_bad()
BEGIN
    DECLARE done INT DEFAULT 0;
    DECLARE emp_id INT;
    DECLARE current_salary DECIMAL(10,2);
    
    -- 声明游标
    DECLARE emp_cursor CURSOR FOR 
        SELECT employee_id, salary FROM employees;
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = 1;
    
    OPEN emp_cursor;
    
    -- 一条一条处理，效率极低
    read_loop: LOOP
        FETCH emp_cursor INTO emp_id, current_salary;
        IF done THEN
            LEAVE read_loop;
        END IF;
        
        -- 每条记录都执行一次UPDATE
        UPDATE employees 
        SET salary = current_salary * 1.1 
        WHERE employee_id = emp_id;
    END LOOP;
    
    CLOSE emp_cursor;
END$$
```

**问题分析**：
```
如果有10万条员工记录：
- 需要执行10万次UPDATE语句
- 每次UPDATE都要解析SQL、获取锁、写日志
- 总耗时可能达到几分钟甚至更长
```

---

## 2. ⚡ 循环结构优化策略


### 2.1 减少循环次数


**核心思想**：能批量处理的绝不逐条处理

```sql
-- ✅ 优化后：直接批量更新
UPDATE employees 
SET salary = salary * 1.1 
WHERE department_id = 10;

-- 一条SQL替代了可能数千次的循环
```

### 2.2 循环内部优化


当必须使用循环时，优化循环内部的操作：

```sql
-- ✅ 优化的游标循环
DELIMITER $$
CREATE PROCEDURE process_orders_optimized()
BEGIN
    DECLARE done INT DEFAULT 0;
    DECLARE order_id INT;
    DECLARE total_amount DECIMAL(10,2);
    
    DECLARE order_cursor CURSOR FOR 
        SELECT o.order_id, o.total_amount 
        FROM orders o 
        WHERE o.status = 'pending'
        ORDER BY o.order_id;  -- 利用索引排序
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = 1;
    
    -- 开启事务，减少提交次数
    START TRANSACTION;
    
    OPEN order_cursor;
    
    read_loop: LOOP
        FETCH order_cursor INTO order_id, total_amount;
        IF done THEN
            LEAVE read_loop;
        END IF;
        
        -- 使用预编译语句提高效率
        SET @sql = 'UPDATE orders SET status = ? WHERE order_id = ?';
        EXECUTE stmt USING 'processed', order_id;
        
    END LOOP;
    
    CLOSE order_cursor;
    COMMIT;  -- 一次性提交
END$$
```

### 2.3 循环条件优化


**智能退出条件**：
```sql
-- ✅ 设置处理上限，避免无限循环
DECLARE processed_count INT DEFAULT 0;
DECLARE max_process INT DEFAULT 10000;

read_loop: LOOP
    FETCH cursor_name INTO variables;
    IF done OR processed_count >= max_process THEN
        LEAVE read_loop;
    END IF;
    
    -- 处理逻辑
    SET processed_count = processed_count + 1;
END LOOP;
```

---

## 3. 📦 批处理结合技术


### 3.1 什么是批处理结合


**批处理**就是把多条记录的操作合并成一次操作，大大提高效率。

```
传统方式：
INSERT INTO table VALUES (1, 'a');
INSERT INTO table VALUES (2, 'b');
INSERT INTO table VALUES (3, 'c');

批处理方式：
INSERT INTO table VALUES 
(1, 'a'), (2, 'b'), (3, 'c');
```

### 3.2 批量插入优化


```sql
-- ✅ 批量插入示例
DELIMITER $$
CREATE PROCEDURE batch_insert_users()
BEGIN
    DECLARE done INT DEFAULT 0;
    DECLARE batch_size INT DEFAULT 1000;
    DECLARE counter INT DEFAULT 0;
    DECLARE user_data TEXT DEFAULT '';
    
    DECLARE user_cursor CURSOR FOR 
        SELECT name, email FROM temp_users;
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = 1;
    
    OPEN user_cursor;
    
    read_loop: LOOP
        FETCH user_cursor INTO @name, @email;
        IF done THEN
            LEAVE read_loop;
        END IF;
        
        -- 构建批量插入语句
        IF counter = 0 THEN
            SET user_data = CONCAT('(', QUOTE(@name), ',', QUOTE(@email), ')');
        ELSE
            SET user_data = CONCAT(user_data, ',(', QUOTE(@name), ',', QUOTE(@email), ')');
        END IF;
        
        SET counter = counter + 1;
        
        -- 达到批次大小时执行插入
        IF counter >= batch_size THEN
            SET @sql = CONCAT('INSERT INTO users (name, email) VALUES ', user_data);
            PREPARE stmt FROM @sql;
            EXECUTE stmt;
            DEALLOCATE PREPARE stmt;
            
            SET counter = 0;
            SET user_data = '';
        END IF;
    END LOOP;
    
    -- 处理剩余数据
    IF counter > 0 THEN
        SET @sql = CONCAT('INSERT INTO users (name, email) VALUES ', user_data);
        PREPARE stmt FROM @sql;
        EXECUTE stmt;
        DEALLOCATE PREPARE stmt;
    END IF;
    
    CLOSE user_cursor;
END$$
```

### 3.3 批量更新技术


```sql
-- ✅ 使用CASE WHEN进行批量更新
UPDATE employees 
SET salary = CASE 
    WHEN department_id = 1 THEN salary * 1.15
    WHEN department_id = 2 THEN salary * 1.10
    WHEN department_id = 3 THEN salary * 1.08
    ELSE salary * 1.05
END
WHERE department_id IN (1, 2, 3, 4);
```

---

## 4. 🎯 索引利用优化


### 4.1 游标查询中的索引优化


**核心原则**：游标的查询语句必须走索引，否则性能会非常差。

```sql
-- ❌ 没有利用索引的游标
DECLARE slow_cursor CURSOR FOR 
    SELECT * FROM orders 
    WHERE YEAR(order_date) = 2024;  -- 函数导致索引失效

-- ✅ 利用索引的游标
DECLARE fast_cursor CURSOR FOR 
    SELECT order_id, customer_id, total_amount 
    FROM orders 
    WHERE order_date >= '2024-01-01' 
      AND order_date < '2025-01-01'
    ORDER BY order_id;  -- 利用主键索引排序
```

### 4.2 创建合适的索引


```sql
-- 为游标查询创建复合索引
CREATE INDEX idx_orders_status_date ON orders(status, order_date);

-- 游标查询就能高效利用这个索引
DECLARE order_cursor CURSOR FOR 
    SELECT order_id, customer_id 
    FROM orders 
    WHERE status = 'pending' 
      AND order_date >= DATE_SUB(NOW(), INTERVAL 7 DAY)
    ORDER BY order_date;
```

### 4.3 避免索引失效


**常见的索引失效情况**：
```sql
-- ❌ 这些写法会导致索引失效
WHERE UPPER(name) = 'JOHN'      -- 函数
WHERE age + 1 = 25              -- 运算
WHERE name LIKE '%john%'        -- 前导通配符
WHERE id != 100                 -- 不等于

-- ✅ 正确的写法
WHERE name = 'john' COLLATE utf8_general_ci
WHERE age = 24
WHERE name LIKE 'john%'
WHERE id > 100 OR id < 100
```

---

## 5. 🗃️ 临时表辅助优化


### 5.1 什么时候使用临时表


**临时表的作用**：把复杂的游标处理分解成多个简单步骤。

```
使用场景：
1. 需要对数据进行多轮处理
2. 中间结果需要排序或分组
3. 复杂的数据转换逻辑
4. 需要去重或过滤的情况
```

### 5.2 临时表优化示例


```sql
-- ✅ 使用临时表优化复杂处理
DELIMITER $$
CREATE PROCEDURE optimize_with_temp_table()
BEGIN
    -- 创建临时表存储中间结果
    CREATE TEMPORARY TABLE temp_order_summary (
        customer_id INT,
        total_orders INT,
        total_amount DECIMAL(15,2),
        avg_amount DECIMAL(15,2),
        INDEX idx_customer (customer_id)
    );
    
    -- 第一步：汇总客户订单数据
    INSERT INTO temp_order_summary (customer_id, total_orders, total_amount, avg_amount)
    SELECT 
        customer_id,
        COUNT(*) as total_orders,
        SUM(total_amount) as total_amount,
        AVG(total_amount) as avg_amount
    FROM orders 
    WHERE order_date >= DATE_SUB(NOW(), INTERVAL 1 YEAR)
    GROUP BY customer_id;
    
    -- 第二步：批量更新客户等级
    UPDATE customers c
    INNER JOIN temp_order_summary t ON c.customer_id = t.customer_id
    SET c.customer_level = CASE 
        WHEN t.total_amount >= 10000 THEN 'VIP'
        WHEN t.total_amount >= 5000 THEN 'Gold'
        WHEN t.total_amount >= 2000 THEN 'Silver'
        ELSE 'Bronze'
    END;
    
    -- 临时表会在会话结束时自动删除
END$$
```

### 5.3 内存临时表优化


```sql
-- 使用MEMORY引擎提高临时表性能
CREATE TEMPORARY TABLE temp_data (
    id INT PRIMARY KEY,
    value VARCHAR(100),
    amount DECIMAL(10,2)
) ENGINE=MEMORY;
```

---

## 6. 📊 执行计划优化分析


### 6.1 分析游标查询的执行计划


```sql
-- 分析游标中SQL的执行计划
EXPLAIN SELECT order_id, customer_id, total_amount 
FROM orders 
WHERE status = 'pending' 
  AND order_date >= DATE_SUB(NOW(), INTERVAL 7 DAY)
ORDER BY order_date;
```

**重点关注的指标**：
```
type: 理想情况是 range 或 ref
key: 应该显示使用了索引
rows: 扫描的行数，越少越好
Extra: 避免 Using filesort 和 Using temporary
```

### 6.2 执行计划优化实例


```sql
-- ❌ 执行计划显示全表扫描
SELECT * FROM orders WHERE MONTH(order_date) = 12;
-- 执行计划：type=ALL, rows=100000

-- ✅ 优化后走索引
SELECT * FROM orders 
WHERE order_date >= '2024-12-01' 
  AND order_date < '2025-01-01';
-- 执行计划：type=range, key=idx_order_date, rows=5000
```

---

## 7. 🧠 算法改进策略


### 7.1 分而治之策略


**核心思想**：把大问题分解成小问题，分批处理。

```sql
-- ✅ 分批处理大量数据
DELIMITER $$
CREATE PROCEDURE process_large_dataset()
BEGIN
    DECLARE batch_size INT DEFAULT 10000;
    DECLARE min_id INT DEFAULT 0;
    DECLARE max_id INT;
    DECLARE current_batch INT DEFAULT 0;
    
    -- 获取数据范围
    SELECT MAX(id) INTO max_id FROM large_table;
    
    WHILE min_id < max_id DO
        -- 处理当前批次
        UPDATE large_table 
        SET processed = 1,
            updated_at = NOW()
        WHERE id > min_id 
          AND id <= min_id + batch_size
          AND processed = 0;
        
        SET min_id = min_id + batch_size;
        SET current_batch = current_batch + 1;
        
        -- 每100批次提交一次
        IF current_batch % 100 = 0 THEN
            COMMIT;
            START TRANSACTION;
        END IF;
        
    END WHILE;
    
    COMMIT;
END$$
```

### 7.2 预计算策略


```sql
-- ✅ 预先计算复杂结果，避免游标中重复计算
CREATE TABLE customer_stats (
    customer_id INT PRIMARY KEY,
    total_orders INT,
    total_amount DECIMAL(15,2),
    last_order_date DATE,
    customer_level VARCHAR(20),
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 定期更新统计表
INSERT INTO customer_stats (customer_id, total_orders, total_amount, last_order_date)
SELECT 
    customer_id,
    COUNT(*),
    SUM(total_amount),
    MAX(order_date)
FROM orders 
GROUP BY customer_id
ON DUPLICATE KEY UPDATE
    total_orders = VALUES(total_orders),
    total_amount = VALUES(total_amount),
    last_order_date = VALUES(last_order_date),
    updated_at = NOW();
```

---

## 8. 🚀 高效实现模式


### 8.1 避免游标的常见模式


**模式1：聚合计算**
```sql
-- ❌ 使用游标计算总和
-- ✅ 直接使用聚合函数
SELECT SUM(amount), AVG(amount), COUNT(*) 
FROM transactions 
WHERE transaction_date >= '2024-01-01';
```

**模式2：条件更新**
```sql
-- ❌ 游标逐条判断更新
-- ✅ 使用CASE WHEN批量更新
UPDATE products 
SET status = CASE 
    WHEN stock_quantity = 0 THEN 'out_of_stock'
    WHEN stock_quantity < 10 THEN 'low_stock'
    ELSE 'in_stock'
END;
```

### 8.2 高效的数据迁移模式


```sql
-- ✅ 高效的数据迁移
INSERT INTO target_table (col1, col2, col3)
SELECT 
    source_col1,
    UPPER(source_col2),
    CASE 
        WHEN source_col3 > 100 THEN 'high'
        ELSE 'normal'
    END
FROM source_table 
WHERE migration_flag = 0;

-- 标记已迁移
UPDATE source_table 
SET migration_flag = 1 
WHERE migration_flag = 0;
```

### 8.3 分页处理模式


```sql
-- ✅ 使用LIMIT分页处理，避免游标
DELIMITER $$
CREATE PROCEDURE process_with_pagination()
BEGIN
    DECLARE page_size INT DEFAULT 1000;
    DECLARE offset_val INT DEFAULT 0;
    DECLARE row_count INT;
    
    REPEAT
        -- 分页处理数据
        UPDATE users 
        SET last_login_check = NOW() 
        WHERE user_id IN (
            SELECT user_id FROM (
                SELECT user_id 
                FROM users 
                WHERE last_login_check IS NULL
                ORDER BY user_id 
                LIMIT page_size OFFSET offset_val
            ) AS temp
        );
        
        GET DIAGNOSTICS row_count = ROW_COUNT();
        SET offset_val = offset_val + page_size;
        
    UNTIL row_count < page_size END REPEAT;
END$$
```

---

## 9. 🔄 循环展开优化


### 9.1 什么是循环展开


**循环展开**就是减少循环的迭代次数，一次处理多个元素。

```
原始循环：处理1个，循环1000次
展开循环：处理10个，循环100次
```

### 9.2 手动循环展开示例


```sql
-- ✅ 循环展开技术
DELIMITER $$
CREATE PROCEDURE unrolled_processing()
BEGIN
    DECLARE done INT DEFAULT 0;
    DECLARE id1, id2, id3, id4, id5 INT;
    DECLARE batch_cursor CURSOR FOR 
        SELECT id FROM processing_queue 
        WHERE status = 'pending'
        ORDER BY priority DESC, id
        LIMIT 5;
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = 1;
    
    OPEN batch_cursor;
    
    read_loop: LOOP
        -- 一次获取5条记录
        FETCH batch_cursor INTO id1;
        IF done THEN LEAVE read_loop; END IF;
        
        FETCH batch_cursor INTO id2;
        FETCH batch_cursor INTO id3;
        FETCH batch_cursor INTO id4;
        FETCH batch_cursor INTO id5;
        
        -- 一次性处理5条记录
        UPDATE processing_queue 
        SET status = 'processed', 
            processed_at = NOW()
        WHERE id IN (id1, IFNULL(id2,0), IFNULL(id3,0), IFNULL(id4,0), IFNULL(id5,0))
          AND id > 0;
          
    END LOOP;
    
    CLOSE batch_cursor;
END$$
```

### 9.3 使用FIND_IN_SET优化


```sql
-- ✅ 使用字符串拼接减少循环
DELIMITER $$
CREATE PROCEDURE batch_with_find_in_set()
BEGIN
    DECLARE done INT DEFAULT 0;
    DECLARE id_list TEXT DEFAULT '';
    DECLARE current_id INT;
    DECLARE counter INT DEFAULT 0;
    DECLARE batch_size INT DEFAULT 100;
    
    DECLARE id_cursor CURSOR FOR 
        SELECT id FROM tasks WHERE status = 'pending';
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = 1;
    
    OPEN id_cursor;
    
    read_loop: LOOP
        FETCH id_cursor INTO current_id;
        IF done THEN
            LEAVE read_loop;
        END IF;
        
        -- 构建ID列表
        IF id_list = '' THEN
            SET id_list = current_id;
        ELSE
            SET id_list = CONCAT(id_list, ',', current_id);
        END IF;
        
        SET counter = counter + 1;
        
        -- 达到批次大小时处理
        IF counter >= batch_size THEN
            UPDATE tasks 
            SET status = 'completed',
                completed_at = NOW()
            WHERE FIND_IN_SET(id, id_list);
            
            SET id_list = '';
            SET counter = 0;
        END IF;
        
    END LOOP;
    
    -- 处理剩余数据
    IF id_list != '' THEN
        UPDATE tasks 
        SET status = 'completed',
            completed_at = NOW()
        WHERE FIND_IN_SET(id, id_list);
    END IF;
    
    CLOSE id_cursor;
END$$
```

---

## 10. 📋 核心要点总结


### 10.1 必须掌握的核心概念


```
🔸 游标循环性能问题：逐条处理效率低，网络开销大
🔸 批处理优化：一次处理多条记录，大幅提升性能
🔸 索引利用：游标查询必须走索引，避免全表扫描
🔸 临时表辅助：分解复杂逻辑，提供中间存储
🔸 执行计划分析：监控SQL性能，及时发现问题
🔸 算法改进：分而治之、预计算等策略
🔸 循环展开：减少迭代次数，批量处理数据
```

### 10.2 关键优化原则


**🔹 能批量就不逐条**
```
原则：凡是能用一条SQL解决的，绝不用游标循环
示例：UPDATE、INSERT、DELETE都支持批量操作
```

**🔹 必须走索引**
```
要求：游标的查询语句必须有合适的索引
检查：使用EXPLAIN分析执行计划
```

**🔹 分批处理大数据**
```
策略：大数据集分成小批次处理
好处：减少锁定时间，提高并发性能
```

### 10.3 性能对比示例


| **处理方式** | **10万条记录耗时** | **资源消耗** | **推荐程度** |
|-------------|------------------|-------------|-------------|
| 🔴 **逐条游标** | `5-10分钟` | `CPU高，内存高` | ❌ **不推荐** |
| 🟡 **批量游标** | `30-60秒` | `CPU中，内存中` | ⚠️ **谨慎使用** |
| 🟢 **直接批量** | `1-5秒` | `CPU低，内存低` | ✅ **强烈推荐** |

### 10.4 实际应用指导


**🎯 选择标准**：
- **数据量小(<1000条)**：任何方式都可以
- **数据量中(1000-10万)**：优先批量，必要时优化游标
- **数据量大(>10万)**：必须批量处理，禁用游标

**⚠️ 注意事项**：
- 游标会长时间占用锁资源
- 大批量操作要控制事务大小
- 复杂逻辑可以分解成多个简单步骤
- 定期监控慢查询日志

**核心记忆**：
- 游标循环是性能杀手，能避免就避免
- 批处理是王道，一次处理胜过千次循环
- 索引是基础，没有索引就是灾难
- 分而治之，化大为小是智慧