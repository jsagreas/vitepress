---
title: 3、查询执行引擎架构
---
## 📚 目录

1. [执行器架构设计](#1-执行器架构设计)
2. [Iterator执行模式详解](#2-Iterator执行模式详解)
3. [火山模型Volcano原理](#3-火山模型Volcano原理)
4. [执行器调度机制](#4-执行器调度机制)
5. [算子实现原理](#5-算子实现原理)
6. [内存管理策略](#6-内存管理策略)
7. [并发控制机制](#7-并发控制机制)
8. [现代执行引擎技术](#8-现代执行引擎技术)
9. [核心要点总结](#9-核心要点总结)

---

## 1. 🏗️ 执行器架构设计


### 1.1 执行器的本质作用


**执行器是什么？**
执行器就像是一个"工作安排员"，它拿到优化器制定的"执行计划"后，负责具体安排各个工作步骤怎么执行。

```
简单理解：
查询语句: SELECT name FROM users WHERE age > 25
优化器说: 先扫描索引，再回表查询
执行器做: 具体调用存储引擎，一步步执行
```

### 1.2 执行器的整体架构


**🔸 核心组件构成**
```
┌─────────────────────────────────────┐
│           查询执行器                │
├─────────────────────────────────────┤
│  执行计划解析器                     │ ← 解读执行计划
├─────────────────────────────────────┤
│  算子调度器                         │ ← 协调各个算子
├─────────────────────────────────────┤
│  算子执行器                         │ ← 具体执行操作
│  ├─扫描算子  ├─连接算子  ├─排序算子 │
├─────────────────────────────────────┤
│  内存管理器                         │ ← 管理执行内存
├─────────────────────────────────────┤
│  存储引擎接口                       │ ← 与存储层交互
└─────────────────────────────────────┘
```

### 1.3 执行器的工作流程


**执行器工作的三个阶段：**

> 💡 **第一阶段：准备阶段**
> 
> - 解析执行计划树
> - 初始化各种算子
> - 分配执行所需内存
> - 建立与存储引擎的连接

> 🔄 **第二阶段：执行阶段**
> 
> - 按照执行计划逐步执行
> - 协调各个算子之间的数据流转
> - 管理临时结果的存储

> ✅ **第三阶段：清理阶段**
> 
> - 释放占用的内存资源
> - 关闭打开的文件句柄
> - 返回查询结果给客户端

---

## 2. 🔄 Iterator执行模式详解


### 2.1 什么是Iterator模式


**Iterator模式的通俗解释：**
Iterator（迭代器）模式就像是"逐个取数据"的方式。想象你有一箱苹果，Iterator模式就是每次伸手取一个苹果，而不是一次性把整箱苹果都倒出来。

```
传统方式（批量处理）：
一次性处理所有数据 → 需要大量内存 → 可能内存不够

Iterator方式（流式处理）：
每次处理一行数据 → 内存占用固定 → 适合大数据量
```

### 2.2 Iterator接口设计


**🔸 核心接口方法**
```cpp
class Iterator {
public:
    // 获取下一行数据
    virtual bool Next() = 0;
    
    // 获取当前行数据
    virtual Row* GetRow() = 0;
    
    // 初始化迭代器
    virtual bool Init() = 0;
    
    // 释放资源
    virtual void Close() = 0;
};
```

**每个方法的作用：**
- `Next()`：移动到下一行，如果有数据返回true，没有返回false
- `GetRow()`：获取当前行的具体数据内容
- `Init()`：做一些初始化工作，比如打开文件、分配内存
- `Close()`：清理工作，释放占用的资源

### 2.3 Iterator模式的优势


**🎯 为什么要用Iterator模式？**

| 优势 | 具体说明 | 实际效果 |
|------|----------|----------|
| **内存效率** | 每次只处理一行数据 | 处理TB级数据也只需要MB级内存 |
| **响应快速** | 有数据就立即返回 | 用户不用等所有数据处理完 |
| **资源节约** | 按需处理数据 | 如果只要前10行，就只处理10行 |
| **管道化** | 多个算子可以并行工作 | 提高整体执行效率 |

---

## 3. 🌋 火山模型Volcano原理


### 3.1 火山模型的形象比喻


**火山模型是什么？**
火山模型就像是一个"数据流水线"。想象一下工厂的装配线，每个工位（算子）完成自己的工作后，把产品传递给下一个工位。

```
火山模型的数据流：

┌─────────┐    ┌─────────┐    ┌─────────┐
│  排序   │◄───│  过滤   │◄───│  扫描   │
│ 算子    │    │ 算子    │    │ 算子    │
└─────────┘    └─────────┘    └─────────┘
    ▲              ▲              ▲
    │              │              │
  一行           一行           一行
  数据           数据           数据

执行流程：
1. 排序算子向过滤算子要数据：Next()
2. 过滤算子向扫描算子要数据：Next()  
3. 扫描算子读取一行数据，返回给过滤算子
4. 过滤算子处理后，返回给排序算子
5. 排序算子收集足够数据后，返回结果
```

### 3.2 火山模型的工作机制


**🔸 拉取式执行（Pull-based）**
```
执行顺序（从上往下拉取）：
1. 客户端调用：result.Next()
2. 排序算子调用：filter.Next()
3. 过滤算子调用：scan.Next()
4. 扫描算子读取数据返回
5. 数据逐层返回到客户端
```

**实际代码示例：**
```cpp
// 扫描算子实现
bool TableScanIterator::Next() {
    // 从存储引擎读取下一行
    if (storage_engine->GetNextRow(&current_row)) {
        return true;  // 有数据
    }
    return false;     // 没有数据了
}

// 过滤算子实现
bool FilterIterator::Next() {
    while (child_iterator->Next()) {
        Row* row = child_iterator->GetRow();
        if (condition->Evaluate(row)) {
            current_row = row;
            return true;  // 找到符合条件的行
        }
    }
    return false;  // 没有更多符合条件的行
}
```

### 3.3 火山模型的特点


**🔸 优点分析**
- **内存友好**：每次只处理一行，内存占用恒定
- **流水线化**：多个算子可以同时工作
- **中断友好**：可以随时停止，支持LIMIT查询
- **实现简单**：每个算子都是独立的，易于开发维护

**🔸 缺点分析**
- **函数调用开销**：每行数据都要多次函数调用
- **分支预测困难**：条件判断较多，CPU分支预测效果差
- **缓存不友好**：数据访问模式对CPU缓存不友好

---

## 4. ⚙️ 执行器调度机制


### 4.1 调度器的作用


**调度器是做什么的？**
调度器就像是一个"项目经理"，它要安排什么时候执行哪个算子，怎么分配资源，确保整个查询能够高效完成。

### 4.2 调度策略


**🔸 单线程调度**
```
简单的顺序执行：
扫描 → 过滤 → 排序 → 返回结果

特点：
✅ 实现简单，调试容易
❌ 无法充分利用多核CPU
```

**🔸 多线程调度**
```
并行执行示例：
       ┌─扫描线程1─┐
       │          │
扫描 ──┼─扫描线程2─┼── 合并 ── 排序 ── 结果
       │          │
       └─扫描线程3─┘

特点：
✅ 充分利用多核资源
❌ 需要处理线程同步问题
```

### 4.3 资源分配策略


**内存分配原则：**
```cpp
// 根据算子类型分配内存
class MemoryAllocator {
    size_t AllocateForOperator(OperatorType type) {
        switch(type) {
            case SORT:
                return total_memory * 0.6;  // 排序需要更多内存
            case HASH_JOIN:
                return total_memory * 0.4;  // 哈希连接需要较多内存
            case SCAN:
                return total_memory * 0.1;  // 扫描需要较少内存
            default:
                return total_memory * 0.1;
        }
    }
};
```

---

## 5. 🔧 算子实现原理


### 5.1 什么是算子


**算子的通俗解释：**
算子就像是数据处理的"小工具"，每个算子都有自己的专门功能。就像厨房里有不同的工具：刀用来切菜，锅用来炒菜，每个工具都有特定的用途。

### 5.2 常见算子类型


**🔸 扫描算子（Scan Operator）**
```
作用：从表中读取数据
工作方式：
1. 打开表文件或索引
2. 逐行读取数据
3. 返回给上层算子

实现要点：
- 支持顺序扫描和索引扫描
- 处理谓词下推优化
- 管理读取缓冲区
```

**🔸 过滤算子（Filter Operator）**
```
作用：根据条件筛选数据
工作方式：
1. 从子算子获取数据
2. 评估过滤条件
3. 只返回符合条件的行

实现要点：
- 高效的条件评估
- 支持复合条件
- 短路求值优化
```

**🔸 连接算子（Join Operator）**
```
作用：连接两个表的数据
常见类型：
- 嵌套循环连接：简单但慢
- 哈希连接：内存友好，速度快
- 排序合并连接：适合大数据量

实现示例：
```cpp
bool HashJoinIterator::Next() {
    if (!build_phase_complete) {
        BuildHashTable();  // 构建哈希表
        build_phase_complete = true;
    }
    
    while (probe_iterator->Next()) {
        Row* probe_row = probe_iterator->GetRow();
        if (hash_table.Probe(probe_row)) {
            return true;  // 找到匹配
        }
    }
    return false;  // 没有更多匹配
}
```

### 5.3 算子的组合


**算子树的概念：**
```
     投影算子
        │
     排序算子
        │
     连接算子
      ┌───┴───┐
   过滤算子  过滤算子
      │        │
   扫描算子  扫描算子
   (用户表)  (订单表)

执行流程：
1. 扫描算子读取基础数据
2. 过滤算子进行条件筛选
3. 连接算子关联两表数据
4. 排序算子对结果排序
5. 投影算子选择需要的列
```

---

## 6. 🧠 内存管理策略


### 6.1 内存管理的重要性


**为什么需要精细的内存管理？**
数据库查询可能需要处理GB甚至TB级别的数据，但服务器内存是有限的。如果内存管理不当，要么查询失败，要么影响其他查询的性能。

### 6.2 内存分配策略


**🔸 静态内存分配**
```
特点：
- 启动时就分配固定大小的内存池
- 各个算子从内存池中申请内存
- 简单可靠，但可能造成浪费

适用场景：
- 内存充足的环境
- 查询模式比较固定
```

**🔸 动态内存分配**
```
特点：
- 根据实际需要动态申请内存
- 可以更好地利用系统资源
- 实现复杂，需要处理内存不足情况

适用场景：
- 内存紧张的环境
- 查询模式变化较大
```

### 6.3 内存溢出处理


**当内存不够用时怎么办？**

> ⚠️ **内存溢出的处理策略**
> 
> **磁盘溢写（Spill to Disk）**：
> - 将部分数据写入临时文件
> - 需要时再从磁盘读取
> - 性能下降但保证查询正常完成
> 
> **内存压缩**：
> - 压缩存储在内存中的数据
> - 减少内存占用，但增加CPU开销
> 
> **查询降级**：
> - 选择更节省内存的执行算法
> - 比如用嵌套循环代替哈希连接

```cpp
class MemoryManager {
public:
    bool TryAllocate(size_t size) {
        if (available_memory >= size) {
            available_memory -= size;
            return true;
        }
        
        // 内存不足，触发溢写
        if (SpillToDisk()) {
            return TryAllocate(size);  // 重试
        }
        
        return false;  // 内存分配失败
    }
    
private:
    bool SpillToDisk() {
        // 选择合适的算子进行溢写
        // 释放内存空间
        // 返回是否成功
    }
};
```

---

## 7. 🔒 并发控制机制


### 7.1 为什么需要并发控制


**并发执行的挑战：**
当多个查询同时执行，或者单个查询使用多个线程时，就会出现资源竞争的问题。比如两个线程同时修改同一个变量，结果就可能出错。

### 7.2 锁机制


**🔸 互斥锁（Mutex）**
```cpp
class ThreadSafeCounter {
private:
    std::mutex mutex_;
    int count_ = 0;
    
public:
    void Increment() {
        std::lock_guard<std::mutex> lock(mutex_);
        count_++;  // 这里是线程安全的
    }
};
```

**🔸 读写锁（RWLock）**
```
使用场景：
- 多个线程可以同时读取数据
- 但写入时需要独占访问

优势：
- 提高读操作的并发性
- 减少不必要的等待时间
```

### 7.3 无锁编程


**什么是无锁编程？**
无锁编程就像是在繁忙的路口不设红绿灯，而是通过巧妙的设计让车辆自然有序通行。

```cpp
// 原子操作示例
class LockFreeQueue {
    std::atomic<Node*> head_;
    std::atomic<Node*> tail_;
    
public:
    void Enqueue(T item) {
        Node* new_node = new Node{item, nullptr};
        Node* prev = tail_.exchange(new_node);
        prev->next = new_node;
    }
};
```

**优势：**
- 避免锁竞争，性能更好
- 不会出现死锁问题
- 更好的扩展性

---

## 8. 🚀 现代执行引擎技术


### 8.1 向量化执行引擎


**什么是向量化执行？**
传统执行方式是一行一行处理数据，向量化执行是一批一批处理数据。就像包装工厂，传统方式是一个一个包装，向量化方式是一次包装一整排。

```
传统方式：
for (each row) {
    process(row);  // 每次处理一行
}

向量化方式：
for (each batch) {
    process(batch);  // 每次处理一批（比如1000行）
}
```

**🔸 向量化的优势**
- **减少函数调用**：1000行数据只需要一次函数调用
- **更好的缓存利用**：连续的内存访问对CPU缓存友好
- **SIMD指令支持**：可以利用CPU的并行计算能力

### 8.2 JIT编译技术


**JIT是什么意思？**
JIT（Just-In-Time）编译就是"即时编译"。传统的执行引擎是解释执行，JIT是把查询逻辑编译成机器码再执行，就像把剧本变成演员的肌肉记忆。

```
传统执行：
解释器读取指令 → 执行对应操作 → 重复

JIT执行：
生成专门的机器码 → 直接执行机器码
```

**JIT的优势：**
- **执行速度快**：机器码执行比解释执行快很多
- **优化机会多**：可以针对具体查询进行优化
- **消除抽象层开销**：减少函数调用和条件判断

### 8.3 SIMD并行计算


**SIMD是什么？**
SIMD（Single Instruction Multiple Data）就是"一条指令处理多个数据"。就像一把特殊的刀，一刀下去可以同时切4个苹果。

```cpp
// 传统方式：逐个比较
for (int i = 0; i < 1000; i++) {
    if (array[i] > threshold) {
        result[i] = 1;
    }
}

// SIMD方式：4个一组比较
__m128i threshold_vec = _mm_set1_epi32(threshold);
for (int i = 0; i < 1000; i += 4) {
    __m128i data = _mm_load_si128(&array[i]);
    __m128i mask = _mm_cmpgt_epi32(data, threshold_vec);
    _mm_store_si128(&result[i], mask);
}
```

### 8.4 列式存储执行


**列式存储的执行特点：**
传统行式存储是把一行的所有列放在一起，列式存储是把一列的所有行放在一起。

```
行式存储：[ID1,Name1,Age1][ID2,Name2,Age2][ID3,Name3,Age3]
列式存储：[ID1,ID2,ID3][Name1,Name2,Name3][Age1,Age2,Age3]

查询SELECT Age FROM users：
行式：需要读取所有列，然后提取Age列
列式：直接读取Age列即可
```

**列式执行的优势：**
- **IO更少**：只读取需要的列
- **压缩率高**：相同类型数据聚集，压缩效果好
- **向量化友好**：天然适合向量化处理

### 8.5 批量执行模式


**什么是批量执行？**
批量执行就是把数据分组处理，每次处理一批数据。这样可以减少调度开销，提高缓存利用率。

```cpp
class BatchExecutor {
    static const int BATCH_SIZE = 1000;
    
public:
    bool ProcessBatch(std::vector<Row>& batch) {
        // 一次处理1000行数据
        for (int i = 0; i < BATCH_SIZE && i < batch.size(); i++) {
            // 处理每一行
            ProcessRow(batch[i]);
        }
        return batch.size() == BATCH_SIZE;  // 还有更多数据
    }
};
```

### 8.6 异步执行框架


**异步执行的思路：**
传统执行是同步的，一个步骤完成后才能进行下一步。异步执行允许多个步骤并行进行。

```
同步执行：
读取数据 → 等待IO → 处理数据 → 等待CPU → 输出结果

异步执行：
读取数据1 ┐
         ├→ 处理数据1 ┐
读取数据2 ┘          ├→ 输出结果1
                    ├→ 处理数据2
                    └→ 输出结果2
```

---

## 9. 📋 核心要点总结


### 9.1 必须掌握的核心概念


```
🔸 执行器本质：负责具体执行优化器生成的执行计划
🔸 Iterator模式：逐行处理数据，内存友好，支持流水线
🔸 火山模型：拉取式执行，算子组合，实现简单
🔸 算子概念：数据处理的基本单元，每个有专门功能
🔸 内存管理：合理分配内存，处理溢出情况
🔸 并发控制：保证多线程执行的正确性
```

### 9.2 关键理解要点


**🔹 为什么选择Iterator模式**
```
核心优势：
✅ 内存占用恒定 - 无论数据多大，内存需求固定
✅ 响应速度快 - 有数据立即返回，不需要等全部处理完
✅ 支持中断 - LIMIT查询可以提前停止
✅ 管道并行 - 多个算子可以同时工作
```

**🔹 火山模型的工作机制**
```
执行特点：
- 拉取式：上层算子主动向下层要数据
- 懒加载：只有需要时才处理数据
- 流水线：多个算子形成处理流水线
- 组合性：复杂查询由简单算子组合而成
```

**🔹 现代优化技术的价值**
```
技术演进方向：
向量化执行 → 减少函数调用开销，提高缓存利用率
JIT编译 → 生成优化的机器码，消除解释开销
SIMD并行 → 利用CPU并行计算能力
异步执行 → 提高资源利用率，减少等待时间
```

### 9.3 实际应用价值


**🎯 对数据库性能的影响**
- **查询速度**：执行引擎效率直接决定查询响应时间
- **内存使用**：合理的内存管理避免OOM和性能下降
- **并发能力**：并发控制机制影响系统吞吐量
- **扩展性**：现代执行技术提供更好的扩展能力

**🔧 优化思路**
- **算子优化**：选择合适的算子实现算法
- **内存调优**：根据查询特点分配内存
- **并行执行**：利用多核CPU提高性能
- **技术升级**：采用向量化、JIT等现代技术

**核心记忆**：
- 执行器是查询处理的"实干家"，负责具体执行工作
- Iterator模式和火山模型是经典架构，简单高效
- 现代执行引擎通过向量化、JIT等技术大幅提升性能
- 内存管理和并发控制是保证系统稳定的关键