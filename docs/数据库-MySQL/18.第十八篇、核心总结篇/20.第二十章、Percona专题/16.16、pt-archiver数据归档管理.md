---
title: 16、pt-archiver数据归档管理
---
## 📚 目录

1. [pt-archiver归档工具概述](#1-pt-archiver归档工具概述)
2. [归档原理与工作机制](#2-归档原理与工作机制)
3. [归档策略设计](#3-归档策略设计)
4. [数据选择条件配置](#4-数据选择条件配置)
5. [归档目标与输出配置](#5-归档目标与输出配置)
6. [批量处理优化](#6-批量处理优化)
7. [事务处理策略](#7-事务处理策略)
8. [归档进度监控](#8-归档进度监控)
9. [数据完整性验证](#9-数据完整性验证)
10. [归档文件管理](#10-归档文件管理)
11. [自动化归档流程](#11-自动化归档流程)
12. [核心要点总结](#12-核心要点总结)

---

## 1. 🗃️ pt-archiver归档工具概述


### 1.1 什么是pt-archiver


**简单理解**：pt-archiver就像是数据库的"搬家工具"，专门用来把旧数据从主表搬到其他地方

```
数据库就像一个仓库：
┌─────────────────────────┐
│    MySQL数据库仓库       │
│  ┌─────┐  ┌─────┐       │
│  │新数据│  │旧数据│ ←─── 需要搬走
│  │常用 │  │很少用│       │
│  └─────┘  └─────┘       │
└─────────────────────────┘
           ↓ pt-archiver
┌─────────────────────────┐
│    优化后的数据库        │
│  ┌─────┐                │
│  │新数据│  旧数据→文件   │
│  │常用 │     或其他表    │
│  └─────┘                │
└─────────────────────────┘
```

**核心作用**：
- **数据迁移**：把旧数据从活跃表中移走
- **性能优化**：减小表大小，提升查询速度
- **空间释放**：释放存储空间
- **合规管理**：按照数据保留政策管理数据

### 1.2 为什么需要数据归档


**现实场景**：订单表越来越大的问题
```
订单表成长历程：
第1年：100万条记录    查询很快 ⚡
第2年：500万条记录    开始变慢 ⏳  
第3年：2000万条记录   查询很慢 🐌
第5年：1亿条记录      系统卡死 💀

问题分析：
• 大部分查询只关心最近3个月的订单
• 3年前的订单几乎不会被查询
• 但是这些旧数据占用了大量空间和资源
```

**归档的价值**：
- 🚀 **查询提速**：表变小了，查询自然快了
- 💾 **节省空间**：旧数据迁移，释放存储
- 🔧 **维护简化**：备份、索引重建都更快
- 📋 **合规需求**：满足数据保留政策

### 1.3 pt-archiver的优势


**相比手动删除的优势**：
```
手动DELETE的问题：
┌─────────────────────────┐
│ DELETE FROM orders      │
│ WHERE create_date <     │
│   '2021-01-01'         │
└─────────────────────────┘
         ↓
❌ 锁表时间长
❌ 可能导致主从延迟  
❌ 数据无法恢复
❌ 影响业务运行

pt-archiver的优势：
✅ 小批量处理，不锁表
✅ 可以先备份再删除
✅ 支持断点续传
✅ 对业务影响最小
```

---

## 2. ⚙️ 归档原理与工作机制


### 2.1 pt-archiver工作流程


**基本工作步骤**：
```
pt-archiver工作流程图：

源表 ──┐
       │
       ├─→ [选择数据] ──→ [批量读取] ──┐
       │                              │
       └─→ [条件过滤]                  ├─→ [写入目标] ──→ 目标位置
                                     │                  (文件/表)
       [验证完成] ←──── [删除源数据] ←─┘
           │
           └─→ [下一批次]
```

**详细执行过程**：

① **数据选择阶段**
```sql
-- pt-archiver内部会执行类似这样的查询
SELECT * FROM orders 
WHERE create_date < '2021-01-01' 
ORDER BY id 
LIMIT 1000;
```

② **数据备份阶段**
```bash
# 可以输出到文件
echo "INSERT INTO archived_orders VALUES (...)" >> archive.sql
```

③ **数据删除阶段**
```sql
-- 删除已经备份的数据
DELETE FROM orders WHERE id IN (1,2,3...1000);
```

④ **循环处理**
- 继续处理下一批1000条数据
- 直到所有符合条件的数据处理完毕

### 2.2 批量处理机制


**为什么要分批处理**：
```
大批量 vs 小批量对比：

一次性处理100万条：
┌─────────────────────────┐
│     锁表10分钟          │ ❌ 业务中断
│   主从延迟严重          │ ❌ 影响读取
│   可能导致超时          │ ❌ 操作失败
└─────────────────────────┘

分1000批次处理：
┌──┐┌──┐┌──┐...┌──┐
│批1││批2││批3│...│批n│      ✅ 每批几秒
└──┘└──┘└──┘...└──┘      ✅ 业务正常运行
                          ✅ 可随时暂停
```

**批量大小的选择**：
```bash
# 不同场景的批量大小建议
--limit=1000    # 高并发场景，影响最小
--limit=5000    # 一般场景，平衡效率和影响
--limit=10000   # 低峰期，追求效率
```

### 2.3 安全机制设计


**多重安全保障**：

🔒 **锁机制**：避免并发冲突
```bash
# 使用文件锁确保只有一个实例运行
--pid=/tmp/pt-archiver.pid
```

⏸️ **限速机制**：控制对数据库的压力
```bash
# 每批处理后暂停1秒
--sleep=1

# 监控复制延迟，延迟超过10秒就暂停
--check-slave-lag=slave-host --max-lag=10
```

🔄 **事务控制**：保证数据一致性
```bash
# 每批都在事务中处理
--txn-size=1000
```

---

## 3. 📋 归档策略设计


### 3.1 归档策略类型


**按时间归档**：最常见的策略
```sql
-- 归档6个月前的订单数据
WHERE order_date < DATE_SUB(NOW(), INTERVAL 6 MONTH)

-- 归档1年前的日志数据  
WHERE log_time < DATE_SUB(NOW(), INTERVAL 1 YEAR)
```

**按状态归档**：根据业务状态
```sql
-- 归档已完成或已取消的订单
WHERE status IN ('completed', 'cancelled')

-- 归档已处理的消息
WHERE process_status = 'processed'
```

**按大小归档**：控制表的大小
```sql
-- 只保留最新的100万条记录
WHERE id < (SELECT MAX(id) - 1000000 FROM table_name)
```

### 3.2 归档策略选择


**业务场景分析**：

| 业务类型 | **归档策略** | **保留时间** | **归档频率** |
|---------|------------|-------------|-------------|
| 📊 **电商订单** | `时间+状态组合` | `完成订单保留1年` | `每月归档` |
| 📝 **系统日志** | `时间归档` | `保留3个月` | `每周归档` |
| 💬 **用户消息** | `时间归档` | `保留6个月` | `每月归档` |
| 📈 **统计数据** | `按大小归档` | `保留1000万条` | `每季度归档` |

**制定归档策略的步骤**：

① **业务需求分析**
```
问自己几个问题：
• 这些数据多久会被查询？
• 查询频率如何？
• 是否有法律法规要求？
• 存储成本是否考虑？
```

② **技术可行性评估**
```
技术考虑：
• 表的大小和增长速度
• 索引设计是否支持高效归档
• 归档操作的时间窗口
• 对业务的影响程度
```

③ **归档测试验证**
```bash
# 先在测试环境验证
pt-archiver --source h=test-db,D=test,t=orders \
            --where "order_date < '2023-01-01'" \
            --limit=100 \
            --dry-run
```

### 3.3 归档策略配置示例


**配置文件方式**：
```ini
[archiver_config]
# 基本连接信息
host=localhost
port=3306
user=archiver
password=your_password

# 归档策略
database=ecommerce
table=orders
where=order_date < DATE_SUB(NOW(), INTERVAL 6 MONTH) AND status IN ('completed','cancelled')

# 处理参数
limit=1000
sleep=1
txn-size=1000

# 输出配置
file=/data/archive/orders_%Y%m.sql
```

---

## 4. 🎯 数据选择条件配置


### 4.1 WHERE条件设计原则


**高效的WHERE条件**：

✅ **使用索引列**：
```sql
-- 好的例子：使用有索引的时间列
WHERE create_time < '2023-01-01'

-- 不好的例子：使用函数会导致索引失效
WHERE YEAR(create_time) < 2023
```

✅ **条件具有选择性**：
```sql
-- 好的例子：选择性高，只选择少部分数据
WHERE status = 'archived' AND create_time < '2023-01-01'

-- 不好的例子：选择性差，可能选择大部分数据
WHERE status != 'active'
```

✅ **避免复杂子查询**：
```sql
-- 好的例子：简单直接的条件
WHERE order_id IN (SELECT id FROM completed_orders)

-- 更好的例子：JOIN方式
WHERE EXISTS (SELECT 1 FROM completed_orders c WHERE c.id = orders.order_id)
```

### 4.2 常用WHERE条件模式


**时间范围条件**：
```bash
# 基本时间条件
--where "create_time < DATE_SUB(NOW(), INTERVAL 6 MONTH)"

# 时间范围条件
--where "create_time BETWEEN '2022-01-01' AND '2022-12-31'"

# 相对时间条件
--where "update_time < UNIX_TIMESTAMP() - 86400*30"  # 30天前
```

**状态条件**：
```bash
# 单状态条件
--where "status = 'completed'"

# 多状态条件
--where "status IN ('completed', 'cancelled', 'expired')"

# 状态+时间组合
--where "status = 'completed' AND finish_time < DATE_SUB(NOW(), INTERVAL 3 MONTH)"
```

**数据范围条件**：
```bash
# ID范围条件
--where "id < 1000000"

# 排除活跃数据
--where "last_access_time < DATE_SUB(NOW(), INTERVAL 1 YEAR)"
```

### 4.3 WHERE条件优化技巧


**索引优化建议**：
```sql
-- 为归档条件创建复合索引
CREATE INDEX idx_archive ON orders (status, create_time);

-- 验证索引使用情况
EXPLAIN SELECT * FROM orders 
WHERE status = 'completed' AND create_time < '2023-01-01';
```

**分区表的条件**：
```sql
-- 分区表可以按分区归档
ALTER TABLE orders DROP PARTITION p_202201;

-- 或者使用分区键作为条件
--where "create_time >= '2022-01-01' AND create_time < '2022-02-01'"
```

**条件测试**：
```bash
# 先测试条件的选择性
pt-archiver --source h=localhost,D=test,t=orders \
            --where "status='completed' AND create_time < '2023-01-01'" \
            --dry-run \
            --statistics
```

---

## 5. 📁 归档目标与输出配置


### 5.1 归档目标类型


**输出到文件**：最简单的方式
```bash
# 输出到SQL文件
pt-archiver --source h=localhost,D=ecommerce,t=orders \
            --file /data/archive/orders_2023.sql \
            --where "create_time < '2023-01-01'"

# 生成的文件内容示例：
INSERT INTO `orders` VALUES (1,'2022-01-01','completed',...);
INSERT INTO `orders` VALUES (2,'2022-01-02','completed',...);
```

**输出到另一个表**：
```bash
# 归档到同一数据库的归档表
pt-archiver --source h=localhost,D=ecommerce,t=orders \
            --dest h=localhost,D=ecommerce,t=orders_archive \
            --where "create_time < '2023-01-01'"
```

**输出到另一个数据库**：
```bash
# 归档到专门的归档数据库
pt-archiver --source h=db1,D=ecommerce,t=orders \
            --dest h=archive-db,D=archive,t=orders \
            --where "create_time < '2023-01-01'"
```

### 5.2 文件输出配置


**文件命名策略**：
```bash
# 按日期命名
--file /data/archive/orders_%Y%m%d.sql

# 按时间戳命名  
--file /data/archive/orders_$(date +%Y%m%d_%H%M%S).sql

# 分库分表命名
--file /data/archive/${database}_${table}_%Y%m.sql
```

**文件格式选项**：
```bash
# 标准SQL格式（默认）
--file orders.sql

# 带表结构的完整SQL
--file orders.sql --header

# 只输出数据，不包含INSERT语句
--file orders.txt --tab-separated-values
```

**压缩输出**：
```bash
# 直接压缩输出
pt-archiver ... --file >(gzip > orders_archive.sql.gz)

# 使用管道压缩
pt-archiver ... --file - | gzip > orders_archive.sql.gz
```

### 5.3 目标表配置


**自动创建目标表**：
```bash
# pt-archiver会自动创建相同结构的表
pt-archiver --source h=localhost,D=source,t=orders \
            --dest h=localhost,D=archive,t=orders \
            --create-dest-table
```

**目标表结构调整**：
```sql
-- 可以预先创建优化的目标表结构
CREATE TABLE archive.orders_2023 (
  id bigint PRIMARY KEY,
  order_date date,
  status varchar(20),
  -- 省略不需要的列
  -- 添加归档时间
  archived_at timestamp DEFAULT CURRENT_TIMESTAMP,
  
  -- 针对归档查询优化的索引
  KEY idx_order_date (order_date),
  KEY idx_status (status)
);
```

**分区目标表**：
```sql
-- 创建按月分区的归档表
CREATE TABLE archive.orders (
  id bigint,
  order_date date,
  status varchar(20),
  ...
) PARTITION BY RANGE (YEAR(order_date)*100 + MONTH(order_date)) (
  PARTITION p202301 VALUES LESS THAN (202302),
  PARTITION p202302 VALUES LESS THAN (202303),
  ...
);
```

---

## 6. ⚡ 批量处理优化


### 6.1 批量大小调优


**批量大小的影响因素**：
```
批量大小权衡：

小批量（100-500）：
✅ 对业务影响最小
✅ 锁定时间短
❌ 归档效率较低
❌ 总耗时较长

中批量（1000-5000）：
✅ 效率和影响的平衡
✅ 适合大多数场景
⚖️ 需要根据具体情况调整

大批量（10000+）：
✅ 归档效率高
✅ 总耗时短
❌ 可能影响业务
❌ 锁定时间长
```

**动态调整批量大小**：
```bash
# 根据服务器负载动态调整
if [ $(uptime | awk '{print $NF}') > 2.0 ]; then
    LIMIT=500   # 高负载时减小批量
else
    LIMIT=2000  # 低负载时增大批量
fi

pt-archiver --limit=$LIMIT ...
```

### 6.2 处理速度控制


**睡眠时间配置**：
```bash
# 基本睡眠配置
--sleep=1                    # 每批后暂停1秒
--sleep=0.5                  # 每批后暂停0.5秒
--sleep-coef=1.5            # 动态调整睡眠时间

# 根据时间段调整
current_hour=$(date +%H)
if [ $current_hour -ge 9 ] && [ $current_hour -le 18 ]; then
    SLEEP=2    # 工作时间延长暂停
else
    SLEEP=0.5  # 非工作时间减少暂停
fi
```

**复制延迟控制**：
```bash
# 监控主从延迟
--check-slave-lag=slave-server.com
--max-lag=10                 # 延迟超过10秒就暂停
--check-interval=5           # 每5秒检查一次延迟

# 多个从库监控
--check-slave-lag=slave1.com,slave2.com
```

### 6.3 并发处理策略


**单表多进程归档**：
```bash
# 按ID范围分片处理
# 进程1：处理ID 1-1000000
pt-archiver --where "id >= 1 AND id < 1000000 AND create_time < '2023-01-01'" &

# 进程2：处理ID 1000000-2000000  
pt-archiver --where "id >= 1000000 AND id < 2000000 AND create_time < '2023-01-01'" &

# 进程3：处理ID 2000000以上
pt-archiver --where "id >= 2000000 AND create_time < '2023-01-01'" &
```

**多表并行归档**：
```bash
# 并行归档多个表
for table in orders order_items payments; do
    pt-archiver --source h=localhost,D=ecommerce,t=$table \
                --where "create_time < '2023-01-01'" \
                --file /data/archive/${table}_archive.sql &
done

wait  # 等待所有进程完成
```

**资源限制**：
```bash
# 限制CPU使用
nice -n 10 pt-archiver ...

# 限制IO优先级
ionice -c 3 pt-archiver ...

# 组合使用
nice -n 10 ionice -c 3 pt-archiver ...
```

---

## 7. 🔄 事务处理策略


### 7.1 事务大小配置


**事务大小的选择**：
```bash
# 与批量大小相同（推荐）
--limit=1000 --txn-size=1000

# 多批合并为一个事务
--limit=500 --txn-size=2000    # 4批合并为1个事务

# 每条记录一个事务（不推荐）
--limit=1000 --txn-size=1
```

**事务大小影响分析**：
```
事务大小对比：

小事务（txn-size=1）：
✅ 故障恢复快
✅ 锁竞争少
❌ 事务开销大
❌ 性能较差

中事务（txn-size=1000）：
✅ 性能和安全的平衡
✅ 适合大多数场景
⚖️ 需要适当的innodb_log_file_size

大事务（txn-size=10000）：
✅ 性能最好
❌ 锁定时间长
❌ 回滚耗时长
❌ 可能导致死锁
```

### 7.2 事务隔离级别


**隔离级别选择**：
```sql
-- 设置适当的隔离级别
SET SESSION TRANSACTION ISOLATION LEVEL READ COMMITTED;

-- 在pt-archiver中使用
pt-archiver --set-vars "tx_isolation=READ-COMMITTED" ...
```

**不同隔离级别的影响**：
```
READ UNCOMMITTED：
❌ 可能读到脏数据
✅ 性能最好

READ COMMITTED：
✅ 避免脏读
✅ 性能较好
⚖️ 可能出现不可重复读

REPEATABLE READ（MySQL默认）：
✅ 避免不可重复读
❌ 可能产生更多锁冲突

SERIALIZABLE：
✅ 最高一致性
❌ 性能最差
```

### 7.3 错误处理和恢复


**事务失败处理**：
```bash
# 遇到错误时的处理策略
--max-retries=3              # 失败时重试3次
--retry-sleep=5              # 重试前等待5秒

# 忽略某些错误继续处理
--ignore-errors=1062         # 忽略重复键错误
```

**断点续传机制**：
```bash
# 使用状态文件记录进度
--progress=/tmp/pt-archiver-progress.txt

# 从上次中断的地方继续
pt-archiver --resume-from-file=/tmp/pt-archiver-progress.txt ...
```

**数据一致性保证**：
```bash
# 启用完整性检查
--check-charset              # 检查字符集一致性
--check-columns              # 检查列定义一致性

# 验证归档结果
--verify                     # 归档后验证数据
```

---

## 8. 📊 归档进度监控


### 8.1 进度显示配置


**基本进度信息**：
```bash
# 显示详细进度
pt-archiver --progress=time,1 \
            --print \
            --statistics \
            ...

# 输出示例：
# TIME                ELAPSED COUNT
# 2023-09-11T10:00:00      0s     0
# 2023-09-11T10:00:01      1s  1000
# 2023-09-11T10:00:02      2s  2000
```

**自定义进度格式**：
```bash
# 详细的进度信息
--progress=time,5           # 每5秒显示一次进度
--print                     # 打印正在处理的数据
--statistics                # 显示统计信息

# 输出到日志文件
--progress=time,10 >> /var/log/pt-archiver.log 2>&1
```

### 8.2 监控指标


**关键监控指标**：
```bash
# 处理速度监控
SELECT 
  COUNT(*) as processed_count,
  COUNT(*) / (UNIX_TIMESTAMP() - @start_time) as rows_per_second
FROM information_schema.processlist 
WHERE info LIKE '%pt-archiver%';

# 剩余数据量估算
SELECT COUNT(*) as remaining_rows 
FROM orders 
WHERE create_time < '2023-01-01';
```

**系统资源监控**：
```bash
# CPU和内存监控
top -p $(pgrep pt-archiver)

# 磁盘IO监控
iostat -x 1

# MySQL进程监控
SHOW PROCESSLIST;
SHOW ENGINE INNODB STATUS;
```

### 8.3 告警机制


**进度告警脚本**：
```bash
#!/bin/bash
# 归档进度监控脚本

LOG_FILE="/var/log/pt-archiver.log"
ALERT_EMAIL="admin@company.com"

# 检查进程是否运行
if ! pgrep pt-archiver > /dev/null; then
    echo "pt-archiver进程已停止" | mail -s "归档告警" $ALERT_EMAIL
fi

# 检查是否长时间无进展
last_progress=$(tail -1 $LOG_FILE | awk '{print $3}')
sleep 300  # 等待5分钟
current_progress=$(tail -1 $LOG_FILE | awk '{print $3}')

if [ "$last_progress" == "$current_progress" ]; then
    echo "归档进程可能卡死" | mail -s "归档告警" $ALERT_EMAIL
fi
```

**钉钉/企业微信告警**：
```bash
# 发送告警到钉钉
send_dingtalk_alert() {
    local message=$1
    curl -X POST "https://oapi.dingtalk.com/robot/send?access_token=YOUR_TOKEN" \
         -H 'Content-Type: application/json' \
         -d "{\"msgtype\": \"text\", \"text\": {\"content\": \"$message\"}}"
}

# 使用示例
send_dingtalk_alert "订单表归档完成，共处理100万条记录"
```

---

## 9. ✅ 数据完整性验证


### 9.1 归档前验证


**数据一致性检查**：
```bash
# 验证源表数据
--dry-run                    # 只检查不执行
--check-columns             # 检查列定义
--check-charset             # 检查字符集

# 统计待归档数据
pt-archiver --source h=localhost,D=test,t=orders \
            --where "create_time < '2023-01-01'" \
            --dry-run \
            --statistics
```

**预估归档影响**：
```sql
-- 检查待归档数据量
SELECT 
    COUNT(*) as archive_count,
    MIN(create_time) as earliest_date,
    MAX(create_time) as latest_date,
    SUM(LENGTH(order_data)) as total_size_bytes
FROM orders 
WHERE create_time < '2023-01-01';

-- 检查是否有外键依赖
SELECT 
    CONSTRAINT_NAME,
    TABLE_NAME,
    REFERENCED_TABLE_NAME
FROM information_schema.KEY_COLUMN_USAGE 
WHERE REFERENCED_TABLE_NAME = 'orders';
```

### 9.2 归档过程验证


**实时数据校验**：
```bash
# 启用数据校验
--verify                     # 归档后验证数据
--check-interval=100        # 每100行检查一次

# 校验特定列
--verify-checksum           # 使用校验和验证
```

**关键数据监控**：
```sql
-- 监控归档过程中的数据变化
CREATE TABLE archive_monitor (
    check_time timestamp,
    source_count bigint,
    dest_count bigint,
    diff_count bigint
);

-- 定期检查数据一致性
INSERT INTO archive_monitor 
SELECT NOW(),
       (SELECT COUNT(*) FROM orders WHERE create_time < '2023-01-01'),
       (SELECT COUNT(*) FROM orders_archive),
       ABS((SELECT COUNT(*) FROM orders WHERE create_time < '2023-01-01') - 
           (SELECT COUNT(*) FROM orders_archive)) as diff;
```

### 9.3 归档后验证


**数据完整性检查**：
```bash
# 全面的数据校验脚本
#!/bin/bash

SOURCE_DB="ecommerce"
SOURCE_TABLE="orders"
DEST_DB="archive"
DEST_TABLE="orders_archive"
ARCHIVE_DATE="2023-01-01"

echo "开始数据完整性验证..."

# 1. 检查总记录数
SOURCE_COUNT=$(mysql -e "SELECT COUNT(*) FROM $SOURCE_DB.$SOURCE_TABLE WHERE create_time < '$ARCHIVE_DATE'" -sN)
DEST_COUNT=$(mysql -e "SELECT COUNT(*) FROM $DEST_DB.$DEST_TABLE" -sN)

echo "源表待归档记录数: $SOURCE_COUNT"
echo "目标表记录数: $DEST_COUNT"

# 2. 检查数据一致性
CHECKSUM_SOURCE=$(mysql -e "SELECT BIT_XOR(CRC32(CONCAT_WS(',', id, order_date, status))) FROM $SOURCE_DB.$SOURCE_TABLE WHERE create_time < '$ARCHIVE_DATE'" -sN)
CHECKSUM_DEST=$(mysql -e "SELECT BIT_XOR(CRC32(CONCAT_WS(',', id, order_date, status))) FROM $DEST_DB.$DEST_TABLE" -sN)

if [ "$CHECKSUM_SOURCE" == "$CHECKSUM_DEST" ]; then
    echo "✅ 数据校验通过"
else
    echo "❌ 数据校验失败"
    exit 1
fi

# 3. 检查关键字段
mysql -e "
SELECT 
    'Source' as source,
    MIN(create_time) as min_date,
    MAX(create_time) as max_date,
    COUNT(DISTINCT status) as status_count
FROM $SOURCE_DB.$SOURCE_TABLE WHERE create_time < '$ARCHIVE_DATE'
UNION ALL
SELECT 
    'Dest' as source,
    MIN(create_time) as min_date,
    MAX(create_time) as max_date,
    COUNT(DISTINCT status) as status_count
FROM $DEST_DB.$DEST_TABLE;
"
```

**业务逻辑验证**：
```sql
-- 验证业务规则
-- 例：检查订单金额分布是否正常
SELECT 
    'Source' as table_name,
    COUNT(*) as total_orders,
    AVG(total_amount) as avg_amount,
    SUM(total_amount) as sum_amount
FROM orders WHERE create_time < '2023-01-01'
UNION ALL
SELECT 
    'Archive' as table_name,
    COUNT(*) as total_orders,
    AVG(total_amount) as avg_amount,
    SUM(total_amount) as sum_amount
FROM orders_archive;

-- 检查状态分布
SELECT status, COUNT(*) 
FROM orders_archive 
GROUP BY status
ORDER BY COUNT(*) DESC;
```

---

## 10. 📁 归档文件管理


### 10.1 文件命名和组织


**标准命名规则**：
```bash
# 按日期和表名命名
/data/archive/
├── 2023/
│   ├── 01/
│   │   ├── orders_20230101.sql.gz
│   │   ├── order_items_20230101.sql.gz
│   │   └── payments_20230101.sql.gz
│   └── 02/
│       └── orders_20230201.sql.gz
└── 2024/
    └── 01/
        └── orders_20240101.sql.gz

# 命名模板
ARCHIVE_DIR="/data/archive"
YEAR=$(date +%Y)
MONTH=$(date +%m)
TABLE_NAME="orders"
ARCHIVE_FILE="$ARCHIVE_DIR/$YEAR/$MONTH/${TABLE_NAME}_$(date +%Y%m%d).sql.gz"
```

**文件元数据记录**：
```bash
# 创建归档清单文件
cat > /data/archive/2023/01/manifest.txt << EOF
# 归档文件清单
# 归档日期: 2023-01-15
# 归档操作员: admin
# 数据范围: 2022年全年订单数据

orders_20230115.sql.gz      1.2GB   1000000 rows   orders table
order_items_20230115.sql.gz 800MB   3000000 rows   order_items table  
payments_20230115.sql.gz    300MB   1000000 rows   payments table

# 校验信息
orders_checksum: a1b2c3d4e5f6
order_items_checksum: f1e2d3c4b5a6
payments_checksum: b2c3d4e5f6a1
EOF
```

### 10.2 文件压缩和存储


**压缩策略**：
```bash
# 实时压缩归档
pt-archiver --file >(gzip -9 > orders_archive.sql.gz) ...

# 归档后压缩
pt-archiver --file orders_archive.sql ...
gzip -9 orders_archive.sql

# 使用更高效的压缩算法
pt-archiver --file orders_archive.sql ...
xz -9 orders_archive.sql      # 更高压缩比
lz4 orders_archive.sql        # 更快压缩速度
```

**压缩效果对比**：
```
压缩算法对比（1GB SQL文件）：

gzip -1:  压缩到200MB,  压缩用时30s,  解压用时10s
gzip -9:  压缩到150MB,  压缩用时60s,  解压用时10s  
xz -9:    压缩到100MB,  压缩用时300s, 解压用时30s
lz4:      压缩到300MB,  压缩用时5s,   解压用时3s

推荐策略：
- 频繁访问：使用lz4，平衡压缩比和速度
- 长期存储：使用xz -9，最高压缩比
- 一般情况：使用gzip -6，性能和效果平衡
```

### 10.3 文件生命周期管理


**自动清理脚本**：
```bash
#!/bin/bash
# 归档文件生命周期管理

ARCHIVE_ROOT="/data/archive"
LOG_FILE="/var/log/archive_cleanup.log"

cleanup_log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" >> $LOG_FILE
}

# 清理策略：
# 1. 本地保留2年
# 2. 2-5年迁移到冷存储
# 3. 5年以上根据法规要求处理

cleanup_log "开始归档文件清理..."

# 清理5年以上的文件
find $ARCHIVE_ROOT -name "*.sql.gz" -mtime +1825 | while read file; do
    cleanup_log "删除过期文件: $file"
    rm -f "$file"
done

# 迁移2年以上的文件到冷存储
find $ARCHIVE_ROOT -name "*.sql.gz" -mtime +730 -mtime -1825 | while read file; do
    if [ ! -f "${file}.cold" ]; then
        cleanup_log "迁移到冷存储: $file"
        aws s3 cp "$file" s3://company-archive-cold/
        touch "${file}.cold"  # 标记已迁移
        rm -f "$file"         # 删除本地文件
    fi
done

cleanup_log "归档文件清理完成"
```

**备份和冗余**：
```bash
# 多重备份策略
backup_archive_files() {
    local source_file=$1
    local base_name=$(basename "$source_file")
    
    # 本地备份到不同磁盘
    cp "$source_file" "/backup/archive/$base_name"
    
    # 远程备份
    rsync -av "$source_file" backup-server:/archive/
    
    # 云存储备份
    aws s3 cp "$source_file" s3://company-archive-backup/
    
    # 生成校验和
    md5sum "$source_file" > "${source_file}.md5"
}
```

---

## 11. 🤖 自动化归档流程


### 11.1 定时归档任务


**Cron任务配置**：
```bash
# 编辑crontab
crontab -e

# 每月1号凌晨2点归档上月数据
0 2 1 * * /opt/scripts/monthly_archive.sh

# 每周日凌晨3点归档日志数据
0 3 * * 0 /opt/scripts/weekly_log_archive.sh

# 每天凌晨4点清理临时数据
0 4 * * * /opt/scripts/daily_cleanup.sh
```

**月度归档脚本**：
```bash
#!/bin/bash
# 月度数据归档脚本

set -e  # 遇到错误立即退出

# 配置参数
MYSQL_HOST="localhost"
MYSQL_USER="archiver"
MYSQL_PASS="your_password"
DATABASE="ecommerce"
ARCHIVE_DIR="/data/archive"
LOG_FILE="/var/log/monthly_archive.log"

# 日志函数
log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a $LOG_FILE
}

# 计算上个月的日期范围
LAST_MONTH=$(date -d "last month" +%Y-%m)
ARCHIVE_DATE="${LAST_MONTH}-01"
NEXT_MONTH=$(date -d "${LAST_MONTH}-01 +1 month" +%Y-%m-%d)

log "开始归档 $LAST_MONTH 的数据..."

# 创建归档目录
MONTHLY_DIR="$ARCHIVE_DIR/$(date -d "last month" +%Y/%m)"
mkdir -p "$MONTHLY_DIR"

# 归档订单表
log "归档订单表..."
pt-archiver \
    --source h=$MYSQL_HOST,u=$MYSQL_USER,p=$MYSQL_PASS,D=$DATABASE,t=orders \
    --file "$MONTHLY_DIR/orders_$LAST_MONTH.sql" \
    --where "create_time >= '$ARCHIVE_DATE' AND create_time < '$NEXT_MONTH'" \
    --limit=1000 \
    --sleep=1 \
    --progress=time,60 \
    --statistics 2>&1 | tee -a $LOG_FILE

# 压缩归档文件
log "压缩归档文件..."
gzip -9 "$MONTHLY_DIR/orders_$LAST_MONTH.sql"

# 验证归档结果
ARCHIVE_COUNT=$(zcat "$MONTHLY_DIR/orders_$LAST_MONTH.sql.gz" | grep "INSERT INTO" | wc -l)
log "归档完成，共归档 $ARCHIVE_COUNT 条记录"

# 发送通知
send_notification "订单数据归档完成" "成功归档 $LAST_MONTH 的 $ARCHIVE_COUNT 条订单记录"

log "月度归档任务完成"
```

### 11.2 归档任务编排


**复杂归档流程**：
```bash
#!/bin/bash
# 完整的归档工作流

# 阶段1：预检查
pre_check() {
    log "执行预检查..."
    
    # 检查磁盘空间
    DISK_USAGE=$(df /data | tail -1 | awk '{print $5}' | sed 's/%//')
    if [ $DISK_USAGE -gt 80 ]; then
        log "ERROR: 磁盘空间不足 ($DISK_USAGE%)"
        exit 1
    fi
    
    # 检查数据库连接
    if ! mysql -h$MYSQL_HOST -u$MYSQL_USER -p$MYSQL_PASS -e "SELECT 1" >/dev/null 2>&1; then
        log "ERROR: 数据库连接失败"
        exit 1
    fi
    
    # 检查复制延迟
    SLAVE_LAG=$(mysql -h$SLAVE_HOST -e "SHOW SLAVE STATUS\G" | grep "Seconds_Behind_Master" | awk '{print $2}')
    if [ "$SLAVE_LAG" != "NULL" ] && [ $SLAVE_LAG -gt 60 ]; then
        log "WARNING: 主从延迟较大 (${SLAVE_LAG}s)"
    fi
    
    log "预检查通过"
}

# 阶段2：执行归档
execute_archive() {
    local table=$1
    local where_condition=$2
    local output_file=$3
    
    log "开始归档表: $table"
    
    # 执行归档
    pt-archiver \
        --source h=$MYSQL_HOST,u=$MYSQL_USER,p=$MYSQL_PASS,D=$DATABASE,t=$table \
        --file "$output_file" \
        --where "$where_condition" \
        --limit=1000 \
        --sleep=1 \
        --check-slave-lag=$SLAVE_HOST \
        --max-lag=30 \
        --progress=time,300 \
        --statistics 2>&1 | tee -a $LOG_FILE
    
    if [ ${PIPESTATUS[0]} -eq 0 ]; then
        log "表 $table 归档成功"
        return 0
    else
        log "ERROR: 表 $table 归档失败"
        return 1
    fi
}

# 阶段3：后处理
post_process() {
    local archive_file=$1
    
    # 压缩文件
    gzip -9 "$archive_file"
    
    # 生成校验和
    md5sum "${archive_file}.gz" > "${archive_file}.gz.md5"
    
    # 备份到远程
    rsync -av "${archive_file}.gz" backup-server:/archive/
    
    # 上传到云存储
    aws s3 cp "${archive_file}.gz" s3://company-archive/
}

# 主流程
main() {
    log "======== 开始自动化归档流程 ========"
    
    pre_check
    
    # 归档各个表
    TABLES=("orders" "order_items" "payments" "user_logs")
    for table in "${TABLES[@]}"; do
        output_file="$MONTHLY_DIR/${table}_$LAST_MONTH.sql"
        
        if execute_archive "$table" "$WHERE_CONDITION" "$output_file"; then
            post_process "$output_file"
        else
            log "ERROR: 归档失败，停止流程"
            exit 1
        fi
    done
    
    log "======== 归档流程完成 ========"
}

# 执行主流程
main
```

### 11.3 监控和告警集成


**集成监控系统**：
```bash
# Prometheus指标收集
#!/bin/bash
# 归档指标收集脚本

METRICS_FILE="/var/lib/prometheus/node-exporter/archive_metrics.prom"

collect_metrics() {
    # 归档进度指标
    echo "# HELP archive_progress_total Total records to archive" > $METRICS_FILE
    echo "# TYPE archive_progress_total gauge" >> $METRICS_FILE
    echo "archive_progress_total{table=\"orders\"} $(get_total_records)" >> $METRICS_FILE
    
    echo "# HELP archive_progress_completed Completed records" >> $METRICS_FILE
    echo "# TYPE archive_progress_completed gauge" >> $METRICS_FILE
    echo "archive_progress_completed{table=\"orders\"} $(get_completed_records)" >> $METRICS_FILE
    
    # 归档文件大小指标
    echo "# HELP archive_file_size_bytes Archive file size in bytes" >> $METRICS_FILE
    echo "# TYPE archive_file_size_bytes gauge" >> $METRICS_FILE
    for file in $(find /data/archive -name "*.gz" -mtime -1); do
        size=$(stat -c%s "$file")
        basename=$(basename "$file")
        echo "archive_file_size_bytes{file=\"$basename\"} $size" >> $METRICS_FILE
    done
}

# Grafana仪表板配置示例
cat > archive_dashboard.json << 'EOF'
{
  "dashboard": {
    "title": "数据归档监控",
    "panels": [
      {
        "title": "归档进度",
        "type": "stat",
        "targets": [
          {
            "expr": "archive_progress_completed / archive_progress_total * 100"
          }
        ]
      },
      {
        "title": "归档速度",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(archive_progress_completed[5m])"
          }
        ]
      }
    ]
  }
}
EOF
```

**告警规则配置**：
```yaml
# Prometheus告警规则
groups:
- name: archive_alerts
  rules:
  - alert: ArchiveProcessStopped
    expr: up{job="pt-archiver"} == 0
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "归档进程已停止"
      description: "pt-archiver进程已停止超过5分钟"
      
  - alert: ArchiveProgressSlow
    expr: rate(archive_progress_completed[10m]) < 100
    for: 15m
    labels:
      severity: warning
    annotations:
      summary: "归档进度缓慢"
      description: "归档速度低于100条/分钟，持续15分钟"
      
  - alert: ArchiveDiskSpaceLow
    expr: (node_filesystem_avail_bytes{mountpoint="/data"} / node_filesystem_size_bytes{mountpoint="/data"}) * 100 < 20
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "归档目录磁盘空间不足"
      description: "归档目录剩余空间少于20%"
```

---

## 12. 📋 核心要点总结


### 12.1 必须掌握的核心概念


```
🔸 pt-archiver本质：MySQL数据归档的专业工具，安全高效地迁移历史数据
🔸 归档原理：小批量、分事务、可控制的数据迁移过程
🔸 归档策略：基于时间、状态、大小等条件的数据生命周期管理
🔸 批量优化：通过合理的批量大小和睡眠时间平衡性能和影响
🔸 完整性保证：多层次的数据验证确保归档过程的安全性
```

### 12.2 关键操作要点


**🔹 安全第一的归档原则**
```
操作前必检查：
• 数据库连接和权限
• 磁盘空间和网络状况  
• 主从复制状态
• 业务影响时间窗口

操作中必监控：
• 归档进度和速度
• 系统资源使用情况
• 复制延迟状态
• 错误和异常情况

操作后必验证：
• 数据完整性校验
• 业务功能正常性
• 归档文件可用性
• 清理工作完成度
```

**🔹 性能优化策略**
```
批量大小调优：
• 高并发场景：500-1000条/批
• 一般场景：1000-5000条/批
• 低峰期：5000-10000条/批

时间控制策略：
• 工作时间：增加睡眠时间，减小批量
• 非工作时间：减少睡眠，增大批量
• 复制延迟：动态调整处理速度

资源限制：
• 使用nice调整CPU优先级
• 使用ionice控制IO优先级
• 监控内存使用避免OOM
```

### 12.3 最佳实践指南


**🎯 归档流程最佳实践**
```
规划阶段：
✅ 制定明确的归档策略和时间表
✅ 评估对业务的影响和风险
✅ 准备充足的存储空间和备份
✅ 建立完善的监控和告警机制

执行阶段：
✅ 在业务低峰期执行归档操作
✅ 分批次处理，避免一次性大量操作
✅ 实时监控进度和系统状态
✅ 保持与业务团队的沟通

验证阶段：
✅ 全面的数据完整性验证
✅ 业务功能回归测试
✅ 归档文件的可用性检查
✅ 文档化归档结果和经验教训
```

**🔧 常见问题和解决方案**
```
问题1：归档速度太慢
解决：增大批量大小，减少睡眠时间，优化WHERE条件索引

问题2：影响线上业务
解决：减小批量大小，增加睡眠时间，监控复制延迟

问题3：磁盘空间不足
解决：实时压缩，分批处理，及时清理临时文件

问题4：数据验证失败
解决：检查字符集，验证外键约束，使用校验和对比

问题5：进程意外中断
解决：使用进度文件，支持断点续传，建立监控告警
```

### 12.4 工具选择和替代方案


**pt-archiver vs 其他方案**：
```
pt-archiver优势：
✅ 专业的MySQL归档工具
✅ 丰富的配置选项和安全机制
✅ 良好的监控和进度控制
✅ 经过生产环境大量验证

替代方案比较：
• 手工DELETE：简单但风险高，不推荐生产使用
• mysqldump+DELETE：适合小数据量，缺乏增量处理
• 自定义脚本：灵活但需要大量开发和测试
• 分区表：天然的归档机制，但需要前期设计

推荐使用场景：
• 大于100万条记录的表归档
• 需要精细控制归档过程
• 对业务影响要求严格
• 需要完整的监控和验证
```

### 12.5 发展趋势和扩展


**归档技术发展方向**：
```
云原生归档：
• 与云存储的深度集成
• 基于Kubernetes的归档任务调度
• 无服务器归档函数

智能化归档：
• 基于AI的归档策略优化
• 自动化的归档时机选择
• 智能的性能调优

分布式归档：
• 多数据库实例的统一归档
• 分布式事务的一致性保证
• 大规模集群的并行归档
```

**核心记忆要点**：
- pt-archiver是MySQL数据归档的首选工具
- 安全性和可控性是归档操作的核心原则  
- 合理的批量设置是性能优化的关键
- 完整的监控验证体系保证归档质量
- 自动化流程是大规模归档的必要条件