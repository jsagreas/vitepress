---
title: 2、gh-ost工作流程详解
---
## 📚 目录

1. [gh-ost工作流程概述](#1-gh-ost工作流程概述)
2. [影子表创建阶段](#2-影子表创建阶段)
3. [数据复制拷贝阶段](#3-数据复制拷贝阶段)
4. [binlog事件捕获阶段](#4-binlog事件捕获阶段)
5. [数据同步追赶阶段](#5-数据同步追赶阶段)
6. [原子切换执行阶段](#6-原子切换执行阶段)
7. [清理收尾工作阶段](#7-清理收尾工作阶段)
8. [流程监控与异常处理](#8-流程监控与异常处理)
9. [核心要点总结](#9-核心要点总结)

---

## 1. 🔄 gh-ost工作流程概述


### 1.1 什么是gh-ost工作流程


**简单理解**：gh-ost的工作流程就像是给房子装修时的步骤 - 先搭建临时住所，然后慢慢搬家，最后一次性切换到新房子。

**核心思想**：
```
传统DDL：直接在原表上改结构 → 长时间锁表 → 影响业务
gh-ost：创建新表 → 慢慢同步数据 → 瞬间切换 → 不影响业务
```

### 1.2 整体流程架构图


```
原始表(original)     影子表(_gho)     幽灵表(_ghc)
     │                   │                │
     │ ①创建影子表         │                │
     │─────────────────→  │                │
     │                   │                │
     │ ②复制数据结构        │                │
     │─────────────────→  │                │
     │                   │                │
     │ ③批量复制数据        │                │
     │═══════════════════→│                │
     │                   │                │
     │ ④实时同步变更        │                │
     │═══════════════════→│                │
     │                   │                │
     │ ⑤原子切换           │                │
     │⟺⟺⟺⟺⟺⟺⟺⟺⟺⟺⟺⟺⟺│                │
     │                   │                │
     │ ⑥清理工作           │                │
     │─────────────────→  │                │
```

### 1.3 流程阶段总览


| 阶段 | **主要工作** | **预估时间** | **对业务影响** |
|------|------------|------------|----------------|
| **①创建阶段** | `创建影子表和幽灵表` | `几秒钟` | `几乎无影响` |
| **②复制阶段** | `批量复制历史数据` | `数小时-数天` | `轻微IO影响` |
| **③捕获阶段** | `监听binlog事件` | `贯穿整个过程` | `几乎无影响` |
| **④追赶阶段** | `同步实时变更` | `几分钟-几小时` | `轻微影响` |
| **⑤切换阶段** | `原子性表切换` | `几毫秒-几秒` | `瞬时锁表` |
| **⑥清理阶段** | `删除临时表` | `几秒钟` | `无影响` |

---

## 2. 🏗️ 影子表创建阶段


### 2.1 影子表是什么


**通俗解释**：影子表就是原表的"替身演员"，它有着和原表一样的结构，但包含了我们想要的DDL变更。

```
原表：users (旧结构)
影子表：_users_gho (新结构) ← gho = ghost online
幽灵表：_users_ghc (控制表) ← ghc = ghost cut-over
```

### 2.2 创建过程详解


**🔸 步骤1：生成影子表名**
```sql
原表名：users
影子表名：_users_gho
命名规则：_[原表名]_gho
```

**🔸 步骤2：复制表结构**
```sql
-- gh-ost内部执行类似操作
SHOW CREATE TABLE users;
-- 获取建表语句，然后修改表名并应用DDL变更
CREATE TABLE _users_gho LIKE users;
ALTER TABLE _users_gho ADD COLUMN email VARCHAR(100);
```

**🔸 步骤3：创建控制表**
```sql
-- 幽灵表用于控制切换时机
CREATE TABLE _users_ghc (
  id bigint auto_increment,
  last_update timestamp,
  hint varchar(64),
  primary key(id)
) ENGINE=InnoDB;
```

### 2.3 创建阶段的关键特点


```
时间消耗：通常在几秒钟内完成
资源消耗：很小，主要是元数据操作
业务影响：几乎为零
失败风险：很低，即使失败也容易重试
```

**💡 为什么需要两个表？**
- **影子表(`_gho`)**：存储新结构的数据
- **幽灵表(`_ghc`)**：控制切换时机的信号表

---

## 3. 📦 数据复制拷贝阶段


### 3.1 复制策略概述


**分批复制原理**：就像搬家时不是一次性搬完，而是一箱一箱地搬，这样不会累死，也不会影响正常生活。

```
批量大小控制：
默认：1000行/批次
可调节：根据服务器性能调整
目标：平衡速度和性能影响
```

### 3.2 复制过程图解


```
原表 users (1000万行)                影子表 _users_gho
┌─────────────────┐                ┌─────────────────┐
│ id=1-1000   ★   │────复制批次1───→│ id=1-1000       │
│ id=1001-2000    │────复制批次2───→│ id=1001-2000    │  
│ id=2001-3000    │────复制批次3───→│ id=2001-3000    │
│ ...             │      ...       │ ...             │
│ id=9999001-10M  │────复制批次N───→│ id=9999001-10M  │
└─────────────────┘                └─────────────────┘
        ↓                                    ↓
   继续处理新的DML              等待追赶同步完成
```

### 3.3 复制执行流程


**🔸 步骤1：确定复制范围**
```sql
-- 获取表的主键范围
SELECT MIN(id), MAX(id) FROM users;
-- 假设结果：min=1, max=10000000
```

**🔸 步骤2：分批复制数据**
```sql
-- 每次复制1000行（可配置）
INSERT INTO _users_gho 
SELECT * FROM users 
WHERE id >= 1 AND id < 1001 
ORDER BY id;

-- 下一批
INSERT INTO _users_gho 
SELECT * FROM users 
WHERE id >= 1001 AND id < 2001 
ORDER BY id;
```

**🔸 步骤3：进度跟踪**
```
复制进度计算：
已复制行数 / 总行数 × 100%
例：已复制500万行 / 总计1000万行 = 50%
```

### 3.4 复制阶段性能优化


**⚡ 优化策略**：
```
批量大小调整：
- 大批次：复制速度快，但IO压力大
- 小批次：IO压力小，但复制时间长
- 建议：1000-5000行/批次

执行间隔控制：
- 连续执行：速度最快，但影响业务
- 间隔执行：减少影响，但时间更长
- 建议：每批间隔100-500毫秒

并发控制：
- 单线程：安全性高，速度相对慢
- 多线程：速度快，但复杂度高
- gh-ost：采用单线程保证安全性
```

### 3.5 时间评估算法


```
复制时间估算公式：
预估时间 = 总行数 ÷ (批量大小 ÷ 单批耗时)

实际示例：
- 表行数：1000万行
- 批量大小：1000行
- 单批耗时：0.1秒
- 预估时间：10,000,000 ÷ (1000 ÷ 0.1) = 1000秒 ≈ 16分钟
```

---

## 4. 📡 binlog事件捕获阶段


### 4.1 binlog捕获原理


**简单理解**：binlog就像是数据库的"录像机"，记录了所有的数据变更。gh-ost就像一个"观察员"，实时观看这些录像并同步到影子表。

```
应用程序                MySQL服务器                gh-ost
    │                      │                        │
    │──INSERT user───────→  │                        │
    │                      │──写入binlog───────────→ │
    │                      │                        │───应用到影子表
    │                      │                        │
    │──UPDATE user───────→  │                        │
    │                      │──写入binlog───────────→ │
    │                      │                        │───应用到影子表
```

### 4.2 binlog解析过程


**🔸 连接方式选择**

| 连接方式 | **工作原理** | **优势** | **劣势** |
|---------|------------|---------|---------|
| **主库连接** | `直接连接主库读binlog` | `实时性好，延迟最小` | `增加主库负载` |
| **从库连接** | `连接从库读binlog` | `不影响主库性能` | `可能有延迟` |
| **中继连接** | `通过中继日志读取` | `降低网络压力` | `配置相对复杂` |

**🔸 事件过滤机制**
```sql
-- gh-ost只关心目标表的变更事件
监听事件类型：
✓ INSERT events  → 插入新数据
✓ UPDATE events  → 更新现有数据  
✓ DELETE events  → 删除数据
✗ CREATE events  → 忽略建表语句
✗ DROP events    → 忽略删表语句
```

### 4.3 事件应用流程


```
binlog事件流程：
原表变更 → binlog记录 → gh-ost捕获 → 转换格式 → 应用到影子表

具体示例：
原表执行：UPDATE users SET age=25 WHERE id=100;
        ↓
binlog记录：UPDATE_ROWS_EVENT
        ↓  
gh-ost捕获并转换：UPDATE _users_gho SET age=25 WHERE id=100;
        ↓
应用到影子表：执行转换后的SQL
```

### 4.4 事件处理的挑战


**⚠️ 常见问题及解决**：

```
问题1：binlog格式不兼容
解决：检查并要求ROW格式的binlog
mysql> SET binlog_format = 'ROW';

问题2：网络延迟导致事件丢失  
解决：增加重试机制和断点续传

问题3：大事务导致内存溢出
解决：分批处理大事务的变更事件

问题4：DDL操作的并发冲突
解决：暂停DDL执行期间的其他结构变更
```

---

## 5. 🔄 数据同步追赶阶段


### 5.1 追赶阶段的必要性


**为什么需要追赶？**
想象一下：你在复制文件的同时，原文件还在被其他人修改。等你复制完成后，原文件已经和你刚开始复制时不一样了，这时就需要"追赶"这些变化。

```
时间线分析：
T0: 开始复制历史数据 (影子表为空)
T1: 应用程序继续写入原表
T2: 历史数据复制完成
T3: 需要追赶T0-T2期间的变更
T4: 达到同步状态，准备切换
```

### 5.2 追赶同步流程图


```
数据同步状态图：

原表数据变化：
T0 |████████████████████| (1000万行)
T1 |████████████████████▓| (1001万行) ← 新增1万行
T2 |████████████████████▓▓| (1002万行) ← 又增1万行
T3 |████████████████████▓▓▓| (1003万行) ← 再增1万行

影子表同步过程：
T0 |                    | (0行)
T1 |██████              | (复制到600万行)
T2 |████████████████████| (复制完历史1000万行)
T3 |████████████████████▓▓▓| (追赶完成，1003万行)
```

### 5.3 追赶性能指标


**🔸 关键性能指标**

| 指标名称 | **含义说明** | **理想值** | **监控方法** |
|---------|------------|-----------|-------------|
| **复制延迟** | `影子表落后原表的时间` | `< 1秒` | `对比最新变更时间戳` |
| **事件积压** | `待处理的binlog事件数` | `< 1000个` | `监控事件队列长度` |
| **处理速率** | `每秒处理的事件数量` | `> 1000/秒` | `统计单位时间处理量` |
| **内存使用** | `事件缓冲区内存占用` | `< 100MB` | `监控进程内存使用` |

### 5.4 追赶策略优化


**⚡ 加速追赶的方法**：

```
策略1：增加批处理大小
- 原设置：每批1000个事件
- 优化后：每批5000个事件
- 效果：减少网络往返，提升吞吐量

策略2：减少处理间隔
- 原设置：每批间隔100ms
- 优化后：每批间隔10ms  
- 效果：更快的事件处理速度

策略3：优化SQL执行
- 使用预编译语句减少解析时间
- 批量提交事务减少提交开销
- 合并相同主键的多次操作
```

### 5.5 追赶完成判断


**📊 同步完成的判断标准**：
```
判断条件：
✓ binlog事件队列为空
✓ 最后一个事件的时间戳接近当前时间
✓ 连续N秒(如10秒)没有新的延迟事件
✓ 影子表和原表的行数基本一致
```

---

## 6. ⚡ 原子切换执行阶段


### 6.1 原子切换的含义


**什么是原子切换？**
原子切换就像换轮胎 - 要么成功换好，要么保持原状，绝不能出现"半换不换"的中间状态。

```
原子性保证：
要么：原表 → 影子表 (切换成功)
要么：保持原表不变 (切换失败)
绝不：出现两个表同时存在或都不存在的情况
```

### 6.2 切换执行流程


```
切换时序图：

应用程序            MySQL服务器           gh-ost
    │                    │                  │
    │                    │ ①获取全局锁       │
    │                    │←─────────────────│
    │                    │                  │
    │─────写请求被阻塞─────→│ (等待锁释放)      │
    │                    │                  │
    │                    │ ②重命名表操作      │
    │                    │←─────────────────│
    │                    │                  │
    │                    │ ③释放全局锁       │
    │                    │←─────────────────│
    │                    │                  │
    │─────写请求恢复执行───→│ (锁已释放)        │
```

### 6.3 切换前置检查


**🔍 切换前的安全检查**：

```
检查项目清单：
☑️ 影子表数据完整性验证
☑️ 主从复制延迟检查 (< 1秒)
☑️ 系统负载检查 (CPU < 80%)
☑️ 连接数检查 (< 最大连接数的80%)
☑️ 磁盘空间检查 (剩余 > 10%)
☑️ 业务低峰期确认
```

**🚨 检查失败的处理**：
```
如果检查失败：
- 延迟切换执行
- 等待条件满足
- 或者终止整个操作
```

### 6.4 切换SQL语句序列


**🔸 核心切换操作**：
```sql
-- 步骤1：获取锁(阻止其他操作)
LOCK TABLES users WRITE, _users_gho WRITE;

-- 步骤2：原子重命名操作
RENAME TABLE 
  users TO _users_old,           -- 原表改名为备份表
  _users_gho TO users;           -- 影子表改名为正式表

-- 步骤3：释放锁
UNLOCK TABLES;

-- 整个过程通常在几毫秒到几秒内完成
```

### 6.5 切换时间分析


**⏱️ 切换耗时构成**：

| 阶段 | **耗时范围** | **影响因素** | **优化方法** |
|------|------------|-------------|-------------|
| **获取锁** | `1-100ms` | `当前活跃连接数` | `选择低峰期执行` |
| **重命名** | `1-10ms` | `表元数据大小` | `无法优化，极快` |
| **释放锁** | `1ms` | `几乎无影响因素` | `自动完成` |
| **总计** | `5-200ms` | `主要看获取锁时间` | `合理选择执行时机` |

### 6.6 切换失败处理


**⚠️ 失败场景及处理**：

```
场景1：获取锁超时
- 原因：有长时间运行的查询阻塞
- 处理：等待或杀死阻塞查询

场景2：重命名操作失败  
- 原因：表名冲突或权限问题
- 处理：回滚操作，保持原状

场景3：主从延迟过大
- 原因：从库同步跟不上
- 处理：等待同步追赶完成

恢复策略：
所有失败都会自动回滚，保持原表可用性
```

---

## 7. 🧹 清理收尾工作阶段


### 7.1 清理工作概述


**为什么需要清理？**
就像搬家完成后，需要清理旧房子和搬家过程中的临时物品一样，DDL完成后也需要清理临时创建的表和资源。

```
清理对象：
- 原表备份 (_users_old)  
- 控制表 (_users_ghc)
- binlog连接资源
- 临时文件和日志
- 监控进程和状态
```

### 7.2 清理执行流程


```
清理时序流程：

切换完成后:
    │
    ├─ ①验证新表正常工作 (必须)
    │     └─ 检查应用程序访问正常
    │
    ├─ ②保留备份表一段时间 (可选)  
    │     └─ 默认保留24-48小时
    │
    ├─ ③删除控制表 (立即)
    │     └─ DROP TABLE _users_ghc;
    │
    ├─ ④清理binlog连接 (立即)
    │     └─ 断开复制连接
    │
    ├─ ⑤删除临时文件 (立即)
    │     └─ 删除日志和状态文件
    │
    └─ ⑥删除原表备份 (延迟)
          └─ DROP TABLE _users_old;
```

### 7.3 清理策略选择


**🔸 保守策略 (推荐)**：
```
立即清理：
- 控制表 (_users_ghc)
- binlog连接资源  
- 临时状态文件

延迟清理：
- 原表备份 (_users_old) 保留1-7天
- 详细日志文件保留1-30天

优点：安全性高，可以快速回滚
缺点：占用额外存储空间
```

**🔸 激进策略**：
```
立即清理所有资源：
- 包括原表备份也立即删除
- 所有临时文件立即清理

优点：节省存储空间
缺点：无法快速回滚，风险较高
```

### 7.4 清理验证检查


**✅ 清理前验证**：
```sql
-- 1. 确认新表数据完整
SELECT COUNT(*) FROM users;  -- 新表
SELECT COUNT(*) FROM _users_old;  -- 原表备份

-- 2. 确认应用程序正常
-- 检查错误日志，确保没有访问异常

-- 3. 确认主从同步正常  
SHOW SLAVE STATUS\G
-- 检查Seconds_Behind_Master < 1

-- 4. 确认索引和约束正常
SHOW INDEX FROM users;
SHOW CREATE TABLE users;
```

### 7.5 清理脚本示例


```bash
#!/bin/bash
# gh-ost清理脚本

TABLE_NAME="users"
BACKUP_TABLE="_${TABLE_NAME}_old"  
CONTROL_TABLE="_${TABLE_NAME}_ghc"

echo "开始清理gh-ost相关资源..."

# 1. 删除控制表
mysql -e "DROP TABLE IF EXISTS ${CONTROL_TABLE};" 2>/dev/null
echo "✓ 控制表已删除"

# 2. 清理临时文件
rm -f /tmp/gh-ost.${TABLE_NAME}.*
echo "✓ 临时文件已清理"

# 3. 可选：删除备份表 (建议保留一段时间)
read -p "是否删除原表备份 ${BACKUP_TABLE}? (y/N): " confirm
if [[ $confirm == [yY] ]]; then
    mysql -e "DROP TABLE IF EXISTS ${BACKUP_TABLE};"
    echo "✓ 原表备份已删除"  
else
    echo "→ 原表备份已保留，请稍后手动清理"
fi

echo "清理工作完成！"
```

---

## 8. 📊 流程监控与异常处理


### 8.1 监控指标体系


**🔸 核心监控指标**

```
进度监控：
┌─────────────────────────────────────────┐
│ 阶段：数据复制中                         │  
│ 进度：68.5% (6,850,000/10,000,000行)   │
│ 速度：1,250行/秒                        │
│ 预计剩余时间：42分钟                     │
│ 当前延迟：0.8秒                         │
└─────────────────────────────────────────┘

性能监控：
┌─────────────────────────────────────────┐
│ CPU使用率：15.2%                        │
│ 内存使用：245MB                         │  
│ 磁盘IO：读45MB/s，写38MB/s              │
│ 网络IO：接收12MB/s，发送8MB/s           │
│ 复制延迟：0.8秒                         │
└─────────────────────────────────────────┘
```

### 8.2 实时状态监控


**📱 监控命令示例**：
```bash
# 查看gh-ost运行状态
echo "show processlist;" | mysql | grep gh-ost

# 查看复制进度 (通过日志)  
tail -f /var/log/gh-ost.log | grep "Migrating"

# 查看表大小变化
watch "mysql -e 'SELECT TABLE_NAME, TABLE_ROWS, DATA_LENGTH 
FROM information_schema.tables 
WHERE TABLE_NAME IN (\"users\", \"_users_gho\", \"_users_old\");'"
```

### 8.3 异常情况分类


**⚠️ 常见异常及处理策略**

| 异常类型 | **表现症状** | **影响程度** | **处理方法** |
|---------|-------------|-------------|-------------|
| **网络中断** | `binlog连接断开` | `🟡 中等` | `自动重连，继续执行` |
| **磁盘空间不足** | `写入操作失败` | `🔴 严重` | `立即停止，清理空间` |
| **主从延迟过大** | `从库同步滞后` | `🟡 中等` | `暂停操作，等待追赶` |
| **长事务阻塞** | `获取锁超时` | `🟡 中等` | `等待或杀死长事务` |
| **内存溢出** | `进程被系统杀死` | `🔴 严重` | `调整参数，重新启动` |
| **权限不足** | `操作被拒绝` | `🔴 严重` | `检查并修正权限` |

### 8.4 自动恢复机制


**🔄 断点续传功能**：
```
恢复原理：
1. gh-ost定期记录执行进度到状态文件
2. 异常中断时，读取最后的进度点
3. 从中断点继续执行，避免重复工作

状态文件示例：
{
  "last_processed_binlog_file": "mysql-bin.000123",
  "last_processed_binlog_pos": 45672345,  
  "copied_rows": 6850000,
  "current_stage": "copy_data",
  "start_time": "2024-01-15 10:30:00"
}
```

### 8.5 紧急停止处理


**🚨 紧急停止流程**：
```bash
# 1. 优雅停止 (推荐)
echo "postpone" > /tmp/gh-ost.users.postpone
# gh-ost会在当前批次完成后停止

# 2. 强制停止 (紧急情况)  
kill -TERM $(pgrep gh-ost)
# 立即停止进程

# 3. 数据库层面停止
mysql -e "KILL QUERY [gh-ost的连接ID];"
# 停止正在执行的查询
```

**恢复检查清单**：
```
停止后的检查项目：
☑️ 原表完整性验证
☑️ 影子表状态检查  
☑️ binlog位置记录
☑️ 临时文件清理
☑️ 连接资源释放
☑️ 锁状态确认
```

---

## 9. 📋 核心要点总结


### 9.1 工作流程核心要点


```
🔸 gh-ost核心思想：通过影子表实现无锁DDL操作
🔸 六大阶段：创建→复制→捕获→追赶→切换→清理  
🔸 关键特性：分批处理、实时同步、原子切换
🔸 安全保障：断点续传、异常恢复、进度监控
🔸 性能平衡：业务影响最小化，执行效率优化
```

### 9.2 各阶段重点理解


**🔹 创建阶段**：
```
重点：理解影子表和控制表的作用
影子表：承载新结构数据的"替身"
控制表：控制切换时机的"信号灯"
耗时：秒级，几乎不影响业务
```

**🔹 复制阶段**：
```
重点：理解分批复制的平衡策略  
批量大小：影响速度和性能的关键参数
执行间隔：减少业务影响的重要手段
耗时：最长，可能数小时到数天
```

**🔹 同步阶段**：
```
重点：理解实时追赶的必要性
binlog监听：捕获所有数据变更
事件应用：保持影子表与原表同步
追赶完成：为原子切换做准备
```

**🔹 切换阶段**：
```
重点：理解原子性的重要意义
瞬间完成：通过表重命名实现
业务影响：仅几毫秒到几秒的锁定
成功保障：充分的前置检查
```

### 9.3 实际应用指导


**📊 执行时机选择**：
```
最佳执行时间：
✓ 业务低峰期 (如凌晨2-6点)
✓ 系统负载较低时 (CPU < 50%)  
✓ 主从延迟最小时 (< 1秒)
✓ 有足够维护窗口时
```

**⚡ 性能优化要点**：
```
参数调优：
- 批量大小：根据表大小和性能要求调整
- 执行间隔：平衡速度和业务影响  
- 并发控制：避免对业务造成冲突
- 资源限制：控制CPU、内存、IO使用
```

**🛡️ 风险控制措施**：
```
安全策略：
- 充分的预演和测试
- 完整的备份和回滚方案
- 实时的监控和告警
- 紧急情况的停止机制
```

### 9.4 与传统DDL对比


| 对比维度 | **传统DDL** | **gh-ost流程** |
|---------|------------|----------------|
| **执行方式** | `直接修改原表` | `影子表+原子切换` |
| **锁定时间** | `整个DDL期间` | `仅切换瞬间` |
| **业务影响** | `严重，可能数小时` | `轻微，几乎无感知` |
| **可控制性** | `启动后难以控制` | `可暂停、恢复、取消` |
| **资源使用** | `锁定表，阻塞业务` | `额外空间，但不阻塞` |
| **安全性** | `失败风险高` | `多重安全保障` |

**核心记忆**：
- gh-ost通过"影子表魔法"实现无痛DDL
- 六步流程环环相扣，安全可控  
- 分批处理保平衡，原子切换保安全
- 监控异常双保险，业务无感是目标