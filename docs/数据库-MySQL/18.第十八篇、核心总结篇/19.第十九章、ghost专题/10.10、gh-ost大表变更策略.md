---
title: 10、gh-ost大表变更策略
---
## 📚 目录

1. [大表识别标准](#1-大表识别标准)
2. [变更时间评估](#2-变更时间评估)
3. [分批执行策略](#3-分批执行策略)
4. [资源使用规划](#4-资源使用规划)
5. [业务影响评估](#5-业务影响评估)
6. [维护窗口规划](#6-维护窗口规划)
7. [回滚准备方案](#7-回滚准备方案)
8. [大表优化建议](#8-大表优化建议)
9. [并发控制策略](#9-并发控制策略)
10. [容量规划考虑](#10-容量规划考虑)
11. [核心要点总结](#11-核心要点总结)

---

## 1. 📊 大表识别标准


### 1.1 什么是大表？


**大表不仅仅是数据量大**，而是综合考虑多个维度的表：

```
大表判定维度：
数据量维度 ━━━━━━━━━━━━━━━━━━━━━━━━
├─ 行数：通常 > 1000万行
├─ 数据大小：> 10GB
└─ 索引大小：> 2GB

业务维度 ━━━━━━━━━━━━━━━━━━━━━━━━━━
├─ 读写频繁：QPS > 1000
├─ 核心业务：订单、用户、支付等
└─ 24x7运行：不允许停机

技术维度 ━━━━━━━━━━━━━━━━━━━━━━━━━━
├─ DDL耗时：预估 > 2小时
├─ 锁定时间：会阻塞业务
└─ 资源消耗：CPU、内存、磁盘IO高
```

### 1.2 大表识别方法


**🔍 数据量评估**
```sql
-- 检查表的基本信息
SELECT 
    table_name,
    table_rows,
    ROUND((data_length + index_length) / 1024 / 1024 / 1024, 2) AS 'size_gb',
    ROUND(data_length / 1024 / 1024 / 1024, 2) AS 'data_gb',
    ROUND(index_length / 1024 / 1024 / 1024, 2) AS 'index_gb'
FROM information_schema.tables 
WHERE table_schema = 'your_database' 
    AND table_name = 'your_table';
```

**⚡ 性能影响评估**
```sql
-- 查看表的读写频率
SELECT 
    table_name,
    rows_read,
    rows_changed,
    rows_changed_x_indexes
FROM sys.schema_table_statistics 
WHERE table_schema = 'your_database';
```

### 1.3 大表分类标准


| 表类型 | **数据量** | **QPS范围** | **变更难度** | **建议策略** |
|--------|-----------|------------|-------------|-------------|
| 🟢 **中型表** | `1-10GB` | `< 500` | `低` | `直接gh-ost` |
| 🟡 **大型表** | `10-100GB` | `500-2000` | `中` | `分时段执行` |
| 🔴 **超大表** | `> 100GB` | `> 2000` | `高` | `分批+预案` |
| ⚫ **核心表** | `任意` | `> 5000` | `极高` | `专项方案` |

---

## 2. ⏱️ 变更时间评估


### 2.1 时间评估公式


gh-ost的变更时间主要由三个阶段组成：

```
总时间 = 全量复制时间 + 增量同步时间 + 切换时间

详细计算：
┌─ 全量复制时间 ─┐   ┌─ 增量同步 ─┐   ┌─ 切换 ─┐
│ 数据大小(GB)    │   │ 取决于写入  │   │ < 1秒 │
│ ÷ 复制速度     │ + │ 频率和延迟  │ + │      │
│ (GB/hour)     │   │           │   │      │
└──────────────┘   └───────────┘   └──────┘
```

### 2.2 复制速度评估


**🚀 影响复制速度的因素**

```
硬件因素：
├─ 磁盘类型：SSD > 机械硬盘
├─ 网络带宽：千兆 > 百兆
├─ CPU性能：影响数据处理速度
└─ 内存大小：影响缓冲区

配置因素：
├─ chunk-size：默认1000行
├─ max-load：负载控制阈值
├─ throttle：手动限速设置
└─ 并发连接数：影响数据传输
```

**📈 速度基准参考**
```
典型环境下的复制速度：
┌─ 普通配置 ─────────────────────┐
│ SSD + 千兆网络：2-5 GB/hour    │
│ 机械盘 + 千兆：1-3 GB/hour     │
│ SSD + 万兆网络：5-10 GB/hour   │
└─────────────────────────────┘

实际测试命令：
gh-ost --dry-run --estimate-time \
  --host="localhost" \
  --database="test" \
  --table="large_table" \
  --alter="ADD COLUMN new_col INT"
```

### 2.3 时间评估示例


**🔢 具体计算实例**
```
表信息：
├─ 数据大小：50GB
├─ 行数：8000万行
├─ 写入QPS：500
└─ 平均行大小：640字节

时间评估：
┌─ 全量复制 ─┐
│ 50GB ÷ 3GB/h = 16.7小时
│
┌─ 增量同步 ─┐
│ 取决于binlog延迟，通常几分钟
│
┌─ 总耗时 ─┐
│ 约17小时（加上缓冲时间）
```

---

## 3. 🔄 分批执行策略


### 3.1 为什么要分批？


**单次执行的问题：**
- ⚠️ **长时间占用资源**：影响正常业务
- ⚠️ **风险集中**：一旦失败，影响巨大
- ⚠️ **难以控制**：无法中途调整策略
- ⚠️ **回滚困难**：数据量大，回滚耗时

### 3.2 分批策略设计


**📋 按时间分批**
```
策略1：按日分批
├─ 周一-周三：非核心表
├─ 周四：中等重要表
└─ 周五-周日：观察期，不执行

策略2：按时段分批
├─ 22:00-02:00：大表DDL窗口
├─ 02:00-06:00：数据验证
└─ 06:00-08:00：回滚准备期
```

**🎯 按表分批**
```bash
# 分批执行脚本示例
#!/bin/bash

TABLES=("user_orders" "user_payments" "user_profiles")
DATABASE="ecommerce"

for table in "${TABLES[@]}"; do
    echo "开始处理表: $table"
    echo "当前时间: $(date)"
    
    # 执行gh-ost
    gh-ost \
        --host="localhost" \
        --user="ghost" \
        --password="password" \
        --database="$DATABASE" \
        --table="$table" \
        --alter="ADD COLUMN created_at_new TIMESTAMP" \
        --execute \
        --max-load="Threads_running=30" \
        --critical-load="Threads_running=50" \
        --chunk-size=500 \
        --throttle-query="SELECT COUNT(*) FROM processlist WHERE command != 'Sleep'" \
        --throttle-flag-file="/tmp/gh-ost.throttle.$table"
    
    if [ $? -eq 0 ]; then
        echo "表 $table 处理成功"
    else
        echo "表 $table 处理失败，停止后续操作"
        break
    fi
    
    # 间隔等待，让系统恢复
    echo "等待系统恢复..."
    sleep 1800  # 等待30分钟
done
```

### 3.3 分批监控要点


**📊 关键监控指标**
```
系统资源监控：
├─ CPU使用率：< 70%
├─ 内存使用率：< 80%
├─ 磁盘IO：< 80%
└─ 网络带宽：< 60%

MySQL状态监控：
├─ Threads_running：< 30
├─ Threads_connected：正常范围
├─ 主从延迟：< 5秒
└─ 慢查询：无异常增长
```

---

## 4. 💻 资源使用规划


### 4.1 资源需求评估


**🔧 CPU资源规划**
```
gh-ost CPU消耗来源：
┌─ 数据处理 ─┐
│ ├─ 行数据解析
│ ├─ 索引重建计算
│ └─ 校验和计算
│
┌─ 网络通信 ─┐
│ ├─ binlog读取
│ ├─ 数据传输
│ └─ 复制协议处理

建议配置：
├─ 预留20-30% CPU资源
├─ 监控CPU load < 核心数
└─ 必要时降低chunk-size
```

**💾 内存资源规划**
```
内存使用分析：
┌─ gh-ost进程 ─────────┐
│ 基础内存：~100MB       │
│ 缓冲区：chunk-size相关 │
│ 连接池：连接数 × 8MB   │
│
┌─ MySQL影响 ─────────┐
│ InnoDB缓冲池：可能增加│
│ 查询缓存：临时增长    │
│ 临时表：DDL过程产生  │

规划原则：
├─ 预留系统内存的15-20%
├─ 监控swap使用情况
└─ 合理设置chunk-size
```

### 4.2 磁盘IO规划


**💿 磁盘空间需求**
```
空间计算公式：
需要空间 = 原表大小 × 1.5

空间分布：
┌─ 幽灵表 ─┐   ┌─ 原表 ─┐   ┌─ 缓冲 ─┐
│ 1.0倍    │ + │ 1.0倍  │ + │ 0.5倍 │
└─────────┘   └───────┘   └───────┘

示例：
原表50GB → 需要75GB可用空间
```

**⚡ IO性能优化**
```bash
# IO监控命令
iostat -x 1

# 优化参数
gh-ost \
    --chunk-size=500 \          # 减小chunk降低IO压力
    --max-load="Threads_running=25,Innodb_rows_read=5000" \
    --nice-ratio=0.1 \          # 降低优先级
    --sleep=100ms               # 增加间歇时间
```

### 4.3 资源监控脚本


**📊 监控脚本示例**
```bash
#!/bin/bash
# 资源监控脚本

LOG_FILE="/var/log/gh-ost-monitor.log"

while true; do
    TIMESTAMP=$(date '+%Y-%m-%d %H:%M:%S')
    
    # CPU使用率
    CPU_USAGE=$(top -bn1 | grep "Cpu(s)" | awk '{print $2}' | cut -d'%' -f1)
    
    # 内存使用率
    MEM_USAGE=$(free | grep Mem | awk '{printf "%.1f", ($3/$2) * 100.0}')
    
    # 磁盘IO
    IO_UTIL=$(iostat -x 1 2 | tail -1 | awk '{print $NF}')
    
    # MySQL连接数
    MYSQL_CONN=$(mysql -e "SHOW STATUS LIKE 'Threads_connected';" | tail -1 | awk '{print $2}')
    
    # 记录日志
    echo "$TIMESTAMP,CPU:${CPU_USAGE}%,MEM:${MEM_USAGE}%,IO:${IO_UTIL}%,CONN:$MYSQL_CONN" >> $LOG_FILE
    
    # 检查阈值
    if (( $(echo "$CPU_USAGE > 80" | bc -l) )); then
        echo "$TIMESTAMP: 警告 - CPU使用率过高: ${CPU_USAGE}%" >> $LOG_FILE
    fi
    
    sleep 60
done
```

---

## 5. 📈 业务影响评估


### 5.1 影响维度分析


**🎯 业务影响的三个层面**

```
用户体验影响：
├─ 响应时间：查询可能变慢
├─ 功能可用性：某些功能暂时受限
└─ 数据一致性：短暂的读取延迟

系统性能影响：
├─ 数据库负载：CPU、内存、IO增加
├─ 网络流量：数据复制增加带宽消耗
└─ 存储空间：临时需要额外空间

业务流程影响：
├─ 批处理任务：可能需要调整时间
├─ 报表生成：可能出现延迟
└─ 数据备份：需要协调执行时间
```

### 5.2 影响等级划分


| 影响等级 | **响应时间** | **可用性** | **数据准确性** | **应对策略** |
|---------|-------------|------------|---------------|-------------|
| 🟢 **轻微** | `< 10%增加` | `100%可用` | `无影响` | `正常执行` |
| 🟡 **中等** | `10-30%增加` | `99%可用` | `轻微延迟` | `业务通知` |
| 🔴 **严重** | `> 30%增加` | `< 99%可用` | `明显延迟` | `错峰执行` |
| ⚫ **极严重** | `超时增多` | `功能不可用` | `数据不一致` | `紧急停止` |

### 5.3 影响评估工具


**📊 性能基线建立**
```sql
-- 执行前的性能基线
CREATE TABLE performance_baseline AS
SELECT 
    NOW() as check_time,
    'before_ddl' as phase,
    (SELECT COUNT(*) FROM information_schema.processlist WHERE state != '') as active_threads,
    (SELECT VARIABLE_VALUE FROM information_schema.global_status WHERE VARIABLE_NAME = 'Queries') as total_queries,
    (SELECT VARIABLE_VALUE FROM information_schema.global_status WHERE VARIABLE_NAME = 'Slow_queries') as slow_queries;

-- 执行中监控
INSERT INTO performance_baseline 
SELECT 
    NOW(),
    'during_ddl',
    (SELECT COUNT(*) FROM information_schema.processlist WHERE state != ''),
    (SELECT VARIABLE_VALUE FROM information_schema.global_status WHERE VARIABLE_NAME = 'Queries'),
    (SELECT VARIABLE_VALUE FROM information_schema.global_status WHERE VARIABLE_NAME = 'Slow_queries');
```

**🔍 业务监控脚本**
```bash
#!/bin/bash
# 业务影响监控

API_ENDPOINT="http://your-api.com/health"
RESPONSE_TIME_THRESHOLD=2000  # 2秒

check_api_performance() {
    START_TIME=$(date +%s%N)
    HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" $API_ENDPOINT)
    END_TIME=$(date +%s%N)
    
    RESPONSE_TIME=$(( (END_TIME - START_TIME) / 1000000 ))  # 转换为毫秒
    
    if [ $HTTP_CODE -eq 200 ] && [ $RESPONSE_TIME -lt $RESPONSE_TIME_THRESHOLD ]; then
        echo "OK: API响应正常 (${RESPONSE_TIME}ms)"
    else
        echo "WARN: API异常 HTTP:$HTTP_CODE 时间:${RESPONSE_TIME}ms"
        # 可以触发报警
    fi
}

# 每分钟检查一次
while true; do
    check_api_performance
    sleep 60
done
```

---

## 6. 🕐 维护窗口规划


### 6.1 维护窗口选择原则


**📅 时间窗口优先级**

```
最佳时间窗口：
┌─ 业务低峰期 ─┐
│ 凌晨 2:00-6:00  │  ← 用户最少
│ 周末凌晨        │  ← 业务量最低
│ 节假日深夜      │  ← 影响最小
└──────────────┘

可接受时间窗口：
┌─ 次优选择 ─┐
│ 晚上 22:00-2:00  │  ← 部分用户在线
│ 工作日凌晨       │  ← 少量夜间业务
└──────────────┘

避免时间窗口：
┌─ 不建议 ─┐
│ 白天工作时间      │  ← 用户集中
│ 促销活动期间      │  ← 业务高峰
│ 月末季末         │  ← 财务结算
└──────────────┘
```

### 6.2 窗口时长规划


**⏰ 时间窗口计算**
```
窗口时间 = DDL执行时间 × 1.5 + 验证时间 + 回滚缓冲时间

具体构成：
┌─ DDL执行 ─┐   ┌─ 数据验证 ─┐   ┌─ 回滚缓冲 ─┐
│ 预估时间   │ + │ 30-60分钟  │ + │ 30分钟     │
│ × 1.5倍   │   │           │   │           │
└──────────┘   └───────────┘   └───────────┘

示例计算：
├─ 预估DDL：4小时
├─ 安全系数：4 × 1.5 = 6小时
├─ 验证时间：1小时
├─ 回滚缓冲：0.5小时
└─ 总窗口：7.5小时
```

### 6.3 窗口规划模板


**📋 维护计划模板**
```
维护窗口规划表：
┌─────────────────────────────────────┐
│ 项目：大表DDL变更                    │
│ 负责人：DBA团队                      │
│ 时间：2024-01-15 02:00-09:00        │
├─────────────────────────────────────┤
│ 时间安排：                          │
│ 01:30-02:00  准备阶段               │
│ 02:00-06:00  DDL执行                │
│ 06:00-07:00  数据验证               │
│ 07:00-08:00  业务验证               │
│ 08:00-09:00  监控观察               │
├─────────────────────────────────────┤
│ 人员安排：                          │
│ 主执行：DBA-A                       │
│ 监控：DBA-B                         │
│ 应急：DBA-C(待命)                   │
│ 业务：业务负责人                     │
├─────────────────────────────────────┤
│ 应急预案：                          │
│ 09:00前未完成 → 立即回滚             │
│ 业务异常 → 评估后决定                │
│ 系统故障 → 紧急恢复                 │
└─────────────────────────────────────┘
```

---

## 7. 🔄 回滚准备方案


### 7.1 回滚触发条件


**🚨 自动回滚条件**
```
系统层面触发：
├─ CPU持续 > 90% 超过5分钟
├─ 内存使用 > 95%
├─ 磁盘空间 < 5%
└─ 主从延迟 > 60秒

业务层面触发：
├─ API错误率 > 1%
├─ 响应时间 > 5秒
├─ 用户投诉激增
└─ 关键业务无法访问

时间层面触发：
├─ 超出维护窗口80%仍未完成
├─ 执行时间超过预估2倍
└─ 临近业务高峰期
```

### 7.2 回滚方案设计


**⚡ 快速回滚步骤**

```bash
#!/bin/bash
# gh-ost 快速回滚脚本

GHOST_PID_FILE="/tmp/gh-ost.pid"
GHOST_LOG_FILE="/var/log/gh-ost.log"
ROLLBACK_LOG="/var/log/gh-ost-rollback.log"

echo "$(date): 开始回滚操作" >> $ROLLBACK_LOG

# 1. 停止gh-ost进程
if [ -f $GHOST_PID_FILE ]; then
    GHOST_PID=$(cat $GHOST_PID_FILE)
    echo "$(date): 停止gh-ost进程 PID:$GHOST_PID" >> $ROLLBACK_LOG
    kill -TERM $GHOST_PID
    
    # 等待进程正常结束
    sleep 30
    
    # 强制结束（如果需要）
    if kill -0 $GHOST_PID 2>/dev/null; then
        kill -KILL $GHOST_PID
        echo "$(date): 强制终止gh-ost进程" >> $ROLLBACK_LOG
    fi
fi

# 2. 清理幽灵表
mysql -e "
USE your_database;
DROP TABLE IF EXISTS _your_table_gho;
DROP TABLE IF EXISTS _your_table_ghc;
"

echo "$(date): 清理完成，系统已回滚到DDL前状态" >> $ROLLBACK_LOG

# 3. 验证原表状态
mysql -e "
SELECT 
    table_name,
    table_rows,
    ROUND((data_length + index_length)/1024/1024/1024,2) as size_gb
FROM information_schema.tables 
WHERE table_schema = 'your_database' 
AND table_name = 'your_table';
"
```

### 7.3 回滚验证清单


**✅ 回滚后验证项目**

```
数据完整性验证：
☐ 原表数据行数正确
☐ 原表结构未改变  
☐ 索引状态正常
☐ 外键约束完整

系统状态验证：
☐ 磁盘空间已释放
☐ 系统负载恢复正常
☐ MySQL连接数正常
☐ 主从复制正常

业务功能验证：
☐ 关键API响应正常
☐ 用户操作无异常
☐ 数据查询结果正确
☐ 报表统计准确

监控指标验证：
☐ 错误率恢复正常
☐ 响应时间恢复基线
☐ 系统资源使用正常
☐ 数据库性能指标正常
```

---

## 8. 🔧 大表优化建议


### 8.1 表结构优化


**📊 索引优化策略**

```sql
-- 优化前分析
EXPLAIN FORMAT=JSON SELECT * FROM large_table WHERE status = 'active';

-- 索引优化建议
-- 1. 删除冗余索引
DROP INDEX duplicate_index_name ON large_table;

-- 2. 创建复合索引
CREATE INDEX idx_status_created ON large_table (status, created_at);

-- 3. 前缀索引（适用于长字符串）
CREATE INDEX idx_email_prefix ON large_table (email(20));
```

**🗃️ 分区策略**
```sql
-- 按时间分区（推荐用于大表）
ALTER TABLE large_table PARTITION BY RANGE (YEAR(created_at)) (
    PARTITION p2020 VALUES LESS THAN (2021),
    PARTITION p2021 VALUES LESS THAN (2022),
    PARTITION p2022 VALUES LESS THAN (2023),
    PARTITION p2023 VALUES LESS THAN (2024),
    PARTITION p2024 VALUES LESS THAN (2025),
    PARTITION p_future VALUES LESS THAN MAXVALUE
);

-- 查看分区效果
SELECT 
    partition_name,
    table_rows,
    ROUND((data_length + index_length)/1024/1024/1024,2) as size_gb
FROM information_schema.partitions 
WHERE table_name = 'large_table' AND partition_name IS NOT NULL;
```

### 8.2 查询优化


**⚡ 慢查询优化**
```sql
-- 开启慢查询日志
SET GLOBAL slow_query_log = 'ON';
SET GLOBAL long_query_time = 1;

-- 分析慢查询
SELECT 
    sql_text,
    count_star,
    avg_timer_wait/1000000000 as avg_time_sec,
    sum_timer_wait/1000000000 as total_time_sec
FROM performance_schema.events_statements_summary_by_digest 
WHERE schema_name = 'your_database'
ORDER BY sum_timer_wait DESC 
LIMIT 10;
```

**🎯 查询重写建议**
```sql
-- 避免全表扫描
-- ❌ 不好的查询
SELECT * FROM large_table WHERE YEAR(created_at) = 2023;

-- ✅ 优化后的查询  
SELECT * FROM large_table 
WHERE created_at >= '2023-01-01' 
  AND created_at < '2024-01-01';

-- 避免SELECT *
-- ❌ 不好的查询
SELECT * FROM large_table WHERE id = 12345;

-- ✅ 优化后的查询
SELECT id, name, status FROM large_table WHERE id = 12345;
```

### 8.3 维护优化


**🔄 定期维护策略**
```bash
#!/bin/bash
# 大表维护脚本

DATABASE="your_database"
TABLE="large_table"

# 1. 分析表统计信息
mysql -e "ANALYZE TABLE $DATABASE.$TABLE;"

# 2. 优化表（谨慎使用，会锁表）
# mysql -e "OPTIMIZE TABLE $DATABASE.$TABLE;"

# 3. 检查表完整性
mysqlcheck --check --databases $DATABASE --tables $TABLE

# 4. 更新统计信息
mysql -e "
USE $DATABASE;
ANALYZE TABLE $TABLE;
SHOW TABLE STATUS LIKE '$TABLE'\G
"

echo "表 $TABLE 维护完成: $(date)"
```

---

## 9. 🚦 并发控制策略


### 9.1 并发控制原理


**🔒 gh-ost并发控制机制**

```
并发控制层次：
┌─ 连接层控制 ─┐
│ ├─ max-load：负载阈值
│ ├─ critical-load：紧急阈值  
│ └─ throttle：主动限速
│
┌─ 操作层控制 ─┐
│ ├─ chunk-size：批次大小
│ ├─ nice-ratio：优先级控制
│ └─ sleep：操作间隔
│
┌─ 业务层控制 ─┐
│ ├─ throttle-query：业务查询
│ ├─ throttle-flag-file：外部控制
│ └─ postpone-cut-over：延迟切换
```

### 9.2 并发参数调优


**⚖️ 负载控制参数**
```bash
# 基础负载控制
gh-ost \
    --max-load="Threads_running=25,Threads_connected=100" \
    --critical-load="Threads_running=50,Threads_connected=200" \
    --chunk-size=1000 \
    --nice-ratio=0.1

# 高级负载控制
gh-ost \
    --throttle-query="SELECT COUNT(*) FROM INFORMATION_SCHEMA.PROCESSLIST WHERE COMMAND != 'Sleep' AND TIME > 5" \
    --throttle-flag-file="/tmp/gh-ost.throttle" \
    --max-lag-millis=3000
```

**📊 参数优化表格**

| 参数 | **低负载环境** | **中负载环境** | **高负载环境** | **说明** |
|------|--------------|--------------|--------------|----------|
| `chunk-size` | `2000-5000` | `1000-2000` | `500-1000` | `批次越小，影响越小` |
| `max-load` | `Threads_running=20` | `Threads_running=15` | `Threads_running=10` | `运行线程数阈值` |
| `nice-ratio` | `0.1` | `0.2` | `0.5` | `让出时间比例` |
| `sleep` | `100ms` | `200ms` | `500ms` | `批次间隔时间` |

### 9.3 动态调节策略


**🎛️ 实时调节脚本**
```bash
#!/bin/bash
# 动态负载调节脚本

THROTTLE_FILE="/tmp/gh-ost.throttle"
LOG_FILE="/var/log/gh-ost-throttle.log"

monitor_and_throttle() {
    while [ -f "/tmp/gh-ost.pid" ]; do
        # 获取当前负载
        THREADS_RUNNING=$(mysql -sN -e "SHOW STATUS LIKE 'Threads_running';" | awk '{print $2}')
        CPU_USAGE=$(top -bn1 | grep "Cpu(s)" | awk '{print $2}' | cut -d'%' -f1)
        
        # 动态调节策略
        if [ $THREADS_RUNNING -gt 30 ] || [ $(echo "$CPU_USAGE > 80" | bc) -eq 1 ]; then
            # 高负载：开启限流
            touch $THROTTLE_FILE
            echo "$(date): 高负载限流 - Threads:$THREADS_RUNNING, CPU:$CPU_USAGE%" >> $LOG_FILE
            sleep 60
        elif [ $THREADS_RUNNING -lt 15 ] && [ $(echo "$CPU_USAGE < 50" | bc) -eq 1 ]; then
            # 低负载：取消限流
            rm -f $THROTTLE_FILE
            echo "$(date): 低负载恢复 - Threads:$THREADS_RUNNING, CPU:$CPU_USAGE%" >> $LOG_FILE
            sleep 30
        else
            # 中等负载：保持当前状态
            sleep 45
        fi
    done
}

# 启动监控
monitor_and_throttle &
```

---

## 10. 📏 容量规划考虑


### 10.1 存储容量规划


**💾 空间需求计算**

```
存储空间规划公式：
总需求 = 原表空间 × 2.5 + 日志空间 + 备份空间

详细分解：
┌─ 原表空间 ─┐   ┌─ 幽灵表空间 ─┐   ┌─ 缓冲空间 ─┐
│ 100%      │ + │ 110%        │ + │ 40%       │
│           │   │ (含索引重建) │   │ (安全边际)  │
└───────────┘   └─────────────┘   └───────────┘

┌─ binlog空间 ─┐   ┌─ 备份空间 ─┐
│ 原表大小×0.3  │ + │ 原表大小   │
│ (DDL期间产生) │   │ (全备份)   │
└─────────────┘   └───────────┘
```

**📊 容量规划示例**
```
假设：原表 100GB

空间分配：
├─ 原表：100GB (保持不变)
├─ 幽灵表：110GB (包含新增列和索引)  
├─ 缓冲空间：40GB (应对意外情况)
├─ binlog：30GB (DDL期间的变更日志)
├─ 备份：100GB (DDL前的完整备份)
└─ 总需求：380GB

实际建议：预留 400GB 空间
```

### 10.2 性能容量规划


**⚡ IOPS需求评估**
```
IOPS需求计算：
基础IOPS = 正常业务IOPS
gh-ost额外IOPS = (表大小GB / chunk执行时间秒) × IOPS系数

示例计算：
├─ 正常业务：2000 IOPS
├─ 表大小：50GB
├─ chunk处理：每秒处理1000行
├─ 平均行大小：1KB
├─ gh-ost额外：约1500 IOPS
└─ 总需求：3500 IOPS

磁盘类型选择：
├─ 机械盘：150 IOPS → 不足
├─ SSD：10000 IOPS → 充足
└─ NVMe SSD：50000 IOPS → 充足
```

### 10.3 网络带宽规划


**🌐 带宽需求计算**
```bash
# 带宽监控脚本
#!/bin/bash

interface="eth0"
monitor_duration=300  # 5分钟

get_bytes() {
    cat /proc/net/dev | grep $interface | awk '{print $2 "," $10}'
}

# DDL执行前基线
echo "建立网络基线..."
baseline=$(get_bytes)
baseline_rx=$(echo $baseline | cut -d',' -f1)
baseline_tx=$(echo $baseline | cut -d',' -f2)

sleep $monitor_duration

# DDL执行中的使用量
current=$(get_bytes)
current_rx=$(echo $current | cut -d',' -f1)
current_tx=$(echo $current | cut -d',' -f2)

# 计算带宽使用
rx_bytes=$((current_rx - baseline_rx))
tx_bytes=$((current_tx - baseline_tx))
rx_mbps=$((rx_bytes * 8 / monitor_duration / 1024 / 1024))
tx_mbps=$((tx_bytes * 8 / monitor_duration / 1024 / 1024))

echo "DDL期间网络使用："
echo "下行: ${rx_mbps} Mbps"
echo "上行: ${tx_mbps} Mbps"
```

**📈 容量规划建议表**

| 表大小 | **磁盘空间** | **IOPS需求** | **带宽需求** | **内存建议** |
|-------|-------------|-------------|-------------|-------------|
| `< 10GB` | `30GB` | `+500 IOPS` | `+50 Mbps` | `+2GB` |
| `10-50GB` | `150GB` | `+1500 IOPS` | `+150 Mbps` | `+8GB` |
| `50-200GB` | `600GB` | `+3000 IOPS` | `+300 Mbps` | `+16GB` |
| `> 200GB` | `定制规划` | `+5000 IOPS` | `+500 Mbps` | `+32GB` |

---

## 11. 📋 核心要点总结


### 11.1 必须掌握的关键概念


```
🔸 大表标准：不只看大小，要综合评估业务重要性和性能影响
🔸 时间评估：全量复制 + 增量同步 + 切换时间，留足安全余量  
🔸 分批策略：按表分批、按时间分批，降低风险集中度
🔸 资源规划：CPU、内存、磁盘、网络四维度评估
🔸 影响评估：用户体验、系统性能、业务流程三个层面
🔸 维护窗口：选择业务低峰期，预留充足时间
🔸 回滚方案：明确触发条件，快速回滚步骤
🔸 优化建议：表结构、查询、维护三个方向优化
🔸 并发控制：负载阈值、批次大小、优先级调节
🔸 容量规划：存储、性能、网络全方位规划
```

### 11.2 实际操作要点


**🔹 执行前准备**
```
环境准备：
- 确认磁盘空间充足（至少2.5倍表大小）
- 验证数据库配置参数
- 建立监控基线
- 准备回滚脚本

风险评估：
- 评估业务影响程度
- 确定维护时间窗口
- 制定应急预案
- 通知相关业务方
```

**🔹 执行中监控**
```
关键指标：
- 系统负载：CPU、内存、IO
- MySQL状态：连接数、运行线程数
- 业务指标：响应时间、错误率
- 执行进度：完成百分比、剩余时间

调节策略：
- 负载过高时启用限流
- 业务异常时暂停执行
- 时间超限时考虑回滚
- 资源不足时释放空间
```

**🔹 执行后验证**
```
数据验证：
- 表结构变更正确性
- 数据完整性校验
- 索引创建完整性
- 业务功能正常性

性能验证：
- 系统负载恢复正常
- 查询性能无明显下降
- 业务指标回归基线
- 用户体验保持稳定
```

### 11.3 最佳实践建议


**💡 经验总结**
- **准备充分**：执行前的准备时间至少是执行时间的2倍
- **监控完备**：建立多维度监控，及时发现问题
- **沟通到位**：与业务方充分沟通，设定合理预期
- **预案完善**：制定详细的应急处理方案
- **文档记录**：详细记录执行过程，便于后续优化

**⚠️ 常见陷阱避免**
- 不要在业务高峰期执行大表DDL
- 不要忽视磁盘空间监控
- 不要设置过于激进的chunk-size
- 不要在没有回滚方案的情况下执行
- 不要忽视对主从复制的影响

**🚀 优化方向**
- 根据业务特点调整执行策略
- 建立标准化的执行流程
- 积累不同表类型的最佳参数配置
- 开发自动化监控和调节工具
- 持续优化表结构和查询性能

**核心记忆要点**：
- gh-ost大表变更需要综合考虑多个维度
- 充分的准备和完善的监控是成功的关键
- 分批执行和灵活调节可以有效控制风险
- 容量规划和性能评估确保系统稳定运行