---
title: 6、Gravity基础配置详解
---
## 📚 目录

1. [Gravity配置概述](#1-gravity配置概述)
2. [配置文件结构详解](#2-配置文件结构详解)
3. [全局配置参数](#3-全局配置参数)
4. [数据库连接配置](#4-数据库连接配置)
5. [同步规则配置](#5-同步规则配置)
6. [输入输出配置](#6-输入输出配置)
7. [过滤器配置](#7-过滤器配置)
8. [路由规则配置](#8-路由规则配置)
9. [监控配置](#9-监控配置)
10. [配置最佳实践](#10-配置最佳实践)
11. [核心要点总结](#11-核心要点总结)

---

## 1. 🎯 Gravity配置概述


### 1.1 什么是Gravity配置


**🔸 简单理解**
Gravity的配置就像是给这个MySQL同步工具写一份"工作说明书"，告诉它：
- 从哪个数据库读数据（源端）
- 把数据写到哪里去（目标端）
- 哪些数据需要同步，哪些不需要
- 同步过程中要做什么处理

**🔸 配置的重要性**
```
没有配置 = 工具不知道怎么工作
配置错误 = 数据同步出问题
配置合理 = 稳定高效的数据同步
```

### 1.2 配置文件的作用


**🌰 生活类比**
就像你要让一个搬家工人帮你搬家，你需要告诉他：
- 从哪个房子搬（源数据库）
- 搬到哪个房子（目标系统）
- 哪些东西要搬，哪些不搬（过滤规则）
- 什么时候搬，怎么搬（同步策略）

### 1.3 配置文件格式


Gravity使用 `TOML` 格式的配置文件，这种格式的特点：
- **易读易写**：比JSON更容易阅读
- **支持注释**：可以写注释说明
- **层次清晰**：用中括号表示不同的配置段

```toml
# 这是注释，以#开头
[global]  # 全局配置段
name = "gravity-cluster"

[mysql]   # MySQL配置段  
host = "localhost"
port = 3306
```

---

## 2. 📋 配置文件结构详解


### 2.1 配置文件整体结构


```
gravity.toml 配置文件结构：

├── [global]           # 全局配置
├── [mysql]            # MySQL连接配置
├── [inputs]           # 输入源配置
│   ├── [inputs.mysql] # MySQL输入配置
│   └── [inputs.mongo] # MongoDB输入配置(可选)
├── [outputs]          # 输出目标配置
│   ├── [outputs.mysql]# MySQL输出配置
│   ├── [outputs.kafka]# Kafka输出配置
│   └── [outputs.elasticsearch] # ES输出配置
├── [filters]          # 过滤器配置
├── [scheduler]        # 调度器配置
└── [web]              # Web监控配置
```

### 2.2 配置段的关系


```
┌─────────────┐    ┌─────────────┐    ┌─────────────┐
│   输入源     │───▶│   过滤器     │───▶│   输出目标   │
│  (inputs)   │    │  (filters)  │    │  (outputs)  │
└─────────────┘    └─────────────┘    └─────────────┘
       ▲                   ▲                   ▲
       │                   │                   │
       └─────────────── 全局配置控制 ────────────┘
```

### 2.3 最小配置示例


```toml
# 最简单的配置文件示例
[global]
name = "my-gravity"

[mysql]
host = "127.0.0.1"
username = "root"
password = "123456"
port = 3306

[inputs.mysql]
source = "test_db"

[outputs.mysql]
target = "target_db"
```

> 💡 **新手提示**  
> 这是一个最基础的配置，实现从本地MySQL的test_db同步到target_db

---

## 3. ⚙️ 全局配置参数


### 3.1 基本全局参数


**🔸 核心参数说明**

```toml
[global]
# 集群名称，用于标识这个Gravity实例
name = "gravity-production"

# 工作目录，Gravity会在这里存放临时文件
work-dir = "/data/gravity"

# 日志级别：debug, info, warn, error
log-level = "info"

# 最大内存使用量，超过会触发GC
max-memory = "2GB"

# 心跳间隔，用于集群协调
heartbeat-interval = "10s"
```

**🔸 参数详细含义**

| 参数名 | **作用** | **示例值** | **注意事项** |
|--------|---------|-----------|-------------|
| `name` | `实例标识` | `"gravity-prod"` | `集群中唯一，建议有意义的名字` |
| `work-dir` | `工作目录` | `"/data/gravity"` | `确保目录存在且有写权限` |
| `log-level` | `日志级别` | `"info"` | `生产环境建议info或warn` |
| `max-memory` | `内存限制` | `"2GB"` | `根据服务器配置调整` |

### 3.2 高级全局参数


```toml
[global]
# 是否启用调试模式
debug = false

# PID文件位置，用于进程管理
pid-file = "/var/run/gravity.pid"

# 优雅关闭超时时间
shutdown-timeout = "30s"

# 是否启用性能分析
enable-profile = false
profile-port = 6060
```

> ⚠️ **重要提醒**  
> debug模式会输出大量日志，生产环境请关闭

---

## 4. 🔗 数据库连接配置


### 4.1 MySQL连接基础配置


**🔸 基本连接参数**

```toml
[mysql]
# 数据库主机地址
host = "192.168.1.100"

# 端口号
port = 3306

# 用户名和密码
username = "gravity_user"
password = "strong_password123"

# 默认数据库
database = "test_db"
```

**🔸 连接池配置**

```toml
[mysql]
# 最大连接数
max-connections = 100

# 最大空闲连接数
max-idle-connections = 10

# 连接最大生存时间
connection-max-lifetime = "3600s"

# 连接超时时间
connection-timeout = "30s"

# 读取超时时间
read-timeout = "30s"

# 写入超时时间
write-timeout = "30s"
```

**🌰 连接池类比理解**
```
连接池就像停车场：
- max-connections = 停车场总车位数
- max-idle-connections = 平时保留的空车位
- connection-max-lifetime = 车最长停放时间
- timeout = 进出停车场的最长等待时间
```

### 4.2 高级连接配置


```toml
[mysql]
# 字符集设置
charset = "utf8mb4"

# 时区设置
location = "Asia/Shanghai"

# 是否启用SSL
tls = false

# 自动重连
auto-reconnect = true

# 批量插入大小
batch-size = 1000

# binlog格式要求
binlog-format = "ROW"
```

### 4.3 权限要求说明


**🔸 源数据库权限（用于读取）**
```sql
-- Gravity需要的最小权限
GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'gravity_user'@'%';

-- 如果需要读取binlog位置信息
GRANT SUPER ON *.* TO 'gravity_user'@'%';
```

**🔸 目标数据库权限（用于写入）**
```sql
-- 目标数据库需要的权限
GRANT SELECT, INSERT, UPDATE, DELETE, CREATE, ALTER ON target_db.* TO 'gravity_user'@'%';
```

> 🔍 **权限最小化原则**  
> 生产环境建议只给必要的权限，提高安全性

---

## 5. 📊 同步规则配置


### 5.1 基础同步规则


**🔸 表级别同步规则**

```toml
[sync-rules]
# 指定要同步的数据库
databases = ["test_db", "user_db"]

# 指定要同步的表（支持通配符）
tables = [
    "test_db.users",           # 同步users表
    "test_db.orders_*",        # 同步所有orders_开头的表
    "user_db.*"                # 同步user_db的所有表
]

# 排除的表
exclude-tables = [
    "test_db.temp_*",          # 排除临时表
    "test_db.logs"             # 排除日志表
]
```

**🔸 字段级别同步规则**

```toml
[sync-rules.column-rules]
# 指定要同步的字段
include-columns = [
    "users.id",
    "users.name", 
    "users.email"
]

# 排除敏感字段
exclude-columns = [
    "users.password",          # 排除密码字段
    "users.phone",             # 排除手机号
    "*.created_by"             # 排除所有表的created_by字段
]
```

### 5.2 数据过滤规则


**🔸 基于条件的过滤**

```toml
[sync-rules.filters]
# 只同步活跃用户
"test_db.users" = "status = 'active'"

# 只同步最近的订单
"test_db.orders" = "created_at > DATE_SUB(NOW(), INTERVAL 30 DAY)"

# 排除测试数据
"test_db.products" = "name NOT LIKE 'test_%'"
```

**🔸 批量处理规则**

```toml
[sync-rules.batch]
# 批量大小
size = 1000

# 批量超时时间
timeout = "30s"

# 并发批次数
parallel = 4
```

> 💡 **过滤规则建议**  
> 在源端过滤数据比在目标端处理更高效

---

## 6. 📥 输入输出配置


### 6.1 输入源配置


**🔸 MySQL输入配置**

```toml
[inputs.mysql]
# 数据源模式：full（全量）, incremental（增量）, binlog（实时）
mode = "binlog"

# 起始位置配置
[inputs.mysql.position]
# binlog文件名
binlog-name = "mysql-bin.000001"
# binlog位置
binlog-pos = 154

# 增量同步配置
[inputs.mysql.incremental]
# 用于增量同步的时间字段
timestamp-column = "updated_at"
# 同步间隔
interval = "5m"
```

**🔸 输入模式选择指南**

| 模式 | **适用场景** | **优点** | **缺点** |
|------|------------|---------|---------|
| `full` | `首次同步，数据修复` | `数据完整` | `速度慢，影响性能` |
| `incremental` | `定时批量同步` | `可控制影响` | `可能有延迟` |
| `binlog` | `实时同步` | `延迟最低` | `对源库有要求` |

### 6.2 输出目标配置


**🔸 MySQL输出配置**

```toml
[outputs.mysql]
# 目标数据库配置
host = "target-mysql-host"
port = 3306
username = "target_user"
password = "target_password"
database = "target_db"

# 写入模式
mode = "upsert"  # insert, update, upsert, replace

# 批量写入配置
batch-size = 500
batch-timeout = "10s"

# 冲突处理
conflict-resolution = "source-wins"  # source-wins, target-wins, merge
```

**🔸 Kafka输出配置**

```toml
[outputs.kafka]
# Kafka集群地址
brokers = ["kafka1:9092", "kafka2:9092", "kafka3:9092"]

# 主题配置
topic = "mysql-changes"

# 消息格式
format = "json"  # json, avro, protobuf

# 生产者配置
[outputs.kafka.producer]
# 确认级别
acks = "all"
# 重试次数
retries = 3
# 批量大小
batch-size = 16384
```

### 6.3 输出格式配置


**🔸 JSON格式输出**

```toml
[outputs.format]
type = "json"

# 包含的元数据
include-schema = true
include-timestamp = true
include-binlog-info = true

# JSON格式示例输出
# {
#   "database": "test_db",
#   "table": "users", 
#   "type": "insert",
#   "data": {"id": 1, "name": "张三"},
#   "timestamp": "2025-09-12T16:30:00Z"
# }
```

---

## 7. 🔍 过滤器配置


### 7.1 数据转换过滤器


**🔸 字段转换过滤器**

```toml
[filters.transform]
# 字段重命名
[filters.transform.rename]
"old_column_name" = "new_column_name"
"user_id" = "uid"

# 字段类型转换
[filters.transform.cast]
"age" = "string"           # 将age转为字符串
"price" = "decimal(10,2)"  # 将price转为decimal

# 字段默认值
[filters.transform.default]
"status" = "active"        # 如果status为空，设为active
"created_at" = "NOW()"     # 如果created_at为空，设为当前时间
```

**🔸 数据清洗过滤器**

```toml
[filters.clean]
# 去除空白字符
trim-whitespace = true

# 处理空值
null-handling = "skip"  # skip, default, error

# 数据验证
[filters.clean.validation]
"email" = "email"          # 验证邮箱格式
"phone" = "phone"          # 验证手机号格式
"age" = "range(0,120)"     # 验证年龄范围
```

### 7.2 业务逻辑过滤器


**🔸 条件过滤器**

```toml
[filters.condition]
# 只处理特定条件的数据
expression = "status = 'active' AND age >= 18"

# 根据表名应用不同过滤条件
[filters.condition.rules]
"users" = "status != 'deleted'"
"orders" = "amount > 0"
"products" = "stock > 0"
```

**🔸 路由过滤器**

```toml
[filters.route]
# 根据数据内容路由到不同输出
[filters.route.rules]
# VIP用户数据发送到特殊队列
"user_type = 'vip'" = "outputs.kafka-vip"
# 普通用户数据发送到普通队列  
"user_type = 'normal'" = "outputs.kafka-normal"
# 订单数据发送到订单处理系统
"table = 'orders'" = "outputs.order-system"
```

### 7.3 自定义过滤器


```toml
[filters.custom]
# 自定义Lua脚本过滤器
script = """
function filter(row)
    -- 加密敏感字段
    if row.phone then
        row.phone = encrypt(row.phone)
    end
    
    -- 添加计算字段
    if row.birth_date then
        row.age = calculate_age(row.birth_date)
    end
    
    return row
end
"""
```

> 🔧 **过滤器执行顺序**  
> 数据流：输入 → 清洗 → 转换 → 条件过滤 → 路由 → 输出

---

## 8. 🗺️ 路由规则配置


### 8.1 基础路由规则


**🔸 基于表名的路由**

```toml
[router]
# 路由模式：table（按表）, database（按库）, custom（自定义）
mode = "table"

# 表路由规则
[router.table-routes]
"users" = "outputs.user-kafka"
"orders" = "outputs.order-mysql"
"products" = "outputs.product-es"
"logs" = "outputs.log-file"
```

**🔸 基于数据库的路由**

```toml
[router]
mode = "database"

[router.database-routes]
"user_db" = "outputs.user-cluster"
"order_db" = "outputs.order-cluster"
"analytics_db" = "outputs.analytics-cluster"
```

### 8.2 条件路由规则


**🔸 基于数据内容的路由**

```toml
[router.condition-routes]
# 大额订单发送到风控系统
"table = 'orders' AND amount > 10000" = "outputs.risk-control"

# VIP用户数据发送到专用集群
"table = 'users' AND vip_level > 3" = "outputs.vip-cluster"

# 历史数据发送到归档系统
"created_at < DATE_SUB(NOW(), INTERVAL 1 YEAR)" = "outputs.archive"
```

**🔸 基于操作类型的路由**

```toml
[router.operation-routes]
# 插入操作发送到实时处理
"operation = 'insert'" = "outputs.realtime-kafka"

# 更新操作发送到变更追踪
"operation = 'update'" = "outputs.change-log"

# 删除操作发送到审计系统  
"operation = 'delete'" = "outputs.audit-log"
```

### 8.3 多目标路由


```toml
[router.multi-target]
# 一份数据同时发送到多个目标
"users" = [
    "outputs.user-mysql",     # 主数据库
    "outputs.user-es",        # 搜索引擎
    "outputs.user-cache"      # 缓存系统
]

# 备份路由配置
"orders" = [
    "outputs.order-primary",   # 主目标
    "outputs.order-backup"     # 备份目标
]
```

> 💡 **路由设计原则**  
> 根据业务需求合理设计路由，避免数据重复和遗漏

---

## 9. 📈 监控配置


### 9.1 Web监控配置


**🔸 基础Web配置**

```toml
[web]
# 监控服务端口
port = 8080

# 绑定地址
bind = "0.0.0.0"

# 启用认证
enable-auth = true
username = "admin"
password = "gravity123"

# 静态文件目录
static-dir = "/opt/gravity/web"
```

**🔸 监控面板功能**

```
Web监控面板提供：
┌─────────────────┐
│   实时状态监控   │ ← 同步状态、错误统计
├─────────────────┤
│   性能指标展示   │ ← QPS、延迟、吞吐量
├─────────────────┤
│   配置管理界面   │ ← 在线修改配置
├─────────────────┤
│   日志查看功能   │ ← 实时日志查看
└─────────────────┘
```

### 9.2 指标监控配置


**🔸 Prometheus监控**

```toml
[monitoring.prometheus]
# 启用Prometheus监控
enabled = true

# 指标暴露端口
port = 9090

# 指标前缀
namespace = "gravity"

# 监控指标包括
metrics = [
    "sync_lag",           # 同步延迟
    "sync_qps",           # 每秒同步数量
    "error_count",        # 错误计数
    "connection_count",   # 连接数
    "memory_usage"        # 内存使用量
]
```

**🔸 日志监控配置**

```toml
[monitoring.logging]
# 日志输出格式
format = "json"  # text, json

# 日志轮转配置
[monitoring.logging.rotation]
max-size = "100MB"    # 单个日志文件最大大小
max-age = 7           # 日志保留天数
max-backups = 10      # 最大备份文件数
compress = true       # 是否压缩旧日志
```

### 9.3 告警配置


**🔸 基础告警规则**

```toml
[alerts]
# 同步延迟告警
[alerts.sync-lag]
threshold = "30s"     # 延迟超过30秒告警
action = "email"      # 告警方式

# 错误率告警
[alerts.error-rate]
threshold = "5%"      # 错误率超过5%告警
window = "5m"         # 统计时间窗口
action = "webhook"    # 发送到webhook

# 内存使用告警
[alerts.memory]
threshold = "80%"     # 内存使用超过80%告警
action = "log"        # 记录到日志
```

**🔸 告警通知配置**

```toml
[alerts.notifications]
# 邮件通知配置
[alerts.notifications.email]
smtp-host = "smtp.company.com"
smtp-port = 587
username = "gravity@company.com"
password = "email_password"
to = ["admin@company.com", "ops@company.com"]

# Webhook通知配置
[alerts.notifications.webhook]
url = "https://hooks.slack.com/services/xxx"
timeout = "10s"
```

---

## 10. 🎯 配置最佳实践


### 10.1 环境配置管理


**🔸 多环境配置策略**

```bash
# 目录结构
/opt/gravity/config/
├── gravity-base.toml      # 基础配置
├── gravity-dev.toml       # 开发环境
├── gravity-test.toml      # 测试环境
└── gravity-prod.toml      # 生产环境
```

```toml
# gravity-base.toml（基础配置）
[global]
log-level = "info"
work-dir = "/data/gravity"

# gravity-prod.toml（生产环境覆盖）
[global]
log-level = "warn"
max-memory = "4GB"
debug = false
```

### 10.2 安全配置建议


**🔸 密码安全管理**

```toml
# 方式1：环境变量引用
[mysql]
password = "${MYSQL_PASSWORD}"

# 方式2：密码文件引用
[mysql]
password-file = "/etc/gravity/mysql.pwd"

# 方式3：加密密码（需要解密key）
[mysql]
encrypted-password = "AES:encrypted_string"
```

**🔸 权限最小化配置**

```toml
# 为不同功能创建不同用户
[inputs.mysql]
username = "gravity_reader"  # 只读权限

[outputs.mysql]
username = "gravity_writer"  # 写入权限

[monitoring]
username = "gravity_monitor" # 监控权限
```

### 10.3 性能优化配置


**🔸 连接池优化**

```toml
[mysql]
# 根据服务器配置调整
max-connections = 50        # CPU核数 * 2
max-idle-connections = 10   # max-connections / 5
connection-max-lifetime = "1h"

# 批量操作优化
batch-size = 1000          # 根据网络和内存情况调整
batch-timeout = "5s"       # 平衡实时性和性能
```

**🔸 内存使用优化**

```toml
[global]
# 根据可用内存设置
max-memory = "2GB"         # 服务器内存的50-70%

[buffers]
# 缓冲区大小配置
input-buffer-size = "10MB"
output-buffer-size = "10MB" 
filter-buffer-size = "5MB"
```

### 10.4 故障恢复配置


**🔸 重试机制配置**

```toml
[retry]
# 最大重试次数
max-attempts = 3

# 重试间隔（指数退避）
initial-interval = "1s"
max-interval = "30s"
multiplier = 2.0

# 可重试的错误类型
retryable-errors = [
    "connection timeout",
    "temporary failure",
    "network error"
]
```

**🔸 故障转移配置**

```toml
[failover]
# 启用故障转移
enabled = true

# 健康检查间隔
health-check-interval = "30s"

# 故障阈值
failure-threshold = 3

# 备用输出配置
backup-outputs = ["outputs.backup-mysql", "outputs.backup-kafka"]
```

---

## 11. 📋 核心要点总结


### 11.1 配置文件核心要素


```
🔸 配置文件结构：TOML格式，分段配置，支持注释
🔸 全局配置：实例标识、日志级别、内存限制、工作目录
🔸 数据库连接：主机信息、连接池、权限要求、字符集
🔸 同步规则：表选择、字段过滤、数据过滤、批量处理
🔸 输入输出：数据源配置、目标配置、格式定义
🔸 过滤器：数据转换、清洗、路由、自定义处理
🔸 路由规则：基于表名、条件、操作类型的路由策略
🔸 监控配置：Web面板、指标监控、日志管理、告警机制
```

### 11.2 配置原则总结


**🔹 安全性原则**
- 密码不明文存储，使用环境变量或加密
- 权限最小化，不同功能使用不同账号
- 网络访问控制，限制连接来源

**🔹 性能原则**  
- 连接池合理配置，避免连接耗尽
- 批量处理平衡实时性和效率
- 内存使用限制，避免OOM

**🔹 可靠性原则**
- 配置重试机制，应对临时故障
- 启用监控告警，及时发现问题
- 备份配置，支持故障转移

**🔹 可维护性原则**
- 配置文件结构清晰，添加必要注释
- 环境配置分离，便于管理
- 版本控制，追踪配置变更

### 11.3 常见配置问题


| 问题类型 | **常见原因** | **解决方案** |
|---------|------------|-------------|
| 🔴 **连接失败** | `权限不足、网络不通` | `检查用户权限和网络连接` |
| 🟡 **同步延迟** | `批量大小不合理` | `调整batch-size和timeout` |
| 🟠 **内存溢出** | `max-memory设置过小` | `增加内存限制或优化配置` |
| 🔵 **数据丢失** | `过滤规则过于严格` | `检查过滤条件和路由规则` |

### 11.4 配置检查清单


**📋 部署前检查**
- [ ] 所有必需的配置段都已配置
- [ ] 数据库连接信息正确
- [ ] 权限配置满足要求
- [ ] 同步规则符合业务需求
- [ ] 监控和告警已启用
- [ ] 安全配置已设置

**📋 运行时监控**
- [ ] 同步状态正常
- [ ] 错误率在可接受范围内
- [ ] 内存和CPU使用正常
- [ ] 日志没有异常错误
- [ ] 告警机制工作正常

**核心记忆要点**：
- 配置是Gravity的大脑，决定了工具如何工作
- 安全、性能、可靠性是配置的三大核心原则
- 合理的配置是稳定数据同步的基础
- 监控和告警配置同样重要，及时发现问题