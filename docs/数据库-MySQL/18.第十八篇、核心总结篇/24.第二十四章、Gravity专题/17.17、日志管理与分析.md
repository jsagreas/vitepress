---
title: 17、日志管理与分析
---
## 📚 目录

1. [Gravity日志系统概述](#1-Gravity日志系统概述)
2. [日志配置管理](#2-日志配置管理)
3. [日志级别设置详解](#3-日志级别设置详解)
4. [日志文件轮转机制](#4-日志文件轮转机制)
5. [错误日志分析](#5-错误日志分析)
6. [同步日志分析](#6-同步日志分析)
7. [性能日志分析](#7-性能日志分析)
8. [日志聚合收集](#8-日志聚合收集)
9. [日志监控告警](#9-日志监控告警)
10. [核心要点总结](#10-核心要点总结)

---

## 1. 🌐 Gravity日志系统概述


### 1.1 什么是Gravity日志系统


**简单理解**：日志就像汽车的"行车记录仪"，记录Gravity运行过程中发生的所有重要事件。

```
现实中的记录：            Gravity日志记录：
汽车行车记录仪             同步工具运行日志
 ↓                        ↓
记录行驶轨迹               记录同步过程
记录交通事故               记录错误异常
记录违章行为               记录性能问题
便于事后分析               便于故障排查
```

**🔸 核心作用**
```
故障诊断：出问题时知道哪里坏了
性能监控：了解同步效率如何
运维管理：掌握系统运行状态
合规审计：满足数据同步的审计要求
```

### 1.2 Gravity日志的分类


**📊 日志类型一览**
```
应用日志：记录Gravity自身运行情况
 ├── 启动日志：服务启动和关闭
 ├── 配置日志：配置加载和变更
 └── 业务日志：同步任务执行情况

同步日志：记录数据同步的详细过程
 ├── 源库日志：从源数据库读取数据
 ├── 转换日志：数据转换和处理
 └── 目标日志：写入目标数据库

性能日志：记录系统性能指标
 ├── 延迟统计：同步延迟时间
 ├── 吞吐量：每秒同步记录数
 └── 资源使用：CPU、内存使用情况

错误日志：记录各种异常和错误
 ├── 连接错误：数据库连接问题
 ├── 数据错误：数据格式或类型问题
 └── 系统错误：系统级别的异常
```

### 1.3 日志系统架构


**🏗️ 整体架构**
```
应用程序                日志框架               日志输出
┌─────────┐           ┌─────────┐           ┌─────────┐
│ Gravity │ --------→ │ Logrus  │ --------→ │ 文件    │
│ 应用    │           │ 日志库  │           │ 存储    │
└─────────┘           └─────────┘           └─────────┘
     │                     │                     │
     │                     ├─────────────────→ │ 控制台  │
     │                     │                   │ 输出    │
     │                     │                   └─────────┘
     │                     │                   ┌─────────┐
     │                     └─────────────────→ │ 远程    │
     │                                         │ 收集器  │
     └─── 配置控制 ──────────────────────────→ └─────────┘
```

---

## 2. ⚙️ 日志配置管理


### 2.1 基础配置文件


**🔧 配置文件结构**
```toml
# gravity.toml 中的日志配置
[log]
# 日志级别：debug, info, warn, error
level = "info"

# 日志输出格式：json, text
format = "json"

# 日志文件路径
file = "/var/log/gravity/gravity.log"

# 是否输出到控制台
stdout = true

# 日志文件最大大小（MB）
max-size = 100

# 保留的日志文件数量
max-backups = 10

# 日志文件保留天数
max-age = 30

# 是否压缩旧日志文件
compress = true
```

**💡 配置参数详解**

| 参数 | **含义** | **推荐值** | **说明** |
|------|---------|-----------|---------|
| `level` | `日志记录级别` | `info` | `debug适合开发，info适合生产` |
| `format` | `日志输出格式` | `json` | `json便于程序解析，text便于人阅读` |
| `file` | `日志文件路径` | `/var/log/gravity/` | `建议放在专门的日志目录` |
| `max-size` | `单个文件最大大小` | `100MB` | `太大影响查看，太小频繁切换` |
| `max-backups` | `保留文件数量` | `10个` | `根据磁盘空间和需求调整` |

### 2.2 分模块日志配置


**🎯 不同模块配置**
```toml
# 同步模块日志
[log.sync]
level = "info"
file = "/var/log/gravity/sync.log"
# 同步日志通常需要更详细的记录
enable-progress = true

# 错误日志单独配置
[log.error]
level = "error"
file = "/var/log/gravity/error.log"
# 错误日志需要立即写入
buffer = false

# 性能日志配置
[log.performance]
level = "info"
file = "/var/log/gravity/performance.log"
# 性能日志可以采样记录
sample-rate = 0.1
```

### 2.3 动态配置管理


**🔄 运行时配置调整**
```bash
# 通过管理API调整日志级别
curl -X PUT http://localhost:8080/admin/log/level \
  -H "Content-Type: application/json" \
  -d '{"level": "debug"}'

# 查看当前日志配置
curl http://localhost:8080/admin/log/config

# 重新加载日志配置
curl -X POST http://localhost:8080/admin/log/reload
```

**⚡ 配置热更新示例**
```go
// Gravity支持的配置热更新
type LogConfig struct {
    Level      string `json:"level"`
    Format     string `json:"format"`
    File       string `json:"file"`
    MaxSize    int    `json:"max_size"`
    MaxBackups int    `json:"max_backups"`
}

// 动态更新日志级别
func UpdateLogLevel(newLevel string) error {
    // 验证级别是否有效
    if !isValidLevel(newLevel) {
        return errors.New("invalid log level")
    }
    
    // 应用新的日志级别
    logger.SetLevel(newLevel)
    return nil
}
```

---

## 3. 📊 日志级别设置详解


### 3.1 日志级别分类


**🔸 级别说明**
```
DEBUG（调试级别）：
含义：最详细的日志信息
用途：开发调试、问题诊断
示例：每个SQL语句的执行、变量值变化

INFO（信息级别）：
含义：程序正常运行的关键信息
用途：监控程序运行状态
示例：任务开始/结束、连接建立/断开

WARN（警告级别）：
含义：可能的问题，但不影响正常运行
用途：预警潜在问题
示例：连接重试、数据格式异常但已处理

ERROR（错误级别）：
含义：发生错误，但程序可以继续运行
用途：记录需要关注的错误
示例：单条数据同步失败、网络超时

FATAL（致命级别）：
含义：严重错误，程序无法继续运行
用途：记录导致程序停止的错误
示例：配置文件损坏、数据库完全不可访问
```

### 3.2 不同场景的级别选择


**🎯 环境配置建议**

| 环境 | **推荐级别** | **原因** | **注意事项** |
|------|-------------|---------|-------------|
| **开发环境** | `DEBUG` | `需要详细信息调试` | `日志量大，注意磁盘空间` |
| **测试环境** | `INFO` | `关注业务流程` | `平衡信息量和性能` |
| **生产环境** | `WARN` | `只关注问题` | `减少IO压力，提高性能` |
| **故障排查** | `DEBUG` | `临时开启详细日志` | `排查完及时调回` |

### 3.3 级别设置的实际效果


**📈 日志量对比示例**
```
同一个同步任务在不同级别下的日志输出：

DEBUG级别输出：
2025-09-12 10:01:00 [DEBUG] 连接源数据库 mysql://source:3306/db1
2025-09-12 10:01:01 [DEBUG] 执行SQL: SELECT * FROM users WHERE id > 1000
2025-09-12 10:01:01 [DEBUG] 查询返回 500 条记录
2025-09-12 10:01:02 [DEBUG] 开始转换数据格式
2025-09-12 10:01:02 [DEBUG] 转换记录 #1: {id: 1001, name: "张三"}
2025-09-12 10:01:02 [INFO]  同步批次完成，处理 500 条记录
2025-09-12 10:01:03 [DEBUG] 连接目标数据库 mysql://target:3306/db2
2025-09-12 10:01:03 [DEBUG] 执行插入操作...

INFO级别输出：
2025-09-12 10:01:00 [INFO]  开始同步任务 users_sync
2025-09-12 10:01:02 [INFO]  同步批次完成，处理 500 条记录
2025-09-12 10:01:05 [INFO]  同步任务完成，总计处理 2000 条记录

WARN级别输出：
2025-09-12 10:01:04 [WARN]  连接超时，正在重试... (尝试 2/3)

错误记录量：DEBUG > INFO > WARN > ERROR > FATAL
```

### 3.4 动态调整策略


**⚡ 智能级别调整**
```bash
# 正常运行时保持较高级别
gravity_log_level="warn"

# 发现问题时临时降低级别
if [ "$error_count" -gt 10 ]; then
    gravity_log_level="info"
    echo "检测到错误增多，调整日志级别为 info"
fi

# 深度排查时开启debug
if [ "$debug_mode" = "true" ]; then
    gravity_log_level="debug"
    echo "进入调试模式，开启详细日志"
fi
```

---

## 4. 🔄 日志文件轮转机制


### 4.1 什么是日志轮转


**简单理解**：就像笔记本写满了要换新本一样，日志文件太大了就要创建新文件。

```
传统方式（不轮转）：
gravity.log (持续增长)
 ↓
变得非常大 (几个GB)
 ↓
查看困难、磁盘占满

轮转方式：
gravity.log         ← 当前日志文件
gravity.log.1       ← 昨天的日志
gravity.log.2       ← 前天的日志
gravity.log.3.gz    ← 更早的压缩日志
```

### 4.2 轮转触发条件


**🔸 轮转规则配置**
```toml
[log.rotation]
# 按文件大小轮转（推荐）
max-size = "100MB"

# 按时间轮转
daily = true          # 每天轮转
hourly = false        # 每小时轮转

# 按数量轮转
max-backups = 10      # 保留10个备份文件

# 按时间轮转
max-age = 30          # 保留30天的日志

# 压缩设置
compress = true       # 压缩旧日志文件
```

**📊 轮转策略对比**

| 策略 | **优点** | **缺点** | **适用场景** |
|------|---------|---------|-------------|
| **按大小** | `文件大小可控，便于处理` | `时间跨度不固定` | `日志量不稳定的系统` |
| **按时间** | `时间范围明确，便于归档` | `文件大小不可控` | `需要按时间分析的场景` |
| **按数量** | `磁盘使用可控` | `时间跨度不确定` | `磁盘空间有限的环境` |

### 4.3 轮转文件命名规则


**📁 文件命名示例**
```bash
# 当前日志文件
/var/log/gravity/gravity.log

# 轮转后的文件命名
/var/log/gravity/gravity.log.1     # 最近一次轮转
/var/log/gravity/gravity.log.2     # 第二次轮转
/var/log/gravity/gravity.log.3.gz  # 压缩的历史文件

# 按时间命名的方式
/var/log/gravity/gravity-2025-09-12.log
/var/log/gravity/gravity-2025-09-11.log.gz
/var/log/gravity/gravity-2025-09-10.log.gz
```

### 4.4 自定义轮转脚本


**🔧 高级轮转管理**
```bash
#!/bin/bash
# gravity-log-rotate.sh

LOG_DIR="/var/log/gravity"
MAX_SIZE="100M"
KEEP_DAYS=30

# 检查日志文件大小
check_log_size() {
    local log_file="$1"
    local current_size=$(du -m "$log_file" | cut -f1)
    local max_size_mb=$(echo $MAX_SIZE | sed 's/M//')
    
    if [ $current_size -gt $max_size_mb ]; then
        echo "日志文件 $log_file 大小 ${current_size}MB，需要轮转"
        return 0
    fi
    return 1
}

# 执行轮转
rotate_log() {
    local log_file="$1"
    local backup_file="${log_file}.$(date +%Y%m%d_%H%M%S)"
    
    # 移动当前日志文件
    mv "$log_file" "$backup_file"
    
    # 发送信号让Gravity重新打开日志文件
    pkill -USR1 gravity
    
    # 压缩备份文件
    gzip "$backup_file"
    
    echo "日志轮转完成：$backup_file.gz"
}

# 清理过期日志
cleanup_old_logs() {
    find "$LOG_DIR" -name "*.log.*.gz" -mtime +$KEEP_DAYS -delete
    echo "清理 $KEEP_DAYS 天前的日志文件"
}

# 主执行逻辑
main() {
    for log_file in "$LOG_DIR"/*.log; do
        if check_log_size "$log_file"; then
            rotate_log "$log_file"
        fi
    done
    
    cleanup_old_logs
}

main "$@"
```

---

## 5. 🚨 错误日志分析


### 5.1 常见错误类型


**🔸 错误分类体系**
```
连接错误：
 ├── 数据库连接失败
 ├── 网络超时
 ├── 认证失败
 └── 连接池耗尽

数据错误：
 ├── 数据类型不匹配
 ├── 字符编码问题
 ├── 数据格式错误
 └── 约束冲突

配置错误：
 ├── 配置文件格式错误
 ├── 参数值无效
 ├── 路径不存在
 └── 权限不足

系统错误：
 ├── 内存不足
 ├── 磁盘空间不足
 ├── 文件句柄耗尽
 └── 系统调用失败
```

### 5.2 错误日志格式解读


**📋 错误日志示例分析**
```json
{
  "timestamp": "2025-09-12T10:30:15.123Z",
  "level": "ERROR",
  "module": "mysql-sync",
  "error_code": "DB_CONNECTION_FAILED",
  "message": "连接目标数据库失败",
  "details": {
    "host": "192.168.1.100",
    "port": 3306,
    "database": "target_db",
    "user": "gravity_user",
    "error": "dial tcp 192.168.1.100:3306: connect: connection refused",
    "retry_count": 3,
    "max_retries": 5
  },
  "context": {
    "task_id": "users_sync_001",
    "batch_id": "batch_20250912_001",
    "table": "users"
  }
}
```

**💡 字段含义解释**
- **timestamp**: 错误发生的精确时间
- **level**: 日志级别，ERROR表示错误
- **module**: 发生错误的模块，这里是mysql同步模块
- **error_code**: 错误代码，便于程序化处理
- **message**: 人类可读的错误描述
- **details**: 错误的技术细节
- **context**: 错误发生时的上下文信息

### 5.3 错误分析方法


**🔍 分析流程**
```
步骤1：识别错误类型
 ↓
步骤2：查看错误详情
 ↓
步骤3：分析错误上下文
 ↓
步骤4：确定影响范围
 ↓
步骤5：制定解决方案
```

**📊 错误分析实例**
```bash
# 使用 jq 工具分析错误日志
cat gravity-error.log | jq '
  select(.level == "ERROR") | 
  group_by(.error_code) | 
  map({
    error_code: .[0].error_code,
    count: length,
    first_occurrence: .[0].timestamp,
    last_occurrence: .[-1].timestamp
  })
'

# 输出结果示例：
[
  {
    "error_code": "DB_CONNECTION_FAILED",
    "count": 15,
    "first_occurrence": "2025-09-12T08:30:15.123Z",
    "last_occurrence": "2025-09-12T10:30:15.123Z"
  },
  {
    "error_code": "DATA_TYPE_MISMATCH",
    "count": 3,
    "first_occurrence": "2025-09-12T09:15:22.456Z",
    "last_occurrence": "2025-09-12T09:20:33.789Z"
  }
]
```

### 5.4 常见问题的解决方案


**🛠️ 问题解决指南**

| 错误类型 | **可能原因** | **解决方案** | **预防措施** |
|---------|-------------|-------------|-------------|
| **连接失败** | `网络问题、服务停止` | `检查网络、重启服务` | `增加健康检查、连接重试` |
| **认证失败** | `用户名密码错误` | `检查认证信息` | `使用密钥管理、定期更新` |
| **数据类型错误** | `源目标结构不一致` | `调整表结构或转换规则` | `部署前验证结构一致性` |
| **权限不足** | `数据库权限设置` | `授予必要权限` | `最小权限原则` |

---

## 6. 📈 同步日志分析


### 6.1 同步日志的结构


**🔸 同步过程日志记录**
```
同步开始 → 读取源数据 → 数据转换 → 写入目标 → 同步完成
   ↓           ↓           ↓          ↓         ↓
 开始日志    读取日志    转换日志    写入日志   完成日志
```

**📋 同步日志示例**
```json
// 任务开始日志
{
  "timestamp": "2025-09-12T10:00:00.000Z",
  "level": "INFO",
  "event": "SYNC_TASK_START",
  "task_id": "users_sync_001",
  "config": {
    "source": "mysql://source:3306/app_db",
    "target": "mysql://target:3306/warehouse_db",
    "table": "users",
    "batch_size": 1000
  }
}

// 批次处理日志
{
  "timestamp": "2025-09-12T10:00:05.123Z",
  "level": "INFO",
  "event": "BATCH_PROCESSED",
  "task_id": "users_sync_001",
  "batch_id": "batch_001",
  "metrics": {
    "records_read": 1000,
    "records_transformed": 998,
    "records_written": 998,
    "records_failed": 2,
    "processing_time_ms": 5123
  }
}

// 任务完成日志
{
  "timestamp": "2025-09-12T10:15:30.456Z",
  "level": "INFO",
  "event": "SYNC_TASK_COMPLETE",
  "task_id": "users_sync_001",
  "summary": {
    "total_records": 50000,
    "successful_records": 49950,
    "failed_records": 50,
    "total_time_ms": 930456,
    "avg_throughput_per_sec": 53.7
  }
}
```

### 6.2 同步性能指标


**📊 关键性能指标**
```
吞吐量指标：
 ├── 每秒处理记录数 (Records/sec)
 ├── 每分钟处理数据量 (MB/min)
 └── 批次处理时间 (ms/batch)

延迟指标：
 ├── 端到端延迟 (End-to-end latency)
 ├── 数据读取延迟 (Read latency)
 └── 数据写入延迟 (Write latency)

可靠性指标：
 ├── 成功率 (Success rate)
 ├── 重试次数 (Retry count)
 └── 错误率 (Error rate)
```

### 6.3 同步日志分析脚本


**🔧 性能分析工具**
```bash
#!/bin/bash
# 分析同步性能的脚本

LOG_FILE="/var/log/gravity/sync.log"

# 计算平均吞吐量
calculate_throughput() {
    echo "=== 同步吞吐量分析 ==="
    cat "$LOG_FILE" | jq -r '
        select(.event == "BATCH_PROCESSED") | 
        .metrics.records_written / (.metrics.processing_time_ms / 1000)
    ' | awk '{sum+=$1; count++} END {print "平均吞吐量:", sum/count, "records/sec"}'
}

# 分析失败率
analyze_failure_rate() {
    echo "=== 失败率分析 ==="
    cat "$LOG_FILE" | jq -r '
        select(.event == "SYNC_TASK_COMPLETE") | 
        [.summary.failed_records, .summary.total_records] | 
        @csv
    ' | awk -F',' '{
        failed+=$1; total+=$2
    } END {
        rate = (failed/total)*100
        printf "总记录数: %d\n失败记录数: %d\n失败率: %.2f%%\n", total, failed, rate
    }'
}

# 分析处理时间分布
analyze_processing_time() {
    echo "=== 处理时间分析 ==="
    cat "$LOG_FILE" | jq -r '
        select(.event == "BATCH_PROCESSED") | 
        .metrics.processing_time_ms
    ' | sort -n | awk '
    BEGIN {count=0}
    {times[count]=$1; count++}
    END {
        p50 = times[int(count*0.5)]
        p95 = times[int(count*0.95)]
        p99 = times[int(count*0.99)]
        printf "50%% 处理时间: %d ms\n", p50
        printf "95%% 处理时间: %d ms\n", p95
        printf "99%% 处理时间: %d ms\n", p99
    }'
}

# 执行所有分析
main() {
    calculate_throughput
    echo ""
    analyze_failure_rate
    echo ""
    analyze_processing_time
}

main
```

---

## 7. ⚡ 性能日志分析


### 7.1 性能监控指标


**🔸 系统级性能指标**
```
CPU使用率：
 ├── 整体CPU使用率
 ├── 各个线程CPU使用率
 └── CPU等待时间

内存使用：
 ├── 总内存使用量
 ├── 堆内存使用情况
 └── 垃圾回收频率

网络IO：
 ├── 网络连接数
 ├── 数据传输速率
 └── 网络延迟

磁盘IO：
 ├── 磁盘读写速率
 ├── IO等待时间
 └── 磁盘使用率
```

### 7.2 应用级性能指标


**📈 业务性能监控**
```json
{
  "timestamp": "2025-09-12T10:30:00.000Z",
  "level": "INFO",
  "event": "PERFORMANCE_METRICS",
  "metrics": {
    "system": {
      "cpu_usage_percent": 35.2,
      "memory_usage_mb": 512,
      "goroutines_count": 128,
      "gc_pause_ms": 2.3
    },
    "application": {
      "active_connections": 15,
      "pending_tasks": 3,
      "completed_tasks_last_minute": 45,
      "avg_task_duration_ms": 1250
    },
    "database": {
      "source_connection_pool_size": 10,
      "source_active_connections": 7,
      "target_connection_pool_size": 8,
      "target_active_connections": 5,
      "avg_query_time_ms": 25
    }
  }
}
```

### 7.3 性能瓶颈识别


**🔍 瓶颈分析方法**
```bash
# 1. CPU瓶颈检测
check_cpu_bottleneck() {
    cpu_usage=$(cat /var/log/gravity/performance.log | \
        jq -r '.metrics.system.cpu_usage_percent' | \
        tail -10 | awk '{sum+=$1} END {print sum/NR}')
    
    if (( $(echo "$cpu_usage > 80" | bc -l) )); then
        echo "⚠️  CPU使用率过高: ${cpu_usage}%"
        echo "建议：优化算法或增加并发控制"
    fi
}

# 2. 内存瓶颈检测
check_memory_bottleneck() {
    memory_mb=$(cat /var/log/gravity/performance.log | \
        jq -r '.metrics.system.memory_usage_mb' | \
        tail -1)
    
    if [ "$memory_mb" -gt 1024 ]; then
        echo "⚠️  内存使用过高: ${memory_mb}MB"
        echo "建议：减少批次大小或优化内存使用"
    fi
}

# 3. 数据库连接瓶颈检测
check_db_bottleneck() {
    active_connections=$(cat /var/log/gravity/performance.log | \
        jq -r '.metrics.database.source_active_connections' | \
        tail -1)
    pool_size=$(cat /var/log/gravity/performance.log | \
        jq -r '.metrics.database.source_connection_pool_size' | \
        tail -1)
    
    usage_rate=$(echo "scale=2; $active_connections / $pool_size * 100" | bc)
    
    if (( $(echo "$usage_rate > 90" | bc -l) )); then
        echo "⚠️  数据库连接池使用率过高: ${usage_rate}%"
        echo "建议：增加连接池大小或优化查询"
    fi
}
```

### 7.4 性能优化建议


**🚀 优化策略**

| 问题类型 | **症状** | **优化方案** | **预期效果** |
|---------|---------|-------------|-------------|
| **CPU瓶颈** | `CPU使用率>80%` | `减少并发数、优化算法` | `降低CPU使用率到50-70%` |
| **内存瓶颈** | `内存使用持续增长` | `减少批次大小、及时释放对象` | `稳定的内存使用曲线` |
| **网络瓶颈** | `网络延迟高、超时多` | `增加连接池、启用压缩` | `减少50%的网络超时` |
| **磁盘瓶颈** | `IO等待时间长` | `使用SSD、优化查询` | `提高20-30%的处理速度` |

---

## 8. 📊 日志聚合收集


### 8.1 日志聚合的必要性


**🔸 为什么需要日志聚合**
```
分布式环境挑战：
 ├── 多个Gravity实例运行
 ├── 日志分散在不同服务器
 ├── 难以统一查看和分析
 └── 排查问题效率低

聚合收集的好处：
 ├── 统一的日志查看界面
 ├── 快速的全局搜索能力
 ├── 集中的监控和告警
 └── 便于数据分析和挖掘
```

### 8.2 日志收集架构


**🏗️ 收集系统架构**
```
Gravity实例1 ──┐
               │    ┌─────────────┐    ┌─────────────┐
Gravity实例2 ──┼──→ │   Filebeat  │ ──→│ Elasticsearch│
               │    │  日志收集器  │    │   存储引擎   │
Gravity实例3 ──┘    └─────────────┘    └─────────────┘
                            │                    │
                            ▼                    ▼
                    ┌─────────────┐    ┌─────────────┐
                    │   Logstash  │    │   Kibana    │
                    │  日志处理器  │    │  可视化界面  │
                    └─────────────┘    └─────────────┘
```

### 8.3 Filebeat配置示例


**🔧 日志收集配置**
```yaml
# filebeat.yml
filebeat.inputs:
- type: log
  enabled: true
  paths:
    - /var/log/gravity/*.log
  fields:
    service: gravity
    environment: production
  fields_under_root: true
  
  # 多行日志处理（针对stack trace）
  multiline.pattern: '^\d{4}-\d{2}-\d{2}'
  multiline.negate: true
  multiline.match: after

# 输出到Elasticsearch
output.elasticsearch:
  hosts: ["elasticsearch1:9200", "elasticsearch2:9200"]
  index: "gravity-logs-%{+yyyy.MM.dd}"
  template.settings:
    index.number_of_shards: 2
    index.number_of_replicas: 1

# 日志处理
processors:
- add_host_metadata:
    when.not.contains.tags: forwarded
- decode_json_fields:
    fields: ["message"]
    target: ""
    overwrite_keys: true
```

### 8.4 Logstash数据处理


**⚙️ 日志数据清洗和结构化**
```ruby
# logstash.conf
input {
  beats {
    port => 5044
  }
}

filter {
  # 解析JSON格式日志
  if [message] =~ /^\{.*\}$/ {
    json {
      source => "message"
    }
  }
  
  # 添加解析时间戳
  date {
    match => [ "timestamp", "ISO8601" ]
  }
  
  # 提取错误级别
  if [level] == "ERROR" {
    mutate {
      add_tag => [ "error" ]
    }
  }
  
  # 提取同步任务信息
  if [event] == "SYNC_TASK_START" or [event] == "SYNC_TASK_COMPLETE" {
    mutate {
      add_tag => [ "sync_task" ]
    }
  }
  
  # 计算处理时间
  if [metrics][processing_time_ms] {
    ruby {
      code => "event.set('processing_time_sec', event.get('[metrics][processing_time_ms]').to_f / 1000)"
    }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "gravity-logs-%{+YYYY.MM.dd}"
  }
}
```

### 8.5 日志查询和分析


**🔍 常用查询示例**
```json
# 1. 查询错误日志
GET gravity-logs-*/_search
{
  "query": {
    "bool": {
      "must": [
        {"term": {"level": "ERROR"}},
        {"range": {"@timestamp": {"gte": "now-1h"}}}
      ]
    }
  },
  "sort": [{"@timestamp": {"order": "desc"}}]
}

# 2. 统计不同错误类型
GET gravity-logs-*/_search
{
  "size": 0,
  "query": {"term": {"level": "ERROR"}},
  "aggs": {
    "error_types": {
      "terms": {
        "field": "error_code.keyword",
        "size": 10
      }
    }
  }
}

# 3. 分析同步性能趋势
GET gravity-logs-*/_search
{
  "size": 0,
  "query": {"term": {"event": "BATCH_PROCESSED"}},
  "aggs": {
    "performance_over_time": {
      "date_histogram": {
        "field": "@timestamp",
        "calendar_interval": "5m"
      },
      "aggs": {
        "avg_throughput": {
          "avg": {
            "script": {
              "source": "doc['metrics.records_written'].value / (doc['metrics.processing_time_ms'].value / 1000.0)"
            }
          }
        }
      }
    }
  }
}
```

---

## 9. 🚨 日志监控告警


### 9.1 告警策略设计


**🎯 告警级别分类**
```
紧急告警（P0）：
 ├── 系统完全停止
 ├── 数据丢失风险
 ├── 安全漏洞
 └── 响应时间：立即（5分钟内）

高优先级告警（P1）：
 ├── 同步任务失败率>10%
 ├── 性能严重下降
 ├── 连接异常频繁
 └── 响应时间：30分钟内

中优先级告警（P2）：
 ├── 性能轻微下降
 ├── 偶发错误
 ├── 配置异常
 └── 响应时间：2小时内

低优先级告警（P3）：
 ├── 监控指标异常
 ├── 容量预警
 ├── 优化建议
 └── 响应时间：工作日处理
```

### 9.2 基于ElastAlert的告警配置


**⚠️ 告警规则配置**
```yaml
# error_rate_alert.yml - 错误率告警
name: Gravity高错误率告警
type: frequency
index: gravity-logs-*
num_events: 10
timeframe:
  minutes: 5

filter:
- term:
    level: "ERROR"

alert:
- "email"
- "slack"

email:
- "ops-team@company.com"

slack:
webhook_url: "https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK"
slack_channel_override: "#gravity-alerts"

alert_text: |
  🚨 Gravity错误率告警
  
  在过去5分钟内检测到超过10个错误日志
  
  时间范围: {0} 到 {1}
  错误数量: {2}
  
  请立即检查系统状态！

alert_text_args:
  - "@timestamp"
  - "@timestamp"
  - num_matches
```

```yaml
# performance_degradation_alert.yml - 性能下降告警
name: Gravity性能下降告警
type: metric_aggregation
index: gravity-logs-*
metric_agg_key: "metrics.processing_time_ms"
metric_agg_type: "avg"
doc_type: "_doc"

filter:
- term:
    event: "BATCH_PROCESSED"

buffer_time:
  minutes: 10

timeframe:
  minutes: 15

threshold: 5000  # 平均处理时间超过5秒

alert:
- "email"

email:
- "dev-team@company.com"

alert_text: |
  ⚠️ Gravity性能下降告警
  
  平均批次处理时间: {0}ms (阈值: 5000ms)
  
  可能原因：
  - 数据库性能问题
  - 网络延迟增加
  - 系统资源不足
  
  建议立即检查性能指标。

alert_text_args:
  - metric_agg_value
```

### 9.3 自定义监控脚本


**🔧 监控脚本示例**
```bash
#!/bin/bash
# gravity-monitor.sh

# 配置参数
LOG_FILE="/var/log/gravity/gravity.log"
ERROR_THRESHOLD=5
PERFORMANCE_THRESHOLD=3000
ALERT_EMAIL="ops@company.com"

# 检查错误率
check_error_rate() {
    local current_time=$(date -d '1 minute ago' '+%Y-%m-%dT%H:%M')
    local error_count=$(grep -c "ERROR.*${current_time}" "$LOG_FILE")
    
    if [ "$error_count" -gt "$ERROR_THRESHOLD" ]; then
        send_alert "ERROR_RATE" "在过去1分钟内发现${error_count}个错误（阈值：${ERROR_THRESHOLD}）"
        return 1
    fi
    return 0
}

# 检查性能指标
check_performance() {
    local avg_time=$(tail -100 "$LOG_FILE" | \
        grep "BATCH_PROCESSED" | \
        jq -r '.metrics.processing_time_ms' | \
        awk '{sum+=$1; count++} END {print int(sum/count)}')
    
    if [ "$avg_time" -gt "$PERFORMANCE_THRESHOLD" ]; then
        send_alert "PERFORMANCE" "平均处理时间${avg_time}ms超过阈值${PERFORMANCE_THRESHOLD}ms"
        return 1
    fi
    return 0
}

# 发送告警
send_alert() {
    local alert_type="$1"
    local message="$2"
    local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
    
    # 发送邮件告警
    echo "时间: $timestamp
类型: $alert_type
消息: $message

请立即检查Gravity系统状态。" | \
    mail -s "🚨 Gravity告警: $alert_type" "$ALERT_EMAIL"
    
    # 记录告警日志
    echo "[$timestamp] ALERT: $alert_type - $message" >> /var/log/gravity/alerts.log
}

# 主监控逻辑
main() {
    echo "开始Gravity监控检查 - $(date)"
    
    check_error_rate
    error_status=$?
    
    check_performance
    perf_status=$?
    
    if [ $error_status -eq 0 ] && [ $perf_status -eq 0 ]; then
        echo "✅ 所有检查通过"
    else
        echo "❌ 检测到问题，已发送告警"
    fi
}

# 每分钟执行一次监控
while true; do
    main
    sleep 60
done
```

### 9.4 告警响应流程


**📋 告警处理标准流程**
```
第1步：接收告警
 ├── 查看告警级别和类型
 ├── 确认告警是否为误报
 └── 评估影响范围

第2步：初步诊断
 ├── 检查系统状态
 ├── 查看相关日志
 └── 确定问题根因

第3步：应急处理
 ├── 执行临时修复措施
 ├── 恢复服务正常运行
 └── 记录处理过程

第4步：根因分析
 ├── 深入分析问题原因
 ├── 制定长期解决方案
 └── 更新监控规则

第5步：总结改进
 ├── 撰写故障报告
 ├── 优化监控策略
 └── 预防类似问题
```

---

## 10. 📋 核心要点总结


### 10.1 必须掌握的核心概念


```
🔸 日志系统架构：应用日志、同步日志、性能日志、错误日志的分类和作用
🔸 配置管理：日志级别、格式、轮转等核心配置参数的含义
🔸 分析方法：如何通过日志快速定位问题和优化性能
🔸 聚合收集：分布式环境下的日志统一管理方案
🔸 监控告警：基于日志的主动监控和及时响应机制
```

### 10.2 关键理解要点


**🔹 日志级别的合理使用**
```
开发调试：DEBUG级别，获取详细信息
生产运行：WARN级别，只关注问题
故障排查：临时调整到INFO或DEBUG
性能考虑：高级别减少IO开销
```

**🔹 日志分析的价值**
```
故障诊断：快速定位问题根因
性能优化：识别瓶颈和优化点
容量规划：了解系统负载趋势
业务洞察：分析同步模式和效率
```

**🔹 监控告警的重要性**
```
主动发现：在用户发现前识别问题
及时响应：缩短故障恢复时间
量化管理：用数据驱动运维决策
持续改进：基于告警优化系统
```

### 10.3 实际应用指导


**🎯 日常运维建议**
- **日志级别设置**：生产环境建议WARN级别，保持系统性能
- **轮转策略**：根据磁盘空间和查看需求选择合适的轮转规则
- **监控覆盖**：确保关键指标都有对应的告警规则
- **响应流程**：建立标准化的告警处理流程

**🔧 故障排查技巧**
- **时间对齐**：先确定问题发生的时间范围
- **关键词搜索**：使用错误代码、任务ID等关键信息快速定位
- **上下文分析**：查看问题前后的相关日志
- **模式识别**：寻找错误的规律和趋势

**⚡ 性能优化要点**
- **监控趋势**：关注性能指标的变化趋势而不只是绝对值
- **瓶颈识别**：结合CPU、内存、网络、磁盘等多维度分析
- **优化验证**：通过日志验证优化措施的效果
- **容量预测**：基于历史数据预测未来的资源需求

**核心记忆口诀**：
- 日志分类要清楚，级别设置要合理
- 轮转策略保空间，聚合分析提效率  
- 监控告警要及时，故障排查有章法
- 性能优化看趋势，持续改进是关键