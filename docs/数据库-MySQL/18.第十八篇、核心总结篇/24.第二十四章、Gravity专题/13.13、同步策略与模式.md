---
title: 13、同步策略与模式
---
## 📚 目录

1. [Gravity同步概述](#1-Gravity同步概述)
2. [全量同步策略](#2-全量同步策略)
3. [增量同步策略](#3-增量同步策略)
4. [混合同步模式](#4-混合同步模式)
5. [断点续传机制](#5-断点续传机制)
6. [数据一致性保证](#6-数据一致性保证)
7. [冲突与失败处理](#7-冲突与失败处理)
8. [核心要点总结](#8-核心要点总结)

---

## 1. 🎯 Gravity同步概述


### 1.1 什么是Gravity


**简单理解**：Gravity是摩拜单车开源的MySQL数据同步工具，专门解决数据库之间的数据传输问题

```
使用场景示例：
主数据库 ──────────── Gravity ──────────── 目标数据库
  (MySQL)                                  (MySQL/Kafka)
     │                                          │
  业务写入                                  实时同步读取
  高并发操作                                分析/备份/搜索
```

**核心特点**：
- 🚀 **高性能**：支持大数据量的快速同步
- 🔄 **实时性**：毫秒级的增量同步延迟
- 🛡️ **可靠性**：完善的故障恢复和重试机制
- 🎯 **灵活性**：支持多种同步策略和目标

### 1.2 Gravity架构原理


**整体架构图**：
```
┌─────────────────────────────────────────────────────────┐
│                    Gravity同步架构                        │
├─────────────┬─────────────────┬─────────────────────────┤
│   Input     │    Process      │       Output            │
│             │                 │                         │
│ ┌─────────┐ │ ┌─────────────┐ │ ┌─────────────────────┐ │
│ │ Binlog  │─┼─│ 数据解析     │─┼─│ MySQL Target        │ │
│ │ Reader  │ │ │ 格式转换     │ │ │ Kafka Target        │ │
│ │         │ │ │ 路由分发     │ │ │ Elasticsearch       │ │
│ └─────────┘ │ │ 过滤筛选     │ │ │ Custom Output       │ │
│             │ └─────────────┘ │ └─────────────────────┘ │
│ ┌─────────┐ │                 │                         │
│ │ Full    │ │ ┌─────────────┐ │ ┌─────────────────────┐ │
│ │ Scan    │─┼─│ 断点续传     │─┼─│ 监控告警             │ │
│ │         │ │ │ 故障恢复     │ │ │ 状态管理             │ │
│ └─────────┘ │ └─────────────┘ │ └─────────────────────┘ │
└─────────────┴─────────────────┴─────────────────────────┘
```

**工作流程**：
1. **数据获取**：从源MySQL读取binlog或执行全表扫描
2. **数据处理**：解析、转换、过滤数据
3. **数据同步**：将处理后的数据发送到目标系统
4. **状态管理**：记录同步进度，处理异常情况

---

## 2. 📦 全量同步策略


### 2.1 全量同步概念


**什么是全量同步**：一次性将源表的所有数据完整复制到目标位置

```
全量同步场景：
├─ 初始化新的数据副本
├─ 数据库迁移项目
├─ 建立新的分析环境
└─ 修复数据不一致问题
```

**全量同步特点**：
- ✅ **数据完整**：确保所有历史数据都被同步
- ✅ **一致性强**：基于特定时间点的快照
- ❌ **耗时较长**：大表可能需要几小时甚至几天
- ❌ **资源消耗大**：占用大量IO和网络带宽

### 2.2 全量同步实现原理


**数据读取策略**：
```sql
-- Gravity的全量扫描方式
SELECT * FROM source_table 
WHERE id BETWEEN start_id AND end_id
ORDER BY id LIMIT batch_size;

分批读取逻辑：
┌─────────────────────────────────────────┐
│ 表记录分片策略                            │
├─────────────────────────────────────────┤
│ 片段1: id 1-10000      → 线程1处理      │
│ 片段2: id 10001-20000  → 线程2处理      │
│ 片段3: id 20001-30000  → 线程3处理      │
│ ...                                     │
│ 片段N: id N*10000+1-end → 线程N处理     │
└─────────────────────────────────────────┘
```

**性能优化技巧**：
```yaml
# gravity配置示例
full-sync:
  batch-size: 10000        # 每批次处理记录数
  worker-count: 4          # 并发工作线程数
  chunk-size: 100MB        # 内存缓冲区大小
  rate-limit: 1000         # 每秒处理记录数限制
```

### 2.3 全量同步配置


**基础配置示例**：
```toml
# gravity.toml配置文件
[mysql-stream]
source-host = "source-mysql.example.com"
source-port = 3306
source-user = "gravity_user"
source-password = "password"

# 全量同步设置
[full-sync]
enabled = true
tables = ["users", "orders", "products"]
batch-size = 5000
max-full-dump-worker = 4

# 目标配置
[output]
type = "mysql"
target-host = "target-mysql.example.com"
target-port = 3306
```

**高级配置选项**：
```toml
[full-sync]
# 数据一致性设置
consistent-snapshot = true
lock-timeout = 30s

# 性能调优
read-timeout = 300s
write-timeout = 300s
max-retry = 3

# 断点续传
enable-checkpoint = true
checkpoint-interval = "1m"
```

---

## 3. 🔄 增量同步策略


### 3.1 增量同步概念


**什么是增量同步**：只同步源数据库发生变更的数据，基于MySQL binlog实现

```
增量同步原理：
MySQL Binlog 事件流：
┌──────┬──────┬──────┬──────┬──────┐
│INSERT│UPDATE│DELETE│INSERT│UPDATE│
└──────┴──────┴──────┴──────┴──────┘
    │      │      │      │      │
    ▼      ▼      ▼      ▼      ▼
┌─────────────────────────────────┐
│        Gravity处理              │
│ 1. 解析binlog事件               │
│ 2. 转换为目标格式               │ 
│ 3. 应用到目标系统               │
└─────────────────────────────────┘
    │      │      │      │      │
    ▼      ▼      ▼      ▼      ▼
目标系统实时更新
```

**增量同步优势**：
- ⚡ **实时性强**：延迟通常在毫秒级
- 💡 **资源占用少**：只处理变更数据
- 🔄 **持续运行**：7x24小时不间断同步
- 📊 **可监控**：详细的同步指标和状态

### 3.2 Binlog事件处理


**支持的事件类型**：
```
┌─────────────────┬─────────────────┬─────────────────┐
│   事件类型       │     触发场景     │    处理方式      │
├─────────────────┼─────────────────┼─────────────────┤
│ WRITE_ROWS      │ INSERT操作      │ 插入目标表       │
│ UPDATE_ROWS     │ UPDATE操作      │ 更新目标表       │
│ DELETE_ROWS     │ DELETE操作      │ 删除目标记录     │
│ QUERY_EVENT     │ DDL操作         │ 结构变更同步     │
│ XID_EVENT       │ 事务提交        │ 保证事务一致性   │
└─────────────────┴─────────────────┴─────────────────┘
```

**事件解析流程**：
```
Binlog原始事件
      ↓
┌─────────────┐
│ 事件过滤     │ ← 根据库表配置过滤
├─────────────┤
│ 格式解析     │ ← 解析行记录格式
├─────────────┤  
│ 数据转换     │ ← 类型转换和映射
├─────────────┤
│ 目标写入     │ ← 写入目标系统
└─────────────┘
      ↓
同步完成确认
```

### 3.3 增量同步配置


**基本配置**：
```toml
[mysql-stream]
# binlog同步起始位置
binlog-file = "mysql-bin.000001"
binlog-pos = 4

# 同步过滤规则
replicate-do-db = ["app_db", "user_db"]
replicate-ignore-table = ["app_db.temp_*"]

[incremental-sync]
enabled = true
batch-commit-size = 1000    # 批量提交大小
flush-interval = "1s"       # 刷新间隔
```

**高级过滤配置**：
```toml
# 表级过滤
[[table-config]]
schema = "app_db"
table = "users"
# 列过滤
ignore-columns = ["password_hash", "internal_notes"]
# 行过滤  
where-condition = "status != 'deleted'"

# DML操作过滤
[[table-config]]
schema = "app_db" 
table = "audit_log"
# 只同步INSERT，忽略UPDATE/DELETE
events = ["insert"]
```

---

## 4. 🔀 混合同步模式


### 4.1 混合模式概念


**什么是混合同步**：结合全量同步和增量同步，先全量后增量的完整数据同步方案

```
混合同步时间线：
时间轴: T0────T1────T2────T3────T4────→
        │     │     │     │     │
        │   全量开始 全量结束│   正常增量同步
        │     │     │  增量追赶│
     启动    记录   切换    完成  │
    位置点   binlog   模式    追赶 持续运行
```

**适用场景**：
- 🎯 **新环境初始化**：既要历史数据又要实时同步
- 🔄 **数据库迁移**：平滑的数据迁移过程
- 🛠️ **故障恢复**：从备份恢复后追赶最新数据
- 📊 **分析环境搭建**：建立实时数据分析平台

### 4.2 混合模式执行流程


**详细执行步骤**：
```
步骤1: 准备阶段
┌─────────────────────────────────────┐
│ 1. 记录当前binlog位置 (Position A)   │
│ 2. 创建一致性快照                   │
│ 3. 启动增量同步监听                 │
│ 4. 缓存Position A之后的binlog事件   │
└─────────────────────────────────────┘
                    ↓
步骤2: 全量同步阶段  
┌─────────────────────────────────────┐
│ 1. 基于快照执行全量数据同步         │
│ 2. 持续缓存增量binlog事件           │
│ 3. 监控全量同步进度                 │
│ 4. 全量完成后记录Position B         │
└─────────────────────────────────────┘
                    ↓
步骤3: 增量追赶阶段
┌─────────────────────────────────────┐
│ 1. 应用Position A到B之间的事件      │
│ 2. 快速处理堆积的变更               │
│ 3. 逐步追平实时位置                 │
│ 4. 达到实时同步状态                 │
└─────────────────────────────────────┘
                    ↓
步骤4: 持续增量同步
┌─────────────────────────────────────┐
│ 实时处理binlog事件，保持数据同步    │
└─────────────────────────────────────┘
```

### 4.3 混合模式配置


**完整配置示例**：
```toml
[sync-mode]
type = "hybrid"              # 混合模式
full-sync-first = true       # 先执行全量同步

[full-sync]
enabled = true
batch-size = 10000
worker-count = 8
# 全量同步表列表
tables = ["users", "orders", "products", "categories"]

[incremental-sync] 
enabled = true
# 增量同步在全量完成后自动启动
auto-start-after-full = true
catch-up-timeout = "1h"      # 追赶超时时间

[hybrid-config]
# 混合模式特殊设置
binlog-buffer-size = "100MB"  # binlog缓冲区大小
catch-up-batch-size = 5000    # 追赶阶段批量大小
switch-threshold = 1000       # 切换到实时的积压阈值
```

---

## 5. 📍 断点续传机制


### 5.1 断点续传概念


**什么是断点续传**：当同步过程因故障中断时，能够从中断位置继续执行，而不是重新开始

```
断点续传场景：
正常同步: ████████████████████ 100%
故障中断: ████████░░░░░░░░░░░░ 40%
重启续传: ████████████████████ 100%
                 ↑
            从40%位置继续，而不是从0%重新开始
```

**断点信息内容**：
- 🎯 **全量同步**：已处理的表、记录ID范围、批次进度
- 🔄 **增量同步**：binlog文件名、位置、事务ID
- 📊 **混合模式**：当前阶段、阶段内进度、切换条件

### 5.2 断点保存机制


**断点存储策略**：
```
断点信息存储位置：
├─ 本地文件：checkpoint.json
├─ MySQL表：gravity_checkpoint
├─ Redis缓存：checkpoint:gravity:instance_id
└─ Consul/etcd：分布式环境配置中心

存储内容结构：
{
  "instance_id": "gravity-001",
  "sync_mode": "hybrid", 
  "full_sync": {
    "status": "running",
    "current_table": "orders",
    "processed_tables": ["users", "products"],
    "current_offset": 150000,
    "total_rows": 500000
  },
  "incremental_sync": {
    "binlog_file": "mysql-bin.000123", 
    "binlog_pos": 1048576,
    "gtid_set": "uuid:1-100"
  },
  "last_update": "2024-01-15T10:30:00Z"
}
```

### 5.3 断点恢复策略


**恢复流程**：
```
Gravity启动
     ↓
┌─────────────────┐
│ 读取断点信息     │
├─────────────────┤
│ 验证断点有效性   │ ← 检查binlog文件是否存在
├─────────────────┤  
│ 确定恢复策略     │ ← 全量/增量/混合
├─────────────────┤
│ 从断点位置恢复   │ ← 继续未完成的工作
└─────────────────┘
     ↓
正常同步运行
```

**断点配置**：
```toml
[checkpoint]
enabled = true
storage-type = "mysql"       # 存储类型: file/mysql/redis
save-interval = "30s"        # 保存间隔
cleanup-retention = "7d"     # 清理保留时间

# MySQL存储配置
[checkpoint.mysql]
host = "gravity-meta.example.com"
database = "gravity_meta"
table = "checkpoints"

# 恢复策略
[recovery]
auto-resume = true           # 自动恢复
resume-timeout = "30s"       # 恢复超时
validate-checkpoint = true   # 验证断点有效性
```

---

## 6. ⚖️ 数据一致性保证


### 6.1 一致性挑战


**数据一致性问题**：
```
常见一致性问题：
├─ 全量同步期间源数据变更
├─ 网络故障导致部分数据丢失  
├─ 目标系统写入失败
├─ 并发写入导致数据冲突
└─ 系统故障中断同步过程

示例问题场景：
时间T1: 全量同步读取用户表 (user_id=100, name='张三')
时间T2: 源数据库更新 (user_id=100, name='李四') 
时间T3: 全量同步将'张三'写入目标
时间T4: 增量同步将'李四'写入目标
结果: 目标数据可能是'张三'而不是正确的'李四'
```

### 6.2 一致性保证机制


**🔸 事务一致性**
```sql
-- Gravity的事务处理方式
BEGIN;
  INSERT INTO target_table VALUES (...);
  UPDATE gravity_checkpoint SET position = 'new_position';
COMMIT;

-- 保证数据写入和位置更新的原子性
要么都成功，要么都失败，避免数据不一致
```

**🔸 顺序一致性**
```
binlog事件处理顺序：
源数据库事务顺序: T1 → T2 → T3
Gravity处理顺序:  T1 → T2 → T3  (严格保持顺序)
目标系统写入顺序: T1 → T2 → T3

实现机制：
├─ 单线程处理同一表的事件
├─ 使用事务ID排序
├─ 失败重试不影响顺序
└─ 死锁检测和处理
```

**🔸 最终一致性**
```toml
[consistency]
# 一致性检查配置
enable-checksum = true       # 启用校验和验证
checksum-interval = "1h"     # 校验间隔
repair-inconsistency = true  # 自动修复不一致

# 冲突处理策略
conflict-resolution = "source-wins"  # 源端优先
```

### 6.3 一致性监控


**监控指标**：
```
关键监控指标：
┌─────────────────┬─────────────────┬─────────────────┐
│     指标类型     │      指标名称    │     正常范围     │
├─────────────────┼─────────────────┼─────────────────┤
│ 延迟指标        │ replication_lag │ < 1秒           │
│ 数据完整性      │ row_count_diff  │ = 0             │
│ 校验和对比      │ checksum_match  │ = 100%          │
│ 事务完整性      │ transaction_gap │ = 0             │
└─────────────────┴─────────────────┴─────────────────┘

告警配置：
- 延迟 > 10秒：WARNING
- 延迟 > 60秒：CRITICAL  
- 数据不一致：CRITICAL
- 校验和失败：CRITICAL
```

---

## 7. ⚠️ 冲突与失败处理


### 7.1 冲突处理策略


**数据冲突类型**：
```
主键冲突 (Primary Key Conflict):
源端INSERT: user_id=123, name='张三'
目标端已存在: user_id=123, name='李四'

唯一键冲突 (Unique Key Conflict):  
源端INSERT: email='test@example.com', user_id=124
目标端已存在: email='test@example.com', user_id=125

数据不存在冲突 (Row Not Found):
源端UPDATE/DELETE: user_id=126
目标端不存在该记录
```

**冲突解决策略**：
```toml
[conflict-resolution]
# 主键冲突处理
primary-key-conflict = "source-wins"  # 源端优先
# 可选值: source-wins, target-wins, ignore, error

# 唯一键冲突处理  
unique-key-conflict = "error"         # 报错停止
# 可选值: source-wins, target-wins, ignore, error

# 数据不存在处理
row-not-found = "ignore"              # 忽略继续
# 可选值: ignore, error, insert-instead

# 自定义冲突处理器
custom-handler = "com.company.CustomConflictHandler"
```

### 7.2 重试机制配置


**重试策略设计**：
```
重试级别分类：
├─ 连接级重试：网络连接失败
├─ 事务级重试：事务执行失败  
├─ 语句级重试：单条SQL失败
└─ 批次级重试：批量操作失败

重试算法：指数退避 + 最大重试次数
重试间隔 = base_interval × 2^(attempt_count)
```

**重试配置示例**：
```toml
[retry-config]
# 基础重试设置
max-retry-attempts = 3       # 最大重试次数
base-retry-interval = "1s"   # 基础重试间隔
max-retry-interval = "60s"   # 最大重试间隔
retry-backoff-multiplier = 2 # 退避倍数

# 按错误类型配置重试
[[retry-rules]]
error-code = "1062"          # MySQL主键冲突
max-attempts = 1             # 不重试，直接处理冲突
action = "apply-conflict-resolution"

[[retry-rules]]  
error-code = "2006"          # MySQL连接断开
max-attempts = 5             # 最多重试5次
base-interval = "2s"         # 重试间隔2秒
```

### 7.3 失败处理策略


**失败分类处理**：
```
临时性失败 (Temporary Failures):
├─ 网络超时 → 自动重试
├─ 目标数据库锁等待 → 延迟重试
├─ 目标数据库连接数满 → 等待重试
└─ 磁盘空间不足 → 清理后重试

永久性失败 (Permanent Failures):  
├─ 数据格式错误 → 记录错误日志，跳过
├─ 表结构不匹配 → 停止同步，人工处理
├─ 权限不足 → 停止同步，修复权限
└─ 配置错误 → 停止同步，修复配置
```

**失败恢复流程**：
```
检测到失败
     ↓
┌─────────────────┐
│ 判断失败类型     │
├─────────────────┤
│ 临时失败 → 重试  │ ← 应用重试策略
│ 永久失败 → 停止  │ ← 记录详细错误信息
├─────────────────┤
│ 发送告警通知     │ ← 邮件/短信/钉钉等
├─────────────────┤
│ 保存错误现场     │ ← 便于问题排查
└─────────────────┘
     ↓
等待人工干预或自动恢复
```

**错误处理配置**：
```toml
[error-handling]
# 失败行为
on-error = "pause"           # 遇错暂停: pause/continue/stop
error-log-level = "ERROR"    # 错误日志级别

# 错误数据处理
save-error-data = true       # 保存出错的数据
error-data-path = "/var/log/gravity/errors"
max-error-files = 100        # 最大错误文件数

# 告警配置
[alerting]
enabled = true
webhook-url = "https://hooks.slack.com/xxx"
alert-on = ["error", "lag-high", "sync-stopped"]

# 监控检查
[health-check]  
enabled = true
check-interval = "30s"       # 健康检查间隔
lag-threshold = "10s"        # 延迟告警阈值
error-threshold = 10         # 错误数告警阈值
```

---

## 8. 📋 核心要点总结


### 8.1 必须掌握的核心概念


```
🔸 三种同步策略：全量同步、增量同步、混合同步模式
🔸 断点续传机制：故障恢复的关键，避免重复同步
🔸 数据一致性：事务一致性、顺序一致性、最终一致性
🔸 冲突处理：主键冲突、唯一键冲突、数据不存在的处理策略  
🔸 重试机制：指数退避算法、分类重试、最大重试限制
🔸 失败处理：临时失败vs永久失败、告警通知、错误恢复
```

### 8.2 关键理解要点


**🔹 同步策略选择原则**
```
全量同步适用：
✅ 初始化新环境
✅ 数据修复和校验
✅ 历史数据迁移
❌ 不适合实时同步需求

增量同步适用：
✅ 实时数据同步
✅ 长期运行的同步任务
✅ 资源占用敏感场景
❌ 不适合全量数据初始化

混合模式适用：
✅ 新环境搭建（既要历史又要实时）
✅ 数据库迁移项目
✅ 灾难恢复场景
❌ 配置复杂，维护成本高
```

**🔹 一致性vs性能的权衡**
```
强一致性保证：
├─ 单线程同步 → 低性能但强一致
├─ 事务边界严格 → 延迟高但准确
└─ 实时校验 → 开销大但可靠

高性能优化：  
├─ 多线程并行 → 高性能但需处理冲突
├─ 批量提交 → 高吞吐但可能丢失
└─ 异步写入 → 低延迟但可能不一致
```

### 8.3 实际应用指导


**🔸 配置最佳实践**
```toml
# 生产环境推荐配置
[sync-mode]
type = "hybrid"              # 混合模式最完整

[full-sync]
batch-size = 10000           # 平衡内存和效率
worker-count = 4             # 不要超过CPU核心数

[incremental-sync]
batch-commit-size = 1000     # 平衡性能和一致性
flush-interval = "1s"        # 1秒延迟可接受

[checkpoint]
enabled = true               # 必须启用断点续传
save-interval = "30s"        # 30秒保存一次

[retry-config]
max-retry-attempts = 3       # 3次重试通常足够
base-retry-interval = "1s"   # 起始间隔不要太短
```

**🔸 监控告警配置**
```yaml
# 关键监控指标
监控项目:
  - 同步延迟: < 5秒正常，> 30秒告警
  - 错误率: < 0.1%正常，> 1%告警  
  - 数据一致性: 必须100%一致
  - 系统资源: CPU < 80%，内存 < 85%

告警级别:
  - WARNING: 延迟10-30秒，错误率0.1-1%
  - CRITICAL: 延迟>30秒，数据不一致，同步停止
  - EMERGENCY: 系统崩溃，数据丢失风险
```

**🔸 故障处理流程**
```
故障应急处理步骤：
1️⃣ 立即暂停同步，防止错误扩散
2️⃣ 保存现场信息，记录详细日志  
3️⃣ 分析故障原因，确定影响范围
4️⃣ 修复问题后，验证数据一致性
5️⃣ 从断点位置恢复同步
6️⃣ 持续监控，确保恢复正常

数据修复工具：
- 全量对比工具验证一致性
- 增量修复工具补齐缺失数据
- 回滚工具撤销错误操作
```

**核心记忆要点**：
- Gravity提供完整的MySQL同步解决方案
- 混合同步模式是最佳实践，兼顾完整性和实时性
- 断点续传是生产环境必备，保证故障恢复能力
- 数据一致性比性能更重要，出现冲突要谨慎处理
- 完善的监控告警是稳定运行的基础保障