---
title: 34、典型慢查询案例分析
---
## 📚 目录

1. [全表扫描优化案例](#1-全表扫描优化案例)
2. [复杂JOIN优化实例](#2-复杂JOIN优化实例)
3. [大数据量分页优化](#3-大数据量分页优化)
4. [统计查询优化方案](#4-统计查询优化方案)
5. [实时报表优化策略](#5-实时报表优化策略)
6. [批量数据处理优化](#6-批量数据处理优化)
7. [搜索功能性能提升](#7-搜索功能性能提升)
8. [历史数据查询优化](#8-历史数据查询优化)
9. [综合案例总结](#9-综合案例总结)

---

## 1. 🔍 全表扫描优化案例


### 1.1 经典全表扫描问题


**📋 问题场景**：电商系统查询用户订单

```sql
-- 问题SQL：查询某用户的所有订单
SELECT * FROM orders 
WHERE user_id = 12345 
AND status IN ('pending', 'processing');

-- 执行时间：3.2秒，扫描了500万行数据
```

**🔍 问题分析**：
```
EXPLAIN结果显示：
+----+-------+--------+------+------+------+--------+
| id | type  | table  | rows | key  | ref  | Extra  |
+----+-------+--------+------+------+------+--------+
|  1 | ALL   | orders | 5M   | NULL | NULL | Using  |
|    |       |        |      |      |      | where  |
+----+-------+--------+------+------+------+--------+

问题根源：
- user_id字段没有索引
- status字段没有索引  
- MySQL只能逐行检查500万条记录
```

**⚡ 优化方案**：

```sql
-- 步骤1：创建复合索引
ALTER TABLE orders 
ADD INDEX idx_user_status (user_id, status);

-- 步骤2：重新执行查询
SELECT * FROM orders 
WHERE user_id = 12345 
AND status IN ('pending', 'processing');

-- 优化结果：执行时间从3.2秒 → 0.02秒
```

**📊 优化效果对比**：
```
优化前：
- 扫描行数：5,000,000行
- 执行时间：3.2秒
- 索引使用：无

优化后：
- 扫描行数：150行
- 执行时间：0.02秒  
- 索引使用：idx_user_status
- 性能提升：160倍
```

### 1.2 隐式类型转换导致的全表扫描


**📋 问题场景**：根据手机号查询用户信息

```sql
-- 问题SQL：手机号是VARCHAR类型，但传入了数字
SELECT * FROM users 
WHERE mobile = 13812345678;  -- 注意：没有引号

-- 问题：MySQL会将字符串转换为数字进行比较
-- 导致索引失效，全表扫描
```

**🔍 问题诊断**：
```sql
-- 查看执行计划
EXPLAIN SELECT * FROM users WHERE mobile = 13812345678;

结果显示：
- type: ALL (全表扫描)
- possible_keys: NULL
- key: NULL
- 即使mobile字段有索引也无法使用
```

**⚡ 解决方案**：
```sql
-- 正确写法：给数字加引号
SELECT * FROM users 
WHERE mobile = '13812345678';

-- 或者使用显式转换
SELECT * FROM users 
WHERE mobile = CAST(13812345678 AS CHAR);
```

> 💡 **核心原理**：当字段类型与查询条件类型不匹配时，MySQL会进行隐式转换，这通常会导致索引失效。

---

## 2. 🔗 复杂JOIN优化实例


### 2.1 多表JOIN性能问题


**📋 问题场景**：电商系统订单详情查询

```sql
-- 问题SQL：查询订单详细信息
SELECT 
    o.order_id,
    o.order_time,
    u.username,
    u.email,
    p.product_name,
    p.price,
    oi.quantity
FROM orders o
JOIN users u ON o.user_id = u.user_id
JOIN order_items oi ON o.order_id = oi.order_id  
JOIN products p ON oi.product_id = p.product_id
WHERE o.order_time >= '2024-01-01'
AND o.status = 'completed';

-- 执行时间：25秒
```

**🔍 性能分析**：
```
问题根源：
1. 多表关联缺少合适的索引
2. JOIN顺序不当，导致中间结果集过大
3. WHERE条件没有充分利用索引过滤

执行计划显示：
- orders表：全表扫描
- 其他表：通过主键关联，但效率低
```

**⚡ 优化策略**：

```sql
-- 步骤1：添加必要的索引
ALTER TABLE orders ADD INDEX idx_time_status (order_time, status);
ALTER TABLE order_items ADD INDEX idx_order_product (order_id, product_id);

-- 步骤2：使用子查询优化
SELECT 
    o.order_id,
    o.order_time,
    u.username,
    u.email,
    p.product_name,
    p.price,
    oi.quantity
FROM (
    -- 先过滤出符合条件的订单
    SELECT order_id, user_id, order_time 
    FROM orders 
    WHERE order_time >= '2024-01-01'
    AND status = 'completed'
) o
JOIN users u ON o.user_id = u.user_id
JOIN order_items oi ON o.order_id = oi.order_id
JOIN products p ON oi.product_id = p.product_id;

-- 执行时间：1.5秒
```

### 2.2 大表JOIN小表优化


**📋 问题场景**：订单表(1000万条)关联省份表(34条)

```sql
-- 问题SQL：统计各省份订单数量
SELECT 
    p.province_name,
    COUNT(*) as order_count
FROM orders o
JOIN provinces p ON o.province_id = p.province_id
WHERE o.order_time >= '2024-01-01'
GROUP BY p.province_name;

-- 执行时间：12秒
```

**⚡ 优化方案**：
```sql
-- 方案1：调整JOIN顺序，小表驱动大表
SELECT 
    p.province_name,
    COUNT(*) as order_count
FROM provinces p
LEFT JOIN orders o ON p.province_id = o.province_id
    AND o.order_time >= '2024-01-01'
GROUP BY p.province_name;

-- 方案2：使用子查询预先过滤
SELECT 
    p.province_name,
    tmp.order_count
FROM provinces p
JOIN (
    SELECT province_id, COUNT(*) as order_count
    FROM orders 
    WHERE order_time >= '2024-01-01'
    GROUP BY province_id
) tmp ON p.province_id = tmp.province_id;

-- 执行时间：0.8秒
```

---

## 3. 📄 大数据量分页优化


### 3.1 深度分页性能问题


**📋 问题场景**：商品列表分页查询

```sql
-- 问题SQL：查询第10000页的商品（每页20条）
SELECT * FROM products 
ORDER BY create_time DESC 
LIMIT 200000, 20;

-- 执行时间：8.5秒
-- MySQL需要先排序前200020条记录，然后丢弃前200000条
```

**🔍 问题分析**：
```
深度分页问题：
1. OFFSET很大时，MySQL需要扫描大量数据
2. 即使有索引，也要定位到第200000条记录
3. 随着页数增加，性能线性下降

性能测试结果：
第1页：   0.01秒
第100页： 0.05秒  
第1000页：0.5秒
第10000页：8.5秒
```

**⚡ 优化方案1：使用游标分页**

```sql
-- 记录上一页的最后一条记录的时间
-- 第一页
SELECT id, name, create_time FROM products 
ORDER BY create_time DESC 
LIMIT 20;

-- 后续页面（假设上一页最后记录的create_time是'2024-06-01 10:30:00'）
SELECT id, name, create_time FROM products 
WHERE create_time < '2024-06-01 10:30:00'
ORDER BY create_time DESC 
LIMIT 20;

-- 执行时间：始终保持在0.01秒
```

**⚡ 优化方案2：子查询优化**

```sql
-- 先通过索引定位到起始位置，再关联查询详细信息
SELECT p.* FROM products p
JOIN (
    SELECT id FROM products 
    ORDER BY create_time DESC 
    LIMIT 200000, 20
) tmp ON p.id = tmp.id
ORDER BY p.create_time DESC;

-- 执行时间：从8.5秒 → 2.1秒
```

### 3.2 计数查询优化


**📋 问题场景**：分页时需要总记录数

```sql
-- 问题SQL：既要分页数据，又要总数
SELECT SQL_CALC_FOUND_ROWS * FROM products 
WHERE category_id = 5 
ORDER BY create_time DESC 
LIMIT 0, 20;

SELECT FOUND_ROWS(); -- 获取总数

-- 执行时间：1.2秒
```

**⚡ 优化策略**：
```sql
-- 方案1：分离查询
-- 先查询数据
SELECT * FROM products 
WHERE category_id = 5 
ORDER BY create_time DESC 
LIMIT 0, 20;

-- 单独查询总数（只在需要时）
SELECT COUNT(*) FROM products WHERE category_id = 5;

-- 方案2：估算总数
SELECT table_rows FROM information_schema.tables 
WHERE table_name = 'products';

-- 方案3：缓存总数
-- 在Redis中缓存每个分类的商品总数
-- 当有商品增删时更新缓存
```

---

## 4. 📊 统计查询优化方案


### 4.1 复杂聚合查询优化


**📋 问题场景**：销售数据统计分析

```sql
-- 问题SQL：多维度销售统计
SELECT 
    DATE(order_time) as order_date,
    category_id,
    COUNT(*) as order_count,
    SUM(amount) as total_amount,
    AVG(amount) as avg_amount,
    MAX(amount) as max_amount
FROM orders o
JOIN order_items oi ON o.order_id = oi.order_id
JOIN products p ON oi.product_id = p.product_id  
WHERE o.order_time >= '2024-01-01'
GROUP BY DATE(order_time), category_id
ORDER BY order_date DESC, total_amount DESC;

-- 执行时间：45秒
```

**⚡ 优化方案1：创建统计表**

```sql
-- 创建日常统计表
CREATE TABLE daily_sales_stats (
    stat_date DATE,
    category_id INT,
    order_count INT,
    total_amount DECIMAL(15,2),
    avg_amount DECIMAL(10,2),
    max_amount DECIMAL(10,2),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    PRIMARY KEY (stat_date, category_id)
);

-- 通过定时任务每日更新
INSERT INTO daily_sales_stats 
SELECT 
    DATE(order_time) as stat_date,
    category_id,
    COUNT(*) as order_count,
    SUM(amount) as total_amount,
    AVG(amount) as avg_amount,
    MAX(amount) as max_amount
FROM orders o
JOIN order_items oi ON o.order_id = oi.order_id
JOIN products p ON oi.product_id = p.product_id  
WHERE DATE(order_time) = CURDATE() - INTERVAL 1 DAY
GROUP BY DATE(order_time), category_id;

-- 查询时直接从统计表获取
SELECT * FROM daily_sales_stats 
WHERE stat_date >= '2024-01-01'
ORDER BY stat_date DESC, total_amount DESC;

-- 执行时间：0.05秒
```

**⚡ 优化方案2：使用物化视图**

```sql
-- MySQL 8.0+支持CTE，可以模拟物化视图
WITH sales_summary AS (
    SELECT 
        DATE(order_time) as order_date,
        category_id,
        COUNT(*) as order_count,
        SUM(amount) as total_amount
    FROM orders_summary  -- 预计算的汇总表
    WHERE order_time >= '2024-01-01'
    GROUP BY DATE(order_time), category_id
)
SELECT * FROM sales_summary 
ORDER BY order_date DESC, total_amount DESC;
```

### 4.2 去重统计优化


**📋 问题场景**：用户活跃度统计

```sql
-- 问题SQL：统计每日活跃用户数
SELECT 
    DATE(login_time) as login_date,
    COUNT(DISTINCT user_id) as active_users
FROM user_login_logs 
WHERE login_time >= '2024-01-01'
GROUP BY DATE(login_time);

-- 执行时间：15秒，日志表有5000万条记录
```

**⚡ 优化方案**：
```sql
-- 方案1：创建日活跃用户表
CREATE TABLE daily_active_users (
    activity_date DATE,
    user_id INT,
    first_login_time DATETIME,
    PRIMARY KEY (activity_date, user_id),
    KEY idx_date (activity_date)
);

-- 实时维护（在用户登录时插入）
INSERT IGNORE INTO daily_active_users 
VALUES (CURDATE(), ?, NOW());

-- 统计查询变为简单计数
SELECT 
    activity_date,
    COUNT(*) as active_users
FROM daily_active_users 
WHERE activity_date >= '2024-01-01'
GROUP BY activity_date;

-- 执行时间：0.1秒
```

---

## 5. ⏱️ 实时报表优化策略


### 5.1 实时大屏数据查询


**📋 问题场景**：电商实时监控大屏

```sql
-- 问题SQL：实时数据统计
SELECT 
    COUNT(*) as today_orders,
    SUM(amount) as today_revenue,
    COUNT(DISTINCT user_id) as today_users,
    AVG(amount) as avg_order_value
FROM orders 
WHERE DATE(order_time) = CURDATE();

-- 每5秒刷新一次，给数据库造成很大压力
```

**⚡ 优化策略1：Redis缓存 + 异步更新**

```sql
-- 创建实时统计缓存表
CREATE TABLE realtime_stats (
    stat_key VARCHAR(50) PRIMARY KEY,
    stat_value DECIMAL(15,2),
    update_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
);

-- 后台异步任务每分钟更新一次
INSERT INTO realtime_stats VALUES 
('today_orders', ?, NOW()),
('today_revenue', ?, NOW()),
('today_users', ?, NOW()),
('avg_order_value', ?, NOW())
ON DUPLICATE KEY UPDATE 
stat_value = VALUES(stat_value),
update_time = NOW();

-- 前端查询缓存数据
SELECT stat_key, stat_value FROM realtime_stats 
WHERE stat_key IN ('today_orders', 'today_revenue', 'today_users', 'avg_order_value');
```

**⚡ 优化策略2：读写分离 + 从库查询**

```sql
-- 统计查询路由到只读从库
-- 主库专门处理写操作
-- 从库处理所有统计和报表查询

-- 应用层配置示例
@Transactional(readOnly = true)
@DataSource("slave")
public DashboardStats getRealTimeStats() {
    // 从只读库查询统计数据
}
```

### 5.2 多维度实时分析


**📋 问题场景**：按地区、时间、品类的实时分析

```sql
-- 问题SQL：多维度实时统计
SELECT 
    province,
    category_name,
    HOUR(order_time) as hour_slot,
    COUNT(*) as order_count,
    SUM(amount) as revenue
FROM orders o
JOIN users u ON o.user_id = u.user_id
JOIN order_items oi ON o.order_id = oi.order_id
JOIN products p ON oi.product_id = p.product_id
JOIN categories c ON p.category_id = c.category_id
WHERE DATE(order_time) = CURDATE()
GROUP BY province, category_name, HOUR(order_time);

-- 执行时间：30秒
```

**⚡ 优化方案：OLAP立方体预计算**

```sql
-- 创建多维度汇总表
CREATE TABLE hourly_sales_cube (
    stat_hour DATETIME,
    province VARCHAR(50),
    category_id INT,
    order_count INT,
    total_revenue DECIMAL(15,2),
    PRIMARY KEY (stat_hour, province, category_id),
    KEY idx_hour (stat_hour),
    KEY idx_province (province),
    KEY idx_category (category_id)
);

-- 每小时预计算并插入
INSERT INTO hourly_sales_cube 
SELECT 
    DATE_FORMAT(order_time, '%Y-%m-%d %H:00:00') as stat_hour,
    u.province,
    p.category_id,
    COUNT(*) as order_count,
    SUM(amount) as total_revenue
FROM orders o
JOIN users u ON o.user_id = u.user_id
JOIN order_items oi ON o.order_id = oi.order_id  
JOIN products p ON oi.product_id = p.product_id
WHERE order_time >= DATE_FORMAT(NOW(), '%Y-%m-%d %H:00:00') - INTERVAL 1 HOUR
AND order_time < DATE_FORMAT(NOW(), '%Y-%m-%d %H:00:00')
GROUP BY stat_hour, u.province, p.category_id;

-- 查询时从立方体获取
SELECT 
    province,
    c.category_name,
    HOUR(stat_hour) as hour_slot,
    SUM(order_count) as order_count,
    SUM(total_revenue) as revenue
FROM hourly_sales_cube h
JOIN categories c ON h.category_id = c.category_id
WHERE DATE(stat_hour) = CURDATE()
GROUP BY province, c.category_name, HOUR(stat_hour);

-- 执行时间：0.2秒
```

---

## 6. 📦 批量数据处理优化


### 6.1 大批量INSERT优化


**📋 问题场景**：数据迁移或批量导入

```sql
-- 问题SQL：逐条插入数据
INSERT INTO products (name, price, category_id) VALUES ('Product1', 99.99, 1);
INSERT INTO products (name, price, category_id) VALUES ('Product2', 199.99, 2);
-- ... 重复100万次
-- 执行时间：45分钟
```

**⚡ 优化方案1：批量INSERT**

```sql
-- 优化SQL：批量插入
INSERT INTO products (name, price, category_id) VALUES 
('Product1', 99.99, 1),
('Product2', 199.99, 2),
('Product3', 299.99, 3),
-- ... 每批1000条
('Product1000', 999.99, 10);

-- 执行时间：3分钟
```

**⚡ 优化方案2：使用LOAD DATA INFILE**

```sql
-- 最优方案：文件导入
LOAD DATA INFILE '/tmp/products.csv' 
INTO TABLE products 
FIELDS TERMINATED BY ',' 
ENCLOSED BY '"'
LINES TERMINATED BY '\n'
IGNORE 1 ROWS
(name, price, category_id);

-- 执行时间：1分钟
```

### 6.2 大批量UPDATE优化


**📋 问题场景**：批量更新商品价格

```sql
-- 问题SQL：逐条更新
UPDATE products SET price = price * 1.1 WHERE category_id = 1;
UPDATE products SET price = price * 1.2 WHERE category_id = 2;
-- ... 100个分类
-- 执行时间：20分钟
```

**⚡ 优化方案**：
```sql
-- 方案1：使用CASE WHEN批量更新
UPDATE products 
SET price = CASE category_id
    WHEN 1 THEN price * 1.1
    WHEN 2 THEN price * 1.2
    WHEN 3 THEN price * 1.15
    -- ... 其他分类
    ELSE price
END
WHERE category_id IN (1, 2, 3, ...);

-- 方案2：分批处理，避免长时间锁表
UPDATE products 
SET price = price * 1.1 
WHERE category_id = 1 
LIMIT 1000;

-- 重复执行直到影响行数为0
```

### 6.3 批量DELETE优化


**📋 问题场景**：删除历史数据

```sql
-- 问题SQL：一次性删除大量数据
DELETE FROM order_logs 
WHERE create_time < '2023-01-01';
-- 要删除500万条记录，执行时间：1小时，还可能锁表
```

**⚡ 优化方案**：
```sql
-- 方案1：分批删除
DELETE FROM order_logs 
WHERE create_time < '2023-01-01' 
LIMIT 1000;

-- 编写脚本重复执行，每次删除1000条，避免长时间锁表

-- 方案2：创建新表，保留需要的数据
CREATE TABLE order_logs_new LIKE order_logs;

INSERT INTO order_logs_new 
SELECT * FROM order_logs 
WHERE create_time >= '2023-01-01';

-- 原子性替换表名
RENAME TABLE order_logs TO order_logs_old, 
             order_logs_new TO order_logs;

DROP TABLE order_logs_old;
```

---

## 7. 🔍 搜索功能性能提升


### 7.1 模糊搜索优化


**📋 问题场景**：商品名称搜索

```sql
-- 问题SQL：模糊搜索商品
SELECT * FROM products 
WHERE product_name LIKE '%手机%' 
ORDER BY sales_count DESC 
LIMIT 20;

-- 执行时间：5秒，无法使用索引
```

**⚡ 优化方案1：全文索引**

```sql
-- 创建全文索引
ALTER TABLE products ADD FULLTEXT(product_name);

-- 使用全文搜索
SELECT * FROM products 
WHERE MATCH(product_name) AGAINST('手机' IN NATURAL LANGUAGE MODE)
ORDER BY sales_count DESC 
LIMIT 20;

-- 执行时间：0.1秒
```

**⚡ 优化方案2：搜索词分解**

```sql
-- 创建关键词表
CREATE TABLE product_keywords (
    product_id INT,
    keyword VARCHAR(20),
    PRIMARY KEY (product_id, keyword),
    KEY idx_keyword (keyword)
);

-- 将商品名称分解为关键词
INSERT INTO product_keywords VALUES 
(1, '苹果'), (1, 'iPhone'), (1, '手机'),
(2, '华为'), (2, 'P50'), (2, '手机');

-- 搜索时关联关键词表
SELECT DISTINCT p.* FROM products p
JOIN product_keywords pk ON p.product_id = pk.product_id
WHERE pk.keyword = '手机'
ORDER BY p.sales_count DESC 
LIMIT 20;

-- 执行时间：0.05秒
```

### 7.2 多条件搜索优化


**📋 问题场景**：商品筛选功能

```sql
-- 问题SQL：多条件筛选
SELECT * FROM products 
WHERE category_id = 5
AND price BETWEEN 100 AND 500
AND brand_id = 10
AND product_name LIKE '%手机%'
AND status = 'active'
ORDER BY sales_count DESC 
LIMIT 20;

-- 执行时间：8秒
```

**⚡ 优化策略**：
```sql
-- 方案1：创建覆盖索引
ALTER TABLE products 
ADD INDEX idx_category_brand_price_status 
(category_id, brand_id, price, status);

-- 方案2：先用索引条件过滤，再应用其他条件
SELECT * FROM products 
WHERE category_id = 5
AND brand_id = 10
AND price BETWEEN 100 AND 500
AND status = 'active'
AND product_name LIKE '%手机%'  -- 最后应用LIKE条件
ORDER BY sales_count DESC 
LIMIT 20;

-- 方案3：使用搜索引擎
-- 将数据同步到Elasticsearch
-- 复杂搜索由ES处理，MySQL只负责存储
```

---

## 8. 📂 历史数据查询优化


### 8.1 时间范围查询优化


**📋 问题场景**：查询历史订单数据

```sql
-- 问题SQL：查询某时间段的订单
SELECT * FROM orders 
WHERE order_time BETWEEN '2023-01-01' AND '2023-12-31'
ORDER BY order_time DESC;

-- 执行时间：12秒，orders表有2000万条记录
```

**⚡ 优化方案1：分区表**

```sql
-- 创建按月分区的订单表
CREATE TABLE orders_partitioned (
    order_id INT AUTO_INCREMENT,
    user_id INT,
    order_time DATETIME,
    amount DECIMAL(10,2),
    status VARCHAR(20),
    PRIMARY KEY (order_id, order_time),
    KEY idx_user_time (user_id, order_time)
) PARTITION BY RANGE (YEAR(order_time) * 100 + MONTH(order_time)) (
    PARTITION p202301 VALUES LESS THAN (202302),
    PARTITION p202302 VALUES LESS THAN (202303),
    -- ... 每月一个分区
    PARTITION p202412 VALUES LESS THAN (202501)
);

-- 查询时只扫描相关分区
SELECT * FROM orders_partitioned 
WHERE order_time BETWEEN '2023-06-01' AND '2023-06-30'
ORDER BY order_time DESC;

-- 执行时间：0.5秒，只扫描6月份分区
```

**⚡ 优化方案2：冷热数据分离**

```sql
-- 热数据表（近3个月）
CREATE TABLE orders_hot AS 
SELECT * FROM orders 
WHERE order_time >= CURDATE() - INTERVAL 3 MONTH;

-- 冷数据表（3个月之前）
CREATE TABLE orders_cold AS 
SELECT * FROM orders 
WHERE order_time < CURDATE() - INTERVAL 3 MONTH;

-- 查询时根据时间范围选择表
-- 应用层逻辑决定查询哪个表或两个表
```

### 8.2 归档数据查询


**📋 问题场景**：查询已归档的历史数据

```sql
-- 问题SQL：在归档表中查询历史订单
SELECT * FROM orders_archive 
WHERE user_id = 12345
AND order_time >= '2022-01-01';

-- 归档表有5000万条记录，执行时间：20秒
```

**⚡ 优化方案**：
```sql
-- 方案1：创建归档索引策略
ALTER TABLE orders_archive 
ADD INDEX idx_user_time (user_id, order_time);

-- 方案2：使用压缩存储引擎
ALTER TABLE orders_archive ENGINE=MyISAM ROW_FORMAT=COMPRESSED;

-- 方案3：分层存储
-- 1年内数据：MySQL
-- 1-3年数据：压缩存储
-- 3年以上：对象存储(OSS) + 离线查询
```

---

## 9. 📋 综合案例总结


### 9.1 性能优化通用原则


**🎯 索引优化原则**
```
1. 最左前缀原则：复合索引要考虑查询条件顺序
2. 覆盖索引：尽量让索引包含所有需要的字段
3. 索引选择性：高选择性字段建索引效果更好
4. 避免过度索引：每个索引都有维护成本
```

**⚡ 查询优化原则**
```
1. 小表驱动大表：JOIN时让小表做驱动表
2. 先过滤再关联：WHERE条件尽量在子查询中
3. 避免SELECT *：只查询需要的字段
4. 合理使用LIMIT：避免返回过多数据
```

**📊 架构优化原则**
```
1. 读写分离：查询走从库，写操作走主库
2. 分库分表：单表数据量控制在合理范围
3. 缓存策略：热点数据放入缓存
4. 异步处理：统计类查询异步计算
```

### 9.2 常见慢查询类型总结


| **慢查询类型** | **典型场景** | **主要原因** | **优化方案** |
|---------------|-------------|-------------|-------------|
| **全表扫描** | `WHERE条件无索引` | `缺少合适的索引` | `创建索引、优化WHERE条件` |
| **深度分页** | `LIMIT offset很大` | `需要跳过大量数据` | `游标分页、子查询优化` |
| **复杂JOIN** | `多表关联查询` | `关联条件无索引、顺序不当` | `添加索引、调整JOIN顺序` |
| **聚合统计** | `GROUP BY、COUNT` | `需要扫描大量数据` | `预计算、汇总表` |
| **模糊搜索** | `LIKE '%keyword%'` | `无法使用索引` | `全文索引、搜索引擎` |
| **批量操作** | `大量INSERT/UPDATE` | `逐条操作效率低` | `批量SQL、文件导入` |

### 9.3 监控和诊断工具


**🔍 慢查询监控**
```sql
-- 开启慢查询日志
SET GLOBAL slow_query_log = 1;
SET GLOBAL long_query_time = 1;

-- 查看慢查询统计
SELECT * FROM mysql.slow_log 
ORDER BY start_time DESC LIMIT 10;
```

**📊 性能分析工具**
```sql
-- 使用EXPLAIN分析查询计划
EXPLAIN SELECT * FROM orders WHERE user_id = 12345;

-- 使用EXPLAIN ANALYZE查看实际执行情况（MySQL 8.0+）
EXPLAIN ANALYZE SELECT * FROM orders WHERE user_id = 12345;

-- 查看索引使用情况
SHOW INDEX FROM orders;
```

**⚠️ 关键监控指标**
```
1. 慢查询数量：每分钟慢查询的数量
2. 查询响应时间：平均响应时间和95%分位数
3. 索引命中率：通过索引扫描的比例
4. 锁等待时间：事务锁等待的时间
5. 连接数使用率：当前连接数/最大连接数
```

> 💡 **核心记忆**：
> - **慢查询优化三步骤**：发现问题 → 分析原因 → 制定方案
> - **性能优化四原则**：索引优先、查询简化、架构分离、缓存加速
> - **监控诊断五指标**：慢查询、响应时间、索引命中、锁等待、连接使用

**🎯 实战建议**：
1. **建立监控体系**：及时发现慢查询问题
2. **定期分析优化**：每周回顾慢查询日志
3. **预防性设计**：新功能上线前进行性能测试
4. **持续学习改进**：跟踪新的优化技术和工具