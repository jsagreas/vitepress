---
title: 17、MySQL Shell数据导入导出功能
---
## 📚 目录

1. [MySQL Shell数据导入导出概述](#1-mysql-shell数据导入导出概述)
2. [util.importTable()数据导入详解](#2-util.importtable数据导入详解)
3. [util.exportTable()数据导出详解](#3-util.exporttable数据导出详解)
4. [数据格式支持与选择](#4-数据格式支持与选择)
5. [并行加载机制原理](#5-并行加载机制原理)
6. [数据转换与字符编码](#6-数据转换与字符编码)
7. [大文件处理策略](#7-大文件处理策略)
8. [错误处理与性能优化](#8-错误处理与性能优化)
9. [进度监控与实战应用](#9-进度监控与实战应用)
10. [核心要点总结](#10-核心要点总结)

---

## 1. 🗃️ MySQL Shell数据导入导出概述


### 1.1 什么是MySQL Shell数据导入导出


**通俗理解**：就像我们平时复制粘贴文件一样，MySQL Shell的导入导出功能就是帮我们把数据从外部文件"搬进"数据库，或者把数据库里的数据"搬出"到文件里。

```
传统方式 vs MySQL Shell方式：

传统mysqldump方式：
数据库 → SQL文件 → 手动执行SQL → 目标数据库
（慢，容易出错，难以监控）

MySQL Shell方式：
数据库 ↔ 各种格式文件（CSV、JSON、TSV等）
（快，自动化，有进度条，支持并行）
```

### 1.2 核心工具说明


**两个核心工具**：
- `util.importTable()` - **数据导入工具**，把外部文件的数据导入到MySQL表中
- `util.exportTable()` - **数据导出工具**，把MySQL表的数据导出到文件中

### 1.3 主要优势特点


| 特点 | **传统方式** | **MySQL Shell方式** |
|------|-------------|---------------------|
| **速度** | `较慢` | `快速并行处理` |
| **格式** | `主要SQL格式` | `CSV、JSON、TSV等多种格式` |
| **监控** | `无进度显示` | `实时进度条` |
| **错误处理** | `遇错停止` | `灵活的错误处理策略` |
| **大文件** | `容易超时` | `专门的大文件处理机制` |

---

## 2. 📥 util.importTable()数据导入详解


### 2.1 基本语法和概念


**基本语法结构**：
```javascript
util.importTable('文件路径', {
    schema: '数据库名',
    table: '表名',
    // 其他选项...
})
```

**简单理解**：就是告诉MySQL Shell"把这个文件的数据，按照我指定的规则，导入到指定的数据库表里"。

### 2.2 核心参数详解


**必需参数**：
```javascript
// 最基本的导入示例
util.importTable('/path/to/data.csv', {
    schema: 'mydb',        // 目标数据库名
    table: 'users'         // 目标表名
})
```

**重要可选参数**：

| 参数 | **含义** | **示例** | **说明** |
|------|---------|----------|----------|
| `columns` | `指定列对应关系` | `['id','name','email']` | `告诉MySQL哪一列对应表的哪个字段` |
| `fieldsTerminatedBy` | `字段分隔符` | `','` | `CSV用逗号，TSV用制表符` |
| `fieldsEnclosedBy` | `字段包围符` | `'"'` | `处理包含特殊字符的字段` |
| `linesTerminatedBy` | `行分隔符` | `'\n'` | `指定换行符类型` |
| `skipRows` | `跳过行数` | `1` | `跳过标题行` |

### 2.3 实际使用示例


**CSV文件导入示例**：
```javascript
// 有标题行的CSV文件导入
util.importTable('/data/users.csv', {
    schema: 'company',
    table: 'employees',
    columns: ['emp_id', 'name', 'department', 'salary'],
    skipRows: 1,                    // 跳过标题行
    fieldsTerminatedBy: ',',        // 逗号分隔
    fieldsEnclosedBy: '"',          // 双引号包围
    showProgress: true              // 显示进度
})
```

**CSV文件内容示例**：
```csv
ID,姓名,部门,薪资
1001,"张三","技术部",8000
1002,"李四","销售部",6000
1003,"王五","人事部",7000
```

### 2.4 导入模式选择


**三种导入模式**：

```javascript
// 1. 替换模式（默认）- 清空表后导入
util.importTable('data.csv', {
    schema: 'mydb',
    table: 'users',
    replaceDuplicates: true    // 遇到重复数据就替换
})

// 2. 追加模式 - 在现有数据后面追加
util.importTable('data.csv', {
    schema: 'mydb', 
    table: 'users',
    replaceDuplicates: false   // 遇到重复数据跳过
})

// 3. 严格模式 - 遇到重复数据报错
util.importTable('data.csv', {
    schema: 'mydb',
    table: 'users'
    // 默认遇到重复数据会报错停止
})
```

---

## 3. 📤 util.exportTable()数据导出详解


### 3.1 基本导出概念


**基本语法**：
```javascript
util.exportTable('数据库.表名', '输出文件路径', {
    // 导出选项...
})
```

**简单理解**：就是把数据库表里的数据，按照指定格式"倒出来"保存到文件里。

### 3.2 基本导出示例


**最简单的导出**：
```javascript
// 导出整个表到CSV文件
util.exportTable('company.employees', '/export/employees.csv')
```

**带条件的导出**：
```javascript
// 只导出特定条件的数据
util.exportTable('company.employees', '/export/tech_employees.csv', {
    where: "department = '技术部'",
    fieldsTerminatedBy: ',',
    fieldsEnclosedBy: '"',
    showProgress: true
})
```

### 3.3 导出格式控制


**CSV格式导出**：
```javascript
util.exportTable('mydb.users', '/path/users.csv', {
    fieldsTerminatedBy: ',',       // 逗号分隔
    fieldsEnclosedBy: '"',         // 双引号包围
    linesTerminatedBy: '\n',       // 换行符
    fieldsOptionallyEnclosed: true  // 只在需要时加引号
})
```

**TSV格式导出**：
```javascript
util.exportTable('mydb.users', '/path/users.tsv', {
    fieldsTerminatedBy: '\t',      // 制表符分隔
    linesTerminatedBy: '\n'
})
```

### 3.4 导出字段控制


**选择特定字段导出**：
```javascript
util.exportTable('company.employees', '/export/employee_list.csv', {
    columns: ['emp_id', 'name', 'department'],  // 只导出这几个字段
    where: "status = 'active'",                 // 只导出在职员工
    orderBy: 'emp_id'                          // 按员工ID排序
})
```

---

## 4. 📊 数据格式支持与选择


### 4.1 支持的数据格式


```
支持的主要格式：
┌─────────────┬─────────────┬─────────────────┐
│   格式类型   │    扩展名    │      适用场景      │
├─────────────┼─────────────┼─────────────────┤
│    CSV      │    .csv     │  通用数据交换     │
│    TSV      │    .tsv     │  大数据量处理     │
│    JSON     │    .json    │  结构化数据       │
│   纯文本     │    .txt     │  简单数据导出     │
└─────────────┴─────────────┴─────────────────┘
```

### 4.2 格式选择指导


**CSV格式 - 最常用**：
```javascript
// 优点：通用性好，Excel可直接打开
// 缺点：不支持复杂数据结构
util.importTable('data.csv', {
    schema: 'mydb',
    table: 'products',
    fieldsTerminatedBy: ',',
    fieldsEnclosedBy: '"'
})
```

**TSV格式 - 大数据首选**：
```javascript
// 优点：处理速度快，不容易出现分隔符冲突
// 缺点：不如CSV直观
util.importTable('bigdata.tsv', {
    schema: 'warehouse',
    table: 'sales_data',
    fieldsTerminatedBy: '\t'      // 制表符分隔
})
```

### 4.3 字段分隔符详解


**常用分隔符对比**：

| 分隔符 | **字符** | **适用场景** | **注意事项** |
|-------|----------|-------------|-------------|
| **逗号** | `,` | `CSV文件标准` | `字段内容不能包含逗号` |
| **制表符** | `\t` | `TSV文件，大数据` | `处理速度快，冲突少` |
| **分号** | `;` | `欧洲CSV标准` | `适合包含逗号的数据` |
| **管道符** | `|` | `数据库导出` | `冲突概率很低` |

**分隔符选择示例**：
```javascript
// 数据包含逗号时，用分号分隔
util.importTable('products.csv', {
    schema: 'shop',
    table: 'items',
    fieldsTerminatedBy: ';',       // 用分号分隔
    fieldsEnclosedBy: '"'          // 双引号包围
})
```

---

## 5. ⚡ 并行加载机制原理


### 5.1 并行加载概念


**传统单线程 vs 并行加载**：
```
传统方式：
文件 → [单线程处理] → 数据库
速度：慢，一条一条处理

并行方式：
文件 → [线程1] ┐
文件 → [线程2] ├─→ 数据库
文件 → [线程3] ┘
速度：快，多条同时处理
```

### 5.2 并行参数配置


**关键并行参数**：
```javascript
util.importTable('large_data.csv', {
    schema: 'bigdata',
    table: 'transactions',
    threads: 8,                    // 使用8个并行线程
    bytesPerChunk: '50M',          // 每块50MB
    maxRate: '100M',              // 最大速率100MB/s
    showProgress: true
})
```

**参数说明**：
- `threads` - **并行线程数**，通常设为CPU核心数
- `bytesPerChunk` - **数据块大小**，影响内存使用和效率
- `maxRate` - **速率限制**，避免影响其他数据库操作

### 5.3 并行效果示例


**性能对比**：
```
测试文件：1GB CSV文件，100万行数据

单线程模式：
threads: 1
导入时间：约15分钟

并行模式：
threads: 4
导入时间：约4分钟

8核并行模式：
threads: 8  
导入时间：约2分钟
```

### 5.4 并行设置建议


**硬件配置对应的线程建议**：

| CPU核心数 | **推荐线程数** | **数据块大小** | **适用场景** |
|----------|---------------|---------------|-------------|
| `2-4核` | `2-4` | `10-20M` | `小型数据库` |
| `4-8核` | `4-8` | `20-50M` | `中型数据库` |
| `8核以上` | `8-16` | `50-100M` | `大型数据库` |

---

## 6. 🔄 数据转换与字符编码


### 6.1 字符编码基础


**编码问题的表现**：
```
常见乱码情况：
原始数据：张三、李四
错误显示：å¼ ä¸‰ã€æŽå››
原因：字符编码不匹配
```

**MySQL Shell支持的编码**：
- `utf8mb4` - **推荐使用**，支持所有Unicode字符包括emoji
- `utf8` - 标准UTF-8编码
- `latin1` - 西欧字符集
- `gbk` - 中文编码

### 6.2 编码设置方法


**导入时指定编码**：
```javascript
util.importTable('/data/chinese_data.csv', {
    schema: 'mydb',
    table: 'users',
    characterSet: 'utf8mb4',       // 指定文件编码
    fieldsTerminatedBy: ',',
    skipRows: 1
})
```

**处理编码不匹配问题**：
```javascript
// 如果文件是GBK编码，数据库是UTF8
util.importTable('/data/gbk_file.csv', {
    schema: 'mydb',
    table: 'customers',
    characterSet: 'gbk',           // 文件编码
    // MySQL会自动转换为数据库编码
    showProgress: true
})
```

### 6.3 数据转换选项


**基本数据转换**：
```javascript
util.importTable('/data/products.csv', {
    schema: 'shop',
    table: 'items',
    columns: ['id', 'name', 'price', 'create_date'],
    // 数据类型会自动转换
    // 字符串 → VARCHAR
    // 数字 → DECIMAL/INT  
    // 日期 → DATE/DATETIME
})
```

**处理NULL值**：
```javascript
util.importTable('/data/incomplete_data.csv', {
    schema: 'mydb',
    table: 'records', 
    fieldsTerminatedBy: ',',
    fieldsEnclosedBy: '"',
    // 空字符串会转换为NULL（如果字段允许NULL）
})
```

### 6.4 常见编码问题解决


**解决编码问题的步骤**：

```
1. 确认文件编码
   - Windows记事本另存为时可看到编码
   - Linux用 file -i filename 命令查看

2. 确认数据库编码  
   - SHOW VARIABLES LIKE 'character_set%';

3. 在导入时明确指定编码
   - characterSet参数设置正确

4. 如果还有问题，考虑预处理文件
   - 用工具转换文件编码后再导入
```

---

## 7. 📁 大文件处理策略


### 7.1 大文件处理挑战


**大文件导入的常见问题**：
```
问题类型：
┌─────────────────┬─────────────────┬─────────────────┐
│    内存不足      │    处理超时      │    进度不明      │
├─────────────────┼─────────────────┼─────────────────┤
│ 文件太大内存      │ 单次操作时间     │ 不知道处理到     │
│ 装不下          │ 太长被中断       │ 哪里了          │
└─────────────────┴─────────────────┴─────────────────┘
```

### 7.2 分块处理机制


**MySQL Shell的分块策略**：
```javascript
util.importTable('/data/huge_file.csv', {
    schema: 'bigdata',
    table: 'transactions',
    bytesPerChunk: '100M',         // 每次处理100MB
    threads: 4,                    // 4个线程并行
    maxRate: '50M',               // 限制速率，不影响其他操作
    showProgress: true            // 显示详细进度
})
```

**分块处理原理**：
```
大文件(1GB) 分块处理示意：
┌─────────────────────────────────────────────┐
│ 原始文件 1GB                                 │
└─────────────────────────────────────────────┘
              ↓ 分块
┌──────┬──────┬──────┬──────┬──────┬──────┐
│ 块1  │ 块2  │ 块3  │ 块4  │ 块5  │ 块6  │
│100MB │100MB │100MB │100MB │100MB │100MB │
└──────┴──────┴──────┴──────┴──────┴──────┘
              ↓ 并行处理
       [线程1] [线程2] [线程3] [线程4]
              ↓ 合并到数据库
┌─────────────────────────────────────────────┐
│ MySQL表中的完整数据                          │
└─────────────────────────────────────────────┘
```

### 7.3 大文件导入最佳实践


**推荐配置**：
```javascript
// 超大文件(>1GB)导入配置
util.importTable('/data/massive_data.csv', {
    schema: 'warehouse',
    table: 'big_table',
    
    // 分块设置
    bytesPerChunk: '200M',         // 大块提高效率
    threads: 8,                    // 充分利用CPU
    
    // 速率控制
    maxRate: '100M',              // 避免影响生产环境
    
    // 错误处理
    skipRows: 1,                  // 跳过标题
    showProgress: true,           // 必须显示进度
    
    // 编码设置
    characterSet: 'utf8mb4'
})
```

### 7.4 内存使用优化


**内存使用控制**：
```javascript
// 控制内存使用的配置
util.importTable('/data/big_file.csv', {
    schema: 'mydb',
    table: 'large_table',
    
    bytesPerChunk: '50M',          // 较小的块减少内存占用
    threads: 4,                    // 适中的线程数
    
    // 避免一次性加载太多数据到内存
})
```

**监控内存使用**：
- 在MySQL Shell中可以看到当前内存使用情况
- 如果内存不足，减小`bytesPerChunk`值
- 如果处理很慢，适当增大块大小

---

## 8. ⚠️ 错误处理与性能优化


### 8.1 错误处理策略


**三种错误处理模式**：

```javascript
// 1. 严格模式 - 遇错即停（默认）
util.importTable('/data/data.csv', {
    schema: 'mydb',
    table: 'users'
    // 遇到任何错误立即停止，适合数据质量要求高的场景
})

// 2. 容错模式 - 跳过错误行
util.importTable('/data/data.csv', {
    schema: 'mydb', 
    table: 'users',
    skipRows: 1,
    maxRate: '50M',
    // 会跳过有问题的行，继续处理后面的数据
})

// 3. 替换模式 - 遇到重复就替换
util.importTable('/data/data.csv', {
    schema: 'mydb',
    table: 'users', 
    replaceDuplicates: true        // 重复数据直接替换
})
```

### 8.2 常见错误类型及解决


**数据类型错误**：
```javascript
// 问题：CSV中的数字格式和数据库不匹配
// 解决：预处理数据或调整表结构

util.importTable('/data/numbers.csv', {
    schema: 'mydb',
    table: 'statistics',
    columns: ['id', 'value', 'percentage'],
    // 确保CSV中的数字格式正确
    // 例如：123.45 而不是 "123,45"
})
```

**字符长度超限**：
```javascript
// 问题：CSV中的文本超过数据库字段长度
// 解决方法1：扩大数据库字段长度
// ALTER TABLE users MODIFY COLUMN name VARCHAR(500);

// 解决方法2：在导入前截断数据
// 这需要预处理CSV文件
```

### 8.3 性能优化参数


**关键性能参数对比**：

| 参数 | **作用** | **推荐值** | **注意事项** |
|------|----------|-----------|-------------|
| `threads` | `并行线程数` | `CPU核心数` | `过多会降低效率` |
| `bytesPerChunk` | `数据块大小` | `50-200M` | `内存够用的情况下越大越好` |
| `maxRate` | `速率限制` | `不限制或50-100M` | `生产环境建议限制` |

**高性能导入配置示例**：
```javascript
util.importTable('/data/performance_test.csv', {
    schema: 'speedtest',
    table: 'large_data',
    
    // 性能优化设置
    threads: 8,                    // 8线程并行
    bytesPerChunk: '100M',         // 大数据块
    
    // 数据库优化
    skipRows: 1,                  // 跳过标题行
    fieldsTerminatedBy: '\t',     // TSV格式更快
    
    // 监控设置
    showProgress: true            // 显示进度便于监控
})
```

### 8.4 性能监控指标


**导入过程中的关键指标**：
```
监控指标：
┌─────────────────┬─────────────────┬─────────────────┐
│   处理速度       │    内存使用      │    错误统计      │
├─────────────────┼─────────────────┼─────────────────┤
│ 每秒处理行数     │ 当前内存占用     │ 错误行数量       │
│ 每秒处理字节     │ 最大内存占用     │ 错误类型分布     │
│ 剩余处理时间     │ 内存使用趋势     │ 跳过行数量       │
└─────────────────┴─────────────────┴─────────────────┘
```

---

## 9. 📊 进度监控与实战应用


### 9.1 进度监控功能


**进度显示效果**：
```
Importing from file '/data/large_file.csv' to table `mydb`.`users` 
in MySQL Server at localhost:3306

[################] 67%
Records imported: 670000/1000000
Time elapsed: 00:02:34, ETA: 00:01:15
Speed: 4321 rows/sec, 12.5 MB/sec
Errors: 0, Warnings: 3
```

**进度监控配置**：
```javascript
util.importTable('/data/monitor_test.csv', {
    schema: 'mydb',
    table: 'test_data',
    showProgress: true,            // 启用进度显示
    threads: 4,
    bytesPerChunk: '50M'
})
```

### 9.2 实际应用场景


**场景1：日志数据导入**：
```javascript
// 每日导入Web服务器日志
util.importTable('/logs/access_log_2024-09-11.csv', {
    schema: 'analytics',
    table: 'access_logs',
    
    columns: ['timestamp', 'ip', 'method', 'url', 'status', 'size'],
    skipRows: 1,                  // 跳过CSV标题
    fieldsTerminatedBy: ',',
    
    // 日志文件通常很大，使用并行处理
    threads: 6,
    bytesPerChunk: '100M',
    showProgress: true
})
```

**场景2：数据迁移**：
```javascript
// 从旧系统迁移用户数据
util.importTable('/migration/old_users.csv', {
    schema: 'new_system',
    table: 'users',
    
    columns: ['old_id', 'username', 'email', 'created_at'],
    replaceDuplicates: false,     // 不替换重复数据
    skipRows: 1,
    
    // 迁移要求数据完整性，使用严格模式
    showProgress: true
})
```

### 9.3 数据导出实战


**场景1：报表数据导出**：
```javascript
// 导出月度销售报表
util.exportTable('sales.orders', '/reports/monthly_sales_2024-09.csv', {
    where: "order_date >= '2024-09-01' AND order_date < '2024-10-01'",
    columns: ['order_id', 'customer_name', 'product_name', 'amount', 'order_date'],
    orderBy: 'order_date DESC',
    
    fieldsTerminatedBy: ',',
    fieldsEnclosedBy: '"',
    showProgress: true
})
```

**场景2：数据备份导出**：
```javascript
// 导出重要表数据作为备份
util.exportTable('production.customers', '/backup/customers_backup.tsv', {
    fieldsTerminatedBy: '\t',     // TSV格式，适合大数据量
    maxRate: '20M',              // 限制速率，不影响生产
    showProgress: true
})
```

### 9.4 自动化脚本示例


**批量导入脚本**：
```javascript
// 批量导入多个文件的JavaScript脚本示例
const files = [
    '/data/users_2024_01.csv',
    '/data/users_2024_02.csv', 
    '/data/users_2024_03.csv'
]

files.forEach(file => {
    print(`开始导入文件: ${file}`)
    
    util.importTable(file, {
        schema: 'yearly_data',
        table: 'users',
        
        skipRows: 1,
        threads: 4,
        showProgress: true,
        
        // 追加模式，不覆盖已有数据
        replaceDuplicates: false
    })
    
    print(`完成导入文件: ${file}`)
})
```

---

## 10. 📋 核心要点总结


### 10.1 必须掌握的核心概念


```
🔸 导入导出工具：util.importTable()和util.exportTable()是核心工具
🔸 数据格式支持：CSV、TSV、JSON等多种格式，CSV最常用
🔸 并行处理：通过threads参数实现并行，大幅提升处理速度
🔸 字符编码：characterSet参数解决中文乱码问题
🔸 大文件处理：bytesPerChunk分块处理，避免内存不足
🔸 错误处理：支持严格、容错、替换三种错误处理策略
🔸 进度监控：showProgress参数提供实时处理进度
```

### 10.2 关键理解要点


**🔹 并行处理的本质**：
```
核心原理：把大文件分成小块，多个线程同时处理不同的块
关键参数：threads（线程数）、bytesPerChunk（块大小）
性能提升：通常可以提升3-8倍的处理速度
```

**🔹 字符编码的重要性**：
```
问题表现：中文显示为乱码符号
解决方法：设置正确的characterSet参数
推荐编码：utf8mb4（支持所有字符包括emoji）
```

**🔹 错误处理策略选择**：
```
严格模式：数据质量要求高，遇错即停
容错模式：允许部分数据有问题，跳过继续处理
替换模式：处理重复数据，直接替换
```

### 10.3 实际应用指导


**参数配置建议**：

| 数据量 | **推荐配置** | **适用场景** |
|-------|-------------|-------------|
| `< 100MB` | `threads: 2-4, bytesPerChunk: 10M` | `小型数据导入` |
| `100MB-1GB` | `threads: 4-8, bytesPerChunk: 50M` | `中型数据处理` |
| `> 1GB` | `threads: 8+, bytesPerChunk: 100M+` | `大数据量处理` |

**常用命令模板**：
```javascript
// 标准CSV导入模板
util.importTable('文件路径', {
    schema: '数据库名',
    table: '表名',
    skipRows: 1,                  // 跳过标题行
    fieldsTerminatedBy: ',',      // CSV逗号分隔
    fieldsEnclosedBy: '"',        // 双引号包围
    characterSet: 'utf8mb4',      // 支持中文
    threads: 4,                   // 并行处理
    showProgress: true            // 显示进度
})

// 标准数据导出模板
util.exportTable('数据库.表名', '输出文件路径', {
    fieldsTerminatedBy: ',',
    fieldsEnclosedBy: '"',
    showProgress: true
})
```

### 10.4 故障排查指南


**常见问题及解决方案**：

| 问题现象 | **可能原因** | **解决方法** |
|---------|-------------|-------------|
| `中文乱码` | `字符编码不匹配` | `设置characterSet参数` |
| `导入很慢` | `未使用并行处理` | `增加threads参数` |
| `内存不足` | `数据块太大` | `减小bytesPerChunk值` |
| `数据重复` | `未设置重复处理策略` | `使用replaceDuplicates参数` |
| `导入中断` | `数据格式错误` | `检查CSV格式，设置错误处理策略` |

**核心记忆要点**：
- MySQL Shell导入导出比传统方法快很多，支持并行处理
- CSV是最常用格式，注意字符编码和分隔符设置
- 大文件用分块+并行处理，小文件用简单配置
- 错误处理策略要根据业务需求选择
- 进度监控帮助了解处理状态，便于优化调整