---
title: 13、慢查询分析工具使用实战
---
## 📚 目录

1. [慢查询分析工具概述](#1-慢查询分析工具概述)
2. [mysqldumpslow工具详解](#2-mysqldumpslow工具详解)
3. [pt-query-digest深度分析](#3-pt-query-digest深度分析)
4. [mysqlsla分析工具](#4-mysqlsla分析工具)
5. [分析报告解读技巧](#5-分析报告解读技巧)
6. [批量分析与自动化](#6-批量分析与自动化)
7. [实战案例演示](#7-实战案例演示)
8. [核心要点总结](#8-核心要点总结)

---

## 1. 🎯 慢查询分析工具概述


### 1.1 为什么需要分析工具


**手工分析的困难**：
```
慢查询日志原始格式：
# Time: 2025-09-11T15:30:45.123456Z
# User@Host: app_user[app_user] @  [192.168.1.100]
# Thread_id: 12345  Schema: ecommerce
# Query_time: 5.123456  Lock_time: 0.000789  Rows_sent: 150  Rows_examined: 50000
SELECT o.*, u.name, u.email FROM orders o 
LEFT JOIN users u ON o.user_id = u.id 
WHERE o.create_time >= '2025-01-01' 
ORDER BY o.create_time DESC LIMIT 50;

问题：
❌ 格式复杂，人工读取困难
❌ 数据量大，无法手工统计
❌ 查询模式难以识别
❌ 无法快速找到性能瓶颈
```

**分析工具的价值**：
- 🎯 **快速定位**：找出最耗时的查询类型
- 📊 **统计汇总**：按查询模式聚合分析
- 🔍 **深度挖掘**：发现潜在的性能问题
- 📈 **趋势分析**：查看性能变化趋势

### 1.2 主流分析工具对比


| 工具名称 | **优势** | **适用场景** | **学习成本** |
|----------|----------|-------------|-------------|
| 🔧 **mysqldumpslow** | `官方工具，简单易用` | `快速概览，基础分析` | `极低` |
| ⚡ **pt-query-digest** | `功能强大，报告详细` | `深度分析，生产环境` | `中等` |
| 📊 **mysqlsla** | `图形化界面，直观` | `可视化展示，演示` | `中等` |
| 🎨 **第三方工具** | `集成化，自动化` | `企业级监控` | `较高` |

---

## 2. 🔧 mysqldumpslow工具详解


### 2.1 工具基本介绍


**mysqldumpslow是什么**：MySQL官方提供的慢查询日志分析工具
- 💡 **核心功能**：将相似的SQL语句归类，统计执行次数和时间
- ⚡ **特点**：简单直接，快速出结果
- 📦 **安装**：随MySQL自带，无需额外安装

### 2.2 基本使用语法


**命令格式**：
```bash
mysqldumpslow [选项] [日志文件...]

# 最简单的用法
mysqldumpslow /var/log/mysql/slow.log

# 查看帮助
mysqldumpslow --help
```

### 2.3 常用参数详解


**🔸 排序相关参数**
```bash
# 按查询时间排序（默认）
mysqldumpslow -s t slow.log

# 按平均查询时间排序
mysqldumpslow -s at slow.log

# 按查询次数排序
mysqldumpslow -s c slow.log

# 按锁等待时间排序
mysqldumpslow -s l slow.log

排序选项说明：
├─ t: 按总查询时间排序
├─ at: 按平均查询时间排序  
├─ c: 按查询次数排序
├─ l: 按锁等待时间排序
├─ al: 按平均锁等待时间排序
└─ r: 反向排序
```

**🔸 输出控制参数**
```bash
# 只显示前10条记录
mysqldumpslow -t 10 slow.log

# 详细输出模式
mysqldumpslow -v slow.log

# 调试模式
mysqldumpslow -d slow.log

# 不要将数字抽象化
mysqldumpslow -n slow.log
```

**🔸 过滤相关参数**
```bash
# 只显示查询次数>=5的记录
mysqldumpslow -g "Count: [5-9]" slow.log

# 过滤包含特定表名的查询
mysqldumpslow -g "users" slow.log

# 排除某些查询
mysqldumpslow --grep="SELECT.*users" slow.log
```

### 2.4 实际使用示例


**🔸 基础分析示例**
```bash
# 查看最慢的10个查询
mysqldumpslow -s t -t 10 /var/log/mysql/slow.log

输出示例：
Count: 25  Time=5.12s (128s)  Lock=0.00s (0s)  Rows=150.0 (3750), app_user[app_user]@[192.168.1.100]
  SELECT o.*, u.name, u.email FROM orders o LEFT JOIN users u ON o.user_id = u.id WHERE o.create_time >= 'S' ORDER BY o.create_time DESC LIMIT N

解读说明：
├─ Count: 25 → 这种查询模式出现了25次
├─ Time=5.12s (128s) → 平均耗时5.12秒，总耗时128秒
├─ Lock=0.00s (0s) → 平均锁等待0秒，总锁等待0秒
├─ Rows=150.0 (3750) → 平均返回150行，总共返回3750行
└─ 'S'和N → 字符串和数字被抽象化处理
```

**🔸 高级分析技巧**
```bash
# 组合多个选项
mysqldumpslow -s at -t 20 -g "users" slow.log

# 分析特定时间段的日志
mysqldumpslow -s t -t 10 slow-$(date +%Y%m%d).log

# 将结果保存到文件
mysqldumpslow -s t -t 50 slow.log > slow_analysis.txt
```

### 2.5 mysqldumpslow的局限性


**主要限制**：
```
功能限制：
❌ 无法显示具体的执行时间
❌ 不能按用户或数据库分组
❌ 报告格式比较简单
❌ 无法生成图表或可视化

适用建议：
✅ 快速初步分析时使用
✅ 脚本化批量处理
✅ 简单的TOP查询识别
❌ 不适合深度性能分析
```

---

## 3. ⚡ pt-query-digest深度分析


### 3.1 工具介绍与安装


**pt-query-digest是什么**：Percona Toolkit中的强大查询分析工具
- 🎯 **核心优势**：功能强大，报告详细，可定制性强
- 📊 **特色功能**：查询指纹识别，执行统计，性能分析
- 🔧 **安装方式**：
```bash
# CentOS/RHEL安装
yum install percona-toolkit

# Ubuntu/Debian安装  
apt-get install percona-toolkit

# 验证安装
pt-query-digest --version
```

### 3.2 基本使用方法


**🔸 简单分析示例**
```bash
# 分析慢查询日志
pt-query-digest /var/log/mysql/slow.log

# 分析指定时间范围
pt-query-digest --since='2025-09-10 00:00:00' \
                --until='2025-09-11 00:00:00' \
                /var/log/mysql/slow.log

# 输出到HTML格式
pt-query-digest --output html /var/log/mysql/slow.log > report.html
```

### 3.3 详细参数配置


**🔸 时间筛选参数**
```bash
# 时间范围筛选
pt-query-digest \
  --since='2025-09-10 08:00:00' \
  --until='2025-09-10 18:00:00' \
  slow.log

# 相对时间筛选
pt-query-digest --since='-1d' slow.log    # 最近1天
pt-query-digest --since='-6h' slow.log    # 最近6小时
```

**🔸 过滤和排序参数**
```bash
# 按查询时间排序，只显示前20个
pt-query-digest --order-by Query_time:sum --limit 20 slow.log

# 过滤特定数据库
pt-query-digest --filter '$event->{db} eq "ecommerce"' slow.log

# 过滤特定用户
pt-query-digest --filter '$event->{user} eq "app_user"' slow.log

# 排除某些查询类型
pt-query-digest --ignore-command Query slow.log
```

**🔸 输出定制参数**
```bash
# 详细模式输出
pt-query-digest --report-format=profile,query_report,prepared slow.log

# 自定义输出字段
pt-query-digest --group-by fingerprint \
                --order-by Query_time:sum \
                --limit 10 \
                slow.log
```

### 3.4 分析报告详解


**🔸 报告结构说明**
```
pt-query-digest 报告包含三部分：

1. 整体统计摘要（Overall Stats）
┌─────────────────────────────────┐
│ Total: 1.2k QPS, 0.76 conc     │
│ Time range: 2025-09-10 to ..   │
│ Unique queries: 45              │
│ Total time: 2.5ks               │
└─────────────────────────────────┘

2. 查询排行榜（Top Queries）
┌─────────────────────────────────┐
│ Rank Query ID    Response time  │
│   1  0x123...    30.5s  42.1%  │
│   2  0x456...    15.2s  21.0%  │
│   3  0x789...    12.8s  17.7%  │
└─────────────────────────────────┘

3. 查询详细分析（Query Details）
每个查询的详细统计信息
```

**🔸 关键指标解读**
```bash
# Query 1: 0.89 QPS, 0.32x concurrency, ID 0xABCD1234 at byte 0
# This item is included in the report because it matches --limit.
# Scores: V/M = 0.89
# Time range: 2025-09-10T08:00:00 to 2025-09-10T18:00:00
# Attribute    pct   total     min     max     avg     95%  stddev  median
# ============ === ======= ======= ======= ======= ======= ======= =======
# Count         10     125       1       1       1       1       0       1
# Exec time     42    35.2s   120ms     2.1s   281ms   895ms   324ms   201ms
# Lock time      8   12.5ms      0    1.2ms   100μs   298μs   150μs    45μs
# Rows sent     15   2.01k       0     125    16.1    98.4   29.45    8.75
# Rows examine  85  125.5k      0   5.12k   1.00k   4.58k   1.89k   542.6

关键指标说明：
├─ QPS: 每秒查询次数
├─ concurrency: 并发度
├─ pct: 占总体的百分比
├─ total: 总计值
├─ avg: 平均值
├─ 95%: 95分位数
└─ stddev: 标准差
```

### 3.5 高级功能使用


**🔸 查询指纹分析**
```bash
# 显示查询指纹
pt-query-digest --print --no-report slow.log

输出示例：
# Query fingerprint
# Time: 2025-09-10T10:30:45
# User: app_user
# Schema: ecommerce
# Query: SELECT o.*, u.name FROM orders o LEFT JOIN users u ON o.user_id = u.id WHERE o.create_time >= ? ORDER BY o.create_time DESC LIMIT ?

查询指纹作用：
├─ 将相似查询归类统计
├─ 忽略具体参数值差异  
├─ 识别查询模式
└─ 便于性能优化
```

**🔸 实时监控模式**
```bash
# 监控processlist
pt-query-digest --processlist h=localhost,u=root,p=password \
                --interval=5 \
                --run-time=300

# 监控二进制日志
pt-query-digest --type=binlog mysql-bin.000001

# 监控tcpdump数据
tcpdump -s 65535 -x -nn -q -tttt -i any -c 1000 port 3306 > mysql.tcp
pt-query-digest --type=tcpdump mysql.tcp
```

### 3.6 pt-query-digest最佳实践


**🔸 定期分析脚本**
```bash
#!/bin/bash
# 每日慢查询分析脚本

DATE=$(date +%Y%m%d)
SLOW_LOG="/var/log/mysql/slow.log"
REPORT_DIR="/var/reports/mysql"

# 创建报告目录
mkdir -p $REPORT_DIR

# 生成HTML报告
pt-query-digest \
  --since="$(date -d '1 day ago' '+%Y-%m-%d 00:00:00')" \
  --until="$(date '+%Y-%m-%d 00:00:00')" \
  --output=html \
  $SLOW_LOG > $REPORT_DIR/slow_query_$DATE.html

# 生成文本报告  
pt-query-digest \
  --since="$(date -d '1 day ago' '+%Y-%m-%d 00:00:00')" \
  --until="$(date '+%Y-%m-%d 00:00:00')" \
  --limit=20 \
  $SLOW_LOG > $REPORT_DIR/slow_query_$DATE.txt

echo "报告已生成: $REPORT_DIR/slow_query_$DATE.*"
```

---

## 4. 📊 mysqlsla分析工具


### 4.1 工具特点与安装


**mysqlsla简介**：MySQL日志分析工具，支持多种日志格式
- 🎨 **特色**：支持图形化输出，报告格式丰富
- 📊 **优势**：可以分析多种日志类型
- 🔧 **安装**：
```bash
# 下载安装
wget http://hackmysql.com/scripts/mysqlsla-2.03.tar.gz
tar -xzf mysqlsla-2.03.tar.gz
cd mysqlsla-2.03
perl Makefile.PL
make && make install
```

### 4.2 基本使用方法


**🔸 基础分析命令**
```bash
# 分析慢查询日志
mysqlsla -lt slow /var/log/mysql/slow.log

# 分析一般查询日志
mysqlsla -lt general /var/log/mysql/general.log

# 分析二进制日志
mysqlsla -lt binary mysql-bin.000001
```

### 4.3 输出格式定制


**🔸 报告格式选项**
```bash
# 标准报告格式
mysqlsla -lt slow -sort t_sum -top 10 slow.log

# 微秒精度显示
mysqlsla -lt slow -mf slow.log

# 自定义输出字段
mysqlsla -lt slow -sf "+db,user,host" slow.log

输出字段说明：
├─ db: 数据库名
├─ user: 用户名  
├─ host: 主机名
├─ t_sum: 总执行时间
├─ t_avg: 平均执行时间
└─ c_sum: 执行次数
```

**🔸 时间和过滤选项**
```bash
# 时间范围过滤
mysqlsla -lt slow -tf "h=12-14" slow.log     # 12-14点
mysqlsla -lt slow -tf "d=1-15" slow.log      # 1-15号

# 用户过滤
mysqlsla -lt slow -grep "user: app_user" slow.log

# 数据库过滤  
mysqlsla -lt slow -grep "schema: ecommerce" slow.log
```

---

## 5. 🔍 分析报告解读技巧


### 5.1 TOP查询识别方法


**🔸 识别维度分析**
```
性能影响维度：

1. 总执行时间维度
   影响：占用最多的数据库时间
   识别：按 Query_time:sum 排序
   
2. 平均执行时间维度  
   影响：单次查询最慢的类型
   识别：按 Query_time:avg 排序
   
3. 执行频率维度
   影响：执行最频繁的查询
   识别：按 Count 排序
   
4. 影响行数维度
   影响：扫描数据量最大的查询
   识别：按 Rows_examined:sum 排序
```

**🔸 关键指标优先级**
```bash
# 性能优化优先级判断
Priority 1: Query_time:sum > 30% 的查询
Priority 2: Query_time:avg > 5s 的查询  
Priority 3: Count > 1000/hour 的查询
Priority 4: Rows_examined:avg > 10000 的查询

优化收益评估：
总时间占比 × 优化难度系数 = 优化收益指数
```

### 5.2 查询模式聚合分析


**🔸 查询模式分类**
```
常见查询模式：

📊 OLTP类查询（在线事务）
特征：
├─ 查询时间短（<100ms）
├─ 返回行数少（<100行）
├─ 执行频率高（>100次/分钟）
└─ 索引使用良好

📈 OLAP类查询（分析报表）  
特征：
├─ 查询时间长（>1s）
├─ 扫描行数多（>10000行）
├─ 执行频率低（<10次/小时）
└─ 需要大量计算

🔄 批处理查询
特征：
├─ 执行时间很长（>10s）
├─ 影响行数多（>1000行）
├─ 执行频率低（定时任务）
└─ 资源消耗大
```

### 5.3 执行统计信息解读


**🔸 关键统计指标**
```bash
# pt-query-digest 报告中的关键指标

Exec time 分析：
├─ min: 最短执行时间（检查是否有缓存）
├─ max: 最长执行时间（检查是否有异常）
├─ avg: 平均执行时间（主要优化目标）
├─ 95%: 95分位数（用户体验指标）
└─ stddev: 标准差（性能稳定性指标）

Lock time 分析：
├─ 高锁等待 → 表锁冲突问题
├─ 零锁等待 → 查询性能问题  
└─ 不稳定 → 并发冲突问题

Rows examined vs Rows sent：
├─ 比值过大 → 索引效率问题
├─ 比值适中 → 查询相对合理
└─ 比值很小 → 可能存在限制条件
```

### 5.4 异常模式识别


**🔸 性能异常特征**
```
典型异常模式：

⚠️ 全表扫描模式
识别特征：
├─ Rows_examined 很大
├─ Rows_examined/Rows_sent 比值很高
├─ Query_time 与数据量成正比
└─ 缺少有效索引

🔥 热点查询模式  
识别特征：
├─ Count 极高
├─ 单个查询占用大量总时间
├─ 集中在特定时间段
└─ 可能是缓存失效

💥 锁等待模式
识别特征：  
├─ Lock_time 很高
├─ Query_time 中 Lock_time 占比大
├─ 并发执行时性能下降
└─ 涉及写操作较多
```

---

## 6. 🤖 批量分析与自动化


### 6.1 批量分析脚本编写


**🔸 多日志文件批量分析**
```bash
#!/bin/bash
# 批量分析多个慢查询日志文件

SLOW_LOG_DIR="/var/log/mysql"
REPORT_DIR="/var/reports/mysql"
DATE_RANGE=7  # 分析最近7天

# 创建报告目录
mkdir -p $REPORT_DIR

# 批量分析循环
for i in $(seq 0 $((DATE_RANGE-1))); do
    DATE=$(date -d "$i days ago" +%Y%m%d)
    SLOW_LOG="$SLOW_LOG_DIR/slow-$DATE.log"
    
    if [ -f "$SLOW_LOG" ]; then
        echo "分析日志: $SLOW_LOG"
        
        # 使用pt-query-digest分析
        pt-query-digest \
            --limit=20 \
            --output=html \
            "$SLOW_LOG" > "$REPORT_DIR/analysis-$DATE.html"
            
        # 提取TOP 5查询
        pt-query-digest \
            --limit=5 \
            --no-report \
            --print \
            "$SLOW_LOG" > "$REPORT_DIR/top5-$DATE.sql"
    else
        echo "日志文件不存在: $SLOW_LOG"
    fi
done

echo "批量分析完成，报告保存在: $REPORT_DIR"
```

### 6.2 自动化分析流程


**🔸 定时任务配置**
```bash
# 添加到crontab
crontab -e

# 每天凌晨2点分析前一天的慢查询
0 2 * * * /opt/scripts/daily_slow_analysis.sh

# 每周一分析上周的汇总报告
0 3 * * 1 /opt/scripts/weekly_slow_summary.sh

# 每小时检查异常查询
0 * * * * /opt/scripts/realtime_slow_monitor.sh
```

**🔸 自动化监控脚本**
```bash
#!/bin/bash
# 实时慢查询监控脚本

SLOW_LOG="/var/log/mysql/slow.log"
ALERT_THRESHOLD=10    # 告警阈值：10秒
ALERT_EMAIL="dba@company.com"

# 检查最近1小时的慢查询
RECENT_SLOW=$(pt-query-digest \
    --since='-1h' \
    --filter='$event->{Query_time} > $ALERT_THRESHOLD' \
    --no-report \
    --print \
    $SLOW_LOG)

if [ -n "$RECENT_SLOW" ]; then
    # 发送告警邮件
    echo "发现超过${ALERT_THRESHOLD}秒的慢查询:" | mail -s "慢查询告警" $ALERT_EMAIL
    echo "$RECENT_SLOW" | mail -s "慢查询详情" $ALERT_EMAIL
    
    # 记录到告警日志
    echo "$(date): 发现慢查询告警" >> /var/log/mysql/slow_alert.log
fi
```

### 6.3 多维度统计分析


**🔸 按用户维度统计**
```bash
# 按用户统计慢查询
pt-query-digest \
    --group-by user \
    --order-by Query_time:sum \
    /var/log/mysql/slow.log

# 生成用户维度报告
for user in $(pt-query-digest --print --no-report slow.log | grep "^# User:" | awk '{print $3}' | sort -u); do
    echo "=== 用户 $user 的慢查询分析 ==="
    pt-query-digest \
        --filter "\$event->{user} eq '$user'" \
        --limit=10 \
        slow.log
done
```

**🔸 按数据库维度统计**
```bash
# 按数据库统计
pt-query-digest \
    --group-by db \
    --order-by Query_time:sum \
    /var/log/mysql/slow.log

# 按时间段统计
pt-query-digest \
    --group-by ts \
    --order-by ts \
    /var/log/mysql/slow.log
```

---

## 7. 💼 实战案例演示


### 7.1 电商系统慢查询分析


**🔸 场景描述**
```
业务背景：
├─ 电商系统订单查询响应慢
├─ 用户投诉页面加载时间长
├─ 数据库CPU使用率居高不下
└─ 需要快速定位性能瓶颈

数据规模：
├─ orders表：500万条记录
├─ users表：100万条记录  
├─ products表：10万条记录
└─ 日慢查询量：约1000条
```

**🔸 分析步骤演示**
```bash
# 第一步：快速概览
mysqldumpslow -s t -t 10 /var/log/mysql/slow.log

输出摘要：
Count: 156  Time=8.45s (1318s)  Lock=0.01s (2s)  Rows=45.2 (7051), app[app]@[%]
  SELECT o.*, u.name, u.email, p.title FROM orders o 
  LEFT JOIN users u ON o.user_id = u.id 
  LEFT JOIN products p ON o.product_id = p.id 
  WHERE o.status = 'S' AND o.create_time >= 'S' 
  ORDER BY o.create_time DESC LIMIT N

初步结论：订单关联查询是主要瓶颈
```

```bash
# 第二步：详细分析
pt-query-digest --limit=20 /var/log/mysql/slow.log > detailed_analysis.txt

关键发现：
┌─────────────────────────────────────────┐
│ Query 1: 订单列表查询                    │
│ ├─ 执行次数: 156次                      │  
│ ├─ 平均耗时: 8.45秒                     │
│ ├─ 总耗时占比: 42%                      │
│ ├─ 扫描行数: 平均45万行                  │
│ └─ 返回行数: 平均45行                   │
│                                        │
│ 问题分析：                              │
│ ❌ 缺少复合索引                         │
│ ❌ 关联查询效率低                       │  
│ ❌ 排序操作使用临时表                    │
└─────────────────────────────────────────┘
```

**🔸 优化方案制定**
```sql
-- 基于分析结果的优化建议

-- 1. 创建复合索引
CREATE INDEX idx_orders_status_time ON orders(status, create_time);

-- 2. 优化查询语句
-- 原始查询（慢）
SELECT o.*, u.name, u.email, p.title 
FROM orders o 
LEFT JOIN users u ON o.user_id = u.id 
LEFT JOIN products p ON o.product_id = p.id 
WHERE o.status = 'paid' AND o.create_time >= '2025-01-01' 
ORDER BY o.create_time DESC LIMIT 20;

-- 优化后查询（快）
SELECT o.id, o.order_no, o.total, o.create_time,
       u.name, u.email, p.title
FROM orders o FORCE INDEX(idx_orders_status_time)
LEFT JOIN users u ON o.user_id = u.id 
LEFT JOIN products p ON o.product_id = p.id 
WHERE o.status = 'paid' AND o.create_time >= '2025-01-01' 
ORDER BY o.create_time DESC LIMIT 20;
```

### 7.2 优化效果验证


**🔸 优化前后对比**
```bash
# 优化前分析
pt-query-digest --since='2025-09-10 00:00:00' --until='2025-09-10 23:59:59' slow-before.log

# 优化后分析  
pt-query-digest --since='2025-09-11 00:00:00' --until='2025-09-11 23:59:59' slow-after.log

性能对比结果：
┌─────────────────┬─────────────┬─────────────┬─────────────┐
│      指标        │   优化前     │   优化后     │   改善程度   │
├─────────────────┼─────────────┼─────────────┼─────────────┤
│ 平均查询时间      │    8.45s    │    0.23s    │   97% ⬇️   │
│ 最大查询时间      │   15.2s     │    0.89s    │   94% ⬇️   │  
│ 每小时慢查询数    │    156      │     12      │   92% ⬇️   │
│ 扫描行数比例      │  45万/45    │   150/45    │   99% ⬇️   │
└─────────────────┴─────────────┴─────────────┴─────────────┘
```

---

## 8. 📋 核心要点总结


### 8.1 必须掌握的工具使用


```
🔸 工具选择策略：
├─ 快速分析 → mysqldumpslow  
├─ 深度分析 → pt-query-digest
├─ 可视化展示 → mysqlsla
└─ 生产监控 → 自动化脚本

🔸 分析维度掌握：
├─ 时间维度：总时间、平均时间、最大时间
├─ 频率维度：执行次数、每秒查询数  
├─ 资源维度：扫描行数、返回行数、锁等待
└─ 业务维度：用户、数据库、查询类型
```

### 8.2 关键技能要点


**🔹 报告解读能力**
```
核心指标理解：
✅ Query_time:sum → 总体性能影响
✅ Query_time:avg → 单次查询体验
✅ Count → 查询频率和重要性
✅ Rows_examined/Rows_sent → 索引效率
✅ Lock_time → 并发冲突情况

异常识别技巧：
⚠️ 执行时间突然增长 → 数据量增长或索引失效
⚠️ 锁等待时间过长 → 并发冲突或死锁
⚠️ 扫描行数过多 → 缺少合适索引
⚠️ 查询频率异常 → 可能有程序bug
```

**🔹 自动化运维能力**
```
脚本编写要点：
🤖 定时分析：每日、每周、每月报告
🚨 实时监控：超时查询立即告警
📊 趋势分析：性能变化趋势跟踪
📧 报告分发：自动发送给相关人员

监控策略制定：
├─ 告警阈值设置（时间、频率、资源）
├─ 分级响应机制（紧急、重要、一般）
├─ 自动化处理（索引建议、查询重写）
└─ 定期回顾优化（月度、季度总结）
```

### 8.3 最佳实践建议


**🔸 日常分析流程**
```bash
# 标准分析流程
1. 快速概览 → mysqldumpslow -s t -t 10 slow.log
2. 详细分析 → pt-query-digest --limit=20 slow.log  
3. 问题定位 → 分析具体查询指纹和执行计划
4. 优化实施 → 索引优化、查询重写、参数调整
5. 效果验证 → 对比优化前后的分析报告
```

**🔸 工具使用技巧**
```
mysqldumpslow技巧：
├─ 组合使用 -s 和 -t 参数
├─ 使用 -g 进行关键字过滤
├─ 配合 -n 显示具体数字
└─ 结果重定向到文件便于对比

pt-query-digest技巧：  
├─ 灵活使用时间筛选参数
├─ 掌握 --filter 高级过滤语法
├─ 善用 --group-by 进行维度分析
├─ 结合 --output html 生成可视化报告
└─ 配置 --order-by 按需求排序
```

**核心记忆要点**：
- 工具是手段，分析是关键，优化是目标
- 先看整体影响，再看单次性能，最后看执行频率
- 自动化分析是生产环境的必备能力
- 持续监控和定期优化形成闭环管理