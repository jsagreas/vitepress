---
title: 25、主从复制高级配置
---
## 📚 目录

1. [并行复制配置](#1-并行复制配置)
2. [复制信息存储配置](#2-复制信息存储配置)
3. [行搜索与类型转换](#3-行搜索与类型转换)
4. [选择性复制配置](#4-选择性复制配置)
5. [性能优化策略](#5-性能优化策略)
6. [核心要点总结](#6-核心要点总结)

---

## 1. 🚀 并行复制配置


### 1.1 什么是并行复制


**🔸 基本概念**
```
传统复制：一个一个按顺序执行，就像排队买票
并行复制：多个线程同时干活，就像开多个售票窗口

好处：大大提升复制速度，减少主从延迟
前提：保证数据一致性，不能乱了顺序
```

**📊 性能对比示意**
```
传统单线程复制：
主库写入: [事务1] → [事务2] → [事务3] → [事务4]
从库执行: [事务1] → [事务2] → [事务3] → [事务4]  (慢)

并行复制：
主库写入: [事务1] → [事务2] → [事务3] → [事务4]
从库执行: [事务1]   [事务3]
          [事务2]   [事务4]                    (快)
```

### 1.2 并行复制类型配置


**⚙️ slave_parallel_type**
```ini
# 并行复制类型 - 决定怎么分配工作
slave_parallel_type = LOGICAL_CLOCK    # 推荐设置

# 可选值解释：
# DATABASE    - 按数据库分，不同库可以并行
# LOGICAL_CLOCK - 按逻辑时钟分，更智能的并行
```

**💡 通俗理解**
```
DATABASE模式：
就像公司按部门分工，销售部和技术部可以同时干活
但同一个部门内还是要排队

LOGICAL_CLOCK模式：
更聪明的分工方式，系统自动判断哪些事务可以同时执行
不会互相冲突的就并行处理
```

**🧪 实际效果对比**
```
假设有4个事务：
事务A：更新用户表 user_id=1
事务B：更新订单表 order_id=100  
事务C：更新用户表 user_id=2
事务D：插入日志表

DATABASE模式：
- A和C因为都操作user表，必须串行
- B和D可以并行（不同表）

LOGICAL_CLOCK模式：
- A和C虽然同表但不同行，可以并行
- 四个事务都能并行执行
```

### 1.3 并行工作线程配置


**⚙️ slave_parallel_workers**
```ini
# 并行工作线程数 - 同时干活的工人数量
slave_parallel_workers = 4             # 一般设置为CPU核数

# 配置建议：
# CPU 2核  → 设置 2-4
# CPU 4核  → 设置 4-8  
# CPU 8核  → 设置 8-16
```

**📈 线程数选择策略**
```
线程太少：
就像只开1个收银台，顾客排长队
→ 复制速度慢，跟不上主库

线程太多：
就像开100个收银台但只有10个顾客
→ 浪费资源，线程切换开销大

合理设置：
根据CPU核数和实际负载调整
一般是CPU核数的1-2倍
```

### 1.4 提交顺序保持


**⚙️ slave_preserve_commit_order**
```ini
# 保持提交顺序 - 确保事务执行顺序和主库一致
slave_preserve_commit_order = 1        # 开启顺序保持

# 作用说明：
# ON  - 严格按主库顺序提交，保证一致性
# OFF - 允许乱序提交，性能更好但可能不一致
```

**🎯 为什么需要顺序保持**
```
举个例子：
主库执行顺序：
1. 创建用户 user_id=100
2. 为该用户创建订单 user_id=100

如果从库乱序执行：
1. 先执行创建订单 → 失败！用户不存在
2. 再创建用户 → 数据不一致了

开启顺序保持：
确保先创建用户，再创建订单，逻辑正确
```

### 1.5 检查点配置


**⚙️ slave_checkpoint_period**
```ini
# 检查点周期 - 多久保存一次进度
slave_checkpoint_period = 300          # 300毫秒保存一次

# 类比理解：
# 就像玩游戏的自动保存功能
# 300毫秒 = 每0.3秒保存一次复制进度
```

**⚙️ slave_checkpoint_group**
```ini
# 检查点组大小 - 处理多少个事务后保存进度
slave_checkpoint_group = 512           # 处理512个事务后保存

# 平衡考虑：
# 数值小 → 保存频繁，故障恢复快，但性能略低
# 数值大 → 保存少，性能好，但故障恢复慢
```

**📊 检查点工作机制**
```
复制进度保存时机：
时间触发: 每300毫秒保存一次
数量触发: 每处理512个事务保存一次

保存内容：
- 当前复制到哪个位置
- 每个工作线程的状态  
- 待处理的事务队列

故障恢复：
从最近的检查点继续，不用从头开始
```

### 1.6 待处理作业大小


**⚙️ slave_pending_jobs_size_max**
```ini
# 待处理作业队列最大大小
slave_pending_jobs_size_max = 134217728  # 128MB

# 通俗理解：
# 就像工厂的待加工零件仓库
# 128MB = 排队等待处理的事务最多占用128MB内存
```

**⚖️ 大小设置考虑**
```
设置过小：
→ 工作线程经常等待，降低并行效果
→ 就像仓库太小，工人总是没活干

设置过大：  
→ 占用内存多，可能导致内存不足
→ 就像仓库太大，占地方但不一定有用

推荐设置：
根据服务器内存大小调整
内存16GB以上可以设置256MB-512MB
```

---

## 2. 💾 复制信息存储配置


### 2.1 存储方式对比


**📋 两种存储方式**
```
文件存储 (FILE)：
把复制信息保存在文件里
就像用记事本记录工作进度

表存储 (TABLE)：
把复制信息保存在MySQL表里  
就像用Excel表格记录工作进度
```

**🔄 工作机制示意**
```
文件方式：
master.info文件    → 记录主库连接信息
relay-log.info文件 → 记录中继日志位置

表方式：
mysql.slave_master_info表     → 记录主库信息
mysql.slave_relay_log_info表  → 记录中继日志信息
```

### 2.2 主库信息存储配置


**⚙️ master_info_repository**
```ini
# 主库信息存储方式
master_info_repository = TABLE         # 推荐使用表存储

# 可选值：
# FILE  - 文件存储，传统方式
# TABLE - 表存储，现代推荐方式
```

**✅ 表存储的优势**
```
1. 事务安全：
   文件方式：写文件可能一半成功一半失败
   表方式：要么全成功要么全失败，更安全

2. 查询方便：
   可以用SQL查询复制状态
   SELECT * FROM mysql.slave_master_info;

3. 备份一致：
   跟随数据库一起备份，不会丢失

4. 崩溃恢复：
   结合InnoDB事务，恢复更可靠
```

### 2.3 中继日志信息存储


**⚙️ relay_log_info_repository**
```ini
# 中继日志信息存储方式
relay_log_info_repository = TABLE      # 推荐使用表存储

# 对应的表：
# mysql.slave_relay_log_info - 存储中继日志执行位置
```

**🔍 存储内容说明**
```
中继日志信息包含：
- 当前执行到哪个中继日志文件
- 文件中的具体位置
- 对应主库的binlog位置
- 工作线程的分配信息

就像看小说时夹的书签：
记录看到第几页第几行
下次打开直接从这里继续
```

**📊 故障恢复流程**
```
正常情况：
主库 → binlog → 从库relay log → 从库数据

故障发生：
从库宕机，重启后需要知道：
1. 主库同步到哪里了？  (master_info)
2. 中继日志执行到哪了？(relay_log_info)

表存储优势：
信息和数据在同一个事务中
保证一致性，恢复更准确
```

---

## 3. 🔍 行搜索与类型转换


### 3.1 行搜索算法


**⚙️ slave_rows_search_algorithms**
```ini
# 行搜索算法 - 从库如何找到要更新的行
slave_rows_search_algorithms = 'INDEX_SCAN,HASH_SCAN'

# 可选算法：
# TABLE_SCAN - 全表扫描，最慢但最可靠
# INDEX_SCAN - 索引扫描，快速定位
# HASH_SCAN  - 哈希扫描，内存中快速查找
```

**💡 算法选择策略**
```
INDEX_SCAN（索引扫描）：
就像查字典用目录
适合：有主键或唯一索引的表
速度：快
要求：表必须有合适的索引

HASH_SCAN（哈希扫描）：
就像在脑子里记住所有信息快速查找
适合：没有好索引但数据量不大的情况
速度：很快（内存操作）
要求：消耗内存

TABLE_SCAN（全表扫描）：
就像一页一页翻整本书
适合：最后的保底选择
速度：慢
要求：总能找到，但效率低
```

**🚀 性能对比示例**
```
假设要更新一条记录：
UPDATE user SET name='张三' WHERE id=12345;

INDEX_SCAN：
1. 查找主键索引 id=12345
2. 直接定位到对应行
3. 执行更新
时间：毫秒级

HASH_SCAN：
1. 在内存哈希表中查找
2. 快速定位记录
3. 执行更新  
时间：微秒级（如果内存够用）

TABLE_SCAN：
1. 从第一行开始逐行检查
2. 比较每行的id值
3. 找到匹配的行再更新
时间：可能秒级（表很大时）
```

### 3.2 类型转换配置


**⚙️ slave_type_conversions**
```ini
# 数据类型转换规则
slave_type_conversions = 'ALL_LOSSY'

# 可选值：
# ''         - 不允许任何类型转换
# ALL_LOSSY  - 允许可能丢失精度的转换  
# ALL_NON_LOSSY - 只允许无损转换
```

**📊 类型转换场景**
```
主从表结构略有不同时：

主库字段：age INT
从库字段：age TINYINT

数据转换：
主库值 150 → 从库值 127 (TINYINT最大值)
这就是"有损转换"，会丢失精度

无损转换示例：
主库：name VARCHAR(50)  
从库：name VARCHAR(100)
扩大长度，不会丢失数据
```

**⚠️ 类型转换风险**
```
ALL_LOSSY风险：
可能导致数据不一致
例：主库金额 999999.99
    从库金额 999999 (精度丢失)

建议做法：
1. 保持主从表结构完全一致
2. 如必须转换，充分测试
3. 监控转换日志，及时发现问题
```

---

## 4. 🎯 选择性复制配置


### 4.1 通配符复制表


**⚙️ replicate_wild_do_table**
```ini
# 只复制匹配模式的表
replicate_wild_do_table = 'ecommerce.order_%'
replicate_wild_do_table = 'user.user_info'

# 通配符规则：
# % - 匹配任意多个字符
# _ - 匹配单个字符
```

**💡 使用场景示例**
```
电商系统场景：
只想复制订单相关的表：
replicate_wild_do_table = 'shop.order_%'

会复制：
✅ shop.order_main     (订单主表)
✅ shop.order_detail   (订单详情)  
✅ shop.order_log      (订单日志)

不会复制：
❌ shop.user_info      (用户信息)
❌ shop.product_info   (商品信息)

好处：节省存储空间，只同步需要的数据
```

### 4.2 通配符忽略表


**⚙️ replicate_wild_ignore_table**
```ini
# 忽略匹配模式的表
replicate_wild_ignore_table = 'logs.%'
replicate_wild_ignore_table = '%.temp_%'

# 常见忽略场景：
# 日志表、临时表、缓存表等
```

**🚫 忽略表的典型应用**
```
忽略日志表：
replicate_wild_ignore_table = 'system.log_%'

忽略临时表：
replicate_wild_ignore_table = '%.tmp_%'
replicate_wild_ignore_table = '%.temp_%'

忽略测试表：
replicate_wild_ignore_table = '%.test_%'

实际效果：
主库有100张表，只复制重要的80张
节省从库磁盘空间20%
提高复制速度
```

### 4.3 选择性复制策略


**📋 配置组合策略**
```ini
# 策略1：白名单模式（只复制指定的）
replicate_wild_do_table = 'business.%'
replicate_wild_do_table = 'user.%'

# 策略2：黑名单模式（忽略指定的）
replicate_wild_ignore_table = 'logs.%'
replicate_wild_ignore_table = 'temp.%'
replicate_wild_ignore_table = 'cache.%'

# 策略3：混合模式（先包含再排除）
replicate_wild_do_table = 'app.%'
replicate_wild_ignore_table = 'app.log_%'
```

**🎯 选择原则**
```
选择性复制的考虑因素：

数据重要性：
🔴 核心业务数据 → 必须复制
🟡 辅助数据 → 可选复制  
🟢 日志数据 → 通常不复制

存储成本：
从库磁盘空间有限时，优先复制重要数据

网络带宽：
复制表越少，网络传输压力越小

查询需求：
从库用于查询的表才需要复制
```

**⚠️ 配置注意事项**
```
规则冲突处理：
如果同时配置do和ignore，ignore优先级更高

配置验证：
配置后检查 SHOW SLAVE STATUS
确认 Replicate_Wild_Do_Table 和 Replicate_Wild_Ignore_Table 显示正确

测试建议：
先在测试环境验证配置效果
确认数据复制符合预期
```

---

## 5. 🚀 性能优化策略


### 5.1 综合配置示例


**⚙️ 高性能主从复制配置**
```ini
# ===================
# 主从复制优化配置
# ===================

# 并行复制配置
slave_parallel_type = LOGICAL_CLOCK
slave_parallel_workers = 8
slave_preserve_commit_order = 1

# 检查点配置  
slave_checkpoint_period = 300
slave_checkpoint_group = 512
slave_pending_jobs_size_max = 268435456  # 256MB

# 存储方式配置
master_info_repository = TABLE
relay_log_info_repository = TABLE

# 行搜索优化
slave_rows_search_algorithms = 'INDEX_SCAN,HASH_SCAN'

# 类型转换（谨慎使用）
# slave_type_conversions = 'ALL_NON_LOSSY'

# 选择性复制（根据需要配置）
# replicate_wild_do_table = 'business.%'
# replicate_wild_ignore_table = 'logs.%'
```

### 5.2 性能监控指标


**📊 关键监控指标**
```sql
-- 查看主从延迟
SHOW SLAVE STATUS\G

-- 关注这些字段：
-- Seconds_Behind_Master  主从延迟秒数
-- Slave_SQL_Running_State  SQL线程状态
-- Last_SQL_Error         最后SQL错误

-- 查看并行工作线程状态
SELECT * FROM performance_schema.replication_applier_status_by_worker;

-- 查看复制事件统计
SELECT * FROM performance_schema.replication_group_member_stats;
```

**🎯 性能调优建议**
```
延迟过大时：
1. 增加 slave_parallel_workers
2. 检查从库硬件性能（IO/CPU）
3. 优化SQL语句和索引

内存使用过多时：
1. 减少 slave_pending_jobs_size_max
2. 减少 slave_parallel_workers
3. 使用选择性复制减少数据量

复制经常出错时：
1. 检查 slave_rows_search_algorithms 配置
2. 确保主从表结构一致
3. 避免使用类型转换
```

### 5.3 故障排查流程


**🔧 常见问题诊断**
```
问题1：复制延迟很大
排查步骤：
1. SHOW SLAVE STATUS 查看延迟
2. 检查 slave_parallel_workers 设置
3. 查看从库系统负载
4. 检查网络连接质量

问题2：复制经常中断
排查步骤：
1. 查看 Last_SQL_Error 错误信息
2. 检查主从表结构差异
3. 验证 slave_rows_search_algorithms 设置
4. 检查磁盘空间和权限

问题3：内存占用过高
排查步骤：  
1. 调整 slave_pending_jobs_size_max
2. 减少 slave_parallel_workers
3. 使用选择性复制
4. 检查是否有内存泄漏
```

---

## 6. 📋 核心要点总结


### 6.1 必须掌握的核心概念


```
🔸 并行复制：多线程同时处理，提升复制速度
🔸 存储方式：TABLE存储比FILE存储更安全可靠
🔸 行搜索算法：INDEX_SCAN最常用，性能最好
🔸 选择性复制：只复制需要的表，节省资源
🔸 类型转换：尽量避免，保持主从结构一致
```

### 6.2 关键配置建议


**🔹 性能优先配置**
```
推荐配置：
slave_parallel_type = LOGICAL_CLOCK
slave_parallel_workers = CPU核数 × 2
slave_preserve_commit_order = 1
master_info_repository = TABLE
relay_log_info_repository = TABLE
slave_rows_search_algorithms = 'INDEX_SCAN,HASH_SCAN'
```

**🔹 安全优先配置**
```
保守配置：
slave_parallel_workers = CPU核数
slave_preserve_commit_order = 1  
master_info_repository = TABLE
relay_log_info_repository = TABLE
# 不使用类型转换
# 不使用选择性复制（全量复制）
```

### 6.3 实际应用价值


**🎯 业务场景应用**
- **高并发系统**：使用并行复制减少主从延迟
- **大数据量系统**：使用选择性复制节省存储
- **金融系统**：使用表存储确保数据安全
- **读写分离**：优化从库性能支持更多读请求

**🔧 运维实践**
- **监控告警**：设置主从延迟告警阈值
- **定期检查**：检查复制状态和错误日志
- **性能调优**：根据业务负载调整并行线程数
- **故障恢复**：制定主从故障切换方案

**💡 核心记忆口诀**：
- 并行复制提速度，TABLE存储保安全
- 索引扫描最高效，选择复制省资源
- 顺序保持不能丢，监控告警要及时

**🎯 关键理解**：
主从复制高级配置的核心是在**性能**和**安全**之间找平衡，根据业务需求选择合适的配置策略，既要保证数据一致性，又要提升复制效率。