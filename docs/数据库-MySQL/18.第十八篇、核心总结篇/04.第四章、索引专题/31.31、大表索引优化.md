---
title: 31、大表索引优化
---
## 📚 目录

1. [大表索引挑战概述](#1-大表索引挑战概述)
2. [索引创建策略](#2-索引创建策略)
3. [在线索引构建技术](#3-在线索引构建技术)
4. [索引维护与优化](#4-索引维护与优化)
5. [分批处理技术](#5-分批处理技术)
6. [索引空间管理](#6-索引空间管理)
7. [索引性能监控](#7-索引性能监控)
8. [高级优化策略](#8-高级优化策略)
9. [核心要点总结](#9-核心要点总结)

---

## 1. 🏔️ 大表索引挑战概述


### 1.1 什么是大表索引挑战


**📖 核心概念**
> **大表**：通常指数据量超过千万级别（10M+）或存储空间超过几个GB的表  
> **索引挑战**：在大表上创建、维护索引时遇到的性能、空间、时间等问题

**💡 生活类比**
想象你要为一个拥有1000万本书的图书馆建立索引卡片系统：
```
小图书馆（1000本书）：
- 建索引：1小时完成 ✅
- 查找书籍：几分钟找到 ✅
- 维护索引：每天更新 ✅

超大图书馆（1000万本书）：
- 建索引：可能需要几天几夜 ❌
- 占用空间：索引卡片堆积如山 ❌  
- 维护索引：每次更新都很费时 ❌
```

### 1.2 大表索引的典型问题


**⚠️ 主要挑战**

```
🔥 **创建时间过长**
问题：千万级数据创建索引可能耗时数小时
影响：阻塞业务操作，影响系统可用性
现实例子：用户表2000万记录，创建索引需要3小时

💾 **存储空间压力**  
问题：索引可能占用与数据同等甚至更多的空间
影响：服务器存储资源紧张
现实例子：100GB的表，索引可能需要80GB空间

⚡ **维护性能下降**
问题：INSERT/UPDATE/DELETE操作变慢
影响：实时业务响应时间增加
现实例子：原本1秒的插入操作变成10秒
```

### 1.3 大表的判断标准


**📊 大表识别指标**

| 类型 | **判断标准** | **典型特征** | **常见场景** |
|------|-------------|-------------|-------------|
| 🔢 **数据量型** | `> 1000万行` | 查询扫描行数多 | 用户行为日志 |
| 💾 **存储型** | `> 10GB` | 物理空间占用大 | 文件存储表 |
| 📈 **增长型** | `日增长>10万行` | 持续快速增长 | 交易流水表 |
| 🔍 **查询型** | `查询耗时>5秒` | 业务查询慢 | 统计分析表 |

**🎯 实际判断方法**
```sql
-- 查看表的基本信息
SELECT 
    table_name,
    table_rows,                    -- 行数（估算值）
    ROUND(data_length/1024/1024/1024, 2) as data_gb,    -- 数据大小GB
    ROUND(index_length/1024/1024/1024, 2) as index_gb   -- 索引大小GB
FROM information_schema.tables 
WHERE table_schema = 'your_database'
ORDER BY data_length DESC;
```

---

## 2. 🛠️ 索引创建策略


### 2.1 创建前的评估与规划


**📋 创建前评估清单**

```
✅ **业务影响评估**
- 预估创建时间窗口
- 确认可接受的业务中断时间
- 评估对并发查询的影响

✅ **资源需求评估**  
- 计算所需的额外存储空间
- 评估CPU和内存使用量
- 确认I/O负载能力

✅ **索引必要性评估**
- 分析查询频率和重要性
- 评估性能提升预期
- 考虑索引维护成本
```

**🔍 索引选择原则**

```
🎯 **优先级排序**
1. 高频查询的WHERE条件字段
2. JOIN操作的关联字段  
3. ORDER BY排序字段
4. GROUP BY分组字段

📊 **选择性分析**
-- 计算字段选择性（值越接近1越适合建索引）
SELECT 
    COUNT(DISTINCT column_name) / COUNT(*) as selectivity
FROM table_name;

💡 **经验法则**
- 选择性 > 0.1：适合建立索引
- 选择性 < 0.01：不建议单独建索引
- 可考虑组合索引提高选择性
```

### 2.2 渐进式索引创建策略


**🎯 分阶段创建方案**

```
阶段1: 核心业务索引（必需）
├── 主键索引（已存在）
├── 核心查询索引（1-2个）
└── 外键索引（如果使用外键）

阶段2: 高频查询索引（重要）  
├── 常用WHERE条件索引
├── 排序字段索引
└── 分组查询索引

阶段3: 辅助优化索引（可选）
├── 覆盖索引
├── 部分索引
└── 函数索引
```

**⏰ 时间窗口选择**
```
🌙 **业务低峰期**
- 凌晨2:00-6:00（典型选择）
- 周末或节假日
- 业务维护窗口期

📅 **分批创建计划**
第1天：创建最核心的1个索引
第2天：观察影响，创建第2个索引
第3天：继续创建，循序渐进
```

### 2.3 索引创建语法优化


**🔧 基础创建语法**
```sql
-- 标准创建方式
CREATE INDEX idx_user_email ON users(email);

-- 指定索引算法（推荐BTREE）
CREATE INDEX idx_user_status 
ON users(status) 
USING BTREE;

-- 创建组合索引（注意字段顺序）
CREATE INDEX idx_user_status_createtime 
ON users(status, create_time);
```

**⚡ 性能优化参数**
```sql
-- 设置创建索引时的参数
SET SESSION sort_buffer_size = 256*1024*1024;    -- 增大排序缓冲区
SET SESSION read_buffer_size = 2*1024*1024;      -- 增大读缓冲区

-- 创建索引
CREATE INDEX idx_order_date ON orders(order_date);

-- 恢复默认设置
SET SESSION sort_buffer_size = DEFAULT;
SET SESSION read_buffer_size = DEFAULT;
```

---

## 3. 🚀 在线索引构建技术


### 3.1 MySQL在线DDL机制


**📖 核心概念**
> **在线DDL（Online DDL）**：允许在不阻塞并发DML操作（INSERT、UPDATE、DELETE）的情况下执行DDL操作（如创建索引）

**💡 工作原理简化理解**
```
传统方式（会锁表）：
用户访问 ──❌阻塞──> 数据库表（正在创建索引）

在线DDL方式：
用户访问 ──✅正常──> 数据库表
              ↓
          临时记录变更 ──> 索引构建完成后合并
```

### 3.2 在线索引创建语法


**🛠️ ALGORITHM 参数说明**

```sql
-- INPLACE算法（推荐，真正的在线操作）
CREATE INDEX idx_user_phone 
ON users(phone) 
ALGORITHM=INPLACE, 
LOCK=NONE;

-- COPY算法（会锁表，避免使用）  
CREATE INDEX idx_user_name 
ON users(name) 
ALGORITHM=COPY;

-- 让MySQL自动选择最优算法
CREATE INDEX idx_user_age 
ON users(age) 
ALGORITHM=DEFAULT;
```

**🔒 LOCK 参数详解**

| 锁类型 | **说明** | **影响** | **适用场景** |
|--------|---------|---------|-------------|
| `NONE` | `无锁，允许并发读写` | 最小影响 | 生产环境首选 |
| `SHARED` | `共享锁，允许读，阻塞写` | 中等影响 | 读多写少场景 |
| `EXCLUSIVE` | `排他锁，阻塞所有操作` | 最大影响 | 维护窗口期 |

**🎯 实际使用示例**
```sql
-- 生产环境推荐写法
CREATE INDEX idx_order_status_time 
ON orders(status, create_time) 
ALGORITHM=INPLACE, 
LOCK=NONE,
COMMENT='订单状态和时间复合索引';
```

### 3.3 在线索引构建监控


**📊 进度监控查询**
```sql
-- 查看正在执行的DDL操作
SELECT 
    id,
    user,
    host,
    db,
    command,
    time,
    state,
    info
FROM information_schema.processlist 
WHERE command = 'Query' 
  AND info LIKE '%CREATE INDEX%';

-- 查看索引创建进度（MySQL 8.0+）
SELECT 
    event_name,
    work_completed,
    work_estimated,
    ROUND(work_completed/work_estimated*100, 2) as progress_percent
FROM performance_schema.events_stages_current
WHERE event_name LIKE '%index%';
```

**⚠️ 监控关键指标**
```
🔍 **系统资源监控**
- CPU使用率：创建索引时CPU会升高
- 内存使用：sort_buffer_size影响内存占用
- 磁盘I/O：大量读写操作

📈 **数据库性能监控**  
- 并发连接数：确保不影响正常业务
- 查询响应时间：监控是否有性能下降
- 锁等待情况：避免出现锁竞争
```

---

## 4. 🔧 索引维护与优化


### 4.1 索引碎片问题


**📖 核心概念**
> **索引碎片**：由于大量INSERT/UPDATE/DELETE操作，导致索引页面利用率下降，影响查询性能

**💡 类比理解**
```
整齐的书架（无碎片）：
书架A: [书1][书2][书3][书4][书5] ← 查找快速
书架B: [书6][书7][书8][书9][书10]

有碎片的书架（有碎片）：  
书架A: [书1][空][书3][空][书5] ← 查找变慢，浪费空间
书架B: [书6][空][空][书9][空]
```

**🔍 碎片检测方法**
```sql
-- 检查表和索引的碎片情况
SELECT 
    table_name,
    index_name,
    ROUND(stat_value/1024/1024, 2) as size_mb,
    CASE 
        WHEN stat_name = 'n_leaf_pages' THEN '叶子页数'
        WHEN stat_name = 'size' THEN '索引大小'
    END as stat_description
FROM mysql.innodb_index_stats 
WHERE table_name = 'your_table_name'
  AND stat_name IN ('n_leaf_pages', 'size');

-- 简单的碎片率估算
SHOW TABLE STATUS LIKE 'your_table_name'\G
-- 查看 Data_free 字段，表示碎片空间
```

### 4.2 索引重建与优化


**🛠️ 索引重建方法**

```sql
-- 方法1: 删除重建（会影响查询性能）
DROP INDEX idx_user_email ON users;
CREATE INDEX idx_user_email ON users(email);

-- 方法2: 优化表（推荐，会重建所有索引）
OPTIMIZE TABLE users;

-- 方法3: ALTER TABLE重建（MySQL 5.6+推荐）
ALTER TABLE users ENGINE=InnoDB;
```

**⏰ 重建时机选择**
```
📊 **重建触发条件**
- 表碎片率 > 30%
- 查询性能明显下降
- 定期维护（如每月一次）

🌙 **执行时间选择**
- 业务低峰期（凌晨时段）
- 数据库维护窗口
- 读写分离的从库优先
```

### 4.3 索引维护自动化


**🤖 自动化维护脚本**
```bash
#!/bin/bash
# 索引维护自动化脚本

# 数据库连接信息
DB_HOST="localhost"
DB_USER="maintenance_user"
DB_PASS="password"
DB_NAME="your_database"

# 检查大表碎片率
mysql -h$DB_HOST -u$DB_USER -p$DB_PASS $DB_NAME -e "
SELECT 
    table_name,
    ROUND(data_free/data_length*100, 2) as fragment_percent
FROM information_schema.tables 
WHERE table_schema = '$DB_NAME' 
  AND data_length > 1024*1024*1024  -- 大于1GB的表
  AND data_free/data_length > 0.3   -- 碎片率>30%
"

# 如果碎片率高，执行优化（在低峰期）
current_hour=$(date +%H)
if [ $current_hour -ge 2 ] && [ $current_hour -le 6 ]; then
    echo "开始优化表..."
    # 这里添加具体的优化命令
fi
```

---

## 5. 📦 分批处理技术


### 5.1 为什么需要分批处理


**💡 问题场景**
```
一次性处理大量数据的问题：
- 处理1亿条记录的UPDATE操作
- 内存使用过高，可能导致OOM
- 长时间锁定资源，影响其他操作
- 回滚日志过大，恢复困难

分批处理的好处：
- 减少内存压力
- 降低锁竞争  
- 便于监控进度
- 出错时影响范围可控
```

### 5.2 分批创建索引策略


**🎯 大表索引分批创建方案**

```sql
-- 方案1: 按主键范围分批创建
-- 第一步：创建临时索引（部分数据）
CREATE INDEX idx_temp_user_email 
ON users(email) 
WHERE id BETWEEN 1 AND 1000000;

-- 第二步：逐步扩展范围
-- （注意：这种方法在实际中较少使用，因为索引不支持部分创建）

-- 方案2: 使用分区表策略（推荐）
-- 为每个分区单独创建索引
ALTER TABLE orders_2024 ADD INDEX idx_order_date (order_date);
ALTER TABLE orders_2023 ADD INDEX idx_order_date (order_date);
```

**🔄 分批处理数据更新**
```sql
-- 分批更新示例：为历史数据添加索引辅助字段
DELIMITER $$
CREATE PROCEDURE batch_update_index_field()
BEGIN
    DECLARE done INT DEFAULT FALSE;
    DECLARE batch_size INT DEFAULT 10000;
    DECLARE current_id BIGINT DEFAULT 0;
    DECLARE max_id BIGINT;
    
    -- 获取最大ID
    SELECT MAX(id) INTO max_id FROM large_table;
    
    -- 分批处理循环
    WHILE current_id < max_id DO
        -- 更新一批数据
        UPDATE large_table 
        SET index_helper_field = CONCAT(field1, '_', field2)
        WHERE id > current_id 
          AND id <= current_id + batch_size;
        
        -- 移动到下一批
        SET current_id = current_id + batch_size;
        
        -- 短暂休息，减少系统压力
        SELECT SLEEP(0.1);
        
        -- 提交事务
        COMMIT;
    END WHILE;
END$$
DELIMITER ;

-- 执行分批处理
CALL batch_update_index_field();
```

### 5.3 分批处理监控与控制


**📊 进度监控**
```sql
-- 创建进度监控表
CREATE TABLE batch_process_log (
    id INT AUTO_INCREMENT PRIMARY KEY,
    process_name VARCHAR(100),
    current_batch INT,
    total_batches INT,
    start_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    last_update TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    status ENUM('running', 'completed', 'error') DEFAULT 'running'
);

-- 在处理过程中记录进度
INSERT INTO batch_process_log (process_name, current_batch, total_batches) 
VALUES ('large_table_index_creation', 1, 100);
```

---

## 6. 💾 索引空间管理


### 6.1 索引空间占用分析


**🔍 空间使用查询**
```sql
-- 查看数据库中所有表的索引空间占用
SELECT 
    table_schema as '数据库',
    table_name as '表名',
    ROUND(data_length/1024/1024/1024, 2) as '数据大小(GB)',
    ROUND(index_length/1024/1024/1024, 2) as '索引大小(GB)',
    ROUND(index_length/data_length*100, 2) as '索引比例(%)',
    table_rows as '估算行数'
FROM information_schema.tables 
WHERE table_schema NOT IN ('mysql', 'information_schema', 'performance_schema', 'sys')
  AND table_type = 'BASE TABLE'
ORDER BY index_length DESC;
```

**📊 索引大小预估公式**
```
🧮 **B+树索引大小估算**
基本公式：索引大小 ≈ 行数 × (索引字段长度 + 指针长度)

实际例子：
- 1000万行数据
- INT类型字段索引：4字节 + 6字节指针 = 10字节
- 预估索引大小：10,000,000 × 10 ≈ 95MB

💡 **组合索引大小**
组合索引大小 = 行数 × (所有字段长度之和 + 指针长度)

例如：(status INT, create_time DATETIME)
索引大小 ≈ 1000万 × (4 + 8 + 6) = 171MB
```

### 6.2 索引空间优化策略


**🎯 减少索引空间占用的方法**

```sql
-- 1. 使用前缀索引（减少字符串索引空间）
-- 原始索引（可能很大）
CREATE INDEX idx_user_email ON users(email);

-- 前缀索引（节省空间）
CREATE INDEX idx_user_email_prefix ON users(email(10));

-- 检验前缀长度的选择性
SELECT 
    COUNT(DISTINCT email) as full_selectivity,
    COUNT(DISTINCT LEFT(email, 10)) as prefix_selectivity,
    COUNT(DISTINCT LEFT(email, 10)) / COUNT(DISTINCT email) as ratio
FROM users;
```

**🔧 索引类型选择优化**
```sql
-- 2. 选择合适的数据类型
-- 避免：使用VARCHAR(255)存储状态
status VARCHAR(255)  -- 浪费空间

-- 推荐：使用ENUM或TINYINT
status ENUM('active', 'inactive', 'pending')  -- 节省空间
-- 或者
status TINYINT  -- 1字节，配合注释说明含义

-- 3. 避免过长的组合索引
-- 避免：包含太多字段的组合索引
CREATE INDEX idx_too_long ON users(name, email, phone, address, created_at);

-- 推荐：根据查询需求创建合理的组合索引
CREATE INDEX idx_user_search ON users(status, created_at);
```

### 6.3 索引空间清理策略


**🗑️ 无用索引清理**
```sql
-- 查找重复索引
SELECT 
    table_schema,
    table_name,
    index_name,
    column_name,
    seq_in_index
FROM information_schema.statistics 
WHERE table_schema = 'your_database'
ORDER BY table_name, index_name, seq_in_index;

-- 查找从未使用的索引（MySQL 8.0+）
SELECT 
    object_schema,
    object_name,
    index_name,
    count_star,
    count_read,
    count_fetch
FROM performance_schema.table_io_waits_summary_by_index_usage
WHERE index_name IS NOT NULL
  AND count_star = 0
  AND count_read = 0 
  AND count_fetch = 0;
```

---

## 7. 📈 索引性能监控


### 7.1 索引使用情况监控


**🔍 监控索引是否被使用**
```sql
-- 启用索引使用统计（如果未开启）
UPDATE performance_schema.setup_instruments 
SET enabled = 'YES' 
WHERE name LIKE '%table%';

-- 查看索引使用频率
SELECT 
    object_schema as 数据库,
    object_name as 表名,
    index_name as 索引名,
    count_fetch as 使用次数,
    count_insert as 插入次数,
    count_update as 更新次数,
    count_delete as 删除次数
FROM performance_schema.table_io_waits_summary_by_index_usage
WHERE object_schema = 'your_database'
  AND index_name IS NOT NULL
ORDER BY count_fetch DESC;
```

**📊 查询执行计划分析**
```sql
-- 使用EXPLAIN分析查询是否使用了索引
EXPLAIN FORMAT=JSON 
SELECT * FROM users 
WHERE email = 'user@example.com' 
  AND status = 'active';

-- 关键指标解读：
-- type: 连接类型（const > eq_ref > ref > range > index > ALL）
-- key: 实际使用的索引
-- rows: 扫描的行数
-- filtered: 过滤后的行数百分比
```

### 7.2 索引性能指标监控


**⚡ 关键性能指标**

```sql
-- 1. 查询响应时间统计
SELECT 
    schema_name,
    digest_text,
    count_star as 执行次数,
    ROUND(avg_timer_wait/1000000000, 3) as 平均响应时间_秒,
    ROUND(max_timer_wait/1000000000, 3) as 最大响应时间_秒
FROM performance_schema.events_statements_summary_by_digest
WHERE schema_name = 'your_database'
ORDER BY avg_timer_wait DESC
LIMIT 10;

-- 2. 索引扫描效率
SELECT 
    table_schema,
    table_name,
    index_name,
    ROUND(count_read/count_fetch, 2) as 扫描效率比
FROM performance_schema.table_io_waits_summary_by_index_usage
WHERE object_schema = 'your_database'
  AND count_fetch > 0
ORDER BY 扫描效率比 DESC;
```

**📋 监控告警设置**
```bash
# 监控脚本示例
#!/bin/bash
# 索引性能监控脚本

DB_HOST="localhost"
DB_USER="monitor_user"  
DB_PASS="password"
DB_NAME="your_database"

# 检查慢查询
slow_queries=$(mysql -h$DB_HOST -u$DB_USER -p$DB_PASS -e "
SELECT COUNT(*) FROM mysql.slow_log 
WHERE start_time > DATE_SUB(NOW(), INTERVAL 1 HOUR)
" -s -N)

if [ $slow_queries -gt 100 ]; then
    echo "警告：最近1小时慢查询数量：$slow_queries"
    # 发送告警通知
fi

# 检查索引使用率
unused_indexes=$(mysql -h$DB_HOST -u$DB_USER -p$DB_PASS $DB_NAME -e "
SELECT COUNT(*) FROM performance_schema.table_io_waits_summary_by_index_usage
WHERE object_schema = '$DB_NAME' 
  AND index_name IS NOT NULL 
  AND count_fetch = 0
" -s -N)

if [ $unused_indexes -gt 5 ]; then
    echo "提醒：发现 $unused_indexes 个未使用的索引"
fi
```

---

## 8. 🚀 高级优化策略


### 8.1 索引压缩技术


**📖 核心概念**
> **索引压缩**：通过压缩算法减少索引的存储空间，但可能增加CPU开销

**🔧 InnoDB压缩表**
```sql
-- 创建压缩表（适用于大表）
CREATE TABLE large_log_compressed (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    user_id INT,
    action VARCHAR(100),
    log_data TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_user_action (user_id, action)
) ENGINE=InnoDB 
  ROW_FORMAT=COMPRESSED 
  KEY_BLOCK_SIZE=8;

-- 查看压缩效果
SELECT 
    table_name,
    ROUND(data_length/1024/1024, 2) as data_mb,
    ROUND(index_length/1024/1024, 2) as index_mb,
    ROUND((data_length + index_length)/1024/1024, 2) as total_mb
FROM information_schema.tables 
WHERE table_name IN ('large_log', 'large_log_compressed');
```

**💡 压缩效果评估**
```
🎯 **适合压缩的场景**
- 历史数据表（读多写少）
- 日志记录表
- 归档数据表

⚠️ **不适合压缩的场景**  
- 频繁更新的表
- CPU资源紧张的环境
- 对查询延迟敏感的业务
```

### 8.2 索引分区策略


**📖 核心概念**
> **分区索引**：将大表按照某种规则分割成多个较小的分区，每个分区可以独立管理索引

**🗓️ 时间分区示例**
```sql
-- 创建按月分区的订单表
CREATE TABLE orders_partitioned (
    id BIGINT AUTO_INCREMENT,
    user_id INT,
    order_amount DECIMAL(10,2),
    order_date DATE,
    status ENUM('pending', 'paid', 'shipped', 'completed'),
    
    PRIMARY KEY (id, order_date),  -- 分区键必须包含在主键中
    INDEX idx_user_status (user_id, status),
    INDEX idx_order_date (order_date)
) ENGINE=InnoDB
PARTITION BY RANGE (YEAR(order_date) * 100 + MONTH(order_date)) (
    PARTITION p202301 VALUES LESS THAN (202302),
    PARTITION p202302 VALUES LESS THAN (202303),
    PARTITION p202303 VALUES LESS THAN (202304),
    -- ... 更多分区
    PARTITION p202412 VALUES LESS THAN (202413),
    PARTITION p_future VALUES LESS THAN MAXVALUE
);
```

**🎯 分区优势**
```
✅ **查询优化**
- 分区裁剪：只扫描相关分区
- 并行处理：多个分区可并行查询
- 索引更小：每个分区的索引更小更快

✅ **维护优化**
- 独立维护：可以单独优化某个分区
- 快速删除：删除整个分区而不是逐行删除
- 灵活备份：可以按分区进行备份
```

### 8.3 历史数据处理策略


**📊 历史数据索引优化**

```sql
-- 1. 冷热数据分离
-- 热数据表（最近3个月）
CREATE TABLE orders_hot AS 
SELECT * FROM orders 
WHERE order_date >= DATE_SUB(NOW(), INTERVAL 3 MONTH);

-- 冷数据表（3个月以前）
CREATE TABLE orders_cold AS 
SELECT * FROM orders 
WHERE order_date < DATE_SUB(NOW(), INTERVAL 3 MONTH);

-- 2. 为冷数据创建不同的索引策略
-- 热数据：创建全量索引（查询频繁）
ALTER TABLE orders_hot ADD INDEX idx_user_status_date (user_id, status, order_date);
ALTER TABLE orders_hot ADD INDEX idx_amount_date (order_amount, order_date);

-- 冷数据：只创建必要索引（主要用于统计分析）
ALTER TABLE orders_cold ADD INDEX idx_date_amount (order_date, order_amount);
```

**🗑️ 自动化历史数据清理**
```sql
-- 创建历史数据清理存储过程
DELIMITER $$
CREATE PROCEDURE cleanup_old_data()
BEGIN
    DECLARE done INT DEFAULT FALSE;
    DECLARE partition_name VARCHAR(64);
    
    -- 删除6个月前的分区
    DECLARE cur CURSOR FOR 
        SELECT partition_name 
        FROM information_schema.partitions 
        WHERE table_name = 'orders_partitioned'
          AND partition_description < DATE_FORMAT(DATE_SUB(NOW(), INTERVAL 6 MONTH), '%Y%m');
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    OPEN cur;
    read_loop: LOOP
        FETCH cur INTO partition_name;
        IF done THEN
            LEAVE read_loop;
        END IF;
        
        -- 删除分区
        SET @sql = CONCAT('ALTER TABLE orders_partitioned DROP PARTITION ', partition_name);
        PREPARE stmt FROM @sql;
        EXECUTE stmt;
        DEALLOCATE PREPARE stmt;
        
    END LOOP;
    CLOSE cur;
END$$
DELIMITER ;

-- 设置定时任务执行清理
-- 在crontab中添加：
-- 0 2 1 * * mysql -u user -p password -e "CALL cleanup_old_data();"
```

---

## 9. 📋 核心要点总结


### 9.1 必须掌握的核心概念


```
🔸 **大表定义**：千万级数据或GB级存储的表
🔸 **在线DDL**：不阻塞业务的索引创建技术  
🔸 **分批处理**：将大任务分解为小批次执行
🔸 **索引监控**：持续监控索引使用情况和性能
🔸 **空间管理**：合理控制索引占用的存储空间
```

### 9.2 关键实践要点


**🎯 索引创建最佳实践**
```
规划先行：
- 评估业务影响和资源需求
- 选择合适的时间窗口
- 制定分阶段创建计划

技术选择：
- 优先使用ALGORITHM=INPLACE
- 设置LOCK=NONE保证业务连续性
- 充分利用MySQL的在线DDL特性

监控保障：
- 实时监控创建进度
- 关注系统资源使用情况  
- 建立异常情况的应急预案
```

**⚡ 性能优化关键点**
```
索引设计：
- 基于实际查询需求创建索引
- 避免过多的冗余索引
- 合理使用组合索引

维护策略：
- 定期检查和清理无用索引
- 监控索引碎片率并及时整理
- 建立自动化维护机制

空间控制：
- 使用前缀索引减少空间占用
- 考虑索引压缩技术
- 实施冷热数据分离
```

### 9.3 实际应用指导


**📊 大表索引决策流程**
```
步骤1: 问题识别
├── 查询性能是否下降？
├── 索引空间是否过大？
└── 维护成本是否过高？

步骤2: 方案评估  
├── 评估索引的必要性
├── 计算预期性能提升
└── 评估实施风险和成本

步骤3: 实施执行
├── 选择合适的时间窗口
├── 使用在线DDL技术
└── 分批次逐步实施

步骤4: 效果验证
├── 监控查询性能改善
├── 检查资源使用情况
└── 评估业务影响
```

**🚀 性能优化检查清单**
```
✅ **创建前检查**
- [ ] 确认索引的必要性
- [ ] 评估对系统的影响
- [ ] 准备回滚方案

✅ **创建中监控**
- [ ] 监控系统资源使用
- [ ] 检查业务正常运行
- [ ] 记录创建进度

✅ **创建后验证**
- [ ] 验证查询性能提升
- [ ] 检查索引使用情况
- [ ] 监控长期稳定性
```

**🧠 记忆要点**
- **规划为先**：充分评估，制定方案
- **在线优先**：使用ALGORITHM=INPLACE，LOCK=NONE
- **分批执行**：大任务分解，循序渐进
- **持续监控**：关注性能，及时调整
- **空间控制**：合理设计，避免浪费

**核心记忆口诀**：
> 大表索引需规划，在线创建不阻塞  
> 分批处理降风险，监控维护保性能  
> 空间管理要精细，冷热分离提效率