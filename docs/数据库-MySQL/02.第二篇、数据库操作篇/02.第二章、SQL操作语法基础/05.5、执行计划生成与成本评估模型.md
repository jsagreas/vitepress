---
title: 5、执行计划生成与成本评估模型
---
## 📚 目录

1. [执行计划成本模型基础](#1-执行计划成本模型基础)
2. [页面访问成本评估](#2-页面访问成本评估)
3. [CPU处理成本计算](#3-CPU处理成本计算)
4. [I/O成本评估机制](#4-IO成本评估机制)
5. [统计信息对成本评估的影响](#5-统计信息对成本评估的影响)
6. [成本模型参数调优](#6-成本模型参数调优)
7. [执行计划选择过程](#7-执行计划选择过程)
8. [核心要点总结](#8-核心要点总结)

---

## 1. 🎯 执行计划成本模型基础


### 1.1 什么是成本模型


**🔸 成本模型的本质**
MySQL的成本模型是一套**数学计算系统**，用来预估执行一个SQL查询需要消耗多少资源。就像你去超市买东西前会估算要花多少钱一样，MySQL在执行查询前也会"算账"，看看哪种执行方式最"便宜"。

```
成本模型的作用：
┌─────────────────┐    计算成本    ┌─────────────────┐
│  SQL查询语句    │ ────────────▶ │  多种执行方案    │
└─────────────────┘               └─────────────────┘
                                         │
                                         ▼
                                  ┌─────────────────┐
                                  │  选择最低成本    │
                                  │    的方案       │
                                  └─────────────────┘
```

**💡 成本的组成部分**
成本主要由两大部分组成：
- **I/O成本**：读取数据页的时间消耗（磁盘读写）
- **CPU成本**：处理数据的时间消耗（比较、排序等）

### 1.2 成本计算的基本原理


**⚡ 成本计算公式**
```
总成本 = I/O成本 + CPU成本

其中：
I/O成本 = 需要读取的数据页数量 × 每页I/O成本
CPU成本 = 需要处理的记录数量 × 每条记录CPU成本
```

**🔢 默认成本常数（MySQL 8.0）**
```
基础成本参数：
- 随机页面读取成本：1.0
- 顺序页面读取成本：0.25  
- 处理一条记录的CPU成本：0.1
- 比较一次的CPU成本：0.05
- 创建临时表的成本：1.0
```

### 1.3 成本模型的演进历史


**📈 MySQL成本模型发展**
```
MySQL版本演进：

MySQL 5.6及之前
├─ 简单的启发式规则
├─ 固定的成本参数
├─ 缺乏精确的成本计算
└─ 优化器选择有时不准确

MySQL 5.7
├─ 引入可配置的成本模型
├─ 区分存储引擎的成本差异  
├─ 支持成本参数调优
└─ 优化器决策更加精确

MySQL 8.0+
├─ 直方图统计信息支持
├─ 改进的成本计算算法
├─ 更准确的cardinality估算
└─ 机器学习辅助优化
```

---

## 2. 📄 页面访问成本评估


### 2.1 数据页访问类型


**📊 页面访问模式分类**
```
页面访问模式：

随机访问（Random Access）
┌─────┐    ┌─────┐    ┌─────┐    ┌─────┐
│页面A│    │页面C│    │页面X│    │页面M│
└─────┘    └─────┘    └─────┘    └─────┘
   ↑          ↑          ↑          ↑
   └──────────┼──────────┼──────────┘
             随机跳跃访问

特点：
• 磁盘寻道时间长
• 每次访问都需要定位
• 成本高，默认成本系数：1.0

顺序访问（Sequential Access）  
┌─────┐ ┌─────┐ ┌─────┐ ┌─────┐ ┌─────┐
│页面1│ │页面2│ │页面3│ │页面4│ │页面5│
└─────┘ └─────┘ └─────┘ └─────┘ └─────┘
   └─────┴─────┴─────┴─────┘
        连续顺序访问

特点：
• 磁盘寻道时间短
• 可以预读多个页面
• 成本低，默认成本系数：0.25
```

### 2.2 页面成本计算详解


**🔸 不同扫描方式的页面成本**
```
全表扫描（Table Scan）：
┌─────────────────────────────────┐
│ 表总页面数：1000                │
│ 访问方式：顺序读取              │
│ I/O成本 = 1000 × 0.25 = 250    │
└─────────────────────────────────┘

索引范围扫描（Index Range Scan）：
┌─────────────────────────────────┐
│ 索引页面数：50                  │
│ 数据页面数：200（随机访问）     │
│ I/O成本 = 50×0.25 + 200×1.0    │
│         = 12.5 + 200 = 212.5    │
└─────────────────────────────────┘

索引全扫描（Index Full Scan）：
┌─────────────────────────────────┐
│ 索引页面数：100                 │
│ 访问方式：顺序读取              │
│ I/O成本 = 100 × 0.25 = 25      │
└─────────────────────────────────┘
```

### 2.3 页面缓存对成本的影响


**🚀 缓冲池命中率影响**
```
缓存命中场景分析：

冷数据访问（Cache Miss）
┌─────────────┐    磁盘I/O    ┌─────────────┐
│  查询请求   │ ────────────▶ │   磁盘存储   │
└─────────────┘    成本：1.0   └─────────────┘

热数据访问（Cache Hit）
┌─────────────┐   内存访问    ┌─────────────┐
│  查询请求   │ ────────────▶ │  Buffer Pool │
└─────────────┘   成本：0.1    └─────────────┘

实际成本计算：
实际I/O成本 = 理论I/O成本 × (1 - 缓存命中率) + 
              理论I/O成本 × 缓存命中率 × 0.1

示例：
假设缓存命中率80%，理论I/O成本100
实际成本 = 100 × (1-0.8) + 100 × 0.8 × 0.1
        = 100 × 0.2 + 100 × 0.08
        = 20 + 8 = 28
```

---

## 3. 🖥️ CPU处理成本计算


### 3.1 CPU成本的构成


**⚡ CPU处理操作类型**
```
CPU成本分解：

记录处理成本
├─ 读取记录：0.1 成本单位/记录
├─ 记录比较：0.05 成本单位/次
├─ 记录排序：0.1 成本单位/记录
└─ 记录连接：0.1 成本单位/记录

条件评估成本
├─ 简单条件（=, >, <）：0.05
├─ 复杂条件（LIKE, IN）：0.1  
├─ 函数计算：0.1-0.5
└─ 正则表达式：0.5-1.0

数据转换成本
├─ 类型转换：0.05
├─ 字符集转换：0.1
├─ 日期格式化：0.1
└─ 数学运算：0.05
```

### 3.2 不同操作的CPU成本分析


**📊 典型查询操作的CPU成本**

| 操作类型 | **单位成本** | **影响因素** | **优化建议** |
|---------|-------------|-------------|-------------|
| **WHERE条件过滤** | `0.05/记录` | 条件复杂度、数据类型 | 使用索引减少扫描记录数 |
| **ORDER BY排序** | `0.1/记录` | 排序字段数、记录大小 | 利用索引避免排序 |
| **GROUP BY分组** | `0.1/记录` | 分组字段数、组数量 | 使用覆盖索引 |
| **JOIN连接** | `0.1/记录对` | 连接方式、数据量 | 选择合适的连接算法 |
| **子查询处理** | `0.2/记录` | 子查询复杂度 | 转换为JOIN操作 |

### 3.3 复杂查询的CPU成本计算


**🔧 实际计算示例**
```sql
-- 示例查询
SELECT u.name, COUNT(o.id)
FROM users u 
JOIN orders o ON u.id = o.user_id
WHERE u.age > 25 
GROUP BY u.name
ORDER BY COUNT(o.id) DESC;
```

**💭 成本分析过程**
```
CPU成本详细分解：

1. 扫描users表
   └─ 100,000条记录 × 0.1 = 10,000

2. 年龄条件过滤  
   └─ 100,000条记录 × 0.05 = 5,000

3. 扫描orders表
   └─ 500,000条记录 × 0.1 = 50,000

4. JOIN连接操作
   └─ 80,000 × 500,000 × 0.1 = 4,000,000,000
   （使用Hash Join优化后实际为：200,000）

5. GROUP BY分组  
   └─ 200,000条记录 × 0.1 = 20,000

6. COUNT聚合计算
   └─ 50,000个分组 × 0.05 = 2,500

7. ORDER BY排序
   └─ 50,000条记录 × 0.1 = 5,000

总CPU成本：约 292,500 成本单位
```

---

## 4. 💾 I/O成本评估机制


### 4.1 存储引擎差异


**🔧 不同存储引擎的I/O特点**
```
InnoDB存储引擎：
┌─────────────────────────────────┐
│ 页面大小：16KB                   │
│ 缓存机制：Buffer Pool           │
│ 读取特点：                       │
│ • 聚集索引：数据和索引一起存储   │
│ • 随机读：1.0成本              │
│ • 顺序读：0.25成本             │
│ • 预读：可连续读取多个页面      │
└─────────────────────────────────┘

MyISAM存储引擎：
┌─────────────────────────────────┐
│ 页面大小：1KB-64KB可配置        │
│ 缓存机制：Key Cache (仅索引)    │
│ 读取特点：                       │
│ • 索引和数据分离存储            │
│ • 数据文件顺序访问成本低        │
│ • 索引文件随机访问              │
└─────────────────────────────────┘

Memory存储引擎：
┌─────────────────────────────────┐
│ 存储位置：完全在内存中          │
│ I/O成本：接近0                  │
│ 访问速度：极快                  │
│ 限制：数据易丢失               │
└─────────────────────────────────┘
```

### 4.2 I/O成本计算公式


**📐 精确的I/O成本计算**
```
I/O成本计算公式：

基础公式：
I/O_Cost = Pages_Random × Cost_Random + 
           Pages_Sequential × Cost_Sequential

扩展公式（考虑缓存）：
I/O_Cost = (Pages_Random × Cost_Random × Miss_Rate) +
           (Pages_Sequential × Cost_Sequential × Miss_Rate) +
           (Total_Pages × Hit_Rate × Memory_Access_Cost)

其中：
- Pages_Random：需要随机访问的页面数
- Pages_Sequential：需要顺序访问的页面数  
- Cost_Random：随机访问成本系数（默认1.0）
- Cost_Sequential：顺序访问成本系数（默认0.25）
- Miss_Rate：缓存未命中率
- Hit_Rate：缓存命中率
- Memory_Access_Cost：内存访问成本（默认0.1）
```

### 4.3 不同查询类型的I/O成本


**📊 查询类型与I/O成本对比**
```
查询类型成本分析：

全表扫描：
表大小：100万记录，10000个页面
I/O成本 = 10000 × 0.25 = 2500
适用：小表或需要大部分数据

主键查询：
索引层级：3层
I/O成本 = 3 × 1.0 + 1 × 1.0 = 4  
适用：精确匹配查询

范围查询：
索引页面：50个（顺序）
数据页面：500个（随机）
I/O成本 = 50 × 0.25 + 500 × 1.0 = 512.5
适用：范围条件查询

索引覆盖查询：
索引页面：200个（顺序）
数据页面：0个（无需访问）
I/O成本 = 200 × 0.25 = 50
适用：所需字段都在索引中
```

---

## 5. 📈 统计信息对成本评估的影响


### 5.1 统计信息的作用


**🔍 统计信息是什么**
统计信息是MySQL收集的**关于表和索引的数据特征**，就像是给数据做"体检报告"。这些信息帮助优化器更准确地估算查询成本。

```
统计信息包含的内容：

表级统计信息
├─ 表的总记录数
├─ 表的总页面数
├─ 平均行长度
└─ 数据文件大小

索引级统计信息  
├─ 索引的唯一值数量（Cardinality）
├─ 索引的深度（B+树层数）
├─ 索引页面数量
└─ 索引选择性

列级统计信息
├─ 列值的分布情况
├─ NULL值数量
├─ 最小值和最大值
└─ 直方图分布（MySQL 8.0+）
```

### 5.2 Cardinality对成本评估的影响


**🎯 Cardinality的重要性**
Cardinality（基数）表示某个索引列的**唯一值数量**，它直接影响优化器对查询结果集大小的估算。

```sql
-- 查看索引的Cardinality信息
SHOW INDEX FROM users;

-- 示例输出解读：
-- Table: users, Column: age, Cardinality: 50
-- 意思：age列大概有50个不同的值
-- 
-- Table: users, Column: email, Cardinality: 95000  
-- 意思：email列大概有95000个不同的值（接近总记录数）
```

**📊 Cardinality对查询选择的影响**
```
场景分析：用户表100,000条记录

高选择性索引（email）：
┌─────────────────────────────────┐
│ Cardinality: 95,000             │
│ 选择性 = 95,000/100,000 = 0.95  │
│                                 │
│ 查询：WHERE email = 'xxx'       │
│ 预期结果：1-2条记录            │
│ 成本评估：索引查找成本低        │
│ 优化器选择：使用索引           │
└─────────────────────────────────┘

低选择性索引（gender）：
┌─────────────────────────────────┐
│ Cardinality: 2 (男/女)          │
│ 选择性 = 2/100,000 = 0.00002   │
│                                 │
│ 查询：WHERE gender = '男'       │
│ 预期结果：50,000条记录         │
│ 成本评估：索引查找 + 回表成本高 │
│ 优化器选择：全表扫描           │
└─────────────────────────────────┘
```

### 5.3 直方图统计信息（MySQL 8.0+）


**📊 直方图的价值**
直方图提供了**数据分布的详细信息**，让优化器能更准确地估算查询结果。

```sql
-- 创建直方图
ANALYZE TABLE users UPDATE HISTOGRAM ON age WITH 100 BUCKETS;

-- 查看直方图信息  
SELECT * FROM INFORMATION_SCHEMA.COLUMN_STATISTICS 
WHERE TABLE_NAME = 'users' AND COLUMN_NAME = 'age';
```

**🔸 直方图改善成本估算的例子**
```
没有直方图的情况：
查询：SELECT * FROM users WHERE age BETWEEN 25 AND 30;
优化器假设：数据均匀分布
估算结果：(30-25)/(最大值-最小值) × 总记录数
        = 5/80 × 100,000 = 6,250条

有直方图的情况：
查询：同样的范围查询
优化器参考：直方图显示25-30岁占总数的12%
估算结果：100,000 × 0.12 = 12,000条
实际结果：11,800条（更准确！）

影响：
- 更准确的成本评估
- 更合理的执行计划选择
- 更好的查询性能
```

### 5.4 统计信息更新策略


**🔄 统计信息何时需要更新**
```
自动更新触发条件：
├─ 表数据变化超过10%
├─ 新增/删除大量数据后
├─ 表结构变更后
└─ 索引创建/删除后

手动更新时机：
├─ 查询性能突然下降
├─ 执行计划不合理
├─ 数据分布发生重大变化
└─ 定期维护时

更新命令：
-- 更新表统计信息
ANALYZE TABLE table_name;

-- 更新特定索引统计信息
ANALYZE TABLE table_name UPDATE HISTOGRAM ON column_name WITH 100 BUCKETS;

-- 查看统计信息更新时间
SELECT TABLE_NAME, UPDATE_TIME 
FROM INFORMATION_SCHEMA.TABLES 
WHERE TABLE_SCHEMA = 'your_database';
```

---

## 6. ⚙️ 成本模型参数调优


### 6.1 可调优的成本参数


**🔧 MySQL成本模型参数表**
```sql
-- 查看当前成本模型配置
SELECT * FROM mysql.server_cost;
SELECT * FROM mysql.engine_cost;
```

**📊 主要成本参数说明**

| 参数名称 | **默认值** | **含义** | **调优建议** |
|---------|-----------|----------|-------------|
| **disk_temptable_create_cost** | `20.0` | 创建磁盘临时表成本 | SSD环境可适当降低 |
| **disk_temptable_row_cost** | `0.5` | 磁盘临时表行处理成本 | 内存充足时可降低 |
| **key_compare_cost** | `0.05` | 索引比较成本 | CPU性能强可降低 |
| **memory_temptable_create_cost** | `1.0` | 内存临时表创建成本 | 通常不需要调整 |
| **memory_temptable_row_cost** | `0.1` | 内存临时表行处理成本 | 可根据内存性能调整 |
| **row_evaluate_cost** | `0.1` | 行评估成本 | 通用参数，慎重调整 |

### 6.2 存储引擎特定成本参数


**🔸 InnoDB引擎成本参数**
```sql
-- InnoDB特定成本参数
SELECT * FROM mysql.engine_cost WHERE engine_name = 'InnoDB';

-- 主要参数：
-- io_block_read_cost: 1.0    (随机页面读取成本)
-- memory_block_read_cost: 0.25 (内存页面读取成本)  
```

### 6.3 成本参数调优实例


**⚡ 针对SSD环境的优化**
```sql
-- 针对SSD存储的成本优化
-- SSD随机访问性能比机械硬盘好，可以降低随机I/O成本

UPDATE mysql.engine_cost 
SET cost_value = 0.8 
WHERE engine_name = 'InnoDB' 
  AND cost_name = 'io_block_read_cost';

-- 刷新成本模型缓存
FLUSH OPTIMIZER_COSTS;
```

**🚀 针对高内存环境的优化**
```sql
-- 高内存环境，缓存命中率高
UPDATE mysql.engine_cost 
SET cost_value = 0.15
WHERE engine_name = 'InnoDB' 
  AND cost_name = 'memory_block_read_cost';

-- 降低临时表成本，鼓励使用内存临时表
UPDATE mysql.server_cost 
SET cost_value = 0.5
WHERE cost_name = 'disk_temptable_create_cost';

FLUSH OPTIMIZER_COSTS;
```

---

## 7. 🎯 执行计划选择过程


### 7.1 优化器的决策流程


**🔄 执行计划生成流程**
```
SQL优化器决策过程：

1. SQL解析
   ├─ 语法检查
   ├─ 词法分析  
   └─ 生成语法树

2. 执行计划枚举
   ├─ 表访问方法枚举
   │  ├─ 全表扫描
   │  ├─ 索引扫描
   │  └─ 索引查找
   ├─ JOIN算法枚举
   │  ├─ Nested Loop Join
   │  ├─ Hash Join
   │  └─ Sort Merge Join
   └─ 执行顺序枚举

3. 成本评估
   ├─ 每个方案计算总成本
   ├─ I/O成本 + CPU成本
   └─ 考虑统计信息影响

4. 最优计划选择
   ├─ 比较所有方案成本
   ├─ 选择成本最低方案
   └─ 生成最终执行计划
```

### 7.2 执行计划成本比较实例


**📊 实际查询的执行计划对比**
```sql
-- 示例查询
SELECT * FROM orders o 
JOIN users u ON o.user_id = u.id 
WHERE o.order_date > '2024-01-01' 
  AND u.age > 25;
```

**💰 不同执行计划的成本分析**
```
方案1：orders表全表扫描 + users表索引查找
┌─────────────────────────────────┐
│ 成本分解：                       │
│ • orders全表扫描：5000页×0.25=1250│
│ • 处理100万条记录：100万×0.1=10万 │
│ • 过滤日期条件：100万×0.05=5万    │
│ • users索引查找：50万次×4=200万   │
│ • JOIN处理：50万×0.1=5万        │
│ 总成本：约 260万成本单位         │
└─────────────────────────────────┘

方案2：orders表索引范围扫描 + users表全表扫描  
┌─────────────────────────────────┐
│ 成本分解：                       │
│ • orders索引扫描：500页×0.25=125 │
│ • 数据页随机访问：2000页×1.0=2000│
│ • users全表扫描：3000页×0.25=750 │
│ • JOIN处理：20万×10万×0.1=2万亿  │
│ • 年龄条件过滤：10万×0.05=5000   │
│ 总成本：约 2万亿成本单位（太高！）│
└─────────────────────────────────┘

方案3：两表都使用索引 + Hash Join
┌─────────────────────────────────┐
│ 成本分解：                       │
│ • orders索引扫描：500页×0.25=125 │
│ • orders数据页：2000页×1.0=2000  │
│ • users索引扫描：100页×0.25=25   │  
│ • users数据页：500页×1.0=500     │
│ • Hash表构建：5万×0.1=5000      │
│ • Hash连接：20万×0.05=1万       │
│ 总成本：约 1.85万成本单位        │
└─────────────────────────────────┘

优化器选择：方案3（成本最低）
```

### 7.3 成本评估的局限性


**⚠️ 成本模型的不足**
```
估算偏差的常见原因：

1. 统计信息过时
   ├─ 数据分布发生变化
   ├─ Cardinality不准确
   └─ 直方图信息缺失

2. 硬件差异
   ├─ SSD vs 机械硬盘性能差异
   ├─ 内存大小影响缓存命中率
   └─ CPU性能差异

3. 并发影响
   ├─ 多用户同时查询
   ├─ 缓存竞争
   └─ 锁等待时间

4. 网络延迟
   ├─ 主从复制延迟
   ├─ 分布式查询
   └─ 跨数据中心访问

应对策略：
✓ 定期更新统计信息
✓ 调整成本参数适配硬件
✓ 监控查询性能
✓ 使用Hint强制执行计划
```

---

## 8. 📋 核心要点总结


### 8.1 成本模型核心概念


```
🔸 成本模型本质：数学计算系统，用于预估SQL查询资源消耗
🔸 成本组成：I/O成本（页面访问）+ CPU成本（数据处理）
🔸 页面访问：随机访问成本高(1.0)，顺序访问成本低(0.25)
🔸 CPU处理：记录处理、条件评估、数据转换等操作成本
🔸 统计信息：影响成本评估准确性的关键因素
🔸 参数调优：可根据硬件环境调整成本参数
🔸 执行计划：优化器基于成本选择最优执行方案
```

### 8.2 关键理解要点


**🔹 为什么需要成本模型**
```
问题：SQL查询有多种执行方式，如何选择最优？
方案：通过数学模型量化执行成本，选择成本最低的方案
价值：自动化查询优化，提升数据库性能
```

**🔹 影响成本评估的关键因素**
```
数据量：表大小直接影响I/O和CPU成本
索引质量：高选择性索引降低查询成本  
统计信息：准确的统计信息改善成本估算
硬件性能：SSD、内存容量影响实际成本
数据分布：倾斜数据可能导致成本估算偏差
```

**🔹 成本模型的实际应用**
```
执行计划分析：通过EXPLAIN查看成本估算
性能调优：识别高成本操作并优化
索引设计：根据成本评估设计合理索引
查询重写：修改SQL降低执行成本
参数调优：调整成本参数适配环境
```

### 8.3 实际应用价值


**💡 查询优化实践**
- **执行计划分析**：通过成本理解为什么选择某个执行计划
- **索引设计指导**：评估索引的成本效益
- **SQL改写依据**：基于成本比较选择更优的SQL写法
- **硬件选型参考**：理解不同硬件对查询性能的影响

**🔧 数据库调优**
- **参数优化**：根据硬件特性调整成本参数
- **统计信息维护**：保持统计信息的准确性和时效性
- **监控指标**：关注实际执行成本与预估成本的差异
- **容量规划**：基于成本模型预测系统负载

### 8.4 常见问题和解决方案


**❓ 执行计划选择不当**
```
问题现象：优化器选择了低效的执行计划
排查方法：
1. 检查统计信息是否过时：ANALYZE TABLE
2. 查看成本估算：EXPLAIN FORMAT=JSON
3. 比较实际耗时与预估成本

解决方案：
• 更新统计信息
• 调整成本参数
• 使用Hint强制执行计划
• 重写SQL语句
```

**❓ 成本估算不准确**
```
问题现象：预估成本与实际性能不符
原因分析：
1. 硬件性能与默认参数不匹配
2. 缓存命中率与预期不符
3. 数据分布不均匀
4. 并发影响未考虑

解决方案：
• 根据实际硬件调整成本参数
• 创建直方图改善分布估算
• 定期更新统计信息
• 监控实际执行性能
```

**核心记忆口诀**：
- 成本模型算账本，I/O加CPU是核心
- 随机访问成本高，顺序读取更划算
- 统计信息要准确，过时数据误导深
- 硬件环境影响大，参数调优需匹配