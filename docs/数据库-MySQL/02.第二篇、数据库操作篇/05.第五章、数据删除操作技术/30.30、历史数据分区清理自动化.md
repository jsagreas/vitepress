---
title: 30、历史数据分区清理自动化
---
## 📚 目录

1. [分区表自动清理机制概述](#1-分区表自动清理机制概述)
2. [时间分区清理策略设计](#2-时间分区清理策略设计)
3. [分区删除脚本开发](#3-分区删除脚本开发)
4. [清理任务调度系统](#4-清理任务调度系统)
5. [分区清理监控体系](#5-分区清理监控体系)
6. [清理失败恢复机制](#6-清理失败恢复机制)
7. [自动化清理配置实践](#7-自动化清理配置实践)
8. [核心要点总结](#8-核心要点总结)

---

## 1. 🏗️ 分区表自动清理机制概述


### 1.1 什么是分区表自动清理


**🔸 通俗理解**
想象你的数据库就像一个巨大的**档案室**，随着时间推移，旧档案越来越多占用空间。分区清理就像定期清理过期档案的**自动化管理员**，按照规则自动删除不需要的历史数据。

**🔸 为什么需要自动清理**
```
业务场景举例：

电商订单表：
- 每天新增10万订单
- 1年后数据量：3650万条
- 3年后数据量：1亿条
- 5年后数据量：1.8亿条

问题出现：
❌ 查询越来越慢
❌ 备份时间越来越长  
❌ 存储成本越来越高
❌ 维护难度越来越大
```

### 1.2 自动清理的核心价值


**💡 解决的核心问题**：

**性能问题**：
- **查询性能**：数据量减少，查询速度提升
- **索引效率**：索引文件变小，检索更快
- **维护性能**：备份、恢复操作更快

**存储成本**：
- **磁盘空间**：删除不需要的历史数据释放空间
- **备份成本**：备份文件变小，存储费用降低
- **网络传输**：主从同步数据量减少

**运维效率**：
- **自动化**：无需人工干预，按规则自动执行
- **可预测**：清理时间和影响可控
- **风险降低**：避免手工操作的人为错误

### 1.3 分区清理与普通删除的区别


**🔧 传统DELETE vs 分区DROP对比**：

```
传统DELETE清理方式：
┌─────────────────────────────────────────┐
│  DELETE FROM orders                     │
│  WHERE created_time < '2023-01-01';     │
│                                         │
│  执行过程：                              │
│  1. 逐行扫描匹配条件 ←─ 很慢            │
│  2. 标记删除但不释放空间 ←─ 空间未回收   │
│  3. 记录每个删除的日志 ←─ 日志量大      │
│  4. 触发大量随机I/O ←─ 影响性能         │
└─────────────────────────────────────────┘

分区DROP清理方式：
┌─────────────────────────────────────────┐
│  ALTER TABLE orders                     │
│  DROP PARTITION p202301;                │
│                                         │
│  执行过程：                              │
│  1. 直接删除分区文件 ←─ 瞬间完成         │
│  2. 立即释放磁盘空间 ←─ 空间立即回收     │
│  3. 最少的日志记录 ←─ 对系统影响小       │
│  4. 顺序I/O操作 ←─ 性能影响最小         │
└─────────────────────────────────────────┘
```

**性能对比数据**：
```
删除1000万条历史数据的性能对比：

┌─────────────────┬─────────────────┬─────────────────┐
│     操作方式     │     执行时间     │   对系统影响     │
├─────────────────┼─────────────────┼─────────────────┤
│   DELETE语句    │    2-6小时      │    严重影响      │
│   分区DROP      │    2-5秒        │    几乎无影响    │
│   性能提升      │    1000倍以上   │    影响降低99%   │
└─────────────────┴─────────────────┴─────────────────┘
```

---

## 2. 📅 时间分区清理策略设计


### 2.1 时间分区基础知识


**🔸 什么是时间分区**
把数据按照**时间维度**分组存储，就像把档案按年份分别放在不同的文件柜里。

**时间分区示例**：
```
订单表按月分区：
┌─────────────────────────────────────────┐
│              orders表                   │
├─────────────────────────────────────────┤
│  p202301: 2023年1月的数据               │
│  p202302: 2023年2月的数据               │
│  p202303: 2023年3月的数据               │
│  ...                                   │
│  p202412: 2024年12月的数据              │
│  p202501: 2025年1月的数据（当前）        │
└─────────────────────────────────────────┘
```

### 2.2 分区清理策略类型


**🔥 基于数据保留期的清理策略**

**保留期策略示例**：
```
不同业务的数据保留需求：

┌─────────────────┬─────────────────┬─────────────────┐
│     业务类型     │    保留期限      │     清理原因     │
├─────────────────┼─────────────────┼─────────────────┤
│   用户行为日志   │     30天        │   仅用于短期分析 │
│   订单记录      │     3年         │   税务审计要求   │
│   支付流水      │     7年         │   法律法规要求   │
│   系统监控数据   │     90天        │   存储成本考虑   │
│   用户聊天记录   │     1年         │   隐私保护要求   │
└─────────────────┴─────────────────┴─────────────────┘
```

**🔥 基于存储容量的清理策略**

**容量控制策略**：
```
存储容量管控流程：

监控磁盘使用率
        |
     使用率 > 80%？
        |
       是 ──────────── 触发清理流程
        |               |
       否               |
        |               ↓
    继续监控        计算需要清理的分区数量
        ↑               |
        |               ↓
        └─────────── 执行分区清理
```

### 2.3 清理策略配置方法


**🔧 策略配置表设计**

```sql
-- 清理策略配置表
CREATE TABLE partition_cleanup_config (
    id INT AUTO_INCREMENT PRIMARY KEY,
    table_name VARCHAR(100) NOT NULL,          -- 表名
    retention_days INT NOT NULL,               -- 数据保留天数
    partition_type ENUM('daily','monthly') NOT NULL, -- 分区类型
    cleanup_time TIME DEFAULT '02:00:00',      -- 清理执行时间
    enabled BOOLEAN DEFAULT TRUE,              -- 是否启用
    last_cleanup DATETIME,                     -- 最后清理时间
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 配置示例数据
INSERT INTO partition_cleanup_config VALUES
(1, 'user_behavior_log', 30, 'daily', '02:00:00', TRUE, NULL, NOW()),
(2, 'order_history', 1095, 'monthly', '03:00:00', TRUE, NULL, NOW()),
(3, 'system_monitor', 90, 'daily', '01:30:00', TRUE, NULL, NOW());
```

**配置说明**：
- **retention_days**：保留1095天 = 3年
- **partition_type**：`daily`每日分区，`monthly`每月分区
- **cleanup_time**：凌晨执行，避免业务高峰期

---

## 3. 🛠️ 分区删除脚本开发


### 3.1 核心清理脚本结构


**🔸 脚本设计思路**
一个好的清理脚本就像一个**谨慎的管家**，既要高效工作，又要避免误删重要数据。

**🔧 Python清理脚本主体**

```python
#!/usr/bin/env python3
import mysql.connector
import datetime
import logging
import sys
from typing import List, Tuple

class PartitionCleaner:
    def __init__(self, host: str, user: str, password: str, database: str):
        """初始化数据库连接"""
        self.config = {
            'host': host,
            'user': user, 
            'password': password,
            'database': database,
            'autocommit': True
        }
        self.logger = self._setup_logger()
    
    def _setup_logger(self):
        """配置日志记录"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('/var/log/partition_cleanup.log'),
                logging.StreamHandler(sys.stdout)
            ]
        )
        return logging.getLogger(__name__)
    
    def get_cleanup_tasks(self) -> List[Tuple]:
        """获取需要清理的任务配置"""
        conn = mysql.connector.connect(**self.config)
        cursor = conn.cursor()
        
        query = """
        SELECT table_name, retention_days, partition_type
        FROM partition_cleanup_config 
        WHERE enabled = TRUE 
        AND (last_cleanup IS NULL OR last_cleanup < CURDATE())
        """
        
        cursor.execute(query)
        tasks = cursor.fetchall()
        cursor.close()
        conn.close()
        
        return tasks
    
    def get_expired_partitions(self, table_name: str, retention_days: int) -> List[str]:
        """获取过期的分区列表"""
        conn = mysql.connector.connect(**self.config)
        cursor = conn.cursor()
        
        # 计算过期日期
        cutoff_date = datetime.date.today() - datetime.timedelta(days=retention_days)
        
        # 查询现有分区
        query = """
        SELECT PARTITION_NAME 
        FROM INFORMATION_SCHEMA.PARTITIONS 
        WHERE TABLE_SCHEMA = %s AND TABLE_NAME = %s 
        AND PARTITION_NAME IS NOT NULL
        """
        
        cursor.execute(query, (self.config['database'], table_name))
        all_partitions = [row[0] for row in cursor.fetchall()]
        
        # 筛选过期分区
        expired_partitions = []
        for partition in all_partitions:
            if self._is_partition_expired(partition, cutoff_date):
                expired_partitions.append(partition)
        
        cursor.close()
        conn.close()
        return expired_partitions
    
    def _is_partition_expired(self, partition_name: str, cutoff_date: datetime.date) -> bool:
        """判断分区是否过期"""
        try:
            # 解析分区名中的日期 (假设格式为p20231201)
            date_str = partition_name[1:]  # 去掉前缀p
            partition_date = datetime.datetime.strptime(date_str, '%Y%m%d').date()
            return partition_date < cutoff_date
        except ValueError:
            self.logger.warning(f"无法解析分区名日期格式: {partition_name}")
            return False
```

### 3.2 安全清理机制


**🔒 安全检查机制**

```python
def safe_drop_partition(self, table_name: str, partition_name: str) -> bool:
    """安全删除分区"""
    try:
        conn = mysql.connector.connect(**self.config)
        cursor = conn.cursor()
        
        # 步骤1：验证分区存在
        if not self._partition_exists(cursor, table_name, partition_name):
            self.logger.warning(f"分区不存在: {table_name}.{partition_name}")
            return False
        
        # 步骤2：检查分区数据量
        row_count = self._get_partition_row_count(cursor, table_name, partition_name)
        self.logger.info(f"准备删除分区 {partition_name}，包含 {row_count} 条记录")
        
        # 步骤3：安全确认机制
        if row_count > 1000000:  # 超过100万条记录需要额外确认
            self.logger.warning(f"分区数据量较大({row_count}条)，需要管理员确认")
            return False
        
        # 步骤4：执行删除
        drop_sql = f"ALTER TABLE {table_name} DROP PARTITION {partition_name}"
        
        self.logger.info(f"执行删除: {drop_sql}")
        cursor.execute(drop_sql)
        
        # 步骤5：记录删除结果
        self._log_cleanup_result(table_name, partition_name, row_count, True)
        
        cursor.close()
        conn.close()
        return True
        
    except Exception as e:
        self.logger.error(f"删除分区失败: {table_name}.{partition_name}, 错误: {str(e)}")
        self._log_cleanup_result(table_name, partition_name, 0, False, str(e))
        return False
```

### 3.3 批量清理优化


**🚀 批量处理策略**

> ⚠️ **重要提醒**：分区删除是不可逆操作，批量处理需要特别谨慎

```python
def batch_cleanup(self, max_partitions_per_run: int = 5):
    """批量清理多个表的过期分区"""
    cleanup_tasks = self.get_cleanup_tasks()
    total_cleaned = 0
    
    for table_name, retention_days, partition_type in cleanup_tasks:
        self.logger.info(f"开始清理表: {table_name}")
        
        # 获取过期分区列表
        expired_partitions = self.get_expired_partitions(table_name, retention_days)
        
        if not expired_partitions:
            self.logger.info(f"表 {table_name} 无需清理")
            continue
        
        # 限制单次清理数量，避免对系统造成太大影响
        partitions_to_clean = expired_partitions[:max_partitions_per_run]
        
        self.logger.info(f"发现 {len(expired_partitions)} 个过期分区，本次清理 {len(partitions_to_clean)} 个")
        
        # 逐个清理分区
        for partition in partitions_to_clean:
            if self.safe_drop_partition(table_name, partition):
                total_cleaned += 1
                # 每删除一个分区暂停1秒，避免对系统造成冲击
                import time
                time.sleep(1)
            else:
                self.logger.error(f"分区清理失败: {table_name}.{partition}")
        
        # 更新清理配置表的最后清理时间
        self._update_last_cleanup_time(table_name)
    
    self.logger.info(f"本次清理完成，共清理 {total_cleaned} 个分区")
    return total_cleaned
```

---

## 4. ⏰ 清理任务调度系统


### 4.1 调度系统设计原理


**🔸 什么是任务调度**
就像给清洁工安排**工作时间表**，让清理任务在合适的时间自动执行，既不影响正常业务，又能保证定期清理。

**调度系统架构**：
```
调度系统组件架构：

┌─────────────────────────────────────────────┐
│              调度管理中心                    │
├─────────────────────────────────────────────┤
│  ┌─────────────┬─────────────┬─────────────┐ │
│  │  任务配置   │  执行计划   │  监控告警   │ │
│  │  管理器     │  调度器     │  管理器     │ │
│  └─────────────┴─────────────┴─────────────┘ │
├─────────────────────────────────────────────┤
│                执行引擎层                    │
├─────────────────────────────────────────────┤
│  ┌─────────────┬─────────────┬─────────────┐ │
│  │  清理脚本   │  监控脚本   │  恢复脚本   │ │
│  │  执行器     │  执行器     │  执行器     │ │
│  └─────────────┴─────────────┴─────────────┘ │
└─────────────────────────────────────────────┘
```

### 4.2 Cron调度配置


**🔧 Linux Cron配置**

```bash
# 编辑crontab
crontab -e

# 清理任务调度配置
# 分 时 日 月 周 命令
0  2  *  *  * /usr/local/bin/partition_cleanup.py --config /etc/mysql/cleanup.conf
30 2  *  *  0 /usr/local/bin/partition_cleanup.py --deep-clean --notify admin@company.com
0  3  1  *  * /usr/local/bin/partition_cleanup.py --monthly-report
```

**调度时间规划**：
```
时间安排策略：

┌─────────────────────────────────────────────┐
│              24小时调度规划                  │
├─────────────────────────────────────────────┤
│  00:00-08:00  ← 业务低峰期，适合清理操作    │
│  08:00-12:00  ← 业务高峰期，避免清理操作    │
│  12:00-14:00  ← 午休时间，可执行轻量清理    │
│  14:00-18:00  ← 业务高峰期，避免清理操作    │
│  18:00-24:00  ← 业务逐渐减少，可准备清理    │
└─────────────────────────────────────────────┘

推荐时间窗口：
✅ 02:00-04:00  主要清理时间
✅ 03:00-05:00  深度清理时间  
✅ 01:00-02:00  预检查时间
```

### 4.3 高级调度策略


**🔥 智能调度机制**

```python
class SmartScheduler:
    def __init__(self):
        self.load_threshold = 0.7  # CPU负载阈值
        self.min_free_space = 20   # 最小剩余空间(GB)
    
    def should_run_cleanup(self) -> Tuple[bool, str]:
        """智能判断是否应该执行清理"""
        
        # 检查系统负载
        if self._get_system_load() > self.load_threshold:
            return False, "系统负载过高，延后执行"
        
        # 检查磁盘空间
        free_space = self._get_free_disk_space()
        if free_space < self.min_free_space:
            return True, f"磁盘空间不足({free_space}GB)，立即清理"
        
        # 检查数据库连接数
        if self._get_active_connections() > 100:
            return False, "数据库连接数过多，延后执行"
        
        return True, "系统状态正常，可以执行清理"
    
    def _get_system_load(self) -> float:
        """获取系统负载"""
        import os
        return os.getloadavg()[0]  # 1分钟平均负载
    
    def _get_free_disk_space(self) -> float:
        """获取磁盘剩余空间(GB)"""
        import shutil
        free_bytes = shutil.disk_usage('/var/lib/mysql').free
        return free_bytes / (1024**3)  # 转换为GB
```

---

## 5. 📊 分区清理监控体系


### 5.1 监控指标体系


**🔸 监控的重要性**
清理操作就像开车，需要**仪表盘**时刻显示各种状态，确保一切正常运行。

**核心监控指标**：
```
┌─────────────────┬─────────────────┬─────────────────┬──────────────┐
│   监控类别      │     具体指标     │    监控目的      │   告警阈值    │
├─────────────────┼─────────────────┼─────────────────┼──────────────┤
│ 清理执行状态     │ 任务成功率       │ 确保清理正常执行 │   < 95%      │
│ 清理执行状态     │ 平均执行时间     │ 监控性能变化     │   > 10分钟   │
│ 数据状态        │ 分区数量变化     │ 确保清理有效     │   异常增长    │
│ 数据状态        │ 数据量变化       │ 监控清理效果     │   异常增长    │
│ 系统资源        │ 清理期间CPU      │ 避免影响业务     │   > 80%      │
│ 系统资源        │ 清理期间I/O      │ 避免影响业务     │   > 90%      │
└─────────────────┴─────────────────┴─────────────────┴──────────────┘
```

### 5.2 监控数据收集


**🔧 监控数据表设计**

```sql
-- 清理执行记录表
CREATE TABLE partition_cleanup_log (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    table_name VARCHAR(100) NOT NULL,
    partition_name VARCHAR(100) NOT NULL,
    action_type ENUM('DROP', 'CHECK', 'SKIP') NOT NULL,
    rows_affected BIGINT DEFAULT 0,
    execution_time DECIMAL(10,3),              -- 执行时间(秒)
    status ENUM('SUCCESS', 'FAILED', 'SKIPPED') NOT NULL,
    error_message TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    INDEX idx_table_date (table_name, created_at),
    INDEX idx_status_date (status, created_at)
);

-- 清理统计表
CREATE TABLE partition_cleanup_stats (
    id INT AUTO_INCREMENT PRIMARY KEY,
    cleanup_date DATE NOT NULL,
    total_partitions_checked INT DEFAULT 0,
    partitions_dropped INT DEFAULT 0,
    total_rows_deleted BIGINT DEFAULT 0,
    total_space_freed_mb DECIMAL(12,2) DEFAULT 0,
    execution_duration_seconds INT DEFAULT 0,
    errors_count INT DEFAULT 0,
    
    UNIQUE KEY uk_date (cleanup_date)
);
```

### 5.3 实时监控脚本


**📈 监控数据收集脚本**

```python
class CleanupMonitor:
    def collect_cleanup_metrics(self):
        """收集清理操作的监控指标"""
        conn = mysql.connector.connect(**self.config)
        cursor = conn.cursor()
        
        # 今日清理统计
        today_stats_query = """
        SELECT 
            COUNT(*) as total_operations,
            SUM(CASE WHEN status = 'SUCCESS' THEN 1 ELSE 0 END) as successful_operations,
            SUM(CASE WHEN status = 'FAILED' THEN 1 ELSE 0 END) as failed_operations,
            SUM(rows_affected) as total_rows_cleaned,
            AVG(execution_time) as avg_execution_time,
            MAX(execution_time) as max_execution_time
        FROM partition_cleanup_log 
        WHERE DATE(created_at) = CURDATE()
        """
        
        cursor.execute(today_stats_query)
        stats = cursor.fetchone()
        
        # 构建监控报告
        report = {
            'date': datetime.date.today().isoformat(),
            'total_operations': stats[0] or 0,
            'success_rate': (stats[1] / stats[0] * 100) if stats[0] else 100,
            'failed_operations': stats[2] or 0,
            'total_rows_cleaned': stats[3] or 0,
            'avg_execution_time': float(stats[4] or 0),
            'max_execution_time': float(stats[5] or 0)
        }
        
        cursor.close()
        conn.close()
        
        return report
    
    def check_cleanup_health(self) -> dict:
        """检查清理系统健康状态"""
        health_status = {
            'overall_status': 'HEALTHY',
            'issues': [],
            'recommendations': []
        }
        
        # 检查最近3天的清理成功率
        success_rate = self._get_recent_success_rate(days=3)
        if success_rate < 95:
            health_status['overall_status'] = 'WARNING'
            health_status['issues'].append(f"清理成功率偏低: {success_rate:.1f}%")
            health_status['recommendations'].append("检查清理脚本和数据库连接")
        
        # 检查磁盘空间增长趋势
        if self._is_disk_usage_growing_too_fast():
            health_status['overall_status'] = 'WARNING'
            health_status['issues'].append("磁盘使用增长过快")
            health_status['recommendations'].append("考虑缩短数据保留期或增加清理频率")
        
        return health_status
```

---

## 6. 🔧 清理失败恢复机制


### 6.1 常见失败场景


**🔸 失败原因分析**

**数据库层面失败**：
```
场景1：数据库连接失败
原因：网络问题、认证失败、数据库宕机
影响：清理任务无法执行
解决：重试机制 + 告警通知

场景2：分区删除被阻塞  
原因：有长时间运行的查询锁定了表
影响：删除操作等待或超时
解决：智能等待 + 错峰执行

场景3：磁盘空间不足
原因：清理过程中临时空间不够
影响：操作中断，可能造成数据不一致
解决：预检查 + 分批处理
```

**系统层面失败**：
```
场景4：脚本执行被中断
原因：服务器重启、进程被杀死
影响：清理任务中断，状态不明
解决：状态检查 + 断点续传

场景5：权限问题
原因：数据库用户权限不足
影响：无法执行DROP PARTITION
解决：权限检查 + 权限申请流程
```

### 6.2 重试与恢复机制


**🔄 智能重试策略**

```python
class RetryHandler:
    def __init__(self):
        self.max_retries = 3
        self.retry_delays = [60, 300, 900]  # 1分钟、5分钟、15分钟
    
    def execute_with_retry(self, operation_func, *args, **kwargs):
        """带重试机制的操作执行"""
        last_error = None
        
        for attempt in range(self.max_retries + 1):
            try:
                if attempt > 0:
                    delay = self.retry_delays[min(attempt-1, len(self.retry_delays)-1)]
                    self.logger.info(f"第{attempt}次重试，等待{delay}秒...")
                    time.sleep(delay)
                
                # 执行清理操作
                result = operation_func(*args, **kwargs)
                
                if attempt > 0:
                    self.logger.info(f"重试成功，第{attempt}次尝试")
                
                return result
                
            except Exception as e:
                last_error = e
                self.logger.warning(f"第{attempt+1}次尝试失败: {str(e)}")
                
                # 判断是否值得重试
                if not self._should_retry(e):
                    self.logger.error(f"错误类型不适合重试: {str(e)}")
                    break
        
        # 所有重试都失败
        self.logger.error(f"操作最终失败，已重试{self.max_retries}次: {str(last_error)}")
        raise last_error
    
    def _should_retry(self, error) -> bool:
        """判断错误类型是否值得重试"""
        # 网络相关错误值得重试
        network_errors = ['Connection', 'timeout', 'refused']
        error_str = str(error).lower()
        
        for err_keyword in network_errors:
            if err_keyword.lower() in error_str:
                return True
        
        # 权限错误不值得重试
        if 'access denied' in error_str or 'permission' in error_str:
            return False
        
        # 语法错误不值得重试
        if 'syntax error' in error_str:
            return False
        
        return True
```

### 6.3 清理状态恢复


**🔧 断点续传机制**

```python
def resume_interrupted_cleanup(self):
    """恢复被中断的清理任务"""
    
    # 查找最近24小时内未完成的清理任务
    incomplete_tasks = self._find_incomplete_tasks()
    
    if not incomplete_tasks:
        self.logger.info("没有发现未完成的清理任务")
        return
    
    self.logger.info(f"发现 {len(incomplete_tasks)} 个未完成的清理任务")
    
    for task in incomplete_tasks:
        table_name = task['table_name']
        last_partition = task['last_completed_partition']
        
        self.logger.info(f"恢复表 {table_name} 的清理，从分区 {last_partition} 之后开始")
        
        # 获取剩余需要清理的分区
        remaining_partitions = self._get_remaining_partitions(table_name, last_partition)
        
        # 继续执行清理
        for partition in remaining_partitions:
            try:
                if self.safe_drop_partition(table_name, partition):
                    self._update_cleanup_progress(table_name, partition)
                else:
                    break  # 如果失败，停止继续清理
            except Exception as e:
                self.logger.error(f"恢复清理失败: {str(e)}")
                break

def _find_incomplete_tasks(self) -> List[dict]:
    """查找未完成的清理任务"""
    conn = mysql.connector.connect(**self.config)
    cursor = conn.cursor()
    
    # 查找昨天开始但今天没有完成记录的任务
    query = """
    SELECT DISTINCT c.table_name,
           (SELECT partition_name 
            FROM partition_cleanup_log l2 
            WHERE l2.table_name = c.table_name 
            AND l2.status = 'SUCCESS'
            AND l2.created_at >= CURDATE() - INTERVAL 1 DAY
            ORDER BY l2.created_at DESC LIMIT 1) as last_completed_partition
    FROM partition_cleanup_config c
    WHERE c.enabled = TRUE
    AND EXISTS (
        SELECT 1 FROM partition_cleanup_log l1
        WHERE l1.table_name = c.table_name
        AND l1.created_at >= CURDATE() - INTERVAL 1 DAY
        AND l1.status = 'FAILED'
    )
    """
    
    cursor.execute(query)
    tasks = [{'table_name': row[0], 'last_completed_partition': row[1]} 
             for row in cursor.fetchall()]
    
    cursor.close()
    conn.close()
    return tasks
```

---

## 7. ⚙️ 自动化清理配置实践


### 7.1 完整配置文件


**🔧 清理配置文件设计**

```yaml
# /etc/mysql/partition_cleanup.yml
database:
  host: "localhost"
  port: 3306
  user: "cleanup_user"
  password: "secure_password"
  database: "production_db"
  
cleanup:
  # 全局配置
  max_partitions_per_run: 5        # 单次最多清理分区数
  cleanup_window_start: "02:00"    # 清理时间窗口开始
  cleanup_window_end: "04:00"      # 清理时间窗口结束
  safety_checks: true              # 是否启用安全检查
  dry_run: false                   # 是否只模拟不实际执行
  
  # 表级配置
  tables:
    - name: "user_behavior_log"
      retention_days: 30
      partition_type: "daily"
      enabled: true
      priority: 1                   # 优先级，数字越小优先级越高
      
    - name: "order_history"  
      retention_days: 1095          # 3年
      partition_type: "monthly"
      enabled: true
      priority: 2
      
    - name: "system_monitor"
      retention_days: 90
      partition_type: "daily" 
      enabled: true
      priority: 3

monitoring:
  # 告警配置
  alert:
    email: "dba@company.com"
    threshold:
      success_rate: 95              # 成功率低于95%告警
      execution_time: 600           # 执行超过10分钟告警
      
  # 报告配置  
  report:
    daily: true                     # 每日报告
    weekly: true                    # 周报
    monthly: true                   # 月报
```

### 7.2 权限配置


**🔒 数据库权限设置**

```sql
-- 创建专用清理用户
CREATE USER 'partition_cleaner'@'localhost' IDENTIFIED BY 'secure_password';

-- 授予必要权限
GRANT SELECT ON *.* TO 'partition_cleaner'@'localhost';
GRANT ALTER ON production_db.* TO 'partition_cleaner'@'localhost';
GRANT DROP ON production_db.* TO 'partition_cleaner'@'localhost';

-- 授予系统表查询权限（用于获取分区信息）
GRANT SELECT ON INFORMATION_SCHEMA.PARTITIONS TO 'partition_cleaner'@'localhost';
GRANT SELECT ON INFORMATION_SCHEMA.TABLES TO 'partition_cleaner'@'localhost';

-- 授予清理配置表的完整权限
GRANT ALL ON production_db.partition_cleanup_config TO 'partition_cleaner'@'localhost';
GRANT ALL ON production_db.partition_cleanup_log TO 'partition_cleaner'@'localhost';
GRANT ALL ON production_db.partition_cleanup_stats TO 'partition_cleaner'@'localhost';
```

**权限说明**：
- **SELECT权限**：查询分区信息和配置
- **ALTER权限**：执行DROP PARTITION操作
- **最小权限原则**：只授予必要权限，提高安全性

### 7.3 部署与启动配置


**🚀 服务化部署**

```bash
#!/bin/bash
# /etc/systemd/system/partition-cleanup.service

[Unit]
Description=MySQL Partition Cleanup Service
After=mysql.service
Requires=mysql.service

[Service]
Type=simple
User=mysql
Group=mysql
ExecStart=/usr/local/bin/partition_cleanup.py --config /etc/mysql/cleanup.yml --daemon
ExecReload=/bin/kill -HUP $MAINPID
Restart=always
RestartSec=30

# 日志配置
StandardOutput=journal
StandardError=journal
SyslogIdentifier=partition-cleanup

[Install]
WantedBy=multi-user.target
```

**启动和管理命令**：
```bash
# 启用服务
sudo systemctl enable partition-cleanup.service

# 启动服务
sudo systemctl start partition-cleanup.service

# 查看状态
sudo systemctl status partition-cleanup.service

# 查看日志
sudo journalctl -u partition-cleanup.service -f
```

### 7.4 健康检查配置


**🩺 自动健康检查**

```python
def daily_health_check(self):
    """每日健康检查"""
    health_report = {
        'check_time': datetime.datetime.now(),
        'status': 'HEALTHY',
        'issues': [],
        'metrics': {}
    }
    
    # 检查1：清理任务执行情况
    recent_failures = self._count_recent_failures(hours=24)
    if recent_failures > 3:
        health_report['status'] = 'WARNING'
        health_report['issues'].append(f"24小时内失败次数过多: {recent_failures}")
    
    # 检查2：分区数量增长趋势
    for table_config in self.get_table_configs():
        table_name = table_config['table_name']
        partition_count = self._get_partition_count(table_name)
        
        if partition_count > 100:  # 分区数量过多
            health_report['status'] = 'WARNING'
            health_report['issues'].append(f"表 {table_name} 分区数量过多: {partition_count}")
    
    # 检查3：磁盘空间使用
    disk_usage = self._get_disk_usage_percent()
    health_report['metrics']['disk_usage'] = disk_usage
    
    if disk_usage > 85:
        health_report['status'] = 'CRITICAL'
        health_report['issues'].append(f"磁盘使用率过高: {disk_usage}%")
    
    # 生成健康报告
    self._generate_health_report(health_report)
    
    # 如果有严重问题，发送告警
    if health_report['status'] in ['WARNING', 'CRITICAL']:
        self._send_alert(health_report)
    
    return health_report
```

---

## 8. 📋 核心要点总结


### 8.1 必须掌握的核心概念


```
🔸 自动清理本质：定期删除过期分区，释放存储空间，保持数据库性能
🔸 分区优势：DROP PARTITION比DELETE快1000倍，瞬间释放空间
🔸 清理策略：基于保留期 + 容量控制的双重策略
🔸 调度系统：智能调度避开业务高峰，确保系统稳定
🔸 监控体系：全方位监控清理过程，及时发现问题
🔸 恢复机制：失败自动重试，中断状态恢复，保证操作完整性
🔸 配置管理：灵活配置适应不同业务需求
```

### 8.2 关键实施要点


**🔹 安全第一原则**
```
安全措施清单：
✅ 分区存在性验证 - 避免误删
✅ 数据量安全阈值 - 防止意外删除大量数据
✅ 执行前备份验证 - 确保数据可恢复
✅ 操作日志记录 - 可追溯所有操作
✅ 权限最小化 - 只授予必要权限
✅ 多重确认机制 - 重要操作需要确认
```

**🔹 性能影响控制**
```
影响最小化策略：
- 错峰执行：凌晨2-4点业务低峰期
- 分批处理：每次最多清理5个分区
- 间隔控制：分区间暂停1秒
- 负载监控：CPU超过80%时暂停清理
- 智能调度：系统繁忙时延后执行
```

**🔹 监控告警策略**
```
告警级别设计：
INFO级别：日常清理完成通知
WARNING级别：成功率<95%，执行时间>10分钟
CRITICAL级别：连续3次失败，磁盘使用>90%
```

### 8.3 实际应用价值


**🎯 业务价值**
- **成本控制**：减少存储成本50-80%
- **性能提升**：查询性能提升30-50%  
- **运维效率**：自动化操作减少人工干预90%
- **风险降低**：规范化操作避免人为错误

**🔧 技术价值**
- **架构优化**：为大数据量应用提供可持续方案
- **运维自动化**：建立标准化的数据生命周期管理
- **监控体系**：完善的操作监控和问题预警
- **扩展性**：配置化设计支持业务快速增长

**💡 最佳实践总结**：
```
实施建议：
1. 从小规模开始，逐步扩展到全部表
2. 先在测试环境充分验证，再部署生产环境  
3. 建立完善的监控和告警机制
4. 制定清晰的应急处理流程
5. 定期评估和优化清理策略

常见误区避免：
❌ 一次性清理大量分区导致系统压力
❌ 没有充分测试就直接在生产环境执行
❌ 忽略监控导致问题发现滞后
❌ 缺乏恢复机制导致操作不可逆
```

**核心记忆**：
- 分区清理核心是"自动化+安全性"的平衡
- DROP PARTITION是删除历史数据的最高效方式  
- 完善的监控和恢复机制是自动化的基础保障
- 配置化设计让系统具备良好的扩展性和灵活性