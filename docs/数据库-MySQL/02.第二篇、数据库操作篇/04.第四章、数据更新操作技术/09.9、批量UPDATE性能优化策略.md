---
title: 9、批量UPDATE性能优化策略
---
## 📚 目录

1. [批量UPDATE概述](#1-批量update概述)
2. [批量更新优化策略](#2-批量更新优化策略)
3. [大表更新分批处理](#3-大表更新分批处理)
4. [更新性能监控指标](#4-更新性能监控指标)
5. [更新操作基准测试](#5-更新操作基准测试)
6. [大批量更新分页处理](#6-大批量更新分页处理)
7. [pt-online-schema-change工具](#7-pt-online-schema-change工具)
8. [核心要点总结](#8-核心要点总结)

---

## 1. 🚀 批量UPDATE概述


### 1.1 什么是批量UPDATE


> 💡 **通俗理解**：批量UPDATE就像工厂流水线批量加工产品，比一个一个单独处理效率更高

**批量更新的本质**：
```
单条更新 vs 批量更新对比：

单条更新模式：
UPDATE users SET status = 1 WHERE id = 1;    ← 执行1次
UPDATE users SET status = 1 WHERE id = 2;    ← 执行1次  
UPDATE users SET status = 1 WHERE id = 3;    ← 执行1次
...
UPDATE users SET status = 1 WHERE id = 1000; ← 执行1次
总计：1000次数据库交互

批量更新模式：
UPDATE users SET status = 1 
WHERE id IN (1,2,3,...,1000);                ← 执行1次
总计：1次数据库交互
```

### 1.2 批量UPDATE的优势


**性能提升原因分析**：
```
批量更新性能优势来源：
┌─────────────────────────────────┐
│ 1. 减少网络往返次数              │
│    └─ 1000次请求 → 1次请求      │
│                                 │
│ 2. 降低SQL解析开销              │
│    └─ 1000次解析 → 1次解析      │
│                                 │
│ 3. 优化事务处理                 │ 
│    └─ 1000个事务 → 1个事务      │
│                                 │
│ 4. 批量锁管理                   │
│    └─ 减少锁的获取释放次数       │
└─────────────────────────────────┘
```

**适用场景判断**：
- ✅ **数据清理**：批量修改历史数据状态
- ✅ **数据迁移**：批量更新字段值
- ✅ **统计更新**：批量计算和更新统计信息
- ✅ **状态同步**：批量同步外部系统状态

### 1.3 批量UPDATE面临的挑战


**主要性能瓶颈**：
```
大批量更新的性能挑战：
┌─ 锁竞争激烈 ─┐
│              │ ← 长时间持锁影响其他操作
├─ 内存消耗大 ─┤ ← 大事务占用大量内存
├─ 回滚日志多 ─┤ ← undo log快速增长
├─ 主从延迟 ───┤ ← 大事务复制延迟
└─ 死锁风险 ───┘ ← 多表更新可能死锁
```

---

## 2. ⚡ 批量更新优化策略


### 2.1 核心优化原则


> 📖 **指导思想**：在保证数据一致性的前提下，最大化更新效率，最小化对系统的影响

**优化策略层次**：
```
批量更新优化策略金字塔：

        ┌─ 业务层优化 ─┐
        │ 分批处理策略  │ ← 避免大事务
        ├─ SQL层优化 ──┤
        │ 语句结构优化  │ ← 提升执行效率  
        ├─ 索引层优化 ──┤
        │ 合理建立索引  │ ← 加速WHERE条件
        ├─ 存储层优化 ──┤
        │ 存储引擎调优  │ ← InnoDB参数优化
        └─ 系统层优化 ──┘
          硬件资源配置   ← CPU/内存/磁盘
```

### 2.2 SQL语句结构优化


**多种批量更新语法对比**：

| 更新方式 | **语法示例** | **适用场景** | **性能特点** |
|---------|-------------|-------------|-------------|
| **IN子句** | `WHERE id IN (1,2,3)` | `简单条件批量更新` | `高效，但有长度限制` |
| **CASE WHEN** | `SET col = CASE WHEN...` | `不同记录不同值` | `灵活，但语法复杂` |
| **JOIN更新** | `UPDATE t1 JOIN t2...` | `关联表批量更新` | `复杂逻辑，需优化` |
| **多表更新** | `UPDATE t1,t2 SET...` | `多表同步更新` | `事务性强，锁范围大` |

**实际优化示例**：

<details>
<summary>🔧 批量更新SQL优化对比</summary>

```sql
-- ❌ 效率低下的单条更新
DELIMITER $$
BEGIN
  DECLARE i INT DEFAULT 1;
  WHILE i <= 1000 DO
    UPDATE users SET last_login = NOW() WHERE id = i;
    SET i = i + 1;
  END WHILE;
END$$

-- ✅ 高效的批量更新
UPDATE users 
SET last_login = NOW() 
WHERE id BETWEEN 1 AND 1000;

-- ✅ 复杂条件批量更新
UPDATE users 
SET status = CASE 
  WHEN age < 18 THEN 'minor'
  WHEN age >= 60 THEN 'senior'  
  ELSE 'adult'
END
WHERE id BETWEEN 1 AND 1000;

-- ✅ 关联表批量更新
UPDATE users u
JOIN user_profiles p ON u.id = p.user_id
SET u.profile_complete = 1
WHERE p.avatar IS NOT NULL 
  AND p.bio IS NOT NULL;
```

</details>

### 2.3 索引优化策略


**更新操作索引考虑**：
```
索引对批量更新的影响：
┌─ WHERE条件索引 ─┐
│ 作用：加速记录定位│ ← 必须建立
│ 建议：组合索引   │
├─ 更新字段索引 ───┤  
│ 影响：索引维护成本│ ← 权衡考虑
│ 策略：临时删除？ │
└─ 外键约束索引 ───┘
  影响：约束检查   ← 可能需要优化
```

**索引优化实践**：
```sql
-- 检查更新语句的执行计划
EXPLAIN UPDATE users 
SET status = 'active' 
WHERE created_at < '2023-01-01';

-- 为批量更新创建临时索引
ALTER TABLE users ADD INDEX idx_temp_created (created_at);

-- 执行批量更新
UPDATE users 
SET status = 'active' 
WHERE created_at < '2023-01-01';

-- 删除临时索引（可选）
ALTER TABLE users DROP INDEX idx_temp_created;
```

### 2.4 事务控制优化


> ⚠️ **重要提醒**：大事务是批量更新性能杀手，必须合理控制事务大小

**事务大小控制策略**：
```
事务大小影响分析：
┌─ 小事务(100-1000行) ─┐
│ 优点：锁时间短       │
│ 优点：回滚成本低     │  
│ 缺点：提交开销多     │
├─ 中等事务(1000-5000)─┤
│ 平衡：性能和锁时间   │ ← 推荐选择
├─ 大事务(>10000行) ──┤
│ 优点：提交开销少     │
│ 缺点：锁时间长       │
│ 缺点：内存消耗大     │
└─ 超大事务(>100000) ─┘
  风险：可能导致系统卡死
```

---

## 3. 📊 大表更新分批处理


### 3.1 为什么需要分批处理


> 🎯 **核心原理**：化整为零，将大任务分解为多个小任务，降低对系统的冲击

**大表更新的问题**：
```
千万级表一次性更新问题：
┌─ 表：users (10,000,000 行) ─┐
│                             │
│ UPDATE users SET status=1;  │ ← 危险操作！
│                             │
│ 问题：                       │
│ ├─ 锁表时间长(几小时)        │
│ ├─ 内存消耗巨大(>10GB)      │  
│ ├─ undo日志爆满              │
│ ├─ 主从复制中断              │
│ └─ 其他业务完全阻塞          │
└─────────────────────────────┘
```

### 3.2 分批处理实现方案


**基于主键范围分批**：
```sql
-- 方案1：基于主键ID范围分批
SET @batch_size = 5000;
SET @min_id = 1;
SET @max_id = (SELECT MAX(id) FROM users);
SET @current_id = @min_id;

-- 循环处理每个批次
WHILE @current_id <= @max_id DO
  -- 更新当前批次
  UPDATE users 
  SET status = 'processed'
  WHERE id >= @current_id 
    AND id < @current_id + @batch_size
    AND status = 'pending';
  
  -- 记录处理进度
  SELECT CONCAT('Processed: ', @current_id, ' to ', @current_id + @batch_size) as progress;
  
  -- 更新游标
  SET @current_id = @current_id + @batch_size;
  
  -- 短暂休息，让出CPU
  DO SLEEP(0.1);
END WHILE;
```

**基于时间范围分批**：
```sql
-- 方案2：基于时间字段分批
SET @start_date = '2023-01-01';
SET @end_date = '2024-01-01';  
SET @batch_days = 7;

-- 按周分批处理
WHILE @start_date < @end_date DO
  UPDATE user_logs 
  SET processed = 1
  WHERE log_date >= @start_date
    AND log_date < DATE_ADD(@start_date, INTERVAL @batch_days DAY)
    AND processed = 0;
    
  -- 显示进度  
  SELECT @start_date as current_batch_start;
  
  SET @start_date = DATE_ADD(@start_date, INTERVAL @batch_days DAY);
  DO SLEEP(0.5);
END WHILE;
```

### 3.3 智能分批处理脚本


<details>
<summary>💻 Python自动分批处理脚本</summary>

```python
import pymysql
import time
import logging

class BatchUpdateProcessor:
    def __init__(self, connection_config):
        self.conn = pymysql.connect(**connection_config)
        self.batch_size = 5000
        self.sleep_time = 0.1
        
    def batch_update_by_id(self, table, update_sql, where_condition):
        """基于ID范围的批量更新"""
        cursor = self.conn.cursor()
        
        # 获取ID范围
        cursor.execute(f"SELECT MIN(id), MAX(id) FROM {table}")
        min_id, max_id = cursor.fetchone()
        
        current_id = min_id
        total_updated = 0
        
        while current_id <= max_id:
            # 构建批量更新SQL
            batch_sql = f"""
            {update_sql} 
            WHERE id >= %s AND id < %s 
            AND ({where_condition})
            """
            
            # 执行批量更新
            cursor.execute(batch_sql, (current_id, current_id + self.batch_size))
            affected_rows = cursor.rowcount
            total_updated += affected_rows
            
            # 提交事务
            self.conn.commit()
            
            # 日志记录
            logging.info(f"Updated {affected_rows} rows, total: {total_updated}")
            
            current_id += self.batch_size
            time.sleep(self.sleep_time)
            
        cursor.close()
        return total_updated

# 使用示例
config = {
    'host': 'localhost',
    'user': 'root', 
    'password': 'password',
    'database': 'test'
}

processor = BatchUpdateProcessor(config)
result = processor.batch_update_by_id(
    table='users',
    update_sql='UPDATE users SET status = "active"',
    where_condition='status = "pending"'
)
```

</details>

### 3.4 分批处理监控


**处理进度监控**：
```sql
-- 创建处理进度表
CREATE TABLE batch_update_progress (
  id INT AUTO_INCREMENT PRIMARY KEY,
  task_name VARCHAR(100),
  total_records INT,
  processed_records INT,
  current_batch_start INT,
  start_time DATETIME,
  estimated_completion DATETIME,
  status ENUM('running', 'completed', 'failed')
);

-- 更新进度
UPDATE batch_update_progress 
SET processed_records = @processed_count,
    current_batch_start = @current_id,
    estimated_completion = DATE_ADD(NOW(), 
      INTERVAL (@total_records - @processed_count) / @avg_speed SECOND)
WHERE task_name = 'user_status_update';
```

---

## 4. 📈 更新性能监控指标


### 4.1 核心性能指标


> 📊 **监控目的**：实时掌握更新操作的性能表现，及时发现和解决问题

**关键监控指标体系**：
```
批量更新性能监控指标：
┌─ 吞吐量指标 ─┐
│ ├─ 每秒更新行数(UPS) │ ← 核心性能指标
│ ├─ 每分钟事务数(TPM) │
│ └─ 批次处理速度      │
├─ 延迟指标 ───┤
│ ├─ 平均响应时间      │ ← 用户体验指标  
│ ├─ 95%响应时间      │
│ └─ 最大响应时间      │
├─ 资源使用指标 ┤
│ ├─ CPU使用率        │ ← 系统负载指标
│ ├─ 内存使用量        │
│ ├─ 磁盘IO等待       │
│ └─ 网络带宽使用      │
└─ 数据库指标 ──┘
  ├─ 锁等待时间
  ├─ 死锁次数
  └─ 慢查询数量
```

### 4.2 性能监控SQL


**实时性能监控查询**：
```sql
-- 监控当前更新操作
SELECT 
    PROCESSLIST_ID,
    PROCESSLIST_USER,
    PROCESSLIST_HOST,
    PROCESSLIST_DB,
    PROCESSLIST_COMMAND,
    PROCESSLIST_TIME,
    PROCESSLIST_STATE,
    LEFT(PROCESSLIST_INFO, 100) AS SQL_TEXT
FROM performance_schema.processlist 
WHERE PROCESSLIST_COMMAND = 'Query'
  AND PROCESSLIST_INFO LIKE '%UPDATE%'
ORDER BY PROCESSLIST_TIME DESC;

-- 监控锁等待情况
SELECT 
    r.trx_id waiting_trx_id,
    r.trx_mysql_thread_id waiting_thread,
    r.trx_query waiting_query,
    b.trx_id blocking_trx_id,
    b.trx_mysql_thread_id blocking_thread,
    b.trx_query blocking_query
FROM information_schema.innodb_lock_waits w
INNER JOIN information_schema.innodb_trx b ON b.trx_id = w.blocking_trx_id
INNER JOIN information_schema.innodb_trx r ON r.trx_id = w.requesting_trx_id;

-- 监控事务大小
SELECT 
    trx_id,
    trx_mysql_thread_id,
    trx_state,
    trx_started,
    trx_rows_locked,
    trx_rows_modified,
    LEFT(trx_query, 100) as sql_text
FROM information_schema.innodb_trx
ORDER BY trx_rows_modified DESC;
```

### 4.3 性能指标计算


**关键指标计算公式**：

<details>
<summary>📊 性能指标计算方法</summary>

```sql
-- 计算更新吞吐量(UPS - Updates Per Second)
SET @start_time = NOW();
SET @start_rows = (SELECT VARIABLE_VALUE FROM performance_schema.global_status WHERE VARIABLE_NAME = 'Com_update');

-- 执行批量更新...

SET @end_time = NOW();
SET @end_rows = (SELECT VARIABLE_VALUE FROM performance_schema.global_status WHERE VARIABLE_NAME = 'Com_update');

SELECT 
    (@end_rows - @start_rows) AS total_updates,
    TIMESTAMPDIFF(SECOND, @start_time, @end_time) AS elapsed_seconds,
    ROUND((@end_rows - @start_rows) / TIMESTAMPDIFF(SECOND, @start_time, @end_time), 2) AS updates_per_second;

-- 计算平均事务大小
SELECT 
    ROUND(Com_update / Com_commit, 2) AS avg_updates_per_transaction
FROM (
    SELECT 
        VARIABLE_VALUE AS Com_update
    FROM performance_schema.global_status 
    WHERE VARIABLE_NAME = 'Com_update'
) t1
CROSS JOIN (
    SELECT 
        VARIABLE_VALUE AS Com_commit
    FROM performance_schema.global_status 
    WHERE VARIABLE_NAME = 'Com_commit'  
) t2;
```

</details>

### 4.4 告警阈值设置


**性能告警规则**：
```sql
-- 性能告警阈值配置
CREATE TABLE update_performance_alerts (
    metric_name VARCHAR(50) PRIMARY KEY,
    warning_threshold DECIMAL(10,2),
    critical_threshold DECIMAL(10,2),
    current_value DECIMAL(10,2),
    alert_status ENUM('normal', 'warning', 'critical'),
    last_check_time DATETIME
);

INSERT INTO update_performance_alerts VALUES
('updates_per_second', 1000, 500, 0, 'normal', NOW()),
('avg_response_time_ms', 100, 500, 0, 'normal', NOW()),
('lock_wait_time_ms', 1000, 5000, 0, 'normal', NOW()),
('transaction_rollback_rate', 1.0, 5.0, 0, 'normal', NOW());
```

---

## 5. 🧪 更新操作基准测试


### 5.1 基准测试的重要性


> 🎯 **测试目标**：量化不同更新策略的性能表现，为生产环境选择最优方案

**基准测试价值**：
```
基准测试解决的问题：
┌─ 方案选择依据 ─┐
│ 哪种批量更新最快？│ ← 性能对比
├─ 容量规划依据 ──┤
│ 硬件配置够用吗？ │ ← 资源评估  
├─ 风险评估依据 ──┤
│ 会影响业务吗？   │ ← 影响分析
└─ 优化效果验证 ──┘
  改进后效果如何？   ← 效果量化
```

### 5.2 测试环境搭建


**标准测试环境**：
```sql
-- 创建测试表
CREATE TABLE users_test (
    id INT AUTO_INCREMENT PRIMARY KEY,
    username VARCHAR(50),
    email VARCHAR(100),
    status ENUM('active', 'inactive', 'pending'),
    created_at DATETIME,
    last_login DATETIME,
    profile_complete BOOLEAN DEFAULT FALSE,
    
    INDEX idx_status (status),
    INDEX idx_created (created_at),
    INDEX idx_email (email)
);

-- 生成测试数据
INSERT INTO users_test (username, email, status, created_at)
SELECT 
    CONCAT('user_', n) as username,
    CONCAT('user_', n, '@example.com') as email,
    CASE WHEN n % 3 = 0 THEN 'active' 
         WHEN n % 3 = 1 THEN 'inactive' 
         ELSE 'pending' END as status,
    DATE_ADD('2023-01-01', INTERVAL FLOOR(RAND() * 365) DAY) as created_at
FROM (
    SELECT a.N + b.N * 10 + c.N * 100 + d.N * 1000 + e.N * 10000 + 1 n
    FROM 
    (SELECT 0 AS N UNION ALL SELECT 1 UNION ALL SELECT 2 UNION ALL SELECT 3 UNION ALL SELECT 4 UNION ALL SELECT 5 UNION ALL SELECT 6 UNION ALL SELECT 7 UNION ALL SELECT 8 UNION ALL SELECT 9) a,
    (SELECT 0 AS N UNION ALL SELECT 1 UNION ALL SELECT 2 UNION ALL SELECT 3 UNION ALL SELECT 4 UNION ALL SELECT 5 UNION ALL SELECT 6 UNION ALL SELECT 7 UNION ALL SELECT 8 UNION ALL SELECT 9) b,
    (SELECT 0 AS N UNION ALL SELECT 1 UNION ALL SELECT 2 UNION ALL SELECT 3 UNION ALL SELECT 4 UNION ALL SELECT 5 UNION ALL SELECT 6 UNION ALL SELECT 7 UNION ALL SELECT 8 UNION ALL SELECT 9) c,
    (SELECT 0 AS N UNION ALL SELECT 1 UNION ALL SELECT 2 UNION ALL SELECT 3 UNION ALL SELECT 4 UNION ALL SELECT 5 UNION ALL SELECT 6 UNION ALL SELECT 7 UNION ALL SELECT 8 UNION ALL SELECT 9) d,
    (SELECT 0 AS N UNION ALL SELECT 1 UNION ALL SELECT 2 UNION ALL SELECT 3 UNION ALL SELECT 4 UNION ALL SELECT 5 UNION ALL SELECT 6 UNION ALL SELECT 7 UNION ALL SELECT 8 UNION ALL SELECT 9) e
) numbers
WHERE n <= 100000;
```

### 5.3 基准测试用例


**不同更新策略测试对比**：

<details>
<summary>🧪 基准测试脚本</summary>

```sql
-- 测试1：单条更新性能
SET @start_time = NOW(6);
UPDATE users_test SET last_login = NOW() WHERE id = 1;
UPDATE users_test SET last_login = NOW() WHERE id = 2;
-- ... 重复1000次
SET @end_time = NOW(6);
SELECT TIMESTAMPDIFF(MICROSECOND, @start_time, @end_time) / 1000 AS single_update_ms;

-- 测试2：批量更新性能
SET @start_time = NOW(6);
UPDATE users_test 
SET last_login = NOW() 
WHERE id BETWEEN 1001 AND 2000;
SET @end_time = NOW(6);
SELECT TIMESTAMPDIFF(MICROSECOND, @start_time, @end_time) / 1000 AS batch_update_ms;

-- 测试3：分批更新性能
SET @start_time = NOW(6);
SET @batch_size = 100;
SET @current_id = 2001;

WHILE @current_id <= 3000 DO
    UPDATE users_test 
    SET last_login = NOW() 
    WHERE id >= @current_id AND id < @current_id + @batch_size;
    
    SET @current_id = @current_id + @batch_size;
END WHILE;

SET @end_time = NOW(6);
SELECT TIMESTAMPDIFF(MICROSECOND, @start_time, @end_time) / 1000 AS batched_update_ms;

-- 测试4：不同批次大小性能对比
DELIMITER $$
CREATE PROCEDURE test_batch_sizes()
BEGIN
    DECLARE batch_size INT DEFAULT 10;
    DECLARE test_result TEXT DEFAULT '';
    
    WHILE batch_size <= 10000 DO
        SET @start_time = NOW(6);
        SET @current_id = 10000;
        
        WHILE @current_id <= 11000 DO
            UPDATE users_test 
            SET profile_complete = TRUE 
            WHERE id >= @current_id AND id < @current_id + batch_size;
            
            SET @current_id = @current_id + batch_size;
        END WHILE;
        
        SET @end_time = NOW(6);
        SET @elapsed_ms = TIMESTAMPDIFF(MICROSECOND, @start_time, @end_time) / 1000;
        
        INSERT INTO batch_test_results VALUES (batch_size, @elapsed_ms, NOW());
        
        SET batch_size = batch_size * 2;
    END WHILE;
END$$
DELIMITER ;
```

</details>

### 5.4 测试结果分析


**性能测试结果示例**：
```
典型测试结果对比：
┌─────────────────────────────────────────┐
│ 更新方式     │ 耗时(ms) │ TPS  │ 资源占用 │
├─────────────────────────────────────────┤
│ 单条更新     │  15,420  │  65  │ 高CPU   │
│ 小批量(100)  │   2,340  │ 427  │ 中等    │
│ 中批量(1000) │   1,890  │ 529  │ 中等    │
│ 大批量(5000) │   2,100  │ 476  │ 高内存   │
│ 超大批量     │   3,200  │ 312  │ 锁等待   │
└─────────────────────────────────────────┘

结论：批量大小1000-2000时性能最佳
```

---

## 6. 📄 大批量更新分页处理


### 6.1 分页处理原理


> 💡 **核心思想**：将大量数据按页分割，每页处理适量数据，避免单个操作过大

**分页处理优势**：
```
分页处理 vs 一次性处理：

一次性处理：
┌─ 100万行数据 ─┐
│ 更新全部数据   │ → 长时间锁表 → 业务阻塞
└───────────────┘

分页处理：  
┌─ 第1页:1000行 ─┐ → 短时间锁 → 释放
├─ 第2页:1000行 ─┤ → 短时间锁 → 释放
├─ 第3页:1000行 ─┤ → 短时间锁 → 释放
│      ...      │
└─ 第1000页     ─┘ → 短时间锁 → 释放

优势：每次只锁少量数据，其他业务可正常进行
```

### 6.2 基于LIMIT的分页更新


**LIMIT分页实现**：
```sql
-- 方案1：基于LIMIT OFFSET的分页更新
SET @page_size = 1000;
SET @offset = 0;
SET @total_updated = 0;

-- 获取总记录数
SELECT COUNT(*) INTO @total_count 
FROM users 
WHERE status = 'pending';

-- 分页处理循环
WHILE @offset < @total_count DO
    -- 更新当前页数据
    UPDATE users 
    SET status = 'processed', updated_at = NOW()
    WHERE status = 'pending'
    ORDER BY id
    LIMIT @page_size;
    
    -- 统计更新行数
    SET @updated_rows = ROW_COUNT();
    SET @total_updated = @total_updated + @updated_rows;
    
    -- 如果没有更新行，说明处理完成
    IF @updated_rows = 0 THEN
        LEAVE;
    END IF;
    
    -- 显示进度
    SELECT CONCAT('Updated: ', @total_updated, '/', @total_count) as progress;
    
    -- 短暂休息
    DO SLEEP(0.1);
END WHILE;
```

> ⚠️ **注意**：使用LIMIT更新时，每次都是更新前N条记录，已更新的记录条件已变化，不会重复更新

### 6.3 游标分页处理


**游标分页优势**：
```
LIMIT分页问题：
SELECT * FROM users WHERE status='pending' ORDER BY id LIMIT 10000, 1000;
                                                    ↑
                                          需要跳过10000行，效率低

游标分页优势：  
SELECT * FROM users WHERE status='pending' AND id > 10000 ORDER BY id LIMIT 1000;
                                          ↑
                                    直接定位，效率高
```

**游标分页实现**：
```sql
-- 方案2：基于游标的分页更新
SET @page_size = 1000;
SET @last_id = 0;
SET @total_updated = 0;

-- 游标分页循环
REPEAT
    -- 更新当前批次
    UPDATE users 
    SET status = 'processed', updated_at = NOW()
    WHERE status = 'pending' 
      AND id > @last_id
    ORDER BY id
    LIMIT @page_size;
    
    -- 获取本次更新的最大ID
    SELECT MAX(id) INTO @last_id
    FROM (
        SELECT id FROM users 
        WHERE status = 'processed' 
          AND updated_at >= DATE_SUB(NOW(), INTERVAL 1 SECOND)
        ORDER BY updated_at DESC 
        LIMIT @page_size
    ) t;
    
    SET @updated_rows = ROW_COUNT();
    SET @total_updated = @total_updated + @updated_rows;
    
    SELECT CONCAT('Processed up to ID: ', @last_id, ', Total: ', @total_updated) as progress;
    DO SLEEP(0.1);
    
UNTIL @updated_rows = 0 END REPEAT;
```

### 6.4 并行分页处理


**多线程并行处理**：

<details>
<summary>💻 Python并行分页更新</summary>

```python
import threading
import pymysql
from concurrent.futures import ThreadPoolExecutor

class ParallelBatchUpdater:
    def __init__(self, db_config, thread_count=4):
        self.db_config = db_config
        self.thread_count = thread_count
        self.page_size = 1000
        
    def get_connection(self):
        return pymysql.connect(**self.db_config)
    
    def update_page_range(self, start_id, end_id):
        """更新指定ID范围的数据"""
        conn = self.get_connection()
        try:
            cursor = conn.cursor()
            
            sql = """
            UPDATE users 
            SET status = 'processed', updated_at = NOW()
            WHERE id BETWEEN %s AND %s 
              AND status = 'pending'
            """
            
            cursor.execute(sql, (start_id, end_id))
            affected_rows = cursor.rowcount
            conn.commit()
            
            print(f"Thread {threading.current_thread().ident}: Updated {affected_rows} rows (ID {start_id}-{end_id})")
            return affected_rows
            
        finally:
            conn.close()
    
    def parallel_update(self, total_records):
        """并行执行批量更新"""
        # 计算每个线程处理的范围
        records_per_thread = total_records // self.thread_count
        
        # 创建任务列表
        tasks = []
        for i in range(self.thread_count):
            start_id = i * records_per_thread + 1
            end_id = (i + 1) * records_per_thread
            if i == self.thread_count - 1:  # 最后一个线程处理剩余数据
                end_id = total_records
            tasks.append((start_id, end_id))
        
        # 并行执行
        with ThreadPoolExecutor(max_workers=self.thread_count) as executor:
            futures = [executor.submit(self.update_page_range, start_id, end_id) 
                      for start_id, end_id in tasks]
            
            total_updated = sum(future.result() for future in futures)
            return total_updated

# 使用示例
db_config = {
    'host': 'localhost',
    'user': 'root',
    'password': 'password', 
    'database': 'test'
}

updater = ParallelBatchUpdater(db_config, thread_count=4)
result = updater.parallel_update(100000)
print(f"Total updated: {result} records")
```

</details>

---

## 7. 🛠️ pt-online-schema-change工具


### 7.1 工具介绍


> 🔧 **工具定位**：pt-online-schema-change是Percona Toolkit中的在线表结构变更工具，也可用于大批量数据更新

**工具解决的问题**：
```
传统大表更新问题：
┌─ 大表ALTER/UPDATE ─┐
│                    │
│ 锁表几小时          │ → 业务完全停止
│ 主从复制中断        │ → 数据同步异常
│ 磁盘空间不足        │ → 操作失败
└────────────────────┘

pt-online-schema-change优势：
┌─ 在线变更 ─┐
│            │
│ 不锁原表    │ → 业务正常运行
│ 分批处理    │ → 控制系统负载  
│ 自动回滚    │ → 失败自动恢复
└────────────┘
```

### 7.2 工具工作原理


**核心工作流程**：
```
pt-osc工作原理：
┌─ 原表(users) ─┐          ┌─ 新表(_users_new) ─┐
│               │          │                    │
│ 1. 创建新表    │ ────────► │ 2. 复制表结构      │
│               │          │                    │
│ 3. 创建触发器  │          │ 4. 分批复制数据     │
│    INSERT触发器│ ────────► │    同时应用更新     │
│    UPDATE触发器│ ────────► │                    │  
│    DELETE触发器│ ────────► │                    │
│               │          │                    │
│ 5. 原子重命名  │ ◄──────► │ 6. 交换表名        │
│    users_old   │          │    users           │
└───────────────┘          └────────────────────┘
```

### 7.3 大批量更新应用


**使用pt-osc进行批量更新**：
```bash
# 示例：批量更新用户状态
pt-online-schema-change \
  --alter "UPDATE users SET status = 'active' WHERE created_at < '2023-01-01'" \
  --execute \
  --host=localhost \
  --user=root \
  --password=password \
  --database=mydb \
  --table=users \
  --chunk-size=1000 \
  --chunk-time=0.1 \
  --max-load="Threads_running=25" \
  --critical-load="Threads_running=50" \
  --progress=time,30
```

**关键参数说明**：

| 参数 | **作用** | **推荐值** | **说明** |
|------|---------|-----------|---------|
| `--chunk-size` | `每批处理行数` | `1000-5000` | `根据表大小调整` |
| `--chunk-time` | `批次间等待时间` | `0.1-1.0秒` | `控制系统负载` |
| `--max-load` | `负载上限` | `Threads_running=25` | `负载高时暂停` |
| `--critical-load` | `紧急停止负载` | `Threads_running=50` | `负载过高时停止` |

### 7.4 pt-osc最佳实践


**使用前检查清单**：
```sql
-- 1. 检查表是否有外键约束
SELECT 
    CONSTRAINT_NAME,
    TABLE_NAME,
    REFERENCED_TABLE_NAME,
    REFERENCED_COLUMN_NAME
FROM information_schema.KEY_COLUMN_USAGE
WHERE TABLE_SCHEMA = 'your_database'
  AND TABLE_NAME = 'your_table'
  AND REFERENCED_TABLE_NAME IS NOT NULL;

-- 2. 检查表是否有触发器
SELECT 
    TRIGGER_NAME,
    EVENT_MANIPULATION,
    ACTION_TIMING
FROM information_schema.TRIGGERS
WHERE TABLE_SCHEMA = 'your_database'
  AND TABLE_NAME = 'your_table';

-- 3. 估算磁盘空间需求
SELECT 
    TABLE_NAME,
    ROUND((DATA_LENGTH + INDEX_LENGTH) / 1024 / 1024, 2) AS table_size_mb
FROM information_schema.TABLES
WHERE TABLE_SCHEMA = 'your_database'
  AND TABLE_NAME = 'your_table';
```

**监控和应急处理**：
```bash
# 监控pt-osc进程
ps aux | grep pt-online-schema-change

# 如需停止，发送SIGTERM信号
kill -TERM <pid>

# 查看进度日志
tail -f /tmp/pt-osc-debug.log

# 检查复制延迟
mysql -e "SHOW SLAVE STATUS\G" | grep Seconds_Behind_Master
```

---

## 8. 📋 核心要点总结


### 8.1 必须掌握的核心概念


```
🔸 批量更新本质：通过减少数据库交互次数提升更新效率
🔸 分批处理策略：将大任务分解为小任务，降低系统冲击
🔸 性能监控指标：TPS、响应时间、资源使用率等关键指标
🔸 基准测试方法：科学对比不同更新策略的性能表现
🔸 分页处理技术：LIMIT分页和游标分页的优缺点
🔸 pt-osc工具：在线大表变更的利器，适用于生产环境
```

### 8.2 关键理解要点


**🔹 批量更新优化策略的选择**
```
策略选择原则：
- 数据量小(<10万)：直接批量更新
- 数据量中等(10万-100万)：分批处理  
- 数据量大(>100万)：考虑pt-osc或并行处理
- 超大表(>千万级)：必须使用专业工具
```

**🔹 分批处理的核心要素**
```
关键控制点：
- 批次大小：平衡性能和锁时间
- 间隔时间：让出CPU给其他操作
- 监控指标：及时发现性能问题
- 错误处理：异常情况的恢复机制
```

**🔹 性能监控的重要性**
```
监控价值：
- 实时掌握更新进度和性能
- 及时发现系统瓶颈和异常
- 为容量规划提供数据支持
- 验证优化效果
```

### 8.3 实际应用指导


**生产环境最佳实践**：
- **充分测试**：在测试环境验证更新策略
- **业务窗口**：选择业务低峰期执行大批量更新
- **备份保护**：重要操作前做好数据备份
- **监控告警**：设置关键指标的监控告警
- **应急预案**：准备回滚和应急处理方案

**性能优化建议**：
- **SQL优化**：使用高效的WHERE条件和索引
- **参数调优**：根据硬件配置调整MySQL参数
- **资源规划**：确保有足够的CPU、内存、磁盘资源
- **网络优化**：减少网络延迟，使用连接池

**工具选择指南**：
```
工具选择决策树：
数据量和业务影响评估
        │
    ┌───┴───┐
小批量更新   大批量更新
    │           │  
直接执行      评估停机时间
    │           │
    │       ┌───┴───┐
    │    可以停机  不能停机
    │       │       │
    └─ 分批处理   pt-osc
```

**核心记忆要点**：
- 批量更新要分批，避免大事务锁表时间长
- 性能监控很重要，及时发现问题早解决
- 工具选择有策略，根据场景选最优方案
- 测试验证是基础，生产环境要小心操作