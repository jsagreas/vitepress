---
title: 10、CSV与JSON数据处理
---
## 📚 目录

1. [数据格式处理基础概念](#1-数据格式处理基础概念)
2. [CSV格式数据处理详解](#2-CSV格式数据处理详解)
3. [JSON数据导入与处理](#3-JSON数据导入与处理)
4. [格式转换技术实现](#4-格式转换技术实现)
5. [特殊字符与编码处理](#5-特殊字符与编码处理)
6. [数据类型映射策略](#6-数据类型映射策略)
7. [格式验证与错误处理](#7-格式验证与错误处理)
8. [批量格式处理优化](#8-批量格式处理优化)
9. [核心要点总结](#9-核心要点总结)

---

## 1. 📊 数据格式处理基础概念


### 1.1 什么是数据格式处理


**通俗理解**：就像把不同语言的文件翻译成MySQL能理解的语言

```
生活类比：
外国朋友给你发文件 → 需要翻译成中文 → 你才能理解内容
Excel文件给MySQL → 需要转换成SQL → MySQL才能存储

数据格式转换的本质：
不同系统间的"语言翻译"过程
```

> 📌 **核心概念**  
> **数据格式处理**：将外部数据文件（CSV、JSON、Excel等）转换为MySQL可以识别和存储的格式，这是数据集成的基础工作

### 1.2 为什么需要格式处理


**实际需求场景**：
```
📊 业务数据迁移：
老系统数据 → CSV导出 → 新MySQL系统

📱 第三方数据接入：
API返回JSON → 解析处理 → 存入数据库

📈 数据分析准备：
Excel报表 → 格式转换 → 数据仓库

🔄 系统间数据交换：
系统A的CSV → 格式处理 → 系统B的MySQL
```

**核心价值**：
- **数据互通**：让不同系统的数据能够交流
- **格式统一**：将各种格式统一为数据库标准格式
- **质量保证**：在导入过程中清洗和验证数据
- **效率提升**：自动化处理大批量数据

### 1.3 常见数据格式特点


```
📄 CSV (Comma-Separated Values)：
优点：简单、通用、Excel支持好
缺点：结构简单、不支持嵌套、编码问题多

📋 JSON (JavaScript Object Notation)：
优点：结构化好、支持嵌套、现代系统标准
缺点：体积较大、MySQL原生支持有限

📊 Excel格式：
优点：用户友好、格式丰富、公式支持
缺点：二进制格式、版本兼容性、大文件性能差
```

---

## 2. 📝 CSV格式数据处理详解


### 2.1 CSV格式基础知识


**什么是CSV**：
```
CSV全称：Comma-Separated Values（逗号分隔值）
本质：用逗号分隔数据的纯文本格式
优势：简单、通用、所有系统都支持

基本结构：
第一行：字段名（可选）
后续行：数据记录
分隔符：通常用逗号，也可以是制表符、分号等
```

**CSV文件示例**：
```csv
name,age,email,salary
张三,28,zhangsan@email.com,8000
李四,32,lisi@email.com,12000
王五,25,wangwu@email.com,6000
```

### 2.2 MySQL CSV导入方法


#### 2.2.1 LOAD DATA INFILE 方法


> 💡 **最佳实践**  
> `LOAD DATA INFILE`是MySQL导入CSV最高效的方法，比INSERT语句快10-20倍

**基本语法**：
```sql
-- 基础CSV导入
LOAD DATA INFILE '/path/to/file.csv'
INTO TABLE employees
FIELDS TERMINATED BY ','           -- 字段分隔符
ENCLOSED BY '"'                    -- 字段包围符
LINES TERMINATED BY '\n'           -- 行分隔符
IGNORE 1 ROWS;                     -- 跳过标题行
```

**详细参数说明**：
```sql
LOAD DATA INFILE '/data/employees.csv'
INTO TABLE employees
FIELDS 
    TERMINATED BY ','              -- 逗号分隔
    OPTIONALLY ENCLOSED BY '"'     -- 可选双引号包围
    ESCAPED BY '\\'                -- 转义字符
LINES 
    TERMINATED BY '\r\n'           -- Windows换行符
    STARTING BY ''                 -- 行开始字符（通常为空）
IGNORE 1 ROWS                      -- 忽略标题行
(name, age, email, @salary)        -- 指定字段映射
SET salary = @salary * 100;        -- 数据转换
```

#### 2.2.2 CSV字段引号处理技术


**引号处理的重要性**：
```
问题场景：
CSV内容：
"张三","软件工程师，负责\"前端开发\"","上海市徐汇区"

挑战：
1. 字段内容包含逗号
2. 字段内容包含引号
3. 引号的转义处理
```

**处理策略**：
```sql
-- 标准引号处理
LOAD DATA INFILE '/data/complex.csv'
INTO TABLE employees
FIELDS 
    TERMINATED BY ','
    OPTIONALLY ENCLOSED BY '"'     -- 字段可以用引号包围
    ESCAPED BY '\\'                -- 用反斜杠转义引号
LINES TERMINATED BY '\n';

-- 处理规则：
-- "张三" → 张三
-- "软件工程师，负责\"前端开发\"" → 软件工程师，负责"前端开发"
-- "上海市徐汇区" → 上海市徐汇区
```

> ⚠️ **注意事项**  
> CSV中的引号必须成对出现，如果引号不匹配会导致整行数据解析错误

### 2.3 CSV数据验证与清洗


**数据验证流程**：
```
步骤1：结构验证 → 检查字段数量是否匹配
步骤2：格式验证 → 检查数据类型是否正确
步骤3：业务验证 → 检查数据是否符合业务规则
步骤4：清洗处理 → 修正或丢弃异常数据
```

**实际验证示例**：
```sql
-- 创建临时表进行数据验证
CREATE TEMPORARY TABLE temp_employees (
    line_num INT AUTO_INCREMENT PRIMARY KEY,
    raw_data TEXT,                    -- 原始行数据
    name VARCHAR(100),
    age INT,
    email VARCHAR(200),
    salary DECIMAL(10,2),
    error_msg TEXT                    -- 错误信息
);

-- 导入时进行数据验证
LOAD DATA INFILE '/data/employees.csv'
INTO TABLE temp_employees
FIELDS TERMINATED BY ','
LINES TERMINATED BY '\n'
(name, @age, email, @salary)
SET 
    age = CASE 
        WHEN @age REGEXP '^[0-9]+$' THEN @age 
        ELSE NULL 
    END,
    salary = CASE 
        WHEN @salary REGEXP '^[0-9]+\.?[0-9]*$' THEN @salary 
        ELSE NULL 
    END,
    error_msg = CASE 
        WHEN age IS NULL THEN '年龄格式错误'
        WHEN salary IS NULL THEN '工资格式错误'
        ELSE ''
    END;
```

### 2.4 CSV特殊情况处理


**常见问题与解决方案**：

| **问题类型** | **具体表现** | **解决方法** | **示例** |
|-------------|-------------|-------------|----------|
| 🔤 **编码问题** | 中文乱码 | 指定字符集 | `CHARACTER SET utf8mb4` |
| 📏 **字段数不匹配** | 列数对不上 | 使用字段映射 | `(field1, field2, @skip, field3)` |
| 🔣 **特殊分隔符** | 非逗号分隔 | 指定分隔符 | `TERMINATED BY '\t'` |
| 💭 **空值处理** | 空字段 | 设置默认值 | `SET field = IFNULL(@field, 'default')` |

**处理特殊CSV格式**：
```sql
-- 处理制表符分隔的CSV
LOAD DATA INFILE '/data/tab_separated.csv'
INTO TABLE products
FIELDS TERMINATED BY '\t'         -- 制表符分隔
LINES TERMINATED BY '\n'
(product_name, @price, category)
SET price = CAST(@price AS DECIMAL(10,2));

-- 处理固定宽度格式
LOAD DATA INFILE '/data/fixed_width.txt'
INTO TABLE customers
(
    @row
)
SET 
    customer_id = TRIM(SUBSTRING(@row, 1, 10)),
    customer_name = TRIM(SUBSTRING(@row, 11, 20)),
    phone = TRIM(SUBSTRING(@row, 31, 15));
```

---

## 3. 📋 JSON数据导入与处理


### 3.1 JSON格式基础


**什么是JSON**：
```
JSON全称：JavaScript Object Notation
本质：基于键值对的文本数据格式
特点：结构化、嵌套支持、现代应用标准

基本结构：
{
  "name": "张三",
  "age": 28,
  "skills": ["Java", "Python", "MySQL"],
  "address": {
    "city": "上海",
    "district": "徐汇区"
  }
}
```

**JSON vs CSV对比**：
```
JSON优势：
✅ 支持嵌套结构（对象、数组）
✅ 数据类型明确（字符串、数字、布尔）
✅ 自描述性强，字段含义清晰
✅ 现代API标准格式

CSV优势：
✅ 格式简单，处理速度快
✅ Excel直接支持
✅ 文件体积小
✅ 所有系统都能处理
```

### 3.2 JSON_TABLE函数导入技术


> 🔥 **核心技术**  
> **JSON_TABLE函数**：MySQL 8.0引入的强大JSON处理函数，可以将JSON数据直接转换为表格形式

**JSON_TABLE基本语法**：
```sql
JSON_TABLE(
    json_data,                    -- JSON数据源
    path_expression               -- JSON路径表达式
    COLUMNS (                     -- 列定义
        column_name datatype PATH json_path,
        ...
    )
)
```

**简单JSON数据导入**：
```sql
-- 假设有JSON数据
SET @json_data = '
[
  {"name": "张三", "age": 28, "email": "zhang@email.com"},
  {"name": "李四", "age": 32, "email": "li@email.com"},
  {"name": "王五", "age": 25, "email": "wang@email.com"}
]';

-- 使用JSON_TABLE解析并插入
INSERT INTO employees (name, age, email)
SELECT name, age, email
FROM JSON_TABLE(@json_data, '$[*]'     -- $[*]表示数组中的每个元素
    COLUMNS (
        name VARCHAR(50) PATH '$.name',
        age INT PATH '$.age',
        email VARCHAR(100) PATH '$.email'
    )
) AS jt;
```

**复杂嵌套JSON处理**：
```sql
-- 复杂JSON示例
SET @complex_json = '
{
  "department": "技术部",
  "employees": [
    {
      "basic_info": {
        "name": "张三",
        "age": 28
      },
      "contact": {
        "email": "zhang@email.com",
        "phone": "13800138000"
      },
      "skills": ["Java", "Python", "MySQL"]
    }
  ]
}';

-- 解析嵌套JSON结构
INSERT INTO employee_details (name, age, email, phone, skills)
SELECT 
    basic_name,
    basic_age,
    contact_email,
    contact_phone,
    JSON_ARRAYAGG(skill_item) as skills
FROM JSON_TABLE(@complex_json, '$.employees[*]'
    COLUMNS (
        basic_name VARCHAR(50) PATH '$.basic_info.name',
        basic_age INT PATH '$.basic_info.age',
        contact_email VARCHAR(100) PATH '$.contact.email',
        contact_phone VARCHAR(20) PATH '$.contact.phone',
        NESTED PATH '$.skills[*]' COLUMNS (
            skill_item VARCHAR(50) PATH '$'
        )
    )
) AS jt
GROUP BY basic_name, basic_age, contact_email, contact_phone;
```

### 3.3 JSON文件导入实践


**从文件导入JSON数据**：
```sql
-- 步骤1：将JSON文件内容读取到变量
SET @json_content = LOAD_FILE('/data/employees.json');

-- 步骤2：验证JSON格式
SELECT JSON_VALID(@json_content) as is_valid_json;

-- 步骤3：解析并导入
INSERT INTO employees (name, age, department, skills_json)
SELECT 
    name,
    age,
    department,
    JSON_ARRAY(skills) as skills_json
FROM JSON_TABLE(@json_content, '$.employees[*]'
    COLUMNS (
        name VARCHAR(100) PATH '$.name',
        age INT PATH '$.age', 
        department VARCHAR(100) PATH '$.department',
        skills JSON PATH '$.skills'
    )
) AS parsed_data;
```

> ⚠️ **安全提醒**  
> 使用`LOAD_FILE()`需要确保MySQL服务器有文件读取权限，且文件路径安全可信

---

## 4. 🔄 格式转换技术实现


### 4.1 数据格式转换管道


**转换管道概念**：
```
数据转换管道就像工厂流水线：
原材料 → 预处理 → 格式转换 → 质量检查 → 最终产品

CSV/JSON → 解析 → 类型转换 → 验证 → MySQL表
```

**转换管道实现**：
```
┌─────────────┐    ┌─────────────┐    ┌─────────────┐    ┌─────────────┐
│   源数据     │───▶│   解析阶段   │───▶│   转换阶段   │───▶│   存储阶段   │
│ CSV/JSON文件│    │ 字段识别拆分 │    │ 类型转换验证 │    │ 写入MySQL   │
└─────────────┘    └─────────────┘    └─────────────┘    └─────────────┘
       ▲                   ▲                   ▲                   ▲
    文件读取          格式解析          数据清洗          批量写入
```

### 4.2 CSV到MySQL转换实现


**完整转换流程**：
```sql
-- 步骤1：创建源数据临时表（CSV结构）
CREATE TEMPORARY TABLE csv_temp (
    raw_name TEXT,
    raw_age TEXT,
    raw_email TEXT,
    raw_salary TEXT,
    row_number INT AUTO_INCREMENT PRIMARY KEY
);

-- 步骤2：导入CSV原始数据
LOAD DATA INFILE '/data/employees.csv'
INTO TABLE csv_temp
FIELDS TERMINATED BY ','
OPTIONALLY ENCLOSED BY '"'
LINES TERMINATED BY '\n'
IGNORE 1 ROWS
(raw_name, raw_age, raw_email, raw_salary);

-- 步骤3：数据转换和验证
INSERT INTO employees (name, age, email, salary, import_status)
SELECT 
    TRIM(raw_name) as name,
    CASE 
        WHEN raw_age REGEXP '^[0-9]+$' THEN CAST(raw_age AS UNSIGNED)
        ELSE NULL 
    END as age,
    CASE 
        WHEN raw_email REGEXP '^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}$' 
        THEN TRIM(raw_email)
        ELSE NULL 
    END as email,
    CASE 
        WHEN raw_salary REGEXP '^[0-9]+\.?[0-9]*$' 
        THEN CAST(raw_salary AS DECIMAL(10,2))
        ELSE NULL 
    END as salary,
    CASE 
        WHEN raw_age REGEXP '^[0-9]+$' 
         AND raw_email REGEXP '^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}$'
         AND raw_salary REGEXP '^[0-9]+\.?[0-9]*$'
        THEN 'SUCCESS'
        ELSE 'ERROR'
    END as import_status
FROM csv_temp;
```

### 4.3 JSON到MySQL转换实现


**JSON数据标准化处理**：
```sql
-- 创建JSON处理存储过程
DELIMITER //
CREATE PROCEDURE ProcessJSONEmployee(IN json_data JSON)
BEGIN
    DECLARE done INT DEFAULT FALSE;
    DECLARE emp_name VARCHAR(100);
    DECLARE emp_age INT;
    DECLARE emp_skills JSON;
    
    -- 提取基础信息
    SET emp_name = JSON_UNQUOTE(JSON_EXTRACT(json_data, '$.name'));
    SET emp_age = JSON_EXTRACT(json_data, '$.age');
    SET emp_skills = JSON_EXTRACT(json_data, '$.skills');
    
    -- 插入主表
    INSERT INTO employees (name, age) VALUES (emp_name, emp_age);
    SET @emp_id = LAST_INSERT_ID();
    
    -- 处理技能数组
    SET @skill_count = JSON_LENGTH(emp_skills);
    SET @i = 0;
    
    WHILE @i < @skill_count DO
        SET @skill = JSON_UNQUOTE(JSON_EXTRACT(emp_skills, CONCAT('$[', @i, ']')));
        INSERT INTO employee_skills (employee_id, skill_name) 
        VALUES (@emp_id, @skill);
        SET @i = @i + 1;
    END WHILE;
END //
DELIMITER ;
```

---

## 5. 🔤 特殊字符与编码处理


### 5.1 Unicode字符处理技术


**字符编码基础**：
```
常见编码格式：
UTF-8：可变长度，1-4字节，兼容ASCII
UTF-16：固定长度，2字节，Windows常用
GBK：中文编码，2字节，国标扩展
ASCII：基础英文，1字节，最兼容

MySQL字符集：
utf8：最大3字节，不支持emoji
utf8mb4：最大4字节，完全支持Unicode
```

> 📌 **重要提醒**  
> 现代应用**必须使用utf8mb4字符集**，因为utf8无法存储emoji和部分中文字符

**字符集转换处理**：
```sql
-- 检查CSV文件编码
SELECT 
    CHARSET(raw_data) as file_charset,
    LENGTH(raw_data) as byte_length,
    CHAR_LENGTH(raw_data) as char_length
FROM csv_temp 
LIMIT 1;

-- 转换字符编码
LOAD DATA INFILE '/data/chinese_data.csv'
INTO TABLE products
CHARACTER SET utf8mb4              -- 指定文件字符集
FIELDS TERMINATED BY ','
OPTIONALLY ENCLOSED BY '"'
LINES TERMINATED BY '\n'
(product_name, description, price);
```

### 5.2 特殊字符转义处理


**转义字符处理表**：

| **特殊字符** | **含义** | **转义方式** | **处理示例** |
|-------------|---------|-------------|-------------|
| `\"` | 双引号 | `\\\"` | `"产品\"限量版\""` |
| `\n` | 换行符 | `\\n` | `"第一行\\n第二行"` |
| `\r` | 回车符 | `\\r` | `"Windows\\r\\n"` |
| `\t` | 制表符 | `\\t` | `"字段1\\t字段2"` |
| `\\` | 反斜杠 | `\\\\` | `"路径C:\\\\data"` |

**实际处理示例**：
```sql
-- 处理包含特殊字符的CSV
LOAD DATA INFILE '/data/special_chars.csv'
INTO TABLE product_descriptions
FIELDS 
    TERMINATED BY ','
    OPTIONALLY ENCLOSED BY '"'
    ESCAPED BY '\\'               -- 指定转义字符
LINES TERMINATED BY '\n'
(product_name, @raw_description)
SET description = REPLACE(
    REPLACE(
        REPLACE(@raw_description, '\\n', '\n'),  -- 转换换行符
        '\\t', '\t'),                           -- 转换制表符
    '\\"', '"');                                -- 转换引号
```

### 5.3 多语言字符处理


**国际化字符处理**：
```sql
-- 创建支持多语言的表
CREATE TABLE international_products (
    id INT AUTO_INCREMENT PRIMARY KEY,
    name_en VARCHAR(200) CHARACTER SET utf8mb4,     -- 英文名称
    name_zh VARCHAR(200) CHARACTER SET utf8mb4,     -- 中文名称
    name_ja VARCHAR(200) CHARACTER SET utf8mb4,     -- 日文名称
    emoji_tags TEXT CHARACTER SET utf8mb4,          -- emoji标签
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;

-- 导入多语言CSV数据
LOAD DATA INFILE '/data/multilang_products.csv'
INTO TABLE international_products
CHARACTER SET utf8mb4
FIELDS TERMINATED BY ','
OPTIONALLY ENCLOSED BY '"'
LINES TERMINATED BY '\n'
IGNORE 1 ROWS
(name_en, name_zh, name_ja, emoji_tags);
```

---

## 6. 🎯 数据类型映射策略


### 6.1 CSV到MySQL类型映射


**基础类型映射表**：

| **CSV数据表现** | **MySQL类型** | **转换方法** | **示例** |
|----------------|--------------|-------------|----------|
| `123` | `INT` | `CAST(field AS SIGNED)` | `"28" → 28` |
| `123.45` | `DECIMAL` | `CAST(field AS DECIMAL(10,2))` | `"8000.50" → 8000.50` |
| `"true"/"false"` | `BOOLEAN` | `CASE WHEN field='true' THEN 1 ELSE 0 END` | `"true" → 1` |
| `"2023-06-15"` | `DATE` | `STR_TO_DATE(field, '%Y-%m-%d')` | `"2023-06-15" → DATE` |
| `"文本内容"` | `VARCHAR/TEXT` | `TRIM(field)` | `" 张三 " → "张三"` |

**智能类型检测**：
```sql
-- 自动检测数据类型的函数
DELIMITER //
CREATE FUNCTION detect_data_type(input_value TEXT) RETURNS VARCHAR(20)
READS SQL DATA
DETERMINISTIC
BEGIN
    DECLARE result VARCHAR(20) DEFAULT 'TEXT';
    
    -- 检测整数
    IF input_value REGEXP '^-?[0-9]+$' THEN
        SET result = 'INTEGER';
    -- 检测小数
    ELSEIF input_value REGEXP '^-?[0-9]+\.[0-9]+$' THEN
        SET result = 'DECIMAL';
    -- 检测日期
    ELSEIF input_value REGEXP '^[0-9]{4}-[0-9]{2}-[0-9]{2}$' THEN
        SET result = 'DATE';
    -- 检测布尔值
    ELSEIF UPPER(input_value) IN ('TRUE', 'FALSE', 'YES', 'NO', '1', '0') THEN
        SET result = 'BOOLEAN';
    -- 检测邮箱
    ELSEIF input_value REGEXP '^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}$' THEN
        SET result = 'EMAIL';
    END IF;
    
    RETURN result;
END //
DELIMITER ;
```

### 6.2 JSON到MySQL类型映射


**JSON类型映射策略**：
```sql
-- JSON数据类型识别
SELECT 
    JSON_TYPE('123') as type1,           -- INTEGER
    JSON_TYPE('"hello"') as type2,       -- STRING  
    JSON_TYPE('true') as type3,          -- BOOLEAN
    JSON_TYPE('[1,2,3]') as type4,       -- ARRAY
    JSON_TYPE('{"a":1}') as type5;       -- OBJECT

-- 根据JSON类型进行转换
INSERT INTO flexible_table (id, data_value, data_type)
SELECT 
    row_number() OVER() as id,
    CASE JSON_TYPE(json_value)
        WHEN 'INTEGER' THEN CAST(JSON_UNQUOTE(json_value) AS CHAR)
        WHEN 'STRING' THEN JSON_UNQUOTE(json_value)
        WHEN 'BOOLEAN' THEN IF(JSON_EXTRACT(json_value, '$') = true, 'true', 'false')
        WHEN 'ARRAY' THEN JSON_UNQUOTE(json_value)
        WHEN 'OBJECT' THEN JSON_UNQUOTE(json_value)
        ELSE 'NULL'
    END as data_value,
    JSON_TYPE(json_value) as data_type
FROM JSON_TABLE(@json_data, '$.*' COLUMNS (json_value JSON PATH '$')) AS jt;
```

### 6.3 类型转换错误处理


**安全的类型转换**：
```sql
-- 创建错误处理包装函数
DELIMITER //
CREATE FUNCTION safe_cast_int(input_value TEXT) RETURNS INT
READS SQL DATA
DETERMINISTIC
BEGIN
    DECLARE result INT DEFAULT NULL;
    DECLARE continue_handler CONDITION FOR SQLSTATE '22001';
    
    DECLARE CONTINUE HANDLER FOR continue_handler
    BEGIN
        SET result = NULL;
    END;
    
    IF input_value REGEXP '^-?[0-9]+$' THEN
        SET result = CAST(input_value AS SIGNED);
    END IF;
    
    RETURN result;
END //
DELIMITER ;

-- 使用安全转换函数
INSERT INTO employees (name, age, salary)
SELECT 
    name,
    safe_cast_int(raw_age) as age,
    CASE 
        WHEN raw_salary REGEXP '^[0-9]+\.?[0-9]*$' 
        THEN CAST(raw_salary AS DECIMAL(10,2))
        ELSE 0.00 
    END as salary
FROM csv_temp
WHERE safe_cast_int(raw_age) IS NOT NULL;  -- 只导入年龄有效的记录
```

---

## 7. ✅ 格式验证与错误处理


### 7.1 数据格式验证机制


**为什么需要格式验证**：
```
数据来源多样：不同系统导出的数据格式可能不一致
人为错误：手工编辑的CSV/JSON可能有格式错误
系统兼容：确保数据符合MySQL的约束要求
业务规则：满足具体业务的数据要求

验证的价值：
✅ 避免脏数据进入系统
✅ 提前发现数据问题
✅ 保证数据质量
✅ 减少后期处理成本
```

**多层次验证策略**：
```
第1层：格式验证 → 文件能否正确解析
第2层：结构验证 → 字段数量和名称是否匹配
第3层：类型验证 → 数据类型是否符合要求
第4层：业务验证 → 数据是否符合业务规则
第5层：约束验证 → 是否满足数据库约束
```

### 7.2 CSV格式验证实现


**CSV结构验证**：
```sql
-- 创建验证日志表
CREATE TABLE import_validation_log (
    id INT AUTO_INCREMENT PRIMARY KEY,
    file_name VARCHAR(255),
    row_number INT,
    error_type ENUM('FORMAT', 'TYPE', 'BUSINESS', 'CONSTRAINT'),
    error_message TEXT,
    raw_data TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- CSV行级验证存储过程
DELIMITER //
CREATE PROCEDURE ValidateCSVRow(
    IN row_data TEXT,
    IN row_num INT,
    IN file_name VARCHAR(255)
)
BEGIN
    DECLARE field_count INT;
    DECLARE expected_fields INT DEFAULT 4;  -- 期望4个字段
    
    -- 计算字段数量
    SET field_count = (CHAR_LENGTH(row_data) - CHAR_LENGTH(REPLACE(row_data, ',', ''))) + 1;
    
    -- 字段数量验证
    IF field_count != expected_fields THEN
        INSERT INTO import_validation_log 
        (file_name, row_number, error_type, error_message, raw_data)
        VALUES (file_name, row_num, 'FORMAT', 
                CONCAT('字段数量错误，期望', expected_fields, '个，实际', field_count, '个'), 
                row_data);
    END IF;
    
    -- 引号匹配验证
    IF (CHAR_LENGTH(row_data) - CHAR_LENGTH(REPLACE(row_data, '"', ''))) % 2 != 0 THEN
        INSERT INTO import_validation_log 
        (file_name, row_number, error_type, error_message, raw_data)
        VALUES (file_name, row_num, 'FORMAT', '引号不匹配', row_data);
    END IF;
END //
DELIMITER ;
```

### 7.3 JSON格式验证实现


**JSON有效性验证**：
```sql
-- JSON格式验证函数
DELIMITER //
CREATE FUNCTION validate_json_employee(json_data JSON) RETURNS TEXT
READS SQL DATA
DETERMINISTIC
BEGIN
    DECLARE validation_result TEXT DEFAULT '';
    DECLARE required_fields JSON DEFAULT JSON_ARRAY('name', 'age', 'email');
    DECLARE field_count INT;
    DECLARE i INT DEFAULT 0;
    DECLARE current_field VARCHAR(50);
    
    -- 检查必需字段
    SET field_count = JSON_LENGTH(required_fields);
    
    WHILE i < field_count DO
        SET current_field = JSON_UNQUOTE(JSON_EXTRACT(required_fields, CONCAT('$[', i, ']')));
        
        IF JSON_EXTRACT(json_data, CONCAT('$.', current_field)) IS NULL THEN
            SET validation_result = CONCAT(validation_result, '缺少必需字段: ', current_field, '; ');
        END IF;
        
        SET i = i + 1;
    END WHILE;
    
    -- 检查数据类型
    IF JSON_TYPE(JSON_EXTRACT(json_data, '$.age')) != 'INTEGER' THEN
        SET validation_result = CONCAT(validation_result, '年龄必须是整数; ');
    END IF;
    
    IF JSON_EXTRACT(json_data, '$.age') < 0 OR JSON_EXTRACT(json_data, '$.age') > 150 THEN
        SET validation_result = CONCAT(validation_result, '年龄范围无效; ');
    END IF;
    
    RETURN CASE 
        WHEN validation_result = '' THEN 'VALID'
        ELSE validation_result
    END;
END //
DELIMITER ;

-- 使用验证函数
SELECT 
    employee_data,
    validate_json_employee(employee_data) as validation_status
FROM json_temp
WHERE validate_json_employee(employee_data) != 'VALID';
```

### 7.4 错误处理与恢复策略


**错误分类处理**：
```sql
-- 错误处理策略配置
CREATE TABLE import_error_policy (
    error_type VARCHAR(50) PRIMARY KEY,
    action ENUM('SKIP', 'DEFAULT', 'STOP', 'MANUAL') DEFAULT 'SKIP',
    default_value TEXT,
    description TEXT
);

-- 插入错误处理策略
INSERT INTO import_error_policy VALUES
('INVALID_AGE', 'DEFAULT', '0', '年龄无效时设为0'),
('INVALID_EMAIL', 'SKIP', NULL, '邮箱无效时跳过该行'),
('MISSING_NAME', 'STOP', NULL, '姓名缺失时停止导入'),
('INVALID_SALARY', 'DEFAULT', '0.00', '薪资无效时设为0');

-- 根据策略处理错误
INSERT INTO employees (name, age, email, salary, import_notes)
SELECT 
    CASE 
        WHEN TRIM(raw_name) = '' THEN NULL  -- 触发MISSING_NAME策略
        ELSE TRIM(raw_name)
    END as name,
    CASE 
        WHEN raw_age NOT REGEXP '^[0-9]+$' THEN 0    -- 应用INVALID_AGE策略
        ELSE CAST(raw_age AS UNSIGNED)
    END as age,
    CASE 
        WHEN raw_email NOT REGEXP '^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}$' 
        THEN NULL  -- 应用INVALID_EMAIL策略，跳过
        ELSE raw_email
    END as email,
    CASE 
        WHEN raw_salary NOT REGEXP '^[0-9]+\.?[0-9]*$' THEN 0.00  -- 应用INVALID_SALARY策略
        ELSE CAST(raw_salary AS DECIMAL(10,2))
    END as salary,
    '数据已根据错误策略处理' as import_notes
FROM csv_temp
WHERE TRIM(raw_name) != '';  -- 应用MISSING_NAME策略，姓名为空则不导入
```

---

## 8. ⚡ 批量格式处理优化


### 8.1 大文件处理策略


**为什么需要批量处理**：
```
大文件挑战：
📊 文件过大：几GB的CSV文件一次性处理内存不够
⏰ 时间过长：千万条记录处理需要很长时间
🔒 锁表风险：长时间占用表锁影响业务
💾 资源占用：大量内存和CPU资源消耗

批量处理的价值：
✅ 内存可控：分批处理，避免内存溢出
✅ 时间分散：分时段处理，不影响业务
✅ 进度可控：可以监控进度，支持断点续传
✅ 错误隔离：单批错误不影响其他批次
```

**分批处理实现**：
```sql
-- 创建批量处理控制表
CREATE TABLE batch_import_control (
    batch_id INT AUTO_INCREMENT PRIMARY KEY,
    file_name VARCHAR(255),
    batch_size INT DEFAULT 1000,
    current_offset INT DEFAULT 0,
    total_rows INT,
    processed_rows INT DEFAULT 0,
    status ENUM('PENDING', 'PROCESSING', 'COMPLETED', 'ERROR') DEFAULT 'PENDING',
    start_time TIMESTAMP NULL,
    end_time TIMESTAMP NULL,
    error_message TEXT
);

-- 分批导入存储过程
DELIMITER //
CREATE PROCEDURE BatchImportCSV(
    IN p_file_path VARCHAR(500),
    IN p_batch_size INT DEFAULT 1000
)
BEGIN
    DECLARE v_batch_id INT;
    DECLARE v_offset INT DEFAULT 0;
    DECLARE v_processed INT DEFAULT 0;
    DECLARE done INT DEFAULT FALSE;
    
    -- 创建批次记录
    INSERT INTO batch_import_control (file_name, batch_size, start_time, status)
    VALUES (p_file_path, p_batch_size, NOW(), 'PROCESSING');
    SET v_batch_id = LAST_INSERT_ID();
    
    -- 分批处理循环
    batch_loop: LOOP
        -- 创建临时表存储当前批次
        DROP TEMPORARY TABLE IF EXISTS current_batch;
        CREATE TEMPORARY TABLE current_batch (
            row_id INT AUTO_INCREMENT PRIMARY KEY,
            raw_line TEXT
        );
        
        -- 导入当前批次数据（这里简化，实际需要使用外部脚本控制）
        SET @sql = CONCAT(
            'LOAD DATA INFILE ''', p_file_path, ''' ',
            'INTO TABLE current_batch ',
            'LINES TERMINATED BY ''\n'' ',
            'IGNORE ', v_offset, ' ROWS ',
            '(raw_line) '
        );
        
        PREPARE stmt FROM @sql;
        EXECUTE stmt;
        DEALLOCATE PREPARE stmt;
        
        -- 检查是否还有数据
        SELECT COUNT(*) INTO @batch_count FROM current_batch;
        IF @batch_count = 0 THEN
            LEAVE batch_loop;
        END IF;
        
        -- 处理当前批次
        INSERT INTO employees (name, age, email, batch_id)
        SELECT 
            SUBSTRING_INDEX(SUBSTRING_INDEX(raw_line, ',', 1), ',', -1) as name,
            CAST(SUBSTRING_INDEX(SUBSTRING_INDEX(raw_line, ',', 2), ',', -1) AS UNSIGNED) as age,
            SUBSTRING_INDEX(SUBSTRING_INDEX(raw_line, ',', 3), ',', -1) as email,
            v_batch_id
        FROM current_batch
        WHERE raw_line REGEXP '^[^,]+,[0-9]+,[^,]+@[^,]+$';  -- 基础格式验证
        
        -- 更新进度
        SET v_processed = v_processed + @batch_count;
        SET v_offset = v_offset + p_batch_size;
        
        UPDATE batch_import_control 
        SET processed_rows = v_processed 
        WHERE batch_id = v_batch_id;
        
        -- 避免无限循环
        IF @batch_count < p_batch_size THEN
            LEAVE batch_loop;
        END IF;
    END LOOP;
    
    -- 完成导入
    UPDATE batch_import_control 
    SET status = 'COMPLETED', end_time = NOW() 
    WHERE batch_id = v_batch_id;
END //
DELIMITER ;
```

### 8.2 并行处理优化


**并行导入策略**：
```sql
-- 文件分片处理
-- 将大文件拆分成多个小文件并行处理
CREATE TABLE file_shards (
    shard_id INT AUTO_INCREMENT PRIMARY KEY,
    original_file VARCHAR(255),
    shard_file VARCHAR(255),
    start_line INT,
    end_line INT,
    status ENUM('PENDING', 'PROCESSING', 'COMPLETED') DEFAULT 'PENDING',
    worker_id VARCHAR(50),
    process_time TIMESTAMP NULL
);

-- 创建并行工作任务
INSERT INTO file_shards (original_file, shard_file, start_line, end_line)
VALUES 
('large_data.csv', 'large_data_part1.csv', 1, 100000),
('large_data.csv', 'large_data_part2.csv', 100001, 200000),
('large_data.csv', 'large_data_part3.csv', 200001, 300000);

-- 工作进程认领任务
UPDATE file_shards 
SET status = 'PROCESSING', worker_id = CONNECTION_ID(), process_time = NOW()
WHERE status = 'PENDING' 
LIMIT 1;
```

### 8.3 内存优化技术


**流式处理技术**：
```sql
-- 流式JSON处理（逐行解析）
DELIMITER //
CREATE PROCEDURE StreamProcessJSONFile(IN file_path VARCHAR(500))
BEGIN
    DECLARE json_line TEXT;
    DECLARE line_count INT DEFAULT 0;
    DECLARE continue_reading INT DEFAULT TRUE;
    
    -- 打开文件游标（伪代码，实际需要配合外部脚本）
    WHILE continue_reading DO
        -- 读取一行JSON
        SET json_line = read_next_line(file_path);
        
        IF json_line IS NULL THEN
            SET continue_reading = FALSE;
        ELSE
            SET line_count = line_count + 1;
            
            -- 验证JSON格式
            IF JSON_VALID(json_line) THEN
                -- 解析并插入单行数据
                INSERT INTO employees (name, age, email)
                SELECT name, age, email
                FROM JSON_TABLE(json_line, '$'
                    COLUMNS (
                        name VARCHAR(100) PATH '$.name',
                        age INT PATH '$.age',
                        email VARCHAR(100) PATH '$.email'
                    )
                ) AS jt;
            ELSE
                -- 记录格式错误
                INSERT INTO import_validation_log 
                (file_name, row_number, error_type, error_message, raw_data)
                VALUES (file_path, line_count, 'FORMAT', 'JSON格式无效', json_line);
            END IF;
            
            -- 每1000行提交一次
            IF line_count % 1000 = 0 THEN
                COMMIT;
            END IF;
        END IF;
    END WHILE;
END //
DELIMITER ;
```

### 8.4 性能监控与优化


**导入性能监控**：
```sql
-- 性能监控表
CREATE TABLE import_performance_log (
    id INT AUTO_INCREMENT PRIMARY KEY,
    operation_type VARCHAR(50),       -- CSV, JSON, EXCEL等
    file_size_mb DECIMAL(10,2),      -- 文件大小MB
    record_count INT,                 -- 记录数量
    process_time_seconds INT,         -- 处理时间秒
    throughput_records_per_sec DECIMAL(10,2),  -- 每秒处理记录数
    memory_usage_mb DECIMAL(10,2),    -- 内存使用MB
    cpu_usage_percent DECIMAL(5,2),   -- CPU使用率
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 性能优化配置
SET SESSION bulk_insert_buffer_size = 256 * 1024 * 1024;  -- 256MB
SET SESSION read_buffer_size = 8 * 1024 * 1024;           -- 8MB
SET SESSION innodb_buffer_pool_size = 1024 * 1024 * 1024; -- 1GB

-- 禁用索引加速导入
ALTER TABLE employees DISABLE KEYS;
-- 执行大批量导入
LOAD DATA INFILE '/data/large_file.csv' INTO TABLE employees ...;
-- 重建索引
ALTER TABLE employees ENABLE KEYS;
```

**性能优化技巧**：

| **优化技术** | **作用原理** | **适用场景** | **性能提升** |
|-------------|-------------|-------------|-------------|
| **关闭索引** | 导入时不更新索引 | 大批量数据导入 | 3-5倍 |
| **调整缓冲区** | 增加内存使用 | 大文件处理 | 2-3倍 |
| **事务批量提交** | 减少磁盘写入 | 高频小事务 | 10-20倍 |
| **并行分片** | 多进程同时处理 | 超大文件 | 线性扩展 |

---

## 9. 📋 核心要点总结


### 9.1 必须掌握的核心概念


```
🔸 数据格式处理：不同格式数据转换为MySQL可识别格式的过程
🔸 CSV处理：文本格式，简单高效，需要注意引号和特殊字符
🔸 JSON处理：结构化格式，功能强大，MySQL 8.0原生支持
🔸 格式转换：建立数据处理管道，确保转换质量和效率
🔸 编码处理：Unicode字符正确处理，避免乱码问题
🔸 类型映射：源数据类型到MySQL类型的正确转换
🔸 格式验证：多层次验证确保数据质量
🔸 批量优化：大数据量处理的性能优化策略
```

### 9.2 关键技术要点


**🔹 CSV处理核心技术**
```
LOAD DATA INFILE：最高效的CSV导入方法
字段引号处理：OPTIONALLY ENCLOSED BY '"'
特殊字符转义：ESCAPED BY '\\'
批量处理：分批导入避免资源耗尽
数据验证：多层次验证保证质量
```

**🔹 JSON处理核心技术**
```
JSON_TABLE函数：将JSON转换为表格形式
JSON路径表达式：精确提取嵌套数据
JSON类型检测：JSON_TYPE函数判断数据类型
嵌套数据处理：NESTED PATH处理复杂结构
JSON验证：JSON_VALID确保格式正确
```

**🔹 格式转换核心策略**
```
转换管道：解析 → 转换 → 验证 → 存储
类型映射：根据数据特征选择合适的MySQL类型
错误处理：分级处理不同类型的错误
性能优化：批量处理、索引控制、参数调优
```

### 9.3 实际应用价值


**📊 业务场景应用**
- **数据迁移**：老系统CSV导出到新MySQL系统
- **第三方集成**：API JSON数据批量导入处理
- **报表处理**：Excel报表数据格式化导入
- **数据清洗**：原始数据格式标准化处理

**🔧 技术实践价值**
- **自动化处理**：减少人工数据处理工作量
- **质量保证**：通过验证机制确保数据准确性
- **性能优化**：大数据量处理的工程化方案
- **错误恢复**：完善的错误处理和恢复机制

> 📚 **学习建议**  
> 1. 先掌握基础的CSV和JSON格式特点
> 2. 练习使用LOAD DATA INFILE和JSON_TABLE函数
> 3. 理解字符编码和特殊字符处理
> 4. 掌握数据验证和错误处理机制
> 5. 最后学习大数据量的性能优化技术

**核心记忆口诀**：
- CSV简单快速用LOAD DATA，JSON结构化用JSON_TABLE
- 字符编码用utf8mb4，特殊字符要转义
- 数据验证分层次，错误处理要完善
- 大文件分批处理，性能优化是关键