---
title: 1、抓取配置详解
---
## 📚 目录

1. [抓取配置概述](#1-抓取配置概述)
2. [scrape_configs配置块](#2-scrape_configs配置块)
3. [job_name与实例概念](#3-job_name与实例概念)
4. [采集频率与超时设置](#4-采集频率与超时设置)
5. [路径配置详解](#5-路径配置详解)
6. [标签重写规则](#6-标签重写规则)
7. [完整配置示例](#7-完整配置示例)
8. [核心要点总结](#8-核心要点总结)

---

## 1. 🎯 抓取配置概述


### 1.1 什么是抓取配置


**通俗理解**：抓取配置就像是给Prometheus安排工作任务的时间表

```
类比现实生活：
监控系统 = 巡逻保安
抓取配置 = 巡逻路线和时间安排
- 几点去哪里巡逻
- 多久巡逻一次  
- 巡逻哪些地点
- 遇到问题怎么处理
```

**核心作用**：
- 🎯 **告诉Prometheus去哪里收集数据**
- ⏰ **规定多久收集一次**
- 🛣️ **指定收集数据的具体路径**
- 🏷️ **给收集到的数据打标签分类**

### 1.2 配置在整个监控流程中的位置


```
监控数据流向：
应用程序 → 暴露指标接口 → Prometheus抓取 → 存储 → 查询展示
            ↑
        这里需要抓取配置告诉Prometheus怎么抓取
```

**为什么需要配置**：
- Prometheus不知道你的应用在哪里运行
- 不知道你的监控接口地址是什么
- 不知道你希望多久收集一次数据
- 抓取配置就是解决这些"不知道"的问题

---

## 2. 🔧 scrape_configs配置块


### 2.1 scrape_configs是什么


**简单理解**：`scrape_configs`就是一个任务清单，里面列出了所有要做的监控工作

```yaml
# prometheus.yml 文件结构
global:           # 全局设置
  scrape_interval: 15s

scrape_configs:   # 这里是重点！所有的抓取任务都在这里定义
  - job_name: 'web-servers'     # 第一个任务
    static_configs:
      - targets: ['192.168.1.10:8080']
      
  - job_name: 'databases'       # 第二个任务  
    static_configs:
      - targets: ['192.168.1.20:9100']
```

### 2.2 配置块的基本结构


**每个scrape_config包含的要素**：

| 配置项 | **作用** | **必填** | **简单理解** |
|--------|----------|----------|--------------|
| `job_name` | 任务名称 | ✅ | 给这个监控任务起个名字 |
| `static_configs` | 静态目标 | ✅ | 要监控的服务器地址列表 |
| `scrape_interval` | 采集频率 | ❌ | 多久去收集一次数据 |
| `scrape_timeout` | 超时时间 | ❌ | 等多久没响应就放弃 |
| `metrics_path` | 指标路径 | ❌ | 监控数据的具体网址路径 |

### 2.3 最简单的配置示例


```yaml
scrape_configs:
  - job_name: 'my-first-job'
    static_configs:
      - targets: ['localhost:8080']
```

**这个配置的含义**：
- 创建一个名叫`my-first-job`的监控任务
- 去监控本机的8080端口
- 使用默认设置：每15秒收集一次，超时10秒，访问`/metrics`路径

---

## 3. 👥 job_name与实例概念


### 3.1 job_name的作用


**通俗理解**：`job_name`就像是给一组相似的服务器起个团队名字

```
现实类比：
公司里有多个部门：
- 开发部门 (job_name: 'developers')
- 测试部门 (job_name: 'testers')  
- 运维部门 (job_name: 'ops')

每个部门里有多个员工，对应Prometheus中：
每个job里有多个实例(instance)
```

### 3.2 job与instance的关系


```yaml
scrape_configs:
  - job_name: 'web-servers'           # 这是job名称
    static_configs:
      - targets:                      # 这些是instances
          - '192.168.1.10:8080'       # instance 1
          - '192.168.1.11:8080'       # instance 2  
          - '192.168.1.12:8080'       # instance 3
```

**关系图示**：
```
job: web-servers
├── instance: 192.168.1.10:8080
├── instance: 192.168.1.11:8080
└── instance: 192.168.1.12:8080
```

### 3.3 为什么要这样分组


**实际好处**：
- 🏷️ **便于管理**：相同类型的服务放在一起
- 📊 **便于查询**：可以按job查询所有web服务器的数据
- ⚙️ **统一配置**：同一个job里的所有实例使用相同的采集规则
- 🔍 **故障排查**：快速定位是哪个服务出了问题

**查询示例**：
```promql
# 查询web-servers这个job下所有实例的CPU使用率
cpu_usage{job="web-servers"}

# 查询特定实例的内存使用率  
memory_usage{instance="192.168.1.10:8080"}
```

---

## 4. ⏱️ 采集频率与超时设置


### 4.1 scrape_interval采集频率


**通俗理解**：`scrape_interval`就是设置"多久去看一次"

```yaml
scrape_configs:
  - job_name: 'web-app'
    scrape_interval: 30s              # 每30秒采集一次
    static_configs:
      - targets: ['localhost:8080']
```

**时间设置建议**：

| 服务类型 | **建议频率** | **原因** |
|----------|-------------|----------|
| **Web应用** | `15s-30s` | 需要及时发现问题 |
| **数据库** | `10s-15s` | 性能变化较快 |
| **系统监控** | `15s-60s` | 变化相对缓慢 |
| **批处理任务** | `1m-5m` | 运行时间较长 |

### 4.2 scrape_timeout超时设置


**通俗理解**：`scrape_timeout`就是设置"等多久没反应就不等了"

```yaml
scrape_configs:
  - job_name: 'slow-service'
    scrape_interval: 30s
    scrape_timeout: 10s               # 10秒内必须响应
    static_configs:
      - targets: ['slow-server:8080']
```

**超时时间的影响**：
- ⏰ **太短**：可能误判服务响应慢为服务故障
- ⏰ **太长**：会影响Prometheus的整体采集效率
- ✅ **合理设置**：通常为采集间隔的1/3到1/2

### 4.3 全局vs局部设置


```yaml
global:
  scrape_interval: 15s     # 全局默认：每15秒采集一次
  scrape_timeout: 10s      # 全局默认：10秒超时

scrape_configs:
  - job_name: 'fast-check'
    # 使用全局设置：15s间隔，10s超时
    static_configs:
      - targets: ['app1:8080']
      
  - job_name: 'slow-check'  
    scrape_interval: 60s     # 覆盖全局设置：改为60秒
    scrape_timeout: 30s      # 覆盖全局设置：改为30秒
    static_configs:
      - targets: ['app2:8080']
```

**优先级规则**：`job级别配置` > `全局配置`

---

## 5. 🛣️ 路径配置详解


### 5.1 metrics_path是什么


**通俗理解**：`metrics_path`就是告诉Prometheus"数据放在网站的哪个页面"

```
类比网站访问：
网站首页：http://example.com/
关于我们：http://example.com/about
联系我们：http://example.com/contact
监控数据：http://example.com/metrics  ← 这就是metrics_path
```

### 5.2 默认路径与自定义路径


**默认情况**：
```yaml
scrape_configs:
  - job_name: 'default-path'
    static_configs:
      - targets: ['app:8080']
    # 默认会访问：http://app:8080/metrics
```

**自定义路径**：
```yaml
scrape_configs:
  - job_name: 'custom-path'
    metrics_path: '/monitoring/prometheus'    # 自定义路径
    static_configs:
      - targets: ['app:8080']
    # 实际访问：http://app:8080/monitoring/prometheus
```

### 5.3 不同应用的常见路径


| 应用类型 | **默认路径** | **说明** |
|----------|-------------|----------|
| **Spring Boot** | `/actuator/prometheus` | Spring Boot 2.x的默认路径 |
| **Node.js** | `/metrics` | 大多数Node.js应用 |
| **Nginx** | `/nginx_status` | nginx-prometheus-exporter |
| **自定义应用** | `/health/metrics` | 根据开发团队约定 |

**配置示例**：
```yaml
scrape_configs:
  - job_name: 'spring-boot-apps'
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets: 
          - 'user-service:8080'
          - 'order-service:8080'
          
  - job_name: 'nginx-servers'
    metrics_path: '/nginx_status'
    static_configs:
      - targets:
          - 'nginx1:9113'
          - 'nginx2:9113'
```

---

## 6. 🏷️ 标签重写规则


### 6.1 什么是标签重写


**通俗理解**：标签重写就像是给数据贴标签，方便以后查找和分类

```
现实类比：
图书馆管理员给书贴标签：
- 原始信息：《西游记》
- 贴上标签：类型=小说，作者=吴承恩，时代=古典
- 方便查找：想找小说类的书，直接按标签找

Prometheus的标签重写也是这个道理
```

### 6.2 relabel_configs基础用法


**最常用的标签操作**：

```yaml
scrape_configs:
  - job_name: 'web-servers'
    static_configs:
      - targets: ['web1:8080', 'web2:8080']
        labels:
          environment: 'production'     # 给所有target添加环境标签
          team: 'backend'              # 给所有target添加团队标签
```

### 6.3 动态标签添加


**根据实例信息自动添加标签**：

```yaml
scrape_configs:
  - job_name: 'auto-labeled'
    static_configs:
      - targets: 
          - 'prod-web1:8080'
          - 'test-web2:8080'
    relabel_configs:
      # 从实例名称中提取环境信息
      - source_labels: [__address__]
        regex: '(prod|test)-.*'
        target_label: 'environment'
        replacement: '${1}'
```

**这个配置的效果**：
- `prod-web1:8080` → 自动添加 `environment=prod` 标签
- `test-web2:8080` → 自动添加 `environment=test` 标签

### 6.4 常用的重写操作


| 操作类型 | **action值** | **作用** | **使用场景** |
|----------|-------------|----------|--------------|
| **添加标签** | `replace` | 添加或修改标签 | 环境标记、团队标记 |
| **删除目标** | `drop` | 不采集某些目标 | 排除测试服务器 |
| **保留目标** | `keep` | 只采集某些目标 | 只监控生产环境 |
| **删除标签** | `labeldrop` | 删除指定标签 | 清理敏感信息 |

**实用示例**：
```yaml
relabel_configs:
  # 只监控生产环境的服务
  - source_labels: [__meta_consul_tags]
    regex: '.*,prod,.*'
    action: keep
    
  # 给所有MySQL实例添加数据库类型标签  
  - target_label: 'db_type'
    replacement: 'mysql'
    
  # 删除包含敏感信息的标签
  - regex: 'password|secret'
    action: labeldrop
```

---

## 7. 📋 完整配置示例


### 7.1 多环境Web应用监控


```yaml
global:
  scrape_interval: 15s
  scrape_timeout: 10s

scrape_configs:
  # 生产环境Web应用
  - job_name: 'prod-web-apps'
    scrape_interval: 10s          # 生产环境更频繁监控
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets:
          - 'prod-user-service:8080'
          - 'prod-order-service:8080'
          - 'prod-payment-service:8080'
        labels:
          environment: 'production'
          team: 'backend'
          
  # 测试环境Web应用  
  - job_name: 'test-web-apps'
    scrape_interval: 30s          # 测试环境监控频率低一些
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets:
          - 'test-user-service:8080'
          - 'test-order-service:8080'
        labels:
          environment: 'test'
          team: 'backend'
          
  # 数据库监控
  - job_name: 'databases'
    scrape_interval: 15s
    static_configs:
      - targets:
          - 'mysql-exporter:9104'
          - 'redis-exporter:9121'
        labels:
          component: 'database'
          
  # 系统监控
  - job_name: 'system-monitoring'
    scrape_interval: 30s
    static_configs:
      - targets:
          - 'node-exporter-1:9100'
          - 'node-exporter-2:9100'
        labels:
          component: 'system'
```

### 7.2 配置验证与测试


**检查配置语法**：
```bash
# 检查prometheus.yml语法是否正确
./promtool check config prometheus.yml
```

**查看采集目标状态**：
- 访问Prometheus Web界面
- 点击 `Status` → `Targets`
- 查看各个job的采集状态

**状态说明**：
- 🟢 **UP**：采集正常
- 🔴 **DOWN**：无法连接到目标
- 🟡 **UNKNOWN**：刚开始采集，状态未知

---

## 8. 📝 核心要点总结


### 8.1 必须掌握的核心概念


```
🔸 scrape_configs：定义所有监控任务的配置块
🔸 job_name：给监控任务起名字，便于管理和查询
🔸 instance：具体要监控的服务器地址和端口
🔸 scrape_interval：采集频率，决定多久收集一次数据
🔸 scrape_timeout：超时时间，避免卡在慢响应的服务上
🔸 metrics_path：指标路径，告诉Prometheus数据在哪个URL
```

### 8.2 关键理解要点


**🔹 job与instance的关系**
```
一个job = 一类服务的监控任务
一个instance = 具体的一台服务器

例如：
job "web-servers" 包含 3个web服务器实例
job "databases" 包含 2个数据库实例
```

**🔹 配置优先级**
```
局部配置 > 全局配置
job级别的设置会覆盖global级别的设置
```

**🔹 标签的重要性**
```
标签 = 数据分类的依据
好的标签设计 = 方便的查询和告警
常用标签：environment、team、component、region
```

### 8.3 实际应用指导


**✅ 最佳实践**：
- 按业务功能分组定义job_name
- 生产环境采集频率高于测试环境
- 合理设置超时时间，避免影响整体采集
- 统一使用标准的metrics_path约定
- 使用有意义的标签便于后续查询

**❌ 常见错误**：
- job_name重复导致配置冲突
- 采集频率设置过高影响性能
- 超时时间大于采集间隔
- metrics_path配置错误导致404
- 缺少必要的标签影响查询效率

**🔧 实用技巧**：
- 先用最简单的配置测试连通性
- 逐步添加高级功能如标签重写
- 定期检查targets页面确认采集状态
- 使用promtool验证配置文件语法

### 8.4 与其他组件的关系


```
抓取配置 ↔ 服务发现：
动态发现目标，自动更新配置

抓取配置 ↔ 告警规则：
标签设计影响告警规则的编写

抓取配置 ↔ 查询语句：
job和instance是查询的重要维度
```

**核心记忆**：
- 抓取配置是Prometheus工作的基础
- job管理一类服务，instance指向具体服务器  
- 合理的采集频率和超时设置很重要
- 标签设计影响后续的查询和告警效果