---
title: 3、故障排查手册
---
## 📚 目录

1. [故障排查基础](#1-故障排查基础)
2. [常见错误类型分析](#2-常见错误类型分析)
3. [内存与存储问题](#3-内存与存储问题)
4. [网络连通性问题](#4-网络连通性问题)
5. [配置错误排查](#5-配置错误排查)
6. [性能瓶颈定位](#6-性能瓶颈定位)
7. [日志分析方法](#7-日志分析方法)
8. [核心要点总结](#8-核心要点总结)

---

## 1. 🔍 故障排查基础


### 1.1 什么是故障排查


**💡 通俗理解**
```
监控系统就像医生体检：
- 正常时：默默工作，定期检查
- 异常时：发出警报，需要"诊断治疗"
- 故障排查：就是给监控系统"看病"的过程
```

**🎯 故障排查的核心思路**
```
问题定位的"5W1H"方法：
What？  - 什么问题？（现象是什么）
When？  - 什么时候？（何时开始的）
Where？ - 哪里出错？（哪个组件）
Who？   - 谁受影响？（影响范围）
Why？   - 为什么？（根本原因）
How？   - 怎么解决？（解决方案）
```

### 1.2 故障排查流程


```
故障发现 → 现象确认 → 初步定位 → 深入分析 → 解决验证 → 复盘总结
    ↓         ↓         ↓         ↓         ↓         ↓
  告警通知   收集信息   缩小范围   找到原因   修复问题   预防措施
```

**🔧 标准排查步骤**
```
第一步：确认问题
✓ 症状是什么？
✓ 影响范围多大？
✓ 紧急程度如何？

第二步：收集信息
✓ 查看监控面板
✓ 检查日志文件
✓ 确认配置变更

第三步：分析定位
✓ 从症状推断原因
✓ 验证假设
✓ 缩小问题范围

第四步：解决验证
✓ 实施解决方案
✓ 验证问题解决
✓ 监控恢复情况
```

---

## 2. ⚠️ 常见错误类型分析


### 2.1 "Too many samples" 问题


**💡 什么是"Too many samples"？**
```
简单理解：就像餐厅一下子来了太多客人
- Prometheus 一次采集到的数据点超过了限制
- 默认限制通常是 200万个样本点
- 超过限制就会拒绝这批数据
```

**🔍 问题表现**
```
错误日志示例：
sample limit exceeded, rejecting query

监控面板表现：
- 数据突然中断
- 图表出现空白
- 部分指标消失
```

**🛠️ 解决方案**

**方案1：调整采集配置**
```yaml
# prometheus.yml
global:
  # 降低采集频率
  scrape_interval: 30s      # 从15s改为30s
  
scrape_configs:
  - job_name: 'high-cardinality-app'
    scrape_interval: 60s    # 单独调整某个任务
    static_configs:
      - targets: ['app:8080']
```

**方案2：增加样本限制**
```yaml
# prometheus.yml
global:
  external_labels:
    cluster: 'production'

# 启动参数
--query.max-samples=5000000  # 增加到500万
```

**方案3：减少指标基数**
```
检查高基数指标：
✓ 用户ID作为标签 ❌
✓ 订单号作为标签 ❌  
✓ IP地址作为标签 ❌

正确做法：
✓ 按服务分组 ✅
✓ 按状态码分组 ✅
✓ 按地区分组 ✅
```

### 2.2 指标抓取失败


**🎯 常见抓取错误**

**错误1：连接超时**
```
错误信息：context deadline exceeded

原因分析：
- 目标服务响应慢
- 网络延迟过高
- 防火墙阻拦

解决方法：
scrape_configs:
  - job_name: 'slow-app'
    scrape_timeout: 30s     # 增加超时时间
    scrape_interval: 60s    # 降低抓取频率
```

**错误2：认证失败**
```
错误信息：401 Unauthorized

解决配置：
scrape_configs:
  - job_name: 'secured-app'
    basic_auth:
      username: monitor
      password: secret123
    # 或者使用Bearer Token
    authorization:
      type: Bearer
      credentials: your-token-here
```

**错误3：格式错误**
```
错误信息：expected float as value, got "string"

常见原因：
- 指标值不是数字
- 指标名称不符合规范
- 时间戳格式错误

检查方法：
curl http://target:8080/metrics
```

---

## 3. 💾 内存与存储问题


### 3.1 OOM 内存溢出处理


**💡 为什么会内存溢出？**
```
Prometheus 内存使用就像水池：
- 进水：新数据不断采集
- 蓄水：内存中缓存数据
- 排水：定期写入磁盘
- 溢出：进水太快，排水不及
```

**🔍 OOM 症状识别**
```
系统表现：
✓ Prometheus进程突然重启
✓ 查询变得很慢
✓ 内存使用持续增长
✓ 系统日志有OOM记录

监控指标：
✓ prometheus_tsdb_head_samples 持续增长
✓ go_memstats_alloc_bytes 超过限制
✓ process_resident_memory_bytes 过高
```

**🛠️ 解决方案**

**方案1：增加内存**
```bash
# 调整JVM堆内存（如果使用JVM）
export JAVA_OPTS="-Xmx8g -Xms4g"

# 调整系统内存限制
# 在 docker-compose.yml
services:
  prometheus:
    mem_limit: 8g
    mem_reservation: 4g
```

**方案2：优化数据保留**
```yaml
# prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

# 启动参数
--storage.tsdb.retention.time=15d    # 保留15天
--storage.tsdb.retention.size=10GB   # 最大10GB
--storage.tsdb.wal-compression       # 启用WAL压缩
```

**方案3：减少数据量**
```yaml
# 添加 metric_relabel_configs 过滤不需要的指标
scrape_configs:
  - job_name: 'app'
    static_configs:
      - targets: ['app:8080']
    metric_relabel_configs:
      # 删除高基数指标
      - source_labels: [__name__]
        regex: 'histogram_bucket.*'
        action: drop
      # 只保留重要标签
      - source_labels: [user_id]
        target_label: __tmp_drop
        action: drop
```

### 3.2 磁盘空间爆满


**💡 磁盘问题的影响**
```
磁盘满了就像仓库爆仓：
- 新数据无法存储
- 查询性能下降
- 可能导致数据丢失
- 服务完全停止
```

**🔍 磁盘监控指标**
```bash
# 检查磁盘使用情况
df -h /prometheus-data

# 检查 Prometheus 数据目录
du -sh /prometheus-data/*

# 查看各个时间段数据大小
ls -la /prometheus-data/01*
```

**🛠️ 应急处理**
```bash
# 1. 立即清理老数据
find /prometheus-data -name "01*" -mtime +30 -delete

# 2. 手动压缩数据
prometheus-tsdb compact /prometheus-data

# 3. 调整保留策略
# 重启时添加参数：
--storage.tsdb.retention.time=7d
```

**📊 预防性监控**
```yaml
# 在 Prometheus 中添加磁盘监控
groups:
  - name: disk_alerts
    rules:
      - alert: DiskSpaceWarning
        expr: (node_filesystem_avail_bytes / node_filesystem_size_bytes) < 0.2
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "磁盘空间不足 {{ $labels.instance }}"
          description: "可用空间只剩 {{ $value | humanizePercentage }}"
```

---

## 4. 🌐 网络连通性问题


### 4.1 网络问题诊断思路


**💡 网络问题的层次**
```
网络连接就像快递配送：
第1层：物理连接 - 网线插好了吗？
第2层：IP连通  - 地址能ping通吗？
第3层：端口访问 - 门牌号对吗？
第4层：服务响应 - 有人在家吗？
第5层：数据格式 - 说的是同一种语言吗？
```

### 4.2 基础连通性检查


**🔧 标准检查流程**
```bash
# 第1步：ping 检查基础连通性
ping target-host

# 第2步：telnet 检查端口
telnet target-host 9090

# 第3步：curl 检查HTTP服务
curl -I http://target-host:9090/metrics

# 第4步：检查防火墙
sudo iptables -L | grep 9090
sudo ufw status | grep 9090
```

**🎯 常见网络问题**

**问题1：DNS解析失败**
```bash
# 症状
ping: cannot resolve hostname

# 诊断
nslookup target-host
dig target-host

# 解决
# 1. 检查/etc/hosts
echo "192.168.1.100 target-host" >> /etc/hosts

# 2. 使用IP地址代替域名
static_configs:
  - targets: ['192.168.1.100:9090']
```

**问题2：端口不通**
```bash
# 检查目标端口是否开启
netstat -tlnp | grep 9090
ss -tlnp | grep 9090

# 检查防火墙规则
sudo ufw allow 9090
sudo firewall-cmd --add-port=9090/tcp --permanent
```

### 4.3 服务发现问题


**💡 服务发现就像电话本**
```
静态配置：手工记录电话号码
服务发现：自动更新的电话本
- Consul: 专业的电话本管理员
- K8s API: 集群内部电话本
- 文件发现: 本地电话本文件
```

**🔍 Consul 服务发现问题**
```yaml
# prometheus.yml 配置示例
scrape_configs:
  - job_name: 'consul'
    consul_sd_configs:
      - server: 'consul:8500'
        services: ['web', 'api']
    relabel_configs:
      - source_labels: [__meta_consul_service]
        target_label: service
```

**常见问题排查**
```bash
# 1. 检查 Consul 连接
curl http://consul:8500/v1/agent/self

# 2. 查看注册的服务
curl http://consul:8500/v1/catalog/services

# 3. 检查服务健康状态
curl http://consul:8500/v1/health/service/web
```

---

## 5. ⚙️ 配置错误排查


### 5.1 配置文件验证


**💡 配置错误就像菜谱写错**
```
YAML配置就像做菜的菜谱：
- 缩进错误：盐放成了糖
- 语法错误：看不懂的外语
- 逻辑错误：先放鸡蛋后打散
```

**🔧 配置验证工具**
```bash
# 1. 语法检查
promtool check config prometheus.yml

# 2. 规则文件检查
promtool check rules rules/*.yml

# 3. 查看解析后的配置
curl http://localhost:9090/api/v1/status/config
```

### 5.2 常见配置错误


**错误1：YAML 缩进问题**
```yaml
# ❌ 错误写法
scrape_configs:
- job_name: 'app'
  static_configs:
  - targets: ['app:8080']  # 缩进不对

# ✅ 正确写法  
scrape_configs:
  - job_name: 'app'
    static_configs:
      - targets: ['app:8080']  # 正确缩进
```

**错误2：标签重命名错误**
```yaml
# ❌ 常见错误
relabel_configs:
  - source_labels: [__address__]
    target_label: instance
    replacement: '${1}:9090'    # 错误：没有捕获组

# ✅ 正确写法
relabel_configs:
  - source_labels: [__address__]
    regex: '([^:]+)(:[0-9]+)?'
    target_label: instance  
    replacement: '${1}:9090'    # 正确：使用捕获组
```

**错误3：规则表达式错误**
```yaml
# ❌ 语法错误
groups:
  - name: example
    rules:
      - alert: HighCPU
        expr: cpu_usage > 80    # 错误：指标名可能不存在

# ✅ 验证后的正确写法
groups:
  - name: example  
    rules:
      - alert: HighCPU
        expr: (100 - avg(rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
```

### 5.3 配置热重载


**🔄 如何安全重载配置**
```bash
# 1. 先验证配置
promtool check config prometheus.yml

# 2. 热重载（推荐）
curl -X POST http://localhost:9090/-/reload

# 3. 重启服务（不推荐，会丢失内存数据）
systemctl restart prometheus
```

---

## 6. ⚡ 性能瓶颈定位


### 6.1 性能问题的表现


**💡 性能问题就像交通堵塞**
```
系统性能问题的表现：
- 查询很慢：像开车堵在路上
- 内存占用高：像停车场满了
- CPU使用率高：像发动机超负荷
- 磁盘IO高：像车道太窄
```

### 6.2 查询性能优化


**🔍 慢查询识别**
```bash
# 查看慢查询日志
grep "slow_query" /var/log/prometheus/prometheus.log

# 检查查询统计
curl http://localhost:9090/api/v1/status/tsdb | jq .data.seriesCountByMetricName
```

**🛠️ PromQL 优化技巧**

**优化1：减少时间范围**
```promql
# ❌ 低效查询（范围太大）
rate(http_requests_total[1h])

# ✅ 高效查询（合适范围）
rate(http_requests_total[5m])
```

**优化2：使用高效聚合**
```promql
# ❌ 低效（先聚合再计算）
sum(rate(http_requests_total[5m])) by (job)

# ✅ 高效（先计算再聚合）
sum by (job) (rate(http_requests_total[5m]))
```

**优化3：避免高基数分组**
```promql
# ❌ 高基数分组（用户ID太多）
sum by (user_id) (http_requests_total)

# ✅ 低基数分组（按服务分组）
sum by (service) (http_requests_total)
```

### 6.3 系统资源监控


**📊 关键性能指标**
```yaml
# 添加 Prometheus 自监控
scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']
    scrape_interval: 15s

# 重要指标说明：
prometheus_tsdb_head_series          # 内存中的时间序列数
prometheus_tsdb_head_samples_appended_total  # 追加的样本数
prometheus_engine_query_duration_seconds     # 查询耗时
go_memstats_alloc_bytes             # 内存使用量
```

---

## 7. 📋 日志分析方法


### 7.1 日志级别与位置


**💡 日志就像医生的诊断记录**
```
日志级别（从轻到重）：
DEBUG：详细诊断信息（医生的小笔记）
INFO： 正常运行信息（例行检查记录）
WARN： 警告信息（需要注意的异常）
ERROR：错误信息（确实有问题了）
FATAL：致命错误（生命危险！）
```

**🔍 常见日志位置**
```bash
# 系统日志
journalctl -u prometheus -f

# Docker 容器日志
docker logs prometheus -f

# 文件日志（配置的日志路径）
tail -f /var/log/prometheus/prometheus.log
```

### 7.2 关键错误日志分析


**🚨 内存相关错误**
```
错误信息：
out of memory: cannot allocate memory

分析思路：
1. 查看内存使用趋势
2. 检查高基数指标
3. 优化查询复杂度
4. 调整数据保留策略
```

**🚨 存储相关错误**
```
错误信息：
no space left on device

解决步骤：
1. df -h 检查磁盘空间
2. 清理老数据或增加磁盘
3. 调整保留策略
4. 启用数据压缩
```

**🚨 网络相关错误**
```
错误信息：
context deadline exceeded (Client.Timeout exceeded)

诊断方法：
1. ping 检查网络连通性
2. telnet 检查端口可达性  
3. curl 测试HTTP服务
4. 检查防火墙配置
```

### 7.3 日志监控告警


**📢 重要日志告警规则**
```yaml
groups:
  - name: prometheus_logs
    rules:
      - alert: PrometheusErrorRate
        expr: increase(prometheus_notifications_errors_total[5m]) > 0
        for: 0m
        labels:
          severity: warning
        annotations:
          summary: "Prometheus 出现错误"
          description: "{{ $labels.instance }} 在过去5分钟内出现 {{ $value }} 个错误"

      - alert: PrometheusConfigReloadFailed  
        expr: prometheus_config_last_reload_successful == 0
        for: 0m
        labels:
          severity: critical
        annotations:
          summary: "Prometheus 配置重载失败"
          description: "配置文件可能有语法错误"
```

---

## 8. 📋 核心要点总结


### 8.1 故障排查核心思路


**🎯 黄金法则**
```
第一法则：现象 → 原因 → 解决
- 不要猜测，要基于事实
- 一次只改一个变量
- 每次修改都要验证效果

第二法则：从简单到复杂
- 先检查基础连通性
- 再检查配置正确性
- 最后分析复杂逻辑

第三法则：预防胜于治疗
- 完善监控告警
- 定期健康检查
- 建立故障预案
```

### 8.2 常见问题快速定位


| **问题类型** | **主要症状** | **检查重点** | **解决方向** |
|-------------|-------------|-------------|-------------|
| 🔥 **内存溢出** | `进程重启，查询慢` | `内存使用量，高基数指标` | `增加内存，优化查询` |
| 💾 **磁盘满** | `数据写入失败` | `磁盘空间，数据保留` | `清理数据，扩容磁盘` |
| 🌐 **网络问题** | `抓取失败，超时` | `ping，telnet，防火墙` | `修复网络，调整超时` |
| ⚙️ **配置错误** | `启动失败，语法错误` | `YAML语法，配置验证` | `修正配置，热重载` |
| ⚡ **性能差** | `查询慢，CPU高` | `查询复杂度，资源使用` | `优化PromQL，扩容` |

### 8.3 预防性措施


**🛡️ 监控监控系统**
```yaml
# 关键自监控指标
prometheus_up                              # 服务存活
prometheus_config_last_reload_successful   # 配置重载状态  
prometheus_tsdb_head_series                # 时间序列数量
prometheus_notifications_errors_total      # 通知错误数
go_memstats_alloc_bytes                    # 内存使用量
```

**🔔 告警规则建议**
```yaml
groups:
  - name: prometheus_health
    rules:
      # 服务可用性
      - alert: PrometheusDown
        expr: up{job="prometheus"} == 0
        for: 5m
        
      # 内存使用率
      - alert: PrometheusMemoryHigh
        expr: (go_memstats_alloc_bytes / go_memstats_sys_bytes) > 0.8
        for: 10m
        
      # 磁盘使用率  
      - alert: PrometheusDiskHigh
        expr: (node_filesystem_avail_bytes / node_filesystem_size_bytes) < 0.1
        for: 5m
```

**📚 故障处理清单**
- [x] **准备阶段**：文档齐全，工具就绪，权限确认
- [x] **响应阶段**：快速定位，影响评估，应急处理  
- [x] **恢复阶段**：根因分析，彻底修复，验证恢复
- [x] **改进阶段**：复盘总结，流程优化，预防措施

### 8.4 实用工具箱


**🔧 命令行工具**
```bash
# 配置验证
promtool check config prometheus.yml
promtool check rules alert.rules.yml

# 查询测试
promtool query instant 'up'
promtool query range 'up' --start='2024-01-01T00:00:00Z' --end='2024-01-01T01:00:00Z'

# 性能分析
curl http://localhost:9090/debug/pprof/heap
curl http://localhost:9090/debug/pprof/profile
```

**🌐 在线工具**
```
PromQL 查询测试：/graph 页面
配置查看：/api/v1/status/config
目标状态：/targets 页面  
规则状态：/rules 页面
服务发现：/service-discovery 页面
```

**核心记忆口诀**：
- 故障排查有章法，现象原因解决法
- 从简到繁步步查，基础配置性能抓  
- 日志告警是良医，预防胜过救火急
- 工具文档要备齐，复盘改进不停息