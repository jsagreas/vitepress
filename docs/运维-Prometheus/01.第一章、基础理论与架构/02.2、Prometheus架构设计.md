---
title: 2、Prometheus架构设计
---
## 📚 目录

1. [Prometheus是什么](#1-prometheus是什么)
2. [Prometheus Server核心组件](#2-prometheus-server核心组件)
3. [时序数据库TSDB原理](#3-时序数据库tsdb原理)
4. [数据拉取模型工作流程](#4-数据拉取模型工作流程)
5. [本地存储机制与WAL](#5-本地存储机制与wal)
6. [生态系统组件关系](#6-生态系统组件关系)
7. [架构优势与局限性](#7-架构优势与局限性)
8. [核心要点总结](#8-核心要点总结)

---

## 1. 🎯 Prometheus是什么


### 1.1 通俗理解Prometheus


**简单类比**：想象你是一个大厂的运维工程师，需要监控几百台服务器的运行状况。

```
传统做法：挨个登录服务器查看 → 累死你也看不过来
Prometheus做法：自动收集所有数据 → 统一展示 → 异常自动告警

就像给每台服务器装了个"健康手环"，
实时汇报：CPU使用率、内存占用、磁盘空间...
```

### 1.2 核心定义


**Prometheus** 是一个开源的**系统监控和告警工具包**，最初由SoundCloud开发。

**🔸 主要用途**
- **性能监控**：服务器、应用程序、数据库性能
- **业务监控**：网站访问量、订单数量、用户活跃度
- **异常告警**：系统故障、性能下降时自动通知

### 1.3 为什么需要监控系统


```
没有监控的痛点：
❌ 系统挂了不知道
❌ 性能下降察觉不到
❌ 用户投诉才发现问题
❌ 故障排查没有数据支撑

有了Prometheus：
✅ 实时监控系统状态
✅ 提前发现性能问题
✅ 故障快速定位
✅ 数据驱动的运维决策
```

---

## 2. 🏗️ Prometheus Server核心组件


### 2.1 整体架构图示


```
┌─────────────────────────────────────────────────────────┐
│                   Prometheus Server                     │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────────┐ │
│  │   数据采集   │  │   数据存储   │  │    查询引擎      │ │
│  │   Scraper   │  │    TSDB     │  │  PromQL Engine  │ │
│  │             │  │             │  │                 │ │
│  └─────────────┘  └─────────────┘  └─────────────────┘ │
│           │               │                  │          │
│           └───────────────┼──────────────────┘          │
│                           │                             │
└───────────────────────────┼─────────────────────────────┘
                            │
                   ┌────────▼────────┐
                   │   Web界面/API    │
                   │  (用户交互层)    │
                   └─────────────────┘
```

### 2.2 数据采集器（Scraper）


**🔸 作用说明**
- **定时拉取**：按配置的时间间隔主动获取监控数据
- **HTTP协议**：通过HTTP GET请求获取metrics数据
- **多目标管理**：同时监控多个服务和主机

**生活化理解**：
> 就像快递员按时到各个取件点收快递，Scraper按时到各个监控目标"取数据"

```
工作流程：
1. 读取配置文件，知道要监控哪些目标
2. 每隔15秒（默认）访问一次目标的metrics接口
3. 解析返回的数据格式
4. 将数据存储到时序数据库
```

### 2.3 时序数据库（TSDB）


**🔸 核心概念**
- **时序数据**：带时间戳的数据点
- **高效存储**：专门为时间序列数据优化
- **压缩算法**：减少磁盘占用

**通俗理解**：
> 就像股票K线图的数据存储，每个时间点记录一个数值

```
数据格式示例：
时间点          指标名称         数值    标签
2025-09-21 15:30  cpu_usage       45%    {host="web1"}
2025-09-21 15:31  cpu_usage       48%    {host="web1"}
2025-09-21 15:32  cpu_usage       52%    {host="web1"}
```

### 2.4 查询引擎（PromQL Engine）


**🔸 功能特点**
- **PromQL语言**：专门的查询语言
- **实时计算**：支持复杂的数据分析
- **聚合查询**：支持求和、平均值、百分位等

**简单例子**：
```promql
# 查询CPU使用率
cpu_usage

# 查询最近5分钟平均CPU使用率
avg_over_time(cpu_usage[5m])

# 查询使用率超过80%的服务器
cpu_usage > 80
```

### 2.5 Web界面和API


**🔸 用户交互**
- **Web控制台**：浏览器访问的图形界面
- **REST API**：程序调用的接口
- **Grafana集成**：更美观的图表展示

---

## 3. 💾 时序数据库TSDB原理


### 3.1 什么是时序数据


**通俗解释**：时序数据就是**按时间顺序排列的数据**。

```
生活中的时序数据：
📈 股票价格：每分钟的价格变化
🌡️ 温度记录：每小时的气温数据
💰 银行流水：每笔交易的时间和金额
📊 网站访问：每秒的访问量统计

监控中的时序数据：
⚡ CPU使用率：每15秒采集一次
💿 磁盘使用：每分钟记录一次
🔗 网络流量：每秒统计一次
```

### 3.2 TSDB设计特点


**🔸 写入优化**
```
特点：写多读少
- 90%的操作是写入新数据
- 10%的操作是查询历史数据
- 几乎不修改历史数据

设计优化：
✅ 批量写入提高性能
✅ 顺序写入减少磁盘寻道
✅ 压缩存储节省空间
```

**🔸 查询模式**
```
常见查询：
- 最近1小时的CPU使用率
- 昨天同时段的访问量对比
- 近7天的平均响应时间

优化策略：
✅ 时间范围索引
✅ 标签索引加速过滤
✅ 预聚合减少计算量
```

### 3.3 数据组织结构


```
Metric指标结构：

指标名称: http_requests_total
标签: {method="GET", status="200", instance="web1:8080"}
数值: 1547
时间戳: 1695307800

组合示例：
http_requests_total{method="GET", status="200"} 1547 @1695307800
http_requests_total{method="POST", status="404"} 23 @1695307800
```

**🔸 数据特点**
- **指标名称**：描述监控的内容
- **标签组合**：多维度筛选和分组
- **数值**：实际的监控数值
- **时间戳**：精确到毫秒的时间

---

## 4. 🔄 数据拉取模型工作流程


### 4.1 Pull模型 vs Push模型


**🔸 拉取模型（Prometheus采用）**
```
工作原理：
监控系统 ────主动获取────▶ 被监控目标

优点：
✅ 监控系统主动控制采集频率
✅ 可以检测目标是否存活
✅ 配置集中管理
✅ 避免数据轰炸

缺点：
❌ 需要目标系统提供HTTP接口
❌ 防火墙可能阻止访问
```

**🔸 推送模型（传统方式）**
```
工作原理：
被监控目标 ────主动发送────▶ 监控系统

优点：
✅ 目标系统更灵活
✅ 可以突破防火墙限制

缺点：
❌ 难以控制数据量
❌ 无法判断目标存活状态
❌ 配置分散难管理
```

### 4.2 完整拉取流程


```
数据拉取时序图：

Prometheus Server    目标服务（如Web应用）     Metrics接口
        │                    │                    │
        │                    │                    │
        │ ─── 1.读取配置 ────▶ │                    │
        │                    │                    │
        │ ─── 2.发起HTTP请求 ─│───────────────────▶ │
        │     GET /metrics   │                    │
        │                    │                    │
        │ ◀─── 3.返回metrics数据 ─────────────────── │
        │     (文本格式)      │                    │
        │                    │                    │
        │ ─── 4.解析数据 ────▶ │                    │
        │                    │                    │
        │ ─── 5.存储到TSDB ──▶ │                    │
        │                    │                    │
        │ ─── 6.等待下次采集 ─ │                    │
        │     (默认15秒)      │                    │
```

### 4.3 配置示例


```yaml
# prometheus.yml 配置文件
global:
  scrape_interval: 15s  # 全局采集间隔

scrape_configs:
  - job_name: 'web-servers'
    static_configs:
      - targets: 
        - 'web1:8080'
        - 'web2:8080'
        - 'web3:8080'
    scrape_interval: 10s  # 这个任务的特定间隔
    metrics_path: '/metrics'  # metrics接口路径
```

**配置解释**：
- `job_name`：监控任务的名称，便于管理
- `targets`：要监控的目标列表
- `scrape_interval`：多久采集一次数据
- `metrics_path`：目标系统提供数据的接口路径

---

## 5. 🗃️ 本地存储机制与WAL


### 5.1 存储架构概览


```
Prometheus存储结构：

┌─────────────────────────────────────────┐
│              内存缓存                    │
│        (最新2小时数据)                   │
└─────────────┬───────────────────────────┘
              │
┌─────────────▼───────────────────────────┐
│              WAL日志                     │
│         (防止数据丢失)                   │
└─────────────┬───────────────────────────┘
              │
┌─────────────▼───────────────────────────┐
│             磁盘存储                     │
│          (长期持久化)                    │
└─────────────────────────────────────────┘
```

### 5.2 WAL（Write-Ahead Log）机制


**🔸 什么是WAL**
WAL就像是一个**操作记录本**，在真正存储数据之前，先把要做的操作写下来。

**生活化理解**：
> 就像银行转账，先在流水账上记一笔，再实际转账。即使转账过程中出问题，也能根据流水账恢复。

```
WAL工作流程：

1. 新数据到达 ┌────────────┐
              │  写入WAL   │ ← 先记录操作
              └────┬───────┘
                   │
2. WAL写入成功     │
              ┌────▼───────┐
              │  写入内存   │ ← 再更新内存
              └────┬───────┘
                   │
3. 定期刷盘       │
              ┌────▼───────┐
              │  持久化到   │ ← 最后存磁盘
              │   磁盘     │
              └────────────┘
```

**🔸 WAL的作用**
```
数据安全保障：
✅ 防止进程崩溃导致数据丢失
✅ 服务重启时可以恢复数据
✅ 保证数据的一致性

性能优化：
✅ 顺序写入提高写入速度
✅ 批量处理减少磁盘IO
```

### 5.3 数据分块存储


**🔸 Block块组织**
```
时间分块存储：

├── 20250921_10/     (上午10点-12点的数据)
│   ├── chunks/      (实际数据文件)
│   ├── index        (索引文件)
│   └── meta.json    (元数据)
├── 20250921_12/     (中午12点-14点的数据)
│   ├── chunks/
│   ├── index
│   └── meta.json
└── 20250921_14/     (下午14点-16点的数据)
    ├── chunks/
    ├── index
    └── meta.json
```

**优点分析**：
- **查询加速**：只需要读取相关时间段的块
- **数据清理**：过期数据直接删除整个块
- **压缩优化**：每个块内部可以高效压缩

### 5.4 数据保留策略


```yaml
# 存储配置示例
storage:
  tsdb:
    retention.time: "15d"     # 保留15天数据
    retention.size: "10GB"    # 最大占用10GB
    wal-compression: true     # 启用WAL压缩
```

**🔸 清理策略**
- **时间清理**：超过保留期的数据自动删除
- **空间清理**：磁盘空间不足时删除最旧数据
- **压缩合并**：小块合并成大块提高效率

---

## 6. 🌐 生态系统组件关系


### 6.1 完整架构图


```
                    告警管理
              ┌─────────────────┐
              │  Alertmanager   │ ←─── 告警规则触发
              │   (告警路由)     │
              └─────────────────┘
                      │
                告警通知发送
                      │
    ┌─────────────────┼─────────────────┐
    │                 ▼                 │
┌───▼────┐     ┌─────────────┐     ┌────▼───┐
│ 邮件    │     │   短信      │     │ 钉钉   │
│ Email  │     │   SMS       │     │ 企微   │
└────────┘     └─────────────┘     └────────┘


                监控数据查询
              ┌─────────────────┐
              │   Prometheus    │ ←─── 数据采集存储
              │    Server       │
              └─────────┬───────┘
                        │
                    数据查询
                        │
              ┌─────────▼───────┐
              │    Grafana      │ ←─── 数据可视化
              │   (仪表盘)       │
              └─────────────────┘


              数据源 (被监控目标)
    ┌─────────────┬─────────────┬─────────────┐
    │             │             │             │
┌───▼──────┐ ┌───▼──────┐ ┌────▼─────┐ ┌────▼─────┐
│   应用    │ │  数据库   │ │  服务器   │ │  网络    │
│ Node.js  │ │  MySQL   │ │  Linux   │ │ 交换机   │
│ Java     │ │  Redis   │ │ Windows  │ │ 路由器   │
└──────────┘ └──────────┘ └──────────┘ └──────────┘
```

### 6.2 核心组件详解


**🔸 Prometheus Server**
```
角色：数据大脑
职责：
- 收集监控数据
- 存储时序数据  
- 提供查询接口
- 执行告警规则
```

**🔸 Alertmanager**
```
角色：告警管家
职责：
- 接收告警信息
- 告警去重和分组
- 路由到不同通知渠道
- 告警抑制和静默
```

**🔸 Grafana**
```
角色：数据展示专家
职责：
- 制作漂亮的图表
- 创建监控仪表盘
- 支持多种数据源
- 用户权限管理
```

**🔸 Exporters**
```
角色：数据翻译官
职责：
- 将各种系统的数据转换为Prometheus格式
- 提供标准的metrics接口
- 适配不同的监控目标

常用Exporter：
- node_exporter：Linux系统监控
- mysql_exporter：MySQL数据库监控  
- redis_exporter：Redis监控
- blackbox_exporter：网站可用性监控
```

### 6.3 数据流向


```
数据流转过程：

被监控系统 ─── metrics数据 ──▶ Prometheus Server
                                      │
                               存储+分析+告警
                                      │
                              ┌───────┼───────┐
                              │               │
                         ▼                   ▼
                    Grafana显示        Alertmanager告警
                         │                   │
                    用户查看图表          发送通知消息
```

---

## 7. ⚖️ 架构优势与局限性


### 7.1 核心优势


**🔸 简单可靠**
```
优势体现：
✅ 单进程部署，不依赖外部存储
✅ 配置文件管理，易于理解
✅ 内置Web界面，开箱即用
✅ 社区活跃，文档丰富

实际价值：
- 降低运维复杂度
- 减少故障点
- 快速上手使用
```

**🔸 高性能**
```
性能特点：
✅ 单机可处理百万级指标
✅ 查询响应时间毫秒级
✅ 存储压缩比高达90%
✅ 内存使用效率高

应用场景：
- 大规模集群监控
- 实时性要求高的场景
- 资源有限的环境
```

**🔸 灵活强大**
```
灵活性体现：
✅ PromQL查询语言功能强大
✅ 标签系统支持多维度分析
✅ 丰富的函数和操作符
✅ 支持自定义指标

使用优势：
- 复杂数据分析
- 个性化监控需求
- 业务指标监控
```

### 7.2 主要局限性


**🔸 存储限制**
```
单机存储瓶颈：
❌ 无法水平扩展存储
❌ 历史数据受磁盘限制
❌ 大规模长期存储困难

影响：
- 数据保留期有限
- 需要定期清理数据
- 大集群可能存储不足
```

**🔸 高可用挑战**
```
单点故障风险：
❌ 单机部署存在单点故障
❌ 官方无内置集群方案
❌ 数据恢复依赖备份

解决思路：
- 部署多个实例
- 使用联邦集群
- 定期数据备份
```

**🔸 网络依赖**
```
拉取模型限制：
❌ 需要网络连通性
❌ 防火墙可能阻止访问
❌ 短暂网络中断可能丢失数据

应对策略：
- 使用Pushgateway
- 配置网络策略
- 监控网络连通性
```

### 7.3 适用场景分析


**✅ 最佳适用场景**
```
云原生环境：
- Kubernetes集群监控
- Docker容器监控
- 微服务架构监控

中小规模系统：
- 服务器数量 < 1000台
- 监控指标 < 百万级
- 数据保留期 < 30天

开发测试环境：
- 快速搭建监控
- 性能分析和调试
- 实验和学习
```

**❌ 不推荐场景**
```
超大规模环境：
- 服务器数量 > 10000台
- 监控指标 > 千万级
- 需要年级别数据保留

合规要求严格：
- 金融行业监管要求
- 数据不能丢失
- 需要严格的审计功能

复杂网络环境：
- 跨网段访问困难
- 安全要求极高
- 网络不稳定
```

---

## 8. 📋 核心要点总结


### 8.1 必须掌握的核心概念


```
🔸 Prometheus本质：开源的监控和告警系统
🔸 核心组件：数据采集、存储、查询、告警四大模块
🔸 数据模型：时序数据 + 多维标签系统
🔸 工作方式：主动拉取模型，定时收集数据
🔸 存储机制：内存 + WAL + 磁盘的三层结构
```

### 8.2 关键理解要点


**🔹 为什么选择拉取模型**
```
技术考虑：
- 监控系统主动控制采集频率
- 可以检测目标服务的存活状态
- 避免被监控系统的数据轰炸
- 配置集中管理更容易

实际优势：
- 降低被监控系统的负担
- 提高监控系统的稳定性
- 简化网络配置和管理
```

**🔹 时序数据库的价值**
```
专业设计：
- 针对监控数据特点优化
- 写多读少的访问模式
- 高效的数据压缩算法
- 时间范围查询优化

实际效果：
- 存储空间节省90%以上
- 查询性能提升数十倍
- 支持大规模数据存储
```

**🔹 架构设计哲学**
```
简单至上：
- 单进程部署减少复杂度
- 本地存储避免外部依赖
- 配置文件管理降低门槛

性能优先：
- 内存缓存提高查询速度
- 批量写入减少磁盘IO
- 压缩存储节省空间

可扩展性：
- 标签系统支持多维度
- PromQL支持复杂查询
- 丰富的生态系统组件
```

### 8.3 实际应用指导


**🎯 部署建议**
- **小规模**：单机部署，简单可靠
- **中等规模**：多实例部署，负载分担
- **大规模**：联邦集群，分层监控

**🎯 存储规划**
- **数据量评估**：根据监控目标数量和采集频率
- **保留期设置**：平衡存储成本和数据需求
- **备份策略**：定期备份重要历史数据

**🎯 性能优化**
- **采集频率**：根据实际需求调整，不必过于频繁
- **标签使用**：合理设计标签，避免高基数
- **查询优化**：使用合适的时间范围和聚合函数

**核心记忆**：
- Prometheus是云原生时代的监控标准
- 拉取模型 + 时序数据库 = 高效监控
- 简单部署 + 强大功能 = 广泛应用
- 理解架构原理有助于更好地使用和优化