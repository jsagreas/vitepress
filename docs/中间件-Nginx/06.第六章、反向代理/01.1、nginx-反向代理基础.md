---
title: 1、nginx-反向代理基础
---
## 📚 目录

1. [什么是反向代理](#1-什么是反向代理)
2. [反向代理的工作原理](#2-反向代理的工作原理)
3. [proxy_pass指令详解](#3-proxy_pass指令详解)
4. [代理服务器配置实战](#4-代理服务器配置实战)
5. [后端服务器连接管理](#5-后端服务器连接管理)
6. [代理协议选择指南](#6-代理协议选择指南)
7. [代理缓冲区设置优化](#7-代理缓冲区设置优化)
8. [核心要点总结](#8-核心要点总结)

---

## 1. 🤔 什么是反向代理


### 1.1 生活中的代理概念


想象一下你要买房子，但是不想直接和卖家打交道：

```
你 → 房产中介 → 房主
   (买方)  (代理)   (卖方)
```

**房产中介就是代理**：
- 你只需要和中介沟通
- 中介帮你和房主谈价格
- 房主也只和中介打交道

### 1.2 正向代理 vs 反向代理


**🔸 正向代理（Forward Proxy）**
```
你的电脑 → 代理服务器 → 目标网站
(客户端)    (代理)      (服务器)

现实例子：公司上网代理
- 你要访问Google
- 先连接公司代理服务器
- 代理服务器帮你访问Google
- 目标网站看到的是代理服务器的IP
```

**🔸 反向代理（Reverse Proxy）**
```
用户浏览器 → 反向代理服务器 → 后端应用服务器
(客户端)     (Nginx代理)      (真正的服务器)

现实例子：淘宝网站架构
- 你访问 www.taobao.com
- 实际连接到Nginx反向代理
- Nginx把请求转发给后端的应用服务器
- 你不知道真正的服务器在哪里
```

### 1.3 反向代理的核心作用


**🎯 核心概念理解**

反向代理就像一个**智能前台**：

```
           用户请求进来
               ↓
    ┌─────────────────────┐
    │   Nginx反向代理      │  ← 智能前台
    │   (对外的门面)       │
    └─────────┬───────────┘
              │ 分发请求
    ┌─────────┼───────────┐
    ↓         ↓           ↓
┌──────┐  ┌──────┐   ┌──────┐
│服务器1│  │服务器2│   │服务器3│  ← 后端工作人员
└──────┘  └──────┘   └──────┘
```

**为什么叫"反向"**：
- **正向代理**：代理的是客户端，服务器不知道真正的客户端是谁
- **反向代理**：代理的是服务器，客户端不知道真正的服务器是谁

---

## 2. ⚙️ 反向代理的工作原理


### 2.1 完整的工作流程


```
用户发起请求的完整过程：

Step 1: 用户输入网址
用户浏览器 → http://example.com

Step 2: DNS解析到Nginx
DNS服务器返回Nginx服务器IP：192.168.1.100

Step 3: 连接到Nginx
用户浏览器 → 192.168.1.100:80 (Nginx)

Step 4: Nginx处理请求
Nginx检查配置 → 决定转发到哪个后端服务器

Step 5: 转发到后端
Nginx → 192.168.1.201:8080 (后端应用服务器)

Step 6: 后端处理并响应
后端服务器 → 处理业务逻辑 → 返回结果给Nginx

Step 7: Nginx返回给用户
Nginx → 用户浏览器 (用户看到最终结果)
```

### 2.2 Nginx在其中的角色


**🔸 Nginx扮演的角色**

```
┌─────────────────────────────────────┐
│            Nginx反向代理             │
├─────────────────────────────────────┤
│ 🚪 接收用户请求                      │
│ 🧭 根据配置选择后端服务器             │
│ 📡 转发请求到后端                   │
│ 📥 接收后端响应                     │
│ 📤 处理并返回给用户                  │
│ 🛡️ 提供安全防护                     │
│ ⚡ 缓存常用内容                     │
└─────────────────────────────────────┘
```

**具体做了什么事情**：
- **请求接收**：监听80/443端口，接收HTTP/HTTPS请求
- **请求解析**：分析请求的URL、headers等信息
- **路由决策**：根据配置规则决定转发到哪个后端
- **请求转发**：修改请求头，转发给后端服务器
- **响应处理**：接收后端响应，可能进行缓存或修改
- **返回响应**：将最终结果返回给用户

### 2.3 为什么需要反向代理


**💡 解决的核心问题**

| 问题场景 | 没有反向代理 | 有反向代理 |
|---------|-------------|-----------|
| **用户访问量大** | 单台服务器扛不住 | 多台服务器分担负载 |
| **服务器故障** | 网站完全不可用 | 自动切换到其他服务器 |
| **静态文件访问** | 应用服务器处理图片 | Nginx直接返回，效率更高 |
| **HTTPS处理** | 每台服务器都要配置SSL | 只在Nginx配置一次 |
| **安全防护** | 后端服务器直接暴露 | Nginx提供防护屏障 |

---

## 3. 🎯 proxy_pass指令详解


### 3.1 proxy_pass基本概念


**🔸 什么是proxy_pass**

`proxy_pass`是Nginx最重要的反向代理指令，告诉Nginx把请求转发到哪里去。

**基本语法**：
```nginx
proxy_pass http://backend_server;
```

**就像给快递员写地址**：
- 快递员（Nginx）收到包裹（用户请求）
- 看地址标签（proxy_pass配置）
- 送到指定地址（后端服务器）

### 3.2 proxy_pass的不同写法


**🔸 直接指定IP和端口**
```nginx
location /api/ {
    proxy_pass http://192.168.1.100:8080;
}
```
**含义解释**：
- 当用户访问 `/api/` 开头的URL时
- Nginx把请求转发到 `192.168.1.100:8080`
- 比如用户访问 `/api/users`，实际请求 `http://192.168.1.100:8080/api/users`

**🔸 使用域名**
```nginx
location /app/ {
    proxy_pass http://backend.example.com;
}
```

**🔸 带路径的转发**
```nginx
# 会保留原始路径
location /old-api/ {
    proxy_pass http://192.168.1.100:8080/new-api/;
}
```
**路径转换示例**：
- 用户请求：`/old-api/users`
- 转发到：`http://192.168.1.100:8080/new-api/users`

### 3.3 proxy_pass的关键注意事项


**⚠️ 路径末尾的斜杠很重要**

```nginx
# 情况1：没有斜杠
location /api/ {
    proxy_pass http://backend:8080;
}
# 用户访问 /api/users → 转发到 http://backend:8080/api/users

# 情况2：有斜杠
location /api/ {
    proxy_pass http://backend:8080/;
}
# 用户访问 /api/users → 转发到 http://backend:8080/users
```

**记忆方法**：
- **无斜杠**：完整保留原路径
- **有斜杠**：替换掉location匹配的部分

---

## 4. 🔧 代理服务器配置实战


### 4.1 最简单的反向代理配置


**🔸 场景**：把所有请求转发给后端应用服务器

```nginx
server {
    listen 80;
    server_name example.com;
    
    location / {
        proxy_pass http://127.0.0.1:8080;
    }
}
```

**配置解释**：
- 监听80端口（HTTP默认端口）
- 域名是 `example.com`
- 所有请求（`/`匹配所有）都转发给本机8080端口

### 4.2 添加基本的代理请求头


**🔸 为什么需要设置请求头**

当Nginx转发请求时，后端服务器看到的客户端IP是Nginx的IP，而不是真实用户的IP。我们需要告诉后端服务器真实的客户端信息。

```nginx
server {
    listen 80;
    server_name example.com;
    
    location / {
        proxy_pass http://127.0.0.1:8080;
        
        # 传递真实的客户端IP
        proxy_set_header X-Real-IP $remote_addr;
        
        # 传递原始的Host头
        proxy_set_header Host $host;
        
        # 传递完整的客户端IP链
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        
        # 传递访问协议（HTTP或HTTPS）
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}
```

**请求头含义解释**：

| 请求头 | 含义 | 后端看到的值 |
|-------|------|-------------|
| `X-Real-IP` | 真实客户端IP | `192.168.1.50` |
| `Host` | 用户访问的域名 | `example.com` |
| `X-Forwarded-For` | 经过的所有代理IP | `192.168.1.50, 10.0.0.1` |
| `X-Forwarded-Proto` | 访问协议 | `http` 或 `https` |

### 4.3 分路径转发到不同后端


**🔸 实际业务场景**

```nginx
server {
    listen 80;
    server_name example.com;
    
    # 静态文件直接返回
    location /static/ {
        alias /var/www/static/;
    }
    
    # API请求转发到API服务器
    location /api/ {
        proxy_pass http://192.168.1.100:8080/;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
    
    # 管理后台转发到管理服务器
    location /admin/ {
        proxy_pass http://192.168.1.101:9090/;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
    
    # 其他请求转发到主应用
    location / {
        proxy_pass http://192.168.1.102:3000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
}
```

**访问效果**：
- `example.com/static/logo.png` → Nginx直接返回文件
- `example.com/api/users` → 转发到API服务器
- `example.com/admin/dashboard` → 转发到管理后台
- `example.com/` → 转发到主应用

---

## 5. 🔗 后端服务器连接管理


### 5.1 单个后端服务器配置


**🔸 基本连接设置**

```nginx
location /app/ {
    proxy_pass http://192.168.1.100:8080;
    
    # 连接超时设置
    proxy_connect_timeout 5s;      # 连接后端超时时间
    proxy_send_timeout 10s;        # 发送请求超时时间
    proxy_read_timeout 10s;        # 读取响应超时时间
}
```

**超时设置的含义**：

```
连接建立阶段：proxy_connect_timeout
    Nginx ----建立TCP连接----> 后端服务器
              (5秒内必须成功)

发送请求阶段：proxy_send_timeout  
    Nginx ----发送HTTP请求----> 后端服务器
              (10秒内必须发送完)

读取响应阶段：proxy_read_timeout
    Nginx <----读取HTTP响应---- 后端服务器
              (10秒内必须有响应)
```

### 5.2 多个后端服务器（upstream）


**🔸 什么是upstream**

当你有多台后端服务器时，可以定义一个upstream组，让Nginx自动在多台服务器间分配请求。

```nginx
# 定义后端服务器组
upstream backend_servers {
    server 192.168.1.100:8080;
    server 192.168.1.101:8080;
    server 192.168.1.102:8080;
}

server {
    listen 80;
    server_name example.com;
    
    location / {
        proxy_pass http://backend_servers;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
}
```

**工作原理**：
```
用户请求1 → Nginx → 192.168.1.100:8080
用户请求2 → Nginx → 192.168.1.101:8080  
用户请求3 → Nginx → 192.168.1.102:8080
用户请求4 → Nginx → 192.168.1.100:8080 (循环)
```

### 5.3 upstream负载均衡策略


**🔸 轮询（默认）**
```nginx
upstream backend {
    server 192.168.1.100:8080;
    server 192.168.1.101:8080;
    server 192.168.1.102:8080;
}
```
**特点**：每个请求依次分配给不同服务器

**🔸 加权轮询**
```nginx
upstream backend {
    server 192.168.1.100:8080 weight=3;  # 处理3个请求
    server 192.168.1.101:8080 weight=2;  # 处理2个请求
    server 192.168.1.102:8080 weight=1;  # 处理1个请求
}
```
**使用场景**：服务器性能不同时使用

**🔸 IP哈希**
```nginx
upstream backend {
    ip_hash;  # 根据客户端IP分配
    server 192.168.1.100:8080;
    server 192.168.1.101:8080;
    server 192.168.1.102:8080;
}
```
**特点**：同一个IP的用户总是访问同一台服务器

### 5.4 健康检查配置


**🔸 基本健康检查**
```nginx
upstream backend {
    server 192.168.1.100:8080 max_fails=3 fail_timeout=30s;
    server 192.168.1.101:8080 max_fails=3 fail_timeout=30s;
    server 192.168.1.102:8080 backup;  # 备用服务器
}
```

**参数含义**：
- `max_fails=3`：连续失败3次后认为服务器不可用
- `fail_timeout=30s`：标记为不可用后，30秒后重新尝试
- `backup`：只有主服务器都不可用时才使用

---

## 6. 🌐 代理协议选择指南


### 6.1 HTTP代理 vs HTTPS代理


**🔸 HTTP代理（最常用）**
```nginx
location / {
    proxy_pass http://backend:8080;
}
```
**适用场景**：
- 内网环境，安全性要求不高
- 后端服务器处理HTTP请求
- 性能要求高（HTTP开销更小）

**🔸 HTTPS代理**
```nginx
location / {
    proxy_pass https://backend:8443;
    proxy_ssl_verify off;  # 不验证后端SSL证书
}
```
**适用场景**：
- 后端服务器只提供HTTPS服务
- 端到端加密要求
- 后端在公网上

### 6.2 WebSocket代理配置


**🔸 WebSocket特殊配置**

WebSocket需要保持长连接，需要特殊的配置：

```nginx
location /websocket/ {
    proxy_pass http://backend:8080;
    
    # WebSocket必需的请求头
    proxy_http_version 1.1;
    proxy_set_header Upgrade $http_upgrade;
    proxy_set_header Connection "upgrade";
    proxy_set_header Host $host;
    
    # 延长超时时间
    proxy_read_timeout 3600s;
    proxy_send_timeout 3600s;
}
```

**为什么需要特殊配置**：
- WebSocket需要HTTP/1.1协议
- 需要`Upgrade`和`Connection`头来升级协议
- 需要更长的超时时间（因为是长连接）

### 6.3 文件上传代理优化


**🔸 大文件上传配置**
```nginx
location /upload/ {
    proxy_pass http://backend:8080;
    
    # 允许大文件上传
    client_max_body_size 100M;
    
    # 关闭代理缓冲，流式传输
    proxy_request_buffering off;
    proxy_buffering off;
    
    # 增加超时时间
    proxy_connect_timeout 300s;
    proxy_send_timeout 300s;
    proxy_read_timeout 300s;
}
```

---

## 7. 📦 代理缓冲区设置优化


### 7.1 什么是代理缓冲


**🔸 缓冲的作用**

```
没有缓冲的情况：
用户 ←→ Nginx ←→ 后端服务器
     (实时传输，占用连接时间长)

有缓冲的情况：
用户 ←→ Nginx ←→ 后端服务器
     (Nginx先接收完整响应，再发给用户)
```

**缓冲的好处**：
- 减少后端服务器连接时间
- 提高并发处理能力
- 平滑网络波动影响

### 7.2 缓冲区相关配置


**🔸 基本缓冲设置**
```nginx
location / {
    proxy_pass http://backend:8080;
    
    # 是否启用缓冲
    proxy_buffering on;
    
    # 缓冲区大小
    proxy_buffer_size 4k;        # 响应头缓冲区
    proxy_buffers 8 4k;          # 响应体缓冲区（8个4k）
    proxy_busy_buffers_size 8k;  # 忙碌缓冲区大小
}
```

**🔸 什么时候关闭缓冲**
```nginx
location /stream/ {
    proxy_pass http://backend:8080;
    
    # 关闭缓冲，实时传输
    proxy_buffering off;
}
```

**关闭缓冲的场景**：
- 实时数据流（如视频直播）
- 大文件下载
- 服务器推送事件（SSE）

### 7.3 缓冲区大小优化建议


**💡 优化原则**

| 应用类型 | 缓冲区设置 | 原因 |
|---------|-----------|------|
| **API接口** | 默认设置即可 | 响应通常较小 |
| **文件下载** | 增大缓冲区 | 提高传输效率 |
| **实时推送** | 关闭缓冲 | 需要实时性 |
| **图片服务** | 适中缓冲区 | 平衡性能和内存 |

**典型配置示例**：
```nginx
# API服务
location /api/ {
    proxy_pass http://api_backend;
    proxy_buffering on;
    proxy_buffer_size 4k;
    proxy_buffers 8 4k;
}

# 文件下载
location /download/ {
    proxy_pass http://file_backend;
    proxy_buffering on;
    proxy_buffer_size 8k;
    proxy_buffers 16 8k;
}

# 实时推送
location /events/ {
    proxy_pass http://event_backend;
    proxy_buffering off;
    proxy_cache off;
}
```

---

## 8. 📋 核心要点总结


### 8.1 必须掌握的核心概念


**🔸 反向代理本质**
```
反向代理 = 智能前台 + 请求转发
- 用户不知道真实服务器在哪里
- Nginx负责接收请求和转发
- 可以实现负载均衡、缓存、安全防护
```

**🔸 proxy_pass核心要点**
- `proxy_pass`是最重要的转发指令
- 路径末尾的斜杠影响URL重写规则
- 必须配置合适的请求头传递真实客户端信息

**🔸 upstream负载均衡**
- 多台后端服务器组成服务器组
- 支持轮询、加权、IP哈希等策略
- 自动健康检查和故障转移

### 8.2 实际应用指导


**🎯 典型使用场景**

| 场景 | 配置要点 | 注意事项 |
|------|---------|---------|
| **简单网站** | 单个proxy_pass | 配置基本请求头 |
| **微服务架构** | 多个location分发 | 路径规划要清晰 |
| **高可用服务** | upstream + 健康检查 | 备用服务器配置 |
| **WebSocket应用** | 特殊协议升级配置 | 超时时间要足够长 |

**🔧 配置最佳实践**
```nginx
# 推荐的基础配置模板
server {
    listen 80;
    server_name your-domain.com;
    
    # 基本反向代理配置
    location / {
        proxy_pass http://backend;
        
        # 必需的请求头
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # 合理的超时设置
        proxy_connect_timeout 5s;
        proxy_send_timeout 10s;
        proxy_read_timeout 10s;
        
        # 适当的缓冲配置
        proxy_buffering on;
        proxy_buffer_size 4k;
        proxy_buffers 8 4k;
    }
}

# upstream负载均衡
upstream backend {
    server 192.168.1.100:8080 max_fails=3 fail_timeout=30s;
    server 192.168.1.101:8080 max_fails=3 fail_timeout=30s;
    server 192.168.1.102:8080 backup;
}
```

### 8.3 常见问题和解决方案


**⚠️ 常见错误及解决**

| 问题 | 原因 | 解决方案 |
|------|------|---------|
| 502 Bad Gateway | 后端服务器不可达 | 检查后端服务器状态和网络连接 |
| 504 Gateway Timeout | 后端响应超时 | 调整超时设置或优化后端性能 |
| 客户端IP丢失 | 未配置X-Real-IP | 添加proxy_set_header配置 |
| WebSocket连接失败 | 协议升级失败 | 配置Upgrade和Connection头 |

**核心记忆口诀**：
```
反向代理做中介，用户后端不见面
proxy_pass是核心，请求转发它来管
upstream做均衡，多台服务器共分担
请求头要传递，真实信息不能丢
超时缓冲要配好，性能稳定有保障
```