---
title: 59、大数据量处理
---
## 📚 目录

1. [大数据量处理概述](#1-大数据量处理概述)
2. [分批处理策略](#2-分批处理策略)
3. [流式查询应用](#3-流式查询应用)
4. [内存控制管理](#4-内存控制管理)
5. [异步处理机制](#5-异步处理机制)
6. [数据分片策略](#6-数据分片策略)
7. [性能监控指标](#7-性能监控指标)
8. [核心要点总结](#8-核心要点总结)

---

## 1. 🎯 大数据量处理概述


### 1.1 什么是大数据量问题


**通俗理解**：想象你要搬家，有10000本书要搬到新家。如果一次性全部搬，你会：
- 🚫 搬不动（内存溢出）
- 🚫 累趴下（CPU压力大）
- 🚫 堵住路（数据库连接占用）

**在程序中的表现**：
```
问题场景1：一次查询100万条数据
结果 → 程序卡死，内存爆了（OutOfMemoryError）

问题场景2：批量插入50万条记录
结果 → 数据库压力巨大，其他请求都卡住了

问题场景3：更新几十万条数据
结果 → 长时间占用连接，超时报错
```

### 1.2 常见的错误做法


| ❌ 错误做法 | 💥 后果 | ✅ 正确思路 |
|-----------|--------|-----------|
| `list()` 一次查全部 | 内存溢出 | 分批查询 |
| `saveBatch()` 一次插入全部 | 数据库锁表 | 分批插入 |
| `update()` 不加条件 | 全表扫描 | 分片更新 |
| 循环单条操作 | 性能极差 | 批量处理 |

### 1.3 解决问题的核心思想


```
核心原则：化整为零，各个击破

大任务 → 拆分成 → 小任务 → 逐个处理

就像搬书：
第一趟：搬100本  ✓
第二趟：搬100本  ✓
第三趟：搬100本  ✓
...
最终：全部搬完！
```

---

## 2. 📦 分批处理策略


### 2.1 什么是分批处理


**简单理解**：把大量数据分成若干小批次，一批一批地处理

```
原始方式（危险）：
┌─────────────────────────────┐
│  一次处理100万条数据 💥      │
└─────────────────────────────┘

分批方式（安全）：
┌──────┐ ┌──────┐ ┌──────┐ ┌──────┐
│ 1千条 │ │ 1千条 │ │ 1千条 │ │ 1千条 │ × 1000次
└──────┘ └──────┘ └──────┘ └──────┘
```

### 2.2 分批查询实战


**场景**：查询100万用户数据导出Excel

```java
// ❌ 错误做法：一次查询全部
List<User> users = userMapper.selectList(null); // 💥 内存爆炸

// ✅ 正确做法：分批查询
int pageSize = 1000;  // 每批1000条
int pageNum = 1;

while (true) {
    // 构建分页条件
    Page<User> page = new Page<>(pageNum, pageSize);
    
    // 查询当前批次
    IPage<User> result = userMapper.selectPage(page, null);
    
    // 处理这批数据（比如写入Excel）
    processUsers(result.getRecords());
    
    // 判断是否还有下一批
    if (result.getRecords().isEmpty()) {
        break;  // 没数据了，退出循环
    }
    
    pageNum++;  // 处理下一批
}
```

> 💡 **关键点**：每次只加载1000条到内存，处理完就释放，内存占用稳定

### 2.3 分批插入实战


**场景**：导入50万条商品数据

```java
// ❌ 错误做法：一次插入全部
productService.saveBatch(allProducts); // 💥 数据库扛不住

// ✅ 正确做法：分批插入
int batchSize = 500;  // 每批500条
List<Product> batch = new ArrayList<>();

for (Product product : allProducts) {
    batch.add(product);
    
    // 凑够一批就插入
    if (batch.size() >= batchSize) {
        productService.saveBatch(batch);
        batch.clear();  // 清空，准备下一批
    }
}

// 处理剩余的数据（不足一批的）
if (!batch.isEmpty()) {
    productService.saveBatch(batch);
}
```

> ⚠️ **注意**：`batchSize` 不是越大越好，通常500-1000合适

### 2.4 分批更新技巧


**场景**：更新所有用户的积分

```java
// 使用MyBatis-Plus的Lambda更新
int batchSize = 1000;
long lastId = 0;  // 记录上次处理到的ID

while (true) {
    // 查询一批待更新的数据
    List<User> users = userMapper.selectList(
        new LambdaQueryWrapper<User>()
            .gt(User::getId, lastId)  // ID大于上次的
            .last("limit " + batchSize)  // 限制数量
    );
    
    if (users.isEmpty()) break;
    
    // 批量更新
    users.forEach(user -> {
        user.setPoints(user.getPoints() + 100);
    });
    userService.updateBatchById(users);
    
    // 记录最后一个ID
    lastId = users.get(users.size() - 1).getId();
}
```

---

## 3. 🌊 流式查询应用


### 3.1 什么是流式查询


**通俗对比**：

```
普通查询（一次性加载）：
数据库 → [全部数据] → 内存 💥 可能爆内存

流式查询（逐条取出）：
数据库 → 数据1 → 处理 → 释放
       → 数据2 → 处理 → 释放
       → 数据3 → 处理 → 释放
       ... ✓ 内存占用小
```

**核心特点**：
- 🔹 **边取边处理**：不需要一次性加载所有数据
- 🔹 **内存友好**：内存占用低且稳定
- 🔹 **适合超大数据**：百万、千万级数据处理

### 3.2 MyBatis-Plus流式查询配置


**步骤1：在Mapper中声明**

```java
@Mapper
public interface UserMapper extends BaseMapper<User> {
    
    // 使用@ResultType注解，返回游标
    @Select("SELECT * FROM user WHERE status = #{status}")
    @Options(resultSetType = ResultSetType.FORWARD_ONLY, 
             fetchSize = 1000)  // 每次取1000条
    Cursor<User> selectCursor(@Param("status") Integer status);
}
```

> 📖 **术语解释**：
> - `Cursor` = 游标，像是数据库的"水龙头"，拧开就流出数据
> - `fetchSize` = 每次从数据库取多少条，类似"水流速度"

**步骤2：使用流式查询**

```java
@Service
public class UserService {
    
    @Autowired
    private UserMapper userMapper;
    
    public void exportAllUsers() {
        // 打开游标
        try (Cursor<User> cursor = userMapper.selectCursor(1)) {
            
            // 逐条处理
            cursor.forEach(user -> {
                // 处理单条数据（比如写入文件）
                writeToFile(user);
                
                // 处理完这条，内存就释放了
            });
            
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
}
```

> 💡 **关键优势**：即使有1000万条数据，内存中同时只有1000条左右

### 3.3 流式查询vs分页查询对比


| 对比维度 | 🌊 流式查询 | 📄 分页查询 |
|---------|-----------|-----------|
| **内存占用** | 极小（恒定） | 较小（每批固定） |
| **速度** | 较快（无分页开销） | 较慢（多次查询） |
| **适用场景** | 导出、数据迁移 | 展示列表 |
| **实现难度** | 稍复杂 | 简单 |
| **数据量** | 千万级+ | 百万级 |

**选择建议**：
- ✅ 需要**处理全部数据**且**不关心顺序** → 流式查询
- ✅ 需要**展示给用户**或**跳页查看** → 分页查询

---

## 4. 💾 内存控制管理


### 4.1 为什么要控制内存


**问题根源**：Java程序的内存是有限的

```
JVM内存结构简化图：
┌─────────────────────────────┐
│       堆内存（Heap）         │ ← 对象存这里
│  ┌─────────────────────┐    │
│  │   年轻代（Young）    │    │ ← 新对象
│  ├─────────────────────┤    │
│  │   老年代（Old）      │    │ ← 长期对象
│  └─────────────────────┘    │
├─────────────────────────────┤
│      栈内存（Stack）         │ ← 方法调用
└─────────────────────────────┘
```

**内存溢出过程**：
```
1. 查询100万数据 → 创建100万个对象
2. 对象放入堆内存 → 堆内存装不下
3. 触发垃圾回收 → 发现都还在用
4. 抛出异常 → OutOfMemoryError 💥
```

### 4.2 JVM参数调优


**常用内存参数**：

```bash
# 启动时配置JVM参数
java -Xms2g          # 初始堆内存2GB
     -Xmx4g          # 最大堆内存4GB
     -XX:+UseG1GC    # 使用G1垃圾回收器
     -jar app.jar
```

> 📖 **参数说明**：
> - `-Xms` = 程序启动时分配多少内存
> - `-Xmx` = 最多能用多少内存
> - `G1GC` = 新一代垃圾回收器，处理大内存更高效

**配置建议**：

| 应用类型 | Xms | Xmx | 说明 |
|---------|-----|-----|------|
| 小型应用 | 512m | 1g | 轻量级，几千条数据 |
| 中型应用 | 1g | 2g | 一般业务，十万级数据 |
| 大型应用 | 2g | 4g | 大数据处理，百万级+ |

### 4.3 代码层面的内存控制


**技巧1：及时释放引用**

```java
// ❌ 错误：持有大对象引用
List<User> allUsers = new ArrayList<>();
for (int i = 0; i < 1000; i++) {
    List<User> batch = userMapper.selectBatch();
    allUsers.addAll(batch);  // 💥 越积累越多
}

// ✅ 正确：处理完立即释放
for (int i = 0; i < 1000; i++) {
    List<User> batch = userMapper.selectBatch();
    processBatch(batch);
    batch = null;  // 帮助GC回收
}
```

**技巧2：使用弱引用缓存**

```java
// 使用Guava的缓存（有内存限制）
Cache<Long, User> cache = CacheBuilder.newBuilder()
    .maximumSize(10000)      // 最多缓存1万条
    .expireAfterWrite(10, TimeUnit.MINUTES)  // 10分钟过期
    .build();
```

**技巧3：监控内存使用**

```java
// 获取当前内存使用情况
Runtime runtime = Runtime.getRuntime();
long usedMemory = runtime.totalMemory() - runtime.freeMemory();
long maxMemory = runtime.maxMemory();

// 内存使用率
double usage = (double) usedMemory / maxMemory * 100;

if (usage > 80) {
    // 内存快满了，暂停处理或触发GC
    System.gc();
    Thread.sleep(1000);
}
```

---

## 5. ⚡ 异步处理机制


### 5.1 为什么需要异步处理


**同步处理的问题**：

```
用户请求 → 开始处理100万数据 → 等待... → 等待... → 响应
                                  (30分钟后)

用户：😤 我还要等多久？！
```

**异步处理的优势**：

```
用户请求 → 立即响应"处理中" → 用户继续干别的
            ↓
         后台慢慢处理100万数据
            ↓
         完成后通知用户
```

### 5.2 Spring异步任务配置


**步骤1：启用异步支持**

```java
@Configuration
@EnableAsync  // 开启异步功能
public class AsyncConfig {
    
    // 自定义线程池（重要！）
    @Bean
    public Executor taskExecutor() {
        ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor();
        executor.setCorePoolSize(5);       // 核心线程数
        executor.setMaxPoolSize(10);       // 最大线程数
        executor.setQueueCapacity(100);    // 队列容量
        executor.setThreadNamePrefix("async-task-");
        executor.initialize();
        return executor;
    }
}
```

> 📖 **线程池参数理解**：
> - `核心线程数` = 常驻员工，一直在岗
> - `最大线程数` = 忙时临时工
> - `队列容量` = 任务排队区

**步骤2：编写异步方法**

```java
@Service
public class DataProcessService {
    
    @Async  // 这个注解让方法异步执行
    public void processLargeData(Long taskId) {
        try {
            // 更新任务状态：处理中
            updateTaskStatus(taskId, "PROCESSING");
            
            // 处理大量数据
            int total = 1000000;
            int batchSize = 1000;
            
            for (int i = 0; i < total; i += batchSize) {
                // 分批处理
                processBatch(i, batchSize);
                
                // 更新进度
                int progress = (i * 100) / total;
                updateTaskProgress(taskId, progress);
            }
            
            // 更新任务状态：完成
            updateTaskStatus(taskId, "COMPLETED");
            
        } catch (Exception e) {
            updateTaskStatus(taskId, "FAILED");
        }
    }
}
```

**步骤3：Controller调用**

```java
@RestController
public class DataController {
    
    @Autowired
    private DataProcessService processService;
    
    @PostMapping("/process")
    public Result startProcess() {
        // 生成任务ID
        Long taskId = generateTaskId();
        
        // 异步处理（立即返回）
        processService.processLargeData(taskId);
        
        // 返回任务ID给前端
        return Result.success(taskId);
    }
    
    @GetMapping("/progress/{taskId}")
    public Result getProgress(@PathVariable Long taskId) {
        // 前端轮询进度
        TaskInfo info = getTaskInfo(taskId);
        return Result.success(info);
    }
}
```

### 5.3 使用消息队列实现异步


**更强大的方案：RabbitMQ/Kafka**

```
流程图：
用户 → 请求处理
        ↓
    Controller → 发送消息到队列 → 立即响应
                      ↓
                 消息队列（MQ）
                      ↓
                 后台消费者 → 慢慢处理
                      ↓
                  处理完成 → 通知用户
```

**示例代码（RabbitMQ）**：

```java
// 发送消息到队列
@Service
public class TaskProducer {
    
    @Autowired
    private RabbitTemplate rabbitTemplate;
    
    public void sendTask(DataTask task) {
        rabbitTemplate.convertAndSend("data.queue", task);
    }
}

// 消费消息并处理
@Component
public class TaskConsumer {
    
    @RabbitListener(queues = "data.queue")
    public void handleTask(DataTask task) {
        // 处理大数据任务
        processLargeData(task);
    }
}
```

> 💡 **优势**：
> - 解耦：生产者和消费者独立
> - 削峰：高峰期任务排队处理
> - 可靠：消息持久化，不会丢失

---

## 6. 🔪 数据分片策略


### 6.1 什么是数据分片


**简单理解**：把大表拆成多个小表

```
原始大表（1000万条）：
┌─────────────────────┐
│   user_table        │
│  (10,000,000 rows)  │  💥 查询慢
└─────────────────────┘

分片后（按用户ID）：
┌──────────┐ ┌──────────┐ ┌──────────┐ ┌──────────┐
│ user_0   │ │ user_1   │ │ user_2   │ │ user_3   │
│ (250万)  │ │ (250万)  │ │ (250万)  │ │ (250万)  │
└──────────┘ └──────────┘ └──────────┘ └──────────┘
                          ✓ 每个表小，查询快
```

### 6.2 分片方式


**方式1：范围分片**

```java
// 根据ID范围分表
分表规则：
ID 1-2500000    → user_0
ID 2500001-5000000 → user_1  
ID 5000001-7500000 → user_2
ID 7500001-10000000 → user_3

// 查询时路由到对应表
public String getTableName(Long userId) {
    if (userId <= 2500000) return "user_0";
    if (userId <= 5000000) return "user_1";
    if (userId <= 7500000) return "user_2";
    return "user_3";
}
```

**方式2：哈希分片**

```java
// 根据ID哈希分表
分表规则：
userId % 4 = 0 → user_0
userId % 4 = 1 → user_1
userId % 4 = 2 → user_2
userId % 4 = 3 → user_3

// 查询时计算表名
public String getTableName(Long userId) {
    int index = (int) (userId % 4);
    return "user_" + index;
}
```

**方式3：时间分片**

```java
// 按月份分表（适合日志表）
分表规则：
2024年1月 → log_202401
2024年2月 → log_202402
2024年3月 → log_202403

// 查询时根据时间路由
public String getTableName(LocalDate date) {
    return "log_" + date.format(DateTimeFormatter.ofPattern("yyyyMM"));
}
```

### 6.3 MyBatis-Plus动态表名实现


**配置动态表名处理器**：

```java
@Configuration
public class MybatisPlusConfig {
    
    @Bean
    public DynamicTableNameInnerInterceptor dynamicTableNameInnerInterceptor() {
        DynamicTableNameInnerInterceptor interceptor = 
            new DynamicTableNameInnerInterceptor();
        
        // 设置表名处理器
        interceptor.setTableNameHandler((sql, tableName) -> {
            
            // 获取当前线程的分片信息
            String shardKey = ShardingContext.getShardKey();
            
            if ("user".equals(tableName)) {
                // 计算分表后缀
                int index = Math.abs(shardKey.hashCode() % 4);
                return tableName + "_" + index;
            }
            
            return tableName;
        });
        
        return interceptor;
    }
}
```

**使用示例**：

```java
@Service
public class UserService {
    
    public User getUserById(Long userId) {
        // 设置分片键
        ShardingContext.setShardKey(String.valueOf(userId));
        
        try {
            // 正常查询，表名会自动替换
            return userMapper.selectById(userId);
            // 实际执行：SELECT * FROM user_2 WHERE id = ?
            
        } finally {
            // 清理上下文
            ShardingContext.clear();
        }
    }
}
```

### 6.4 分片注意事项


> ⚠️ **关键问题**：

**问题1：跨分片查询**
```
需求：查询所有年龄>30的用户
困难：数据分散在4个表中

解决方案：
1. 分别查询4个表，合并结果
2. 使用Elasticsearch等搜索引擎
3. 维护一个全局索引表
```

**问题2：分布式ID**
```
问题：多个表的ID可能重复

解决方案：
1. 雪花算法（Snowflake）
2. 数据库序列
3. Redis自增
```

**问题3：扩容困难**
```
场景：从4个分片扩到8个分片
困难：需要重新分配数据

建议：提前规划好分片数量
```

---

## 7. 📊 性能监控指标


### 7.1 关键性能指标


**核心指标体系**：

```
性能金字塔：
         响应时间 (RT)
        /            \
    吞吐量 (TPS)   并发数 (Concurrent)
      /      \        /        \
  CPU使用   内存占用  数据库连接  慢SQL数量
```

| 指标 | 含义 | 正常范围 | 监控方式 |
|-----|------|---------|---------|
| **响应时间** | 请求处理耗时 | <100ms | 日志、APM |
| **TPS/QPS** | 每秒处理数 | >1000 | 压测工具 |
| **CPU使用率** | CPU占用 | <70% | 系统监控 |
| **内存使用率** | 内存占用 | <80% | JVM监控 |
| **慢SQL数量** | 慢查询统计 | <10/分钟 | 数据库监控 |

### 7.2 SQL执行时间监控


**使用MyBatis-Plus的性能插件**：

```java
@Configuration
public class PerformanceConfig {
    
    @Bean
    public PerformanceInterceptor performanceInterceptor() {
        PerformanceInterceptor interceptor = new PerformanceInterceptor();
        
        // SQL执行超过100ms就打印警告
        interceptor.setMaxTime(100);
        
        // 格式化SQL，方便阅读
        interceptor.setFormat(true);
        
        return interceptor;
    }
}
```

**输出示例**：
```
⏱️ Time: 156ms - SQL: 
SELECT * FROM user 
WHERE status = 1 
  AND age > 30 
ORDER BY create_time DESC 
LIMIT 1000

⚠️ 警告：SQL执行超过100ms，需要优化！
```

### 7.3 慢SQL分析与优化


**慢SQL识别**：

```java
@Aspect
@Component
public class SqlPerformanceAspect {
    
    @Around("execution(* com.example.mapper.*.*(..))")
    public Object monitorSql(ProceedingJoinPoint pjp) throws Throwable {
        long start = System.currentTimeMillis();
        
        Object result = pjp.proceed();
        
        long cost = System.currentTimeMillis() - start;
        
        if (cost > 100) {
            String method = pjp.getSignature().getName();
            log.warn("慢SQL检测: {} 耗时 {}ms", method, cost);
            
            // 记录到监控系统
            reportSlowSql(method, cost);
        }
        
        return result;
    }
}
```

**优化策略**：

```
慢SQL优化检查清单：

✓ 添加索引
  - WHERE条件字段
  - ORDER BY字段  
  - JOIN关联字段

✓ 避免全表扫描
  - 不用 SELECT *
  - 限制结果数量 LIMIT
  - 避免 != 和 NOT IN

✓ 分页优化
  - 使用覆盖索引
  - 避免深分页（offset很大）

✓ 批量操作
  - 用批量插入代替循环单条
  - 用IN代替多次单条查询
```

### 7.4 数据库连接池监控


**HikariCP连接池配置与监控**：

```yaml
spring:
  datasource:
    hikari:
      # 核心配置
      maximum-pool-size: 20      # 最大连接数
      minimum-idle: 5            # 最小空闲连接
      connection-timeout: 30000  # 连接超时30秒
      
      # 监控配置
      leak-detection-threshold: 60000  # 连接泄漏检测（60秒）
      
      # 性能优化
      max-lifetime: 1800000      # 连接最大存活30分钟
      idle-timeout: 600000       # 空闲连接10分钟回收
```

**监控代码**：

```java
@Component
public class ConnectionPoolMonitor {
    
    @Autowired
    private HikariDataSource dataSource;
    
    @Scheduled(fixedRate = 60000)  // 每分钟执行
    public void monitorPool() {
        HikariPoolMXBean pool = dataSource.getHikariPoolMXBean();
        
        int active = pool.getActiveConnections();    // 活跃连接
        int idle = pool.getIdleConnections();        // 空闲连接
        int total = pool.getTotalConnections();      // 总连接数
        int waiting = pool.getThreadsAwaitingConnection();  // 等待线程
        
        log.info("连接池状态 - 活跃:{} 空闲:{} 总数:{} 等待:{}", 
                 active, idle, total, waiting);
        
        // 告警
        if (waiting > 5) {
            log.error("连接池不足！有{}个线程在等待连接", waiting);
            // 发送告警通知
        }
    }
}
```

### 7.5 应用性能监控（APM）


**推荐工具**：

| 工具 | 特点 | 适用场景 |
|-----|------|---------|
| **SkyWalking** | 开源、无侵入 | 微服务链路追踪 |
| **Arthas** | 阿里开源、诊断强大 | 线上问题排查 |
| **Prometheus + Grafana** | 时序数据库 | 指标可视化 |
| **ELK Stack** | 日志分析 | 日志聚合分析 |

**SkyWalking监控示例**：

```
服务调用链路：
┌─────────────┐    ┌─────────────┐    ┌─────────────┐
│  Web请求    │ →  │  Service    │ →  │  Mapper     │
│  150ms      │    │  120ms      │    │  80ms       │
└─────────────┘    └─────────────┘    └─────────────┘
                                            ↓
                                       ┌─────────────┐
                                       │  Database   │
                                       │  75ms       │
                                       └─────────────┘

自动识别慢节点，定位性能瓶颈！
```

---

## 8. 📋 核心要点总结


### 8.1 大数据量处理核心原则


```
🎯 三大核心原则：

1. 化整为零
   大任务 → 拆分 → 小批次 → 逐个击破

2. 异步为主  
   耗时操作 → 后台处理 → 不阻塞用户

3. 监控优化
   实时监控 → 发现问题 → 针对性优化
```

### 8.2 技术方案选择指南


| 场景 | 数据量 | 推荐方案 | 关键点 |
|-----|-------|---------|--------|
| **数据导出** | 100万+ | 流式查询 | `Cursor` + 分批写入 |
| **数据导入** | 50万+ | 分批插入 | `saveBatch` + 500条/批 |
| **数据更新** | 10万+ | 分片更新 | 按ID范围分批 |
| **数据统计** | 千万+ | 异步任务 | `@Async` + MQ |
| **实时查询** | 亿级 | 数据分片 | 动态表名 + 路由 |

### 8.3 性能优化检查清单


> ✅ **开发阶段**

```
☑ 使用分页/流式查询，避免一次加载全部
☑ 批量操作代替循环单条（INSERT/UPDATE）
☑ WHERE条件字段添加索引
☑ 避免SELECT *，只查需要的字段
☑ 合理设置batchSize（500-1000）
```

> ✅ **部署阶段**

```
☑ JVM参数调优（-Xms -Xmx）
☑ 数据库连接池配置（最大连接数）
☑ 启用性能监控插件
☑ 配置慢SQL告警阈值
☑ 准备扩容方案（分片策略）
```

> ✅ **运行阶段**

```
☑ 定期检查慢SQL日志
☑ 监控内存使用趋势
☑ 关注连接池状态
☑ 分析性能监控报告
☑ 及时优化热点代码
```

### 8.4 常见问题与解决方案


**问题1：内存溢出（OOM）**
```
症状：java.lang.OutOfMemoryError
原因：一次加载数据过多
方案：分批查询 + 流式处理
```

**问题2：数据库连接耗尽**
```
症状：Could not get JDBC Connection
原因：连接未释放或并发过高
方案：检查连接泄漏 + 增加连接池
```

**问题3：慢SQL拖垮性能**
```
症状：响应时间突然变长
原因：缺少索引或查询不合理
方案：添加索引 + 优化SQL
```

**问题4：分页深度过大**
```
症状：翻到后面几页很慢
原因：OFFSET值过大
方案：游标分页 + 上次ID记录
```

### 8.5 最佳实践总结


> 💡 **核心记忆点**

```
批处理三要素：
  ✓ 合适的批次大小（500-1000）
  ✓ 及时释放资源（clear列表）
  ✓ 异常处理机制（try-catch）

流式查询三注意：
  ✓ 使用Cursor不用List
  ✓ 设置fetchSize控制速度
  ✓ 记得关闭游标（try-with-resources）

异步处理三步走：
  ✓ 自定义线程池（避免无限创建）
  ✓ 任务状态管理（PROCESSING/COMPLETED）
  ✓ 进度反馈机制（让用户知道进度）

性能监控三层次：
  ✓ 应用层：响应时间、吞吐量
  ✓ 数据库层：慢SQL、连接数
  ✓ 系统层：CPU、内存、磁盘IO
```

> 🎯 **实战口诀**

```
大数据处理有诀窍，
分批流式内存小。
异步解耦不阻塞，
监控优化少不了。
索引合理查询快，
连接池够不会倒。
遇到问题别慌张，
监控日志找症状！
```

---

**相关文档**：
- 📖 [MyBatis-Plus分页插件详解](#)
- 📖 [数据库索引优化指南](#)
- 📖 [Spring异步编程实战](#)
- 📖 [分布式任务调度方案](#)