---
title: 48、批量操作性能优化
---
## 📚 目录

1. [批量操作基础概念](#1-批量操作基础概念)
2. [批量插入优化策略](#2-批量插入优化策略)
3. [JDBC批处理配置](#3-JDBC批处理配置)
4. [事务边界控制](#4-事务边界控制)
5. [内存使用控制](#5-内存使用控制)
6. [批量大小调优](#6-批量大小调优)
7. [数据库连接池优化](#7-数据库连接池优化)
8. [核心要点总结](#8-核心要点总结)

---

## 1. 📖 批量操作基础概念


### 1.1 什么是批量操作


**通俗理解**：
批量操作就像搬家时打包行李——把多个物品装在一个箱子里一次性搬运，比一次拿一件效率高得多。

```
❌ 单条操作（低效）：
用户1 → 数据库
用户2 → 数据库
用户3 → 数据库
...每次都要建立连接、发送SQL、等待响应

✅ 批量操作（高效）：
用户1、用户2、用户3... → 一次性发送 → 数据库
减少网络往返，提升处理速度
```

**🔑 核心概念**：
- **批量插入**：一次性插入多条数据
- **批量更新**：一次性更新多条数据
- **批量删除**：一次性删除多条数据

### 1.2 为什么需要批量操作


**性能对比**：

| 🆚 **对比维度** | **单条操作** | **批量操作** |
|----------------|------------|------------|
| ⏱️ **执行时间** | 1000条×10ms = 10秒 | 1次×500ms = 0.5秒 |
| 🔌 **网络开销** | 1000次往返 | 1次往返 |
| 💾 **数据库压力** | 1000次解析SQL | 1次解析SQL |
| 📈 **性能提升** | 基准 | 提升10-20倍 |

**💡 实际场景**：
- 导入Excel数据（几千到几万条）
- 数据迁移（百万级别）
- 日志批量写入
- 订单批量处理

---

## 2. 🚀 批量插入优化策略


### 2.1 MyBatis-Plus批量插入方式


**方式一：使用saveBatch（推荐新手）**

```java
// 🟢 基础用法 - 简单直接
List<User> users = new ArrayList<>();
for (int i = 0; i < 1000; i++) {
    User user = new User();
    user.setName("用户" + i);
    user.setAge(20 + i % 50);
    users.add(user);
}

// 批量保存，每批1000条（默认）
userService.saveBatch(users);

// 🟡 指定批次大小
userService.saveBatch(users, 500); // 每批500条
```

**方式二：使用insertBatchSomeColumn（性能更优）**

```java
// 🟢 只插入指定字段，性能更好
userMapper.insertBatchSomeColumn(users);

// 🔧 Mapper层需要自定义方法
@Mapper
public interface UserMapper extends BaseMapper<User> {
    
    // 批量插入（排除自动填充字段）
    int insertBatchSomeColumn(List<User> list);
}
```

### 2.2 批量插入性能对比


**🔄 操作流程对比**：

```
普通循环插入：
for(user : users) {
    userMapper.insert(user);  // 每次都执行一次SQL
}
执行SQL次数：1000次
执行时间：约10秒

saveBatch批量：
userService.saveBatch(users);
执行SQL次数：1次（或按批次分多次）
执行时间：约0.5-1秒

原生JDBC批处理：
PreparedStatement.executeBatch();
执行SQL次数：1次
执行时间：约0.3-0.5秒
```

**📊 性能测试数据**：

| 插入方式 | 1000条 | 10000条 | 100000条 |
|---------|--------|---------|----------|
| 循环insert | 10s | 100s | 1000s |
| saveBatch | 0.5s | 5s | 50s |
| JDBC批处理 | 0.3s | 3s | 30s |

---

## 3. ⚙️ JDBC批处理配置


### 3.1 开启JDBC批处理


**🔧 数据库连接URL配置**：

```yaml
# application.yml
spring:
  datasource:
    url: jdbc:mysql://localhost:3306/test?
      rewriteBatchedStatements=true&  # 👈 核心参数：开启批处理重写
      cachePrepStmts=true&            # 开启预编译缓存
      useServerPrepStmts=true         # 使用服务端预编译
    username: root
    password: 123456
```

**💡 参数说明**：

| 参数 | 作用 | 效果 |
|-----|------|------|
| `rewriteBatchedStatements` | 批量SQL重写 | 将多条INSERT合并成一条 |
| `cachePrepStmts` | 预编译缓存 | 减少SQL解析时间 |
| `useServerPrepStmts` | 服务端预编译 | 提升执行效率 |

### 3.2 SQL重写原理


**🔍 重写前后对比**：

```sql
-- ❌ 未开启重写（执行3次）
INSERT INTO user (name, age) VALUES ('张三', 20);
INSERT INTO user (name, age) VALUES ('李四', 21);
INSERT INTO user (name, age) VALUES ('王五', 22);

-- ✅ 开启重写后（执行1次）
INSERT INTO user (name, age) VALUES 
('张三', 20),
('李四', 21),
('王五', 22);
```

**⚡ 性能提升原理**：
- 减少网络往返次数（3次 → 1次）
- 减少SQL解析次数（3次 → 1次）
- 减少事务开销（3次提交 → 1次提交）

---

## 4. 🔐 事务边界控制


### 4.1 事务对批量操作的影响


**通俗理解**：
事务就像银行转账——要么全部成功，要么全部失败。批量操作时，事务控制不当会严重影响性能。

```
❌ 错误做法：每条数据一个事务
for(user : users) {
    @Transactional  // 每次都开启新事务
    userService.save(user);
}
问题：1000条数据 = 1000个事务 = 超级慢

✅ 正确做法：整批数据一个事务
@Transactional
public void batchSave(List<User> users) {
    userService.saveBatch(users);
}
优势：1000条数据 = 1个事务 = 快速完成
```

### 4.2 事务大小控制


**🎯 分批事务策略**：

```java
@Service
public class UserBatchService {
    
    @Autowired
    private UserService userService;
    
    /**
     * 分批处理大量数据
     * 避免单个事务过大导致内存溢出
     */
    public void batchSaveWithTransaction(List<User> allUsers) {
        int batchSize = 1000;  // 每批1000条
        
        // 🔄 分批处理
        for (int i = 0; i < allUsers.size(); i += batchSize) {
            int end = Math.min(i + batchSize, allUsers.size());
            List<User> batch = allUsers.subList(i, end);
            
            // 每批一个事务
            saveBatchInTransaction(batch);
        }
    }
    
    @Transactional(rollbackFor = Exception.class)
    public void saveBatchInTransaction(List<User> users) {
        userService.saveBatch(users);
    }
}
```

**⚖️ 事务大小权衡**：

| 事务大小 | 优点 | 缺点 | 适用场景 |
|---------|------|------|---------|
| 小事务（100条） | 内存占用少 | 事务次数多，开销大 | 内存受限环境 |
| 中事务（1000条） | 平衡性能和内存 | - | ⭐⭐⭐ 推荐使用 |
| 大事务（10000+） | 事务次数少 | 内存占用高，失败回滚慢 | 数据一致性要求高 |

---

## 5. 💾 内存使用控制


### 5.1 内存溢出问题


**问题场景**：
```
❌ 危险操作：一次性加载百万数据
List<User> users = userMapper.selectList(null);  // 💥 OOM风险
users.forEach(user -> {
    // 处理逻辑
});
```

**🧠 内存消耗分析**：
```
假设每个User对象占用200字节
100万条数据 = 1,000,000 × 200字节 = 200MB
加上JVM其他开销 ≈ 300-400MB内存占用
如果JVM堆内存只有512MB → 很容易OOM
```

### 5.2 流式查询+批量处理


**✅ 解决方案：分批查询和处理**

```java
@Service
public class UserBatchService {
    
    @Autowired
    private UserMapper userMapper;
    
    /**
     * 分批查询处理，避免内存溢出
     */
    public void processBigData() {
        int pageSize = 1000;  // 每页1000条
        int pageNum = 1;
        
        while (true) {
            // 📄 分页查询
            Page<User> page = new Page<>(pageNum, pageSize);
            IPage<User> userPage = userMapper.selectPage(page, null);
            
            List<User> users = userPage.getRecords();
            if (users.isEmpty()) {
                break;  // 没有数据了，退出
            }
            
            // 🔄 批量处理当前页数据
            processBatch(users);
            
            pageNum++;
        }
    }
    
    @Transactional
    public void processBatch(List<User> users) {
        // 批量更新逻辑
        userService.updateBatchById(users);
    }
}
```

**🎯 内存控制技巧**：

```
✅ 技巧1：分页查询
每次只加载1000条，处理完释放内存

✅ 技巧2：流式处理
使用@ResultType(ResultSetType.FORWARD_ONLY)
配合fetchSize控制每次读取行数

✅ 技巧3：及时释放
处理完一批数据后，显式设置为null
帮助GC回收内存
```

---

## 6. 📏 批量大小调优


### 6.1 最佳批量大小选择


**🔍 批量大小影响因素**：

```
影响因素分析：
┌─────────────────────────────────┐
│  批量大小  │  影响维度         │
├─────────────────────────────────┤
│  太小(100) │ 事务次数多，性能差 │
│  适中(1000)│ 平衡性能和内存    │
│  太大(10000)│ 内存压力大，风险高│
└─────────────────────────────────┘
```

**📊 实测数据参考**：

| 数据量 | 批次大小 | 执行时间 | 内存占用 | 推荐度 |
|--------|---------|---------|---------|--------|
| 1000条 | 100 | 1.2s | 低 | ⭐⭐ |
| 1000条 | 500 | 0.6s | 中 | ⭐⭐⭐ |
| 1000条 | 1000 | 0.5s | 中 | ⭐⭐⭐ |
| 10000条 | 500 | 6s | 中 | ⭐⭐⭐ |
| 10000条 | 2000 | 4s | 高 | ⭐⭐ |
| 100000条 | 1000 | 50s | 中 | ⭐⭐⭐ |

### 6.2 动态批量大小配置


```java
@Configuration
public class BatchConfig {
    
    /**
     * 根据数据量动态调整批次大小
     */
    public int calculateBatchSize(int totalSize) {
        if (totalSize < 1000) {
            return 500;      // 小数据量：500
        } else if (totalSize < 10000) {
            return 1000;     // 中等数据量：1000
        } else {
            return 2000;     // 大数据量：2000
        }
    }
}

// 使用示例
@Service
public class UserBatchService {
    
    public void smartBatchSave(List<User> users) {
        int batchSize = calculateBatchSize(users.size());
        userService.saveBatch(users, batchSize);
    }
}
```

**💡 选择建议**：

| 场景 | 推荐批量大小 | 原因 |
|------|------------|------|
| 🏃 实时导入 | 500-1000 | 快速响应，减少等待 |
| 📦 离线批处理 | 1000-2000 | 平衡性能和资源 |
| 🔄 数据迁移 | 2000-5000 | 追求最大吞吐量 |
| 💻 内存受限 | 200-500 | 控制内存占用 |

---

## 7. 🏊 数据库连接池优化


### 7.1 连接池基础配置


**通俗理解**：
连接池就像停车场——提前准备好停车位（数据库连接），车来了直接停（拿连接使用），走了还回去（归还连接），比每次临时找停车位快得多。

**🔧 HikariCP配置（SpringBoot默认）**：

```yaml
spring:
  datasource:
    hikari:
      # 🏊 连接池大小配置
      minimum-idle: 10          # 最小空闲连接数
      maximum-pool-size: 20     # 最大连接数
      
      # ⏱️ 超时配置
      connection-timeout: 30000  # 获取连接超时时间(ms)
      idle-timeout: 600000       # 空闲连接超时时间(ms)
      max-lifetime: 1800000      # 连接最大生命周期(ms)
      
      # ✅ 连接测试
      connection-test-query: SELECT 1
```

### 7.2 批量操作的连接池调优


**⚙️ 关键参数说明**：

| 参数 | 默认值 | 批量操作推荐 | 说明 |
|------|--------|------------|------|
| `maximum-pool-size` | 10 | 20-50 | 批量操作并发高，需要更多连接 |
| `minimum-idle` | 10 | 10-20 | 保持足够空闲连接 |
| `connection-timeout` | 30s | 60s | 批量操作耗时长，延长超时 |

**🎯 不同场景的配置**：

```yaml
# 场景1：高并发批量插入
spring:
  datasource:
    hikari:
      maximum-pool-size: 50      # 🔼 提高连接数
      minimum-idle: 20
      connection-timeout: 60000

# 场景2：单线程大批量处理
spring:
  datasource:
    hikari:
      maximum-pool-size: 10      # 连接数不需要太多
      minimum-idle: 5
      connection-timeout: 120000  # 🔼 延长超时时间
```

### 7.3 连接池监控


**📊 监控关键指标**：

```java
// 获取连接池状态
@Component
public class DataSourceMonitor {
    
    @Autowired
    private DataSource dataSource;
    
    public void printPoolStatus() {
        HikariDataSource hikariDS = (HikariDataSource) dataSource;
        HikariPoolMXBean poolMXBean = hikariDS.getHikariPoolMXBean();
        
        System.out.println("🏊 连接池状态：");
        System.out.println("总连接数: " + poolMXBean.getTotalConnections());
        System.out.println("活跃连接数: " + poolMXBean.getActiveConnections());
        System.out.println("空闲连接数: " + poolMXBean.getIdleConnections());
        System.out.println("等待线程数: " + poolMXBean.getThreadsAwaitingConnection());
    }
}
```

**⚠️ 常见问题诊断**：

| 问题现象 | 可能原因 | 解决方案 |
|---------|---------|---------|
| 获取连接超时 | 连接池太小 | 增大`maximum-pool-size` |
| 连接频繁创建销毁 | 空闲连接太少 | 增大`minimum-idle` |
| 连接泄露 | 未正确归还 | 检查代码，使用`try-with-resources` |

---

## 8. 📋 核心要点总结


### 8.1 必须掌握的核心概念


```
🔸 批量操作本质：一次性处理多条数据，减少数据库交互次数
🔸 JDBC批处理：通过rewriteBatchedStatements开启SQL重写
🔸 事务控制：合理划分事务边界，避免事务过大或过小
🔸 内存管理：分批处理避免OOM，及时释放内存
🔸 批量大小：根据数据量和场景选择合适的批次大小
🔸 连接池优化：调整连接数和超时时间适应批量操作
```

### 8.2 性能优化核心技巧


**🚀 优化检查清单**：

- ✅ **开启JDBC批处理重写**
  ```yaml
  url: jdbc:mysql://...?rewriteBatchedStatements=true
  ```

- ✅ **使用saveBatch代替循环insert**
  ```java
  userService.saveBatch(users, 1000);  // 而不是for循环insert
  ```

- ✅ **合理控制事务大小**
  ```java
  // 每1000条一个事务，而不是全部数据一个事务
  saveBatchInTransaction(batch);
  ```

- ✅ **分批查询处理大数据**
  ```java
  // 分页查询，每次处理1000条
  Page<User> page = new Page<>(pageNum, 1000);
  ```

- ✅ **调整连接池参数**
  ```yaml
  hikari:
    maximum-pool-size: 20  # 增加连接数
  ```

### 8.3 实际应用建议


**💡 场景化最佳实践**：

| 应用场景 | 推荐方案 | 关键配置 |
|---------|---------|---------|
| 📊 **Excel导入** | saveBatch分批 | 批次1000，开启JDBC批处理 |
| 🔄 **数据迁移** | 流式查询+批量插入 | 批次2000，事务分段 |
| 📝 **日志写入** | 异步批量插入 | 批次500，非事务 |
| 🛒 **订单处理** | 事务批量更新 | 批次1000，严格事务 |

**🧠 记忆口诀**：
```
批量操作记三点：
重写SQL效率高（JDBC批处理）
事务分批内存小（分批事务）
连接池大不慌张（连接池优化）
```

**⚠️ 常见误区**：

| ❌ 错误做法 | ✅ 正确做法 |
|-----------|-----------|
| 循环单条insert | 使用saveBatch批量插入 |
| 每条数据一个事务 | 批次数据共享一个事务 |
| 一次性加载百万数据 | 分批查询分批处理 |
| 使用默认连接池配置 | 根据场景调优连接数 |

### 8.4 性能提升效果


**📈 优化前后对比**：

```
优化前（单条循环）：
插入10000条数据 → 耗时约100秒
内存占用：200MB
数据库连接：频繁创建销毁

优化后（批量+优化）：
插入10000条数据 → 耗时约5秒  ⚡ 提升20倍
内存占用：50MB              📉 降低75%
数据库连接：复用连接池      💪 稳定高效
```

**🎯 核心价值**：
- **性能提升**：10-20倍的性能提升
- **资源节约**：内存和CPU占用显著降低
- **系统稳定**：减少数据库压力，提升系统稳定性
- **用户体验**：缩短等待时间，提升用户满意度