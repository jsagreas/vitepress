---
title: 5、运维自动化与DevOps
---
## 📚 目录

1. [运维自动化基础概念](#1-运维自动化基础概念)
2. [自动化部署实践](#2-自动化部署实践)
3. [配置管理与版本控制](#3-配置管理与版本控制)
4. [监控与告警自动化](#4-监控与告警自动化)
5. [容器化与编排部署](#5-容器化与编排部署)
6. [CI/CD流水线集成](#6-CICD流水线集成)
7. [高可用部署策略](#7-高可用部署策略)
8. [核心要点总结](#8-核心要点总结)

---

## 1. 🤖 运维自动化基础概念


### 1.1 什么是运维自动化


**🔸 通俗理解**
```
传统运维方式：
手动安装 → 手动配置 → 手动监控 → 手动处理故障
     ↓             ↓           ↓             ↓
   耗时长        易出错      反应慢        经验依赖

自动化运维方式：
脚本安装 → 模板配置 → 自动监控 → 自动恢复
     ↓             ↓           ↓             ↓
   快速         一致性      实时         标准化
```

**💡 核心价值**
- **提高效率**：原本1小时的部署，自动化后只需5分钟
- **减少错误**：避免人工操作的配置遗漏和输入错误
- **标准化**：确保每次部署的环境和配置完全一致
- **可重复**：随时可以重现相同的部署过程

### 1.2 Infrastructure as Code 基础概念


**🔸 什么是基础设施即代码**
```
传统方式：基础设施通过图形界面手动创建
IaC方式：基础设施通过代码文件自动创建

就像做菜：
传统方式：每次凭经验和记忆做菜
IaC方式：按照标准菜谱做菜，结果可预期
```

**📋 IaC 的核心优势**
- **版本控制**：基础设施配置可以像代码一样进行版本管理
- **可审计**：所有变更都有记录，可以追溯
- **环境一致性**：开发、测试、生产环境完全一致
- **快速复制**：可以快速在不同区域创建相同环境

### 1.3 DevOps文化理念


**🔄 DevOps核心思想**
```
开发团队 ←→ 运维团队
    ↓           ↓
  Dev        Ops
    ↘       ↙
    DevOps
      ↓
协作、自动化、持续改进
```

**🎯 DevOps实践目标**
- **缩短发布周期**：从月发布到周发布甚至日发布
- **提高发布质量**：通过自动化测试减少生产问题
- **快速故障恢复**：自动化监控和恢复机制
- **团队协作**：开发和运维团队紧密合作

---

## 2. 🚀 自动化部署实践


### 2.1 Ansible自动化部署


**🔸 Ansible简介**
> Ansible是一个简单而强大的自动化工具，就像是服务器的"遥控器"，可以同时控制多台服务器执行相同操作。

**📖 基本概念**
```
Ansible组件说明：

Inventory文件：服务器清单
   ↓
告诉Ansible要管理哪些服务器

Playbook文件：任务手册  
   ↓
告诉Ansible要执行什么任务

Module模块：具体功能
   ↓  
告诉Ansible怎么执行任务
```

**🛠 Elasticsearch集群部署示例**

**Inventory配置**
```ini
# inventory/elasticsearch.ini
[es_masters]
es-master-1 ansible_host=10.0.1.10
es-master-2 ansible_host=10.0.1.11  
es-master-3 ansible_host=10.0.1.12

[es_data]
es-data-1 ansible_host=10.0.1.20
es-data-2 ansible_host=10.0.1.21
es-data-3 ansible_host=10.0.1.22

[elasticsearch:children]
es_masters
es_data
```

**核心部署Playbook**
```yaml
# playbooks/deploy-elasticsearch.yml
---
- name: 部署Elasticsearch集群
  hosts: elasticsearch
  become: yes
  vars:
    es_version: "8.10.0"
    es_cluster_name: "my-es-cluster"
  
  tasks:
    - name: 创建elasticsearch用户
      user:
        name: elasticsearch
        system: yes
        shell: /bin/false
    
    - name: 下载Elasticsearch
      get_url:
        url: "https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-{{ es_version }}-linux-x86_64.tar.gz"
        dest: /tmp/elasticsearch.tar.gz
    
    - name: 解压安装
      unarchive:
        src: /tmp/elasticsearch.tar.gz
        dest: /opt
        remote_src: yes
        owner: elasticsearch
        group: elasticsearch
    
    - name: 创建配置文件
      template:
        src: elasticsearch.yml.j2
        dest: /opt/elasticsearch-{{ es_version }}/config/elasticsearch.yml
        owner: elasticsearch
        group: elasticsearch
      notify: restart elasticsearch
    
    - name: 启动Elasticsearch服务
      systemd:
        name: elasticsearch
        state: started
        enabled: yes
```

### 2.2 自动扩容机制


**🔧 动态扩容策略**

```
扩容触发条件：
CPU使用率 > 80% 持续5分钟
    ↓
内存使用率 > 85% 持续5分钟  
    ↓
磁盘使用率 > 90%
    ↓
自动触发扩容流程
```

**📊 自动扩容实现**
```bash
#!/bin/bash
# 自动扩容脚本示例

# 监控指标检查
check_cluster_health() {
    local cpu_usage=$(get_avg_cpu_usage)
    local memory_usage=$(get_avg_memory_usage)
    local disk_usage=$(get_avg_disk_usage)
    
    if [[ $cpu_usage -gt 80 && $memory_usage -gt 85 ]]; then
        echo "触发扩容条件：CPU=${cpu_usage}%, 内存=${memory_usage}%"
        return 0
    fi
    return 1
}

# 执行扩容
scale_cluster() {
    echo "开始自动扩容..."
    
    # 1. 准备新节点
    ansible-playbook deploy-new-node.yml
    
    # 2. 加入集群
    ansible-playbook join-cluster.yml
    
    # 3. 验证节点状态
    verify_new_node
    
    echo "扩容完成"
}

# 主流程
if check_cluster_health; then
    scale_cluster
fi
```

### 2.3 配置模板化管理


**📝 配置模板示例**
```yaml
# templates/elasticsearch.yml.j2
cluster.name: {{ es_cluster_name }}
node.name: {{ ansible_hostname }}

# 节点角色配置
{% if inventory_hostname in groups['es_masters'] %}
node.roles: [ master, data ]
{% else %}
node.roles: [ data ]
{% endif %}

# 网络配置
network.host: {{ ansible_default_ipv4.address }}
http.port: 9200
transport.port: 9300

# 集群发现配置
discovery.seed_hosts:
{% for host in groups['es_masters'] %}
  - {{ hostvars[host]['ansible_default_ipv4']['address'] }}:9300
{% endfor %}

cluster.initial_master_nodes:
{% for host in groups['es_masters'] %}
  - {{ hostvars[host]['ansible_hostname'] }}
{% endfor %}

# 内存配置
bootstrap.memory_lock: true

# 安全配置
xpack.security.enabled: {{ enable_security | default(true) }}
```

---

## 3. ⚙️ 配置管理与版本控制


### 3.1 版本管理策略


**🔸 配置版本化的重要性**
```
问题场景：
生产环境出现问题 → 需要回滚配置 → 不知道之前配置内容
     ↓                    ↓                ↓
 系统不稳定           回滚困难          恢复时间长

解决方案：
配置版本化 → Git管理 → 标签发布 → 快速回滚
     ↓          ↓         ↓         ↓
 可追溯      可对比    可发布    可恢复
```

**📁 配置文件组织结构**
```
elasticsearch-config/
├── environments/
│   ├── dev/
│   │   ├── inventory.ini
│   │   └── group_vars/
│   ├── staging/
│   │   ├── inventory.ini
│   │   └── group_vars/
│   └── prod/
│       ├── inventory.ini
│       └── group_vars/
├── playbooks/
│   ├── deploy.yml
│   ├── upgrade.yml
│   └── rollback.yml
├── templates/
│   └── elasticsearch.yml.j2
└── scripts/
    ├── deploy.sh
    └── health-check.sh
```

### 3.2 配置管理最佳实践


**🎯 环境隔离策略**

| 🏷️ 环境 | **用途** | **配置特点** | **更新频率** |
|---------|---------|-------------|-------------|
| 🧪 **开发环境** | `功能开发测试` | 配置简单，资源较少 | 频繁更新 |
| 🔍 **测试环境** | `集成测试验证` | 接近生产配置 | 定期更新 |
| 🎭 **预发环境** | `上线前验证` | 完全模拟生产 | 发布前更新 |
| 🚀 **生产环境** | `用户服务` | 高可用高性能配置 | 谨慎更新 |

**🔧 配置变更流程**
```
配置变更标准流程：

1. 开发环境验证
   ↓
2. 代码审查(Code Review)
   ↓  
3. 测试环境部署
   ↓
4. 自动化测试验证
   ↓
5. 预发环境部署
   ↓
6. 业务功能验证
   ↓
7. 生产环境发布
   ↓
8. 监控验证结果
```

---

## 4. 📊 监控与告警自动化


### 4.1 监控自动化架构


**🔸 监控体系架构**
```
监控数据收集层：
Metricbeat → Filebeat → Heartbeat
    ↓           ↓          ↓
  性能指标    日志数据    可用性检查

数据处理层：
Elasticsearch ← Logstash ← 各种Beat
      ↓
  存储和索引监控数据

展示分析层：  
Kibana Dashboard → Grafana → 自定义看板
      ↓              ↓           ↓
   可视化展示      图表分析    业务看板

告警处理层：
ElastAlert → Watcher → 自定义脚本
     ↓         ↓          ↓
  规则引擎   实时监控   自动处理
```

### 4.2 核心监控指标


**📈 集群健康监控**
```yaml
# 集群状态监控配置
cluster_health_monitors:
  - name: "集群状态检查"
    query: "GET /_cluster/health"
    alert_conditions:
      - status: "red"
        action: "立即告警并尝试自动恢复"
      - status: "yellow"  
        action: "警告通知，持续监控"
  
  - name: "节点状态检查"
    query: "GET /_cat/nodes?v"
    alert_conditions:
      - node_count: "< 3"
        action: "节点数量不足告警"
      - heap_usage: "> 85%"
        action: "内存使用过高告警"
```

**⚡ 性能监控指标**

| 📊 **监控类别** | **关键指标** | **正常范围** | **告警阈值** |
|---------------|-------------|-------------|-------------|
| 🖥️ **系统资源** | CPU使用率 | < 70% | > 85% |
| 💾 **内存使用** | 堆内存使用率 | < 75% | > 90% |
| 💿 **磁盘IO** | 磁盘使用率 | < 80% | > 95% |
| 🌐 **网络流量** | 网络带宽使用 | < 60% | > 80% |
| 🔍 **搜索性能** | 查询响应时间 | < 100ms | > 500ms |
| 📝 **索引性能** | 索引写入速度 | > 1000/s | < 500/s |

### 4.3 告警自动化配置


**🚨 ElastAlert告警配置**
```yaml
# elastalert_rules/cluster_health.yml
es_host: localhost
es_port: 9200
name: ES集群健康告警
type: any
index: .monitoring-es-*

filter:
- term:
    cluster_stats.status: "red"

alert:
- "email"
- "slack"

email:
- "ops-team@company.com"

slack:
webhook_url: "https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK"
slack_channel_override: "#elasticsearch-alerts"

alert_text: |
  🚨 ES集群状态异常！
  
  集群名称: {0}
  当前状态: {1}  
  时间: {2}
  
  请立即检查集群状态！

alert_text_args:
  - cluster_stats.cluster_name
  - cluster_stats.status
  - "@timestamp"

# 告警频率控制
realert:
  minutes: 5
```

**🔄 自动恢复脚本**
```bash
#!/bin/bash
# 自动恢复脚本

check_and_recover() {
    local cluster_status=$(curl -s "localhost:9200/_cluster/health" | jq -r '.status')
    
    case $cluster_status in
        "red")
            echo "检测到集群RED状态，开始自动恢复..."
            
            # 1. 检查分片状态
            check_unassigned_shards
            
            # 2. 尝试重新分配分片
            curl -X POST "localhost:9200/_cluster/reroute?retry_failed=true"
            
            # 3. 检查磁盘空间
            check_disk_space
            
            # 4. 重启问题节点（如果需要）
            restart_failed_nodes
            ;;
        "yellow")
            echo "集群YELLOW状态，增加副本分片..."
            increase_replica_count
            ;;
        "green")
            echo "集群状态正常"
            ;;
    esac
}

# 主循环
while true; do
    check_and_recover
    sleep 60
done
```

---

## 5. 📦 容器化与编排部署


### 5.1 Docker容器化基础


**🔸 容器化的优势**
```
传统部署 vs 容器化部署：

传统方式：
应用 → 依赖安装 → 系统配置 → 手动部署
  ↓        ↓          ↓          ↓
环境差异   版本冲突   配置复杂   部署繁琐

容器化方式：  
应用 → 打包镜像 → 容器运行 → 自动部署
  ↓        ↓          ↓          ↓
环境一致   隔离完整   配置简单   部署便捷
```

**🐳 Elasticsearch Docker配置**
```dockerfile
# Dockerfile
FROM docker.elastic.co/elasticsearch/elasticsearch:8.10.0

# 自定义配置
COPY config/elasticsearch.yml /usr/share/elasticsearch/config/
COPY config/jvm.options /usr/share/elasticsearch/config/

# 插件安装
RUN bin/elasticsearch-plugin install analysis-ik

# 设置权限
USER elasticsearch

EXPOSE 9200 9300
```

**📋 Docker Compose集群配置**
```yaml
# docker-compose.yml
version: '3.8'

services:
  es-master-1:
    image: elasticsearch:8.10.0
    container_name: es-master-1
    environment:
      - node.name=es-master-1
      - cluster.name=es-docker-cluster
      - node.roles=master,data
      - discovery.seed_hosts=es-master-2,es-master-3
      - cluster.initial_master_nodes=es-master-1,es-master-2,es-master-3
      - "ES_JAVA_OPTS=-Xms1g -Xmx1g"
    volumes:
      - es-data-1:/usr/share/elasticsearch/data
      - ./config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml
    ports:
      - "9201:9200"
    networks:
      - es-network

  es-master-2:
    image: elasticsearch:8.10.0
    container_name: es-master-2
    environment:
      - node.name=es-master-2
      - cluster.name=es-docker-cluster
      - node.roles=master,data
      - discovery.seed_hosts=es-master-1,es-master-3
      - cluster.initial_master_nodes=es-master-1,es-master-2,es-master-3
      - "ES_JAVA_OPTS=-Xms1g -Xmx1g"
    volumes:
      - es-data-2:/usr/share/elasticsearch/data
    ports:
      - "9202:9200"
    networks:
      - es-network

volumes:
  es-data-1:
  es-data-2:
  es-data-3:

networks:
  es-network:
    driver: bridge
```

### 5.2 Kubernetes集群编排


**☸️ Kubernetes部署架构**
```
Kubernetes集群部署架构：

Master节点 (控制平面)
    ↓
StatefulSet → Pod管理
    ↓
Service → 负载均衡  
    ↓
Ingress → 外部访问
    ↓
PersistentVolume → 数据持久化
```

**🎯 StatefulSet配置示例**
```yaml
# k8s/elasticsearch-statefulset.yml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: elasticsearch
  namespace: elastic
spec:
  serviceName: elasticsearch
  replicas: 3
  selector:
    matchLabels:
      app: elasticsearch
  template:
    metadata:
      labels:
        app: elasticsearch
    spec:
      containers:
      - name: elasticsearch
        image: elasticsearch:8.10.0
        env:
        - name: cluster.name
          value: "k8s-es-cluster"
        - name: node.name
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: discovery.seed_hosts
          value: "elasticsearch-0.elasticsearch,elasticsearch-1.elasticsearch,elasticsearch-2.elasticsearch"
        - name: cluster.initial_master_nodes
          value: "elasticsearch-0,elasticsearch-1,elasticsearch-2"
        - name: ES_JAVA_OPTS
          value: "-Xms1g -Xmx1g"
        ports:
        - containerPort: 9200
          name: http
        - containerPort: 9300
          name: transport
        volumeMounts:
        - name: data
          mountPath: /usr/share/elasticsearch/data
        resources:
          requests:
            memory: 2Gi
            cpu: 1000m
          limits:
            memory: 4Gi
            cpu: 2000m
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 100Gi
```

### 5.3 服务发现与负载均衡


**🔍 服务发现机制**
```yaml
# k8s/elasticsearch-service.yml
apiVersion: v1
kind: Service
metadata:
  name: elasticsearch
  namespace: elastic
spec:
  clusterIP: None  # Headless Service
  selector:
    app: elasticsearch
  ports:
  - port: 9200
    name: http
  - port: 9300
    name: transport

---
apiVersion: v1
kind: Service  
metadata:
  name: elasticsearch-client
  namespace: elastic
spec:
  type: LoadBalancer
  selector:
    app: elasticsearch
  ports:
  - port: 9200
    targetPort: 9200
    name: http
```

**⚖️ 负载均衡配置**
```yaml
# k8s/elasticsearch-ingress.yml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: elasticsearch-ingress
  namespace: elastic
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/backend-protocol: "HTTP"
    nginx.ingress.kubernetes.io/proxy-connect-timeout: "600"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "600"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "600"
spec:
  rules:
  - host: elasticsearch.company.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: elasticsearch-client
            port:
              number: 9200
```

---

## 6. 🔄 CI/CD流水线集成


### 6.1 CI/CD基础概念


**🔸 什么是CI/CD**
```
持续集成(CI)：
代码提交 → 自动构建 → 自动测试 → 反馈结果
    ↓           ↓           ↓           ↓
 频繁集成     快速发现     质量保证    快速反馈

持续部署(CD)：
测试通过 → 自动部署 → 环境验证 → 生产发布
    ↓           ↓           ↓           ↓
 质量保证     快速交付     环境一致    持续价值
```

**💡 CI/CD价值**
- **缩短发布周期**：从周发布到日发布
- **提高代码质量**：每次提交都经过测试验证
- **减少人工错误**：自动化消除手动操作失误
- **快速反馈**：问题能在最短时间内被发现

### 6.2 Jenkins流水线配置


**🔧 Jenkinsfile示例**
```groovy
// Jenkinsfile
pipeline {
    agent any
    
    environment {
        DOCKER_REGISTRY = 'registry.company.com'
        ES_IMAGE_NAME = 'elasticsearch-custom'
        K8S_NAMESPACE = 'elastic'
    }
    
    stages {
        stage('代码检出') {
            steps {
                git branch: 'main', 
                    url: 'https://github.com/company/elasticsearch-config.git'
            }
        }
        
        stage('配置验证') {
            steps {
                script {
                    // 验证YAML格式
                    sh 'yamllint k8s/*.yml'
                    
                    // 验证Elasticsearch配置
                    sh 'elasticsearch --check-config'
                }
            }
        }
        
        stage('构建镜像') {
            steps {
                script {
                    def image = docker.build("${DOCKER_REGISTRY}/${ES_IMAGE_NAME}:${BUILD_NUMBER}")
                    docker.withRegistry('https://registry.company.com', 'docker-registry-credentials') {
                        image.push()
                        image.push("latest")
                    }
                }
            }
        }
        
        stage('部署到测试环境') {
            steps {
                script {
                    sh '''
                        kubectl config use-context test-cluster
                        kubectl set image statefulset/elasticsearch elasticsearch=${DOCKER_REGISTRY}/${ES_IMAGE_NAME}:${BUILD_NUMBER} -n ${K8S_NAMESPACE}
                        kubectl rollout status statefulset/elasticsearch -n ${K8S_NAMESPACE}
                    '''
                }
            }
        }
        
        stage('集成测试') {
            steps {
                script {
                    sh '''
                        # 等待服务启动
                        sleep 60
                        
                        # 健康检查
                        curl -f http://elasticsearch-test.company.com/_cluster/health
                        
                        # 功能测试
                        python tests/integration_tests.py
                    '''
                }
            }
        }
        
        stage('部署到生产环境') {
            when {
                branch 'main'
            }
            steps {
                script {
                    // 需要人工确认
                    input message: '确认部署到生产环境？', ok: '部署'
                    
                    sh '''
                        kubectl config use-context prod-cluster
                        kubectl set image statefulset/elasticsearch elasticsearch=${DOCKER_REGISTRY}/${ES_IMAGE_NAME}:${BUILD_NUMBER} -n ${K8S_NAMESPACE}
                        kubectl rollout status statefulset/elasticsearch -n ${K8S_NAMESPACE}
                    '''
                }
            }
        }
    }
    
    post {
        always {
            // 清理工作空间
            cleanWs()
        }
        
        success {
            // 成功通知
            slackSend channel: '#elasticsearch-ops',
                     color: 'good', 
                     message: "✅ ES部署成功 - Build #${BUILD_NUMBER}"
        }
        
        failure {
            // 失败通知
            slackSend channel: '#elasticsearch-ops',
                     color: 'danger',
                     message: "❌ ES部署失败 - Build #${BUILD_NUMBER}"
        }
    }
}
```

### 6.3 GitLab CI/CD配置


**📋 .gitlab-ci.yml示例**
```yaml
# .gitlab-ci.yml
stages:
  - validate
  - build
  - test
  - deploy-staging
  - deploy-production

variables:
  DOCKER_DRIVER: overlay2
  DOCKER_TLS_CERTDIR: "/certs"

# 配置验证阶段
validate-config:
  stage: validate
  image: alpine:latest
  before_script:
    - apk add --no-cache yamllint
  script:
    - yamllint config/
    - yamllint k8s/
  only:
    - merge_requests
    - main

# 构建镜像阶段
build-image:
  stage: build
  image: docker:latest
  services:
    - docker:dind
  script:
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
    - docker build -t $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA .
    - docker push $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA
  only:
    - main

# 测试阶段
test-deployment:
  stage: test
  image: bitnami/kubectl:latest
  script:
    - kubectl config use-context test-cluster
    - kubectl apply -f k8s/
    - kubectl set image statefulset/elasticsearch elasticsearch=$CI_REGISTRY_IMAGE:$CI_COMMIT_SHA
    - kubectl rollout status statefulset/elasticsearch
    - ./scripts/health-check.sh
  only:
    - main

# 预发环境部署
deploy-staging:
  stage: deploy-staging
  image: bitnami/kubectl:latest
  script:
    - kubectl config use-context staging-cluster
    - kubectl apply -f k8s/
    - kubectl set image statefulset/elasticsearch elasticsearch=$CI_REGISTRY_IMAGE:$CI_COMMIT_SHA
    - kubectl rollout status statefulset/elasticsearch
  only:
    - main
  when: manual

# 生产环境部署
deploy-production:
  stage: deploy-production
  image: bitnami/kubectl:latest
  script:
    - kubectl config use-context prod-cluster
    - kubectl apply -f k8s/
    - kubectl set image statefulset/elasticsearch elasticsearch=$CI_REGISTRY_IMAGE:$CI_COMMIT_SHA
    - kubectl rollout status statefulset/elasticsearch
  only:
    - main
  when: manual
  environment:
    name: production
    url: https://elasticsearch.company.com
```

---

## 7. 🎯 高可用部署策略


### 7.1 蓝绿部署


**🔸 蓝绿部署原理**
```
蓝绿部署示意图：

生产流量 → 负载均衡器 → 蓝环境(当前版本)
                ↓
              绿环境(新版本) ← 部署新版本

验证完成后切换：
生产流量 → 负载均衡器 → 绿环境(新版本)
                ↓
              蓝环境(旧版本) ← 保留作为回滚备份
```

**💡 蓝绿部署优势**
- **零停机时间**：新版本部署完成后一键切换
- **快速回滚**：出现问题立即切回旧版本
- **完整测试**：新版本可以完整测试后再切换
- **风险可控**：新旧版本并存，风险最小

**🛠 Kubernetes蓝绿部署配置**
```yaml
# blue-green-deployment.yml
apiVersion: argoproj.io/v1alpha1
kind: Rollout
metadata:
  name: elasticsearch-rollout
spec:
  replicas: 6
  strategy:
    blueGreen:
      # 绿色环境验证时间
      prePromotionAnalysis:
        templates:
        - templateName: success-rate
        args:
        - name: service-name
          value: elasticsearch-green
      # 蓝色环境保留时间
      scaleDownDelaySeconds: 30
      postPromotionAnalysis:
        templates:
        - templateName: success-rate
        args:
        - name: service-name
          value: elasticsearch
      # 服务配置
      activeService: elasticsearch-active
      previewService: elasticsearch-preview
  selector:
    matchLabels:
      app: elasticsearch
  template:
    metadata:
      labels:
        app: elasticsearch
    spec:
      containers:
      - name: elasticsearch
        image: elasticsearch:8.10.0
        ports:
        - containerPort: 9200
```

### 7.2 滚动更新策略


**🔄 滚动更新流程**
```
滚动更新过程：

初始状态：Pod1, Pod2, Pod3 (旧版本)
    ↓
步骤1：停止Pod1 → 启动新Pod1 → 健康检查通过
    ↓
步骤2：停止Pod2 → 启动新Pod2 → 健康检查通过  
    ↓
步骤3：停止Pod3 → 启动新Pod3 → 健康检查通过
    ↓
完成：Pod1, Pod2, Pod3 (新版本)
```

**⚙️ 滚动更新配置**
```yaml
# rolling-update-config.yml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: elasticsearch
spec:
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      # 最大不可用Pod数量
      maxUnavailable: 1
      # 分批更新间隔
      partition: 0
  # Pod管理策略
  podManagementPolicy: Parallel
  template:
    spec:
      containers:
      - name: elasticsearch
        image: elasticsearch:8.10.0
        # 健康检查配置
        readinessProbe:
          httpGet:
            path: /_cluster/health
            port: 9200
          initialDelaySeconds: 30
          periodSeconds: 10
        livenessProbe:
          httpGet:
            path: /_cluster/health
            port: 9200
          initialDelaySeconds: 60
          periodSeconds: 30
```

### 7.3 自动化回滚机制


**🚨 回滚触发条件**
```yaml
# rollback-policy.yml
apiVersion: argoproj.io/v1alpha1
kind: AnalysisTemplate
metadata:
  name: rollback-analysis
spec:
  metrics:
  - name: error-rate
    interval: 1m
    successCondition: result < 0.05
    failureLimit: 3
    provider:
      prometheus:
        address: http://prometheus:9090
        query: |
          sum(rate(http_requests_total{status=~"5.."}[1m])) /
          sum(rate(http_requests_total[1m]))
  
  - name: response-time
    interval: 1m
    successCondition: result < 500
    failureLimit: 3
    provider:
      prometheus:
        address: http://prometheus:9090
        query: |
          histogram_quantile(0.95, 
            sum(rate(http_request_duration_seconds_bucket[1m])) by (le)
          ) * 1000
```

**🔧 自动回滚脚本**
```bash
#!/bin/bash
# 自动回滚脚本

monitor_deployment() {
    local deployment_name=$1
    local namespace=$2
    local timeout=$3
    
    echo "监控部署: $deployment_name"
    
    # 等待部署完成
    kubectl rollout status statefulset/$deployment_name -n $namespace --timeout=${timeout}s
    
    if [ $? -ne 0 ]; then
        echo "部署超时，开始回滚..."
        rollback_deployment $deployment_name $namespace
        return 1
    fi
    
    # 健康检查
    if ! health_check $deployment_name $namespace; then
        echo "健康检查失败，开始回滚..."
        rollback_deployment $deployment_name $namespace
        return 1
    fi
    
    echo "部署成功完成"
    return 0
}

rollback_deployment() {
    local deployment_name=$1
    local namespace=$2
    
    echo "执行回滚操作..."
    
    # 回滚到上一个版本
    kubectl rollout undo statefulset/$deployment_name -n $namespace
    
    # 等待回滚完成
    kubectl rollout status statefulset/$deployment_name -n $namespace
    
    # 发送告警通知
    send_alert "部署回滚" "$deployment_name 已回滚到上一个版本"
    
    echo "回滚完成"
}

health_check() {
    local service_url="http://elasticsearch.$2.svc.cluster.local:9200"
    local max_attempts=10
    local attempt=1
    
    while [ $attempt -le $max_attempts ]; do
        if curl -f "$service_url/_cluster/health" > /dev/null 2>&1; then
            echo "健康检查通过"
            return 0
        fi
        
        echo "健康检查失败，重试 $attempt/$max_attempts"
        sleep 30
        ((attempt++))
    done
    
    echo "健康检查最终失败"
    return 1
}

# 主流程
monitor_deployment "elasticsearch" "elastic" 600
```

---

## 8. 📋 核心要点总结


### 8.1 必须掌握的核心概念


```
🔸 运维自动化：用脚本和工具代替手工操作，提高效率和一致性
🔸 Infrastructure as Code：基础设施通过代码管理，版本化和可重复
🔸 CI/CD流水线：持续集成和持续部署，快速交付价值
🔸 容器化部署：标准化运行环境，简化部署和管理
🔸 服务编排：Kubernetes等工具管理容器化应用的生命周期
🔸 监控自动化：自动收集指标、分析问题、触发告警和恢复
```

### 8.2 关键理解要点


**🔹 自动化的价值**
```
效率提升：
手动部署1小时 → 自动化部署5分钟
手动监控依赖人工 → 7x24小时自动监控

质量保障：
人工配置容易出错 → 模板化配置保证一致性
手动测试覆盖有限 → 自动化测试全面覆盖

风险降低：
人工操作风险高 → 自动化操作标准化
故障恢复依赖经验 → 自动恢复机制
```

**🔹 DevOps文化理念**
```
传统模式：开发 vs 运维（对立关系）
DevOps模式：开发 + 运维（协作关系）

核心理念：
- 自动化优于手动操作
- 协作优于各自为政  
- 快速反馈优于延迟发现
- 持续改进优于一次性完美
```

**🔹 容器化vs传统部署**
```
传统部署问题：
- 环境差异导致"在我机器上能运行"
- 依赖管理复杂，版本冲突
- 扩容缩容困难

容器化优势：
- 环境一致性，消除环境差异
- 依赖打包，避免冲突
- 快速扩缩容，弹性伸缩
```

### 8.3 实际应用指导


**🎯 选择合适的自动化工具**

| 📊 **场景** | **推荐工具** | **适用原因** | **注意事项** |
|------------|-------------|-------------|-------------|
| 🏗️ **基础设施管理** | `Terraform` | 多云支持，状态管理 | 学习成本较高 |
| 🔧 **应用部署** | `Ansible` | 简单易学，无Agent | 大规模性能有限 |
| 📦 **容器编排** | `Kubernetes` | 生态丰富，功能强大 | 复杂度高 |
| 🔄 **CI/CD流水线** | `Jenkins/GitLab CI` | 生态成熟，插件丰富 | 需要维护成本 |
| 📊 **监控告警** | `Prometheus+Grafana` | 云原生，扩展性好 | 配置复杂 |

**🚀 实施路线图**
```
阶段1：基础自动化（1-3个月）
• 自动化部署脚本
• 基础监控告警
• 配置管理

阶段2：流水线建设（3-6个月）  
• CI/CD流水线
• 自动化测试
• 环境标准化

阶段3：高级特性（6-12个月）
• 容器化部署
• 服务网格
• 自动扩缩容

阶段4：持续优化（持续进行）
• 性能优化
• 安全加固
• 成本优化
```

### 8.4 运维自动化最佳实践


**✅ 成功关键因素**
```
技术层面：
• 选择成熟稳定的工具
• 充分的测试和验证
• 完善的监控和日志
• 快速回滚机制

流程层面：
• 标准化的变更流程
• 代码化的配置管理  
• 自动化的测试验证
• 持续的安全扫描

团队层面：
• DevOps文化建设
• 跨团队协作机制
• 持续学习和改进
• 明确的责任分工
```

**⚠️ 常见陷阱避免**
```
过度自动化：
不是所有操作都需要自动化，要评估成本效益

忽视安全：
自动化过程中要考虑安全因素，避免引入安全漏洞

缺乏监控：
自动化系统本身也需要监控，避免"黑盒"运行

一次性完美：
采用迭代方式逐步完善，不要追求一步到位
```

**🎯 核心记忆要点**
- **自动化是手段不是目的**：最终目标是提升效率和质量
- **小步快跑逐步完善**：不要试图一次性解决所有问题
- **监控和回滚同样重要**：自动化的同时要确保可控性
- **团队文化比工具更重要**：DevOps首先是文化变革

**核心价值总结**：
运维自动化与DevOps实践的核心是通过工具和流程的标准化，实现快速、可靠、可重复的软件交付，最终提升整个组织的效率和竞争力。