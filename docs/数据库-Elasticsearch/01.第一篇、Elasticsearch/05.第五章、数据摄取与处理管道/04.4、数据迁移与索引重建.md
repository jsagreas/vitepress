---
title: 4、数据迁移与索引重建
---
## 📚 目录

1. [数据迁移基础概念](#1-数据迁移基础概念)
2. [Reindex API 核心操作](#2-reindex-api-核心操作)
3. [批量更新与删除操作](#3-批量更新与删除操作)
4. [索引重建策略详解](#4-索引重建策略详解)
5. [别名切换与蓝绿部署](#5-别名切换与蓝绿部署)
6. [大数据量迁移实践](#6-大数据量迁移实践)
7. [数据一致性与验证](#7-数据一致性与验证)
8. [零停机迁移方案](#8-零停机迁移方案)
9. [核心要点总结](#9-核心要点总结)

---

## 1. 🔄 数据迁移基础概念


### 1.1 什么是数据迁移


**通俗理解**：数据迁移就像搬家一样，要把数据从一个地方完整地搬到另一个地方。

```
生活中的搬家：                    Elasticsearch中的迁移：
旧房子 → 新房子                   旧索引 → 新索引
物品打包 → 运输 → 拆包           数据提取 → 传输 → 写入
确保不丢东西                     确保数据完整性
```

**核心作用**：
- **索引结构升级**：就像房子装修，改善数据存储结构
- **集群间迁移**：把数据从一个ES集群搬到另一个集群
- **性能优化**：重新组织数据，提升查询效率
- **版本升级**：配合ES版本升级进行数据迁移

### 1.2 迁移场景分类


**📊 常见迁移场景**

| 迁移类型 | **应用场景** | **复杂度** | **停机时间** |
|---------|------------|-----------|-------------|
| 🔄 **同集群迁移** | `索引重建、结构调整` | ⭐⭐ | `几乎无` |
| 🌐 **跨集群迁移** | `数据中心搬迁、灾备` | ⭐⭐⭐ | `计划窗口` |
| 📈 **版本升级迁移** | `ES版本升级` | ⭐⭐⭐⭐ | `维护窗口` |
| 🚀 **性能优化迁移** | `分片重新分布` | ⭐⭐ | `几乎无` |

### 1.3 迁移前的准备工作


**🔍 迁移评估清单**
```
数据规模评估：
├── 索引大小：多少GB？
├── 文档数量：多少条记录？
├── 分片数量：当前分片配置
└── 写入频率：每秒多少次写入？

环境准备：
├── 目标集群资源：CPU、内存、磁盘
├── 网络带宽：集群间连接速度
├── 存储空间：确保有足够空间
└── 备份策略：迁移前必须备份
```

---

## 2. 🛠️ Reindex API 核心操作


### 2.1 Reindex 基本概念


**简单理解**：Reindex就像复印文件，把一个索引的数据完整复制到另一个索引。

**🔸 工作原理**
```
数据流向：
源索引 ────读取数据───→ [Reindex处理] ────写入数据───→ 目标索引
  │                      ↑                        │
  │                   可选的数据                    │
  │                   转换处理                      │
  └─────────────── 保持源数据不变 ──────────────────┘
```

### 2.2 基础Reindex操作


**💡 最简单的数据复制**

```json
POST _reindex
{
  "source": {
    "index": "old_products"
  },
  "dest": {
    "index": "new_products"
  }
}
```

**解释**：
- `source`：源索引，就是要复制的原始数据
- `dest`：目标索引，数据复制到这里
- ES会自动处理数据读取和写入

**💻 实际操作示例**

```json
// 创建目标索引（建议先设置好mapping）
PUT new_products
{
  "mappings": {
    "properties": {
      "title": { "type": "text" },
      "price": { "type": "double" },
      "category": { "type": "keyword" }
    }
  }
}

// 执行reindex
POST _reindex
{
  "source": {
    "index": "old_products"
  },
  "dest": {
    "index": "new_products"
  }
}
```

### 2.3 高级Reindex功能


**🎯 条件过滤迁移**

```json
POST _reindex
{
  "source": {
    "index": "all_orders",
    "query": {
      "range": {
        "order_date": {
          "gte": "2024-01-01"
        }
      }
    }
  },
  "dest": {
    "index": "orders_2024"
  }
}
```

**说明**：只迁移2024年的订单数据，其他的不要

**🔧 数据转换迁移**

```json
POST _reindex
{
  "source": {
    "index": "user_logs"
  },
  "dest": {
    "index": "processed_logs"
  },
  "script": {
    "source": """
      // 给每条记录添加处理时间戳
      ctx._source.processed_at = new Date().getTime();
      // 转换用户等级
      if (ctx._source.score > 1000) {
        ctx._source.level = 'VIP';
      } else {
        ctx._source.level = 'Normal';
      }
    """
  }
}
```

### 2.4 跨集群Reindex


**🌐 集群间数据迁移**

```json
POST _reindex
{
  "source": {
    "remote": {
      "host": "http://old-cluster:9200",
      "username": "admin",
      "password": "password"
    },
    "index": "production_data"
  },
  "dest": {
    "index": "migrated_data"
  }
}
```

**步骤说明**：
1. **配置远程集群**：在elasticsearch.yml中添加白名单
2. **网络连通性**：确保两个集群可以互相访问
3. **权限设置**：远程集群需要相应的读取权限

---

## 3. ⚡ 批量更新与删除操作


### 3.1 Update_by_query 批量更新


**通俗理解**：就像用查找替换功能，一次性修改很多条记录。

**🔄 基础批量更新**

```json
POST products/_update_by_query
{
  "query": {
    "term": {
      "category": "electronics"
    }
  },
  "script": {
    "source": "ctx._source.discount = 0.1"
  }
}
```

**解释**：给所有电子产品类别的商品加上10%的折扣

**💰 实际业务场景**

```json
// 场景：双11活动，给特定品牌商品批量加折扣
POST products/_update_by_query
{
  "query": {
    "bool": {
      "must": [
        { "terms": { "brand": ["Apple", "Samsung", "Huawei"] }},
        { "range": { "price": { "gte": 100 }}}
      ]
    }
  },
  "script": {
    "source": """
      // 原价大于1000的打8折，否则打9折
      if (ctx._source.price > 1000) {
        ctx._source.sale_price = ctx._source.price * 0.8;
      } else {
        ctx._source.sale_price = ctx._source.price * 0.9;
      }
      ctx._source.promotion = 'double11';
    """
  }
}
```

### 3.2 Delete_by_query 批量删除


**⚠️ 批量删除过期数据**

```json
POST logs_2023/_delete_by_query
{
  "query": {
    "range": {
      "timestamp": {
        "lt": "2024-01-01"
      }
    }
  }
}
```

**说明**：删除2024年1月1日之前的所有日志

**🧹 清理无效数据示例**

```json
// 删除状态为"已取消"且超过30天的订单
POST orders/_delete_by_query
{
  "query": {
    "bool": {
      "must": [
        { "term": { "status": "cancelled" }},
        { 
          "range": { 
            "created_at": { 
              "lt": "now-30d" 
            }
          }
        }
      ]
    }
  }
}
```

### 3.3 批量操作性能优化


**📊 性能调优参数**

```json
POST products/_update_by_query
{
  "query": { "match_all": {} },
  "script": { "source": "ctx._source.updated_at = new Date().getTime()" },
  "conflicts": "proceed",     // 冲突时继续处理
  "refresh": false,           // 不立即刷新
  "wait_for_completion": false, // 异步执行
  "requests_per_second": 1000,  // 限制处理速度
  "scroll_size": 100           // 每批处理数量
}
```

**🎯 监控执行进度**

```json
// 查看异步任务进度
GET _tasks?detailed=true&actions=*byquery

// 取消正在执行的任务
POST _tasks/task_id:123/_cancel
```

---

## 4. 🏗️ 索引重建策略详解


### 4.1 为什么需要索引重建


**常见重建场景**：
- **映射修改**：需要改变字段类型（比如从text改为keyword）
- **分片调整**：重新设计分片数量和策略
- **性能优化**：重新组织数据提升查询速度
- **版本升级**：配合ES版本升级

### 4.2 索引重建步骤


**📋 完整重建流程**

```
步骤 1：分析现状
├── 查看当前索引结构
├── 评估数据量和性能
└── 确定优化目标

步骤 2：设计新索引
├── 设计新的mapping
├── 配置索引设置
└── 测试新结构

步骤 3：创建新索引
├── 创建新索引结构
├── 预热索引（可选）
└── 准备数据迁移

步骤 4：数据迁移
├── 使用reindex迁移数据
├── 监控迁移进度
└── 验证数据完整性

步骤 5：切换服务
├── 使用别名切换
├── 测试新索引功能
└── 清理旧索引
```

**💻 实际操作示例**

```json
// 1. 查看现有索引信息
GET old_products/_mapping
GET old_products/_settings

// 2. 创建优化后的新索引
PUT new_products_v2
{
  "settings": {
    "number_of_shards": 3,      // 优化分片数
    "number_of_replicas": 1,
    "refresh_interval": "30s"    // 调整刷新频率
  },
  "mappings": {
    "properties": {
      "title": {
        "type": "text",
        "analyzer": "ik_max_word"  // 优化中文分词
      },
      "category": {
        "type": "keyword"          // 改为keyword便于聚合
      },
      "price": {
        "type": "scaled_float",    // 价格用scaled_float更节省空间
        "scaling_factor": 100
      }
    }
  }
}

// 3. 迁移数据
POST _reindex
{
  "source": { "index": "old_products" },
  "dest": { "index": "new_products_v2" }
}
```

### 4.3 索引重建最佳实践


**🎯 重建策略选择**

| 策略类型 | **适用场景** | **停机时间** | **资源占用** |
|---------|------------|-------------|-------------|
| 🔄 **在线重建** | `小数据量，允许短暂性能下降` | `无` | `高` |
| 🕐 **维护窗口重建** | `中等数据量，可接受短停机` | `分钟级` | `中` |
| 🔀 **滚动重建** | `大数据量，零停机要求` | `无` | `低` |

---

## 5. 🔗 别名切换与蓝绿部署


### 5.1 别名切换技术


**通俗理解**：别名就像门牌号，房子换了但门牌号不变，访客还是能找到正确的地址。

```
应用程序访问路径：
应用 → 索引别名(products) → 实际索引(products_v1)
                        切换后 ↓
应用 → 索引别名(products) → 实际索引(products_v2)
```

**🔧 别名操作基础**

```json
// 创建别名，指向旧索引
POST _aliases
{
  "actions": [
    {
      "add": {
        "index": "products_v1",
        "alias": "products"
      }
    }
  ]
}

// 原子切换：同时移除旧指向，添加新指向
POST _aliases
{
  "actions": [
    {
      "remove": {
        "index": "products_v1",
        "alias": "products"
      }
    },
    {
      "add": {
        "index": "products_v2", 
        "alias": "products"
      }
    }
  ]
}
```

### 5.2 蓝绿部署模式


**🔵🟢 蓝绿部署概念**

```
蓝绿部署示意：
当前线上环境(蓝)：products_blue  ←── 用户访问
新版本环境(绿)：products_green ←── 准备就绪

切换时刻：
products(别名) 从指向 products_blue 切换到 products_green
```

**💻 完整蓝绿部署流程**

```json
// 1. 创建绿环境
PUT products_green
{
  "mappings": { /* 新的映射结构 */ }
}

// 2. 迁移数据到绿环境
POST _reindex
{
  "source": { "index": "products_blue" },
  "dest": { "index": "products_green" }
}

// 3. 测试绿环境
GET products_green/_search
{
  "query": { "match_all": {} }
}

// 4. 原子切换
POST _aliases
{
  "actions": [
    { "remove": { "index": "products_blue", "alias": "products" }},
    { "add": { "index": "products_green", "alias": "products" }}
  ]
}

// 5. 验证切换成功
GET products/_search  // 现在访问的是green环境

// 6. 清理蓝环境（确认无问题后）
DELETE products_blue
```

### 5.3 分阶段部署策略


**🎯 渐进式切换**

```json
// 场景：50%流量切换测试
POST _aliases
{
  "actions": [
    {
      "add": {
        "index": "products_v1",
        "alias": "products_read",
        "filter": { "range": { "user_id": { "lt": 500000 }}}
      }
    },
    {
      "add": {
        "index": "products_v2", 
        "alias": "products_read",
        "filter": { "range": { "user_id": { "gte": 500000 }}}
      }
    }
  ]
}
```

---

## 6. 📊 大数据量迁移实践


### 6.1 大数据量迁移挑战


**⚡ 常见问题**：
- **迁移时间长**：TB级数据需要数小时甚至数天
- **资源压力大**：迁移过程占用大量CPU和内存
- **影响业务**：可能影响正常的读写操作
- **数据一致性**：迁移期间可能有新数据写入

### 6.2 分批迁移策略


**🔄 时间窗口分批**

```json
// 按时间分批迁移：每次迁移一个月的数据
POST _reindex
{
  "source": {
    "index": "large_logs",
    "query": {
      "range": {
        "timestamp": {
          "gte": "2024-01-01",
          "lt": "2024-02-01"
        }
      }
    }
  },
  "dest": {
    "index": "optimized_logs_202401"
  },
  "requests_per_second": 500  // 限制速度避免影响业务
}
```

**📈 增量同步策略**

```json
// 1. 先迁移历史数据（T时刻之前）
POST _reindex
{
  "source": {
    "index": "orders",
    "query": {
      "range": {
        "created_at": { "lt": "2024-09-20T00:00:00" }
      }
    }
  },
  "dest": { "index": "new_orders" }
}

// 2. 增量同步新数据（T时刻之后）
POST _reindex
{
  "source": {
    "index": "orders",
    "query": {
      "range": {
        "created_at": { "gte": "2024-09-20T00:00:00" }
      }
    }
  },
  "dest": { "index": "new_orders" },
  "conflicts": "proceed"  // 有重复就跳过
}
```

### 6.3 迁移性能优化


**🚀 性能调优技巧**

```json
// 优化reindex性能
POST _reindex
{
  "source": {
    "index": "huge_dataset",
    "size": 1000           // 增大批次大小
  },
  "dest": {
    "index": "new_dataset",
    "op_type": "create"    // 只创建，不更新
  },
  "requests_per_second": -1,  // 不限制速度
  "scroll_size": 5000,        // 增大滚动大小
  "max_docs": 1000000         // 限制迁移文档数
}
```

**⚙️ 集群级优化设置**

```json
// 临时调整集群设置提升迁移性能
PUT _cluster/settings
{
  "transient": {
    "indices.store.throttle.max_bytes_per_sec": "200mb",
    "cluster.routing.allocation.node_concurrent_recoveries": 5,
    "indices.recovery.max_bytes_per_sec": "100mb"
  }
}

// 迁移完成后恢复默认设置
PUT _cluster/settings
{
  "transient": {
    "indices.store.throttle.max_bytes_per_sec": null,
    "cluster.routing.allocation.node_concurrent_recoveries": null,
    "indices.recovery.max_bytes_per_sec": null
  }
}
```

---

## 7. ✅ 数据一致性与验证


### 7.1 数据完整性验证


**📊 数据对比验证**

```json
// 1. 对比文档总数
GET old_index/_count
GET new_index/_count

// 2. 对比数据分布
GET old_index/_search
{
  "size": 0,
  "aggs": {
    "by_category": {
      "terms": { "field": "category" }
    }
  }
}

GET new_index/_search
{
  "size": 0, 
  "aggs": {
    "by_category": {
      "terms": { "field": "category" }
    }
  }
}
```

**🔍 抽样验证方法**

```json
// 随机抽取样本进行详细对比
GET old_index/_search
{
  "query": {
    "function_score": {
      "query": { "match_all": {} },
      "random_score": { "seed": 12345 }
    }
  },
  "size": 100
}
```

### 7.2 一致性保证机制


**🛡️ 迁移期间数据保护**

```
一致性策略：
├── 读写分离：读旧索引，写双写
├── 版本控制：使用文档版本号
├── 时间戳验证：对比最后更新时间
└── 业务逻辑验证：关键指标对比
```

**💻 双写策略示例**

```json
// 应用程序双写逻辑（伪代码）
{
  "写入策略": {
    "主写入": "old_index",      // 确保业务不受影响
    "同步写入": "new_index",    // 同时写入新索引
    "失败处理": "记录差异日志"   // 便于后续同步
  }
}
```

### 7.3 数据验证脚本


**🧪 自动化验证工具**

```bash
#!/bin/bash
# 数据迁移验证脚本

OLD_INDEX="products_v1"
NEW_INDEX="products_v2"
ES_HOST="localhost:9200"

echo "开始验证数据迁移..."

# 1. 文档数量对比
OLD_COUNT=$(curl -s "$ES_HOST/$OLD_INDEX/_count" | jq '.count')
NEW_COUNT=$(curl -s "$ES_HOST/$NEW_INDEX/_count" | jq '.count')

echo "旧索引文档数: $OLD_COUNT"
echo "新索引文档数: $NEW_COUNT"

if [ "$OLD_COUNT" -eq "$NEW_COUNT" ]; then
    echo "✅ 文档数量验证通过"
else
    echo "❌ 文档数量不匹配"
    exit 1
fi

# 2. 关键字段验证
echo "验证关键字段分布..."
# 这里添加具体的验证逻辑

echo "验证完成！"
```

---

## 8. 🚀 零停机迁移方案


### 8.1 零停机迁移设计


**🎯 零停机迁移架构**

```
零停机迁移流程：
应用程序 ────┐
             ├─→ 负载均衡器 ─→ 读写别名
             │                    │
             └─→ 数据同步程序      ├─→ 当前索引(读写)
                                  └─→ 新索引(仅写)
                                      ↓
                                  迁移完成后切换
```

### 8.2 实时数据同步


**⚡ 实时同步机制**

```json
// 1. 设置写入别名，支持双写
POST _aliases
{
  "actions": [
    { "add": { "index": "orders_v1", "alias": "orders_write" }},
    { "add": { "index": "orders_v2", "alias": "orders_write" }}
  ]
}

// 2. 应用程序写入时使用别名
PUT orders_write/_doc/12345
{
  "user_id": 1001,
  "amount": 299.99,
  "created_at": "2024-09-20T10:00:00"
}
```

### 8.3 滚动升级策略


**🔄 滚动迁移步骤**

```
第1阶段：准备期
├── 创建新索引结构
├── 配置双写模式  
└── 开始历史数据迁移

第2阶段：同步期
├── 继续迁移历史数据
├── 新数据双写到两个索引
└── 监控数据一致性

第3阶段：验证期
├── 验证新索引数据完整性
├── 性能测试
└── 准备切换

第4阶段：切换期
├── 修改读别名指向新索引
├── 停止向旧索引写入
└── 监控业务影响

第5阶段：清理期
├── 确认业务正常运行
├── 清理旧索引
└── 优化新索引配置
```

---

## 9. 📋 核心要点总结


### 9.1 必须掌握的核心概念


```
🔸 Reindex API：数据复制的核心工具，支持条件过滤和数据转换
🔸 批量操作：update_by_query和delete_by_query处理大量数据
🔸 索引重建：解决mapping变更和性能优化问题
🔸 别名切换：零停机迁移的关键技术
🔸 数据验证：确保迁移过程中数据完整性和一致性
```

### 9.2 关键理解要点


**🔹 迁移策略选择原则**
```
数据量小(<1GB)：
• 可以直接reindex，影响较小
• 适合在线迁移

数据量中等(1GB-100GB)：
• 考虑在维护窗口进行
• 使用分批迁移策略

数据量大(>100GB)：
• 必须使用增量同步
• 实施零停机迁移方案
```

**🔹 性能优化核心要点**
```
写入优化：
• 增大bulk size提升写入速度
• 临时关闭replica减少写入压力
• 调整refresh_interval降低刷新频率

读取优化：
• 合理设置scroll_size
• 使用filter query减少数据传输
• 避免在业务高峰期执行
```

**🔹 数据安全保障**
```
备份先行：迁移前必须完整备份
版本控制：使用文档version避免冲突
监控告警：实时监控迁移进度和错误
回滚预案：准备快速回滚方案
```

### 9.3 实际应用价值


- **业务连续性**：零停机迁移保障业务不中断
- **性能提升**：重建索引优化查询性能
- **成本控制**：合理的分片策略降低资源消耗
- **风险管控**：完善的验证机制确保数据安全

### 9.4 最佳实践建议


**🎯 迁移前准备**
- 充分评估数据规模和业务影响
- 在测试环境先完整演练一遍
- 准备详细的迁移计划和回滚方案
- 与业务方充分沟通迁移窗口

**⚡ 迁移过程管控**
- 实时监控迁移进度和集群状态
- 设置合理的速度限制避免影响业务
- 分阶段验证数据完整性
- 保持与相关团队的实时沟通

**✅ 迁移后验证**
- 全面验证数据完整性和一致性
- 进行性能基准测试
- 观察业务指标是否正常
- 清理临时资源和配置

**核心记忆**：
- 数据迁移如搬家，备份在先安全第一
- Reindex是核心工具，别名切换零停机
- 大数据量要分批，增量同步保一致
- 验证监控不可少，回滚预案要准备