---
title: 3、容器输入类型
---
## 📚 目录

1. [容器日志采集概述](#1-容器日志采集概述)
2. [Docker容器输入配置](#2-Docker容器输入配置)
3. [Kubernetes输入配置](#3-Kubernetes输入配置)
4. [容器元数据采集](#4-容器元数据采集)
5. [自动发现机制](#5-自动发现机制)
6. [容器过滤规则](#6-容器过滤规则)
7. [实战配置案例](#7-实战配置案例)
8. [核心要点总结](#8-核心要点总结)

---

## 1. 🐳 容器日志采集概述


### 1.1 为什么需要容器日志采集


在现代应用架构中，容器已经成为部署应用的主流方式。但是容器的特性给日志管理带来了新的挑战：

**传统服务器 vs 容器化应用**：
```
传统服务器日志：
/var/log/app.log  ← 固定路径，持久存储

容器化应用日志：
/var/lib/docker/containers/abc123.../abc123-json.log  ← 动态路径
容器重启后路径可能变化，日志可能丢失
```

**容器日志的特点**：
- **动态性**：容器启动停止频繁，日志路径不固定
- **临时性**：容器删除后，日志也可能丢失
- **多样性**：同一应用可能有多个容器实例
- **标准化**：容器运行时提供统一的日志接口

### 1.2 Filebeat容器日志采集原理


Filebeat通过以下方式解决容器日志采集问题：

```
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   应用容器1      │    │   应用容器2      │    │   应用容器3      │
│   stdout/stderr │    │   stdout/stderr │    │   stdout/stderr │
└─────────┬───────┘    └─────────┬───────┘    └─────────┬───────┘
          │                      │                      │
          ▼                      ▼                      ▼
┌─────────────────────────────────────────────────────────────────┐
│              Docker/Kubernetes 日志驱动                          │
│   /var/lib/docker/containers/*/...json.log                    │
└─────────────────────┬───────────────────────────────────────────┘
                      │
                      ▼
┌─────────────────────────────────────────────────────────────────┐
│                  Filebeat 容器                                   │
│  • 自动发现新容器                                                 │
│  • 读取容器日志文件                                               │
│  • 添加容器元数据                                                 │
│  • 解析日志格式                                                   │
└─────────────────────┬───────────────────────────────────────────┘
                      │
                      ▼
                ┌─────────────┐
                │ Elasticsearch │
                └─────────────┘
```

---

## 2. 🔧 Docker容器输入配置


### 2.1 基础Docker容器输入


**什么是Docker容器输入**：
Docker容器输入是Filebeat专门用来采集Docker容器日志的输入类型。它能够自动发现运行中的容器，读取容器的标准输出和标准错误日志。

**基础配置示例**：
```yaml
filebeat.inputs:
- type: container
  paths:
    - '/var/lib/docker/containers/*/*.log'
```

**配置解释**：
- `type: container`：指定输入类型为容器类型
- `paths`：指定容器日志文件的路径模式
- `*/*.log`：通配符匹配所有容器的日志文件

### 2.2 Docker容器日志路径详解


**Docker日志存储机制**：
```
Docker容器日志默认路径：
/var/lib/docker/containers/[容器ID]/[容器ID]-json.log

实际例子：
/var/lib/docker/containers/
├── a1b2c3d4e5f6.../
│   ├── a1b2c3d4e5f6-json.log  ← 应用1的日志
│   └── config.v2.json
├── f6e5d4c3b2a1.../
│   ├── f6e5d4c3b2a1-json.log  ← 应用2的日志
│   └── config.v2.json
```

**不同日志驱动的路径**：

| 日志驱动类型 | 存储路径 | 说明 |
|-------------|----------|------|
| **json-file** | `/var/lib/docker/containers/*/` | 默认驱动，JSON格式 |
| **syslog** | `/var/log/syslog` | 系统日志 |
| **journald** | `journalctl` | systemd日志 |
| **none** | 无 | 不记录日志 |

### 2.3 完整的Docker容器配置


```yaml
filebeat.inputs:
- type: container
  paths:
    - '/var/lib/docker/containers/*/*.log'
  
  # 流处理配置
  stream: all  # stdout, stderr, all
  
  # 读取配置
  scan_frequency: 10s
  harvester_buffer_size: 16384
  max_bytes: 10485760
  
  # 多行日志配置（Java异常堆栈）
  multiline.pattern: '^\d{4}-\d{2}-\d{2}'
  multiline.negate: true
  multiline.match: after
  
  # 包含容器元数据
  processors:
    - add_docker_metadata:
        host: "unix:///var/run/docker.sock"
        match_fields: ["container.id"]
        labels.dedot: true
        env.dedot: true
```

### 2.4 Docker容器特定配置选项


**重要配置参数说明**：

- **stream配置**：
  - `stdout`：只采集标准输出
  - `stderr`：只采集标准错误  
  - `all`：采集所有输出（默认）

- **扫描频率**：
  - `scan_frequency: 10s`：每10秒扫描一次新的日志文件

- **缓冲区大小**：
  - `harvester_buffer_size: 16384`：每次读取16KB数据

---

## 3. ☸️ Kubernetes输入配置


### 3.1 Kubernetes日志架构理解


**Kubernetes日志层次**：
```
┌─────────────────────────────────────────────────────────────┐
│                    Kubernetes 集群                          │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐        │
│  │    Node1    │  │    Node2    │  │    Node3    │        │
│  │ ┌─────────┐ │  │ ┌─────────┐ │  │ ┌─────────┐ │        │
│  │ │  Pod A  │ │  │ │  Pod B  │ │  │ │  Pod C  │ │        │
│  │ │ ┌─────┐ │ │  │ │ ┌─────┐ │ │  │ │ ┌─────┐ │ │        │
│  │ │ │容器1│ │ │  │ │ │容器2│ │ │  │ │ │容器3│ │ │        │
│  │ │ └─────┘ │ │  │ │ └─────┘ │ │  │ │ └─────┘ │ │        │
│  │ └─────────┘ │  │ └─────────┘ │  │ └─────────┘ │        │
│  └─────────────┘  └─────────────┘  └─────────────┘        │
└─────────────────────────────────────────────────────────────┘
```

**Kubernetes日志文件路径**：
```
容器日志实际路径：
/var/log/pods/[namespace]_[pod-name]_[pod-uid]/[container-name]/[restart-count].log

示例：
/var/log/pods/default_nginx-app-123_abc-def-ghi/nginx/0.log
/var/log/pods/default_nginx-app-123_abc-def-ghi/sidecar/0.log
```

### 3.2 基础Kubernetes配置


```yaml
filebeat.inputs:
- type: container
  paths:
    - /var/log/containers/*.log
    - /var/log/pods/*/*/*.log
  
  # Kubernetes元数据处理器
  processors:
    - add_kubernetes_metadata:
        host: ${NODE_NAME}
        matchers:
        - logs_path:
            logs_path: "/var/log/containers/"
```

### 3.3 高级Kubernetes配置


```yaml
filebeat.inputs:
- type: container
  paths:
    - /var/log/containers/*.log
  
  # 排除系统容器
  exclude_files: ['\.gz$']
  
  processors:
    # 添加Kubernetes元数据
    - add_kubernetes_metadata:
        host: ${NODE_NAME}
        matchers:
        - logs_path:
            logs_path: "/var/log/containers/"
        labels.dedot: true
        annotations.dedot: true
    
    # 解析容器名称
    - rename:
        fields:
          - from: "container"
            to: "container_parsed"
        ignore_missing: true
    
    # 添加自定义字段
    - add_fields:
        target: environment
        fields:
          cluster: production
          region: us-west-2
```

### 3.4 Kubernetes自动发现配置


**自动发现的作用**：
自动发现机制可以根据Pod的注解（annotations）和标签（labels）来动态配置日志采集规则，无需手动修改Filebeat配置。

```yaml
filebeat.autodiscover:
  providers:
    - type: kubernetes
      node: ${NODE_NAME}
      templates:
        # 默认模板：采集所有容器日志
        - condition.equals:
            kubernetes.container.name: "app"
          config:
            - type: container
              paths:
                - /var/log/containers/*-${data.kubernetes.container.id}.log
              multiline.pattern: '^\d{4}-\d{2}-\d{2}'
              multiline.negate: true
              multiline.match: after
        
        # 特殊应用模板：nginx访问日志
        - condition.contains:
            kubernetes.labels.app: "nginx"
          config:
            - type: container
              paths:
                - /var/log/containers/*-${data.kubernetes.container.id}.log
              json.keys_under_root: true
              json.add_error_key: true
```

---

## 4. 📊 容器元数据采集


### 4.1 什么是容器元数据


**容器元数据**是指容器运行时的各种属性信息，包括：
- 容器ID、名称、镜像信息
- 标签（Labels）和环境变量
- 网络配置、资源配置
- 在Kubernetes中还包括Pod、Namespace等信息

**为什么需要元数据**：
```
没有元数据的日志：
{
  "message": "ERROR: Database connection failed",
  "timestamp": "2025-09-21T10:30:00.000Z"
}

包含元数据的日志：
{
  "message": "ERROR: Database connection failed",
  "timestamp": "2025-09-21T10:30:00.000Z",
  "container": {
    "name": "user-service",
    "image": "myapp:v1.2.3"
  },
  "kubernetes": {
    "pod": "user-service-deployment-abc123",
    "namespace": "production"
  }
}
```

### 4.2 Docker元数据采集


```yaml
filebeat.inputs:
- type: container
  paths:
    - '/var/lib/docker/containers/*/*.log'
  
  processors:
    - add_docker_metadata:
        host: "unix:///var/run/docker.sock"
        # 匹配字段
        match_fields: ["container.id"]
        # 包含的元数据
        labels.dedot: true      # 容器标签
        env.dedot: true         # 环境变量
        
        # 只获取指定的标签
        labels.include:
          - "app.name"
          - "app.version"
          - "environment"
```

**添加的Docker元数据示例**：
```json
{
  "docker": {
    "container": {
      "id": "a1b2c3d4e5f6",
      "name": "user-service",
      "image": "myregistry/user-service:v1.2.3",
      "labels": {
        "app.name": "user-service",
        "app.version": "1.2.3",
        "environment": "production"
      }
    }
  }
}
```

### 4.3 Kubernetes元数据采集


```yaml
processors:
  - add_kubernetes_metadata:
      host: ${NODE_NAME}
      matchers:
      - logs_path:
          logs_path: "/var/log/containers/"
      
      # 包含的Kubernetes资源
      include_labels: ["app", "version", "component"]
      include_annotations: ["deployment.kubernetes.io/revision"]
      
      # 元数据去重和清理
      labels.dedot: true
      annotations.dedot: true
      
      # 索引元数据（提高查询性能）
      indexers:
      - ip_port:
      - container:
```

**添加的Kubernetes元数据示例**：
```json
{
  "kubernetes": {
    "pod": {
      "name": "user-service-deployment-abc123",
      "uid": "12345678-1234-1234-1234-123456789012"
    },
    "namespace": "production",
    "node": {
      "name": "worker-node-1"
    },
    "deployment": {
      "name": "user-service-deployment"
    },
    "labels": {
      "app": "user-service",
      "version": "v1.2.3"
    }
  }
}
```

---

## 5. 🔍 自动发现机制


### 5.1 自动发现机制原理


**什么是自动发现**：
自动发现是Filebeat的一个智能功能，它可以监控容器的启动和停止，并根据预定义的规则自动为新容器配置日志采集。

**传统方式 vs 自动发现**：
```
传统静态配置：
需要手动为每个应用编写采集配置
应用变化时需要重启Filebeat

自动发现方式：
根据容器标签/注解自动应用配置模板
新容器启动时自动开始采集
容器停止时自动停止采集
```

### 5.2 Docker自动发现配置


```yaml
filebeat.autodiscover:
  providers:
    - type: docker
      # Docker守护进程连接
      host: "unix:///var/run/docker.sock"
      
      # 默认配置模板
      templates:
        # 模板1：标准应用日志
        - condition.equals:
            docker.container.labels.log_type: "application"
          config:
            - type: container
              paths:
                - "/var/lib/docker/containers/${data.docker.container.id}/*.log"
              multiline.pattern: '^[0-9]{4}-[0-9]{2}-[0-9]{2}'
              multiline.negate: true
              multiline.match: after
              fields:
                logtype: application
                service: "${data.docker.container.labels.service_name}"
        
        # 模板2：nginx访问日志
        - condition.contains:
            docker.container.image: "nginx"
          config:
            - type: container
              paths:
                - "/var/lib/docker/containers/${data.docker.container.id}/*.log"
              json.keys_under_root: true
              fields:
                logtype: nginx_access
```

### 5.3 Kubernetes自动发现配置


```yaml
filebeat.autodiscover:
  providers:
    - type: kubernetes
      # 节点名称
      node: ${NODE_NAME}
      
      # 配置模板
      templates:
        # 通用应用模板
        - condition.and:
            - not.contains:
                kubernetes.namespace: "kube-system"
            - not.contains:
                kubernetes.container.name: "filebeat"
          config:
            - type: container
              paths:
                - /var/log/containers/*-${data.kubernetes.container.id}.log
              processors:
                - add_kubernetes_metadata:
                    host: ${NODE_NAME}
        
        # Spring Boot应用特殊处理
        - condition.equals:
            kubernetes.labels.framework: "spring-boot"
          config:
            - type: container
              paths:
                - /var/log/containers/*-${data.kubernetes.container.id}.log
              multiline.pattern: '^[0-9]{4}-[0-9]{2}-[0-9]{2}\s+[0-9]{2}:[0-9]{2}:[0-9]{2}'
              multiline.negate: true
              multiline.match: after
              fields:
                framework: spring-boot
                
        # JSON格式日志应用
        - condition.exists:
            kubernetes.annotations.filebeat/json: "true"
          config:
            - type: container
              paths:
                - /var/log/containers/*-${data.kubernetes.container.id}.log
              json.keys_under_root: true
              json.add_error_key: true
```

### 5.4 自动发现的优势


**动态适应**：
- ✅ 新容器自动开始采集
- ✅ 停止的容器自动清理配置
- ✅ 不同应用类型使用不同采集规则

**配置简化**：
- ✅ 一次配置，处理多种场景
- ✅ 通过标签控制采集行为
- ✅ 减少手动配置错误

---

## 6. 🎯 容器过滤规则


### 6.1 为什么需要过滤规则


在容器环境中，并非所有容器的日志都需要采集：

**需要过滤的场景**：
- 系统容器（如kube-proxy、flannel等）
- 测试容器或临时容器
- 日志量过大的容器
- 不包含有用信息的容器

### 6.2 基础过滤配置


```yaml
filebeat.inputs:
- type: container
  paths:
    - '/var/lib/docker/containers/*/*.log'
  
  # 包含规则：只采集特定容器
  include_lines: ['^ERROR', '^WARN', '^INFO']
  
  # 排除规则：排除特定内容
  exclude_lines: ['^DEBUG', '.*health.*check.*']
  
  # 排除文件：排除特定文件
  exclude_files: ['.*pause.*\.log$', '.*kube-proxy.*\.log$']
```

### 6.3 基于标签的过滤


```yaml
filebeat.autodiscover:
  providers:
    - type: kubernetes
      node: ${NODE_NAME}
      
      # 全局过滤器
      exclude_annotations:
        - "filebeat.skip": "true"
        - "beta.kubernetes.io/instance-type": "spot"
      
      templates:
        # 只处理包含特定标签的Pod
        - condition.and:
            - equals:
                kubernetes.labels.collect_logs: "true"
            - not.contains:
                kubernetes.namespace: "kube-system"
          config:
            - type: container
              paths:
                - /var/log/containers/*-${data.kubernetes.container.id}.log
```

### 6.4 高级过滤规则


```yaml
# 复合条件过滤
filebeat.autodiscover:
  providers:
    - type: kubernetes
      node: ${NODE_NAME}
      templates:
        # 复杂过滤条件
        - condition.and:
            # 必须是应用容器
            - equals:
                kubernetes.labels.app_type: "service"
            # 不是系统命名空间
            - not.or:
                - equals:
                    kubernetes.namespace: "kube-system"
                - equals:
                    kubernetes.namespace: "kube-public"
                - equals:
                    kubernetes.namespace: "monitoring"
            # 不是特定容器
            - not.regexp:
                kubernetes.container.name: ".*-sidecar$"
            # 必须有日志采集标识
            - exists:
                kubernetes.annotations.log_collection: "enabled"
          config:
            - type: container
              paths:
                - /var/log/containers/*-${data.kubernetes.container.id}.log
              processors:
                - add_kubernetes_metadata:
                    host: ${NODE_NAME}
```

---

## 7. 🛠️ 实战配置案例


### 7.1 完整的生产环境配置


```yaml
# filebeat.yml - 生产环境容器日志采集配置
filebeat.config:
  modules:
    path: ${path.config}/modules.d/*.yml
    reload.enabled: false

filebeat.autodiscover:
  providers:
    - type: kubernetes
      node: ${NODE_NAME}
      hints.enabled: true
      hints.default_config:
        type: container
        paths:
          - /var/log/containers/*-${data.kubernetes.container.id}.log
      
      templates:
        # 1. Spring Boot应用日志
        - condition.equals:
            kubernetes.labels.framework: "spring-boot"
          config:
            - type: container
              paths:
                - /var/log/containers/*-${data.kubernetes.container.id}.log
              multiline.pattern: '^[0-9]{4}-[0-9]{2}-[0-9]{2}\s[0-9]{2}:[0-9]{2}:[0-9]{2}\.[0-9]{3}'
              multiline.negate: true
              multiline.match: after
              processors:
                - add_kubernetes_metadata:
                    host: ${NODE_NAME}
                - timestamp:
                    field: '@timestamp'
                    layouts:
                      - '2006-01-02 15:04:05.000'
                    test:
                      - '2025-09-21 10:30:00.123'
              fields:
                logtype: spring-boot
                environment: ${ENVIRONMENT:dev}
        
        # 2. Nginx访问日志
        - condition.contains:
            kubernetes.labels.app: "nginx"
          config:
            - type: container
              paths:
                - /var/log/containers/*-${data.kubernetes.container.id}.log
              processors:
                - dissect:
                    tokenizer: '%{clientip} %{ident} %{auth} [%{timestamp}] "%{verb} %{request} %{httpversion}" %{response} %{bytes} "%{referrer}" "%{agent}"'
                    field: "message"
                    target_prefix: "nginx"
                - add_kubernetes_metadata:
                    host: ${NODE_NAME}
              fields:
                logtype: nginx-access
        
        # 3. JSON格式应用日志
        - condition.exists:
            kubernetes.annotations.filebeat/json-logging: "true"
          config:
            - type: container
              paths:
                - /var/log/containers/*-${data.kubernetes.container.id}.log
              json.keys_under_root: true
              json.add_error_key: true
              processors:
                - add_kubernetes_metadata:
                    host: ${NODE_NAME}
              fields:
                logtype: json-application

# 输出配置
output.elasticsearch:
  hosts: ["elasticsearch-1:9200", "elasticsearch-2:9200"]
  index: "filebeat-containers-%{+yyyy.MM.dd}"
  template.settings:
    index.number_of_shards: 1
    index.number_of_replicas: 1

# 日志配置
logging.level: info
logging.to_files: true
logging.files:
  path: /var/log/filebeat
  name: filebeat
  keepfiles: 7
  permissions: 0644

# 监控配置
monitoring.enabled: true
monitoring.elasticsearch:
  hosts: ["elasticsearch-1:9200"]
```

### 7.2 Docker Compose环境配置


```yaml
# docker-compose.yml
version: '3.8'
services:
  # 应用服务
  web-app:
    image: nginx:latest
    labels:
      - "log_type=nginx"
      - "service_name=web-frontend"
      - "collect_logs=true"
    volumes:
      - ./app-logs:/var/log/nginx
  
  # Filebeat服务
  filebeat:
    image: docker.elastic.co/beats/filebeat:8.10.0
    user: root
    volumes:
      # 挂载Docker socket和日志目录
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - ./filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
    environment:
      - ELASTICSEARCH_HOSTS=elasticsearch:9200
    depends_on:
      - elasticsearch
    restart: unless-stopped
```

对应的Filebeat配置：
```yaml
# filebeat.yml for Docker Compose
filebeat.autodiscover:
  providers:
    - type: docker
      host: "unix:///var/run/docker.sock"
      templates:
        - condition.equals:
            docker.container.labels.log_type: "nginx"
          config:
            - type: container
              paths:
                - "/var/lib/docker/containers/${data.docker.container.id}/*.log"
              fields:
                service: "${data.docker.container.labels.service_name}"
                logtype: nginx

output.elasticsearch:
  hosts: ["${ELASTICSEARCH_HOSTS}"]
  index: "docker-logs-%{+yyyy.MM.dd}"
```

### 7.3 多环境配置管理


```yaml
# 使用环境变量区分不同环境
filebeat.autodiscover:
  providers:
    - type: kubernetes
      node: ${NODE_NAME}
      templates:
        - condition.and:
            - equals:
                kubernetes.labels.environment: "${ENVIRONMENT:production}"
            - not.contains:
                kubernetes.namespace: "kube-system"
          config:
            - type: container
              paths:
                - /var/log/containers/*-${data.kubernetes.container.id}.log
              fields:
                environment: ${ENVIRONMENT}
                cluster: ${CLUSTER_NAME}
                region: ${AWS_REGION}
              processors:
                - add_kubernetes_metadata:
                    host: ${NODE_NAME}
                # 生产环境添加更多元数据
                - script:
                    lang: javascript
                    source: >
                      if (event.Get("kubernetes.labels.priority") === "high") {
                        event.Put("priority_routing", true);
                      }

# 不同环境的输出配置
output.elasticsearch:
  hosts: ["${ELASTICSEARCH_HOSTS}"]
  # 根据环境使用不同索引
  index: "filebeat-${ENVIRONMENT:dev}-%{+yyyy.MM.dd}"
  # 生产环境使用ILM
  ilm:
    enabled: ${ILM_ENABLED:false}
    rollover_alias: "filebeat-${ENVIRONMENT}"
    pattern: "{now/d}-000001"
```

---

## 8. 📋 核心要点总结


### 8.1 必须掌握的核心概念


```
🔸 容器日志特性：动态路径、临时性、标准化输出
🔸 Docker容器输入：通过/var/lib/docker/containers路径采集
🔸 Kubernetes输入：通过/var/log/containers和自动发现采集
🔸 元数据采集：丰富日志信息，便于查询和分析
🔸 自动发现机制：动态配置，适应容器环境变化
🔸 过滤规则：精准控制采集范围，提高效率
```

### 8.2 关键理解要点


**🔹 容器日志采集的挑战与解决**
```
挑战：容器路径动态、生命周期短暂
解决：自动发现 + 元数据增强 + 智能过滤

记忆要点：
- 路径模式匹配解决动态路径问题
- 元数据处理器解决上下文缺失问题  
- 自动发现解决配置动态变化问题
```

**🔹 Docker vs Kubernetes配置差异**
```
Docker环境：
- 直接访问Docker API
- 相对简单的元数据
- 主要通过容器标签控制

Kubernetes环境：
- 通过节点文件系统访问
- 丰富的K8s元数据（Pod、Service等）
- 通过注解和标签精细控制
```

**🔹 自动发现的核心价值**
```
静态配置的痛点：
- 每个应用需要独立配置
- 容器变化需要重启Filebeat
- 难以处理大规模动态环境

自动发现的优势：
- 一次配置，处理多种场景
- 容器启停自动适应
- 通过标签实现配置分离
```

### 8.3 实际应用指导


**🎯 配置选择策略**
```
小规模Docker环境：
→ 使用简单的container输入类型
→ 添加基础Docker元数据

大规模Kubernetes环境：
→ 使用自动发现机制
→ 配置多个模板处理不同应用类型
→ 通过标签和注解精细控制

混合环境：
→ 分别配置Docker和Kubernetes提供者
→ 统一索引命名规范
→ 标准化元数据字段
```

**🔧 性能优化要点**
```
减少资源消耗：
- 合理设置scan_frequency
- 使用过滤规则减少无用日志
- 配置合适的缓冲区大小

提高采集效率：
- 避免过于宽泛的路径匹配
- 使用条件匹配精确定位
- 合理配置多行日志规则
```

**🚨 常见问题避免**
```
权限问题：
- 确保Filebeat有读取Docker socket权限
- 在K8s中使用适当的ServiceAccount

路径问题：
- 验证容器日志实际存储路径
- 注意不同容器运行时的差异

配置问题：
- 模板条件要精确，避免冲突
- 测试自动发现规则的匹配效果
```

### 8.4 最佳实践建议


**🏗️ 架构设计**
```
分层采集策略：
1. 基础层：系统和基础设施日志
2. 应用层：业务应用日志  
3. 监控层：监控和告警日志

统一元数据规范：
- 标准化标签命名
- 统一环境标识
- 规范化服务分类
```

**📊 监控与运维**
```
采集状态监控：
- 监控Filebeat自身状态
- 跟踪日志采集量和延迟
- 设置关键容器采集告警

配置管理：
- 版本化配置文件
- 自动化配置部署
- 配置变更审计
```

**核心记忆口诀**：
- 容器日志路径动态变，自动发现来解决
- 元数据增强上下文，过滤规则控精准  
- Docker简单K8s复杂，模板配置要分层
- 生产环境重监控，性能优化不能少