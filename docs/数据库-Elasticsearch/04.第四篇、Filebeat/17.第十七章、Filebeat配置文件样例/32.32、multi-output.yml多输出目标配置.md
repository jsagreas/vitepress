---
title: 32ã€multi-output.ymlå¤šè¾“å‡ºç›®æ ‡é…ç½®
---
## ğŸ“š ç›®å½•

1. [å¤šè¾“å‡ºæ¦‚å¿µä¸åº”ç”¨åœºæ™¯](#1-å¤šè¾“å‡ºæ¦‚å¿µä¸åº”ç”¨åœºæ™¯)
2. [åŸºç¡€å¤šè¾“å‡ºé…ç½®](#2-åŸºç¡€å¤šè¾“å‡ºé…ç½®)
3. [æ¡ä»¶åˆ†å‘ä¸è·¯ç”±è§„åˆ™](#3-æ¡ä»¶åˆ†å‘ä¸è·¯ç”±è§„åˆ™)
4. [è´Ÿè½½å‡è¡¡ä¸å®¹é”™é…ç½®](#4-è´Ÿè½½å‡è¡¡ä¸å®¹é”™é…ç½®)
5. [ç›‘æ§ä¸ä¼˜åŒ–ç­–ç•¥](#5-ç›‘æ§ä¸ä¼˜åŒ–ç­–ç•¥)
6. [å®æˆ˜é…ç½®æ ·ä¾‹å¤§å…¨](#6-å®æˆ˜é…ç½®æ ·ä¾‹å¤§å…¨)
7. [æ ¸å¿ƒè¦ç‚¹æ€»ç»“](#7-æ ¸å¿ƒè¦ç‚¹æ€»ç»“)

---

## 1. ğŸ¯ å¤šè¾“å‡ºæ¦‚å¿µä¸åº”ç”¨åœºæ™¯


### 1.1 ä»€ä¹ˆæ˜¯Filebeatå¤šè¾“å‡º


**ğŸ”¸ ç®€å•ç†è§£**
```
å•è¾“å‡ºæ¨¡å¼ï¼šæ—¥å¿— â†’ Filebeat â†’ Elasticsearch
å¤šè¾“å‡ºæ¨¡å¼ï¼šæ—¥å¿— â†’ Filebeat â†’ å¤šä¸ªç›®æ ‡ï¼ˆES + Kafka + Logstashç­‰ï¼‰

å°±åƒä¸€ä¸ªå¿«é€’åˆ†æ‹£ä¸­å¿ƒï¼š
åŒä¸€æ‰¹åŒ…è£¹å¯ä»¥åŒæ—¶å‘å¾€ä¸åŒçš„ç›®çš„åœ°
```

**ğŸ”¸ æ ¸å¿ƒæ¦‚å¿µ**
- **å¤šè¾“å‡º**ï¼šä¸€ä»½æ—¥å¿—æ•°æ®åŒæ—¶å‘é€åˆ°å¤šä¸ªä¸åŒçš„ç›®æ ‡ç³»ç»Ÿ
- **æ¡ä»¶è·¯ç”±**ï¼šæ ¹æ®æ—¥å¿—å†…å®¹å†³å®šå‘é€åˆ°å“ªä¸ªç›®æ ‡
- **è´Ÿè½½åˆ†æ‹…**ï¼šå°†æ•°æ®æµåˆ†æ•£åˆ°å¤šä¸ªç›¸åŒç±»å‹çš„ç›®æ ‡
- **å¤‡ä»½è¾“å‡º**ï¼šä¸»è¾“å‡ºå¤±è´¥æ—¶è‡ªåŠ¨åˆ‡æ¢åˆ°å¤‡ç”¨è¾“å‡º

### 1.2 å…¸å‹åº”ç”¨åœºæ™¯


**ğŸ¯ ä¸šåŠ¡åœºæ™¯å¯¹ç…§è¡¨**

| åº”ç”¨åœºæ™¯ | **å…·ä½“éœ€æ±‚** | **é…ç½®ç­–ç•¥** | **å®é™…ä»·å€¼** |
|---------|-------------|-------------|-------------|
| ğŸ¢ **ä¼ä¸šçº§æ—¥å¿—åˆ†æ** | `å®æ—¶ç›‘æ§ + é•¿æœŸå­˜å‚¨` | `ESå®æ—¶ + HDFSå­˜å‚¨` | `å¿«é€Ÿå‘Šè­¦ + å†å²åˆ†æ` |
| ğŸ” **å®‰å…¨ç›‘æ§** | `å®‰å…¨æ—¥å¿—å¤šé‡å¤‡ä»½` | `SIEM + ES + æ–‡ä»¶å¤‡ä»½` | `åˆè§„ + å®æ—¶æ£€æµ‹` |
| ğŸ“Š **ä¸šåŠ¡åˆ†æ** | `ä¸åŒå›¢é˜Ÿä¸åŒéœ€æ±‚` | `æŒ‰éƒ¨é—¨åˆ†å‘åˆ°ä¸åŒES` | `æ•°æ®éš”ç¦» + æƒé™æ§åˆ¶` |
| ğŸš¨ **æ•…éšœæ’æŸ¥** | `é”™è¯¯æ—¥å¿—ç‰¹æ®Šå¤„ç†` | `é”™è¯¯â†’å‘Šè­¦ç³»ç»Ÿï¼Œæ­£å¸¸â†’ES` | `å¿«é€Ÿå“åº” + æ•°æ®å®Œæ•´` |

---

## 2. âš™ï¸ åŸºç¡€å¤šè¾“å‡ºé…ç½®


### 2.1 ç†è§£Filebeatè¾“å‡ºæœºåˆ¶


> ğŸ’¡ **é‡è¦æ¦‚å¿µ**ï¼šFilebeatæœ¬èº«åªæ”¯æŒå•ä¸ªè¾“å‡ºï¼Œä½†æˆ‘ä»¬å¯ä»¥é€šè¿‡å¤šç§æ–¹å¼å®ç°"å¤šè¾“å‡ºæ•ˆæœ"

**ğŸ”¸ å®ç°å¤šè¾“å‡ºçš„æ–¹æ³•**

```
æ–¹æ³•ä¸€ï¼šå¤šä¸ªFilebeatå®ä¾‹
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Filebeat-1  â”‚â”€â”€â”€â–¶â”‚Elasticsearchâ”‚    â”‚             â”‚
â”‚ (åŒä¸€æ—¥å¿—)   â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                       â”‚    æ—¥å¿—æ–‡ä»¶  â”‚
â”‚ Filebeat-2  â”‚â”€â”€â”€â–¶â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚             â”‚
â”‚ (åŒä¸€æ—¥å¿—)   â”‚    â”‚    Kafka    â”‚    â”‚             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

æ–¹æ³•äºŒï¼šé€šè¿‡Logstashä¸­è½¬
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Filebeat   â”‚â”€â”€â”€â–¶â”‚  Logstash   â”‚â”€â”€â”€â–¶â”‚Elasticsearchâ”‚
â”‚             â”‚    â”‚  (å¤šè¾“å‡º)    â”‚    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    Kafka    â”‚
                                      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                                      â”‚   æ–‡ä»¶ç³»ç»Ÿ   â”‚
                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 å¤šå®ä¾‹é…ç½®æ–¹æ¡ˆ


**ğŸ”§ é…ç½®æ–‡ä»¶ï¼šfilebeat-to-es.yml**
```yaml
# å‘é€åˆ°Elasticsearchçš„å®ä¾‹
filebeat.inputs:
- type: log
  paths:
    - /var/log/app/*.log
  fields:
    output_target: "elasticsearch"
  fields_under_root: true

output.elasticsearch:
  hosts: ["es-node1:9200", "es-node2:9200"]
  index: "app-logs-%{+yyyy.MM.dd}"

logging.level: info
logging.to_files: true
logging.files:
  path: /var/log/filebeat-es
```

**ğŸ”§ é…ç½®æ–‡ä»¶ï¼šfilebeat-to-kafka.yml**
```yaml
# å‘é€åˆ°Kafkaçš„å®ä¾‹
filebeat.inputs:
- type: log
  paths:
    - /var/log/app/*.log
  fields:
    output_target: "kafka"
  fields_under_root: true

output.kafka:
  hosts: ["kafka1:9092", "kafka2:9092"]
  topic: "app-logs"
  partition.round_robin:
    reachable_only: true

logging.level: info
logging.to_files: true
logging.files:
  path: /var/log/filebeat-kafka
```

**ğŸš€ å¯åŠ¨å¤šå®ä¾‹**
```bash
# å¯åŠ¨å‘é€åˆ°ESçš„å®ä¾‹
nohup ./filebeat -c filebeat-to-es.yml &

# å¯åŠ¨å‘é€åˆ°Kafkaçš„å®ä¾‹  
nohup ./filebeat -c filebeat-to-kafka.yml &

# æŸ¥çœ‹è¿è¡ŒçŠ¶æ€
ps aux | grep filebeat
```

---

## 3. ğŸ”€ æ¡ä»¶åˆ†å‘ä¸è·¯ç”±è§„åˆ™


### 3.1 é€šè¿‡Logstashå®ç°æ™ºèƒ½è·¯ç”±


**ğŸ”¸ æ¶æ„è®¾è®¡æ€è·¯**
```
                    â”Œâ”€â”€â”€ é”™è¯¯æ—¥å¿— â”€â”€â”€â–¶ å‘Šè­¦ç³»ç»Ÿ
æ—¥å¿—æ–‡ä»¶ â”€â”€â–¶ Filebeat â”€â”€â–¶ Logstash â”¼â”€â”€â”€ æ­£å¸¸æ—¥å¿— â”€â”€â”€â–¶ Elasticsearch  
                    â””â”€â”€â”€ å…¨éƒ¨æ—¥å¿— â”€â”€â”€â–¶ é•¿æœŸå­˜å‚¨
```

**ğŸ”§ Filebeaté…ç½®ï¼ˆå‘é€åˆ°Logstashï¼‰**
```yaml
# filebeat-to-logstash.yml
filebeat.inputs:
- type: log
  paths:
    - /var/log/app/app.log
    - /var/log/nginx/access.log
    - /var/log/nginx/error.log
  multiline.pattern: '^\d{4}-\d{2}-\d{2}'
  multiline.negate: true
  multiline.match: after

# æ·»åŠ å…ƒæ•°æ®ä¾¿äºLogstashå¤„ç†
processors:
- add_host_metadata:
    when.not.contains.tags: forwarded
- add_fields:
    target: ""
    fields:
      environment: "production"
      datacenter: "dc1"

output.logstash:
  hosts: ["logstash1:5044", "logstash2:5044"]
  loadbalance: true
  worker: 2

# å¯ç”¨æ—¥å¿—è½®è½¬é¿å…ç£ç›˜æ»¡
logging.level: info
logging.to_files: true
logging.files:
  path: /var/log/filebeat
  name: filebeat
  keepfiles: 7
  permissions: 0644
```

**ğŸ”§ Logstashå¤šè¾“å‡ºé…ç½®**
```ruby
# logstash-multi-output.conf
input {
  beats {
    port => 5044
  }
}

filter {
  # è§£ææ—¥å¿—çº§åˆ«
  if [source] =~ "app\.log" {
    grok {
      match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} \[%{LOGLEVEL:level}\] %{GREEDYDATA:content}" }
    }
  }
  
  # è§£æNginxè®¿é—®æ—¥å¿—
  if [source] =~ "access\.log" {
    grok {
      match => { "message" => "%{NGINXACCESS}" }
    }
  }
  
  # ä¸ºä¸åŒæ—¥å¿—ç±»å‹æ·»åŠ æ ‡ç­¾
  if [source] =~ "error\.log" {
    mutate {
      add_tag => [ "error_log", "needs_alert" ]
    }
  }
  
  if [level] == "ERROR" or [level] == "FATAL" {
    mutate {
      add_tag => [ "application_error", "needs_alert" ]
    }
  }
}

output {
  # é”™è¯¯æ—¥å¿—å‘é€åˆ°å‘Šè­¦ç³»ç»Ÿ
  if "needs_alert" in [tags] {
    elasticsearch {
      hosts => ["alert-es:9200"]
      index => "alerts-%{+yyyy.MM.dd}"
    }
    
    # åŒæ—¶å‘é€åˆ°å‘Šè­¦é˜Ÿåˆ—
    kafka {
      topic_id => "alerts"
      bootstrap_servers => ["kafka1:9092"]
    }
  }
  
  # æ‰€æœ‰æ—¥å¿—å‘é€åˆ°ä¸»ESé›†ç¾¤
  elasticsearch {
    hosts => ["es-cluster:9200"]
    index => "%{[@metadata][beat]}-%{+yyyy.MM.dd}"
  }
  
  # é‡è¦æ—¥å¿—å¤‡ä»½åˆ°HDFS
  if [level] in ["ERROR", "WARN", "INFO"] {
    hdfs {
      path => "/logs/%{environment}/%{+yyyy/MM/dd}/%{[beat][hostname]}"
      compression => "gzip"
    }
  }
  
  # è°ƒè¯•è¾“å‡ºï¼ˆå¼€å‘ç¯å¢ƒï¼‰
  if [environment] == "development" {
    stdout { 
      codec => rubydebug 
    }
  }
}
```

### 3.2 åŸºäºå­—æ®µçš„æ¡ä»¶è·¯ç”±


**ğŸ¯ å®é™…åœºæ™¯ï¼šç”µå•†ç½‘ç«™æ—¥å¿—åˆ†å‘**

```ruby
# æ ¹æ®ä¸åŒä¸šåŠ¡æ¨¡å—åˆ†å‘åˆ°ä¸åŒå­˜å‚¨
filter {
  # è¯†åˆ«ä¸šåŠ¡æ¨¡å—
  if [source] =~ "order" {
    mutate { add_field => { "business_module" => "order" } }
  } else if [source] =~ "payment" {
    mutate { add_field => { "business_module" => "payment" } }
  } else if [source] =~ "user" {
    mutate { add_field => { "business_module" => "user" } }
  }
}

output {
  # è®¢å•ç›¸å…³æ—¥å¿—
  if [business_module] == "order" {
    elasticsearch {
      hosts => ["order-es:9200"]
      index => "orders-%{+yyyy.MM.dd}"
      template_name => "order-template"
    }
  }
  
  # æ”¯ä»˜ç›¸å…³æ—¥å¿—  
  if [business_module] == "payment" {
    elasticsearch {
      hosts => ["payment-es:9200"] 
      index => "payments-%{+yyyy.MM.dd}"
    }
    
    # æ”¯ä»˜æ—¥å¿—åŒæ—¶å¤‡ä»½
    file {
      path => "/backup/payment-logs/%{+yyyy-MM-dd}.log"
      codec => line { format => "%{message}" }
    }
  }
  
  # ç”¨æˆ·è¡Œä¸ºæ—¥å¿—å‘é€åˆ°Kafkaä¾›å®æ—¶åˆ†æ
  if [business_module] == "user" {
    kafka {
      topic_id => "user-behavior"
      bootstrap_servers => ["kafka-cluster:9092"]
    }
  }
}
```

---

## 4. ğŸ”„ è´Ÿè½½å‡è¡¡ä¸å®¹é”™é…ç½®


### 4.1 è´Ÿè½½å‡è¡¡ç­–ç•¥


**ğŸ”¸ ç†è§£è´Ÿè½½å‡è¡¡çš„æœ¬è´¨**
```
é—®é¢˜ï¼šå•ä¸ªç›®æ ‡å‹åŠ›å¤§ï¼Œå®¹æ˜“æˆä¸ºç“¶é¢ˆ
è§£å†³ï¼šå°†æ•°æ®åˆ†æ•£åˆ°å¤šä¸ªç›¸åŒçš„ç›®æ ‡

å°±åƒé“¶è¡Œå¼€è®¾å¤šä¸ªçª—å£ï¼š
å®¢æˆ·æŒ‰æŸç§è§„åˆ™åˆ†é…åˆ°ä¸åŒçª—å£ï¼Œæé«˜æ•´ä½“æ•ˆç‡
```

**ğŸ”§ Elasticsearché›†ç¾¤è´Ÿè½½å‡è¡¡**
```yaml
# è½®è¯¢è´Ÿè½½å‡è¡¡
output.elasticsearch:
  hosts: 
    - "es-node1:9200"
    - "es-node2:9200" 
    - "es-node3:9200"
  loadbalance: true
  worker: 3
  
  # è¿æ¥æ± è®¾ç½®
  max_retries: 3
  bulk_max_size: 1600
  timeout: 90
  
  # å¥åº·æ£€æŸ¥
  backoff.init: 1s
  backoff.max: 60s
```

**ğŸ”§ Kafkaåˆ†åŒºè´Ÿè½½å‡è¡¡**
```yaml
output.kafka:
  hosts: ["kafka1:9092", "kafka2:9092", "kafka3:9092"]
  topic: "app-logs"
  
  # åˆ†åŒºç­–ç•¥
  partition.round_robin:
    reachable_only: true
  
  # æˆ–è€…åŸºäºkeyåˆ†åŒº
  partition.hash:
    hash: ["host.name"]
    
  # æ€§èƒ½ä¼˜åŒ–
  compression: gzip
  max_message_bytes: 1000000
  required_acks: 1
```

### 4.2 å®¹é”™ä¸æ•…éšœè½¬ç§»


**ğŸ”§ å¤šçº§å®¹é”™é…ç½®ç¤ºä¾‹**
```yaml
# filebeat-with-failover.yml
filebeat.inputs:
- type: log
  paths:
    - /var/log/app/*.log

# ä¸»è¾“å‡ºï¼šElasticsearch
output.elasticsearch:
  hosts: ["primary-es:9200"]
  index: "app-logs-%{+yyyy.MM.dd}"
  
  # å¤±è´¥å¤„ç†
  max_retries: 3
  backoff.init: 1s
  backoff.max: 60s
  
  # å½“ESä¸å¯ç”¨æ—¶çš„å¤„ç†
  timeout: 30s

# å¤‡ç”¨æ–¹æ¡ˆï¼šé€šè¿‡processorsé…ç½®
processors:
- script:
    lang: javascript
    id: failover_check
    source: >
      function process(event) {
        // æ£€æµ‹ä¸»è¾“å‡ºçŠ¶æ€ï¼Œå®ç°è‡ªå®šä¹‰å®¹é”™é€»è¾‘
        return event;
      }
```

**ğŸ”§ æ–‡ä»¶å¤‡ä»½å®¹é”™æ–¹æ¡ˆ**
```yaml
# å½“ä¸»è¦è¾“å‡ºå¤±è´¥æ—¶ï¼Œå†™å…¥æœ¬åœ°æ–‡ä»¶
output.file:
  path: "/var/log/filebeat/backup"
  filename: "failed-logs-%{+yyyy-MM-dd}.log"
  rotate_every_kb: 10000
  number_of_files: 7
  
  # ä»…åœ¨ä¸»è¾“å‡ºå¤±è´¥æ—¶å¯ç”¨
  when.equals:
    output.elasticsearch.connection_status: "failed"
```

---

## 5. ğŸ“Š ç›‘æ§ä¸ä¼˜åŒ–ç­–ç•¥


### 5.1 å¤šè¾“å‡ºç›‘æ§é…ç½®


**ğŸ”§ å¯ç”¨Filebeatå†…ç½®ç›‘æ§**
```yaml
# ç›‘æ§é…ç½®
monitoring.enabled: true
monitoring.elasticsearch:
  hosts: ["monitoring-es:9200"]
  index: "filebeat-monitoring"

# HTTPç›‘æ§ç«¯ç‚¹
http.enabled: true
http.host: "0.0.0.0"
http.port: 5066

# æŒ‡æ ‡æ”¶é›†
filebeat.config.monitors:
  reload.enabled: true
  reload.period: 30s

# æ—¥å¿—è¯¦ç»†çº§åˆ«
logging.level: info
logging.metrics.enabled: true
logging.metrics.period: 30s
```

**ğŸ”§ è‡ªå®šä¹‰ç›‘æ§è„šæœ¬**
```bash
#!/bin/bash
# filebeat-monitor.sh - å¤šè¾“å‡ºç›‘æ§è„šæœ¬

FILEBEAT_API="http://localhost:5066"
LOG_FILE="/var/log/filebeat-monitor.log"

check_filebeat_status() {
    echo "$(date): æ£€æŸ¥FilebeatçŠ¶æ€..." >> $LOG_FILE
    
    # æ£€æŸ¥è¿›ç¨‹çŠ¶æ€
    if ! pgrep -f filebeat > /dev/null; then
        echo "ERROR: Filebeatè¿›ç¨‹æœªè¿è¡Œ" >> $LOG_FILE
        # å‘é€å‘Šè­¦
        curl -X POST "http://alert-system/api/alert" \
             -H "Content-Type: application/json" \
             -d '{"level":"critical","message":"Filebeatè¿›ç¨‹åœæ­¢"}'
        return 1
    fi
    
    # æ£€æŸ¥APIå“åº”
    if ! curl -s "$FILEBEAT_API/stats" > /dev/null; then
        echo "WARNING: Filebeat APIæ— å“åº”" >> $LOG_FILE
        return 1
    fi
    
    # è·å–è¾“å‡ºç»Ÿè®¡
    STATS=$(curl -s "$FILEBEAT_API/stats")
    echo "çŠ¶æ€æ­£å¸¸: $STATS" >> $LOG_FILE
}

# æ¯5åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
while true; do
    check_filebeat_status
    sleep 300
done
```

### 5.2 æ€§èƒ½ä¼˜åŒ–é…ç½®


**ğŸ”§ é«˜æ€§èƒ½å¤šè¾“å‡ºé…ç½®**
```yaml
# ä¼˜åŒ–åçš„é…ç½®
filebeat.inputs:
- type: log
  paths:
    - /var/log/app/*.log
  # æ‰¹å¤„ç†ä¼˜åŒ–
  harvester_buffer_size: 16384
  max_bytes: 10485760
  
  # æ‰«æé¢‘ç‡ä¼˜åŒ–
  scan_frequency: 10s
  ignore_older: 24h

# é˜Ÿåˆ—é…ç½®ä¼˜åŒ–
queue.mem:
  events: 4096
  flush.min_events: 2048
  flush.timeout: 5s

# è¾“å‡ºä¼˜åŒ–
output.logstash:
  hosts: ["logstash1:5044", "logstash2:5044"]
  loadbalance: true
  
  # æ€§èƒ½å‚æ•°
  worker: 4
  bulk_max_size: 2048
  timeout: 30s
  pipelining: 2

# å¤„ç†å™¨ä¼˜åŒ–
processors:
- add_host_metadata:
    cache.ttl: 5m
- add_docker_metadata:
    host: "unix:///var/run/docker.sock"
    cache.ttl: 2m
```

---

## 6. ğŸ“‹ å®æˆ˜é…ç½®æ ·ä¾‹å¤§å…¨


### 6.1 ä¼ä¸šçº§å®Œæ•´é…ç½®æ ·ä¾‹


**ğŸ”§ ç”Ÿäº§ç¯å¢ƒå¤šè¾“å‡ºé…ç½®**
```yaml
# enterprise-filebeat.yml - ä¼ä¸šçº§é…ç½®
################### Filebeat Configuration ####################


# å…¨å±€é…ç½®
name: "production-filebeat-multi"
tags: ["production", "multi-output", "enterprise"]

# è¾“å…¥é…ç½®
filebeat.inputs:
# åº”ç”¨æ—¥å¿—
- type: log
  enabled: true
  paths:
    - /var/log/app/application*.log
  fields:
    logtype: "application"
    service: "main-app"
    environment: "production"
  fields_under_root: true
  multiline.pattern: '^\d{4}-\d{2}-\d{2}'
  multiline.negate: true
  multiline.match: after
  exclude_lines: ['DEBUG', 'TRACE']

# WebæœåŠ¡å™¨æ—¥å¿—
- type: log
  enabled: true
  paths:
    - /var/log/nginx/access.log
  fields:
    logtype: "access"
    service: "nginx"
  fields_under_root: true

# é”™è¯¯æ—¥å¿—
- type: log
  enabled: true
  paths:
    - /var/log/nginx/error.log
    - /var/log/app/error*.log
  fields:
    logtype: "error"
    priority: "high"
  fields_under_root: true

# å¤„ç†å™¨é…ç½®
processors:
- add_host_metadata:
    when.not.contains.tags: forwarded
- add_docker_metadata:
    host: "unix:///var/run/docker.sock"
- drop_fields:
    fields: ["agent", "ecs", "input", "log.file"]
- timestamp:
    field: "@timestamp"
    layouts:
      - '2006-01-02T15:04:05.000Z'
      - '2006-01-02 15:04:05'
    test:
      - '2023-10-15T10:30:45.123Z'

# è¾“å‡ºåˆ°Logstashï¼ˆå®ç°å¤šè¾“å‡ºï¼‰
output.logstash:
  hosts: 
    - "logstash-node1:5044"
    - "logstash-node2:5044" 
    - "logstash-node3:5044"
  loadbalance: true
  worker: 3
  compression_level: 3
  escape_html: false

# æ—¥å¿—é…ç½®
logging.level: info
logging.to_files: true
logging.files:
  path: /var/log/filebeat
  name: filebeat-multi
  keepfiles: 10
  permissions: 0600

# ç›‘æ§é…ç½®
monitoring.enabled: true
http.enabled: true
http.host: "0.0.0.0"
http.port: 5066

# æ€§èƒ½ä¼˜åŒ–
queue.mem:
  events: 8192
  flush.min_events: 4096
  flush.timeout: 5s

# å®‰å…¨é…ç½®  
ssl.verification_mode: "full"
ssl.certificate_authorities: ["/etc/ssl/certs/ca.crt"]
```

**ğŸ”§ å¯¹åº”çš„Logstashé…ç½®**
```ruby
# enterprise-logstash.conf
input {
  beats {
    port => 5044
    ssl => true
    ssl_certificate => "/etc/ssl/certs/logstash.crt"
    ssl_key => "/etc/ssl/private/logstash.key"
  }
}

filter {
  # ç»Ÿä¸€æ—¶é—´æˆ³å¤„ç†
  date {
    match => [ "@timestamp", "ISO8601" ]
    target => "@timestamp"
  }
  
  # æ ¹æ®æ—¥å¿—ç±»å‹è¿›è¡Œä¸åŒå¤„ç†
  if [logtype] == "application" {
    grok {
      match => { 
        "message" => "%{TIMESTAMP_ISO8601:timestamp} \[%{LOGLEVEL:level}\] %{DATA:thread} %{DATA:logger} - %{GREEDYDATA:content}" 
      }
    }
    
    # è§£æJSONæ ¼å¼çš„åº”ç”¨æ—¥å¿—
    if [content] =~ /^\{.*\}$/ {
      json {
        source => "content"
        target => "json_data"
      }
    }
  }
  
  if [logtype] == "access" {
    grok {
      match => { 
        "message" => "%{NGINXACCESS}" 
      }
    }
    
    # è®¡ç®—å“åº”æ—¶é—´ç­‰çº§
    if [response_time] {
      ruby {
        code => "
          response_time = event.get('response_time').to_f
          if response_time > 2.0
            event.set('performance_level', 'slow')
          elsif response_time > 1.0
            event.set('performance_level', 'medium')
          else
            event.set('performance_level', 'fast')
          end
        "
      }
    }
  }
  
  # é”™è¯¯æ—¥å¿—ç‰¹æ®Šå¤„ç†
  if [logtype] == "error" or [level] in ["ERROR", "FATAL"] {
    mutate {
      add_tag => [ "error", "needs_attention" ]
      add_field => { "alert_priority" => "high" }
    }
  }
  
  # æ·»åŠ åœ°ç†ä½ç½®ä¿¡æ¯ï¼ˆå¦‚æœæœ‰IPï¼‰
  if [remote_ip] {
    geoip {
      source => "remote_ip"
      target => "geoip"
    }
  }
}

output {
  # 1. é”™è¯¯å’Œå‘Šè­¦æ—¥å¿— -> ä¸“ç”¨ESé›†ç¾¤
  if "error" in [tags] or [alert_priority] == "high" {
    elasticsearch {
      hosts => ["alert-es-1:9200", "alert-es-2:9200"]
      index => "alerts-%{environment}-%{+yyyy.MM.dd}"
      template_name => "alert-template"
      document_type => "_doc"
    }
    
    # åŒæ—¶å‘é€åˆ°å‘Šè­¦é˜Ÿåˆ—
    kafka {
      topic_id => "critical-alerts"
      bootstrap_servers => ["kafka-1:9092", "kafka-2:9092"]
      codec => json
    }
  }
  
  # 2. è®¿é—®æ—¥å¿— -> å®æ—¶åˆ†æES + é•¿æœŸå­˜å‚¨
  if [logtype] == "access" {
    # å®æ—¶åˆ†æES
    elasticsearch {
      hosts => ["analytics-es:9200"]
      index => "access-logs-%{+yyyy.MM.dd}"
      template_name => "access-template"
    }
    
    # å‘é€åˆ°Kafkaä¾›å®æ—¶å¤„ç†
    kafka {
      topic_id => "access-logs"
      bootstrap_servers => ["kafka-1:9092", "kafka-2:9092"]
      partition_key => "%{host.name}"
    }
  }
  
  # 3. åº”ç”¨æ—¥å¿— -> ä¸»ESé›†ç¾¤
  if [logtype] == "application" {
    elasticsearch {
      hosts => ["main-es-1:9200", "main-es-2:9200", "main-es-3:9200"]
      index => "app-logs-%{service}-%{+yyyy.MM.dd}"
      template_name => "app-template"
    }
  }
  
  # 4. æ‰€æœ‰æ—¥å¿—å¤‡ä»½åˆ°HDFSï¼ˆé•¿æœŸå­˜å‚¨ï¼‰
  hdfs {
    path => "/logs/backup/%{environment}/%{logtype}/%{+yyyy/MM/dd}/%{host.name}"
    compression => "gzip"
    file_extension => ".log.gz"
    idle_flush_time => 300
    flush_size => 500
  }
  
  # 5. å¼€å‘ç¯å¢ƒè¾“å‡ºåˆ°stdout
  if [environment] == "development" {
    stdout { 
      codec => rubydebug {
        metadata => true
      }
    }
  }
}
```

### 6.2 å¾®æœåŠ¡æ¶æ„é…ç½®æ ·ä¾‹


**ğŸ”§ å®¹å™¨åŒ–ç¯å¢ƒé…ç½®**
```yaml
# microservices-filebeat.yml
apiVersion: v1
kind: ConfigMap
metadata:
  name: filebeat-config
data:
  filebeat.yml: |
    filebeat.autodiscover:
      providers:
        - type: kubernetes
          node: ${NODE_NAME}
          hints.enabled: true
          hints.default_config:
            type: container
            paths:
              - /var/log/containers/*${data.kubernetes.container.id}.log

    processors:
    - add_kubernetes_metadata:
        host: ${NODE_NAME}
        matchers:
        - logs_path:
            logs_path: "/var/log/containers/"
    
    # å¤šè¾“å‡ºé€šè¿‡ä¸åŒnamespaceå®ç°
    - script:
        lang: javascript
        source: >
          function process(event) {
            var namespace = event.Get("kubernetes.namespace");
            var service = event.Get("kubernetes.container.name");
            
            // æ ¹æ®å‘½åç©ºé—´è®¾ç½®è¾“å‡ºç›®æ ‡
            if (namespace === "production") {
              event.Put("output_target", "production-es");
            } else if (namespace === "staging") {
              event.Put("output_target", "staging-es");
            } else {
              event.Put("output_target", "development-kafka");
            }
            
            return event;
          }

    output.logstash:
      hosts: ["logstash-service:5044"]
      
    setup.template.settings:
      index.number_of_shards: 3
      index.number_of_replicas: 1
```

---

## 7. ğŸ“‹ æ ¸å¿ƒè¦ç‚¹æ€»ç»“


### 7.1 å¿…é¡»æŒæ¡çš„æ ¸å¿ƒæ¦‚å¿µ


```
ğŸ”¸ å¤šè¾“å‡ºæœ¬è´¨ï¼šä¸€ä»½æ•°æ®åŒæ—¶å‘é€åˆ°å¤šä¸ªç›®æ ‡ç³»ç»Ÿ
ğŸ”¸ å®ç°æ–¹å¼ï¼šå¤šå®ä¾‹æ–¹å¼ + Logstashä¸­è½¬æ–¹å¼
ğŸ”¸ è·¯ç”±è§„åˆ™ï¼šåŸºäºå­—æ®µå†…å®¹çš„æ¡ä»¶åˆ†å‘
ğŸ”¸ è´Ÿè½½å‡è¡¡ï¼šæ•°æ®åˆ†æ•£åˆ°å¤šä¸ªç›¸åŒç›®æ ‡
ğŸ”¸ å®¹é”™æœºåˆ¶ï¼šä¸»è¾“å‡ºå¤±è´¥æ—¶çš„å¤‡ç”¨æ–¹æ¡ˆ
```

### 7.2 å…³é”®ç†è§£è¦ç‚¹


**ğŸ”¹ ä¸ºä»€ä¹ˆéœ€è¦å¤šè¾“å‡º**
```
ä¸šåŠ¡éœ€æ±‚ï¼š
- ä¸åŒå›¢é˜Ÿéœ€è¦ä¸åŒçš„æ•°æ®è§†å›¾
- å®æ—¶åˆ†æ + é•¿æœŸå­˜å‚¨çš„åŒé‡éœ€æ±‚
- åˆè§„è¦æ±‚å¤šé‡å¤‡ä»½
- æ•…éšœéš”ç¦»é¿å…å•ç‚¹é£é™©

æŠ€æœ¯ä¼˜åŠ¿ï¼š
- æ•°æ®åˆ©ç”¨ç‡æœ€å¤§åŒ–
- ç³»ç»Ÿå®¹é”™èƒ½åŠ›å¢å¼º  
- æ»¡è¶³ä¸åŒæ€§èƒ½è¦æ±‚
- ä¾¿äºæ•°æ®æ²»ç†å’Œæƒé™æ§åˆ¶
```

**ğŸ”¹ é…ç½®ç­–ç•¥é€‰æ‹©**
```
å¤šå®ä¾‹æ–¹å¼ï¼š
âœ… é…ç½®ç®€å•ï¼Œæ˜“äºç†è§£
âœ… æ•…éšœéš”ç¦»æ€§å¥½
âŒ èµ„æºå ç”¨è¾ƒå¤š
âŒ ç®¡ç†å¤æ‚åº¦é«˜

Logstashä¸­è½¬ï¼š
âœ… åŠŸèƒ½å¼ºå¤§ï¼Œçµæ´»æ€§é«˜
âœ… ç»Ÿä¸€ç®¡ç†ï¼Œä¾¿äºç»´æŠ¤
âŒ å¢åŠ äº†ä¸­é—´ç¯èŠ‚
âŒ Logstashæˆä¸ºæ½œåœ¨ç“¶é¢ˆ
```

### 7.3 å®é™…åº”ç”¨æŒ‡å¯¼


**ğŸ¯ é…ç½®é€‰æ‹©å»ºè®®**
```
å°è§„æ¨¡åœºæ™¯ï¼ˆ<1GB/å¤©ï¼‰ï¼š
â†’ æ¨èå¤šå®ä¾‹æ–¹å¼
â†’ é…ç½®ç®€å•ï¼Œè¿ç»´æˆæœ¬ä½

ä¸­ç­‰è§„æ¨¡åœºæ™¯ï¼ˆ1-10GB/å¤©ï¼‰ï¼š
â†’ æ¨èLogstashä¸­è½¬æ–¹å¼
â†’ å¹³è¡¡æ€§èƒ½ä¸çµæ´»æ€§

å¤§è§„æ¨¡åœºæ™¯ï¼ˆ>10GB/å¤©ï¼‰ï¼š
â†’ æ¨èKafka + å¤šæ¶ˆè´¹è€…æ¨¡å¼
â†’ é«˜æ€§èƒ½ï¼Œæ˜“äºæ‰©å±•
```

**ğŸ”§ ç›‘æ§é‡ç‚¹**
```
å…³é”®æŒ‡æ ‡ï¼š
- å„è¾“å‡ºç›®æ ‡çš„æ•°æ®é‡å’Œå»¶è¿Ÿ
- å¤±è´¥ç‡å’Œé‡è¯•æ¬¡æ•°
- ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ
- æ•°æ®å®Œæ•´æ€§æ£€æŸ¥

å‘Šè­¦è®¾ç½®ï¼š
- è¾“å‡ºå¤±è´¥ç‡ > 5%
- å»¶è¿Ÿ > 30ç§’
- é˜Ÿåˆ—ç§¯å‹ > 10000æ¡
- ç£ç›˜ä½¿ç”¨ > 80%
```

### 7.4 æœ€ä½³å®è·µæ€»ç»“


**ğŸš€ é…ç½®ä¼˜åŒ–è¦ç‚¹**
- åˆç†è®¾ç½®æ‰¹å¤„ç†å¤§å°ï¼Œå¹³è¡¡å»¶è¿Ÿå’Œååé‡
- å¯ç”¨å‹ç¼©å‡å°‘ç½‘ç»œä¼ è¾“å¼€é”€
- é…ç½®é€‚å½“çš„é‡è¯•å’Œè¶…æ—¶å‚æ•°
- ä½¿ç”¨ç›‘æ§ç¡®ä¿æ•°æ®å®Œæ•´æ€§

**âš ï¸ å¸¸è§é—®é¢˜é¿å…**
- é¿å…è¾“å‡ºç›®æ ‡è¿‡å¤šå¯¼è‡´æ€§èƒ½ä¸‹é™
- æ³¨æ„ä¸åŒè¾“å‡ºçš„æ•°æ®æ ¼å¼å…¼å®¹æ€§  
- é˜²æ­¢æŸä¸ªè¾“å‡ºå¤±è´¥å½±å“æ•´ä½“æ€§èƒ½
- ç¡®ä¿æœ‰è¶³å¤Ÿçš„æœ¬åœ°ç¼“å­˜ç©ºé—´

**ğŸ”‘ æ ¸å¿ƒè®°å¿†è¦ç‚¹**
```
å¤šè¾“å‡º = ä¸€ä»½æ•°æ®ï¼Œå¤šä¸ªå»å¤„
å®ç°æ–¹å¼ï¼šå¤šå®ä¾‹ or ä¸­è½¬è·¯ç”±
å…³é”®è€ƒè™‘ï¼šæ€§èƒ½ã€å¯é æ€§ã€ç»´æŠ¤æˆæœ¬
ç›‘æ§é‡ç‚¹ï¼šæ•°æ®å®Œæ•´æ€§å’Œç³»ç»Ÿå¥åº·
```

> ğŸ’¡ **æ€»ç»“æé†’**ï¼šå¤šè¾“å‡ºé…ç½®è™½ç„¶å¼ºå¤§ï¼Œä½†ä¹Ÿå¢åŠ äº†ç³»ç»Ÿå¤æ‚åº¦ã€‚åœ¨è®¾è®¡æ—¶è¦æ ¹æ®å®é™…ä¸šåŠ¡éœ€æ±‚æƒè¡¡åˆ©å¼Šï¼Œé€‰æ‹©æœ€é€‚åˆçš„æ–¹æ¡ˆã€‚è®°ä½ï¼šç®€å•æœ‰æ•ˆçš„æ–¹æ¡ˆå¾€å¾€æ¯”å¤æ‚å®Œç¾çš„æ–¹æ¡ˆæ›´æœ‰ä»·å€¼ã€‚