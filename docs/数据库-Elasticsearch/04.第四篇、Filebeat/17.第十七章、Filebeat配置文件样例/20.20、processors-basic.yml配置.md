---
title: 20、processors-basic.yml配置
---
## 📚 目录

1. [处理器基础概念](#1-处理器基础概念)
2. [字段操作处理器](#2-字段操作处理器)
3. [条件判断处理器](#3-条件判断处理器)
4. [时间处理器](#4-时间处理器)
5. [系统信息处理器](#5-系统信息处理器)
6. [数据转换处理器](#6-数据转换处理器)
7. [实战配置案例](#7-实战配置案例)
8. [核心要点总结](#8-核心要点总结)

---

## 1. 🔧 处理器基础概念


### 1.1 什么是Filebeat处理器


**📋 核心定义**
```
处理器(Processors)：Filebeat内置的数据处理工具
作用：在日志发送到目标之前，对数据进行加工处理
位置：位于输入和输出之间的中间处理环节
```

**🎯 处理器的工作流程**
```
日志文件 → Filebeat读取 → 处理器加工 → 输出到目标

实际例子：
原始日志：192.168.1.100 GET /api/users
↓ 处理器加工
最终数据：{
  "ip": "192.168.1.100",
  "method": "GET", 
  "path": "/api/users",
  "timestamp": "2025-09-21T12:00:00Z",
  "server": "web-01"
}
```

### 1.2 为什么要使用处理器


**💡 实际应用价值**
- **数据清洗**：去掉不需要的字段，保留有用信息
- **格式统一**：把不同格式的日志统一处理
- **信息补充**：添加服务器名称、时间戳等元信息
- **数据转换**：把字符串转成数字，方便后续分析

**🔸 生活化比喻**
> 处理器就像厨房的食材加工台：
> - 原材料（原始日志）→ 清洗切配（处理器）→ 成品菜肴（结构化数据）
> - 每个处理器就是一个加工步骤，比如洗菜、切丝、调味

---

## 2. ✂️ 字段操作处理器


### 2.1 字段添加处理器


**🔸 基本概念**
```yaml
# 20-processors-basic.yml 片段
processors:
  - add_fields:
      target: ""
      fields:
        service_name: "web-api"
        environment: "production"
        team: "backend"
```

**💭 通俗解释**
> `add_fields` 就像给每条日志贴标签，告诉别人这条日志来自哪个服务、哪个环境

**📊 处理效果对比**
```
处理前：
{
  "message": "User login successful",
  "timestamp": "2025-09-21T12:00:00Z"
}

处理后：
{
  "message": "User login successful", 
  "timestamp": "2025-09-21T12:00:00Z",
  "service_name": "web-api",
  "environment": "production",
  "team": "backend"
}
```

### 2.2 字段删除处理器


**🔸 删除敏感字段**
```yaml
processors:
  - drop_fields:
      fields: ["password", "credit_card", "personal_id"]
      ignore_missing: true
```

**💡 实用场景**
- **隐私保护**：删除密码、身份证等敏感信息
- **减少传输**：删除不需要的大字段，节省网络带宽
- **简化数据**：只保留分析需要的核心字段

### 2.3 字段重命名处理器


**🔸 统一字段名称**
```yaml
processors:
  - rename:
      fields:
        - from: "user_id"
          to: "uid"
        - from: "request_time"
          to: "duration"
      ignore_missing: true
```

**🎯 应用价值**
> 不同系统的日志字段名可能不同，重命名让所有数据使用统一的字段名，方便后续统计分析

---

## 3. 🤔 条件判断处理器


### 3.1 条件判断基础


**📋 条件处理器的作用**
```
条件判断：只有满足特定条件时，才执行某个处理器
好处：避免对所有数据进行不必要的处理
类比：就像if语句，满足条件才执行操作
```

**🔸 基础语法**
```yaml
processors:
  - if:
      condition: 判断条件
    then:
      - 执行的处理器1
      - 执行的处理器2
```

### 3.2 常用条件类型


**📊 条件类型对照表**

| 条件类型 | **语法示例** | **含义说明** | **使用场景** |
|---------|------------|-------------|-------------|
| `equals` | `message: "ERROR"` | `字段值完全等于` | `匹配特定状态` |
| `contains` | `message: "failed"` | `字段值包含指定内容` | `关键词筛选` |
| `regexp` | `message: "\\d{4}-\\d{2}-\\d{2}"` | `正则表达式匹配` | `复杂模式匹配` |
| `range` | `status_code: {gte: 400}` | `数值范围判断` | `错误码过滤` |

### 3.3 实用条件配置


**🔸 错误日志特殊处理**
```yaml
processors:
  - if:
      contains:
        message: "ERROR"
    then:
      - add_fields:
          fields:
            alert_level: "high"
            need_notification: true
```

**🔸 HTTP状态码分类**
```yaml
processors:
  - if:
      range:
        status_code:
          gte: 400
    then:
      - add_fields:
          fields:
            response_type: "error"
  - if:
      range:
        status_code:
          gte: 200
          lt: 300
    then:
      - add_fields:
          fields:
            response_type: "success"
```

---

## 4. ⏰ 时间处理器


### 4.1 时间戳处理器


**🔸 基本概念**
```
时间戳处理：把日志中的时间字符串转换成标准的时间格式
重要性：统一时间格式，方便时间范围查询和时间聚合分析
```

**📝 配置示例**
```yaml
processors:
  - timestamp:
      field: log_time
      layouts:
        - '2006-01-02 15:04:05'
        - '2006/01/02 15:04:05'
        - 'Jan _2 15:04:05'
      test:
        - '2025-09-21 12:30:45'
```

**💡 通俗解释**
> `timestamp` 处理器就像翻译官，把各种不同格式的时间都翻译成统一的标准时间格式

### 4.2 时间格式说明


**📊 常用时间格式对照**

| **日志格式** | **配置模板** | **说明** |
|-------------|-------------|----------|
| `2025-09-21 12:30:45` | `2006-01-02 15:04:05` | `标准格式` |
| `2025/09/21 12:30:45` | `2006/01/02 15:04:05` | `斜杠分隔` |
| `Sep 21 12:30:45` | `Jan _2 15:04:05` | `英文月份` |
| `20250921123045` | `20060102150405` | `紧凑格式` |

> **💭 记忆技巧**：Go语言的时间模板使用固定参考时间 `2006-01-02 15:04:05`，记住这个时间点就能写出任何格式

---

## 5. 🖥️ 系统信息处理器


### 5.1 主机信息添加


**🔸 自动添加主机信息**
```yaml
processors:
  - add_host_metadata:
      when.not.contains.tags: forwarded
      fields:
        - hostname
        - ip
        - os.family
        - os.name
```

**📋 可添加的主机信息**

```
hostname     → 主机名称
ip          → IP地址  
os.family   → 操作系统类型（linux/windows）
os.name     → 操作系统名称（Ubuntu/CentOS）
architecture → CPU架构（x86_64/arm64）
```

**💡 实际应用价值**
- **故障定位**：快速识别问题来自哪台服务器
- **负载分析**：统计不同服务器的日志量
- **环境区分**：区分开发、测试、生产环境

### 5.2 Docker容器信息


**🔸 容器环境信息添加**
```yaml
processors:
  - add_docker_metadata:
      host: "unix:///var/run/docker.sock"
      match_fields: ["container.id"]
      match_pids: ["process.pid"]
```

**📊 添加的容器信息**
```
container.name     → 容器名称
container.image    → 镜像名称
container.labels   → 容器标签
container.id       → 容器ID
```

---

## 6. 🔄 数据转换处理器


### 6.1 字段类型转换


**🔸 数据类型转换需求**
```
原始日志："status_code": "200"    (字符串)
转换后：  "status_code": 200      (数字)

好处：数字类型可以进行数学计算和范围查询
```

**📝 转换配置**
```yaml
processors:
  - convert:
      fields:
        - {from: "status_code", to: "status_code", type: "integer"}
        - {from: "response_time", to: "response_time", type: "float"}
        - {from: "is_success", to: "is_success", type: "boolean"}
      ignore_missing: true
```

### 6.2 字符串处理


**🔸 字符串分割处理**
```yaml
processors:
  - dissect:
      tokenizer: "%{ip} %{method} %{url} %{status}"
      field: "message"
      target_prefix: ""
```

**💭 处理效果演示**
```
原始数据：
message: "192.168.1.100 GET /api/users 200"

处理后：
ip: "192.168.1.100"
method: "GET" 
url: "/api/users"
status: "200"
```

---

## 7. 🛠️ 实战配置案例


### 7.1 Web服务器日志处理


**🎯 需求场景**
> 处理Nginx访问日志，提取关键信息，添加环境标识，过滤错误请求

```yaml
# 完整的Web日志处理配置
processors:
  # 1. 解析日志格式
  - dissect:
      tokenizer: '%{ip} - - [%{timestamp}] "%{method} %{url} %{protocol}" %{status} %{size}'
      field: "message"
      target_prefix: ""
      
  # 2. 时间戳处理
  - timestamp:
      field: timestamp
      layouts:
        - '02/Jan/2006:15:04:05 -0700'
        
  # 3. 数据类型转换  
  - convert:
      fields:
        - {from: "status", to: "status_code", type: "integer"}
        - {from: "size", to: "response_size", type: "integer"}
        
  # 4. 添加环境信息
  - add_fields:
      fields:
        service: "nginx"
        environment: "production"
        log_type: "access"
        
  # 5. 错误请求标记
  - if:
      range:
        status_code:
          gte: 400
    then:
      - add_fields:
          fields:
            is_error: true
            alert_needed: true
            
  # 6. 删除原始消息
  - drop_fields:
      fields: ["message", "timestamp"]
```

### 7.2 应用日志处理


**🎯 Java应用日志结构化**
```yaml
processors:
  # 1. 提取日志级别和类名
  - grok:
      field: message
      patterns:
        - '%{TIMESTAMP_ISO8601:timestamp} \[%{DATA:thread}\] %{LOGLEVEL:level} %{DATA:logger} - %{GREEDYDATA:msg}'
        
  # 2. 错误级别处理
  - if:
      or:
        - equals:
            level: "ERROR"
        - equals:
            level: "WARN"  
    then:
      - add_fields:
          fields:
            needs_attention: true
            
  # 3. 添加应用标识
  - add_fields:
      fields:
        application: "user-service"
        version: "1.2.3"
        
  # 4. 主机信息
  - add_host_metadata: ~
```

### 7.3 处理器执行顺序


**⚠️ 重要提醒**
```
处理器按配置顺序依次执行，顺序很重要！

正确顺序：
1. 先解析/分割字段
2. 再进行类型转换  
3. 然后添加额外字段
4. 最后删除不需要的字段

错误顺序：
1. 先删除字段
2. 再尝试解析 → ❌ 字段已经不存在了！
```

---

## 8. 📋 核心要点总结


### 8.1 必须掌握的核心概念


```
🔸 处理器作用：在数据传输前进行加工处理
🔸 基础操作：添加字段、删除字段、重命名字段、类型转换
🔸 条件判断：根据条件选择性执行处理器
🔸 时间处理：标准化时间格式，便于查询分析
🔸 系统信息：自动添加主机、容器等环境信息
🔸 执行顺序：处理器按配置顺序依次执行
```

### 8.2 实用配置技巧


**💡 配置最佳实践**
```
✅ 合理使用条件判断，避免无效处理
✅ 优先进行字段解析，再做类型转换
✅ 及时删除敏感信息和无用字段
✅ 添加环境标识，便于后续过滤
✅ 使用ignore_missing避免字段缺失报错
```

**🔧 常见问题解决**
```
问题1：字段不存在导致处理失败
解决：添加 ignore_missing: true

问题2：正则表达式匹配失败
解决：使用在线工具测试正则表达式

问题3：时间格式解析错误
解决：参考Go语言时间格式，使用test验证

问题4：处理器顺序错误
解决：先解析，再转换，后删除
```

### 8.3 选择指导


**🎯 处理器选择指南**

| **需求** | **推荐处理器** | **使用场景** |
|---------|---------------|-------------|
| `结构化日志` | `dissect/grok` | `文本日志解析` |
| `数据清洗` | `drop_fields` | `删除敏感信息` |
| `信息补充` | `add_fields` | `添加环境标识` |
| `类型转换` | `convert` | `字符串转数字` |
| `条件处理` | `if/when` | `分类处理` |
| `时间统一` | `timestamp` | `时间格式标准化` |

**💭 核心记忆**
> 处理器是Filebeat的数据加工车间：
> - 解析器把原始日志"切菜"（分解字段）
> - 转换器把数据"调味"（类型转换）  
> - 添加器给数据"贴标签"（环境信息）
> - 删除器把垃圾"清理"（敏感字段）
> - 条件器是"质检员"（选择性处理）

记住：**先解析，再转换，后清理**的处理顺序，就能配置出高效的数据处理流水线！