---
title: 5、条件输出与路由
---
## 📚 目录

1. [条件输出基本概念](#1-条件输出基本概念)
2. [条件语法与表达式](#2-条件语法与表达式)
3. [多目标输出配置](#3-多目标输出配置)
4. [输出路由策略](#4-输出路由策略)
5. [动态输出选择](#5-动态输出选择)
6. [负载分发策略](#6-负载分发策略)
7. [实际应用场景](#7-实际应用场景)
8. [核心要点总结](#8-核心要点总结)

---

## 1. 🎯 条件输出基本概念


### 1.1 什么是条件输出


**🔸 通俗理解**
```
想象你是一个邮递员，需要把不同类型的信件送到不同的地方：
- 普通信件 → 送到普通邮筒
- 紧急信件 → 送到快递公司  
- 广告传单 → 送到回收站

Filebeat的条件输出就像这样，根据日志内容的不同特征，
把它们发送到不同的目标地址（Elasticsearch、Logstash、Kafka等）
```

**📋 核心定义**
- **条件输出**：根据日志内容、字段值或其他条件，决定将数据发送到哪个输出目标
- **路由功能**：智能分发，让不同类型的日志去到最合适的地方
- **动态选择**：运行时根据实际数据内容来决定输出目标

### 1.2 为什么需要条件输出


**🤔 实际场景需求**
```
企业日志处理现状：
┌─────────────────┐    ┌─────────────────┐
│   应用服务器     │    │    Web服务器     │
│  - 业务日志      │    │  - 访问日志      │  
│  - 错误日志      │    │  - 错误日志      │
│  - 性能日志      │    │  - 安全日志      │
└─────────────────┘    └─────────────────┘
         │                       │
         └───────┬───────────────┘
                 │
         ┌─────────────────┐
         │    Filebeat     │ ← 所有日志混在一起
         └─────────────────┘
                 │
                 ▼
        需要分别发送到不同地方！
```

**🎯 条件输出解决的问题**
- **日志分类存储**：错误日志发告警系统，访问日志发分析系统
- **性能优化**：重要日志走快速通道，普通日志走标准通道  
- **成本控制**：热数据发SSD存储，冷数据发便宜存储
- **安全合规**：敏感日志发安全审计系统，普通日志发通用系统

### 1.3 条件输出的工作流程


**🔄 处理流程图示**
```
日志收集 → 字段解析 → 条件判断 → 路由分发 → 目标输出

详细流程：
┌──────────┐  ┌──────────┐  ┌──────────┐  ┌──────────┐
│ 原始日志  │→│ 字段提取  │→│ 条件匹配  │→│ 选择输出  │
└──────────┘  └──────────┘  └──────────┘  └──────────┘
      │            │            │            │
      │            │            │            ▼
      │            │            │      ┌──────────┐
      │            │            │      │Elasticsearch│
      │            │            │      └──────────┘
      │            │            │            
      │            │            │      ┌──────────┐
      │            │            └─────▶│ Logstash │
      │            │                   └──────────┘
      │            │                        
      │            │                   ┌──────────┐
      │            └──────────────────▶│  Kafka   │
      │                               └──────────┘
      │
示例：ERROR级别日志 → 告警系统
     INFO级别日志  → 存储系统
```

---

## 2. 📝 条件语法与表达式


### 2.1 基本条件语法


**🔸 条件表达式结构**
```yaml
# 基本语法结构
when:
  <条件表达式>

# 常用条件操作符
equals    # 等于
not:      # 不等于  
contains  # 包含
regexp    # 正则匹配
range     # 范围匹配
and       # 逻辑与
or        # 逻辑或
```

**💡 简单条件示例**
```yaml
# 示例1：根据日志级别路由
output.elasticsearch:
  hosts: ["localhost:9200"]
  when.equals:
    log.level: "ERROR"

# 示例2：根据文件路径路由  
output.logstash:
  hosts: ["localhost:5044"]
  when.contains:
    log.file.path: "/var/log/nginx"
```

### 2.2 字段条件判断


**🔍 常用字段条件**
```yaml
# 1. 日志级别条件
when.equals:
  log.level: "ERROR"

# 2. 服务名称条件
when.contains:
  service.name: "web-server"

# 3. 主机名条件
when.regexp:
  host.hostname: "prod-.*"

# 4. 文件路径条件
when.contains:
  log.file.path: "/var/log/application"
```

**📊 复杂条件组合**
```yaml
# AND条件：同时满足多个条件
when.and:
  - equals:
      log.level: "ERROR"
  - contains:
      service.name: "payment"

# OR条件：满足任一条件
when.or:
  - equals:
      log.level: "ERROR"
  - equals:
      log.level: "WARN"

# NOT条件：排除某些条件
when.not:
  contains:
    message: "debug"
```

### 2.3 高级条件表达式


**🎯 范围条件**
```yaml
# 数值范围判断
when.range:
  response_time:
    gte: 100    # 大于等于100ms
    lt: 1000    # 小于1000ms

# 时间范围判断
when.range:
  "@timestamp":
    gte: "2024-01-01T00:00:00Z"
```

**🔍 正则表达式条件**
```yaml
# IP地址匹配
when.regexp:
  client_ip: "192\.168\..*"

# URL路径匹配
when.regexp:
  request_uri: "/api/v[12]/.*"

# 错误代码匹配
when.regexp:
  status_code: "[45][0-9][0-9]"
```

---

## 3. 🎯 多目标输出配置


### 3.1 多输出基本配置


**🔸 配置结构说明**
```yaml
# Filebeat支持同时配置多个输出，但只能激活一个主输出
# 通过条件可以实现"伪多输出"效果

# 方式1：使用Logstash作为中转（推荐）
output.logstash:
  hosts: ["localhost:5044"]

# 方式2：使用多个Filebeat实例
# 方式3：使用输出条件实现智能路由
```

**⚠️ 重要提醒**
> Filebeat本身**不支持同时向多个不同类型的输出**发送数据，
> 但我们可以通过巧妙的配置实现类似效果！

### 3.2 通过Logstash实现多输出


**🔧 架构设计**
```
┌─────────────┐  ┌──────────────┐  ┌─────────────────┐
│  Filebeat   │─▶│  Logstash    │─▶│  Elasticsearch  │
│             │  │ (路由中心)    │  └─────────────────┘
│             │  │              │  ┌─────────────────┐
│             │  │              │─▶│     Kafka       │
│             │  │              │  └─────────────────┘
│             │  │              │  ┌─────────────────┐
│             │  │              │─▶│   File Output   │
└─────────────┘  └──────────────┘  └─────────────────┘
```

**📝 Filebeat配置**
```yaml
# filebeat.yml - 所有数据发送到Logstash
filebeat.inputs:
- type: log
  paths:
    - /var/log/app/*.log
  fields:
    service: "web-app"
    environment: "production"

output.logstash:
  hosts: ["localhost:5044"]
```

**🔧 Logstash路由配置**
```ruby
# logstash.conf - 根据条件路由到不同输出
input {
  beats {
    port => 5044
  }
}

filter {
  # 解析日志级别
  grok {
    match => { "message" => "%{LOGLEVEL:log_level}" }
  }
}

output {
  # 错误日志发送到告警系统
  if [log_level] == "ERROR" {
    elasticsearch {
      hosts => ["alarm-es:9200"]
      index => "error-logs-%{+YYYY.MM.dd}"
    }
  }
  
  # 普通日志发送到存储系统
  else {
    elasticsearch {
      hosts => ["storage-es:9200"] 
      index => "app-logs-%{+YYYY.MM.dd}"
    }
  }
  
  # 同时发送到Kafka供实时分析
  kafka {
    topic_id => "log-stream"
    bootstrap_servers => "kafka:9092"
  }
}
```

### 3.3 使用多Filebeat实例


**🔄 多实例部署策略**
```bash
# 部署方案：不同类型日志用不同Filebeat实例

# 实例1：处理应用日志
./filebeat -c filebeat-app.yml

# 实例2：处理访问日志  
./filebeat -c filebeat-access.yml

# 实例3：处理系统日志
./filebeat -c filebeat-system.yml
```

**📁 配置文件示例**
```yaml
# filebeat-app.yml - 应用日志专用
filebeat.inputs:
- type: log
  paths:
    - /var/log/app/*.log
  fields:
    log_type: "application"

output.elasticsearch:
  hosts: ["app-es:9200"]
  index: "app-logs-%{+yyyy.MM.dd}"

---
# filebeat-access.yml - 访问日志专用  
filebeat.inputs:
- type: log
  paths:
    - /var/log/nginx/access.log
  fields:
    log_type: "access"

output.kafka:
  hosts: ["kafka:9092"]
  topic: "access-logs"
```

---

## 4. 🗺️ 输出路由策略


### 4.1 基于日志级别的路由


**🚦 级别路由策略**
```yaml
# 策略说明：
# ERROR/FATAL → 告警系统（需要立即处理）
# WARN       → 监控系统（需要关注）  
# INFO/DEBUG → 存储系统（归档查询）

filebeat.inputs:
- type: log
  paths:
    - /var/log/app/*.log
  multiline:
    pattern: '^\d{4}-\d{2}-\d{2}'
    negate: true
    match: after

processors:
- add_fields:
    target: ""
    fields:
      service.name: "payment-service"

# 条件输出配置
output.logstash:
  hosts: ["localhost:5044"]
```

**🔧 对应Logstash配置**
```ruby
filter {
  # 提取日志级别
  grok {
    match => { 
      "message" => "%{TIMESTAMP_ISO8601:timestamp} \[%{LOGLEVEL:log_level}\]" 
    }
  }
  
  # 添加路由标签
  if [log_level] in ["ERROR", "FATAL"] {
    mutate { add_tag => ["alert"] }
  } else if [log_level] == "WARN" {
    mutate { add_tag => ["monitor"] }
  } else {
    mutate { add_tag => ["storage"] }
  }
}

output {
  if "alert" in [tags] {
    elasticsearch {
      hosts => ["alert-es:9200"]
      index => "alerts-%{+YYYY.MM.dd}"
    }
    # 同时发送邮件告警
    email {
      to => ["admin@company.com"]
      subject => "应用错误告警"
    }
  }
  
  if "monitor" in [tags] {
    elasticsearch {
      hosts => ["monitor-es:9200"] 
      index => "warnings-%{+YYYY.MM.dd}"
    }
  }
  
  if "storage" in [tags] {
    elasticsearch {
      hosts => ["storage-es:9200"]
      index => "logs-%{+YYYY.MM.dd}"
    }
  }
}
```

### 4.2 基于应用服务的路由


**🏢 服务路由策略**
```yaml
# 多服务日志路由配置
filebeat.inputs:
# 支付服务日志
- type: log
  paths:
    - /var/log/payment/*.log
  fields:
    service.name: "payment"
    service.type: "critical"

# 用户服务日志  
- type: log
  paths:
    - /var/log/user/*.log
  fields:
    service.name: "user"
    service.type: "important"

# 推荐服务日志
- type: log  
  paths:
    - /var/log/recommend/*.log
  fields:
    service.name: "recommend"
    service.type: "normal"

processors:
- add_docker_metadata: ~
- add_host_metadata: ~

output.logstash:
  hosts: ["logstash:5044"]
```

**🎯 服务级别路由逻辑**
```ruby
output {
  # 关键服务：高可用集群
  if [fields][service][type] == "critical" {
    elasticsearch {
      hosts => ["critical-es-1:9200", "critical-es-2:9200", "critical-es-3:9200"]
      index => "%{[fields][service][name]}-%{+YYYY.MM.dd}"
    }
  }
  
  # 重要服务：标准集群
  else if [fields][service][type] == "important" {
    elasticsearch {
      hosts => ["important-es-1:9200", "important-es-2:9200"]
      index => "%{[fields][service][name]}-%{+YYYY.MM.dd}"
    }
  }
  
  # 普通服务：单节点
  else {
    elasticsearch {
      hosts => ["normal-es:9200"]
      index => "%{[fields][service][name]}-%{+YYYY.MM.dd}"
    }
  }
}
```

### 4.3 基于时间的路由策略


**⏰ 时间路由应用场景**
```yaml
# 场景：工作时间vs非工作时间的不同处理策略
# 工作时间：实时处理，立即告警
# 非工作时间：批量处理，延迟告警

processors:
- script:
    lang: javascript
    source: >
      function process(event) {
        var timestamp = new Date(event.Get("@timestamp"));
        var hour = timestamp.getHours();
        var day = timestamp.getDay();
        
        // 工作时间判断 (周一到周五 9:00-18:00)
        if (day >= 1 && day <= 5 && hour >= 9 && hour < 18) {
          event.Put("time_type", "work_hours");
        } else {
          event.Put("time_type", "off_hours");  
        }
      }
```

**🔧 时间路由配置**
```ruby
output {
  # 工作时间：实时处理
  if [time_type] == "work_hours" {
    if [log_level] == "ERROR" {
      # 立即发送告警
      http {
        url => "http://alert-system/immediate"
        http_method => "post"
      }
    }
    
    elasticsearch {
      hosts => ["realtime-es:9200"]
      index => "realtime-%{+YYYY.MM.dd.HH}"
    }
  }
  
  # 非工作时间：批量处理
  else {
    kafka {
      topic_id => "batch-processing"
      bootstrap_servers => "kafka:9092"
    }
  }
}
```

---

## 5. ⚡ 动态输出选择


### 5.1 基于字段值的动态路由


**🎯 动态索引名称**
```yaml
# Filebeat配置：添加动态字段
filebeat.inputs:
- type: log
  paths:
    - /var/log/apps/*/app.log
  processors:
  - dissect:
      tokenizer: "/var/log/apps/%{app_name}/app.log"
      field: "log.file.path"
  - add_fields:
      target: ""
      fields:
        index_prefix: "%{[app_name]}"

output.elasticsearch:
  hosts: ["localhost:9200"]
  # 动态索引名：根据应用名称创建不同索引
  index: "%{[index_prefix]}-logs-%{+yyyy.MM.dd}"
```

**📊 实际效果展示**
```
日志文件路径          → 解析出的app_name → 生成的索引名
/var/log/apps/web/app.log      → web         → web-logs-2024.09.21
/var/log/apps/api/app.log      → api         → api-logs-2024.09.21  
/var/log/apps/worker/app.log   → worker      → worker-logs-2024.09.21
```

### 5.2 基于内容的智能路由


**🧠 内容分析路由**
```yaml
processors:
# 1. 提取关键信息
- grok:
    field: message
    patterns:
      - '%{TIMESTAMP_ISO8601:log_timestamp} \[%{LOGLEVEL:log_level}\] %{GREEDYDATA:log_message}'

# 2. 分析错误类型      
- script:
    lang: javascript
    source: >
      function process(event) {
        var message = event.Get("log_message");
        
        if (message.includes("OutOfMemoryError")) {
          event.Put("error_type", "memory");
          event.Put("priority", "high");
        } else if (message.includes("ConnectException")) {
          event.Put("error_type", "network");
          event.Put("priority", "medium");
        } else if (message.includes("SQLException")) {
          event.Put("error_type", "database");
          event.Put("priority", "high");
        } else {
          event.Put("error_type", "general");
          event.Put("priority", "low");
        }
      }

# 3. 添加路由标签
- add_tags:
    tags: ["analyzed"]
```

**🔧 智能路由输出**
```ruby
output {
  # 高优先级错误：立即处理
  if [priority] == "high" {
    elasticsearch {
      hosts => ["urgent-es:9200"]
      index => "urgent-%{error_type}-%{+YYYY.MM.dd}"
    }
    
    # 同时发送到告警系统
    http {
      url => "http://alert-system/urgent"
      http_method => "post"
      mapping => {
        "error_type" => "%{error_type}"
        "message" => "%{log_message}"
        "timestamp" => "%{@timestamp}"
      }
    }
  }
  
  # 中等优先级：延迟处理
  else if [priority] == "medium" {
    kafka {
      topic_id => "medium-priority"
      bootstrap_servers => "kafka:9092"
    }
  }
  
  # 低优先级：批量处理
  else {
    elasticsearch {
      hosts => ["batch-es:9200"] 
      index => "batch-logs-%{+YYYY.MM.dd}"
    }
  }
}
```

### 5.3 基于负载的动态选择


**⚖️ 负载均衡路由**
```yaml
# 配置多个Elasticsearch集群
output.elasticsearch:
  hosts: 
    - "es-cluster-1:9200"
    - "es-cluster-2:9200" 
    - "es-cluster-3:9200"
  
  # 负载均衡策略
  loadbalance: true
  
  # 工作节点选择
  worker: 2
  
  # 批量大小优化
  bulk_max_size: 1000
  
  # 超时设置
  timeout: 30s
```

**📈 负载分发策略**
```ruby
# 在Logstash中实现更复杂的负载分发
output {
  # 根据哈希值分发到不同集群
  if [hash_value] % 3 == 0 {
    elasticsearch {
      hosts => ["es-cluster-1:9200"]
      index => "logs-%{+YYYY.MM.dd}"
    }
  } else if [hash_value] % 3 == 1 {
    elasticsearch {
      hosts => ["es-cluster-2:9200"]
      index => "logs-%{+YYYY.MM.dd}"
    }
  } else {
    elasticsearch {
      hosts => ["es-cluster-3:9200"]
      index => "logs-%{+YYYY.MM.dd}"
    }
  }
}
```

---

## 6. 🎪 负载分发策略


### 6.1 轮询分发策略


**🔄 轮询算法说明**
```
轮询分发就像排队叫号，按顺序依次分配：

第1条日志 → 服务器A
第2条日志 → 服务器B  
第3条日志 → 服务器C
第4条日志 → 服务器A (重新开始)
第5条日志 → 服务器B
...依此类推
```

**⚙️ 配置实现**
```yaml
output.elasticsearch:
  hosts: 
    - "es-node-1:9200"
    - "es-node-2:9200"
    - "es-node-3:9200"
  
  # 启用负载均衡（默认轮询）
  loadbalance: true
  
  # 设置工作线程数
  worker: 3
  
  # 连接参数优化
  template.settings:
    index.number_of_shards: 3
    index.number_of_replicas: 1
```

### 6.2 权重分发策略


**⚖️ 权重分配原理**
```
根据服务器性能分配不同权重：

高性能服务器 → 权重3 (处理3份数据)
中等服务器   → 权重2 (处理2份数据)  
普通服务器   → 权重1 (处理1份数据)

总比例：3:2:1
```

**🔧 通过Logstash实现权重分发**
```ruby
filter {
  # 生成随机数用于权重分发
  ruby {
    code => "
      # 生成1-6的随机数实现3:2:1权重
      rand_num = Random.rand(1..6)
      if rand_num <= 3
        event.set('target_cluster', 'high_performance')
      elsif rand_num <= 5  
        event.set('target_cluster', 'medium_performance')
      else
        event.set('target_cluster', 'normal_performance')
      end
    "
  }
}

output {
  if [target_cluster] == "high_performance" {
    elasticsearch {
      hosts => ["high-perf-es-1:9200", "high-perf-es-2:9200"]
      index => "logs-%{+YYYY.MM.dd}"
    }
  } else if [target_cluster] == "medium_performance" {
    elasticsearch {
      hosts => ["medium-es:9200"]
      index => "logs-%{+YYYY.MM.dd}"
    }
  } else {
    elasticsearch {
      hosts => ["normal-es:9200"]
      index => "logs-%{+YYYY.MM.dd}"
    }
  }
}
```

### 6.3 基于响应时间的智能分发


**⚡ 智能分发原理**
```yaml
# 健康检查配置
output.elasticsearch:
  hosts: 
    - "es-fast:9200"
    - "es-medium:9200" 
    - "es-slow:9200"
  
  # 启用健康检查
  template.enabled: true
  
  # 超时设置
  timeout: 10s
  
  # 重试配置
  max_retries: 3
  backoff.init: 1s
  backoff.max: 60s
```

**📊 监控和自动切换**
```bash
# 使用脚本监控Elasticsearch响应时间
#!/bin/bash

check_es_health() {
  local host=$1
  local response_time=$(curl -w "%{time_total}" -s -o /dev/null "$host/_cluster/health")
  echo "$host: ${response_time}s"
  return $(echo "$response_time > 0.5" | bc)
}

# 检查所有节点
for host in es-fast:9200 es-medium:9200 es-slow:9200; do
  if check_es_health $host; then
    echo "节点 $host 响应较慢，考虑降低权重"
  fi
done
```

---

## 7. 🏆 实际应用场景


### 7.1 电商平台日志路由方案


**🛒 业务场景分析**
```
电商平台日志类型：
┌─────────────────┐ ┌─────────────────┐ ┌─────────────────┐
│   订单服务日志    │ │   支付服务日志    │ │   用户服务日志    │
│  - 下单记录      │ │  - 支付记录      │ │  - 登录记录      │
│  - 库存变更      │ │  - 交易异常      │ │  - 行为轨迹      │
│  - 订单异常      │ │  - 风控告警      │ │  - 账户异常      │
└─────────────────┘ └─────────────────┘ └─────────────────┘
         │                   │                   │
         └─────────┬─────────┘─────────┬─────────┘
                   │                   │
              ┌─────────────────────────────────────┐
              │          路由策略                    │
              │  • 支付异常 → 立即告警              │
              │  • 订单记录 → 业务分析系统          │  
              │  • 用户行为 → 推荐系统              │
              │  • 系统错误 → 运维监控              │
              └─────────────────────────────────────┘
```

**📝 配置实现**
```yaml
# filebeat.yml
filebeat.inputs:
# 订单服务
- type: log
  paths:
    - /var/log/order/*.log
  fields:
    service: "order"
    business_type: "transaction"

# 支付服务  
- type: log
  paths:
    - /var/log/payment/*.log
  fields:
    service: "payment"
    business_type: "finance"

# 用户服务
- type: log
  paths:
    - /var/log/user/*.log  
  fields:
    service: "user"
    business_type: "behavior"

processors:
- add_host_metadata: ~
- add_docker_metadata: ~

output.logstash:
  hosts: ["logstash:5044"]
```

**🎯 Logstash路由配置**
```ruby
filter {
  # 解析日志级别和内容
  grok {
    match => { 
      "message" => "%{TIMESTAMP_ISO8601:timestamp} \[%{LOGLEVEL:level}\] %{GREEDYDATA:content}" 
    }
  }
  
  # 业务规则判断
  if [fields][service] == "payment" and [level] == "ERROR" {
    mutate { add_tag => ["finance_alert"] }
  }
  
  if [content] =~ /订单创建成功/ {
    mutate { add_tag => ["business_analysis"] }
  }
  
  if [fields][service] == "user" and [content] =~ /用户访问|点击|浏览/ {
    mutate { add_tag => ["user_behavior"] }
  }
}

output {
  # 金融告警：立即处理
  if "finance_alert" in [tags] {
    elasticsearch {
      hosts => ["alert-es:9200"]
      index => "finance-alerts-%{+YYYY.MM.dd}"
    }
    
    # 发送到告警系统
    http {
      url => "http://alert-system/finance"
      http_method => "post"
    }
  }
  
  # 业务分析：发送到分析系统
  if "business_analysis" in [tags] {
    kafka {
      topic_id => "business-analysis"
      bootstrap_servers => "kafka:9092"
    }
  }
  
  # 用户行为：发送到推荐系统
  if "user_behavior" in [tags] {
    elasticsearch {
      hosts => ["behavior-es:9200"]
      index => "user-behavior-%{+YYYY.MM.dd}"
    }
  }
  
  # 默认：所有日志都保存到通用存储
  elasticsearch {
    hosts => ["general-es:9200"]
    index => "%{[fields][service]}-logs-%{+YYYY.MM.dd}"
  }
}
```

### 7.2 多环境日志路由


**🌍 环境隔离策略**
```
开发环境(dev)   → 开发集群 (资源有限，保留7天)
测试环境(test)  → 测试集群 (中等资源，保留30天)  
生产环境(prod)  → 生产集群 (高可用，保留1年)
```

**⚙️ 环境路由配置**
```yaml
# 多环境Filebeat配置
filebeat.inputs:
- type: log
  paths:
    - /var/log/app/*.log
  fields:
    environment: "${ENV:dev}"  # 从环境变量读取
    app_name: "${APP_NAME:unknown}"

processors:
- add_fields:
    target: ""
    fields:
      cluster_config: >
        {% if fields.environment == "prod" %}
          production
        {% elif fields.environment == "test" %} 
          testing
        {% else %}
          development
        {% endif %}

output.logstash:
  hosts: ["logstash-${ENV:dev}:5044"]
```

**🏗️ 对应的基础设施配置**
```ruby
# logstash-prod.conf (生产环境)
output {
  elasticsearch {
    hosts => ["prod-es-1:9200", "prod-es-2:9200", "prod-es-3:9200"]
    index => "prod-%{[fields][app_name]}-%{+YYYY.MM.dd}"
    
    # 生产环境特殊配置
    template_overwrite => true
    template => "/etc/logstash/templates/production.json"
  }
}

# logstash-test.conf (测试环境)  
output {
  elasticsearch {
    hosts => ["test-es:9200"]
    index => "test-%{[fields][app_name]}-%{+YYYY.MM.dd}"
  }
}

# logstash-dev.conf (开发环境)
output {
  elasticsearch {
    hosts => ["dev-es:9200"]
    index => "dev-%{[fields][app_name]}-%{+YYYY.MM.dd}"
  }
}
```

### 7.3 基于地理位置的分发


**🌏 地理分布式部署**
```
亚洲数据中心(asia)     → asia-es-cluster
欧洲数据中心(europe)   → europe-es-cluster  
美洲数据中心(america)  → america-es-cluster
```

**📍 地理位置路由**
```yaml
processors:
- add_fields:
    target: ""
    fields:
      datacenter: >
        {% if host.hostname contains "asia" %}
          asia
        {% elif host.hostname contains "europe" %}
          europe  
        {% elif host.hostname contains "america" %}
          america
        {% else %}
          unknown
        {% endif %}

# 根据数据中心选择输出
output.elasticsearch:
  hosts: 
    - "${DATACENTER_ES_HOST:localhost:9200}"
  index: "%{[datacenter]}-%{[fields][service]}-%{+YYYY.MM.dd}"
```

---

## 8. 📋 核心要点总结


### 8.1 必须掌握的核心概念


```
🔸 条件输出本质：根据日志内容特征智能分发到不同目标
🔸 路由策略：通过逻辑判断实现日志的分类处理
🔸 多输出实现：虽然Filebeat不直接支持，但可通过Logstash中转
🔸 动态选择：运行时根据实际数据内容决定输出目标
🔸 负载分发：在多个目标间均衡分配负载
```

### 8.2 关键理解要点


**🔹 条件输出的价值**
```
提升效率：
- 重要日志优先处理
- 普通日志批量处理
- 减少无效处理开销

降低成本：
- 热数据用快速存储
- 冷数据用便宜存储
- 按需分配资源

增强安全：
- 敏感日志专门处理
- 普通日志常规处理
- 合规要求分类满足
```

**🔹 实现策略选择**
```
简单场景：
→ 使用Filebeat内置条件输出
→ 配置简单，性能好

复杂场景：
→ 使用Logstash作为路由中心
→ 功能强大，灵活性高

超大规模：
→ 使用多Filebeat实例
→ 分布式部署，水平扩展
```

**🔹 常见应用模式**
```
按级别路由：ERROR→告警，INFO→存储
按服务路由：不同服务发送到专门集群
按时间路由：工作时间实时，非工作时间批量
按地域路由：就近处理，减少网络延迟
按业务路由：交易日志→风控，行为日志→推荐
```

### 8.3 实践要点和注意事项


**✅ 最佳实践**
- **性能优化**：合理设置批量大小和超时时间
- **监控告警**：监控各路由目标的健康状态
- **容错设计**：配置重试和备用输出目标
- **测试验证**：在测试环境充分验证路由逻辑

**⚠️ 常见陷阱**
- **过度复杂**：避免过于复杂的条件判断逻辑
- **性能问题**：复杂条件会影响处理性能
- **维护困难**：保持配置的可读性和可维护性
- **监控盲区**：确保所有路由路径都有监控

**🎯 选择指导**
```
项目初期：
- 使用简单的条件输出
- 重点关注功能实现

项目成熟期：
- 考虑使用Logstash路由
- 重点关注性能和稳定性

大规模部署：
- 考虑多实例部署
- 重点关注可扩展性
```

**核心记忆口诀**：
- 条件输出智能分发，根据内容选路径
- 多目标路由提效率，重要普通分优先
- Logstash中转功能强，复杂场景首选项
- 负载分发保性能，监控告警不可缺