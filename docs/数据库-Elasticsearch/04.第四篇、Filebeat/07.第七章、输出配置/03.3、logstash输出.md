---
title: 3、logstash输出
---
## 📚 目录

1. [Logstash输出基础概念](#1-logstash输出基础概念)
2. [output.logstash核心配置](#2-output-logstash核心配置)
3. [连接与负载均衡配置](#3-连接与负载均衡配置)
4. [性能优化配置](#4-性能优化配置)
5. [故障处理与重试机制](#5-故障处理与重试机制)
6. [与Logstash Pipeline配合](#6-与logstash-pipeline配合)
7. [实际应用案例](#7-实际应用案例)
8. [核心要点总结](#8-核心要点总结)

---

## 1. 🔄 Logstash输出基础概念


### 1.1 什么是Logstash输出


**简单理解**：Filebeat就像一个"数据快递员"，而Logstash就像一个"数据处理工厂"

```
数据流向：
日志文件 → Filebeat收集 → 发送给Logstash → Logstash处理 → 存储到目标
        （快递员）    （处理工厂）     （最终仓库）
```

**🔸 为什么要发给Logstash**
- **数据处理**：Logstash能对日志进行复杂的解析、过滤、转换
- **格式转换**：将原始日志转换成结构化数据
- **数据增强**：添加地理位置、时间戳等额外信息
- **多输出支持**：Logstash可以同时发送到多个目标系统

### 1.2 Logstash输出的工作原理


**数据传输过程**：
```
┌─────────────┐    网络传输    ┌─────────────┐
│  Filebeat   │─────────────→ │  Logstash   │
│   (客户端)   │   (beats协议)  │   (服务端)   │
└─────────────┘               └─────────────┘
      ↑                            ↓
   监控文件                    处理并输出
```

**🔹 传输协议特点**
- **Beats协议**：Elastic官方设计的高效传输协议
- **可靠传输**：支持确认机制，保证数据不丢失
- **压缩传输**：减少网络带宽占用
- **批量传输**：提高传输效率

### 1.3 适用场景分析


**✅ 适合使用Logstash输出的场景**
- 需要复杂的日志解析和处理
- 多种数据源需要统一处理
- 需要数据格式转换和增强
- 有多个输出目标的需求

**❌ 不适合的场景**
- 简单的日志收集，直接存储即可
- 对实时性要求极高的场景
- 网络环境不稳定的情况

---

## 2. ⚙️ output.logstash核心配置


### 2.1 基础配置结构


**配置文件位置**：`filebeat.yml`

```yaml
output.logstash:
  # 基础连接配置
  hosts: ["localhost:5044"]
  
  # 可选的高级配置
  enabled: true
  worker: 1
  compression_level: 3
  escape_html: false
```

**🔸 核心参数说明**
- **`hosts`**：Logstash服务器地址列表
- **`enabled`**：是否启用此输出（默认true）
- **`worker`**：并发工作线程数
- **`compression_level`**：压缩级别（0-9，0不压缩）

### 2.2 hosts地址配置详解


**单机配置**：
```yaml
output.logstash:
  hosts: ["192.168.1.100:5044"]
```

**多机配置**：
```yaml
output.logstash:
  hosts: 
    - "logstash-1.company.com:5044"
    - "logstash-2.company.com:5044" 
    - "192.168.1.101:5044"
```

**🔹 地址格式说明**
- **IP地址**：`192.168.1.100:5044`
- **域名**：`logstash.company.com:5044`
- **默认端口**：如果不指定端口，默认使用5044

> **💡 实用提示**：建议使用域名而不是IP地址，便于后期维护和扩展

### 2.3 连接安全配置


**SSL/TLS加密传输**：
```yaml
output.logstash:
  hosts: ["logstash.company.com:5044"]
  
  # SSL配置
  ssl.enabled: true
  ssl.certificate_authorities: ["/etc/filebeat/certs/ca.crt"]
  ssl.certificate: "/etc/filebeat/certs/client.crt"
  ssl.key: "/etc/filebeat/certs/client.key"
  ssl.verification_mode: "strict"
```

**🔒 安全参数说明**
- **`ssl.enabled`**：启用SSL加密
- **`ssl.certificate_authorities`**：CA证书文件
- **`ssl.verification_mode`**：证书验证模式（strict/certificate/none）

---

## 3. ⚖️ 连接与负载均衡配置


### 3.1 负载均衡策略


当配置多个Logstash节点时，Filebeat会自动进行负载均衡

**负载均衡配置**：
```yaml
output.logstash:
  hosts: 
    - "logstash-1.company.com:5044"
    - "logstash-2.company.com:5044"
    - "logstash-3.company.com:5044"
  
  # 负载均衡设置
  loadbalance: true
  worker: 2
```

**🔄 负载均衡工作原理**
```
Filebeat数据流分发：

数据批次1 ────→ Logstash-1
数据批次2 ────→ Logstash-2  
数据批次3 ────→ Logstash-3
数据批次4 ────→ Logstash-1 (循环)
```

### 3.2 连接池配置


**连接管理参数**：
```yaml
output.logstash:
  hosts: ["logstash.company.com:5044"]
  
  # 连接池配置
  worker: 2                    # 工作线程数
  bulk_max_size: 2048         # 批量发送最大事件数
  timeout: 30s                # 连接超时时间
  ttl: 60s                    # 连接生存时间
```

**📊 参数影响分析**

| 参数 | **作用** | **建议值** | **影响** |
|------|----------|------------|----------|
| `worker` | `并发连接数` | `1-4` | `影响吞吐量和资源占用` |
| `bulk_max_size` | `批量大小` | `1024-4096` | `影响传输效率` |
| `timeout` | `超时时间` | `30s-60s` | `影响容错性` |
| `ttl` | `连接生存时间` | `60s-300s` | `影响连接复用` |

### 3.3 故障转移机制


**自动故障转移**：
```yaml
output.logstash:
  hosts: 
    - "logstash-primary.com:5044"     # 主节点
    - "logstash-backup.com:5044"      # 备用节点
  
  # 故障转移配置
  max_retries: 3               # 最大重试次数
  backoff.init: 1s            # 初始退避时间
  backoff.max: 60s            # 最大退避时间
```

**🔄 故障转移流程**
```
连接失败处理流程：

尝试连接主节点 → 失败 → 等待1s → 重试
                ↓
        重试3次仍失败 → 切换到备用节点
                ↓
        备用节点成功 → 继续传输数据
```

---

## 4. 🚀 性能优化配置


### 4.1 管道传输优化


**pipelining配置**：
```yaml
output.logstash:
  hosts: ["logstash.company.com:5044"]
  
  # 管道传输配置
  pipelining: 2               # 管道深度
  bulk_max_size: 2048        # 批量大小
  flush_interval: 1s         # 刷新间隔
```

**🔸 pipelining原理**
```
不启用pipelining（串行）：
发送批次1 → 等待确认 → 发送批次2 → 等待确认

启用pipelining（并行）：  
发送批次1 ──┐
发送批次2 ──┼── 同时进行，提高效率
等待确认1 ──┘
等待确认2 ──┘
```

### 4.2 压缩传输配置


**compression压缩设置**：
```yaml
output.logstash:
  hosts: ["logstash.company.com:5044"]
  
  # 压缩配置
  compression_level: 3        # 压缩级别(0-9)
  compress: true             # 启用压缩
```

**📈 压缩效果对比**

| 压缩级别 | **CPU占用** | **压缩比** | **适用场景** |
|----------|-------------|------------|--------------|
| `0` | `最低` | `无压缩` | `本地网络，CPU敏感` |
| `1-3` | `低` | `30-50%` | `一般网络环境` |
| `6` | `中等` | `60-70%` | `带宽受限环境` |
| `9` | `最高` | `70-80%` | `极限带宽优化` |

### 4.3 批量传输优化


**批量参数调优**：
```yaml
output.logstash:
  hosts: ["logstash.company.com:5044"]
  
  # 批量传输优化
  bulk_max_size: 2048        # 单批最大事件数
  flush_interval: 1s         # 强制刷新间隔
  worker: 2                  # 并发工作线程
```

**⚡ 性能调优建议**
- **高吞吐量场景**：增大`bulk_max_size`到4096-8192
- **低延迟场景**：减小`flush_interval`到500ms
- **网络不稳定**：增加`worker`数量提高并发

---

## 5. 🛡️ 故障处理与重试机制


### 5.1 重试策略配置


**重试机制详解**：
```yaml
output.logstash:
  hosts: ["logstash.company.com:5044"]
  
  # 重试配置
  max_retries: 3             # 最大重试次数
  backoff.init: 1s          # 初始退避时间
  backoff.max: 60s          # 最大退避时间
  backoff.factor: 2         # 退避因子
```

**🔄 退避算法示例**
```
重试时间计算：
第1次重试：1s
第2次重试：1s × 2 = 2s  
第3次重试：2s × 2 = 4s
第4次重试：4s × 2 = 8s (如果超过max_retries则停止)
```

### 5.2 超时与TTL配置


**连接生命周期管理**：
```yaml
output.logstash:
  hosts: ["logstash.company.com:5044"]
  
  # 超时配置
  timeout: 30s              # 网络操作超时
  ttl: 300s                 # 连接生存时间
  
  # 保活配置
  keepalive: 30s            # 保活间隔
```

**🕐 TTL工作机制**
```
连接生命周期：
建立连接 → 使用连接传输数据 → TTL到期 → 关闭连接 → 重新建立

作用：
- 避免长期空闲连接占用资源
- 定期重新建立连接，提高可靠性
- 适应网络环境变化
```

### 5.3 错误处理策略


**错误处理配置**：
```yaml
output.logstash:
  hosts: ["logstash.company.com:5044"]
  
  # 错误处理
  max_retries: 3
  
  # 日志记录
  logging.level: info
  logging.to_files: true
```

**⚠️ 常见错误处理**
- **连接超时**：增加`timeout`时间，检查网络连接
- **认证失败**：检查SSL证书配置
- **内存不足**：减少`bulk_max_size`或增加系统内存
- **版本不兼容**：确保Filebeat和Logstash版本匹配

---

## 6. 🔗 与Logstash Pipeline配合


### 6.1 Logstash端配置


**Logstash pipeline配置**：
```ruby
# logstash.conf
input {
  beats {
    port => 5044              # 监听端口
    host => "0.0.0.0"        # 监听地址
    
    # SSL配置(可选)
    ssl => true
    ssl_certificate => "/etc/logstash/certs/server.crt"
    ssl_key => "/etc/logstash/certs/server.key"
  }
}

filter {
  # 数据处理逻辑
  if [fields][log_type] == "nginx" {
    grok {
      match => { "message" => "%{NGINXACCESS}" }
    }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "filebeat-%{+YYYY.MM.dd}"
  }
}
```

### 6.2 字段传递与标签


**Filebeat字段配置**：
```yaml
filebeat.inputs:
- type: log
  paths:
    - /var/log/nginx/access.log
  fields:
    log_type: nginx          # 自定义字段
    environment: production
  fields_under_root: false   # 字段放在fields节点下
  tags: ["nginx", "web"]     # 添加标签

output.logstash:
  hosts: ["logstash.company.com:5044"]
```

**📤 传输到Logstash的数据结构**：
```json
{
  "@timestamp": "2025-09-21T14:30:00.000Z",
  "message": "192.168.1.1 - - [21/Sep/2025:14:30:00 +0000] ...",
  "fields": {
    "log_type": "nginx",
    "environment": "production"
  },
  "tags": ["nginx", "web"],
  "agent": {
    "name": "filebeat",
    "version": "8.10.0"
  }
}
```

### 6.3 性能匹配调优


**协调Filebeat和Logstash性能**：

```yaml
# Filebeat配置
output.logstash:
  hosts: ["logstash.company.com:5044"]
  worker: 2                  # 与Logstash worker数量匹配
  bulk_max_size: 2048       # 与Logstash batch size匹配
```

```ruby
# Logstash配置
input {
  beats {
    port => 5044
  }
}

# pipeline.yml中配置
pipeline.workers: 4          # 处理线程数
pipeline.batch.size: 2048    # 与Filebeat bulk_max_size匹配
```

---

## 7. 🎯 实际应用案例


### 7.1 Web服务器日志收集


**场景描述**：收集多台Web服务器的Nginx日志，发送到Logstash进行解析

**Filebeat配置**：
```yaml
filebeat.inputs:
- type: log
  paths:
    - /var/log/nginx/access.log
    - /var/log/nginx/error.log
  fields:
    server_role: webserver
    datacenter: us-east-1
  multiline.pattern: '^\d{4}/\d{2}/\d{2}'
  multiline.negate: true
  multiline.match: after

output.logstash:
  hosts: 
    - "logstash-1.company.com:5044"
    - "logstash-2.company.com:5044"
  loadbalance: true
  compression_level: 3
  
  # 重试配置
  max_retries: 3
  backoff.init: 2s
  backoff.max: 30s

processors:
- add_host_metadata:
    when.not.contains.tags: forwarded
```

### 7.2 高可用集群配置


**多数据中心场景**：
```yaml
output.logstash:
  hosts:
    # 主数据中心
    - "logstash-primary-1.dc1.com:5044"
    - "logstash-primary-2.dc1.com:5044"
    # 备用数据中心  
    - "logstash-backup-1.dc2.com:5044"
    - "logstash-backup-2.dc2.com:5044"
  
  # 高可用配置
  worker: 3
  bulk_max_size: 1024        # 适中的批量大小
  timeout: 45s
  max_retries: 5
  
  # SSL安全传输
  ssl.enabled: true
  ssl.certificate_authorities: ["/etc/filebeat/ca.crt"]
```

### 7.3 性能优化案例


**高吞吐量优化配置**：
```yaml
output.logstash:
  hosts: ["logstash-cluster.com:5044"]
  
  # 性能优化
  worker: 4                  # 增加并发
  bulk_max_size: 4096       # 大批量传输
  pipelining: 3             # 启用管道
  compression_level: 1      # 轻度压缩，平衡CPU和网络
  flush_interval: 2s        # 适当延迟，提高批量效果
  
  # 连接优化
  ttl: 300s                 # 长连接时间
  keepalive: 60s           # 保活间隔
```

---

## 8. 📋 核心要点总结


### 8.1 必须掌握的核心概念


```
🔸 Logstash输出：Filebeat将数据发送给Logstash进行进一步处理
🔸 hosts配置：支持多个Logstash节点，自动负载均衡
🔸 可靠传输：通过Beats协议保证数据传输的可靠性
🔸 性能优化：批量传输、压缩、管道等机制提高效率
🔸 故障处理：重试机制、超时设置、故障转移保证稳定性
```

### 8.2 关键配置参数


**🔹 基础连接配置**
```yaml
必备参数：
- hosts: Logstash服务器地址
- enabled: 是否启用输出
- worker: 并发工作线程数

安全参数：
- ssl.enabled: 启用SSL加密
- ssl.certificate_authorities: CA证书
- ssl.verification_mode: 证书验证模式
```

**🔹 性能调优参数**
```yaml
传输优化：
- bulk_max_size: 批量大小(建议1024-4096)
- compression_level: 压缩级别(建议1-3)
- pipelining: 管道深度(建议1-3)

连接管理：
- timeout: 超时时间(建议30s-60s)  
- ttl: 连接生存时间(建议60s-300s)
- keepalive: 保活间隔(建议30s-60s)
```

**🔹 容错处理参数**
```yaml
重试机制：
- max_retries: 最大重试次数(建议3-5)
- backoff.init: 初始退避时间(建议1s-2s)
- backoff.max: 最大退避时间(建议30s-60s)
```

### 8.3 实践应用要点


**✅ 最佳实践**
- **多节点部署**：配置多个Logstash节点实现高可用
- **性能匹配**：Filebeat和Logstash的批量参数要匹配
- **监控告警**：监控连接状态和传输性能
- **安全传输**：生产环境必须启用SSL加密

**❌ 常见错误**
- **单点故障**：只配置一个Logstash节点
- **参数不匹配**：Filebeat和Logstash的批量大小不一致
- **过度优化**：盲目增大批量大小导致内存问题
- **忽略安全**：在公网环境下不启用SSL

### 8.4 问题排查指南


**🔍 常见问题及解决方案**
```
连接问题：
❓ 无法连接Logstash
✅ 检查网络连通性、端口开放、防火墙设置

性能问题：
❓ 传输速度慢
✅ 调整bulk_max_size、compression_level、worker数量

数据丢失：
❓ 部分日志未传输
✅ 检查max_retries设置，查看Filebeat日志错误信息

内存占用高：
❓ Filebeat内存使用过多
✅ 减少bulk_max_size，增加flush_interval
```

**核心记忆要点**：
- **Logstash输出**：beats协议传输，支持负载均衡和故障转移
- **性能三要素**：批量大小、压缩传输、管道机制
- **可靠性保障**：重试机制、超时设置、SSL加密
- **配置匹配**：Filebeat和Logstash参数要协调一致

> **💡 学习建议**：先掌握基础的hosts配置，然后逐步学习性能优化和高可用配置。在实际使用中，建议从简单配置开始，根据实际需求逐步调优。