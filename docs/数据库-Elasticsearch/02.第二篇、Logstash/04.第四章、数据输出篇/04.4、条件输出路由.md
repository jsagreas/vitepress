---
title: 4、条件输出路由
---
## 📚 目录

1. [条件输出基础概念](#1-条件输出基础概念)
2. [条件判断语法详解](#2-条件判断语法详解)
3. [多目标输出配置](#3-多目标输出配置)
4. [输出分流策略](#4-输出分流策略)
5. [故障转移配置](#5-故障转移配置)
6. [输出性能优化](#6-输出性能优化)
7. [负载均衡输出](#7-负载均衡输出)
8. [实战案例分析](#8-实战案例分析)
9. [核心要点总结](#9-核心要点总结)

---

## 1. 🎯 条件输出基础概念


### 1.1 什么是条件输出路由


**简单理解**：就像邮局分拣员一样，根据不同的地址把信件分发到不同的邮筒。

```
📮 传统输出（所有数据都去同一个地方）：
所有日志 → Elasticsearch

🎯 条件输出（智能分发）：
错误日志 → 告警系统
普通日志 → Elasticsearch
访问日志 → 统计数据库
调试日志 → 开发环境
```

**为什么需要条件输出？**
- **数据分类存储**：不同类型的数据存储到最适合的地方
- **成本优化**：重要数据存储到高性能系统，普通数据存储到便宜的地方
- **处理效率**：减少不必要的数据传输和存储
- **业务需求**：不同的团队需要不同的数据

### 1.2 条件输出的工作原理


**🔄 数据处理流程**：
```
输入数据
    ↓
过滤处理（添加字段、解析等）
    ↓
条件判断（检查字段值、标签等）
    ↓ ↓ ↓
输出A  输出B  输出C
```

**核心概念理解**：
- **条件表达式**：就像if语句，判断数据是否满足某个条件
- **多重输出**：一条数据可以同时发送到多个目标
- **条件优先级**：从上到下依次判断条件
- **默认输出**：不满足任何条件的数据去哪里

---

## 2. 📝 条件判断语法详解


### 2.1 基本条件语法


Logstash的条件语法非常直观，就像写简单的if语句：

**🔸 基本语法结构**：
```ruby
if [field_name] == "value" {
  # 输出配置
}
```

**🔸 常用比较操作符**：

| 操作符 | **含义** | **示例** | **说明** |
|--------|----------|----------|----------|
| `==` | **等于** | `[level] == "error"` | `日志级别是error` |
| `!=` | **不等于** | `[status] != 200` | `HTTP状态码不是200` |
| `<` | **小于** | `[response_time] < 100` | `响应时间小于100ms` |
| `>` | **大于** | `[file_size] > 1000` | `文件大小大于1000字节` |
| `<=` | **小于等于** | `[cpu_usage] <= 80` | `CPU使用率不超过80%` |
| `>=` | **大于等于** | `[memory] >= 1024` | `内存大于等于1024MB` |
| `=~` | **正则匹配** | `[message] =~ /ERROR/` | `消息包含ERROR字样` |
| `!~` | **正则不匹配** | `[path] !~ /tmp/` | `路径不包含tmp` |

### 2.2 逻辑运算符


**🔗 组合多个条件**：

```ruby
# AND 逻辑（所有条件都要满足）
if [level] == "error" and [service] == "web" {
  # 既是错误日志，又来自web服务
}

# OR 逻辑（满足任一条件即可）
if [level] == "error" or [level] == "fatal" {
  # 错误日志或致命错误日志
}

# NOT 逻辑（条件取反）
if ![tags] {
  # 没有tags字段的数据
}

# 复杂组合
if ([level] == "error" or [level] == "warning") and [service] != "test" {
  # 是错误或警告，但不来自测试服务
}
```

### 2.3 特殊条件判断


**🔍 字段存在性检查**：
```ruby
# 检查字段是否存在
if [user_id] {
  # 有user_id字段的数据
}

# 检查字段是否不存在
if ![user_id] {
  # 没有user_id字段的数据
}

# 检查字段值是否为空
if [message] == "" {
  # message字段为空字符串
}
```

**🏷️ 标签条件判断**：
```ruby
# 检查是否有特定标签
if "error" in [tags] {
  # 包含error标签
}

# 检查多个标签
if "web" in [tags] and "production" in [tags] {
  # 同时包含web和production标签
}
```

### 2.4 实用条件示例


**📊 根据日志级别分发**：
```ruby
output {
  if [level] == "error" or [level] == "fatal" {
    # 错误日志发送到告警系统
    email {
      to => "admin@company.com"
      subject => "系统错误告警"
      body => "%{message}"
    }
  }
  
  if [level] == "info" {
    # 普通信息日志存储到ES
    elasticsearch {
      hosts => ["localhost:9200"]
      index => "logs-info-%{+YYYY.MM.dd}"
    }
  }
  
  if [level] == "debug" {
    # 调试日志只在开发环境存储
    if [environment] == "dev" {
      file {
        path => "/var/log/debug-%{+YYYY.MM.dd}.log"
      }
    }
  }
}
```

---

## 3. 🎛️ 多目标输出配置


### 3.1 并行输出配置


**同一条数据发送到多个目标**：

```ruby
output {
  # 所有日志都存储到Elasticsearch
  elasticsearch {
    hosts => ["es1.example.com:9200", "es2.example.com:9200"]
    index => "logs-%{+YYYY.MM.dd}"
  }
  
  # 同时备份到文件
  file {
    path => "/backup/logs-%{+YYYY.MM.dd}.log"
    codec => json_lines
  }
  
  # 错误日志额外发送告警
  if [level] == "error" {
    http {
      url => "https://hooks.slack.com/webhook-url"
      http_method => "post"
      content_type => "application/json"
      mapping => {
        "text" => "错误告警: %{message}"
        "channel" => "#alerts"
      }
    }
  }
}
```

### 3.2 条件分支输出


**🌿 复杂的分支逻辑**：

```ruby
output {
  # 根据服务类型分发
  if [service] == "web" {
    elasticsearch {
      hosts => ["web-es:9200"]
      index => "web-logs-%{+YYYY.MM.dd}"
    }
  } else if [service] == "database" {
    elasticsearch {
      hosts => ["db-es:9200"]
      index => "db-logs-%{+YYYY.MM.dd}"
    }
  } else if [service] == "cache" {
    redis {
      host => "redis.example.com"
      port => 6379
      key => "cache-logs"
    }
  } else {
    # 其他服务的默认处理
    file {
      path => "/var/log/other-services.log"
    }
  }
}
```

### 3.3 标签驱动的输出


**🏷️ 使用标签进行智能分发**：

```ruby
filter {
  # 在过滤阶段添加标签
  if [level] == "error" {
    mutate { add_tag => ["需要告警"] }
  }
  
  if [source] =~ /nginx/ {
    mutate { add_tag => ["web访问"] }
  }
  
  if [response_time] and [response_time] > 1000 {
    mutate { add_tag => ["性能问题"] }
  }
}

output {
  # 根据标签决定输出
  if "需要告警" in [tags] {
    email {
      to => ["ops@company.com", "dev@company.com"]
      subject => "系统告警: %{level}"
      body => "%{message}"
    }
  }
  
  if "web访问" in [tags] {
    elasticsearch {
      hosts => ["web-analytics:9200"]
      index => "web-access-%{+YYYY.MM.dd}"
    }
  }
  
  if "性能问题" in [tags] {
    influxdb {
      host => "metrics.example.com"
      port => 8086
      database => "performance"
    }
  }
}
```

---

## 4. 🚦 输出分流策略


### 4.1 按数据重要性分流


**💎 数据价值分级处理**：

```ruby
output {
  # 高价值数据 - 双重保障
  if "critical" in [tags] or [level] == "error" {
    elasticsearch {
      hosts => ["primary-es:9200"]
      index => "critical-logs-%{+YYYY.MM.dd}"
    }
    
    # 同时备份到另一个集群
    elasticsearch {
      hosts => ["backup-es:9200"]
      index => "critical-backup-%{+YYYY.MM.dd}"
    }
  }
  
  # 普通数据 - 标准存储
  if "normal" in [tags] {
    elasticsearch {
      hosts => ["standard-es:9200"]
      index => "logs-%{+YYYY.MM.dd}"
    }
  }
  
  # 低价值数据 - 临时存储
  if "low-priority" in [tags] {
    file {
      path => "/tmp/low-priority-%{+YYYY.MM.dd}.log"
    }
  }
}
```

### 4.2 按时间段分流


**🕐 时间敏感的数据处理**：

```ruby
filter {
  # 添加小时字段用于判断
  date {
    match => [ "timestamp", "ISO8601" ]
    target => "@timestamp"
  }
  
  ruby {
    code => "
      hour = event.get('@timestamp').hour
      if hour >= 9 && hour <= 17
        event.set('time_period', 'business_hours')
      elsif hour >= 18 && hour <= 23
        event.set('time_period', 'evening')
      else
        event.set('time_period', 'night')
      end
    "
  }
}

output {
  # 工作时间 - 实时处理
  if [time_period] == "business_hours" {
    elasticsearch {
      hosts => ["realtime-es:9200"]
      index => "realtime-logs-%{+YYYY.MM.dd}"
    }
  }
  
  # 晚上时间 - 延迟处理
  if [time_period] == "evening" {
    redis {
      host => "redis.example.com"
      port => 6379
      key => "evening-queue"
    }
  }
  
  # 夜间时间 - 批量处理
  if [time_period] == "night" {
    file {
      path => "/batch/night-logs-%{+YYYY.MM.dd}.log"
    }
  }
}
```

### 4.3 按数据大小分流


**📏 根据数据量智能分发**：

```ruby
filter {
  # 计算消息长度
  ruby {
    code => "
      message_size = event.get('message').to_s.length
      if message_size > 10000
        event.set('size_category', 'large')
      elsif message_size > 1000
        event.set('size_category', 'medium')
      else
        event.set('size_category', 'small')
      end
    "
  }
}

output {
  # 大数据 - 专门的大数据处理系统
  if [size_category] == "large" {
    kafka {
      topic_id => "large-data-topic"
      bootstrap_servers => "kafka:9092"
    }
  }
  
  # 中等数据 - 标准ES集群
  if [size_category] == "medium" {
    elasticsearch {
      hosts => ["standard-es:9200"]
      index => "medium-logs-%{+YYYY.MM.dd}"
    }
  }
  
  # 小数据 - 快速ES集群
  if [size_category] == "small" {
    elasticsearch {
      hosts => ["fast-es:9200"]
      index => "small-logs-%{+YYYY.MM.dd}"
    }
  }
}
```

---

## 5. 🛡️ 故障转移配置


### 5.1 主备输出切换


**🔄 确保数据不丢失的容错机制**：

```ruby
output {
  # 主输出 - 优先使用
  elasticsearch {
    hosts => ["primary-es1:9200", "primary-es2:9200"]
    index => "logs-%{+YYYY.MM.dd}"
    
    # 配置重试机制
    retry_on_conflict => 3
    retry_initial_interval => 2
    retry_max_interval => 64
    
    # 如果主集群完全不可用，自动切换到备用输出
    # 这里通过健康检查实现
  }
  
  # 备用输出 - 当主输出失败时使用
  if "_elasticsearch_output_failure" in [tags] {
    file {
      path => "/backup/failed-to-es-%{+YYYY.MM.dd}.log"
      codec => json_lines
    }
    
    # 同时发送告警
    http {
      url => "https://monitoring.example.com/alert"
      http_method => "post"
      mapping => {
        "message" => "Elasticsearch输出失败，数据已转存到文件"
        "severity" => "high"
      }
    }
  }
}
```

### 5.2 智能故障检测


**🔍 自动检测和处理故障**：

```ruby
filter {
  # 添加健康检查标记
  if [service] == "health-check" {
    mutate { add_tag => ["健康检查"] }
  }
}

output {
  # 正常数据输出
  if "健康检查" not in [tags] {
    elasticsearch {
      hosts => ["es1:9200", "es2:9200", "es3:9200"]
      index => "logs-%{+YYYY.MM.dd}"
      
      # 设置较短的超时时间，快速发现问题
      timeout => 10
    }
  }
  
  # 如果检测到输出问题，启用故障转移
  if "_elasticsearch_output_failure" in [tags] {
    # 紧急输出到可靠的文件系统
    file {
      path => "/emergency/logs-%{+YYYY.MM.dd.HH}.log"
      codec => json_lines
      flush_interval => 1
    }
    
    # 发送紧急告警
    exec {
      command => "/usr/local/bin/send-alert.sh '数据输出系统故障'"
    }
  }
}
```

### 5.3 多级故障转移


**🎯 建立多层次的容错体系**：

```ruby
output {
  # 第一优先级：主ES集群
  elasticsearch {
    hosts => ["primary-es:9200"]
    index => "logs-%{+YYYY.MM.dd}"
    timeout => 5
  }
  
  # 第二优先级：备用ES集群
  if "_elasticsearch_output_failure" in [tags] {
    elasticsearch {
      hosts => ["backup-es:9200"]
      index => "backup-logs-%{+YYYY.MM.dd}"
      timeout => 10
    }
  }
  
  # 第三优先级：消息队列缓存
  if "_elasticsearch_output_failure" in [tags] {
    redis {
      host => "redis-cluster:6379"
      key => "failed-logs"
      congestion_threshold => 0
    }
  }
  
  # 最后手段：本地文件存储
  if "_redis_output_failure" in [tags] {
    file {
      path => "/disaster-recovery/logs-%{+YYYY.MM.dd.HH.mm}.log"
      codec => json_lines
      flush_interval => 0  # 立即写入
    }
  }
}
```

---

## 6. ⚡ 输出性能优化


### 6.1 批量输出优化


**📦 提高输出效率的批量处理**：

```ruby
output {
  elasticsearch {
    hosts => ["es1:9200", "es2:9200"]
    index => "logs-%{+YYYY.MM.dd}"
    
    # 批量配置 - 关键性能参数
    flush_size => 1000        # 每1000条记录批量发送一次
    idle_flush_time => 10     # 最长等待10秒就发送
    
    # 连接池配置
    pool_max => 20           # 最大连接数
    pool_max_per_route => 5  # 每个ES节点最大连接数
    
    # 超时配置
    request_timeout => 30    # 请求超时30秒
    
    # 重试配置
    retry_on_conflict => 3
    retry_initial_interval => 2
    retry_max_interval => 64
  }
}
```

### 6.2 输出队列管理


**🚰 控制数据流量和缓冲**：

```ruby
# pipeline配置文件中的队列设置
pipeline.batch.size: 1000        # 批处理大小
pipeline.batch.delay: 50         # 批处理延迟(毫秒)
pipeline.workers: 4              # 工作线程数
queue.type: persisted           # 持久化队列
queue.max_bytes: 1gb            # 队列最大大小
queue.checkpoint.writes: 1024    # 检查点写入频率
```

**配置示例说明**：
```ruby
output {
  # 高吞吐量输出配置
  if [priority] == "high" {
    elasticsearch {
      hosts => ["fast-es:9200"]
      index => "high-priority-%{+YYYY.MM.dd}"
      
      # 高性能配置
      flush_size => 5000
      idle_flush_time => 5
      workers => 8
    }
  }
  
  # 普通优先级输出
  if [priority] == "normal" {
    elasticsearch {
      hosts => ["standard-es:9200"]
      index => "normal-logs-%{+YYYY.MM.dd}"
      
      # 平衡配置
      flush_size => 1000
      idle_flush_time => 10
      workers => 4
    }
  }
  
  # 低优先级批量处理
  if [priority] == "low" {
    file {
      path => "/batch/low-priority-%{+YYYY.MM.dd}.log"
      
      # 大批量低频处理
      flush_interval => 60  # 每分钟刷新一次
    }
  }
}
```

### 6.3 性能监控配置


**📊 监控输出性能指标**：

```ruby
output {
  # 主要输出配置
  elasticsearch {
    hosts => ["es:9200"]
    index => "logs-%{+YYYY.MM.dd}"
    
    # 性能指标配置
    enable_metric => true
    metric_tags => ["output", "elasticsearch"]
  }
  
  # 性能监控输出
  if [fields][metric_type] == "performance" {
    influxdb {
      host => "metrics.example.com"
      port => 8086
      database => "logstash_metrics"
      measurement => "output_performance"
      
      # 记录关键指标
      send_as_tags => ["host", "pipeline", "output_type"]
    }
  }
  
  # 错误监控
  if "_elasticsearch_output_failure" in [tags] {
    statsd {
      host => "statsd.example.com"
      port => 8125
      increment => ["logstash.output.elasticsearch.errors"]
    }
  }
}
```

---

## 7. ⚖️ 负载均衡输出


### 7.1 轮询负载均衡


**🔄 均匀分配负载到多个目标**：

```ruby
output {
  # 使用多个ES集群实现负载均衡
  if [@metadata][target_cluster] == "cluster1" {
    elasticsearch {
      hosts => ["es-cluster1-1:9200", "es-cluster1-2:9200"]
      index => "logs-%{+YYYY.MM.dd}"
    }
  } else if [@metadata][target_cluster] == "cluster2" {
    elasticsearch {
      hosts => ["es-cluster2-1:9200", "es-cluster2-2:9200"]
      index => "logs-%{+YYYY.MM.dd}"
    }
  } else {
    elasticsearch {
      hosts => ["es-cluster3-1:9200", "es-cluster3-2:9200"]
      index => "logs-%{+YYYY.MM.dd}"
    }
  }
}
```

**在过滤器中实现负载均衡逻辑**：
```ruby
filter {
  # 简单的哈希负载均衡
  ruby {
    code => "
      # 根据数据的某个字段进行哈希
      hash_value = event.get('host').hash % 3
      case hash_value
      when 0
        event.set('[@metadata][target_cluster]', 'cluster1')
      when 1
        event.set('[@metadata][target_cluster]', 'cluster2')
      else
        event.set('[@metadata][target_cluster]', 'cluster3')
      end
    "
  }
}
```

### 7.2 权重负载均衡


**⚖️ 根据集群性能分配不同权重**：

```ruby
filter {
  # 权重负载均衡算法
  ruby {
    code => "
      # 设置权重：cluster1(50%), cluster2(30%), cluster3(20%)
      random_value = rand(100)
      
      if random_value < 50
        event.set('[@metadata][target_cluster]', 'cluster1')
      elsif random_value < 80
        event.set('[@metadata][target_cluster]', 'cluster2')
      else
        event.set('[@metadata][target_cluster]', 'cluster3')
      end
    "
  }
}

output {
  # 高性能集群 - 50%负载
  if [@metadata][target_cluster] == "cluster1" {
    elasticsearch {
      hosts => ["high-perf-es1:9200", "high-perf-es2:9200"]
      index => "logs-%{+YYYY.MM.dd}"
      flush_size => 2000
    }
  }
  
  # 标准集群 - 30%负载  
  if [@metadata][target_cluster] == "cluster2" {
    elasticsearch {
      hosts => ["standard-es1:9200", "standard-es2:9200"]
      index => "logs-%{+YYYY.MM.dd}"
      flush_size => 1000
    }
  }
  
  # 经济集群 - 20%负载
  if [@metadata][target_cluster] == "cluster3" {
    elasticsearch {
      hosts => ["economy-es1:9200", "economy-es2:9200"]
      index => "logs-%{+YYYY.MM.dd}"
      flush_size => 500
    }
  }
}
```

### 7.3 智能负载均衡


**🧠 基于实时性能的动态负载均衡**：

```ruby
filter {
  # 健康检查和性能监控
  if [fields][check_type] == "cluster_health" {
    mutate { add_tag => ["集群健康检查"] }
  }
  
  # 智能选择目标集群
  ruby {
    code => "
      # 模拟从监控系统获取集群状态
      # 实际应用中可以通过HTTP请求获取实时状态
      
      cluster_status = {
        'cluster1' => { 'cpu' => 60, 'available' => true },
        'cluster2' => { 'cpu' => 85, 'available' => true },
        'cluster3' => { 'cpu' => 40, 'available' => false }
      }
      
      # 选择CPU使用率最低且可用的集群
      available_clusters = cluster_status.select { |name, status| 
        status['available'] 
      }
      
      if available_clusters.empty?
        event.set('[@metadata][target_cluster]', 'emergency')
      else
        best_cluster = available_clusters.min_by { |name, status| 
          status['cpu'] 
        }
        event.set('[@metadata][target_cluster]', best_cluster[0])
      end
    "
  }
}

output {
  # 动态路由到最佳集群
  if [@metadata][target_cluster] == "cluster1" {
    elasticsearch {
      hosts => ["cluster1:9200"]
      index => "logs-%{+YYYY.MM.dd}"
    }
  } else if [@metadata][target_cluster] == "cluster2" {
    elasticsearch {
      hosts => ["cluster2:9200"]
      index => "logs-%{+YYYY.MM.dd}"
    }
  } else if [@metadata][target_cluster] == "emergency" {
    # 紧急情况下使用本地存储
    file {
      path => "/emergency/logs-%{+YYYY.MM.dd.HH}.log"
      codec => json_lines
    }
  }
}
```

---

## 8. 🎬 实战案例分析


### 8.1 电商网站日志分发系统


**🛒 业务场景**：电商网站需要将不同类型的日志分发到不同的系统进行处理。

```ruby
input {
  beats {
    port => 5044
  }
}

filter {
  # 解析日志类型
  if [fields][log_type] == "access" {
    grok {
      match => { "message" => "%{COMBINEDAPACHELOG}" }
    }
    mutate { add_tag => ["web访问"] }
  } else if [fields][log_type] == "order" {
    json { source => "message" }
    mutate { add_tag => ["订单"] }
  } else if [fields][log_type] == "payment" {
    json { source => "message" }
    mutate { add_tag => ["支付"] }
  }
  
  # 添加业务标签
  if [response] and [response] >= 400 {
    mutate { add_tag => ["错误"] }
  }
  
  if [order_amount] and [order_amount] > 10000 {
    mutate { add_tag => ["大额订单"] }
  }
}

output {
  # Web访问日志 - 实时分析
  if "web访问" in [tags] {
    elasticsearch {
      hosts => ["web-analytics:9200"]
      index => "web-access-%{+YYYY.MM.dd}"
      template_name => "web-access"
    }
    
    # 错误访问同时告警
    if "错误" in [tags] {
      slack {
        url => "https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK"
        channel => "#web-alerts"
        username => "Logstash"
        message => "网站访问错误: %{clientip} %{response} %{request}"
      }
    }
  }
  
  # 订单日志 - 业务分析
  if "订单" in [tags] {
    elasticsearch {
      hosts => ["business-es:9200"]
      index => "orders-%{+YYYY.MM.dd}"
    }
    
    # 大额订单特殊处理
    if "大额订单" in [tags] {
      http {
        url => "https://api.company.com/big-order-alert"
        http_method => "post"
        content_type => "application/json"
        mapping => {
          "order_id" => "%{order_id}"
          "amount" => "%{order_amount}"
          "customer" => "%{customer_id}"
        }
      }
    }
  }
  
  # 支付日志 - 金融合规
  if "支付" in [tags] {
    elasticsearch {
      hosts => ["finance-es:9200"]
      index => "payments-%{+YYYY.MM.dd}"
      
      # 金融数据高安全要求
      ssl => true
      ssl_certificate_verification => true
    }
    
    # 同时备份到文件系统
    file {
      path => "/secure-backup/payments-%{+YYYY.MM.dd}.log"
      codec => json_lines
    }
  }
  
  # 所有数据的通用备份
  file {
    path => "/backup/all-logs-%{+YYYY.MM.dd}.log"
    codec => json_lines
  }
}
```

### 8.2 多环境日志管理


**🌍 开发、测试、生产环境的统一日志管理**：

```ruby
filter {
  # 环境识别
  if [fields][environment] {
    mutate { 
      add_field => { "env" => "%{[fields][environment]}" }
      add_tag => ["环境_%{[fields][environment]}"]
    }
  }
  
  # 服务识别
  if [fields][service] {
    mutate { 
      add_field => { "service_name" => "%{[fields][service]}" }
    }
  }
  
  # 日志级别处理
  if [level] == "ERROR" or [level] == "FATAL" {
    mutate { add_tag => ["需要关注"] }
  }
}

output {
  # 生产环境 - 高可用配置
  if [env] == "production" {
    elasticsearch {
      hosts => ["prod-es1:9200", "prod-es2:9200", "prod-es3:9200"]
      index => "prod-logs-%{service_name}-%{+YYYY.MM.dd}"
      
      # 生产环境高性能配置
      flush_size => 2000
      workers => 8
    }
    
    # 生产环境错误立即告警
    if "需要关注" in [tags] {
      email {
        to => ["ops@company.com", "on-call@company.com"]
        subject => "生产环境错误告警 - %{service_name}"
        body => "时间: %{@timestamp}\n服务: %{service_name}\n错误: %{message}"
      }
    }
  }
  
  # 测试环境 - 标准配置
  if [env] == "staging" {
    elasticsearch {
      hosts => ["staging-es:9200"]
      index => "staging-logs-%{service_name}-%{+YYYY.MM.dd}"
      
      # 测试环境标准配置
      flush_size => 1000
      workers => 4
    }
  }
  
  # 开发环境 - 简化配置
  if [env] == "development" {
    file {
      path => "/dev-logs/%{service_name}-%{+YYYY.MM.dd}.log"
      codec => json_lines
    }
    
    # 开发环境错误发送到开发团队
    if "需要关注" in [tags] {
      slack {
        url => "https://hooks.slack.com/services/DEV/TEAM/WEBHOOK"
        channel => "#dev-alerts"
        username => "DevLogstash"
        message => "开发环境错误: %{service_name} - %{message}"
      }
    }
  }
}
```

---

## 9. 📋 核心要点总结


### 9.1 必须掌握的基本概念


```
🔸 条件输出本质：根据数据特征智能分发到不同目标
🔸 条件语法：类似编程语言的if-else逻辑判断
🔸 多目标输出：一条数据可以同时发送到多个地方
🔸 故障转移：确保数据不丢失的容错机制
🔸 负载均衡：均匀分配负载提高系统性能
🔸 性能优化：通过批量处理和队列管理提升效率
```

### 9.2 关键理解要点


**🔹 条件输出的设计思路**：
```
数据分类原则：
• 按重要性：关键数据多重保障，普通数据标准处理
• 按类型：不同业务数据送到专门的处理系统
• 按时效性：实时数据立即处理，历史数据批量处理
• 按大小：大数据特殊处理，小数据快速处理
```

**🔹 故障处理策略**：
```
多层次容错：
1. 主输出：正常情况下的首选目标
2. 备份输出：主输出失败时的备选方案
3. 应急输出：所有系统都失败时的最后手段
4. 告警机制：及时通知管理员处理问题
```

**🔹 性能优化要点**：
```
关键配置：
• flush_size：批量大小，影响吞吐量
• idle_flush_time：最大等待时间，影响延迟
• workers：并发处理数，影响性能
• queue配置：缓冲区大小，影响稳定性
```

### 9.3 实际应用指导


**💼 配置策略建议**：
```
小型应用：
• 简单的条件分发
• 基本的故障转移
• 标准的性能配置

中型应用：
• 多层次条件判断
• 完整的故障转移链
• 性能监控和优化

大型应用：
• 复杂的业务逻辑路由
• 智能负载均衡
• 全面的监控告警
```

**🛠️ 最佳实践要点**：
```
配置原则：
1. 先简单后复杂：从基本功能开始，逐步增加复杂性
2. 测试驱动：每个配置都要充分测试
3. 监控优先：确保能及时发现问题
4. 文档完整：记录配置逻辑和维护方法

常见陷阱：
• 条件逻辑过于复杂导致难以维护
• 缺乏故障转移导致数据丢失
• 性能配置不当导致延迟过高
• 缺乏监控导致问题发现不及时
```

### 9.4 学习建议


**📚 学习路径**：
```
第一阶段：基础掌握
• 理解条件语法和基本操作
• 实现简单的条件输出
• 配置基本的故障转移

第二阶段：深入应用
• 设计复杂的分发逻辑
• 实现负载均衡
• 进行性能调优

第三阶段：专业应用
• 设计企业级输出架构
• 实现智能化分发策略
• 建立完整的监控体系
```

**🎯 练习建议**：
```
动手实践：
1. 搭建测试环境，实验不同的条件语法
2. 模拟故障场景，验证故障转移机制
3. 压力测试，优化性能配置
4. 设计真实业务场景的分发方案
```

**🧠 记忆要点**：
- 条件输出就像智能快递分拣，根据地址分发包裹
- 故障转移像救生艇，确保数据安全不丢失
- 负载均衡像交通指挥，合理分配流量
- 性能优化像流水线，批量处理提高效率
- 监控告警像警报系统，及时发现处理问题

**核心理念**：条件输出路由不仅仅是技术实现，更是业务逻辑的体现。要根据实际业务需求设计合理的分发策略，在数据安全、处理效率和系统复杂度之间找到最佳平衡点！