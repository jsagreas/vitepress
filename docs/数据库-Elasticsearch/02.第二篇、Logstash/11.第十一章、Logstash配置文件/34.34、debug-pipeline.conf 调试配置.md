---
title: 34、debug-pipeline.conf 调试配置
---
## 📚 目录导航

1. [调试配置基础概念](#1-调试配置基础概念)
2. [详细日志输出配置](#2-详细日志输出配置)
3. [事件调试信息设置](#3-事件调试信息设置)
4. [性能统计监控](#4-性能统计监控)
5. [慢查询日志配置](#5-慢查询日志配置)
6. [错误事件捕获机制](#6-错误事件捕获机制)
7. [处理时间监控](#7-处理时间监控)
8. [内存使用跟踪](#8-内存使用跟踪)
9. [线程状态监控](#9-线程状态监控)
10. [完整调试配置示例](#10-完整调试配置示例)
11. [核心要点总结](#11-核心要点总结)

---

## 1. 🔍 调试配置基础概念


### 1.1 什么是Logstash调试


**简单理解**：就像医生给病人做体检一样，调试配置让我们能"体检"Logstash的运行状态。

```
类比理解：
医生体检 → 查看心跳、血压、体温
Logstash调试 → 查看处理速度、内存占用、错误信息

目标都是：发现问题，保持健康状态
```

**核心作用**：
- 🔸 **发现问题** - 像体温计一样，及时发现异常
- 🔸 **性能监控** - 像speedometer一样，监控处理速度
- 🔸 **错误定位** - 像GPS一样，精确定位问题所在
- 🔸 **优化指导** - 像健身教练一样，给出改进建议

### 1.2 为什么需要调试配置


**实际场景举例**：
```
问题场景：
网站访问日志处理突然变慢了

没有调试配置：
😰 只知道"慢了"，不知道哪里慢
😰 像在黑暗中摸索，找不到原因

有调试配置：
😊 清楚知道：是解析JSON慢？还是写入ES慢？
😊 像开灯一样，问题一目了然
```

**调试配置的价值**：
- ⚡ **快速定位问题** - 从几小时缩短到几分钟
- 📊 **数据化决策** - 用数据说话，不靠猜测
- 🎯 **精准优化** - 针对性改进，效果显著
- 🛡️ **预防问题** - 提前发现隐患，避免宕机

---

## 2. 📝 详细日志输出配置


### 2.1 日志级别理解


**生活化类比**：
```
日志级别就像新闻的重要程度：

🔴 ERROR (错误)   = 头条新闻    -> 系统出大问题了
🟡 WARN (警告)    = 重要新闻    -> 有问题但还能工作
🔵 INFO (信息)    = 一般新闻    -> 正常运行状态
🟢 DEBUG (调试)   = 生活琐事    -> 详细的处理过程
🔘 TRACE (跟踪)   = 个人日记    -> 每个细节都记录
```

### 2.2 基础日志配置


```yaml
# logstash.yml 日志配置

log.level: debug                    # 设置日志级别为调试模式
path.logs: /var/log/logstash       # 日志文件存放位置

# 详细的日志格式配置

log.format: plain                   # 使用纯文本格式，方便阅读
log.to_syslog: false               # 不发送到系统日志

# 慢日志配置 - 像监控菜品制作时间的厨房计时器

slowlog.threshold.warn: 2s         # 处理超过2秒发出警告
slowlog.threshold.info: 1s         # 处理超过1秒记录信息
slowlog.threshold.debug: 500ms     # 处理超过500毫秒调试记录
```

**配置说明**：
- `log.level: debug` - 开启详细模式，记录更多信息
- `slowlog.threshold.*` - 设置"超时警报"，像设定闹钟一样

### 2.3 管道专用日志配置


```ruby
# pipeline配置中的日志增强

input {
  file {
    path => "/var/log/app.log"
#    # 为这个输入源添加标签，便于追踪
    add_tag => ["app_log", "debug_source"]
  }
}

filter {
#  # 在处理过程中添加调试信息
  mutate {
    add_field => { 
      "debug_timestamp" => "%{@timestamp}"
      "debug_source" => "filter_stage"
    }
  }
  
#  # 记录处理前的原始数据
  if [loglevel] == "DEBUG" {
    mutate {
      copy => { "message" => "original_message" }
    }
  }
}

output {
#  # 调试输出 - 在控制台显示处理结果
  stdout { 
    codec => rubydebug {
      metadata => true    # 显示元数据信息
    }
  }
}
```

---

## 3. 🎯 事件调试信息设置


### 3.1 事件调试的概念


**什么是事件调试**：
```
类比快递跟踪：
📦 快递包裹 = Logstash事件
📱 物流信息 = 事件调试信息

快递跟踪显示：
收件 → 分拣 → 运输 → 派送

事件调试显示：
接收 → 解析 → 过滤 → 输出
```

### 3.2 事件流跟踪配置


```ruby
# 完整的事件调试配置

input {
  beats {
    port => 5044
#    # 添加输入阶段标记
    add_field => { 
      "[@metadata][stage]" => "input"
      "[@metadata][input_time]" => "%{+UNIX}"
    }
  }
}

filter {
#  # 添加过滤阶段标记
  mutate {
    add_field => { 
      "[@metadata][filter_start]" => "%{+UNIX}"
      "[@metadata][stage]" => "filter"
    }
  }
  
#  # 记录每个过滤器的处理情况
  grok {
    match => { "message" => "%{COMMONAPACHELOG}" }
    add_tag => [ "grok_parsed" ]
    tag_on_failure => [ "grok_failed" ]
  }
  
#  # 添加过滤完成标记
  mutate {
    add_field => { "[@metadata][filter_end]" => "%{+UNIX}" }
  }
}

output {
#  # 调试输出到文件
  file {
    path => "/var/log/logstash/debug-events.log"
    codec => line { 
      format => "Stage: %{[@metadata][stage]} | Time: %{@timestamp} | Tags: %{tags} | Message: %{message}"
    }
  }
}
```

### 3.3 事件内容详细显示


```ruby
# 显示事件完整内容的配置

output {
  stdout {
    codec => rubydebug {
      metadata => true        # 显示元数据
      include_tags => true    # 显示标签
      include_timestamp => true # 显示时间戳
    }
  }
}
```

**输出效果示例**：
```
{
    "@timestamp" => 2025-01-20T10:30:00.000Z,
        "message" => "192.168.1.1 - - [20/Jan/2025:10:30:00] GET /api/users HTTP/1.1 200",
           "tags" => ["grok_parsed", "debug_source"],
      "@metadata" => {
        "stage" => "filter",
        "filter_start" => "1642680600",
        "filter_end" => "1642680601"
      }
}
```

---

## 4. 📊 性能统计监控


### 4.1 性能监控的重要性


**生活化理解**：
```
性能监控就像汽车仪表盘：
🚗 速度表 → 每秒处理事件数
⛽ 油量表 → 内存使用情况  
🌡️ 水温表 → CPU使用率
⚠️ 故障灯 → 错误率警告
```

### 4.2 启用性能统计


```yaml
# logstash.yml 性能配置

monitoring.enabled: true                    # 启用监控功能
monitoring.elasticsearch.hosts: ["localhost:9200"]  # ES监控地址

# 详细的性能统计配置

monitoring.collection.interval: 10s         # 每10秒收集一次数据
monitoring.collection.pipeline.details.enabled: true  # 启用管道详情

# JVM监控配置

monitoring.collection.config.reload.automatic: true   # 自动重载配置
```

### 4.3 性能统计输出配置


```ruby
# 性能统计专用输出

output {
#  # 性能数据输出到专门的索引
  elasticsearch {
    hosts => ["localhost:9200"]
    index => "logstash-performance-%{+YYYY.MM.dd}"
    document_type => "_doc"
    template_name => "logstash-performance"
  }
  
#  # 同时输出到文件便于查看
  file {
    path => "/var/log/logstash/performance.log"
    codec => json_lines
  }
}
```

### 4.4 性能指标监控配置


```ruby
# 在管道中添加性能计数器

filter {
#  # 计算处理延迟
  ruby {
    code => "
      start_time = event.get('[@metadata][input_time]').to_f
      current_time = Time.now.to_f
      event.set('processing_latency', current_time - start_time)
    "
  }
  
#  # 添加性能标签
  if [processing_latency] > 1 {
    mutate { add_tag => ["slow_processing"] }
  }
  
  if [processing_latency] > 5 {
    mutate { add_tag => ["very_slow_processing"] }
  }
}
```

---

## 5. 🐌 慢查询日志配置


### 5.1 什么是慢查询


**形象比喻**：
```
慢查询就像交通堵车：
🚗 正常处理 = 畅通道路，几秒钟通过
🐌 慢查询 = 交通堵塞，几分钟才通过

我们需要：
📊 监控堵车情况
🔍 找出堵车原因
🛠️ 解决堵车问题
```

### 5.2 慢查询监控配置


```yaml
# logstash.yml 慢查询配置

slowlog.threshold.warn: 2s        # 超过2秒发出警告
slowlog.threshold.info: 1s        # 超过1秒记录信息
slowlog.threshold.debug: 500ms    # 超过500毫秒详细记录
slowlog.threshold.trace: 100ms    # 超过100毫秒跟踪记录
```

### 5.3 管道级慢查询配置


```ruby
# 在管道中实现慢查询监控

filter {
#  # 记录开始处理时间
  ruby {
    code => "event.set('[@metadata][start_time]', Time.now.to_f)"
  }
  
#  # 你的正常处理逻辑
  grok {
    match => { "message" => "%{COMMONAPACHELOG}" }
  }
  
  date {
    match => [ "timestamp", "dd/MMM/yyyy:HH:mm:ss Z" ]
  }
  
#  # 计算处理时间并记录慢查询
  ruby {
    code => "
      start_time = event.get('[@metadata][start_time]')
      end_time = Time.now.to_f
      duration = end_time - start_time
      event.set('processing_duration', duration)
      
#      # 记录慢查询
      if duration > 2.0
        logger.warn('Slow processing detected', 
                   :duration => duration, 
                   :event => event.to_s)
      end
    "
  }
}
```

### 5.4 慢查询分析输出


```ruby
# 专门的慢查询输出

output {
#  # 只输出慢查询事件
  if [processing_duration] and [processing_duration] > 1 {
    file {
      path => "/var/log/logstash/slow-queries.log"
      codec => line {
        format => "SLOW: %{processing_duration}s | %{@timestamp} | %{message}"
      }
    }
    
#    # 发送慢查询告警
    email {
      to => "admin@company.com"
      subject => "Logstash Slow Query Alert"
      body => "Processing took %{processing_duration} seconds for event: %{message}"
    }
  }
}
```

---

## 6. ❌ 错误事件捕获机制


### 6.1 错误捕获的重要性


**生活化比喻**：
```
错误事件就像工厂的次品：
🏭 正常产品 = 成功处理的日志
❌ 次品 = 处理失败的日志

我们需要：
📊 统计次品率
🔍 分析次品原因
🛠️ 改进生产流程
```

### 6.2 错误捕获配置


```ruby
# 完整的错误捕获配置

input {
  beats {
    port => 5044
    add_field => { "[@metadata][input_source]" => "beats" }
  }
}

filter {
#  # 添加错误处理标签
  mutate {
    add_field => { "[@metadata][processing_stage]" => "start" }
  }
  
#  # 尝试解析，添加错误标签
  grok {
    match => { "message" => "%{COMMONAPACHELOG}" }
    add_tag => [ "grok_success" ]
    tag_on_failure => [ "grok_failure", "_grokparsefailure" ]
  }
  
#  # 如果grok失败，记录详细错误信息
  if "_grokparsefailure" in [tags] {
    mutate {
      add_field => { 
        "error_type" => "grok_parse_failure"
        "error_stage" => "filter"
        "original_message" => "%{message}"
        "error_timestamp" => "%{@timestamp}"
      }
      add_tag => [ "processing_error" ]
    }
  }
  
#  # 日期解析错误处理
  if "grok_success" in [tags] {
    date {
      match => [ "timestamp", "dd/MMM/yyyy:HH:mm:ss Z" ]
      tag_on_failure => [ "date_parse_failure" ]
    }
    
    if "date_parse_failure" in [tags] {
      mutate {
        add_field => { 
          "error_type" => "date_parse_failure"
          "error_stage" => "filter"
        }
        add_tag => [ "processing_error" ]
      }
    }
  }
}

output {
#  # 成功处理的事件正常输出
  if "processing_error" not in [tags] {
    elasticsearch {
      hosts => ["localhost:9200"]
      index => "logs-%{+YYYY.MM.dd}"
    }
  }
  
#  # 错误事件专门处理
  if "processing_error" in [tags] {
#    # 输出到错误索引
    elasticsearch {
      hosts => ["localhost:9200"]
      index => "logstash-errors-%{+YYYY.MM.dd}"
    }
    
#    # 输出到错误日志文件
    file {
      path => "/var/log/logstash/errors.log"
      codec => json_lines
    }
    
#    # 输出到控制台用于调试
    stdout {
      codec => rubydebug
    }
  }
}
```

### 6.3 错误统计与告警


```ruby
# 错误统计配置

filter {
#  # 使用聚合插件统计错误率
  aggregate {
    task_id => "error_stats"
    code => "
      map['total_events'] ||= 0
      map['error_events'] ||= 0
      map['total_events'] += 1
      
      if event.get('tags').include?('processing_error')
        map['error_events'] += 1
      end
      
#      # 每1000个事件计算一次错误率
      if map['total_events'] % 1000 == 0
        error_rate = (map['error_events'].to_f / map['total_events']) * 100
        event.set('error_rate_percent', error_rate)
        event.set('total_processed', map['total_events'])
        event.set('total_errors', map['error_events'])
        
#        # 重置计数器
        map['total_events'] = 0
        map['error_events'] = 0
      end
    "
  }
}
```

---

## 7. ⏱️ 处理时间监控


### 7.1 处理时间监控原理


**时间监控就像秒表计时**：
```
运动员跑步：
🏃 起跑 → 按下开始
🏁 终点 → 按下结束
⏱️ 显示 → 总用时

Logstash处理：
📥 接收 → 记录开始时间
📤 输出 → 记录结束时间  
⏱️ 计算 → 总处理时间
```

### 7.2 详细时间监控配置


```ruby
# 完整的处理时间监控

input {
  file {
    path => "/var/log/app.log"
    add_field => { 
      "[@metadata][input_timestamp]" => "%{+UNIX_MS}"
      "[@metadata][stage_timings]" => {}
    }
  }
}

filter {
#  # 记录过滤器开始时间
  ruby {
    code => "
      current_time = (Time.now.to_f * 1000).to_i
      timings = event.get('[@metadata][stage_timings]') || {}
      timings['filter_start'] = current_time
      event.set('[@metadata][stage_timings]', timings)
    "
  }
  
#  # 第一个过滤器 - grok解析
  ruby {
    code => "
      current_time = (Time.now.to_f * 1000).to_i
      timings = event.get('[@metadata][stage_timings]')
      timings['grok_start'] = current_time
      event.set('[@metadata][stage_timings]', timings)
    "
  }
  
  grok {
    match => { "message" => "%{COMMONAPACHELOG}" }
  }
  
  ruby {
    code => "
      current_time = (Time.now.to_f * 1000).to_i
      timings = event.get('[@metadata][stage_timings]')
      timings['grok_end'] = current_time
      timings['grok_duration'] = current_time - timings['grok_start']
      event.set('[@metadata][stage_timings]', timings)
    "
  }
  
#  # 第二个过滤器 - 日期解析
  ruby {
    code => "
      current_time = (Time.now.to_f * 1000).to_i
      timings = event.get('[@metadata][stage_timings]')
      timings['date_start'] = current_time
      event.set('[@metadata][stage_timings]', timings)
    "
  }
  
  date {
    match => [ "timestamp", "dd/MMM/yyyy:HH:mm:ss Z" ]
  }
  
  ruby {
    code => "
      current_time = (Time.now.to_f * 1000).to_i
      timings = event.get('[@metadata][stage_timings]')
      timings['date_end'] = current_time
      timings['date_duration'] = current_time - timings['date_start']
      timings['filter_end'] = current_time
      timings['total_filter_duration'] = current_time - timings['filter_start']
      event.set('[@metadata][stage_timings]', timings)
      
#      # 计算总处理时间
      input_time = event.get('[@metadata][input_timestamp]').to_i
      total_duration = current_time - input_time
      event.set('total_processing_time_ms', total_duration)
      
#      # 将详细时间信息添加到事件中（用于调试）
      event.set('processing_breakdown', timings)
    "
  }
}

output {
#  # 输出处理时间信息
  if [total_processing_time_ms] {
    file {
      path => "/var/log/logstash/timing.log"
      codec => line {
        format => "Total: %{total_processing_time_ms}ms | Grok: %{[processing_breakdown][grok_duration]}ms | Date: %{[processing_breakdown][date_duration]}ms | Message: %{message}"
      }
    }
  }
  
#  # 正常输出
  elasticsearch {
    hosts => ["localhost:9200"]
    index => "logs-%{+YYYY.MM.dd}"
  }
}
```

### 7.3 时间性能告警


```ruby
# 处理时间告警配置

filter {
#  # 根据处理时间添加告警标签
  if [total_processing_time_ms] {
    if [total_processing_time_ms] > 5000 {
      mutate { add_tag => ["very_slow", "alert_critical"] }
    } else if [total_processing_time_ms] > 2000 {
      mutate { add_tag => ["slow", "alert_warning"] }
    } else if [total_processing_time_ms] > 1000 {
      mutate { add_tag => ["moderate", "alert_info"] }
    }
  }
}

output {
#  # 发送告警
  if "alert_critical" in [tags] {
    email {
      to => "admin@company.com"
      subject => "Critical: Logstash Processing Very Slow"
      body => "Processing time: %{total_processing_time_ms}ms for message: %{message}"
    }
  }
}
```

---

## 8. 💾 内存使用跟踪


### 8.1 内存监控的重要性


**内存就像水桶**：
```
💧 水桶装水：
🪣 桶容量 = 系统总内存
💧 水量 = 已使用内存
⚠️ 快满了 = 内存不足警告
💥 溢出 = 内存溢出错误
```

### 8.2 JVM内存监控配置


```yaml
# jvm.options 内存配置

-Xms1g                    # 初始堆内存1GB
-Xmx4g                    # 最大堆内存4GB
-XX:+UseG1GC             # 使用G1垃圾收集器
-XX:+PrintGCDetails      # 打印GC详细信息
-XX:+PrintGCTimeStamps   # 打印GC时间戳
-Xloggc:/var/log/logstash/gc.log  # GC日志文件
```

### 8.3 内存使用监控配置


```ruby
# 内存监控管道配置

input {
  heartbeat {
    interval => 10        # 每10秒检查一次
    message => "memory_check"
    add_field => { "monitor_type" => "memory" }
  }
}

filter {
  if [monitor_type] == "memory" {
    ruby {
      code => "
#        # 获取JVM内存信息
        runtime = Java::JavaLang::Runtime.getRuntime()
        
        total_memory = runtime.totalMemory()
        free_memory = runtime.freeMemory()
        max_memory = runtime.maxMemory()
        used_memory = total_memory - free_memory
        
#        # 转换为MB
        event.set('memory_total_mb', (total_memory / 1024 / 1024).round(2))
        event.set('memory_used_mb', (used_memory / 1024 / 1024).round(2))
        event.set('memory_free_mb', (free_memory / 1024 / 1024).round(2))
        event.set('memory_max_mb', (max_memory / 1024 / 1024).round(2))
        
#        # 计算使用百分比
        usage_percent = (used_memory.to_f / total_memory * 100).round(2)
        event.set('memory_usage_percent', usage_percent)
        
#        # 添加警告标签
        if usage_percent > 90
          event.set('alert_level', 'critical')
          event.tag('memory_critical')
        elsif usage_percent > 80
          event.set('alert_level', 'warning')
          event.tag('memory_warning')
        end
      "
    }
  }
}

output {
  if [monitor_type] == "memory" {
#    # 输出内存监控数据
    elasticsearch {
      hosts => ["localhost:9200"]
      index => "logstash-memory-%{+YYYY.MM.dd}"
    }
    
#    # 内存告警
    if "memory_critical" in [tags] {
      email {
        to => "admin@company.com"
        subject => "Critical: Logstash Memory Usage High"
        body => "Memory usage: %{memory_usage_percent}% (%{memory_used_mb}MB / %{memory_total_mb}MB)"
      }
    }
  }
}
```

---

## 9. 🧵 线程状态监控


### 9.1 线程监控概念


**线程就像工厂流水线**：
```
🏭 工厂比喻：
👷 工人 = 线程
📦 产品 = 日志事件
⚙️ 流水线 = 处理管道

监控内容：
📊 工人数量 = 线程数量
⏱️ 工作效率 = 线程处理速度
😴 休息状态 = 空闲线程
🔥 加班状态 = 忙碌线程
```

### 9.2 线程监控配置


```ruby
# 线程状态监控配置

input {
  heartbeat {
    interval => 30        # 每30秒检查线程状态
    message => "thread_check"
    add_field => { "monitor_type" => "threads" }
  }
}

filter {
  if [monitor_type] == "threads" {
    ruby {
      code => "
#        # 获取线程信息
        thread_mx_bean = Java::JavaLang::ManagementFactory.getThreadMXBean()
        
#        # 基本线程统计
        event.set('thread_count', thread_mx_bean.getThreadCount())
        event.set('daemon_thread_count', thread_mx_bean.getDaemonThreadCount())
        event.set('peak_thread_count', thread_mx_bean.getPeakThreadCount())
        event.set('total_started_thread_count', thread_mx_bean.getTotalStartedThreadCount())
        
#        # 获取所有线程详细信息
        thread_infos = thread_mx_bean.dumpAllThreads(false, false)
        thread_states = {}
        
        thread_infos.each do |thread_info|
          state = thread_info.getThreadState().toString()
          thread_states[state] = (thread_states[state] || 0) + 1
        end
        
        event.set('thread_states', thread_states)
        
#        # 计算繁忙度
        runnable_threads = thread_states['RUNNABLE'] || 0
        total_threads = thread_mx_bean.getThreadCount()
        busy_percent = (runnable_threads.to_f / total_threads * 100).round(2)
        event.set('thread_busy_percent', busy_percent)
        
#        # 添加告警标签
        if busy_percent > 90
          event.tag('threads_overloaded')
        elsif busy_percent > 80
          event.tag('threads_busy')
        end
      "
    }
  }
}

output {
  if [monitor_type] == "threads" {
#    # 输出线程监控数据
    file {
      path => "/var/log/logstash/threads.log"
      codec => line {
        format => "Threads: %{thread_count} | Busy: %{thread_busy_percent}% | States: %{thread_states}"
      }
    }
    
#    # 线程告警
    if "threads_overloaded" in [tags] {
      email {
        to => "admin@company.com"
        subject => "Critical: Logstash Threads Overloaded"
        body => "Thread busy rate: %{thread_busy_percent}% (%{thread_count} total threads)"
      }
    }
  }
}
```

---

## 10. 🔧 完整调试配置示例


### 10.1 综合调试配置文件


```ruby
# debug-pipeline.conf - 完整调试配置

input {
#  # 主要数据输入
  beats {
    port => 5044
    add_field => { 
      "[@metadata][input_timestamp]" => "%{+UNIX_MS}"
      "[@metadata][input_source]" => "beats"
    }
  }
  
#  # 监控输入（内存、线程等）
  heartbeat {
    interval => 30
    message => "system_monitor"
    add_field => { "monitor_type" => "system" }
  }
}

filter {
#  # 系统监控逻辑
  if [monitor_type] == "system" {
    ruby {
      code => "
#        # JVM内存监控
        runtime = Java::JavaLang::Runtime.getRuntime()
        total_memory = runtime.totalMemory()
        free_memory = runtime.freeMemory()
        used_memory = total_memory - free_memory
        usage_percent = (used_memory.to_f / total_memory * 100).round(2)
        
        event.set('memory_usage_percent', usage_percent)
        event.set('memory_used_mb', (used_memory / 1024 / 1024).round(2))
        
#        # 线程监控
        thread_mx_bean = Java::JavaLang::ManagementFactory.getThreadMXBean()
        event.set('thread_count', thread_mx_bean.getThreadCount())
        
#        # 添加告警标签
        if usage_percent > 85 or thread_mx_bean.getThreadCount() > 50
          event.tag('system_alert')
        end
      "
    }
  } else {
#    # 正常日志处理逻辑
    
#    # 记录处理开始时间
    ruby {
      code => "
        event.set('[@metadata][filter_start]', (Time.now.to_f * 1000).to_i)
      "
    }
    
#    # 日志解析
    grok {
      match => { "message" => "%{COMMONAPACHELOG}" }
      add_tag => [ "grok_success" ]
      tag_on_failure => [ "grok_failure", "processing_error" ]
    }
    
#    # 日期解析
    if "grok_success" in [tags] {
      date {
        match => [ "timestamp", "dd/MMM/yyyy:HH:mm:ss Z" ]
        tag_on_failure => [ "date_failure", "processing_error" ]
      }
    }
    
#    # 计算处理时间
    ruby {
      code => "
        start_time = event.get('[@metadata][filter_start]')
        end_time = (Time.now.to_f * 1000).to_i
        processing_time = end_time - start_time
        
        event.set('processing_time_ms', processing_time)
        
#        # 性能标签
        if processing_time > 1000
          event.tag('slow_processing')
        end
        
#        # 错误统计
        if event.get('tags').include?('processing_error')
          event.set('error_type', 'parsing_failure')
          event.set('original_message', event.get('message'))
        end
      "
    }
  }
}

output {
#  # 系统监控输出
  if [monitor_type] == "system" {
    elasticsearch {
      hosts => ["localhost:9200"]
      index => "logstash-monitoring-%{+YYYY.MM.dd}"
    }
    
    if "system_alert" in [tags] {
      email {
        to => "admin@company.com"
        subject => "Logstash System Alert"
        body => "Memory: %{memory_usage_percent}% | Threads: %{thread_count}"
      }
    }
  }
  
#  # 错误事件专门处理
  else if "processing_error" in [tags] {
    elasticsearch {
      hosts => ["localhost:9200"]
      index => "logstash-errors-%{+YYYY.MM.dd}"
    }
    
    file {
      path => "/var/log/logstash/processing-errors.log"
      codec => json_lines
    }
  }
  
#  # 慢处理事件
  else if "slow_processing" in [tags] {
    file {
      path => "/var/log/logstash/slow-processing.log"
      codec => line {
        format => "SLOW (%{processing_time_ms}ms): %{message}"
      }
    }
  }
  
#  # 正常事件输出
  else {
    elasticsearch {
      hosts => ["localhost:9200"]
      index => "logs-%{+YYYY.MM.dd}"
    }
  }
  
#  # 调试输出（可选，用于开发调试）
  if [loglevel] == "DEBUG" {
    stdout {
      codec => rubydebug {
        metadata => true
      }
    }
  }
}
```

### 10.2 配置文件使用说明


**启动调试模式**：
```bash
# 使用调试配置启动Logstash

/usr/share/logstash/bin/logstash -f debug-pipeline.conf --log.level debug

# 监控日志输出

tail -f /var/log/logstash/logstash-plain.log

# 查看错误日志

tail -f /var/log/logstash/processing-errors.log

# 查看慢处理日志

tail -f /var/log/logstash/slow-processing.log
```

**监控指标查看**：
```bash
# 查看内存使用情况

curl -X GET "localhost:9200/logstash-monitoring-*/_search?q=memory_usage_percent:>80&sort=@timestamp:desc"

# 查看错误统计

curl -X GET "localhost:9200/logstash-errors-*/_count"

# 查看处理时间统计

curl -X GET "localhost:9200/logs-*/_search" -H 'Content-Type: application/json' -d'
{
  "aggs": {
    "avg_processing_time": {
      "avg": {
        "field": "processing_time_ms"
      }
    }
  }
}'
```

---

## 11. 📋 核心要点总结


### 11.1 必须掌握的调试概念


```
🔸 调试配置的本质：给Logstash装上"体检设备"
🔸 日志级别：从ERROR到TRACE，控制详细程度
🔸 事件跟踪：像快递单号一样跟踪数据流转
🔸 性能监控：像汽车仪表盘一样监控运行状态
🔸 错误处理：像质检员一样识别和处理问题数据
```

### 11.2 关键配置要点


**🔹 日志配置最佳实践**：
```
生产环境：log.level: info    # 平衡信息量和性能
调试环境：log.level: debug   # 获取详细信息
开发环境：log.level: trace   # 最详细的信息
```

**🔹 性能监控策略**：
```
监控频率：
- 内存检查：每10-30秒
- 线程检查：每30-60秒  
- 慢查询：实时监控

告警阈值：
- 内存使用：>85% 告警
- 处理时间：>2秒 告警
- 错误率：>5% 告警
```

**🔹 错误处理原则**：
```
分类处理：
✅ 可修复错误 → 自动重试
❌ 不可修复错误 → 记录并跳过
⚠️ 系统错误 → 立即告警

记录信息：
📝 错误类型、发生时间
📝 原始数据、处理阶段
📝 错误原因、解决建议
```

### 11.3 实际应用指导


**🎯 问题诊断流程**：
```
1. 查看整体性能指标
   ↓
2. 识别异常时间段
   ↓
3. 查看详细错误日志
   ↓
4. 分析慢查询记录
   ↓
5. 定位具体问题根源
   ↓
6. 制定解决方案
```

**🔧 优化建议**：
- **定期清理日志文件**，避免磁盘占满
- **根据业务需求调整监控频率**，平衡精度和性能
- **建立告警机制**，及时发现和处理问题
- **定期分析趋势**，预防性地进行优化

**💡 调试技巧**：
- 先用`stdout`输出验证逻辑正确性
- 使用`[@metadata]`字段存储调试信息
- 善用标签(`tags`)进行条件判断
- 合理使用`if`条件避免不必要的处理

**核心记忆**：
- 调试配置像医生体检，全面监控Logstash健康状态
- 日志级别控制信息详细程度，生产和调试要区别设置
- 性能监控关注时间、内存、线程三大核心指标
- 错误处理要分类管理，记录详细，及时告警