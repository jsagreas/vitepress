---
title: 26、application-log-pipeline.conf 日志处理
---
## 📚 目录

1. [应用日志处理概述](#1-应用日志处理概述)
2. [多行日志合并技术](#2-多行日志合并技术)
3. [异常堆栈解析处理](#3-异常堆栈解析处理)
4. [日志级别分类与路由](#4-日志级别分类与路由)
5. [业务事件提取与分析](#5-业务事件提取与分析)
6. [用户行为跟踪配置](#6-用户行为跟踪配置)
7. [性能监控数据处理](#7-性能监控数据处理)
8. [告警条件与通知](#8-告警条件与通知)
9. [数据脱敏与安全](#9-数据脱敏与安全)
10. [完整配置文件示例](#10-完整配置文件示例)
11. [核心要点总结](#11-核心要点总结)

---

## 1. 🎯 应用日志处理概述


### 1.1 什么是应用日志处理


**简单理解**：就像整理一本乱七八糟的日记本，把里面有用的信息分类整理出来

```
原始应用日志（杂乱无章）：
2025-09-21 14:30:01 INFO [main] User login successful: user123
java.lang.NullPointerException: Cannot invoke method
    at com.example.UserService.processUser(UserService.java:45)
    at com.example.Controller.handleRequest(Controller.java:23)
2025-09-21 14:30:05 ERROR Database connection failed
2025-09-21 14:30:06 DEBUG Processing payment for order: 12345

经过Logstash处理后（结构化、分类）：
- 用户行为：登录成功
- 异常信息：空指针异常 + 完整堆栈
- 系统错误：数据库连接失败
- 业务事件：支付处理
```

### 1.2 应用日志的特点与挑战


**🔸 应用日志的特殊性**
```
复杂性挑战：
- 多行异常：一个错误可能跨越10多行
- 格式不统一：不同组件输出格式各异
- 信息混杂：业务日志、系统日志、调试信息混在一起
- 数据量大：高并发应用每秒产生数千条日志

处理价值：
- 故障诊断：快速定位系统问题
- 性能监控：识别性能瓶颈
- 用户行为：分析用户使用模式
- 安全审计：发现异常访问行为
```

### 1.3 Logstash在应用日志处理中的作用


**🔧 Logstash就像一个智能的日志管家**
```
输入阶段：收集各种应用日志
  ↓
过滤阶段：解析、分类、提取关键信息
  ↓  
输出阶段：发送到不同的存储系统

具体能力：
✅ 多行日志合并：把散乱的异常堆栈拼接完整
✅ 结构化解析：从文本日志中提取结构化数据
✅ 智能分类：根据内容自动分类到不同索引
✅ 实时处理：边收集边处理，不影响应用性能
```

---

## 2. 🔗 多行日志合并技术


### 2.1 多行日志问题解析


**什么是多行日志**：一条完整的日志信息分散在多行中显示

```
典型的Java异常日志：
行1: 2025-09-21 14:30:01 ERROR [http-thread-1] Exception in user service
行2: java.lang.NullPointerException: User object is null
行3:     at com.example.UserService.validateUser(UserService.java:45)
行4:     at com.example.UserService.processUser(UserService.java:30)
行5:     at com.example.web.UserController.handleLogin(UserController.java:23)
行6: 2025-09-21 14:30:02 INFO [http-thread-2] New user login attempt

问题：如果不合并，Logstash会把每一行当作独立的日志事件处理
结果：异常信息被拆散，无法进行有效的错误分析
```

### 2.2 multiline插件详解


**🔧 multiline插件工作原理**

> 💡 **核心思想**：通过模式匹配识别哪些行属于同一条日志记录

```ruby
# multiline插件基本配置
input {
  file {
    path => "/var/log/application.log"
    multiline {
      # 匹配模式：以日期时间开头的是新日志
      pattern => "^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}"
      # negate表示"不匹配"时的行为
      negate => true
      # what="previous"表示不匹配的行合并到前一条日志
      what => "previous"
    }
  }
}
```

**🎯 关键参数说明**
```
pattern（模式）：
- 定义什么样的行算是新日志的开始
- 使用正则表达式匹配
- 常见模式：时间戳、日志级别、特定前缀

negate（取反）：
- true：不匹配pattern的行进行合并
- false：匹配pattern的行进行合并

what（合并方向）：
- "previous"：合并到前一条日志（最常用）
- "next"：合并到后一条日志
```

### 2.3 常见多行日志场景配置


**📋 Java应用异常日志**
```ruby
input {
  file {
    path => "/var/log/java-app.log"
    multiline {
      # Java日志通常以时间戳开头
      pattern => "^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}"
      negate => true
      what => "previous"
      # 最大行数限制，防止内存溢出
      max_lines => 1000
      # 超时时间，避免长时间等待
      timeout => 10
    }
  }
}
```

**📋 Python应用错误日志**
```ruby
input {
  file {
    path => "/var/log/python-app.log"
    multiline {
      # Python traceback以Traceback开头
      pattern => "^Traceback"
      what => "next"
      # Python堆栈以空格开头的行继续
      patterns_dir => "/etc/logstash/patterns"
    }
  }
}

# 自定义模式文件内容
# /etc/logstash/patterns/python
PYTHON_TIMESTAMP \d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2},\d{3}
```

### 2.4 多行日志处理最佳实践


**⚠️ 常见问题与解决方案**

```
问题1：内存占用过高
原因：某些异常堆栈信息过长
解决：设置max_lines限制

问题2：日志延迟处理
原因：等待后续行导致处理延迟
解决：设置合理的timeout值

问题3：模式匹配错误
原因：日志格式不规范或变化
解决：使用更灵活的正则表达式
```

> 🚀 **性能优化建议**：
> - 在input阶段处理多行，比在filter阶段效率更高
> - 合理设置缓冲区大小，避免内存问题
> - 定期检查多行合并效果，调整匹配模式

---

## 3. 🐛 异常堆栈解析处理


### 3.1 异常堆栈信息的价值


**为什么要专门处理异常堆栈**：异常信息是系统问题诊断的核心线索

```
完整的异常信息包含：
┌─────────────────────────────────────┐
│ 异常类型：NullPointerException      │
│ 异常消息：User object is null       │  
│ 发生位置：UserService.java:45       │
│ 调用链路：Controller → Service      │
│ 线程信息：http-thread-1             │
│ 时间戳：2025-09-21 14:30:01        │
└─────────────────────────────────────┘

提取这些信息的好处：
✅ 快速定位错误发生的具体代码位置
✅ 分析错误的调用链路和传播路径
✅ 统计异常类型和频率
✅ 监控系统健康状况
```

### 3.2 异常信息解析配置


**🔧 使用grok插件解析异常堆栈**

```ruby
filter {
  # 识别异常日志
  if [message] =~ /Exception|Error/ {
    grok {
      match => { 
        "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} \[%{DATA:thread}\] %{GREEDYDATA:exception_message}"
      }
    }
    
    # 提取异常类型
    grok {
      match => { 
        "exception_message" => "%{JAVACLASS:exception_type}:? ?%{GREEDYDATA:exception_detail}"
      }
      tag_on_failure => ["_grokparsefailure_exception"]
    }
    
    # 解析堆栈跟踪
    if [message] =~ /\s+at\s+/ {
      grok {
        match => { 
          "message" => "\s+at %{JAVACLASS:class}\.%{WORD:method}\(%{DATA:location}\)"
        }
        add_field => { "stack_trace" => "%{class}.%{method}(%{location})" }
      }
    }
  }
}
```

**📊 异常信息分类处理**

```ruby
filter {
  # 根据异常类型进行分类
  if [exception_type] {
    if [exception_type] =~ /NullPointerException/ {
      mutate { add_field => { "error_category" => "null_pointer" } }
      mutate { add_field => { "severity" => "high" } }
    }
    else if [exception_type] =~ /SQLException|DatabaseException/ {
      mutate { add_field => { "error_category" => "database" } }
      mutate { add_field => { "severity" => "critical" } }
    }
    else if [exception_type] =~ /TimeoutException/ {
      mutate { add_field => { "error_category" => "timeout" } }
      mutate { add_field => { "severity" => "medium" } }
    }
    else {
      mutate { add_field => { "error_category" => "unknown" } }
      mutate { add_field => { "severity" => "low" } }
    }
  }
}
```

### 3.3 异常统计与监控


**📈 异常频率统计配置**

```ruby
filter {
  # 创建异常统计字段
  if [exception_type] {
    mutate {
      add_field => { 
        "exception_key" => "%{exception_type}_%{[host]}"
        "hourly_key" => "%{+YYYY.MM.dd.HH}"
      }
    }
  }
}

output {
  # 异常详情存储
  if [exception_type] {
    elasticsearch {
      hosts => ["localhost:9200"]
      index => "app-exceptions-%{+YYYY.MM.dd}"
      template_name => "app-exceptions"
    }
  }
  
  # 异常统计存储（用于告警）
  if [severity] == "critical" {
    elasticsearch {
      hosts => ["localhost:9200"]
      index => "critical-alerts-%{+YYYY.MM.dd}"
    }
  }
}
```

---

## 4. 📊 日志级别分类与路由


### 4.1 日志级别的作用与意义


**🎯 为什么要按日志级别分类**

```
不同级别日志的用途：

DEBUG（调试）：
- 开发调试时使用
- 生产环境通常关闭
- 数据量最大，信息最详细

INFO（信息）：
- 正常业务流程记录
- 用户操作、系统状态
- 适合业务分析

WARN（警告）：
- 潜在问题提示
- 不影响正常功能
- 需要关注但不紧急

ERROR（错误）：
- 系统错误和异常
- 需要立即处理
- 影响用户体验

FATAL（致命）：
- 系统崩溃级别错误
- 需要紧急响应
- 可能导致服务不可用
```

### 4.2 日志级别解析与分类


**🔧 提取日志级别信息**

```ruby
filter {
  # 解析基本日志格式
  grok {
    match => { 
      "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:log_level} \[%{DATA:thread}\] \[%{DATA:logger}\] %{GREEDYDATA:log_message}"
    }
  }
  
  # 统一日志级别格式
  mutate {
    uppercase => [ "log_level" ]
  }
  
  # 添加级别权重（用于排序和过滤）
  if [log_level] == "DEBUG" {
    mutate { add_field => { "level_weight" => 1 } }
  }
  else if [log_level] == "INFO" {
    mutate { add_field => { "level_weight" => 2 } }
  }
  else if [log_level] == "WARN" {
    mutate { add_field => { "level_weight" => 3 } }
  }
  else if [log_level] == "ERROR" {
    mutate { add_field => { "level_weight" => 4 } }
  }
  else if [log_level] == "FATAL" {
    mutate { add_field => { "level_weight" => 5 } }
  }
}
```

### 4.3 基于级别的路由策略


**📤 不同级别日志的存储策略**

```ruby
output {
  # DEBUG和INFO：存储到普通索引，保留7天
  if [log_level] in ["DEBUG", "INFO"] {
    elasticsearch {
      hosts => ["localhost:9200"]
      index => "app-logs-normal-%{+YYYY.MM.dd}"
      template => "normal-logs-template"
    }
  }
  
  # WARN：存储到警告索引，保留30天
  if [log_level] == "WARN" {
    elasticsearch {
      hosts => ["localhost:9200"]
      index => "app-logs-warning-%{+YYYY.MM.dd}"
      template => "warning-logs-template"
    }
  }
  
  # ERROR和FATAL：存储到错误索引，保留90天，同时发送告警
  if [log_level] in ["ERROR", "FATAL"] {
    elasticsearch {
      hosts => ["localhost:9200"]
      index => "app-logs-error-%{+YYYY.MM.dd}"
      template => "error-logs-template"
    }
    
    # 发送到告警系统
    http {
      url => "http://alert-system:8080/api/alerts"
      http_method => "post"
      format => "json"
      mapping => {
        "level" => "%{log_level}"
        "message" => "%{log_message}"
        "timestamp" => "%{timestamp}"
        "host" => "%{host}"
      }
    }
  }
}
```

---

## 5. 💼 业务事件提取与分析


### 5.1 什么是业务事件


**🎯 业务事件**：在应用日志中记录的与业务流程相关的重要操作

```
常见业务事件类型：

用户相关：
- 用户注册、登录、退出
- 密码修改、信息更新
- 权限变更、角色分配

交易相关：
- 订单创建、支付、取消
- 库存变更、价格调整
- 退款、换货处理

系统相关：
- 服务启动、停止
- 配置变更、部署操作
- 数据备份、恢复操作
```

### 5.2 业务事件识别与提取


**🔧 业务事件识别配置**

```ruby
filter {
  # 用户登录事件
  if [log_message] =~ /user.*login|login.*success/ {
    grok {
      match => { 
        "log_message" => "User %{WORD:user_id} login %{WORD:login_status} from %{IP:client_ip}"
      }
    }
    mutate {
      add_field => { 
        "event_type" => "user_login"
        "event_category" => "authentication"
      }
    }
  }
  
  # 订单创建事件
  if [log_message] =~ /order.*created|create.*order/ {
    grok {
      match => { 
        "log_message" => "Order %{INT:order_id} created for user %{WORD:user_id} amount %{NUMBER:amount}"
      }
    }
    mutate {
      add_field => { 
        "event_type" => "order_created"
        "event_category" => "transaction"
      }
      convert => { "amount" => "float" }
    }
  }
  
  # 支付事件
  if [log_message] =~ /payment.*processed|process.*payment/ {
    grok {
      match => { 
        "log_message" => "Payment %{WORD:payment_id} %{WORD:payment_status} for order %{INT:order_id}"
      }
    }
    mutate {
      add_field => { 
        "event_type" => "payment_processed"
        "event_category" => "transaction"
      }
    }
  }
}
```

### 5.3 业务指标计算


**📊 实时业务指标统计**

```ruby
filter {
  # 为业务事件添加时间维度
  if [event_type] {
    date {
      match => [ "timestamp", "yyyy-MM-dd HH:mm:ss" ]
      target => "@timestamp"
    }
    
    mutate {
      add_field => { 
        "hour_bucket" => "%{+YYYY-MM-dd-HH}"
        "day_bucket" => "%{+YYYY-MM-dd}"
      }
    }
  }
  
  # 计算业务KPI
  if [event_type] == "user_login" and [login_status] == "success" {
    mutate { add_field => { "kpi_active_users" => "1" } }
  }
  
  if [event_type] == "order_created" {
    mutate { add_field => { "kpi_order_count" => "1" } }
    if [amount] {
      mutate { add_field => { "kpi_revenue" => "%{amount}" } }
    }
  }
}
```

---

## 6. 👥 用户行为跟踪配置


### 6.1 用户行为跟踪的重要性


**🎯 用户行为分析能告诉我们什么**

```
用户画像分析：
- 活跃时间：用户什么时候最活跃
- 使用习惯：喜欢使用哪些功能
- 操作路径：典型的用户操作流程
- 异常行为：可能的安全风险

业务优化：
- 热门功能：哪些功能最受欢迎
- 瓶颈识别：用户在哪里遇到问题
- 转化分析：从访问到购买的转化率
- 个性化推荐：基于行为的推荐策略
```

### 6.2 用户会话追踪


**🔧 用户会话识别配置**

```ruby
filter {
  # 提取用户会话信息
  if [log_message] =~ /user_id|session_id/ {
    grok {
      match => { 
        "log_message" => ".*user_id=(?<user_id>\w+).*session_id=(?<session_id>\w+)"
      }
    }
  }
  
  # 识别用户操作类型
  if [user_id] {
    if [log_message] =~ /page_view|visit/ {
      mutate { 
        add_field => { 
          "action_type" => "page_view"
          "tracking_category" => "navigation"
        }
      }
      
      # 提取页面信息
      grok {
        match => { 
          "log_message" => ".*page=(?<page_name>\w+).*duration=(?<page_duration>\d+)"
        }
      }
    }
    
    if [log_message] =~ /click|button/ {
      mutate { 
        add_field => { 
          "action_type" => "click"
          "tracking_category" => "interaction"
        }
      }
    }
    
    if [log_message] =~ /search/ {
      mutate { 
        add_field => { 
          "action_type" => "search"
          "tracking_category" => "engagement"
        }
      }
      
      # 提取搜索关键词
      grok {
        match => { 
          "log_message" => ".*query=(?<search_query>[^\\s]+)"
        }
      }
    }
  }
}
```

### 6.3 用户行为路径分析


**📈 用户操作序列跟踪**

```ruby
filter {
  # 为用户行为添加序列号
  if [user_id] and [action_type] {
    mutate {
      add_field => { 
        "user_session_key" => "%{user_id}_%{session_id}"
        "action_timestamp" => "%{+YYYY-MM-dd HH:mm:ss}"
      }
    }
  }
  
  # 计算页面停留时间
  if [page_duration] {
    mutate { convert => { "page_duration" => "integer" } }
    
    if [page_duration] > 300 {
      mutate { add_field => { "engagement_level" => "high" } }
    }
    else if [page_duration] > 60 {
      mutate { add_field => { "engagement_level" => "medium" } }
    }
    else {
      mutate { add_field => { "engagement_level" => "low" } }
    }
  }
}
```

---

## 7. ⚡ 性能监控数据处理


### 7.1 性能监控指标类型


**📊 应用性能关键指标**

```
响应时间指标：
- API响应时间：接口处理耗时
- 数据库查询时间：SQL执行耗时
- 页面加载时间：前端渲染耗时
- 外部服务调用时间：第三方API耗时

资源使用指标：
- CPU使用率：处理器负载情况
- 内存使用率：内存占用情况
- 磁盘IO：读写操作频率
- 网络带宽：网络传输状况

业务性能指标：
- 并发用户数：同时在线用户
- 请求成功率：接口成功率
- 错误率：系统错误比例
- 吞吐量：每秒处理请求数
```

### 7.2 性能数据解析


**🔧 性能日志解析配置**

```ruby
filter {
  # 解析API性能日志
  if [log_message] =~ /API.*response_time/ {
    grok {
      match => { 
        "log_message" => "API %{URIPATH:api_path} processed in %{NUMBER:response_time}ms for user %{WORD:user_id}"
      }
    }
    
    mutate {
      convert => { "response_time" => "float" }
      add_field => { "metric_type" => "api_performance" }
    }
    
    # 性能等级分类
    if [response_time] {
      if [response_time] > 2000 {
        mutate { add_field => { "performance_level" => "poor" } }
      }
      else if [response_time] > 500 {
        mutate { add_field => { "performance_level" => "average" } }
      }
      else {
        mutate { add_field => { "performance_level" => "good" } }
      }
    }
  }
  
  # 解析数据库性能日志
  if [log_message] =~ /SQL.*execution_time/ {
    grok {
      match => { 
        "log_message" => "SQL query executed in %{NUMBER:sql_time}ms: %{GREEDYDATA:sql_query}"
      }
    }
    
    mutate {
      convert => { "sql_time" => "float" }
      add_field => { "metric_type" => "database_performance" }
    }
  }
}
```

### 7.3 性能告警配置


**⚠️ 性能阈值监控**

```ruby
filter {
  # 性能异常检测
  if [metric_type] == "api_performance" {
    if [response_time] > 5000 {
      mutate {
        add_field => { 
          "alert_type" => "performance_critical"
          "alert_message" => "API %{api_path} response time %{response_time}ms exceeds threshold"
        }
      }
    }
  }
  
  if [metric_type] == "database_performance" {
    if [sql_time] > 3000 {
      mutate {
        add_field => { 
          "alert_type" => "database_slow"
          "alert_message" => "SQL query execution time %{sql_time}ms is too slow"
        }
      }
    }
  }
}
```

---

## 8. 🚨 告警条件与通知


### 8.1 告警条件设计原则


**🎯 什么时候需要告警**

```
告警触发条件：

紧急级别（立即通知）：
- 系统崩溃、服务不可用
- 数据丢失、安全攻击
- 支付系统异常

重要级别（15分钟内通知）：
- 错误率超过阈值
- 响应时间过慢
- 数据库连接异常

一般级别（1小时内通知）：
- 磁盘空间不足
- 内存使用率过高
- 非核心功能异常
```

### 8.2 告警规则配置


**🔧 多级告警系统配置**

```ruby
filter {
  # 错误率告警
  if [log_level] == "ERROR" {
    mutate { add_field => { "error_count" => "1" } }
    
    # 使用aggregate插件统计错误率
    aggregate {
      task_id => "%{host}_error_rate"
      code => "
        map['error_count'] ||= 0
        map['total_count'] ||= 0
        map['error_count'] += 1
        map['total_count'] += 1
        
        error_rate = (map['error_count'].to_f / map['total_count']) * 100
        
        if error_rate > 10
          event.set('alert_level', 'critical')
          event.set('alert_message', 'Error rate is #{error_rate.round(2)}%')
        elsif error_rate > 5
          event.set('alert_level', 'warning')
          event.set('alert_message', 'Error rate is #{error_rate.round(2)}%')
        end
      "
      push_map_as_event_on_timeout => true
      timeout => 300  # 5分钟统计一次
    }
  }
  
  # 响应时间告警
  if [response_time] and [response_time] > 2000 {
    mutate {
      add_field => { 
        "alert_level" => "warning"
        "alert_message" => "API %{api_path} response time %{response_time}ms is slow"
        "alert_category" => "performance"
      }
    }
  }
}
```

### 8.3 告警通知配置


**📱 多渠道告警通知**

```ruby
output {
  # 关键错误立即发送邮件和短信
  if [alert_level] == "critical" {
    email {
      to => ["admin@company.com", "ops@company.com"]
      subject => "CRITICAL ALERT: %{alert_message}"
      body => "
        Alert Level: %{alert_level}
        Message: %{alert_message}
        Host: %{host}
        Time: %{@timestamp}
        Log: %{message}
      "
    }
    
    http {
      url => "http://sms-gateway:8080/send"
      http_method => "post"
      format => "json"
      mapping => {
        "phones" => ["13800138000", "13900139000"]
        "message" => "CRITICAL: %{alert_message}"
      }
    }
  }
  
  # 一般告警发送到Slack
  if [alert_level] in ["warning", "info"] {
    http {
      url => "https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK"
      http_method => "post"
      format => "json"
      mapping => {
        "text" => "⚠️ Alert: %{alert_message}",
        "channel" => "#ops-alerts"
      }
    }
  }
}
```

---

## 9. 🔒 数据脱敏与安全


### 9.1 为什么需要数据脱敏


**🛡️ 数据脱敏的重要性**

```
敏感信息类型：
- 用户隐私：手机号、邮箱、身份证号
- 账户信息：密码、支付信息、银行卡号
- 商业机密：价格策略、用户数据、交易信息
- 系统安全：API密钥、数据库连接信息

不脱敏的风险：
- 隐私泄露：用户个人信息被非授权人员获取
- 合规问题：违反GDPR、个人信息保护法等法规
- 安全风险：敏感信息被恶意利用
- 信任危机：用户对企业数据安全失去信心
```

### 9.2 常见脱敏技术配置


**🔧 敏感信息识别与脱敏**

```ruby
filter {
  # 手机号脱敏
  if [log_message] =~ /\b1[3-9]\d{9}\b/ {
    mutate {
      gsub => [
        "log_message", "\b(1[3-9]\d)\d{4}(\d{4})\b", "\1****\2"
      ]
      add_field => { "data_masked" => "phone_number" }
    }
  }
  
  # 邮箱脱敏
  if [log_message] =~ /\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b/ {
    mutate {
      gsub => [
        "log_message", "\b([A-Za-z0-9._%+-]{1,3})[A-Za-z0-9._%+-]*@([A-Za-z0-9.-]+\.[A-Z|a-z]{2,})\b", "\1***@\2"
      ]
      add_field => { "data_masked" => "email" }
    }
  }
  
  # 身份证号脱敏
  if [log_message] =~ /\b\d{15}|\d{18}\b/ {
    mutate {
      gsub => [
        "log_message", "\b(\d{6})\d{8}(\d{4})\b", "\1********\2"
      ]
      add_field => { "data_masked" => "id_card" }
    }
  }
  
  # 银行卡号脱敏
  if [log_message] =~ /\b\d{13,19}\b/ {
    mutate {
      gsub => [
        "log_message", "\b(\d{4})\d{5,11}(\d{4})\b", "\1*******\2"
      ]
      add_field => { "data_masked" => "bank_card" }
    }
  }
}
```

### 9.3 动态脱敏规则


**🎯 基于上下文的智能脱敏**

```ruby
filter {
  # 根据字段名智能脱敏
  ruby {
    code => "
      event.to_hash.each do |key, value|
        if value.is_a?(String)
          # 密码相关字段
          if key.downcase.include?('password') || key.downcase.include?('pwd')
            event.set(key, '***MASKED***')
          end
          
          # Token相关字段
          if key.downcase.include?('token') || key.downcase.include?('key')
            if value.length > 10
              event.set(key, value[0,4] + '*' * (value.length-8) + value[-4,4])
            end
          end
          
          # 用户名脱敏（保留首尾字符）
          if key.downcase.include?('username') || key.downcase.include?('user_name')
            if value.length > 2
              event.set(key, value[0] + '*' * (value.length-2) + value[-1])
            end
          end
        end
      end
    "
  }
}
```

---

## 10. 📁 完整配置文件示例


### 10.1 生产环境完整配置


```ruby
# 26-application-log-pipeline.conf

input {
  beats {
    port => 5044
  }
  
  file {
    path => [
      "/var/log/app/*.log",
      "/var/log/app/archives/*.log"
    ]
    start_position => "beginning"
    multiline {
      pattern => "^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}"
      negate => true
      what => "previous"
      max_lines => 1000
      timeout => 10
    }
    codec => "plain"
    discover_interval => 15
  }
}

filter {
  # 基础日志解析
  grok {
    match => { 
      "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:log_level} \[%{DATA:thread}\] \[%{DATA:logger}\] %{GREEDYDATA:log_message}"
    }
    add_field => { "parsed" => "true" }
    tag_on_failure => ["_grokparsefailure"]
  }
  
  # 时间字段处理
  if [timestamp] {
    date {
      match => [ "timestamp", "yyyy-MM-dd HH:mm:ss,SSS", "yyyy-MM-dd HH:mm:ss" ]
      target => "@timestamp"
    }
  }
  
  # 数据脱敏
  if [log_message] {
    # 手机号脱敏
    mutate {
      gsub => [
        "log_message", "\b(1[3-9]\d)\d{4}(\d{4})\b", "\1****\2"
      ]
    }
    
    # 邮箱脱敏
    mutate {
      gsub => [
        "log_message", "\b([A-Za-z0-9._%+-]{1,3})[A-Za-z0-9._%+-]*@([A-Za-z0-9.-]+\.[A-Z|a-z]{2,})\b", "\1***@\2"
      ]
    }
  }
  
  # 异常处理
  if [log_level] == "ERROR" and [log_message] =~ /Exception/ {
    grok {
      match => { 
        "log_message" => "%{JAVACLASS:exception_type}:? ?%{GREEDYDATA:exception_detail}"
      }
    }
    
    mutate { add_field => { "has_exception" => "true" } }
    
    # 异常分类
    if [exception_type] =~ /NullPointerException/ {
      mutate { 
        add_field => { 
          "error_category" => "null_pointer"
          "severity" => "high"
        }
      }
    }
  }
  
  # 业务事件提取
  if [log_message] =~ /user.*login.*success/ {
    grok {
      match => { 
        "log_message" => ".*user[\\s=:](?<user_id>\\w+).*login.*success.*ip[\\s=:](?<client_ip>\\d+\\.\\d+\\.\\d+\\.\\d+)"
      }
    }
    mutate {
      add_field => { 
        "event_type" => "user_login"
        "event_category" => "authentication"
      }
    }
  }
  
  # 性能监控
  if [log_message] =~ /API.*processed.*\d+ms/ {
    grok {
      match => { 
        "log_message" => "API (?<api_path>/[^\\s]*) processed in (?<response_time>\\d+)ms"
      }
    }
    mutate {
      convert => { "response_time" => "integer" }
      add_field => { "metric_type" => "api_performance" }
    }
    
    if [response_time] > 2000 {
      mutate {
        add_field => { 
          "alert_level" => "warning"
          "alert_message" => "Slow API response: %{api_path} took %{response_time}ms"
        }
      }
    }
  }
  
  # 添加环境标识
  mutate {
    add_field => { 
      "environment" => "${APP_ENV:production}"
      "service_name" => "${SERVICE_NAME:app-service}"
    }
  }
}

output {
  # 正常日志
  if ![has_exception] and ![alert_level] {
    elasticsearch {
      hosts => ["${ES_HOSTS:localhost:9200}"]
      index => "app-logs-normal-%{+YYYY.MM.dd}"
      template_name => "app-logs-template"
    }
  }
  
  # 异常日志
  if [has_exception] {
    elasticsearch {
      hosts => ["${ES_HOSTS:localhost:9200}"]
      index => "app-logs-error-%{+YYYY.MM.dd}"
      template_name => "error-logs-template"
    }
  }
  
  # 业务事件
  if [event_type] {
    elasticsearch {
      hosts => ["${ES_HOSTS:localhost:9200}"]
      index => "business-events-%{+YYYY.MM.dd}"
    }
  }
  
  # 性能数据
  if [metric_type] {
    elasticsearch {
      hosts => ["${ES_HOSTS:localhost:9200}"]
      index => "performance-metrics-%{+YYYY.MM.dd}"
    }
  }
  
  # 告警通知
  if [alert_level] == "warning" {
    http {
      url => "${SLACK_WEBHOOK_URL}"
      http_method => "post"
      format => "json"
      mapping => {
        "text" => "⚠️ %{alert_message}",
        "channel" => "#ops-alerts"
      }
    }
  }
  
  # 调试输出（开发环境）
  if "${APP_ENV}" == "development" {
    stdout { 
      codec => rubydebug 
    }
  }
}
```

---

## 11. 📋 核心要点总结


### 11.1 必须掌握的核心概念


```
🔸 多行日志合并：解决异常堆栈跨行问题
🔸 日志级别分类：按重要性分类存储和处理
🔸 业务事件提取：从日志中识别有价值的业务信息
🔸 性能监控：实时跟踪系统性能指标
🔸 用户行为分析：追踪用户操作路径和习惯
🔸 告警机制：及时发现和通知系统问题
🔸 数据脱敏：保护敏感信息安全
```

### 11.2 关键理解要点


**🔹 多行日志处理技巧**
```
最佳实践：
- 在input阶段处理，效率更高
- 合理设置timeout，避免延迟
- 使用max_lines防止内存溢出
- 定期测试模式匹配效果
```

**🔹 业务价值最大化**
```
重点关注：
- 异常信息完整性：帮助快速定位问题
- 用户行为连续性：形成完整的用户画像
- 性能趋势分析：提前发现性能瓶颈
- 安全合规要求：保护用户隐私安全
```

**🔹 运维效率提升**
```
自动化程度：
- 智能告警：减少无效告警
- 自动分类：按重要性自动路由
- 实时处理：边产生边分析
- 可视化监控：直观展示系统状态
```

### 11.3 实际应用指导


> 💡 **新手建议**：
> 从简单的单行日志解析开始，逐步增加多行处理、业务事件提取等高级功能

> 🚀 **优化策略**：
> 根据实际日志量调整批处理大小，定期监控Logstash性能指标

> ⚠️ **注意事项**：
> 数据脱敏规则要定期更新，确保新的敏感信息类型得到保护

**核心记忆要点**：
- 应用日志处理是日志分析的核心场景
- 多行合并是处理应用日志的基础技能
- 业务事件提取能产生最大的业务价值
- 数据安全和隐私保护不可忽视
- 告警机制要平衡及时性和准确性