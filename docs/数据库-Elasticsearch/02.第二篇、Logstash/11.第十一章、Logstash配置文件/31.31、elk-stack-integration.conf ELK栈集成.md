---
title: 31、elk-stack-integration.conf ELK栈集成
---
## 📚 目录

1. [ELK栈基础理解](#1-ELK栈基础理解)
2. [Elasticsearch集群配置](#2-Elasticsearch集群配置)
3. [Kibana可视化准备](#3-Kibana可视化准备)
4. [索引生命周期管理](#4-索引生命周期管理)
5. [数据保留策略配置](#5-数据保留策略配置)
6. [性能优化配置实战](#6-性能优化配置实战)
7. [监控告警集成](#7-监控告警集成)
8. [用户权限管理](#8-用户权限管理)
9. [备份恢复策略](#9-备份恢复策略)
10. [完整配置文件示例](#10-完整配置文件示例)
11. [核心要点总结](#11-核心要点总结)

---

## 1. 🏗️ ELK栈基础理解


### 1.1 什么是ELK栈


> 📖 **核心概念**  
> ELK栈是三个开源工具的组合：**E**lasticsearch + **L**ogstash + **K**ibana，专门用来处理大量的日志数据

**💡 生活类比**：ELK就像一个智能的图书馆系统
- **Logstash**：像图书管理员，负责收集和整理各种书籍（日志）
- **Elasticsearch**：像巨大的图书馆书架，存储所有书籍并提供快速搜索
- **Kibana**：像阅览室的查询系统，让你能方便地找到和查看书籍

### 1.2 ELK栈的工作流程


```
数据来源              数据处理              数据存储              数据展示
    |                    |                    |                    |
 应用日志  ──收集──> Logstash ──处理──> Elasticsearch ──查询──> Kibana
 系统日志                 |                    |                    |
 网络日志              清洗转换              索引存储            可视化图表
```

**🔄 详细流程解释**：
1. **收集阶段**：Logstash从各种来源收集原始日志
2. **处理阶段**：清洗、转换、丰富日志数据
3. **存储阶段**：将处理好的数据发送到Elasticsearch
4. **展示阶段**：通过Kibana创建图表和仪表盘

### 1.3 为什么需要ELK栈


**🎯 解决的核心问题**：
- **海量日志**：单台服务器每天产生GB级别的日志
- **分散存储**：日志分布在不同服务器上，查找困难
- **格式混乱**：不同应用的日志格式各不相同
- **实时分析**：需要快速发现问题和异常

**✅ ELK的优势**：
- `实时处理` 日志数据，几秒内完成分析
- `统一管理` 所有系统的日志，一个地方搞定
- `强大搜索` 支持复杂条件的快速查询
- `可视化展示` 用图表直观显示数据趋势

---

## 2. 🔧 Elasticsearch集群配置


### 2.1 什么是Elasticsearch集群


> 📖 **核心概念**  
> Elasticsearch集群就是多台服务器联合工作，共同存储和处理数据，就像多个人一起搬家会更快更安全

**🏢 集群架构图**：
```
     负载均衡器
         |
    ┌────┴────┐
    |  Client |  ← 客户端请求入口
    └────┬────┘
         |
┌────────┼────────┐
|   Master Node   |  ← 主节点(管理集群)
├─────────────────┤
|   Data Node 1   |  ← 数据节点1(存储数据)
├─────────────────┤
|   Data Node 2   |  ← 数据节点2(存储数据)
├─────────────────┤
|   Data Node 3   |  ← 数据节点3(存储数据)
└─────────────────┘
```

### 2.2 Logstash中的Elasticsearch配置


**🔸 基础连接配置**：

```ruby
output {
  elasticsearch {
    # 集群节点地址 - 可以配置多个以实现高可用
    hosts => ["192.168.1.10:9200", "192.168.1.11:9200", "192.168.1.12:9200"]
    
    # 索引名称 - 按日期分割便于管理
    index => "logstash-app-%{+YYYY.MM.dd}"
    
    # 文档类型
    document_type => "_doc"
    
    # 文档ID - 如果不指定会自动生成
    document_id => "%{[@metadata][fingerprint]}"
  }
}
```

**💡 配置说明**：
- `hosts` 多个节点地址确保某台服务器挂掉时仍能正常工作
- `index` 按日期分割索引，方便后期数据管理和删除
- `document_id` 使用指纹避免重复数据

### 2.3 集群健康监控配置


```ruby
output {
  elasticsearch {
    hosts => ["es-cluster:9200"]
    index => "logstash-monitor-%{+YYYY.MM}"
    
    # 集群健康检查
    healthcheck_path => "/_cluster/health"
    
    # 连接池配置
    pool_max => 1000
    pool_max_per_route => 100
    
    # 超时设置
    timeout => 60
    
    # 重试机制
    retry_max_interval => 5
    retry_max_times => 3
  }
}
```

### 2.4 负载均衡和故障转移


**⚖️ 负载均衡策略**：

```ruby
output {
  elasticsearch {
    # 多节点配置实现自动负载均衡
    hosts => [
      "es-master:9200",
      "es-data-1:9200", 
      "es-data-2:9200",
      "es-data-3:9200"
    ]
    
    # 负载均衡算法
    load_balance => true
    
    # 故障节点自动剔除
    resurrect_delay => 30
    
    # 连接验证
    validate_after_inactivity => 10000
  }
}
```

**🔄 故障转移机制**：
1. **健康检查**：定期检测节点状态
2. **自动剔除**：发现故障节点立即从列表移除  
3. **自动恢复**：故障节点恢复后重新加入
4. **请求重试**：失败请求自动转发到其他节点

---

## 3. 📊 Kibana可视化准备


### 3.1 为Kibana准备数据


> 📖 **核心概念**  
> Kibana就像一个数据分析师，需要规整的数据才能制作出漂亮的图表，所以Logstash要为它准备好"标准化"的数据

**🎯 数据标准化原则**：
- **字段统一**：相同含义的字段使用相同名称
- **类型一致**：数字就是数字，时间就是时间格式
- **结构清晰**：合理的层级关系，便于分析

### 3.2 为可视化优化字段


```ruby
filter {
  # 解析应用日志
  grok {
    match => { 
      "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} %{GREEDYDATA:content}" 
    }
  }
  
  # 为Kibana准备时间字段
  date {
    match => [ "timestamp", "ISO8601" ]
    target => "@timestamp"
  }
  
  # 创建Kibana友好的字段
  mutate {
    # 添加便于分析的标签
    add_field => {
      "log_source" => "application"
      "environment" => "%{[host][name]}"
      "severity_numeric" => "0"
    }
    
    # 根据日志级别设置数值（便于统计）
    replace => {
      "severity_numeric" => "1" if [level] == "ERROR"
      "severity_numeric" => "2" if [level] == "WARN"  
      "severity_numeric" => "3" if [level] == "INFO"
    }
  }
  
  # 地理位置信息（如果有IP地址）
  if [client_ip] {
    geoip {
      source => "client_ip"
      target => "geoip"
    }
  }
}
```

### 3.3 索引模板配置


**📋 为Kibana创建索引模板**：

```ruby
output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "app-logs-%{+YYYY.MM.dd}"
    
    # 索引模板配置
    template_name => "app-logs-template"
    template => "app-logs-*"
    template_overwrite => true
    
    # 字段映射定义
    mapping => {
      "properties" => {
        "@timestamp" => { "type" => "date" }
        "level" => { "type" => "keyword" }
        "message" => { "type" => "text" }
        "severity_numeric" => { "type" => "integer" }
        "response_time" => { "type" => "float" }
        "user_id" => { "type" => "keyword" }
        "geoip" => {
          "properties" => {
            "location" => { "type" => "geo_point" }
            "country_name" => { "type" => "keyword" }
          }
        }
      }
    }
  }
}
```

**💡 字段类型说明**：
- `keyword` → 用于精确匹配和聚合分析
- `text` → 用于全文搜索
- `date` → 时间字段，支持时间范围查询
- `geo_point` → 地理位置，支持地图可视化

### 3.4 Kibana数据视图准备


```ruby
# 在output中添加Kibana相关配置
output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "kibana-ready-logs-%{+YYYY.MM.dd}"
    
    # 确保Kibana能识别时间字段
    document_type => "_doc"
    
    # 添加元数据供Kibana使用
    action => "index"
  }
}

# 专门为Kibana仪表盘创建汇总数据
if [create_dashboard_data] {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "dashboard-summary-%{+YYYY.MM}"
    
    # 汇总字段
    document_id => "%{log_source}-%{+YYYY.MM.dd.HH}"
  }
}
```

---

## 4. 🔄 索引生命周期管理


### 4.1 什么是索引生命周期


> 📖 **核心概念**  
> 索引生命周期管理(ILM)就像管理家里的物品，新的放在容易拿取的地方，旧的逐渐移到储藏室，很久没用的就扔掉

**📅 生命周期阶段**：
```
Hot (热数据)    Warm (温数据)    Cold (冷数据)    Delete (删除)
     |              |              |               |
   活跃读写  ───>  只读查询  ───>  归档存储  ───>   自动删除
  (0-7天)        (7-30天)       (30-90天)      (90天后)
```

### 4.2 配置生命周期策略


```ruby
output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    
    # 使用ILM策略的索引命名
    index => "app-logs-%{+YYYY.MM.dd}-000001"
    
    # ILM策略配置
    ilm_enabled => true
    ilm_rollover_alias => "app-logs"
    ilm_pattern => "{now/d}-000001"
    ilm_policy => "app-logs-policy"
  }
}
```

### 4.3 定义ILM策略


**🔧 策略配置示例**：

```json
{
  "policy": {
    "phases": {
      "hot": {
        "actions": {
          "rollover": {
            "max_size": "50gb",
            "max_age": "7d",
            "max_docs": 100000000
          },
          "set_priority": {
            "priority": 100
          }
        }
      },
      "warm": {
        "min_age": "7d",
        "actions": {
          "allocate": {
            "number_of_replicas": 0
          },
          "forcemerge": {
            "max_num_segments": 1
          },
          "set_priority": {
            "priority": 50
          }
        }
      },
      "cold": {
        "min_age": "30d",
        "actions": {
          "allocate": {
            "number_of_replicas": 0
          },
          "set_priority": {
            "priority": 0
          }
        }
      },
      "delete": {
        "min_age": "90d"
      }
    }
  }
}
```

**💡 策略说明**：
- **Hot阶段**：数据活跃，高性能硬盘存储
- **Warm阶段**：查询减少，降低副本数节省空间
- **Cold阶段**：很少查询，进一步优化存储
- **Delete阶段**：自动删除过期数据

### 4.4 在Logstash中应用ILM


```ruby
filter {
  # 根据日志类型设置不同的生命周期
  if [log_type] == "application" {
    mutate {
      add_field => { "[@metadata][ilm_policy]" => "app-logs-policy" }
      add_field => { "[@metadata][index_prefix]" => "app-logs" }
    }
  } else if [log_type] == "security" {
    mutate {
      add_field => { "[@metadata][ilm_policy]" => "security-logs-policy" }
      add_field => { "[@metadata][index_prefix]" => "security-logs" }
    }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    
    # 动态设置索引和策略
    index => "%{[@metadata][index_prefix]}-%{+YYYY.MM.dd}-000001"
    ilm_policy => "%{[@metadata][ilm_policy]}"
    ilm_enabled => true
  }
}
```

---

## 5. 🗂️ 数据保留策略配置


### 5.1 为什么需要数据保留策略


> 💡 **生活类比**  
> 数据保留策略就像整理衣柜，经常穿的放前面，偶尔穿的放深处，很久不穿的捐掉，这样衣柜才不会爆满

**🎯 保留策略的目标**：
- **控制成本**：避免无限增长的存储费用
- **提升性能**：减少数据量提高查询速度
- **满足合规**：遵守数据保护法规要求
- **便于管理**：自动化处理，减少人工干预

### 5.2 基于业务的保留策略


**📊 不同类型日志的保留周期**：

| 日志类型 | **Hot期** | **Warm期** | **Cold期** | **保留期** | **原因** |
|---------|-----------|------------|------------|------------|----------|
| `应用日志` | `7天` | `30天` | `90天` | `1年` | `故障排查需要` |
| `安全日志` | `30天` | `90天` | `180天` | `7年` | `合规要求` |
| `访问日志` | `3天` | `14天` | `30天` | `90天` | `性能分析` |
| `调试日志` | `1天` | `7天` | `无` | `30天` | `开发调试` |

### 5.3 配置保留策略


```ruby
filter {
  # 根据日志级别设置保留策略
  if [level] == "ERROR" or [level] == "FATAL" {
    mutate {
      add_field => { "[@metadata][retention_policy]" => "long-term" }
    }
  } else if [level] == "DEBUG" {
    mutate {
      add_field => { "[@metadata][retention_policy]" => "short-term" }
    }
  } else {
    mutate {
      add_field => { "[@metadata][retention_policy]" => "standard" }
    }
  }
  
  # 安全相关日志特殊处理
  if [tags] and "security" in [tags] {
    mutate {
      replace => { "[@metadata][retention_policy]" => "compliance" }
    }
  }
}

output {
  # 根据保留策略选择不同的索引
  if [@metadata][retention_policy] == "long-term" {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "long-term-logs-%{+YYYY.MM.dd}"
      ilm_policy => "long-term-policy"
    }
  } else if [@metadata][retention_policy] == "short-term" {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "short-term-logs-%{+YYYY.MM.dd}"
      ilm_policy => "short-term-policy"
    }
  } else {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "standard-logs-%{+YYYY.MM.dd}"
      ilm_policy => "standard-policy"
    }
  }
}
```

### 5.4 自动化保留管理


**🤖 自动删除配置**：

```ruby
# 在output中配置自动删除
output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "temp-logs-%{+YYYY.MM.dd}"
    
    # 临时日志快速删除策略
    ilm_enabled => true
    ilm_policy => "temp-logs-policy"
    
    # 强制立即应用策略
    ilm_check_exists => false
  }
}

# 为调试日志配置最短保留期
if [logger_name] =~ /debug/ {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "debug-logs-%{+YYYY.MM.dd}"
    
    # 调试日志7天后删除
    ilm_policy => "debug-policy"
  }
}
```

**⚠️ 注意事项**：
- `合规性检查` 确保保留策略符合法规要求
- `业务确认` 与业务团队确认最小保留期限
- `监控告警` 设置存储空间告警，避免意外满盘
- `备份策略` 重要数据删除前要有备份

---

## 6. ⚡ 性能优化配置实战


### 6.1 Logstash性能瓶颈分析


> 🔍 **性能问题识别**  
> Logstash性能问题通常出现在三个地方：输入太慢、处理太复杂、输出太慢，就像水管系统中的不同堵塞点

**📊 性能指标监控**：
```
输入速度     处理速度     输出速度     内存使用
    |           |           |           |
  事件/秒 ──> 事件/秒 ──> 事件/秒 ──> MB/进程
    ↓           ↓           ↓           ↓
  目标值      目标值      目标值       监控值
```

### 6.2 批处理优化配置


```ruby
output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "optimized-logs-%{+YYYY.MM.dd}"
    
    # 批处理优化 - 关键性能参数
    workers => 4                    # 并发工作线程数
    flush_size => 1000             # 批量发送大小
    idle_flush_time => 5           # 空闲刷新时间(秒)
    
    # 连接池优化
    pool_max => 1000               # 最大连接数
    pool_max_per_route => 100      # 每个路由最大连接数
    
    # 请求优化
    request_timeout => 60          # 请求超时时间
    retry_initial_interval => 2    # 重试间隔
    retry_max_interval => 64       # 最大重试间隔
  }
}
```

**💡 参数调优说明**：
- `workers` 根据CPU核心数设置，通常为核心数的1-2倍
- `flush_size` 批量大小，越大效率越高但延迟增加
- `idle_flush_time` 确保数据及时发送，避免长时间积压

### 6.3 管道配置优化


```ruby
# logstash.yml 中的管道配置
pipeline.workers: 8               # 管道工作线程
pipeline.batch.size: 1000         # 批处理大小
pipeline.batch.delay: 50          # 批处理延迟(毫秒)

# JVM内存优化
-Xms4g                           # 初始堆内存
-Xmx4g                           # 最大堆内存
-XX:+UseG1GC                     # 使用G1垃圾收集器
```

### 6.4 多管道配置


**🔄 并行处理配置**：

```ruby
# pipelines.yml 配置文件
- pipeline.id: application-logs
  path.config: "/etc/logstash/conf.d/app-logs.conf"
  pipeline.workers: 4
  pipeline.batch.size: 500

- pipeline.id: security-logs  
  path.config: "/etc/logstash/conf.d/security-logs.conf"
  pipeline.workers: 2
  pipeline.batch.size: 200

- pipeline.id: metrics-logs
  path.config: "/etc/logstash/conf.d/metrics-logs.conf"
  pipeline.workers: 1
  pipeline.batch.size: 1000
```

### 6.5 内存和资源优化


```ruby
filter {
  # 避免内存泄漏的配置
  mutate {
    # 及时清理临时字段
    remove_field => [ "[@metadata][temp_field]" ]
  }
  
  # 优化正则表达式性能
  if [message] =~ /ERROR/ {
    grok {
      match => { "message" => "%{WORD:level} %{GREEDYDATA:content}" }
      # 使用命名捕获减少内存使用
      named_captures_only => true
      # 超时保护
      timeout_millis => 30000
    }
  }
  
  # 条件处理减少不必要的计算
  if [log_source] == "application" and [level] in ["ERROR", "FATAL"] {
    # 只对错误日志做复杂处理
    ruby {
      code => '
        # 复杂的处理逻辑
        event.set("processed_timestamp", Time.now.to_i)
      '
    }
  }
}
```

**🎯 性能优化最佳实践**：
- ✅ **合理分配资源**：CPU、内存根据数据量调整
- ✅ **避免复杂处理**：减少正则表达式和Ruby代码使用
- ✅ **使用条件判断**：只对需要的数据做处理
- ✅ **监控性能指标**：定期检查吞吐量和延迟

---

## 7. 🚨 监控告警集成


### 7.1 监控体系设计


> 📊 **监控理念**  
> 监控系统就像汽车的仪表盘，要让你随时知道系统是否正常运行，出现问题时能及时发现并处理

**🎯 监控层次架构**：
```
业务监控层
    |
  ├─错误率监控
  ├─响应时间监控  
  └─用户行为监控
    |
应用监控层
    |
  ├─应用性能监控
  ├─JVM监控
  └─接口监控
    |
基础设施监控层
    |
  ├─服务器监控
  ├─网络监控
  └─存储监控
```

### 7.2 Logstash监控配置


```ruby
# 监控数据收集配置
input {
  # 监听Logstash自身的监控数据
  http {
    port => 9600
    codec => json
    tags => ["logstash-monitoring"]
  }
  
  # Elasticsearch集群状态监控
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    query => '{ "query": { "range": { "@timestamp": { "gte": "now-1m" } } } }'
    index => ".monitoring-es-*"
    tags => ["elasticsearch-monitoring"]
  }
}

filter {
  if "logstash-monitoring" in [tags] {
    # 解析Logstash性能指标
    mutate {
      add_field => {
        "monitor_type" => "logstash_performance"
        "pipeline_id" => "%{[pipeline][id]}"
        "events_in" => "%{[pipeline][events][in]}"
        "events_out" => "%{[pipeline][events][out]}"
        "pipeline_workers" => "%{[pipeline][workers]}"
      }
    }
    
    # 计算处理延迟
    ruby {
      code => '
        events_in = event.get("[pipeline][events][in]").to_f
        events_out = event.get("[pipeline][events][out]").to_f
        if events_in > 0
          processing_efficiency = (events_out / events_in * 100).round(2)
          event.set("processing_efficiency", processing_efficiency)
        end
      '
    }
  }
}
```

### 7.3 告警规则配置


```ruby
filter {
  # 错误率告警
  if [level] == "ERROR" {
    metrics {
      meter => "error_rate"
      add_tag => "error_metric"
    }
  }
  
  # 响应时间告警
  if [response_time] and [response_time] > 5000 {
    mutate {
      add_field => {
        "alert_type" => "slow_response"
        "alert_level" => "warning"
        "alert_message" => "Response time exceeded 5 seconds: %{response_time}ms"
      }
      add_tag => ["alert", "performance"]
    }
  }
  
  # 磁盘空间告警
  if [disk_usage_percent] and [disk_usage_percent] > 85 {
    mutate {
      add_field => {
        "alert_type" => "disk_space"
        "alert_level" => "critical"  
        "alert_message" => "Disk usage is %{disk_usage_percent}%, exceeding 85% threshold"
      }
      add_tag => ["alert", "infrastructure"]
    }
  }
}

# 告警输出配置
output {
  # 发送告警到专门的索引
  if "alert" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "alerts-%{+YYYY.MM.dd}"
      
      # 告警数据结构化
      document_type => "_doc"
      document_id => "%{alert_type}-%{host}-%{+YYYY.MM.dd.HH.mm}"
    }
    
    # 发送到告警系统
    http {
      url => "http://alertmanager:9093/api/v1/alerts"
      http_method => "post"
      headers => { "Content-Type" => "application/json" }
      mapping => {
        "alerts" => [
          {
            "labels" => {
              "alertname" => "%{alert_type}"
              "severity" => "%{alert_level}"
              "instance" => "%{host}"
            }
            "annotations" => {
              "summary" => "%{alert_message}"
              "description" => "Alert triggered at %{@timestamp}"
            }
          }
        ]
      }
    }
  }
}
```

### 7.4 集成外部监控系统


**📡 Prometheus集成**：

```ruby
# 向Prometheus推送指标
output {
  if "metrics" in [tags] {
    http {
      url => "http://pushgateway:9091/metrics/job/logstash/instance/%{host}"
      http_method => "post"
      headers => { "Content-Type" => "text/plain" }
      
      # 构造Prometheus格式的指标
      format => "message"
      mapping => {
        "message" => "
          logstash_events_processed_total{pipeline=\"%{pipeline_id}\"} %{events_processed}
          logstash_processing_time_seconds{pipeline=\"%{pipeline_id}\"} %{processing_time}
          logstash_memory_usage_bytes{pipeline=\"%{pipeline_id}\"} %{memory_usage}
        "
      }
    }
  }
}
```

**📧 邮件告警集成**：

```ruby
output {
  if "alert" in [tags] and [alert_level] == "critical" {
    email {
      to => ["ops@company.com", "dev@company.com"]
      subject => "Critical Alert: %{alert_type} on %{host}"
      body => "
        Alert Details:
        - Type: %{alert_type}
        - Level: %{alert_level}
        - Host: %{host}
        - Message: %{alert_message}
        - Time: %{@timestamp}
        
        Please investigate immediately.
      "
      from => "logstash@company.com"
    }
  }
}
```

---

## 8. 👤 用户权限管理


### 8.1 理解ELK中的权限体系


> 🔐 **权限管理概念**  
> ELK的权限管理就像公司的门禁系统，不同的人有不同的访问权限，确保敏感数据只有授权人员才能查看

**🏢 权限层级结构**：
```
超级管理员
    |
    ├─ 系统管理员 (集群管理)
    ├─ 数据管理员 (索引管理)  
    ├─ 业务分析师 (只读权限)
    └─ 开发人员   (特定索引)
```

### 8.2 基于角色的权限配置


```ruby
filter {
  # 根据用户角色标记数据访问级别
  if [user_role] == "admin" {
    mutate {
      add_field => { "access_level" => "full" }
      add_field => { "data_classification" => "all" }
    }
  } else if [user_role] == "analyst" {
    mutate {
      add_field => { "access_level" => "read_only" }
      add_field => { "data_classification" => "business" }
    }
  } else if [user_role] == "developer" {
    mutate {
      add_field => { "access_level" => "limited" }
      add_field => { "data_classification" => "application" }
    }
  }
  
  # 敏感数据处理
  if [contains_pii] == "true" {
    if [user_role] != "admin" and [user_role] != "compliance_officer" {
      # 非授权用户的敏感数据脱敏
      mutate {
        gsub => [
          "message", "(\d{4}-\d{4}-\d{4}-)\d{4}", "\1****",  # 信用卡号脱敏
          "message", "(\w+)@(\w+\.\w+)", "***@\2"            # 邮箱脱敏
        ]
        add_tag => ["data_masked"]
      }
    }
  }
}
```

### 8.3 数据分级访问控制


**📊 数据分级策略**：

| 数据级别 | **包含内容** | **访问权限** | **索引模式** |
|---------|-------------|-------------|-------------|
| `公开` | `一般日志、统计数据` | `所有用户` | `public-*` |
| `内部` | `业务日志、性能数据` | `员工` | `internal-*` |
| `保密` | `用户数据、财务信息` | `授权人员` | `confidential-*` |
| `机密` | `安全日志、审计数据` | `管理员` | `restricted-*` |

```ruby
filter {
  # 数据分级处理
  if [log_type] == "user_activity" or [log_type] == "payment" {
    mutate {
      add_field => { "data_level" => "confidential" }
    }
  } else if [log_type] == "security" or [log_type] == "audit" {
    mutate {
      add_field => { "data_level" => "restricted" }
    }
  } else if [log_type] == "application" or [log_type] == "performance" {
    mutate {
      add_field => { "data_level" => "internal" }
    }
  } else {
    mutate {
      add_field => { "data_level" => "public" }
    }
  }
}

output {
  # 根据数据级别分别存储
  if [data_level] == "public" {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "public-logs-%{+YYYY.MM.dd}"
    }
  } else if [data_level] == "internal" {
    elasticsearch {
      hosts => ["elasticsearch:9200"] 
      index => "internal-logs-%{+YYYY.MM.dd}"
    }
  } else if [data_level] == "confidential" {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "confidential-logs-%{+YYYY.MM.dd}"
      # 增加额外的安全配置
      ssl => true
      ssl_certificate_verification => true
    }
  } else if [data_level] == "restricted" {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "restricted-logs-%{+YYYY.MM.dd}"
      ssl => true
      ssl_certificate_verification => true
      # 可能需要额外的认证
    }
  }
}
```

### 8.4 审计日志配置


```ruby
# 记录所有访问行为
filter {
  # 添加访问审计信息
  mutate {
    add_field => {
      "audit_timestamp" => "%{@timestamp}"
      "audit_user" => "%{[user][name]}"
      "audit_action" => "data_access"
      "audit_resource" => "%{index}"
      "audit_source_ip" => "%{[client][ip]}"
    }
  }
  
  # 特殊操作审计
  if [elasticsearch_action] == "delete" {
    mutate {
      replace => { "audit_action" => "data_deletion" }
      add_tag => ["audit", "critical_action"]
    }
  }
}

# 审计日志单独存储
output {
  if "audit" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "audit-logs-%{+YYYY.MM.dd}"
      
      # 审计日志永不删除
      ilm_enabled => false
      
      # 高可用配置
      document_type => "_doc"
      action => "create"  # 防止覆盖
    }
  }
}
```

---

## 9. 💾 备份恢复策略


### 9.1 为什么需要备份策略


> 💡 **备份重要性**  
> 数据备份就像买保险，平时看不出用处，但真正需要时能救命，特别是对于日志这种"删了就找不回来"的数据

**🎯 备份策略目标**：
- **数据安全**：防止意外删除或硬件故障
- **业务连续性**：快速恢复服务，减少停机时间
- **合规要求**：满足法规对数据保留的要求
- **灾难恢复**：应对自然灾害或重大故障

### 9.2 快照备份配置


```ruby
# 在Logstash中触发备份任务
filter {
  # 检查是否需要创建快照
  if [@timestamp] and [minute] == "0" and [hour] == "2" {
    # 每天凌晨2点触发备份
    mutate {
      add_field => { "trigger_backup" => "true" }
      add_tag => ["backup_trigger"]
    }
  }
  
  # 重要数据标记备份
  if [log_type] == "security" or [log_type] == "audit" {
    mutate {
      add_field => { "backup_priority" => "high" }
    }
  } else if [log_type] == "application" {
    mutate {
      add_field => { "backup_priority" => "medium" }
    }
  } else {
    mutate {
      add_field => { "backup_priority" => "low" }
    }
  }
}

output {
  # 备份触发信号
  if "backup_trigger" in [tags] {
    http {
      url => "http://backup-service:8080/api/trigger-snapshot"
      http_method => "post"
      headers => { "Content-Type" => "application/json" }
      mapping => {
        "snapshot_type" => "daily"
        "indices" => "logstash-*"
        "timestamp" => "%{@timestamp}"
      }
    }
  }
}
```

### 9.3 分级备份策略


**📅 备份频率规划**：

| 数据类型 | **备份频率** | **保留期限** | **存储位置** | **恢复时间** |
|---------|-------------|-------------|-------------|-------------|
| `审计日志` | `每天` | `7年` | `异地存储` | `< 4小时` |
| `安全日志` | `每天` | `1年` | `本地+异地` | `< 2小时` |
| `应用日志` | `每周` | `3个月` | `本地存储` | `< 1小时` |
| `调试日志` | `不备份` | `无` | `无` | `无` |

```ruby
filter {
  # 根据数据重要性设置备份策略
  if [data_classification] == "critical" {
    mutate {
      add_field => {
        "backup_frequency" => "daily"
        "backup_retention" => "7_years"
        "backup_location" => "offsite"
      }
    }
  } else if [data_classification] == "important" {
    mutate {
      add_field => {
        "backup_frequency" => "daily"
        "backup_retention" => "1_year"
        "backup_location" => "local_and_offsite"
      }
    }
  } else if [data_classification] == "normal" {
    mutate {
      add_field => {
        "backup_frequency" => "weekly"
        "backup_retention" => "3_months"
        "backup_location" => "local"
      }
    }
  }
}
```

### 9.4 备份验证和恢复测试


```ruby
# 备份验证配置
filter {
  if [event_type] == "backup_completed" {
    # 验证备份完整性
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      query => '{
        "query": {
          "bool": {
            "must": [
              {"term": {"backup_id": "%{backup_id}"}},
              {"range": {"@timestamp": {"gte": "now-1h"}}}
            ]
          }
        }
      }'
      index => "_snapshot"
    }
    
    ruby {
      code => '
        # 检查备份状态
        if event.get("backup_status") == "SUCCESS"
          event.set("backup_verified", true)
        else
          event.set("backup_verified", false)
          event.set("alert_type", "backup_failure")
        end
      '
    }
  }
}

# 自动恢复测试
output {
  if [backup_verified] == false {
    # 发送备份失败告警
    http {
      url => "http://alertmanager:9093/api/v1/alerts"
      http_method => "post"
      mapping => {
        "alerts" => [{
          "labels" => {
            "alertname" => "backup_failure"
            "severity" => "critical"
          },
          "annotations" => {
            "summary" => "Backup verification failed for %{backup_id}"
          }
        }]
      }
    }
  }
  
  # 定期恢复测试
  if [test_recovery] == true {
    elasticsearch {
      hosts => ["test-elasticsearch:9200"]
      index => "recovery-test-%{+YYYY.MM.dd}"
      # 在测试环境验证恢复功能
    }
  }
}
```

---

## 10. 📄 完整配置文件示例


### 10.1 生产环境完整配置


```ruby
# elk-stack-integration.conf - 生产环境ELK栈集成配置

input {
  # Beats输入
  beats {
    port => 5044
    client_inactivity_timeout => 86400
  }
  
  # Syslog输入
  syslog {
    port => 514
    tags => ["syslog"]
  }
  
  # HTTP API输入
  http {
    port => 8080
    codec => json
    tags => ["api"]
  }
}

filter {
  # 添加处理时间戳
  mutate {
    add_field => { "[@metadata][processing_start]" => "%{+UNIX}" }
  }
  
  # 根据来源分类处理
  if [fields][log_type] {
    mutate {
      add_field => { "log_type" => "%{[fields][log_type]}" }
    }
  }
  
  # 应用日志处理
  if [log_type] == "application" {
    grok {
      match => { 
        "message" => "%{TIMESTAMP_ISO8601:timestamp} \[%{LOGLEVEL:level}\] %{GREEDYDATA:content}" 
      }
    }
    
    date {
      match => [ "timestamp", "ISO8601" ]
    }
    
    # 性能数据提取
    if [content] =~ /response_time/ {
      grok {
        match => { "content" => "response_time: %{NUMBER:response_time:float}" }
      }
    }
    
    # 错误分析
    if [level] == "ERROR" {
      mutate {
        add_field => { "severity_numeric" => "1" }
        add_tag => ["error", "alert"]
      }
    } else if [level] == "WARN" {
      mutate {
        add_field => { "severity_numeric" => "2" }
      }
    }
  }
  
  # 安全日志处理
  else if [log_type] == "security" {
    grok {
      match => { 
        "message" => "%{IPORHOST:client_ip} - - \[%{HTTPDATE:timestamp}\] \"%{WORD:method} %{URIPATH:request} HTTP/%{NUMBER:http_version}\" %{NUMBER:response_code:int} %{NUMBER:bytes:int}" 
      }
    }
    
    # 地理位置分析
    if [client_ip] {
      geoip {
        source => "client_ip"
        target => "geoip"
      }
    }
    
    # 异常检测
    if [response_code] >= 400 {
      mutate {
        add_tag => ["http_error", "security_alert"]
      }
    }
  }
  
  # 数据分级
  if [log_type] == "security" or [log_type] == "audit" {
    mutate {
      add_field => { "data_classification" => "restricted" }
      add_field => { "retention_policy" => "long_term" }
    }
  } else if [log_type] == "application" {
    mutate {
      add_field => { "data_classification" => "internal" }
      add_field => { "retention_policy" => "standard" }
    }
  }
  
  # 用户权限标记
  if [user_id] {
    if [user_role] == "admin" {
      mutate {
        add_field => { "access_level" => "full" }
      }
    } else {
      # 敏感数据脱敏
      mutate {
        gsub => [
          "message", "password=\w+", "password=***",
          "message", "token=[\w\-]+", "token=***"
        ]
        add_tag => ["data_masked"]
      }
    }
  }
  
  # 计算处理时间
  ruby {
    code => '
      start_time = event.get("[@metadata][processing_start]").to_f
      current_time = Time.now.to_f
      processing_time = ((current_time - start_time) * 1000).round(2)
      event.set("[@metadata][processing_time_ms]", processing_time)
    '
  }
  
  # 清理临时字段
  mutate {
    remove_field => [ "[@metadata][processing_start]" ]
  }
}

output {
  # 根据数据分级输出到不同索引
  if [data_classification] == "restricted" {
    elasticsearch {
      hosts => ["es-secure-1:9200", "es-secure-2:9200", "es-secure-3:9200"]
      index => "restricted-logs-%{+YYYY.MM.dd}"
      
      # 安全连接配置
      ssl => true
      ssl_certificate_verification => true
      
      # 高可用配置
      workers => 2
      flush_size => 500
      
      # ILM策略
      ilm_enabled => true
      ilm_policy => "restricted-logs-policy"
      
      # 性能优化
      pool_max => 500
      timeout => 60
    }
  }
  
  else if [data_classification] == "internal" {
    elasticsearch {
      hosts => ["es-cluster-1:9200", "es-cluster-2:9200", "es-cluster-3:9200"]
      index => "internal-logs-%{+YYYY.MM.dd}"
      
      # 标准配置
      workers => 4
      flush_size => 1000
      idle_flush_time => 5
      
      # ILM策略
      ilm_enabled => true
      ilm_policy => "standard-logs-policy"
      
      # 性能优化
      pool_max => 1000
      retry_max_interval => 5
    }
  }
  
  else {
    elasticsearch {
      hosts => ["es-general:9200"]
      index => "general-logs-%{+YYYY.MM.dd}"
      
      # 基础配置
      workers => 2
      flush_size => 2000
      
      ilm_enabled => true
      ilm_policy => "short-term-policy"
    }
  }
  
  # 错误和告警单独处理
  if "alert" in [tags] {
    elasticsearch {
      hosts => ["es-monitoring:9200"]
      index => "alerts-%{+YYYY.MM.dd}"
      
      # 实时处理
      flush_size => 1
      idle_flush_time => 1
    }
    
    # 发送到告警系统
    http {
      url => "http://alertmanager:9093/api/v1/alerts"
      http_method => "post"
      headers => { "Content-Type" => "application/json" }
      mapping => {
        "alerts" => [{
          "labels" => {
            "alertname" => "%{log_type}_alert"
            "severity" => "%{level}"
            "instance" => "%{host}"
          },
          "annotations" => {
            "summary" => "%{message}",
            "description" => "Alert from %{log_type} at %{@timestamp}"
          }
        }]
      }
    }
  }
  
  # 性能监控数据
  if "performance" in [tags] {
    elasticsearch {
      hosts => ["es-metrics:9200"]
      index => "performance-metrics-%{+YYYY.MM.dd}"
      
      # 批量处理
      flush_size => 5000
      workers => 1
    }
  }
  
  # 调试输出（开发环境）
  if [@metadata][debug] == "true" {
    stdout {
      codec => rubydebug {
        metadata => true
      }
    }
  }
}
```

### 10.2 配置文件使用说明


**🚀 部署步骤**：

1. **环境准备**：
```bash
# 创建配置目录
mkdir -p /etc/logstash/conf.d/

# 复制配置文件
cp elk-stack-integration.conf /etc/logstash/conf.d/
```

2. **权限设置**：
```bash
# 设置文件权限
chmod 644 /etc/logstash/conf.d/elk-stack-integration.conf
chown logstash:logstash /etc/logstash/conf.d/elk-stack-integration.conf
```

3. **配置验证**：
```bash
# 验证配置语法
/usr/share/logstash/bin/logstash --config.test_and_exit --path.config=/etc/logstash/conf.d/

# 启动Logstash
systemctl start logstash
systemctl enable logstash
```

**⚙️ 配置调优建议**：
- 根据实际硬件调整`workers`和`flush_size`参数
- 监控`[@metadata][processing_time_ms]`优化性能
- 定期检查Elasticsearch集群状态
- 根据数据量调整ILM策略

---

## 11. 📋 核心要点总结


### 11.1 必须掌握的关键概念


> 🎯 **ELK栈集成精髓**  
> 理解ELK不是三个独立工具的简单组合，而是一个有机的数据处理生态系统

**🔸 核心概念回顾**：
```
ELK工作流：数据收集 → 处理转换 → 存储索引 → 可视化分析
集群架构：多节点协作，高可用性，负载均衡
生命周期：Hot → Warm → Cold → Delete，自动化管理
权限体系：基于角色的访问控制，数据分级保护
监控告警：实时监控，主动告警，快速响应
备份恢复：定期备份，验证完整性，灾难恢复
```

### 11.2 关键技术要点


**💡 技术实现要点**：
- **连接配置**：`多节点配置` 确保高可用性
- **性能优化**：`批处理` + `并发` + `连接池` 提升效率  
- **数据管理**：`ILM策略` 自动化生命周期管理
- **安全控制**：`分级存储` + `权限控制` + `数据脱敏`
- **监控体系**：`指标收集` + `告警规则` + `可视化展示`

### 11.3 最佳实践总结


**🎯 生产环境最佳实践**：

✅ **架构设计**：
- 集群规划要考虑未来3-5年的数据增长
- 分离计算和存储，便于独立扩容
- 网络规划要保证低延迟高带宽

✅ **性能优化**：
- 根据数据特点调整批处理大小
- 监控CPU、内存、磁盘IO指标
- 定期清理无用索引和数据

✅ **安全管理**：
- 敏感数据必须加密传输和存储
- 实施最小权限原则
- 定期审计用户访问行为

✅ **运维管理**：
- 建立完善的监控告警体系
- 制定详细的故障应急预案
- 定期进行备份恢复演练

### 11.4 常见问题和解决方案


**🔍 故障排查指南**：

| 问题类型 | **症状** | **可能原因** | **解决方案** |
|---------|---------|-------------|-------------|
| `性能慢` | `处理延迟高` | `批处理配置不当` | `调整flush_size和workers` |
| `连接失败` | `无法连接ES` | `网络或认证问题` | `检查网络和SSL配置` |
| `内存溢出` | `OOM错误` | `JVM配置不当` | `增加堆内存或优化配置` |
| `数据丢失` | `部分日志缺失` | `缓冲区溢出` | `增加队列大小或处理速度` |

**🧠 记忆要点**：
- **三个E的协作**：Elasticsearch存储，Logstash处理，Kibana展示
- **四个阶段管理**：Hot温热数据，Warm温数据，Cold冷数据，Delete删除
- **五个层面优化**：输入、过滤、输出、网络、存储全方位优化
- **安全第一原则**：数据分级、权限控制、审计跟踪、备份恢复

### 11.5 学习建议和发展路径


**📚 进阶学习路径**：
1. **基础阶段**：熟练掌握ELK三组件的基本使用
2. **实践阶段**：在测试环境搭建完整的ELK栈
3. **优化阶段**：学习性能调优和故障排查
4. **专家阶段**：设计大规模生产环境架构

**🔗 相关技术扩展**：
- **Beats家族**：Filebeat、Metricbeat等数据采集器
- **X-Pack**：安全、监控、报表等企业级功能
- **Machine Learning**：异常检测和智能分析
- **APM**：应用性能监控和分布式追踪

**核心记忆口诀**：
> ELK三剑客，数据处理不用愁  
> 集群高可用，性能优化要持续  
> 安全第一位，监控告警不能少  
> 备份要及时，恢复测试常演练