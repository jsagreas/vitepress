---
title: 19、kafka-output.conf 输出配置
---
## 📚 目录

1. [Kafka输出插件概述](#1-kafka输出插件概述)
2. [基础连接配置](#2-基础连接配置)
3. [主题和分区策略](#3-主题和分区策略)
4. [序列化与压缩配置](#4-序列化与压缩配置)
5. [性能优化配置](#5-性能优化配置)
6. [可靠性保障配置](#6-可靠性保障配置)
7. [实战配置示例](#7-实战配置示例)
8. [核心要点总结](#8-核心要点总结)

---

## 1. 🎯 Kafka输出插件概述


### 1.1 什么是Kafka输出插件


**🔸 基本概念**
Kafka输出插件是Logstash的一个输出组件，它的作用就是**把处理好的数据发送到Kafka消息队列中**。

```
简单理解：
数据 → Logstash处理 → Kafka输出插件 → 发送到Kafka → 其他系统消费

就像邮递员把信件投递到指定的邮箱一样
Logstash把数据投递到指定的Kafka主题中
```

**💡 为什么要用Kafka输出**
- **解耦系统**：数据生产者和消费者不直接连接
- **缓冲作用**：Kafka可以暂存大量数据，防止数据丢失
- **扩展性好**：可以有多个消费者处理同一份数据
- **高可靠**：Kafka支持数据持久化和副本机制

### 1.2 工作流程图解


```
┌─────────────┐    ┌──────────────┐    ┌─────────────────┐
│  数据源     │───▶│  Logstash    │───▶│   Kafka集群     │
│ (日志文件)   │    │   处理       │    │   ┌───────────┐ │
└─────────────┘    │   ↓          │    │   │ Topic A   │ │
                   │ Filter过滤   │    │   └───────────┘ │
                   │   ↓          │    │   ┌───────────┐ │
                   │ Output输出   │    │   │ Topic B   │ │
                   └──────────────┘    │   └───────────┘ │
                                       └─────────────────┘
                                                ↓
                                       ┌─────────────────┐
                                       │   消费者应用     │
                                       │ (分析/存储系统)  │
                                       └─────────────────┘
```

### 1.3 插件核心功能


| 功能类别 | **作用说明** | **配置复杂度** |
|---------|-------------|---------------|
| 🔗 **连接管理** | `连接Kafka集群，管理连接状态` | ⭐⭐ |
| 📤 **数据发送** | `将数据发送到指定主题` | ⭐ |
| 🎯 **分区路由** | `决定数据发送到哪个分区` | ⭐⭐⭐ |
| 🗜️ **数据压缩** | `减少网络传输数据量` | ⭐⭐ |
| 🔄 **错误重试** | `发送失败时自动重试` | ⭐⭐⭐ |

---

## 2. 🔌 基础连接配置


### 2.1 Kafka集群地址配置


**🔸 bootstrap_servers 配置**
这是最重要的配置，告诉Logstash去哪里找Kafka集群。

```ruby
output {
  kafka {
    # 基础配置：Kafka集群地址
    bootstrap_servers => "192.168.1.10:9092,192.168.1.11:9092,192.168.1.12:9092"
    
    # 目标主题
    topic_id => "logstash-logs"
  }
}
```

> 💡 **配置说明**  
> `bootstrap_servers` 就像**电话号码簿**，Logstash通过这些地址找到Kafka集群。即使只写一个地址，Kafka也会自动发现其他节点。

**🔸 单机vs集群配置对比**

| 部署方式 | **配置示例** | **使用场景** |
|---------|-------------|-------------|
| 🖥️ **单机** | `"localhost:9092"` | `开发测试环境` |
| 🏢 **集群** | `"host1:9092,host2:9092,host3:9092"` | `生产环境` |
| 🔒 **安全集群** | `"host1:9093,host2:9093"` | `启用SSL的生产环境` |

### 2.2 认证配置


**🔸 SASL认证配置**
当Kafka启用了安全认证时，需要提供用户名和密码。

```ruby
output {
  kafka {
    bootstrap_servers => "kafka1:9092,kafka2:9092"
    topic_id => "secure-logs"
    
    # SASL认证配置
    security_protocol => "SASL_PLAINTEXT"
    sasl_mechanism => "PLAIN"
    sasl_jaas_config => "org.apache.kafka.common.security.plain.PlainLoginModule required username='logstash' password='your-password';"
  }
}
```

### 2.3 连接超时配置


```ruby
output {
  kafka {
    bootstrap_servers => "kafka1:9092"
    topic_id => "my-topic"
    
    # 连接相关配置
    request_timeout_ms => 30000        # 请求超时30秒
    connections_max_idle_ms => 600000  # 连接最大空闲10分钟
    reconnect_backoff_ms => 1000       # 重连间隔1秒
  }
}
```

---

## 3. 🎯 主题和分区策略


### 3.1 主题配置详解


**🔸 静态主题配置**
最简单的方式，所有数据都发送到同一个主题。

```ruby
output {
  kafka {
    bootstrap_servers => "localhost:9092"
    # 固定主题名称
    topic_id => "application-logs"
  }
}
```

**🔸 动态主题配置**
根据数据内容动态选择主题，这样可以**按类型分类存储**。

```ruby
output {
  kafka {
    bootstrap_servers => "localhost:9092"
    # 根据日志级别动态选择主题
    topic_id => "logs-%{[level]}"
    # 如果level是"error"，则发送到"logs-error"主题
    # 如果level是"info"，则发送到"logs-info"主题
  }
}
```

### 3.2 分区策略配置


**🔸 分区的作用**
分区就像**停车场的不同区域**，可以并行处理数据，提高性能。

```
Kafka主题分区示意：
Topic: user-logs
├── Partition 0: [msg1, msg4, msg7...]
├── Partition 1: [msg2, msg5, msg8...]
└── Partition 2: [msg3, msg6, msg9...]
```

**🔸 分区键配置**

```ruby
output {
  kafka {
    bootstrap_servers => "localhost:9092"
    topic_id => "user-activities"
    
    # 按用户ID分区，确保同一用户的数据在同一分区
    partition_key_format => "%{[user_id]}"
  }
}
```

> ⚠️ **重要提醒**  
> 使用分区键的好处是**保证顺序**：同一个用户的所有消息会按顺序存储在同一分区中。

**🔸 分区策略对比**

| 策略类型 | **配置方法** | **适用场景** | **优缺点** |
|---------|-------------|-------------|-----------|
| 🎲 **随机分区** | `不设置partition_key_format` | `不关心顺序，追求吞吐量` | `性能好，但无顺序保证` |
| 🔑 **按键分区** | `partition_key_format => "%{[user_id]}}"` | `需要保证特定数据有序` | `有序保证，但可能数据倾斜` |
| 📍 **指定分区** | `partition => 1` | `特殊数据需要专门处理` | `精确控制，但灵活性差` |

### 3.3 主题自动创建配置


```ruby
output {
  kafka {
    bootstrap_servers => "localhost:9092"
    topic_id => "auto-created-topic"
    
    # 主题自动创建配置
    allow_auto_create_topics => true
    auto_create_topics_partitions => 3    # 自动创建时的分区数
    auto_create_topics_replication_factor => 2  # 副本因子
  }
}
```

---

## 4. 🗜️ 序列化与压缩配置


### 4.1 消息格式配置


**🔸 什么是序列化**
序列化就是把Logstash处理的数据**转换成Kafka能理解的格式**，就像把中文翻译成英文一样。

```ruby
output {
  kafka {
    bootstrap_servers => "localhost:9092"
    topic_id => "formatted-logs"
    
    # 消息格式配置
    codec => json {
      charset => "UTF-8"
    }
  }
}
```

**🔸 支持的序列化格式**

| 格式类型 | **配置示例** | **适用场景** | **特点** |
|---------|-------------|-------------|---------|
| 📄 **JSON** | `codec => json` | `结构化数据，易于解析` | `可读性好，支持嵌套` |
| 📝 **纯文本** | `codec => plain` | `简单日志，原始格式` | `最小开销，保持原样` |
| 🗜️ **Avro** | `codec => avro` | `高性能场景，模式演进` | `紧凑格式，类型安全` |

### 4.2 压缩配置详解


**🔸 压缩的好处**
压缩可以**减少网络传输量**，就像把大文件压缩成ZIP包再发送。

```ruby
output {
  kafka {
    bootstrap_servers => "localhost:9092"
    topic_id => "compressed-logs"
    
    # 压缩配置
    compression_type => "gzip"  # 使用gzip压缩
  }
}
```

**🔸 压缩算法对比**

| 压缩算法 | **压缩比** | **CPU消耗** | **适用场景** |
|---------|-----------|-------------|-------------|
| 🚫 **none** | `1:1` | `最低` | `网络带宽充足，追求速度` |
| ⚡ **snappy** | `1:2` | `低` | `平衡性能和压缩比` |
| 🗜️ **gzip** | `1:3` | `中等` | `网络带宽受限，常用选择` |
| 🔥 **lz4** | `1:2.5` | `很低` | `高吞吐量场景` |

### 4.3 字符编码配置


```ruby
output {
  kafka {
    bootstrap_servers => "localhost:9092"
    topic_id => "unicode-logs"
    
    # 字符编码配置
    codec => json {
      charset => "UTF-8"        # 支持中文等Unicode字符
    }
    
    # 键的序列化（如果使用分区键）
    key_serializer => "org.apache.kafka.common.serialization.StringSerializer"
    value_serializer => "org.apache.kafka.common.serialization.StringSerializer"
  }
}
```

---

## 5. ⚡ 性能优化配置


### 5.1 批处理配置


**🔸 什么是批处理**
批处理就是**攒一批数据再一起发送**，而不是来一条发一条。就像坐公交车，等人坐满了再开车，效率更高。

```ruby
output {
  kafka {
    bootstrap_servers => "localhost:9092"
    topic_id => "batch-logs"
    
    # 批处理大小配置
    batch_size => 16384          # 每批16KB数据
    buffer_memory => 33554432    # 缓冲区32MB
    linger_ms => 100            # 最多等待100毫秒
  }
}
```

**🔸 批处理参数详解**

```
批处理工作原理：

时间轴：
0ms    50ms   100ms  150ms  200ms
│      │      │      │      │
├──────┼──────┤      │      │  ← 100ms内积累数据
              │      │      │
              发送   │      │
                    ├──────┼──────┤ ← 下一批开始
                                  │
                                  发送

条件：
- 数据量达到batch_size：立即发送
- 时间达到linger_ms：无论多少数据都发送
- 缓冲区快满：强制发送
```

### 5.2 并发和线程配置


```ruby
output {
  kafka {
    bootstrap_servers => "localhost:9092"
    topic_id => "high-throughput-logs"
    
    # 并发配置
    workers => 4                    # 使用4个工作线程
    
    # 生产者配置
    max_in_flight_requests_per_connection => 5  # 每个连接最多5个未确认请求
    send_buffer_bytes => 131072     # 发送缓冲区128KB
    receive_buffer_bytes => 65536   # 接收缓冲区64KB
  }
}
```

### 5.3 内存和缓冲优化


```ruby
output {
  kafka {
    bootstrap_servers => "localhost:9092"
    topic_id => "optimized-logs"
    
    # 内存管理
    buffer_memory => 67108864       # 总缓冲区64MB
    max_block_ms => 60000          # 缓冲区满时最多阻塞60秒
    
    # 元数据缓存
    metadata_max_age_ms => 300000   # 元数据缓存5分钟
  }
}
```

---

## 6. 🛡️ 可靠性保障配置


### 6.1 确认机制配置


**🔸 什么是确认机制**
确认机制就是**确保消息真的发送成功了**，就像发快递要求签收确认一样。

```ruby
output {
  kafka {
    bootstrap_servers => "localhost:9092"
    topic_id => "reliable-logs"
    
    # 确认级别配置
    acks => "all"               # 等待所有副本确认（最安全）
    enable_idempotence => true  # 启用幂等性，防止重复
  }
}
```

**🔸 确认级别对比**

| 确认级别 | **配置值** | **可靠性** | **性能** | **使用场景** |
|---------|-----------|-----------|---------|-------------|
| 🚫 **无确认** | `acks => "0"` | `最低` | `最高` | `日志收集，丢失可接受` |
| 👤 **主节点确认** | `acks => "1"` | `中等` | `中等` | `一般业务数据` |
| 👥 **全部确认** | `acks => "all"` | `最高` | `最低` | `重要业务数据` |

### 6.2 重试机制配置


```ruby
output {
  kafka {
    bootstrap_servers => "localhost:9092"
    topic_id => "retry-logs"
    
    # 重试配置
    retries => 3                    # 最多重试3次
    retry_backoff_ms => 1000        # 重试间隔1秒
    max_in_flight_requests_per_connection => 1  # 保证顺序
    
    # 请求超时
    request_timeout_ms => 30000     # 请求超时30秒
    delivery_timeout_ms => 120000   # 投递超时2分钟
  }
}
```

### 6.3 错误处理配置


```ruby
output {
  kafka {
    bootstrap_servers => "localhost:9092"
    topic_id => "main-logs"
    
    # 基本配置...
  }
  
  # 备用输出：当Kafka失败时写入文件
  if "_kafkaoutputfailure" in [tags] {
    file {
      path => "/var/log/logstash/kafka-failures.log"
      codec => json_lines
    }
  }
}
```

---

## 7. 🚀 实战配置示例


### 7.1 基础日志收集配置


```ruby
# 基础Web日志收集到Kafka
input {
  file {
    path => "/var/log/nginx/access.log"
    start_position => "beginning"
  }
}

filter {
  grok {
    match => { "message" => "%{COMMONAPACHELOG}" }
  }
  
  date {
    match => [ "timestamp", "dd/MMM/yyyy:HH:mm:ss Z" ]
  }
}

output {
  kafka {
    bootstrap_servers => "kafka1:9092,kafka2:9092"
    topic_id => "nginx-access-logs"
    
    # 基础配置
    codec => json
    compression_type => "gzip"
    
    # 性能配置
    batch_size => 16384
    linger_ms => 100
    
    # 可靠性配置
    acks => "1"
    retries => 3
  }
}
```

### 7.2 多环境动态路由配置


```ruby
# 根据环境和日志级别动态路由
output {
  kafka {
    bootstrap_servers => "kafka-cluster:9092"
    
    # 动态主题：环境-服务-级别
    topic_id => "%{[environment]}-%{[service]}-%{[level]}"
    
    # 按服务实例分区，保证同一实例日志有序
    partition_key_format => "%{[service_instance]}"
    
    # 格式和压缩
    codec => json {
      charset => "UTF-8"
    }
    compression_type => "snappy"
    
    # 高性能配置
    batch_size => 32768
    linger_ms => 50
    buffer_memory => 67108864
    workers => 2
    
    # 高可靠配置
    acks => "all"
    enable_idempotence => true
    max_in_flight_requests_per_connection => 1
  }
}
```

### 7.3 高吞吐量生产环境配置


```ruby
# 高吞吐量生产环境配置
output {
  kafka {
    # 集群配置
    bootstrap_servers => [
      "kafka1.prod:9092",
      "kafka2.prod:9092", 
      "kafka3.prod:9092"
    ]
    
    topic_id => "prod-application-logs"
    
    # 序列化和压缩
    codec => json
    compression_type => "lz4"  # 高性能压缩
    
    # 高吞吐量配置
    batch_size => 65536        # 64KB批处理
    linger_ms => 10           # 快速发送
    buffer_memory => 134217728 # 128MB缓冲区
    workers => 8              # 8个工作线程
    
    # 网络优化
    send_buffer_bytes => 262144    # 256KB发送缓冲
    receive_buffer_bytes => 131072 # 128KB接收缓冲
    max_in_flight_requests_per_connection => 5
    
    # 平衡可靠性和性能
    acks => "1"
    retries => 2
    retry_backoff_ms => 500
    request_timeout_ms => 20000
    
    # 监控配置
    enable_metrics => true
  }
}
```

### 7.4 安全生产环境配置


```ruby
# 启用SASL+SSL的安全配置
output {
  kafka {
    bootstrap_servers => "secure-kafka:9093"
    topic_id => "secure-audit-logs"
    
    # 安全配置
    security_protocol => "SASL_SSL"
    sasl_mechanism => "SCRAM-SHA-256"
    sasl_jaas_config => "org.apache.kafka.common.security.scram.ScramLoginModule required username='logstash-prod' password='${KAFKA_PASSWORD}';"
    
    # SSL配置
    ssl_truststore_location => "/etc/kafka/ssl/truststore.jks"
    ssl_truststore_password => "${TRUSTSTORE_PASSWORD}"
    ssl_keystore_location => "/etc/kafka/ssl/keystore.jks"
    ssl_keystore_password => "${KEYSTORE_PASSWORD}"
    
    # 数据格式
    codec => json
    compression_type => "gzip"
    
    # 高可靠性配置
    acks => "all"
    enable_idempotence => true
    retries => 5
    retry_backoff_ms => 2000
    
    # 性能平衡
    batch_size => 16384
    linger_ms => 100
    buffer_memory => 33554432
  }
}
```

---

## 8. 📋 核心要点总结


### 8.1 必须掌握的基本配置


```
🔸 连接配置：bootstrap_servers（Kafka集群地址）
🔸 主题配置：topic_id（数据发送的目标主题）  
🔸 格式配置：codec（消息序列化格式）
🔸 确认配置：acks（消息确认级别）
🔸 重试配置：retries（失败重试次数）
```

### 8.2 性能优化关键配置


**⚡ 吞吐量优化清单**
- [x] `batch_size` 增大批处理大小（推荐16KB-64KB）
- [x] `linger_ms` 设置合理等待时间（推荐10-100ms）  
- [x] `compression_type` 启用压缩（推荐snappy或lz4）
- [x] `workers` 增加工作线程数
- [x] `buffer_memory` 增大缓冲区内存

### 8.3 可靠性保障配置要点


**🛡️ 数据安全配置建议**

| 重要程度 | **配置项** | **推荐值** | **说明** |
|---------|-----------|-----------|---------|
| 🔥 **极重要** | `acks` | `"all"` | `等待所有副本确认` |
| 🔥 **极重要** | `enable_idempotence` | `true` | `防止消息重复` |
| 🔥 **重要** | `retries` | `3-5` | `失败重试次数` |
| 💡 **建议** | `max_in_flight_requests_per_connection` | `1` | `保证消息顺序` |

### 8.4 常见问题和解决方案


**❓ 问题：消息发送很慢**
```
解决方案：
1. 增大 batch_size（如32KB）
2. 降低 linger_ms（如50ms）
3. 启用压缩减少网络传输
4. 增加 workers 并发数
```

**❓ 问题：消息可能丢失**
```
解决方案：
1. 设置 acks => "all"
2. 启用 enable_idempotence => true
3. 增加 retries 重试次数
4. 配置备用输出（如文件）
```

**❓ 问题：消息顺序乱了**
```
解决方案：
1. 设置 max_in_flight_requests_per_connection => 1
2. 使用分区键保证相关消息在同一分区
3. 启用幂等性配置
```

### 8.5 配置模板参考


**📄 生产环境基础模板**
```ruby
output {
  kafka {
    # === 必需配置 ===
    bootstrap_servers => "your-kafka-cluster:9092"
    topic_id => "your-topic-name"
    
    # === 推荐配置 ===
    codec => json
    compression_type => "snappy"
    acks => "1"
    retries => 3
    
    # === 性能配置 ===
    batch_size => 16384
    linger_ms => 100
    workers => 2
  }
}
```

**核心记忆口诀**：
- 连接集群先配好，主题名称不能少
- 格式压缩提性能，确认重试保可靠  
- 批处理等待要平衡，工作线程来并发
- 生产环境要谨慎，监控日志不能忘