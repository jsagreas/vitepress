---
title: 9、kafka-input.conf Kafka输入配置
---
## 📚 目录

1. [Kafka输入概述](#1-kafka输入概述)
2. [核心配置参数详解](#2-核心配置参数详解)
3. [完整配置文件示例](#3-完整配置文件示例)
4. [集群配置与高可用](#4-集群配置与高可用)
5. [消费者组管理](#5-消费者组管理)
6. [性能调优配置](#6-性能调优配置)
7. [监控与故障排查](#7-监控与故障排查)
8. [实战配置样例](#8-实战配置样例)
9. [核心要点总结](#9-核心要点总结)

---

## 1. 🎯 Kafka输入概述


### 1.1 什么是Kafka输入插件


**简单理解**：Kafka输入插件就是让Logstash能够从Kafka消息队列中读取数据的"接收器"

```
数据流向示意图：
应用程序 → Kafka集群 → Logstash → Elasticsearch
   |          |          |           |
 产生日志   存储消息   处理数据    索引存储
```

**核心作用**：
- 📨 **消息接收**：从Kafka主题中消费消息
- 🔄 **实时处理**：持续监听和处理新消息
- ⚖️ **负载均衡**：多个Logstash实例协同工作
- 🛡️ **容错机制**：支持断点续传和重试

### 1.2 为什么使用Kafka作为输入源


**业务场景优势**：
```
传统方式问题：
应用 → 直接写入Elasticsearch
• 写入失败会丢数据
• 高峰期可能压垮ES
• 无法灵活处理数据

Kafka缓冲方式：
应用 → Kafka → Logstash → Elasticsearch
• 削峰填谷，平滑处理
• 数据不丢失，可重放
• 灵活的数据处理管道
```

**核心优势**：
- 🚀 **高吞吐量**：支持每秒百万级消息处理
- 💾 **持久化存储**：消息可靠存储，不怕丢失
- 📈 **水平扩展**：轻松增加分区和消费者
- ⏰ **实时性好**：毫秒级消息传递延迟

---

## 2. 🔧 核心配置参数详解


### 2.1 集群连接配置


#### bootstrap_servers - 集群地址配置


**含义解释**：这是告诉Logstash"Kafka集群在哪里"的配置，就像给快递员一个地址列表

```ruby
input {
  kafka {
    # 基础配置：单个服务器
    bootstrap_servers => "localhost:9092"
    
    # 生产环境：多个服务器（推荐）
    bootstrap_servers => ["kafka1:9092", "kafka2:9092", "kafka3:9092"]
  }
}
```

> 💡 **新手理解**：
> - 只需要配置部分Kafka节点地址，不用全部
> - Logstash会自动发现集群中的其他节点
> - 建议至少配置2-3个节点地址，防止单点故障

**配置最佳实践**：
```
单机测试环境：
bootstrap_servers => "localhost:9092"

小规模生产环境：
bootstrap_servers => ["kafka1:9092", "kafka2:9092"]

大规模集群环境：
bootstrap_servers => ["kafka1:9092", "kafka2:9092", "kafka3:9092"]
```

### 2.2 主题订阅配置


#### topics - 订阅主题列表


**通俗解释**：topics就是你要"订阅"的消息频道，就像订阅不同的微信群消息

```ruby
input {
  kafka {
    # 订阅单个主题
    topics => ["application-logs"]
    
    # 订阅多个主题
    topics => ["web-logs", "app-logs", "error-logs"]
    
    # 使用正则表达式匹配主题
    topics_pattern => "log-.*"
  }
}
```

**主题选择策略**：
- 📝 **按应用分类**：`web-logs`, `api-logs`, `db-logs`
- 📊 **按级别分类**：`info-logs`, `error-logs`, `debug-logs`
- 🏢 **按业务分类**：`order-logs`, `user-logs`, `payment-logs`

### 2.3 消费者组配置


#### group_id - 消费者组标识


**简单理解**：group_id就像给一群协同工作的Logstash实例起个"团队名字"

```ruby
input {
  kafka {
    group_id => "logstash-cluster-01"
    # 同一个group_id的多个Logstash实例会协同消费消息
    # 每条消息只会被组内一个实例处理
  }
}
```

**消费者组工作原理**：
```
Kafka主题分区分配示意：
主题: web-logs (3个分区)
┌─分区0─┐  ┌─分区1─┐  ┌─分区2─┐
│ 消息A │  │ 消息B │  │ 消息C │
│ 消息D │  │ 消息E │  │ 消息F │
└───────┘  └───────┘  └───────┘
    ↓          ↓          ↓
Logstash-1  Logstash-2  Logstash-3
(同一group_id)
```

> ⚠️ **重要提醒**：
> - 相同group_id的实例会分摊消息，避免重复处理
> - 不同group_id的实例会各自独立消费全部消息
> - 消费者数量不要超过分区数量

### 2.4 偏移量管理配置


#### auto_offset_reset - 偏移量重置策略


**通俗解释**：当Logstash第一次连接或者断线重连时，从哪里开始读取消息

```ruby
input {
  kafka {
    # 从最新消息开始读取（默认值）
    auto_offset_reset => "latest"
    
    # 从最早消息开始读取
    auto_offset_reset => "earliest"
    
    # 如果没有保存的偏移量就报错
    auto_offset_reset => "none"
  }
}
```

**策略选择指导**：

| 策略 | **使用场景** | **优缺点** |
|------|-------------|-----------|
| `latest` | 🔄 实时日志收集 | 不会重复处理历史消息，但可能丢失重启期间的消息 |
| `earliest` | 📊 数据迁移/完整性分析 | 保证数据完整，但可能重复处理大量历史消息 |
| `none` | 🎯 严格控制场景 | 避免意外消费，但需要手动管理偏移量 |

---

## 3. 📋 完整配置文件示例


### 3.1 基础生产环境配置


```ruby
# 文件名: 09-kafka-input.conf
input {
  kafka {
    # 集群连接配置
    bootstrap_servers => ["kafka1:9092", "kafka2:9092", "kafka3:9092"]
    
    # 主题订阅
    topics => ["application-logs", "system-logs"]
    
    # 消费者配置
    group_id => "logstash-production"
    auto_offset_reset => "latest"
    
    # 消费者线程配置
    consumer_threads => 3
    
    # 消息格式配置
    codec => "json"
    
    # 安全配置（如果启用了安全认证）
    security_protocol => "PLAINTEXT"
    
    # 添加标识字段
    add_field => { "input_source" => "kafka" }
    add_field => { "environment" => "production" }
  }
}

filter {
  # 数据处理逻辑
  if [input_source] == "kafka" {
    date {
      match => [ "timestamp", "ISO8601" ]
    }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch1:9200", "elasticsearch2:9200"]
    index => "logs-%{+YYYY.MM.dd}"
  }
}
```

### 3.2 高性能配置示例


```ruby
input {
  kafka {
    bootstrap_servers => ["kafka1:9092", "kafka2:9092", "kafka3:9092"]
    topics => ["high-volume-logs"]
    group_id => "logstash-high-performance"
    
    # 性能优化配置
    consumer_threads => 8
    max_poll_records => 1000
    fetch_min_bytes => 1024
    fetch_max_wait_ms => 500
    
    # 会话管理
    session_timeout_ms => 30000
    heartbeat_interval_ms => 3000
    
    # 批处理优化
    auto_commit_interval_ms => 1000
    
    codec => "json"
  }
}
```

---

## 4. 🏢 集群配置与高可用


### 4.1 多实例部署策略


**部署架构图**：
```
Kafka集群 (3节点)
    ↓
┌─────────────────────────────┐
│   Logstash集群 (3实例)      │
│ ┌─────┐ ┌─────┐ ┌─────┐    │
│ │ LS1 │ │ LS2 │ │ LS3 │    │
│ └─────┘ └─────┘ └─────┘    │
└─────────────────────────────┘
    ↓
Elasticsearch集群
```

**配置要点**：
- ✅ **相同group_id**：确保消息负载均衡
- ✅ **合理线程数**：consumer_threads不超过分区数
- ✅ **故障恢复**：配置appropriate重试和超时参数

### 4.2 集群连接最佳实践


```ruby
input {
  kafka {
    # 配置多个bootstrap服务器
    bootstrap_servers => [
      "kafka-node1:9092",
      "kafka-node2:9092", 
      "kafka-node3:9092"
    ]
    
    # 连接重试配置
    connections_max_idle_ms => 600000
    reconnect_backoff_ms => 50
    retry_backoff_ms => 100
    
    # 网络超时配置
    request_timeout_ms => 40000
  }
}
```

---

## 5. 👥 消费者组管理


### 5.1 消费者组概念详解


**生活化比喻**：消费者组就像一个"快递配送团队"

```
订单消息队列：
┌─────┐ ┌─────┐ ┌─────┐ ┌─────┐
│订单A│ │订单B│ │订单C│ │订单D│
└─────┘ └─────┘ └─────┘ └─────┘

配送团队(消费者组: "delivery-team-1"):
配送员1 → 处理订单A
配送员2 → 处理订单B  
配送员3 → 处理订单C
配送员4 → 处理订单D

每个订单只会分配给一个配送员处理
```

### 5.2 消费者线程配置


#### consumer_threads - 消费线程数配置


**含义解释**：就是告诉Logstash用多少个"工人"同时处理Kafka消息

```ruby
input {
  kafka {
    # 保守配置：较少线程
    consumer_threads => 1
    
    # 平衡配置：中等线程数
    consumer_threads => 3
    
    # 高并发配置：较多线程
    consumer_threads => 8
  }
}
```

**线程数量选择指导**：

| 场景 | **建议线程数** | **考虑因素** |
|------|---------------|-------------|
| 💻 测试环境 | 1-2 | 资源有限，重点是功能验证 |
| 🏢 小型生产 | 2-4 | 平衡性能和资源消耗 |
| 🚀 高并发生产 | 4-8 | 最大化吞吐量，但不超过分区数 |

> ⚠️ **重要原则**：消费线程数不要超过Kafka主题的分区数，否则多余线程会闲置

---

## 6. ⚡ 性能调优配置


### 6.1 网络和会话参数


#### session_timeout_ms - 会话超时时间


**通俗解释**：就是Kafka等待Logstash"报平安"的最长时间

```ruby
input {
  kafka {
    # 会话超时配置（毫秒）
    session_timeout_ms => 30000  # 30秒
    
    # 心跳间隔（必须小于session_timeout_ms的1/3）
    heartbeat_interval_ms => 3000  # 3秒
  }
}
```

**参数关系图**：
```
时间轴示意：
0s    3s    6s    9s    12s   15s   18s   21s   24s   27s   30s
|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|
  ♥     ♥     ♥     ♥     ♥     ♥     ♥     ♥     ♥     ♥    
心跳间隔=3s，会话超时=30s
如果超过30s没收到心跳，Kafka认为消费者已死
```

#### max_poll_records - 单次拉取记录数


**简单理解**：每次从Kafka"拿货"拿多少条消息

```ruby
input {
  kafka {
    # 保守配置：每次处理少量消息
    max_poll_records => 100
    
    # 平衡配置：中等批量大小  
    max_poll_records => 500
    
    # 高吞吐配置：大批量处理
    max_poll_records => 2000
  }
}
```

**批量大小影响**：
- 📊 **小批量** (100-300)：延迟低，适合实时性要求高的场景
- ⚖️ **中批量** (500-1000)：平衡延迟和吞吐量
- 🚀 **大批量** (1000+)：吞吐量高，但增加处理延迟

### 6.2 性能优化配置组合


```ruby
input {
  kafka {
    bootstrap_servers => ["kafka1:9092", "kafka2:9092", "kafka3:9092"]
    topics => ["high-volume-logs"]
    group_id => "logstash-optimized"
    
    # 核心性能参数
    consumer_threads => 6
    max_poll_records => 1000
    session_timeout_ms => 30000
    heartbeat_interval_ms => 3000
    
    # 网络优化
    fetch_min_bytes => 1024
    fetch_max_wait_ms => 500
    connections_max_idle_ms => 600000
    
    # 提交优化
    auto_commit_interval_ms => 1000
    enable_auto_commit => true
    
    codec => "json"
    
    # 监控标签
    add_field => { "logstash_instance" => "%{HOSTNAME}" }
    add_field => { "consumer_group" => "logstash-optimized" }
  }
}
```

---

## 7. 📊 监控与故障排查


### 7.1 关键监控指标


**消费延迟监控**：
```ruby
input {
  kafka {
    # 启用JMX监控
    enable_metric => true
    
    # 添加监控字段
    add_field => { 
      "kafka_partition" => "%{[@metadata][kafka][partition]}"
      "kafka_offset" => "%{[@metadata][kafka][offset]}" 
      "kafka_topic" => "%{[@metadata][kafka][topic]}"
    }
  }
}
```

**常用监控命令**：
```bash
# 查看消费者组状态
kafka-consumer-groups.sh --bootstrap-server kafka1:9092 \
  --group logstash-production --describe

# 查看主题分区信息  
kafka-topics.sh --bootstrap-server kafka1:9092 \
  --topic application-logs --describe
```

### 7.2 常见问题排查


**问题1：消费延迟过大**
```
症状：Kafka中有消息，但Logstash处理很慢
原因：
• consumer_threads配置过小
• max_poll_records配置过小  
• 下游Elasticsearch处理慢

解决方案：
• 增加consumer_threads
• 适当增大max_poll_records
• 优化ES写入性能
```

**问题2：重复消费消息**
```
症状：相同消息被处理多次
原因：
• 多个不同group_id的Logstash实例
• 偏移量提交失败
• session_timeout_ms配置过小

解决方案：
• 统一group_id配置
• 检查网络连接稳定性
• 适当增大超时时间
```

---

## 8. 🛠️ 实战配置样例


### 8.1 日志收集场景


```ruby
# 应用日志收集配置
input {
  kafka {
    bootstrap_servers => ["kafka1:9092", "kafka2:9092"]
    topics => ["app-logs", "web-logs", "api-logs"]
    group_id => "log-collector"
    auto_offset_reset => "latest"
    consumer_threads => 4
    max_poll_records => 500
    codec => "json"
    
    add_field => { "pipeline" => "log-collection" }
  }
}

filter {
  # 解析应用日志
  if [application] == "web-server" {
    grok {
      match => { "message" => "%{COMBINEDAPACHELOG}" }
    }
  }
  
  # 时间戳处理
  date {
    match => [ "timestamp", "ISO8601" ]
  }
  
  # 字段清理
  mutate {
    remove_field => [ "@version", "host" ]
  }
}

output {
  elasticsearch {
    hosts => ["es1:9200", "es2:9200"]
    index => "logs-%{application}-%{+YYYY.MM.dd}"
  }
}
```

### 8.2 实时分析场景


```ruby
# 实时数据分析配置
input {
  kafka {
    bootstrap_servers => ["kafka1:9092", "kafka2:9092", "kafka3:9092"]
    topics => ["user-events", "click-streams"]
    group_id => "realtime-analytics"
    auto_offset_reset => "latest"
    
    # 实时性优化
    consumer_threads => 8
    max_poll_records => 100  # 小批量，低延迟
    session_timeout_ms => 10000
    heartbeat_interval_ms => 1000
    
    codec => "json"
  }
}

filter {
  # 用户行为分析
  if [event_type] == "page_view" {
    mutate {
      add_field => { "category" => "user_behavior" }
    }
  }
  
  # 地理位置解析
  if [ip] {
    geoip {
      source => "ip"
      target => "geoip"
    }
  }
}

output {
  # 发送到实时分析系统
  elasticsearch {
    hosts => ["es1:9200"]
    index => "events-%{+YYYY.MM.dd.HH}"
  }
  
  # 同时发送到另一个Kafka主题做进一步处理
  kafka {
    topic_id => "processed-events"
    bootstrap_servers => ["kafka1:9092", "kafka2:9092"]
  }
}
```

---

## 9. 📋 核心要点总结


### 9.1 必须掌握的核心概念


```
🔸 bootstrap_servers：Kafka集群的"门牌号"
🔸 topics：要订阅的消息"频道"
🔸 group_id：消费者"团队标识"
🔸 auto_offset_reset：重启后从哪里开始读消息
🔸 consumer_threads：同时工作的"处理线程"数量
🔸 session_timeout_ms：Kafka等待心跳的最长时间
🔸 max_poll_records：单次拉取的消息数量
```

### 9.2 关键配置原则


**🔹 集群配置原则**
```
高可用配置：
• 配置多个bootstrap_servers避免单点故障
• 使用相同group_id实现负载均衡
• 合理设置超时和重试参数

性能优化原则：
• consumer_threads不超过分区数
• 根据处理能力调整max_poll_records
• 平衡实时性和吞吐量需求
```

**🔹 监控和运维要点**
```
关键监控指标：
• 消费延迟 (Consumer Lag)
• 消息处理速率
• 错误率和重试次数
• 网络连接状态

故障排查步骤：
1. 检查Kafka集群连接状态
2. 查看消费者组分区分配
3. 监控Logstash处理性能
4. 分析下游系统瓶颈
```

### 9.3 实际应用价值


**🎯 适用场景**：
- 📊 **大规模日志收集**：支持高吞吐量数据处理
- ⚡ **实时数据分析**：毫秒级数据传输和处理
- 🛡️ **可靠数据传输**：消息持久化，支持重放
- 📈 **弹性架构**：水平扩展，动态负载均衡

**🔧 最佳实践总结**：
- 根据业务需求选择合适的配置参数
- 建立完善的监控和告警机制  
- 定期评估和调优性能参数
- 制定故障恢复和数据回放策略

**核心记忆要点**：
- Kafka输入是Logstash实现大规模数据处理的关键组件
- 正确配置消费者组和线程数是性能优化的基础
- 监控消费延迟和处理速率是运维的重点
- 理解偏移量管理机制对数据完整性至关重要