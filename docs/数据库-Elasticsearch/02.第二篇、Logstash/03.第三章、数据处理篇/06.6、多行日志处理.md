---
title: 6、多行日志处理
---
## 📚 目录

1. [多行日志问题概述](#1-多行日志问题概述)
2. [multiline插件基础](#2-multiline插件基础)
3. [核心参数详解](#3-核心参数详解)
4. [实战场景应用](#4-实战场景应用)
5. [高级配置技巧](#5-高级配置技巧)
6. [常见问题与解决](#6-常见问题与解决)
7. [核心要点总结](#7-核心要点总结)

---

## 1. 🤔 多行日志问题概述


### 1.1 什么是多行日志问题？


**通俗解释**：
想象你在看一本书，正常情况下每一句话都是独立的一行。但有时候，一个完整的意思需要好几行才能表达完整，比如一首诗或者一个完整的故事段落。

在日志世界里也是这样 - 有些日志信息天生就需要多行才能完整表达，最典型的就是**程序报错信息**。

**现实例子**：
```
❌ 错误的理解方式（每行当作独立日志）：
2024-01-15 10:30:15 ERROR - Something went wrong
    at com.example.MyClass.doSomething(MyClass.java:42)
    at com.example.Service.process(Service.java:18)
    at com.example.Controller.handle(Controller.java:25)

如果Logstash把上面每一行都当作独立的日志，那就乱套了！
实际上这是一个完整的错误报告，应该作为一条日志处理。
```

### 1.2 多行日志的典型特征


💡 **识别标志**：
- **堆栈追踪**：Java异常、Python错误等
- **缩进连续**：空格或制表符开头的行
- **特殊开头**：以特定字符开始的日志
- **JSON格式**：跨越多行的JSON数据

**常见场景示例**：
```
场景1 - Java异常堆栈：
2024-01-15 ERROR Exception in thread "main"
java.lang.NullPointerException: Cannot invoke method
    at Main.processData(Main.java:15)
    at Main.main(Main.java:8)

场景2 - 应用启动日志：
[2024-01-15 09:00:00] Starting application...
    Loading configuration from config.properties
    Initializing database connections
    Application ready to serve requests

场景3 - SQL查询日志：
[2024-01-15] Executing query:
SELECT customer.name, 
       order.total_amount,
       order.order_date
FROM customers customer
JOIN orders order ON customer.id = order.customer_id
WHERE order.order_date > '2024-01-01'
```

### 1.3 不处理多行日志的后果


⚠️ **问题影响**：
- **信息割裂**：完整的错误信息被分成多条无意义的片段
- **搜索困难**：无法根据完整错误内容进行查询
- **分析错误**：统计和分析结果不准确
- **排查困难**：故障定位变得复杂

---

## 2. 🔧 multiline插件基础


### 2.1 multiline插件的作用原理


**简单理解**：
multiline插件就像一个**智能书签管理员**。它能识别哪些行是属于同一个"故事"的，然后把这些行合并成一个完整的记录。

**工作流程**：
```
原始日志流 → multiline插件识别 → 合并处理 → 输出完整日志

步骤详解：
1️⃣ 读取每一行日志
2️⃣ 用正则表达式判断：这行是新故事的开始，还是续集？
3️⃣ 如果是续集，就和前面的内容合并
4️⃣ 如果是新故事，就输出之前合并好的内容，开始新的合并
```

### 2.2 插件配置位置


multiline插件可以配置在两个地方，各有不同的用途：

| 配置位置 | **使用场景** | **优势** | **限制** |
|---------|-------------|---------|---------|
| **input段** | `文件读取时处理` | `效率高，在源头解决` | `只能用于file input` |
| **filter段** | `任何数据源` | `灵活，支持所有input` | `效率稍低` |

**配置示例对比**：
```ruby
# 方式1：在input中配置（推荐用于文件）
input {
  file {
    path => "/var/log/app.log"
    codec => multiline {
      pattern => "^\d{4}-\d{2}-\d{2}"
      negate => true
      what => "previous"
    }
  }
}

# 方式2：在filter中配置（推荐用于其他数据源）
filter {
  multiline {
    pattern => "^\d{4}-\d{2}-\d{2}"
    negate => true
    what => "previous"
  }
}
```

---

## 3. ⚙️ 核心参数详解


### 3.1 pattern参数 - 识别规则


**作用**：定义什么样的行是"重要的标志行"

**通俗解释**：
就像给书本的每个章节标题贴上特殊的标签，pattern就是这个标签的规格说明书。

**常用模式**：

| 模式类型 | **正则表达式** | **含义说明** | **匹配示例** |
|---------|---------------|-------------|-------------|
| **时间戳开头** | `^\d{4}-\d{2}-\d{2}` | `年-月-日开头的行` | `2024-01-15 10:30:00` |
| **日志级别** | `^(INFO\|ERROR\|WARN)` | `以日志级别开头` | `ERROR Something wrong` |
| **Java异常** | `^[[:space:]]` | `空格或制表符开头` | `    at Main.java:15` |
| **方括号日期** | `^\[.*\]` | `方括号包围的开头` | `[2024-01-15 10:30:00]` |

**实际配置示例**：
```ruby
# 示例1：处理带时间戳的应用日志
codec => multiline {
  pattern => "^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}"
  negate => true
  what => "previous"
}

# 示例2：处理Java异常堆栈
codec => multiline {
  pattern => "^[[:space:]]"
  negate => false
  what => "previous"
}
```

### 3.2 negate参数 - 反向控制


**作用**：决定是按照pattern匹配，还是按照"不匹配pattern"来判断

💡 **理解技巧**：
- `negate => false`：**按规则执行** - "符合pattern的行执行what操作"
- `negate => true`：**反向执行** - "不符合pattern的行执行what操作"

**实战对比**：
```ruby
场景：处理Java异常日志
2024-01-15 ERROR Exception occurred    ← 主日志行（有时间戳）
    at Main.processData(Main.java:15)   ← 堆栈行（空格开头）
    at Main.main(Main.java:8)          ← 堆栈行（空格开头）
2024-01-15 INFO Processing completed   ← 新的主日志行

# 方案1：匹配空格开头的行
pattern => "^[[:space:]]"
negate => false        # 符合pattern（空格开头）的行合并到前面
what => "previous"

# 方案2：匹配时间戳开头的行（推荐）
pattern => "^\d{4}-\d{2}-\d{2}"
negate => true         # 不符合pattern（无时间戳）的行合并到前面
what => "previous"
```

### 3.3 what参数 - 合并方向


**作用**：决定多行内容的合并方向

**两种选择**：
- `what => "previous"`：**向前合并** - 当前行合并到前面的内容
- `what => "next"`：**向后合并** - 当前行合并到后面的内容

**图解说明**：
```
原始日志：
A: 2024-01-15 ERROR Something wrong
B:     at Main.java:15  
C:     at Service.java:8
D: 2024-01-15 INFO Done

使用 what => "previous"：
- B行合并到A → A+B
- C行合并到A+B → A+B+C
- D行开始新的合并周期

最终结果：
[A+B+C] 和 [D]

使用 what => "next"：
- A行预期和后面合并 → A+B
- A+B继续和C合并 → A+B+C  
- D行独立

结果相同，但处理逻辑不同
```

### 3.4 参数组合策略


**最佳实践组合**：

| 日志类型 | **pattern** | **negate** | **what** | **说明** |
|---------|------------|-----------|----------|----------|
| **标准应用日志** | `^\d{4}-\d{2}-\d{2}` | `true` | `previous` | `无时间戳的行向前合并` |
| **Java异常** | `^[[:space:]]` | `false` | `previous` | `缩进行向前合并` |
| **Nginx访问日志** | `^\d+\.\d+\.\d+\.\d+` | `true` | `previous` | `非IP开头向前合并` |
| **系统日志** | `^[A-Z][a-z]{2} \d{2}` | `true` | `previous` | `非月份开头向前合并` |

---

## 4. 🎯 实战场景应用


### 4.1 Java应用异常处理


**场景描述**：处理Spring Boot应用的异常日志

**原始日志示例**：
```
2024-01-15 14:30:15.123 ERROR 12345 --- [http-nio-8080-exec-1] c.e.s.UserController : Error processing request
java.lang.NullPointerException: Cannot invoke "User.getName()" because "user" is null
	at com.example.service.UserService.processUser(UserService.java:45)
	at com.example.controller.UserController.getUser(UserController.java:28)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
2024-01-15 14:30:16.001 INFO  12345 --- [http-nio-8080-exec-2] c.e.s.UserController : Request completed successfully
```

**配置方案**：
```ruby
input {
  file {
    path => "/var/log/spring-boot/app.log"
    codec => multiline {
      # 匹配标准的Spring Boot日志时间戳格式
      pattern => "^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}\.\d{3}"
      negate => true    # 不是时间戳开头的行都合并到前面
      what => "previous"
    }
  }
}

filter {
  # 解析时间戳和日志级别
  grok {
    match => { 
      "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level}.*" 
    }
  }
  
  # 转换时间格式
  date {
    match => [ "timestamp", "yyyy-MM-dd HH:mm:ss.SSS" ]
  }
}
```

**处理效果**：
```
✅ 合并后的完整日志：
{
  "timestamp": "2024-01-15T14:30:15.123Z",
  "level": "ERROR",
  "message": "2024-01-15 14:30:15.123 ERROR ... Error processing request\njava.lang.NullPointerException: Cannot invoke \"User.getName()\" because \"user\" is null\n\tat com.example.service.UserService.processUser(UserService.java:45)...",
  "tags": ["multiline"]
}
```

### 4.2 Web服务器访问日志


**场景描述**：处理跨行的HTTP请求日志

**原始日志示例**：
```
192.168.1.100 - - [15/Jan/2024:14:30:15 +0800] "POST /api/users HTTP/1.1" 500 1234
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
    "application/json" 0.523
192.168.1.101 - - [15/Jan/2024:14:30:16 +0800] "GET /health HTTP/1.1" 200 15
```

**配置方案**：
```ruby
input {
  file {
    path => "/var/log/nginx/access.log"
    codec => multiline {
      # IP地址开头的行是新请求的开始
      pattern => "^\d+\.\d+\.\d+\.\d+"
      negate => true    # 非IP开头的行合并到前面
      what => "previous"
    }
  }
}

filter {
  # 解析访问日志的各个字段
  grok {
    match => { 
      "message" => "%{IPORHOST:client_ip} .* \[%{HTTPDATE:timestamp}\] \"%{WORD:method} %{URIPATH:request} HTTP/%{NUMBER:http_version}\" %{NUMBER:status_code} %{NUMBER:bytes}"
    }
  }
}
```

### 4.3 数据库慢查询日志


**场景描述**：MySQL慢查询日志通常包含多行SQL语句

**原始日志示例**：
```
# Time: 2024-01-15T14:30:15.123456Z
# User@Host: app_user[app_user] @ [192.168.1.10]
# Query_time: 5.000123  Lock_time: 0.000456 Rows_sent: 1000  Rows_examined: 500000
SET timestamp=1705329015;
SELECT customer.name, 
       customer.email,
       order.total_amount,
       order.order_date
FROM customers customer
LEFT JOIN orders order ON customer.id = order.customer_id
WHERE customer.created_date > '2024-01-01'
  AND order.status = 'completed'
ORDER BY order.order_date DESC
LIMIT 1000;
```

**配置方案**：
```ruby
input {
  file {
    path => "/var/log/mysql/slow.log"
    codec => multiline {
      # MySQL慢查询以# Time:开头
      pattern => "^# Time:"
      negate => true
      what => "previous"
    }
  }
}

filter {
  # 提取查询时间等关键信息
  grok {
    match => { 
      "message" => ".*Query_time: %{NUMBER:query_time}.*Lock_time: %{NUMBER:lock_time}.*"
    }
  }
  
  # 转换查询时间为数字
  mutate {
    convert => { 
      "query_time" => "float"
      "lock_time" => "float"
    }
  }
}
```

---

## 5. 🚀 高级配置技巧


### 5.1 设置合并超时


**为什么需要超时**：
有时候日志文件可能在多行日志的中间就结束了，没有下一个"开始标志"来触发合并。这时需要设置超时来强制输出已收集的内容。

```ruby
input {
  file {
    path => "/var/log/app.log"
    codec => multiline {
      pattern => "^\d{4}-\d{2}-\d{2}"
      negate => true
      what => "previous"
      auto_flush_interval => 5    # 5秒后自动输出未完成的多行内容
    }
  }
}
```

**最佳实践**：
- **实时日志**：设置较短超时（1-5秒）
- **批量处理**：可以设置较长超时（10-30秒）
- **文件结束**：确保最后的多行内容能被处理

### 5.2 大小限制保护


**防止内存问题**：
```ruby
codec => multiline {
  pattern => "^\d{4}-\d{2}-\d{2}"
  negate => true
  what => "previous"
  max_lines => 1000        # 最多合并1000行
  max_bytes => 1048576     # 最大1MB
}
```

### 5.3 条件化多行处理


**场景**：只对特定类型的日志进行多行处理

```ruby
filter {
  # 只对ERROR级别的日志进行多行处理
  if [level] == "ERROR" {
    multiline {
      pattern => "^[[:space:]]"
      negate => false
      what => "previous"
    }
  }
}
```

### 5.4 多种日志格式混合处理


**复杂场景配置**：
```ruby
input {
  file {
    path => "/var/log/mixed.log"
    codec => multiline {
      patterns_dir => "/etc/logstash/patterns"
      # 使用自定义模式文件
      pattern => "%{JAVA_EXCEPTION_START}"
      negate => true
      what => "previous"
    }
  }
}

# 在/etc/logstash/patterns/java文件中定义：
# JAVA_EXCEPTION_START ^\d{4}-\d{2}-\d{2}|\s*at\s|\s*Caused by:
```

---

## 6. ❗ 常见问题与解决


### 6.1 性能问题


**问题**：多行处理导致Logstash性能下降

**解决方案**：
```ruby
# 1. 在input阶段处理（推荐）
input {
  file {
    codec => multiline { ... }  # 效率更高
  }
}

# 2. 设置合理的缓冲区
pipeline.batch.size: 1000      # 增加批处理大小
pipeline.batch.delay: 5        # 减少延迟

# 3. 使用条件过滤
filter {
  if [path] =~ /error\.log$/ {  # 只处理特定文件
    multiline { ... }
  }
}
```

### 6.2 模式匹配错误


**常见错误示例**：
```ruby
❌ 错误写法：
pattern => "^2024-01-15"        # 太具体，只匹配特定日期

✅ 正确写法：
pattern => "^\d{4}-\d{2}-\d{2}" # 通用的日期格式

❌ 错误写法：
pattern => "ERROR"              # 可能误匹配消息内容中的ERROR

✅ 正确写法：
pattern => "^\d{4}.*ERROR"      # 结合时间戳和级别
```

### 6.3 内存占用过高


**问题分析**：
长时间运行的多行合并可能占用大量内存

**解决方案**：
```ruby
# 设置严格的限制
codec => multiline {
  pattern => "..."
  max_lines => 500          # 限制最大行数
  max_bytes => 524288       # 限制最大字节数（512KB）
  auto_flush_interval => 3  # 定期强制输出
}

# 监控配置
input {
  beats {
    port => 5044
  }
}

# 添加监控指标
filter {
  metrics {
    meter => "multiline_events"
    add_tag => "metric"
  }
}
```

### 6.4 时区和编码问题


**解决编码问题**：
```ruby
input {
  file {
    path => "/var/log/app.log"
    codec => multiline {
      pattern => "..."
      charset => "UTF-8"      # 明确指定编码
    }
  }
}

filter {
  # 处理时区
  date {
    match => [ "timestamp", "yyyy-MM-dd HH:mm:ss" ]
    timezone => "Asia/Shanghai"  # 设置正确时区
  }
}
```

---

## 7. 📋 核心要点总结


### 7.1 必须掌握的核心概念


```
🔸 multiline插件：专门解决多行日志合并问题的工具
🔸 pattern参数：用正则表达式定义"重要标志行"的识别规则  
🔸 negate参数：控制是正向匹配还是反向匹配
🔸 what参数：决定多行内容的合并方向（previous/next）
🔸 最佳配置位置：input段处理文件，filter段处理其他数据源
```

### 7.2 关键理解要点


**🔹 工作原理理解**
```
核心逻辑：
1. 读取每一行 → 2. 模式匹配判断 → 3. 决定合并还是输出 → 4. 循环处理

关键判断：
- 这一行是新内容的开始吗？（通过pattern+negate判断）
- 如果不是开始，就合并到前面（what=previous）
- 如果是开始，就输出之前合并的内容，开启新的合并周期
```

**🔹 参数组合技巧**
```
万能组合（适用80%场景）：
pattern => "^\d{4}-\d{2}-\d{2}"   # 匹配时间戳开头
negate => true                    # 非时间戳开头的行
what => "previous"                # 合并到前面的内容

记忆口诀：
"时间戳开头是新篇，其他内容往前贴"
```

**🔹 性能优化要点**
```
配置优先级：
1. input段配置 > filter段配置（效率更高）
2. 设置合理的max_lines和max_bytes（防止内存爆炸）
3. 使用auto_flush_interval（确保及时输出）
4. 添加条件判断（避免不必要的处理）
```

### 7.3 实际应用指导


**适用场景判断**：
- ✅ **Java异常堆栈**：经典应用场景，效果显著
- ✅ **应用启动日志**：多行配置信息合并
- ✅ **SQL查询日志**：跨行查询语句处理
- ✅ **容器日志**：Docker多行输出处理

**配置选择策略**：
```
数据源类型 → 配置位置选择：
• 文件日志 → input段配置（file input + codec）
• Beats输入 → filter段配置（更灵活）
• Syslog输入 → filter段配置（统一处理）
• TCP/UDP输入 → filter段配置（实时处理）
```

**故障排查思路**：
```
问题诊断步骤：
1️⃣ 检查pattern是否正确匹配目标行
2️⃣ 验证negate设置是否符合预期
3️⃣ 确认what方向设置正确
4️⃣ 查看是否有超时或大小限制问题
5️⃣ 监控内存和性能指标
```

### 7.4 学习进阶路径


**基础掌握**：
- 理解多行日志的概念和问题
- 掌握三大核心参数的含义和配合
- 能配置处理Java异常等常见场景

**进阶应用**：
- 复杂正则表达式模式编写
- 性能优化和监控配置
- 多种数据源的统一处理策略

**高级技能**：
- 自定义模式文件管理
- 大规模生产环境调优
- 与其他ELK组件的协同配置

**核心记忆口诀**：
```
多行日志要合并，pattern规则是关键
negate控制正反向，what决定合并方向  
input配置效率高，filter灵活用途广
超时大小要设限，性能监控不能忘
```