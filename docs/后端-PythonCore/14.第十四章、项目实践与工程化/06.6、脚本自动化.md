---
title: 6ã€è„šæœ¬è‡ªåŠ¨åŒ–
---
## ğŸ“š ç›®å½•

1. [è„šæœ¬è‡ªåŠ¨åŒ–æ¦‚å¿µä¸ä»·å€¼](#1-è„šæœ¬è‡ªåŠ¨åŒ–æ¦‚å¿µä¸ä»·å€¼)
2. [ç³»ç»Ÿä»»åŠ¡è‡ªåŠ¨åŒ–](#2-ç³»ç»Ÿä»»åŠ¡è‡ªåŠ¨åŒ–)
3. [æ–‡ä»¶æ‰¹å¤„ç†è„šæœ¬](#3-æ–‡ä»¶æ‰¹å¤„ç†è„šæœ¬)
4. [æ•°æ®å¤„ç†è„šæœ¬](#4-æ•°æ®å¤„ç†è„šæœ¬)
5. [å®šæ—¶ä»»åŠ¡è„šæœ¬](#5-å®šæ—¶ä»»åŠ¡è„šæœ¬)
6. [ç›‘æ§è„šæœ¬å¼€å‘](#6-ç›‘æ§è„šæœ¬å¼€å‘)
7. [éƒ¨ç½²è„šæœ¬å®è·µ](#7-éƒ¨ç½²è„šæœ¬å®è·µ)
8. [å¤‡ä»½è„šæœ¬è®¾è®¡](#8-å¤‡ä»½è„šæœ¬è®¾è®¡)
9. [è„šæœ¬é”™è¯¯å¤„ç†ç­–ç•¥](#9-è„šæœ¬é”™è¯¯å¤„ç†ç­–ç•¥)
10. [æ ¸å¿ƒè¦ç‚¹æ€»ç»“](#10-æ ¸å¿ƒè¦ç‚¹æ€»ç»“)

---

## 1. ğŸ¤– è„šæœ¬è‡ªåŠ¨åŒ–æ¦‚å¿µä¸ä»·å€¼


### 1.1 ä»€ä¹ˆæ˜¯è„šæœ¬è‡ªåŠ¨åŒ–


**ğŸ’¡ é€šä¿—ç†è§£**
è„šæœ¬è‡ªåŠ¨åŒ–å°±åƒç»™ç”µè„‘å†™"æ“ä½œæ‰‹å†Œ"ï¼Œè®©å®ƒæŒ‰ç…§ä½ çš„æŒ‡ç¤ºè‡ªåŠ¨å®Œæˆé‡å¤æ€§å·¥ä½œã€‚å°±åƒä½ æ•™ä¼šæœºå™¨äººåšå®¶åŠ¡ä¸€æ ·ï¼Œä¸€æ—¦å†™å¥½è„šæœ¬ï¼Œç”µè„‘å°±èƒ½24å°æ—¶ä¸é—´æ–­åœ°å¸®ä½ å¹²æ´»ã€‚

**ğŸ”¸ æ ¸å¿ƒæ¦‚å¿µ**
```
è„šæœ¬ = ä¸€ç³»åˆ—è‡ªåŠ¨æ‰§è¡Œçš„å‘½ä»¤
è‡ªåŠ¨åŒ– = å‡å°‘äººå·¥å¹²é¢„ï¼Œæé«˜æ•ˆç‡
Pythonè„šæœ¬ = ç”¨Pythonè¯­è¨€å†™çš„è‡ªåŠ¨åŒ–ç¨‹åº
```

**âš¡ ä¸ºä»€ä¹ˆè¦ç”¨è„šæœ¬è‡ªåŠ¨åŒ–**
- **è§£æ”¾åŒæ‰‹**ï¼šä¸ç”¨æ‰‹åŠ¨é‡å¤åšåŒæ ·çš„äº‹æƒ…
- **æé«˜æ•ˆç‡**ï¼šç”µè„‘æ‰§è¡Œæ¯”äººå·¥å¿«å¾—å¤š
- **å‡å°‘é”™è¯¯**ï¼šé¿å…äººä¸ºæ“ä½œå¤±è¯¯
- **èŠ‚çº¦æ—¶é—´**ï¼šä¸€æ¬¡ç¼–å†™ï¼Œå¤šæ¬¡ä½¿ç”¨
- **24å°æ—¶å·¥ä½œ**ï¼šå¯ä»¥åœ¨ä½ ç¡è§‰æ—¶è‡ªåŠ¨è¿è¡Œ

### 1.2 è„šæœ¬è‡ªåŠ¨åŒ–çš„åº”ç”¨åœºæ™¯


**ğŸ  æ—¥å¸¸ç”Ÿæ´»åœºæ™¯**
```
ä¸ªäººä½¿ç”¨ï¼š
â€¢ æ•´ç†ä¸‹è½½æ–‡ä»¶å¤¹ä¸­çš„æ–‡ä»¶
â€¢ æ‰¹é‡é‡å‘½åç…§ç‰‡
â€¢ è‡ªåŠ¨å¤‡ä»½é‡è¦æ–‡æ¡£
â€¢ å®šæ—¶æ¸…ç†åƒåœ¾æ–‡ä»¶

å·¥ä½œåœºæ™¯ï¼š
â€¢ è‡ªåŠ¨ç”ŸæˆæŠ¥è¡¨
â€¢ æ‰¹é‡å¤„ç†æ•°æ®æ–‡ä»¶
â€¢ ç›‘æ§ç³»ç»ŸçŠ¶æ€
â€¢ è‡ªåŠ¨éƒ¨ç½²ç¨‹åº
```

### 1.3 Pythonè„šæœ¬çš„ä¼˜åŠ¿


**ğŸŒŸ ä¸ºä»€ä¹ˆé€‰æ‹©Pythonå†™è„šæœ¬**

| ç‰¹ç‚¹ | è¯´æ˜ | ä¸¾ä¾‹ |
|-----|------|------|
| **è¯­æ³•ç®€å•** | æ¥è¿‘äººç±»è¯­è¨€ï¼Œå®¹æ˜“ç†è§£ | `if file_exists: delete_file()` |
| **åº“ä¸°å¯Œ** | æœ‰ç°æˆçš„å·¥å…·åŒ… | `os`, `shutil`, `schedule` |
| **è·¨å¹³å°** | Windowsã€Macã€Linuxéƒ½èƒ½ç”¨ | åŒä¸€è„šæœ¬åœ¨ä¸åŒç³»ç»Ÿè¿è¡Œ |
| **ç¤¾åŒºæ´»è·ƒ** | é‡åˆ°é—®é¢˜å®¹æ˜“æ‰¾åˆ°è§£å†³æ–¹æ¡ˆ | ç½‘ä¸Šæ•™ç¨‹å’Œç¤ºä¾‹ä¸°å¯Œ |

---

## 2. ğŸ–¥ï¸ ç³»ç»Ÿä»»åŠ¡è‡ªåŠ¨åŒ–


### 2.1 ä»€ä¹ˆæ˜¯ç³»ç»Ÿä»»åŠ¡è‡ªåŠ¨åŒ–


**ğŸ”¸ ç®€å•ç†è§£**
ç³»ç»Ÿä»»åŠ¡è‡ªåŠ¨åŒ–å°±æ˜¯è®©Pythonå¸®ä½ æ“ä½œç”µè„‘ç³»ç»Ÿï¼Œæ¯”å¦‚åˆ›å»ºæ–‡ä»¶å¤¹ã€å¯åŠ¨ç¨‹åºã€ç®¡ç†è¿›ç¨‹ç­‰ã€‚å°±åƒä½ ç”¨é¼ æ ‡å’Œé”®ç›˜èƒ½åšçš„äº‹æƒ…ï¼ŒPythonè„šæœ¬ä¹Ÿèƒ½è‡ªåŠ¨å®Œæˆã€‚

### 2.2 å¸¸ç”¨ç³»ç»Ÿæ“ä½œæ¨¡å—


**ğŸ“¦ æ ¸å¿ƒæ¨¡å—ä»‹ç»**

```python
import os        # æ“ä½œç³»ç»Ÿæ¥å£
import sys       # ç³»ç»Ÿç›¸å…³åŠŸèƒ½
import subprocess # æ‰§è¡Œç³»ç»Ÿå‘½ä»¤
import platform  # è·å–å¹³å°ä¿¡æ¯
import psutil    # ç³»ç»Ÿå’Œè¿›ç¨‹ç›‘æ§ï¼ˆéœ€è¦å®‰è£…ï¼‰
```

**ğŸ”§ osæ¨¡å—å¸¸ç”¨åŠŸèƒ½**
```python
# è·å–å½“å‰è·¯å¾„
current_path = os.getcwd()
print(f"å½“å‰ä½ç½®ï¼š{current_path}")

# åˆ‡æ¢ç›®å½•
os.chdir("/path/to/directory")

# åˆ›å»ºç›®å½•
os.makedirs("æ–°æ–‡ä»¶å¤¹", exist_ok=True)

# åˆ—å‡ºæ–‡ä»¶
files = os.listdir(".")
print("å½“å‰ç›®å½•æ–‡ä»¶ï¼š", files)
```

### 2.3 ç³»ç»Ÿä¿¡æ¯è·å–è„šæœ¬


**ğŸ“Š è·å–ç³»ç»ŸåŸºæœ¬ä¿¡æ¯**
```python
import platform
import psutil
import datetime

def get_system_info():
    """è·å–ç³»ç»ŸåŸºæœ¬ä¿¡æ¯"""
    info = {
        "ç³»ç»Ÿ": platform.system(),
        "ç‰ˆæœ¬": platform.version(),
        "æ¶æ„": platform.architecture()[0],
        "CPUæ ¸å¿ƒæ•°": psutil.cpu_count(),
        "å†…å­˜æ€»é‡": f"{psutil.virtual_memory().total // (1024**3)} GB",
        "å½“å‰æ—¶é—´": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    }
    return info

# ä½¿ç”¨ç¤ºä¾‹
system_info = get_system_info()
for key, value in system_info.items():
    print(f"{key}: {value}")
```

### 2.4 è¿›ç¨‹ç®¡ç†è„šæœ¬


**âš™ï¸ ç®¡ç†ç³»ç»Ÿè¿›ç¨‹**
```python
import psutil
import time

def monitor_process(process_name):
    """ç›‘æ§æŒ‡å®šè¿›ç¨‹"""
    for process in psutil.process_iter(['pid', 'name', 'cpu_percent']):
        if process_name.lower() in process.info['name'].lower():
            print(f"è¿›ç¨‹: {process.info['name']}")
            print(f"PID: {process.info['pid']}")
            print(f"CPUä½¿ç”¨ç‡: {process.info['cpu_percent']}%")
            return True
    print(f"æœªæ‰¾åˆ°è¿›ç¨‹: {process_name}")
    return False

# ä½¿ç”¨ç¤ºä¾‹
monitor_process("python")
```

### 2.5 ç¯å¢ƒå˜é‡ç®¡ç†


**ğŸŒ æ“ä½œç¯å¢ƒå˜é‡**
```python
import os

def manage_environment():
    """ç¯å¢ƒå˜é‡ç®¡ç†ç¤ºä¾‹"""
    # è¯»å–ç¯å¢ƒå˜é‡
    path = os.environ.get('PATH')
    print(f"ç³»ç»ŸPATH: {path[:100]}...")
    
    # è®¾ç½®ä¸´æ—¶ç¯å¢ƒå˜é‡
    os.environ['MY_SCRIPT_VAR'] = 'Hello World'
    
    # éªŒè¯è®¾ç½®
    my_var = os.environ.get('MY_SCRIPT_VAR')
    print(f"æˆ‘çš„å˜é‡: {my_var}")

manage_environment()
```

---

## 3. ğŸ“ æ–‡ä»¶æ‰¹å¤„ç†è„šæœ¬


### 3.1 æ–‡ä»¶æ‰¹å¤„ç†çš„æ¦‚å¿µ


**ğŸ”¸ ä»€ä¹ˆæ˜¯æ–‡ä»¶æ‰¹å¤„ç†**
æ–‡ä»¶æ‰¹å¤„ç†å°±æ˜¯ä¸€æ¬¡æ€§å¤„ç†å¤šä¸ªæ–‡ä»¶ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªä¸€ä¸ªæ‰‹åŠ¨æ“ä½œã€‚æ¯”å¦‚æŠŠ100å¼ ç…§ç‰‡éƒ½é‡å‘½åï¼Œæˆ–è€…æŠŠæ‰€æœ‰Wordæ–‡æ¡£è½¬æ¢æˆPDFï¼Œè¿™äº›é‡å¤æ€§å·¥ä½œéƒ½å¯ä»¥ç”¨è„šæœ¬è‡ªåŠ¨å®Œæˆã€‚

### 3.2 æ–‡ä»¶åŸºæœ¬æ“ä½œ


**ğŸ“‹ å¸¸ç”¨æ–‡ä»¶æ“ä½œæ¨¡å—**
```python
import os
import shutil
import glob
from pathlib import Path
```

**ğŸ”§ åŸºç¡€æ–‡ä»¶æ“ä½œ**
```python
# å¤åˆ¶æ–‡ä»¶
shutil.copy("æºæ–‡ä»¶.txt", "ç›®æ ‡æ–‡ä»¶.txt")

# ç§»åŠ¨æ–‡ä»¶
shutil.move("æ—§ä½ç½®/æ–‡ä»¶.txt", "æ–°ä½ç½®/æ–‡ä»¶.txt")

# åˆ é™¤æ–‡ä»¶
os.remove("è¦åˆ é™¤çš„æ–‡ä»¶.txt")

# é‡å‘½åæ–‡ä»¶
os.rename("æ—§åå­—.txt", "æ–°åå­—.txt")
```

### 3.3 æ‰¹é‡é‡å‘½åè„šæœ¬


**ğŸ“ æ™ºèƒ½æ‰¹é‡é‡å‘½å**
```python
import os
import datetime

def batch_rename_files(folder_path, prefix="æ–‡ä»¶", extension=None):
    """
    æ‰¹é‡é‡å‘½åæ–‡ä»¶
    
    å‚æ•°:
    folder_path: æ–‡ä»¶å¤¹è·¯å¾„
    prefix: æ–°æ–‡ä»¶åå‰ç¼€
    extension: åªå¤„ç†æŒ‡å®šæ‰©å±•åçš„æ–‡ä»¶
    """
    files = os.listdir(folder_path)
    
    # è¿‡æ»¤æ–‡ä»¶ï¼ˆå¦‚æœæŒ‡å®šäº†æ‰©å±•åï¼‰
    if extension:
        files = [f for f in files if f.endswith(extension)]
    
    # æ’åºç¡®ä¿é‡å‘½åé¡ºåºä¸€è‡´
    files.sort()
    
    renamed_count = 0
    for i, filename in enumerate(files, 1):
        # è·å–æ–‡ä»¶æ‰©å±•å
        _, ext = os.path.splitext(filename)
        
        # ç”Ÿæˆæ–°æ–‡ä»¶å
        new_name = f"{prefix}_{i:03d}{ext}"
        
        # å®Œæ•´è·¯å¾„
        old_path = os.path.join(folder_path, filename)
        new_path = os.path.join(folder_path, new_name)
        
        try:
            os.rename(old_path, new_path)
            print(f"âœ… {filename} â†’ {new_name}")
            renamed_count += 1
        except Exception as e:
            print(f"âŒ é‡å‘½åå¤±è´¥ {filename}: {e}")
    
    print(f"\nğŸ‰ å®Œæˆï¼å…±é‡å‘½å {renamed_count} ä¸ªæ–‡ä»¶")

# ä½¿ç”¨ç¤ºä¾‹
batch_rename_files("./ç…§ç‰‡æ–‡ä»¶å¤¹", "æ—…è¡Œç…§ç‰‡", ".jpg")
```

### 3.4 æ–‡ä»¶åˆ†ç±»æ•´ç†è„šæœ¬


**ğŸ“‚ æŒ‰ç±»å‹è‡ªåŠ¨æ•´ç†æ–‡ä»¶**
```python
import os
import shutil

def organize_files_by_type(source_folder):
    """æŒ‰æ–‡ä»¶ç±»å‹æ•´ç†æ–‡ä»¶"""
    
    # å®šä¹‰æ–‡ä»¶ç±»å‹æ˜ å°„
    file_types = {
        'å›¾ç‰‡': ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.svg'],
        'æ–‡æ¡£': ['.txt', '.doc', '.docx', '.pdf', '.xlsx', '.ppt'],
        'è§†é¢‘': ['.mp4', '.avi', '.mkv', '.mov', '.wmv'],
        'éŸ³é¢‘': ['.mp3', '.wav', '.flac', '.aac'],
        'å‹ç¼©åŒ…': ['.zip', '.rar', '.7z', '.tar', '.gz']
    }
    
    # åˆ›å»ºåˆ†ç±»æ–‡ä»¶å¤¹
    for folder_name in file_types.keys():
        folder_path = os.path.join(source_folder, folder_name)
        os.makedirs(folder_path, exist_ok=True)
    
    # æ•´ç†æ–‡ä»¶
    for filename in os.listdir(source_folder):
        file_path = os.path.join(source_folder, filename)
        
        # è·³è¿‡æ–‡ä»¶å¤¹
        if os.path.isdir(file_path):
            continue
        
        # è·å–æ–‡ä»¶æ‰©å±•å
        _, ext = os.path.splitext(filename)
        ext = ext.lower()
        
        # æ‰¾åˆ°å¯¹åº”çš„åˆ†ç±»
        moved = False
        for category, extensions in file_types.items():
            if ext in extensions:
                target_folder = os.path.join(source_folder, category)
                target_path = os.path.join(target_folder, filename)
                
                try:
                    shutil.move(file_path, target_path)
                    print(f"ğŸ“ {filename} â†’ {category}/")
                    moved = True
                    break
                except Exception as e:
                    print(f"âŒ ç§»åŠ¨å¤±è´¥ {filename}: {e}")
        
        if not moved:
            print(f"â“ æœªçŸ¥ç±»å‹æ–‡ä»¶: {filename}")

# ä½¿ç”¨ç¤ºä¾‹
organize_files_by_type("./ä¸‹è½½æ–‡ä»¶å¤¹")
```

### 3.5 é‡å¤æ–‡ä»¶æŸ¥æ‰¾ä¸å¤„ç†


**ğŸ” æŸ¥æ‰¾å’Œå¤„ç†é‡å¤æ–‡ä»¶**
```python
import os
import hashlib
from collections import defaultdict

def find_duplicate_files(folder_path):
    """æŸ¥æ‰¾é‡å¤æ–‡ä»¶"""
    
    def get_file_hash(file_path):
        """è®¡ç®—æ–‡ä»¶çš„MD5å“ˆå¸Œå€¼"""
        hash_md5 = hashlib.md5()
        try:
            with open(file_path, "rb") as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    hash_md5.update(chunk)
            return hash_md5.hexdigest()
        except Exception:
            return None
    
    # å­˜å‚¨æ–‡ä»¶å“ˆå¸Œå€¼å’Œè·¯å¾„çš„æ˜ å°„
    hash_to_files = defaultdict(list)
    
    # éå†æ‰€æœ‰æ–‡ä»¶
    for root, dirs, files in os.walk(folder_path):
        for filename in files:
            file_path = os.path.join(root, filename)
            file_hash = get_file_hash(file_path)
            
            if file_hash:
                hash_to_files[file_hash].append(file_path)
    
    # æ‰¾å‡ºé‡å¤æ–‡ä»¶
    duplicates = {hash_val: files for hash_val, files in hash_to_files.items() if len(files) > 1}
    
    if duplicates:
        print("ğŸ” å‘ç°é‡å¤æ–‡ä»¶ï¼š")
        for hash_val, files in duplicates.items():
            print(f"\nğŸ“„ é‡å¤ç»„ ({len(files)} ä¸ªæ–‡ä»¶):")
            for file_path in files:
                file_size = os.path.getsize(file_path)
                print(f"  â€¢ {file_path} ({file_size} bytes)")
    else:
        print("âœ… æ²¡æœ‰å‘ç°é‡å¤æ–‡ä»¶")
    
    return duplicates

# ä½¿ç”¨ç¤ºä¾‹
duplicates = find_duplicate_files("./æˆ‘çš„æ–‡æ¡£")
```

---

## 4. ğŸ“Š æ•°æ®å¤„ç†è„šæœ¬


### 4.1 æ•°æ®å¤„ç†è„šæœ¬çš„ä½œç”¨


**ğŸ”¸ ä»€ä¹ˆæ˜¯æ•°æ®å¤„ç†è„šæœ¬**
æ•°æ®å¤„ç†è„šæœ¬å°±æ˜¯ä¸“é—¨ç”¨æ¥å¤„ç†å„ç§æ•°æ®æ–‡ä»¶çš„ç¨‹åºï¼Œæ¯”å¦‚Excelè¡¨æ ¼ã€CSVæ–‡ä»¶ã€JSONæ•°æ®ç­‰ã€‚å®ƒèƒ½å¸®ä½ å¿«é€Ÿåˆ†ææ•°æ®ã€è½¬æ¢æ ¼å¼ã€ç”ŸæˆæŠ¥è¡¨ï¼Œçœå»å¤§é‡æ‰‹å·¥æ“ä½œã€‚

### 4.2 CSVæ–‡ä»¶å¤„ç†


**ğŸ“‹ CSVæ–‡ä»¶è¯»å†™åŸºç¡€**
```python
import csv
import pandas as pd

def process_csv_basic(file_path):
    """åŸºç¡€CSVæ–‡ä»¶å¤„ç†"""
    
    # æ–¹æ³•1ï¼šä½¿ç”¨csvæ¨¡å—
    print("=== ä½¿ç”¨csvæ¨¡å—è¯»å– ===")
    with open(file_path, 'r', encoding='utf-8') as file:
        reader = csv.DictReader(file)
        for i, row in enumerate(reader):
            if i < 3:  # åªæ˜¾ç¤ºå‰3è¡Œ
                print(row)
    
    # æ–¹æ³•2ï¼šä½¿ç”¨pandasï¼ˆæ›´å¼ºå¤§ï¼‰
    print("\n=== ä½¿ç”¨pandasè¯»å– ===")
    df = pd.read_csv(file_path)
    print(f"æ•°æ®å½¢çŠ¶ï¼š{df.shape}")
    print(f"åˆ—åï¼š{list(df.columns)}")
    print("\nå‰3è¡Œæ•°æ®ï¼š")
    print(df.head(3))

# åˆ›å»ºç¤ºä¾‹CSVæ–‡ä»¶
def create_sample_csv():
    """åˆ›å»ºç¤ºä¾‹CSVæ–‡ä»¶"""
    data = [
        ["å§“å", "å¹´é¾„", "åŸå¸‚", "è–ªèµ„"],
        ["å¼ ä¸‰", 25, "åŒ—äº¬", 8000],
        ["æå››", 30, "ä¸Šæµ·", 12000],
        ["ç‹äº”", 28, "æ·±åœ³", 10000],
        ["èµµå…­", 35, "å¹¿å·", 15000]
    ]
    
    with open("å‘˜å·¥æ•°æ®.csv", "w", newline='', encoding='utf-8') as file:
        writer = csv.writer(file)
        writer.writerows(data)
    print("âœ… ç¤ºä¾‹CSVæ–‡ä»¶åˆ›å»ºæˆåŠŸ")

# ä½¿ç”¨ç¤ºä¾‹
create_sample_csv()
process_csv_basic("å‘˜å·¥æ•°æ®.csv")
```

### 4.3 æ•°æ®æ¸…æ´—è„šæœ¬


**ğŸ§¹ æ•°æ®æ¸…æ´—å’Œé¢„å¤„ç†**
```python
import pandas as pd
import re

def clean_data(input_file, output_file):
    """æ•°æ®æ¸…æ´—è„šæœ¬"""
    
    # è¯»å–æ•°æ®
    df = pd.read_csv(input_file)
    print(f"åŸå§‹æ•°æ®: {df.shape[0]} è¡Œ, {df.shape[1]} åˆ—")
    
    # 1. åˆ é™¤é‡å¤è¡Œ
    df_cleaned = df.drop_duplicates()
    print(f"åˆ é™¤é‡å¤å: {df_cleaned.shape[0]} è¡Œ")
    
    # 2. å¤„ç†ç¼ºå¤±å€¼
    missing_before = df_cleaned.isnull().sum().sum()
    df_cleaned = df_cleaned.dropna()  # åˆ é™¤åŒ…å«ç¼ºå¤±å€¼çš„è¡Œ
    missing_after = df_cleaned.isnull().sum().sum()
    print(f"ç¼ºå¤±å€¼å¤„ç†: åˆ é™¤äº† {missing_before - missing_after} ä¸ªç¼ºå¤±å€¼")
    
    # 3. æ•°æ®ç±»å‹è½¬æ¢
    if 'å¹´é¾„' in df_cleaned.columns:
        df_cleaned['å¹´é¾„'] = pd.to_numeric(df_cleaned['å¹´é¾„'], errors='coerce')
    
    if 'è–ªèµ„' in df_cleaned.columns:
        df_cleaned['è–ªèµ„'] = pd.to_numeric(df_cleaned['è–ªèµ„'], errors='coerce')
    
    # 4. æ–‡æœ¬æ¸…æ´—ï¼ˆå»é™¤å¤šä½™ç©ºæ ¼ï¼‰
    for col in df_cleaned.select_dtypes(include=['object']).columns:
        df_cleaned[col] = df_cleaned[col].astype(str).str.strip()
    
    # 5. ä¿å­˜æ¸…æ´—åçš„æ•°æ®
    df_cleaned.to_csv(output_file, index=False, encoding='utf-8')
    print(f"âœ… æ¸…æ´—å®Œæˆï¼Œä¿å­˜åˆ°: {output_file}")
    print(f"æœ€ç»ˆæ•°æ®: {df_cleaned.shape[0]} è¡Œ, {df_cleaned.shape[1]} åˆ—")
    
    return df_cleaned

# ä½¿ç”¨ç¤ºä¾‹
cleaned_data = clean_data("å‘˜å·¥æ•°æ®.csv", "å‘˜å·¥æ•°æ®_æ¸…æ´—å.csv")
```

### 4.4 æ•°æ®ç»Ÿè®¡åˆ†æè„šæœ¬


**ğŸ“ˆ è‡ªåŠ¨ç”Ÿæˆæ•°æ®åˆ†ææŠ¥å‘Š**
```python
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime

def analyze_data(csv_file):
    """æ•°æ®ç»Ÿè®¡åˆ†æ"""
    
    df = pd.read_csv(csv_file)
    
    print("=" * 50)
    print("ğŸ“Š æ•°æ®åˆ†ææŠ¥å‘Š")
    print("=" * 50)
    print(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"æ•°æ®æ–‡ä»¶: {csv_file}")
    print(f"æ•°æ®è§„æ¨¡: {df.shape[0]} è¡Œ Ã— {df.shape[1]} åˆ—")
    
    # 1. åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
    print("\nğŸ“ˆ æ•°å€¼åˆ—ç»Ÿè®¡ä¿¡æ¯:")
    numeric_cols = df.select_dtypes(include=['number']).columns
    if len(numeric_cols) > 0:
        print(df[numeric_cols].describe())
    
    # 2. ç¼ºå¤±å€¼ç»Ÿè®¡
    print("\nâ“ ç¼ºå¤±å€¼ç»Ÿè®¡:")
    missing_stats = df.isnull().sum()
    for col, missing_count in missing_stats.items():
        if missing_count > 0:
            percentage = (missing_count / len(df)) * 100
            print(f"  {col}: {missing_count} ä¸ª ({percentage:.1f}%)")
    
    # 3. åˆ†ç±»æ•°æ®ç»Ÿè®¡
    print("\nğŸ“Š åˆ†ç±»æ•°æ®ç»Ÿè®¡:")
    categorical_cols = df.select_dtypes(include=['object']).columns
    for col in categorical_cols:
        unique_count = df[col].nunique()
        print(f"  {col}: {unique_count} ä¸ªä¸åŒå€¼")
        if unique_count <= 10:  # å¦‚æœç±»åˆ«ä¸å¤šï¼Œæ˜¾ç¤ºåˆ†å¸ƒ
            print(f"    åˆ†å¸ƒ: {dict(df[col].value_counts())}")
    
    return df

# ä½¿ç”¨ç¤ºä¾‹
analyze_data("å‘˜å·¥æ•°æ®.csv")
```

### 4.5 å¤šæ–‡ä»¶æ•°æ®åˆå¹¶è„šæœ¬


**ğŸ”— åˆå¹¶å¤šä¸ªæ•°æ®æ–‡ä»¶**
```python
import pandas as pd
import os
import glob

def merge_csv_files(folder_path, output_file, pattern="*.csv"):
    """åˆå¹¶å¤šä¸ªCSVæ–‡ä»¶"""
    
    # æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…çš„CSVæ–‡ä»¶
    csv_files = glob.glob(os.path.join(folder_path, pattern))
    
    if not csv_files:
        print(f"âŒ åœ¨ {folder_path} ä¸­æœªæ‰¾åˆ°åŒ¹é… {pattern} çš„æ–‡ä»¶")
        return
    
    print(f"ğŸ“ æ‰¾åˆ° {len(csv_files)} ä¸ªæ–‡ä»¶:")
    for file in csv_files:
        print(f"  â€¢ {os.path.basename(file)}")
    
    # è¯»å–å¹¶åˆå¹¶æ‰€æœ‰æ–‡ä»¶
    all_dataframes = []
    
    for file in csv_files:
        try:
            df = pd.read_csv(file)
            # æ·»åŠ æ¥æºæ–‡ä»¶åˆ—
            df['æ•°æ®æ¥æº'] = os.path.basename(file)
            all_dataframes.append(df)
            print(f"âœ… è¯»å– {os.path.basename(file)}: {df.shape[0]} è¡Œ")
        except Exception as e:
            print(f"âŒ è¯»å–å¤±è´¥ {os.path.basename(file)}: {e}")
    
    if all_dataframes:
        # åˆå¹¶æ‰€æœ‰æ•°æ®
        merged_df = pd.concat(all_dataframes, ignore_index=True)
        
        # ä¿å­˜åˆå¹¶ç»“æœ
        merged_df.to_csv(output_file, index=False, encoding='utf-8')
        
        print(f"\nğŸ‰ åˆå¹¶å®Œæˆ!")
        print(f"  åˆå¹¶åæ•°æ®: {merged_df.shape[0]} è¡Œ Ã— {merged_df.shape[1]} åˆ—")
        print(f"  ä¿å­˜åˆ°: {output_file}")
        
        return merged_df
    else:
        print("âŒ æ²¡æœ‰æˆåŠŸè¯»å–ä»»ä½•æ–‡ä»¶")

# ä½¿ç”¨ç¤ºä¾‹
# merge_csv_files("./æ•°æ®æ–‡ä»¶å¤¹", "åˆå¹¶æ•°æ®.csv")
```

---

## 5. â° å®šæ—¶ä»»åŠ¡è„šæœ¬


### 5.1 å®šæ—¶ä»»åŠ¡çš„æ¦‚å¿µ


**ğŸ”¸ ä»€ä¹ˆæ˜¯å®šæ—¶ä»»åŠ¡**
å®šæ—¶ä»»åŠ¡å°±æ˜¯è®©ç¨‹åºåœ¨æŒ‡å®šçš„æ—¶é—´è‡ªåŠ¨è¿è¡Œï¼Œå°±åƒé—¹é’Ÿä¸€æ ·ã€‚æ¯”å¦‚æ¯å¤©æ—©ä¸Š8ç‚¹è‡ªåŠ¨å¤‡ä»½æ–‡ä»¶ï¼Œæ¯å°æ—¶æ£€æŸ¥ä¸€æ¬¡æœåŠ¡å™¨çŠ¶æ€ï¼Œæ¯å‘¨ç”Ÿæˆä¸€æ¬¡æŠ¥è¡¨ç­‰ã€‚

### 5.2 ä½¿ç”¨scheduleåº“å®ç°å®šæ—¶ä»»åŠ¡


**â° scheduleåº“åŸºç¡€ä½¿ç”¨**
```python
import schedule
import time
import datetime

# é¦–å…ˆéœ€è¦å®‰è£…ï¼špip install schedule

def job_function():
    """å®šæ—¶æ‰§è¡Œçš„ä»»åŠ¡å‡½æ•°"""
    current_time = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"ğŸ• å®šæ—¶ä»»åŠ¡æ‰§è¡Œæ—¶é—´: {current_time}")
    print("âœ… ä»»åŠ¡æ‰§è¡Œå®Œæˆ!")

# å®šä¹‰å„ç§å®šæ—¶ç­–ç•¥
def setup_scheduled_tasks():
    """è®¾ç½®å®šæ—¶ä»»åŠ¡"""
    
    # æ¯10ç§’æ‰§è¡Œä¸€æ¬¡
    schedule.every(10).seconds.do(job_function)
    
    # æ¯åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡
    schedule.every().minute.do(job_function)
    
    # æ¯å°æ—¶æ‰§è¡Œä¸€æ¬¡
    schedule.every().hour.do(job_function)
    
    # æ¯å¤©ä¸Šåˆ9ç‚¹æ‰§è¡Œ
    schedule.every().day.at("09:00").do(job_function)
    
    # æ¯å‘¨ä¸€æ‰§è¡Œ
    schedule.every().monday.do(job_function)
    
    print("â° å®šæ—¶ä»»åŠ¡å·²è®¾ç½®")
    print("  â€¢ æ¯10ç§’æ‰§è¡Œä¸€æ¬¡")
    print("  â€¢ æ¯åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡") 
    print("  â€¢ æ¯å°æ—¶æ‰§è¡Œä¸€æ¬¡")
    print("  â€¢ æ¯å¤©09:00æ‰§è¡Œ")
    print("  â€¢ æ¯å‘¨ä¸€æ‰§è¡Œ")

# è¿è¡Œå®šæ—¶ä»»åŠ¡
def run_scheduler():
    """è¿è¡Œå®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨"""
    setup_scheduled_tasks()
    
    print("ğŸš€ å®šæ—¶ä»»åŠ¡å¼€å§‹è¿è¡Œ...")
    print("æŒ‰ Ctrl+C åœæ­¢")
    
    try:
        while True:
            schedule.run_pending()  # æ£€æŸ¥å¹¶è¿è¡Œåˆ°æœŸçš„ä»»åŠ¡
            time.sleep(1)          # ç­‰å¾…1ç§’
    except KeyboardInterrupt:
        print("\nâ¹ï¸ å®šæ—¶ä»»åŠ¡å·²åœæ­¢")

# ä½¿ç”¨ç¤ºä¾‹ï¼ˆæ³¨é‡Šæ‰é¿å…åœ¨æ¼”ç¤ºæ—¶æŒç»­è¿è¡Œï¼‰
# run_scheduler()
```

### 5.3 å®ç”¨çš„å®šæ—¶ä»»åŠ¡ç¤ºä¾‹


**ğŸ—‚ï¸ å®šæ—¶æ¸…ç†ä¸´æ—¶æ–‡ä»¶**
```python
import os
import time
import schedule
from datetime import datetime, timedelta

def clean_temp_files():
    """æ¸…ç†ä¸´æ—¶æ–‡ä»¶çš„å®šæ—¶ä»»åŠ¡"""
    
    temp_folders = [
        os.path.expanduser("~/Downloads"),  # ä¸‹è½½æ–‡ä»¶å¤¹
        "C:/Temp" if os.name == 'nt' else "/tmp",  # ç³»ç»Ÿä¸´æ—¶æ–‡ä»¶å¤¹
    ]
    
    # æ¸…ç†7å¤©å‰çš„æ–‡ä»¶
    cutoff_time = time.time() - (7 * 24 * 60 * 60)
    cleaned_count = 0
    
    for folder in temp_folders:
        if not os.path.exists(folder):
            continue
            
        print(f"ğŸ§¹ æ¸…ç†æ–‡ä»¶å¤¹: {folder}")
        
        try:
            for filename in os.listdir(folder):
                file_path = os.path.join(folder, filename)
                
                # è·³è¿‡æ–‡ä»¶å¤¹
                if os.path.isdir(file_path):
                    continue
                
                # æ£€æŸ¥æ–‡ä»¶ä¿®æ”¹æ—¶é—´
                if os.path.getmtime(file_path) < cutoff_time:
                    try:
                        os.remove(file_path)
                        print(f"  ğŸ—‘ï¸ åˆ é™¤: {filename}")
                        cleaned_count += 1
                    except Exception as e:
                        print(f"  âŒ åˆ é™¤å¤±è´¥ {filename}: {e}")
                        
        except Exception as e:
            print(f"âŒ è®¿é—®æ–‡ä»¶å¤¹å¤±è´¥ {folder}: {e}")
    
    print(f"âœ… æ¸…ç†å®Œæˆï¼Œå…±åˆ é™¤ {cleaned_count} ä¸ªæ–‡ä»¶")

def setup_cleanup_task():
    """è®¾ç½®æ¸…ç†ä»»åŠ¡"""
    # æ¯å¤©å‡Œæ™¨2ç‚¹æ‰§è¡Œæ¸…ç†
    schedule.every().day.at("02:00").do(clean_temp_files)
    
    # ä¹Ÿå¯ä»¥ç«‹å³æ‰§è¡Œä¸€æ¬¡çœ‹æ•ˆæœ
    # clean_temp_files()
    
    print("ğŸ• å·²è®¾ç½®å®šæ—¶æ¸…ç†ä»»åŠ¡ï¼šæ¯å¤©å‡Œæ™¨2ç‚¹æ‰§è¡Œ")

# ä½¿ç”¨ç¤ºä¾‹
setup_cleanup_task()
```

### 5.4 å®šæ—¶å¤‡ä»½è„šæœ¬


**ğŸ’¾ è‡ªåŠ¨å¤‡ä»½é‡è¦æ–‡ä»¶**
```python
import shutil
import os
import schedule
from datetime import datetime
import zipfile

def backup_important_files():
    """å®šæ—¶å¤‡ä»½é‡è¦æ–‡ä»¶"""
    
    # é…ç½®å¤‡ä»½è®¾ç½®
    backup_config = {
        "æºæ–‡ä»¶å¤¹": [
            os.path.expanduser("~/Documents"),  # æ–‡æ¡£æ–‡ä»¶å¤¹
            os.path.expanduser("~/Desktop"),    # æ¡Œé¢
            # å¯ä»¥æ·»åŠ æ›´å¤šæ–‡ä»¶å¤¹
        ],
        "å¤‡ä»½ç›®å½•": os.path.expanduser("~/Backups"),
        "ä¿ç•™å¤©æ•°": 30  # ä¿ç•™30å¤©çš„å¤‡ä»½
    }
    
    # åˆ›å»ºå¤‡ä»½ç›®å½•
    os.makedirs(backup_config["å¤‡ä»½ç›®å½•"], exist_ok=True)
    
    # ç”Ÿæˆå¤‡ä»½æ–‡ä»¶åï¼ˆåŒ…å«æ—¶é—´æˆ³ï¼‰
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_filename = f"backup_{timestamp}.zip"
    backup_path = os.path.join(backup_config["å¤‡ä»½ç›®å½•"], backup_filename)
    
    print(f"ğŸ”„ å¼€å§‹å¤‡ä»½...")
    print(f"ğŸ“¦ å¤‡ä»½æ–‡ä»¶: {backup_filename}")
    
    # åˆ›å»ºZIPå¤‡ä»½
    try:
        with zipfile.ZipFile(backup_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
            file_count = 0
            
            for source_folder in backup_config["æºæ–‡ä»¶å¤¹"]:
                if not os.path.exists(source_folder):
                    print(f"âš ï¸ æºæ–‡ä»¶å¤¹ä¸å­˜åœ¨: {source_folder}")
                    continue
                
                print(f"ğŸ“ å¤‡ä»½æ–‡ä»¶å¤¹: {source_folder}")
                
                # éå†æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡ä»¶
                for root, dirs, files in os.walk(source_folder):
                    for file in files:
                        file_path = os.path.join(root, file)
                        # è®¡ç®—ç›¸å¯¹è·¯å¾„
                        arc_name = os.path.relpath(file_path, os.path.dirname(source_folder))
                        
                        try:
                            zipf.write(file_path, arc_name)
                            file_count += 1
                        except Exception as e:
                            print(f"  âš ï¸ è·³è¿‡æ–‡ä»¶ {file}: {e}")
            
            print(f"âœ… å¤‡ä»½å®Œæˆ! å…±å¤‡ä»½ {file_count} ä¸ªæ–‡ä»¶")
            
    except Exception as e:
        print(f"âŒ å¤‡ä»½å¤±è´¥: {e}")
        return
    
    # æ¸…ç†æ—§å¤‡ä»½
    cleanup_old_backups(backup_config["å¤‡ä»½ç›®å½•"], backup_config["ä¿ç•™å¤©æ•°"])

def cleanup_old_backups(backup_dir, keep_days):
    """æ¸…ç†æ—§çš„å¤‡ä»½æ–‡ä»¶"""
    cutoff_time = time.time() - (keep_days * 24 * 60 * 60)
    cleaned_count = 0
    
    for filename in os.listdir(backup_dir):
        if filename.startswith("backup_") and filename.endswith(".zip"):
            file_path = os.path.join(backup_dir, filename)
            if os.path.getmtime(file_path) < cutoff_time:
                try:
                    os.remove(file_path)
                    print(f"ğŸ—‘ï¸ åˆ é™¤æ—§å¤‡ä»½: {filename}")
                    cleaned_count += 1
                except Exception as e:
                    print(f"âŒ åˆ é™¤å¤±è´¥ {filename}: {e}")
    
    if cleaned_count > 0:
        print(f"ğŸ§¹ æ¸…ç†äº† {cleaned_count} ä¸ªæ—§å¤‡ä»½æ–‡ä»¶")

def setup_backup_schedule():
    """è®¾ç½®å¤‡ä»½å®šæ—¶ä»»åŠ¡"""
    # æ¯å¤©æ™šä¸Š11ç‚¹å¤‡ä»½
    schedule.every().day.at("23:00").do(backup_important_files)
    
    # å¯ä»¥ç«‹å³æ‰§è¡Œä¸€æ¬¡æµ‹è¯•
    # backup_important_files()
    
    print("ğŸ’¾ å·²è®¾ç½®å®šæ—¶å¤‡ä»½ä»»åŠ¡ï¼šæ¯å¤©æ™šä¸Š11ç‚¹æ‰§è¡Œ")

# ä½¿ç”¨ç¤ºä¾‹
setup_backup_schedule()
```

### 5.5 å®šæ—¶ç›‘æ§è„šæœ¬


**ğŸ‘€ ç³»ç»Ÿç›‘æ§å®šæ—¶ä»»åŠ¡**
```python
import psutil
import schedule
import smtplib
from email.mime.text import MIMEText
from datetime import datetime

def system_health_check():
    """ç³»ç»Ÿå¥åº·æ£€æŸ¥"""
    
    # è·å–ç³»ç»Ÿä¿¡æ¯
    cpu_percent = psutil.cpu_percent(interval=1)
    memory = psutil.virtual_memory()
    disk = psutil.disk_usage('/')
    
    # è®¾ç½®è­¦å‘Šé˜ˆå€¼
    CPU_THRESHOLD = 80  # CPUä½¿ç”¨ç‡è¶…è¿‡80%è­¦å‘Š
    MEMORY_THRESHOLD = 80  # å†…å­˜ä½¿ç”¨ç‡è¶…è¿‡80%è­¦å‘Š
    DISK_THRESHOLD = 90  # ç£ç›˜ä½¿ç”¨ç‡è¶…è¿‡90%è­¦å‘Š
    
    warnings = []
    
    # æ£€æŸ¥CPU
    if cpu_percent > CPU_THRESHOLD:
        warnings.append(f"âš ï¸ CPUä½¿ç”¨ç‡è¿‡é«˜: {cpu_percent:.1f}%")
    
    # æ£€æŸ¥å†…å­˜
    memory_percent = memory.percent
    if memory_percent > MEMORY_THRESHOLD:
        warnings.append(f"âš ï¸ å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {memory_percent:.1f}%")
    
    # æ£€æŸ¥ç£ç›˜
    disk_percent = (disk.used / disk.total) * 100
    if disk_percent > DISK_THRESHOLD:
        warnings.append(f"âš ï¸ ç£ç›˜ä½¿ç”¨ç‡è¿‡é«˜: {disk_percent:.1f}%")
    
    # ç”ŸæˆæŠ¥å‘Š
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    report = f"""
ğŸ–¥ï¸ ç³»ç»Ÿå¥åº·æ£€æŸ¥æŠ¥å‘Š
æ—¶é—´: {timestamp}

ğŸ“Š ç³»ç»ŸçŠ¶æ€:
  CPUä½¿ç”¨ç‡: {cpu_percent:.1f}%
  å†…å­˜ä½¿ç”¨ç‡: {memory_percent:.1f}%
  ç£ç›˜ä½¿ç”¨ç‡: {disk_percent:.1f}%

"""
    
    if warnings:
        report += "âš ï¸ å‘ç°é—®é¢˜:\n"
        for warning in warnings:
            report += f"  {warning}\n"
    else:
        report += "âœ… ç³»ç»Ÿè¿è¡Œæ­£å¸¸"
    
    print(report)
    
    # å¦‚æœæœ‰è­¦å‘Šï¼Œå¯ä»¥å‘é€é‚®ä»¶é€šçŸ¥ï¼ˆéœ€è¦é…ç½®é‚®ç®±ï¼‰
    if warnings:
        # send_alert_email(report)  # éœ€è¦å®ç°é‚®ä»¶å‘é€åŠŸèƒ½
        pass
    
    return warnings

def setup_monitoring():
    """è®¾ç½®ç›‘æ§å®šæ—¶ä»»åŠ¡"""
    # æ¯5åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
    schedule.every(5).minutes.do(system_health_check)
    
    print("ğŸ‘€ å·²è®¾ç½®ç³»ç»Ÿç›‘æ§ï¼šæ¯5åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡")
    
    # ç«‹å³æ‰§è¡Œä¸€æ¬¡
    system_health_check()

# ä½¿ç”¨ç¤ºä¾‹
setup_monitoring()
```

---

## 6. ğŸ‘€ ç›‘æ§è„šæœ¬å¼€å‘


### 6.1 ç›‘æ§è„šæœ¬çš„ä½œç”¨


**ğŸ”¸ ä»€ä¹ˆæ˜¯ç›‘æ§è„šæœ¬**
ç›‘æ§è„šæœ¬å°±åƒä¸€ä¸ª24å°æ—¶ä¸ä¼‘æ¯çš„"å®ˆé—¨å‘˜"ï¼Œå®ƒä¼šæŒç»­è§‚å¯Ÿç³»ç»Ÿçš„å„ç§çŠ¶æ€ï¼Œæ¯”å¦‚CPUä½¿ç”¨ç‡ã€å†…å­˜æ¶ˆè€—ã€ç£ç›˜ç©ºé—´ã€ç½‘ç»œè¿æ¥ç­‰ã€‚ä¸€æ—¦å‘ç°å¼‚å¸¸ï¼Œç«‹å³å‘å‡ºè­¦æŠ¥ã€‚

### 6.2 ç³»ç»Ÿèµ„æºç›‘æ§


**ğŸ“ˆ åŸºç¡€ç³»ç»Ÿèµ„æºç›‘æ§**
```python
import psutil
import time
import json
from datetime import datetime

class SystemMonitor:
    """ç³»ç»Ÿç›‘æ§ç±»"""
    
    def __init__(self):
        self.log_file = "system_monitor.log"
        
    def get_system_stats(self):
        """è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            "æ—¶é—´": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "CPUä½¿ç”¨ç‡": psutil.cpu_percent(interval=1),
            "å†…å­˜ä¿¡æ¯": {
                "æ€»å†…å­˜": psutil.virtual_memory().total // (1024**3),  # GB
                "å·²ä½¿ç”¨": psutil.virtual_memory().used // (1024**3),   # GB
                "ä½¿ç”¨ç‡": psutil.virtual_memory().percent
            },
            "ç£ç›˜ä¿¡æ¯": {
                "æ€»ç©ºé—´": psutil.disk_usage('/').total // (1024**3),  # GB
                "å·²ä½¿ç”¨": psutil.disk_usage('/').used // (1024**3),   # GB
                "ä½¿ç”¨ç‡": (psutil.disk_usage('/').used / psutil.disk_usage('/').total) * 100
            },
            "ç½‘ç»œIO": {
                "å‘é€å­—èŠ‚": psutil.net_io_counters().bytes_sent,
                "æ¥æ”¶å­—èŠ‚": psutil.net_io_counters().bytes_recv
            }
        }
        return stats
    
    def check_thresholds(self, stats):
        """æ£€æŸ¥æ˜¯å¦è¶…è¿‡é˜ˆå€¼"""
        alerts = []
        
        # CPUé˜ˆå€¼æ£€æŸ¥
        if stats["CPUä½¿ç”¨ç‡"] > 80:
            alerts.append(f"ğŸ”´ CPUä½¿ç”¨ç‡è¿‡é«˜: {stats['CPUä½¿ç”¨ç‡']:.1f}%")
        
        # å†…å­˜é˜ˆå€¼æ£€æŸ¥
        if stats["å†…å­˜ä¿¡æ¯"]["ä½¿ç”¨ç‡"] > 85:
            alerts.append(f"ğŸ”´ å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {stats['å†…å­˜ä¿¡æ¯']['ä½¿ç”¨ç‡']:.1f}%")
        
        # ç£ç›˜é˜ˆå€¼æ£€æŸ¥
        if stats["ç£ç›˜ä¿¡æ¯"]["ä½¿ç”¨ç‡"] > 90:
            alerts.append(f"ğŸ”´ ç£ç›˜ä½¿ç”¨ç‡è¿‡é«˜: {stats['ç£ç›˜ä¿¡æ¯']['ä½¿ç”¨ç‡']:.1f}%")
        
        return alerts
    
    def log_stats(self, stats, alerts):
        """è®°å½•ç»Ÿè®¡ä¿¡æ¯åˆ°æ—¥å¿—"""
        log_entry = {
            "stats": stats,
            "alerts": alerts,
            "alert_count": len(alerts)
        }
        
        with open(self.log_file, "a", encoding="utf-8") as f:
            f.write(json.dumps(log_entry, ensure_ascii=False) + "\n")
    
    def display_stats(self, stats, alerts):
        """æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯"""
        print("=" * 60)
        print(f"ğŸ–¥ï¸ ç³»ç»Ÿç›‘æ§æŠ¥å‘Š - {stats['æ—¶é—´']}")
        print("=" * 60)
        
        # CPUä¿¡æ¯
        cpu_status = "ğŸ”´" if stats["CPUä½¿ç”¨ç‡"] > 80 else "ğŸŸ¢"
        print(f"{cpu_status} CPUä½¿ç”¨ç‡: {stats['CPUä½¿ç”¨ç‡']:.1f}%")
        
        # å†…å­˜ä¿¡æ¯
        mem = stats["å†…å­˜ä¿¡æ¯"]
        mem_status = "ğŸ”´" if mem["ä½¿ç”¨ç‡"] > 85 else "ğŸŸ¢"
        print(f"{mem_status} å†…å­˜: {mem['å·²ä½¿ç”¨']}GB / {mem['æ€»å†…å­˜']}GB ({mem['ä½¿ç”¨ç‡']:.1f}%)")
        
        # ç£ç›˜ä¿¡æ¯
        disk = stats["ç£ç›˜ä¿¡æ¯"]
        disk_status = "ğŸ”´" if disk["ä½¿ç”¨ç‡"] > 90 else "ğŸŸ¢"
        print(f"{disk_status} ç£ç›˜: {disk['å·²ä½¿ç”¨']}GB / {disk['æ€»ç©ºé—´']}GB ({disk['ä½¿ç”¨ç‡']:.1f}%)")
        
        # ç½‘ç»œä¿¡æ¯
        net = stats["ç½‘ç»œIO"]
        print(f"ğŸŒ ç½‘ç»œ: â†‘{net['å‘é€å­—èŠ‚']//1024//1024}MB â†“{net['æ¥æ”¶å­—èŠ‚']//1024//1024}MB")
        
        # æ˜¾ç¤ºè­¦æŠ¥
        if alerts:
            print("\nâš ï¸ è­¦æŠ¥ä¿¡æ¯:")
            for alert in alerts:
                print(f"  {alert}")
        else:
            print("\nâœ… ç³»ç»Ÿè¿è¡Œæ­£å¸¸")
    
    def run_monitoring(self, interval=60):
        """è¿è¡Œç›‘æ§"""
        print(f"ğŸš€ ç³»ç»Ÿç›‘æ§å¼€å§‹è¿è¡Œï¼Œæ£€æŸ¥é—´éš”: {interval}ç§’")
        print("æŒ‰ Ctrl+C åœæ­¢ç›‘æ§")
        
        try:
            while True:
                # è·å–ç³»ç»Ÿç»Ÿè®¡
                stats = self.get_system_stats()
                
                # æ£€æŸ¥é˜ˆå€¼
                alerts = self.check_thresholds(stats)
                
                # æ˜¾ç¤ºä¿¡æ¯
                self.display_stats(stats, alerts)
                
                # è®°å½•æ—¥å¿—
                self.log_stats(stats, alerts)
                
                # ç­‰å¾…ä¸‹ä¸€æ¬¡æ£€æŸ¥
                time.sleep(interval)
                
        except KeyboardInterrupt:
            print("\nâ¹ï¸ ç›‘æ§å·²åœæ­¢")

# ä½¿ç”¨ç¤ºä¾‹
monitor = SystemMonitor()
# monitor.run_monitoring(30)  # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡
```

### 6.3 è¿›ç¨‹ç›‘æ§è„šæœ¬


**ğŸ” ç›‘æ§ç‰¹å®šè¿›ç¨‹**
```python
import psutil
import time
from datetime import datetime

class ProcessMonitor:
    """è¿›ç¨‹ç›‘æ§ç±»"""
    
    def __init__(self, process_names):
        """
        åˆå§‹åŒ–è¿›ç¨‹ç›‘æ§
        process_names: è¦ç›‘æ§çš„è¿›ç¨‹ååˆ—è¡¨
        """
        self.process_names = process_names if isinstance(process_names, list) else [process_names]
        self.monitored_processes = {}
    
    def find_processes(self):
        """æŸ¥æ‰¾è¦ç›‘æ§çš„è¿›ç¨‹"""
        found_processes = {}
        
        for proc in psutil.process_iter(['pid', 'name', 'cpu_percent', 'memory_info']):
            try:
                proc_name = proc.info['name'].lower()
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯æˆ‘ä»¬è¦ç›‘æ§çš„è¿›ç¨‹
                for target_name in self.process_names:
                    if target_name.lower() in proc_name:
                        if target_name not in found_processes:
                            found_processes[target_name] = []
                        
                        found_processes[target_name].append({
                            'pid': proc.info['pid'],
                            'name': proc.info['name'],
                            'cpu_percent': proc.info['cpu_percent'],
                            'memory_mb': proc.info['memory_info'].rss // (1024 * 1024)
                        })
            except (psutil.NoSuchProcess, psutil.AccessDenied):
                continue
        
        return found_processes
    
    def monitor_processes(self):
        """ç›‘æ§è¿›ç¨‹çŠ¶æ€"""
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        processes = self.find_processes()
        
        print(f"ğŸ” è¿›ç¨‹ç›‘æ§æŠ¥å‘Š - {current_time}")
        print("=" * 60)
        
        for target_name in self.process_names:
            if target_name in processes:
                print(f"\nğŸ“‹ è¿›ç¨‹: {target_name}")
                print("  PID     | CPU%  | å†…å­˜(MB) | è¿›ç¨‹å")
                print("  " + "-" * 45)
                
                for proc in processes[target_name]:
                    print(f"  {proc['pid']:<8} | {proc['cpu_percent']:<5.1f} | {proc['memory_mb']:<8} | {proc['name']}")
                
                # æ£€æŸ¥å¼‚å¸¸æƒ…å†µ
                total_memory = sum(proc['memory_mb'] for proc in processes[target_name])
                if total_memory > 1000:  # è¶…è¿‡1GBå†…å­˜
                    print(f"  âš ï¸ å†…å­˜ä½¿ç”¨è¿‡é«˜: {total_memory}MB")
                
                avg_cpu = sum(proc['cpu_percent'] for proc in processes[target_name]) / len(processes[target_name])
                if avg_cpu > 50:  # å¹³å‡CPUè¶…è¿‡50%
                    print(f"  âš ï¸ CPUä½¿ç”¨ç‡è¿‡é«˜: {avg_cpu:.1f}%")
            else:
                print(f"\nâŒ æœªæ‰¾åˆ°è¿›ç¨‹: {target_name}")
    
    def run_monitoring(self, interval=30):
        """è¿è¡Œè¿›ç¨‹ç›‘æ§"""
        print(f"ğŸš€ è¿›ç¨‹ç›‘æ§å¼€å§‹ï¼Œç›‘æ§è¿›ç¨‹: {', '.join(self.process_names)}")
        print(f"æ£€æŸ¥é—´éš”: {interval}ç§’")
        print("æŒ‰ Ctrl+C åœæ­¢ç›‘æ§")
        
        try:
            while True:
                self.monitor_processes()
                time.sleep(interval)
        except KeyboardInterrupt:
            print("\nâ¹ï¸ è¿›ç¨‹ç›‘æ§å·²åœæ­¢")

# ä½¿ç”¨ç¤ºä¾‹
processes_to_monitor = ["python", "chrome", "notepad"]
proc_monitor = ProcessMonitor(processes_to_monitor)
# proc_monitor.run_monitoring(30)
```

### 6.4 ç½‘ç»œè¿æ¥ç›‘æ§


**ğŸŒ ç›‘æ§ç½‘ç»œè¿æ¥çŠ¶æ€**
```python
import psutil
import socket
import time
from collections import defaultdict
from datetime import datetime

class NetworkMonitor:
    """ç½‘ç»œç›‘æ§ç±»"""
    
    def __init__(self):
        self.previous_stats = None
    
    def get_network_stats(self):
        """è·å–ç½‘ç»œç»Ÿè®¡ä¿¡æ¯"""
        stats = psutil.net_io_counters()
        connections = psutil.net_connections()
        
        # ç»Ÿè®¡è¿æ¥çŠ¶æ€
        connection_stats = defaultdict(int)
        for conn in connections:
            connection_stats[conn.status] += 1
        
        return {
            "io_stats": stats,
            "connections": dict(connection_stats),
            "timestamp": datetime.now()
        }
    
    def calculate_speed(self, current_stats):
        """è®¡ç®—ç½‘ç»œé€Ÿåº¦"""
        if self.previous_stats is None:
            return None
        
        time_diff = (current_stats["timestamp"] - self.previous_stats["timestamp"]).total_seconds()
        
        if time_diff <= 0:
            return None
        
        current_io = current_stats["io_stats"]
        previous_io = self.previous_stats["io_stats"]
        
        upload_speed = (current_io.bytes_sent - previous_io.bytes_sent) / time_diff
        download_speed = (current_io.bytes_recv - previous_io.bytes_recv) / time_diff
        
        return {
            "upload_speed_mbps": upload_speed / (1024 * 1024),
            "download_speed_mbps": download_speed / (1024 * 1024)
        }
    
    def check_suspicious_connections(self):
        """æ£€æŸ¥å¯ç–‘è¿æ¥"""
        suspicious = []
        
        try:
            connections = psutil.net_connections(kind='inet')
            
            # ç»Ÿè®¡å„ä¸ªç«¯å£çš„è¿æ¥æ•°
            port_connections = defaultdict(int)
            for conn in connections:
                if conn.laddr:
                    port_connections[conn.laddr.port] += 1
            
            # æ£€æŸ¥ç«¯å£è¿æ¥æ•°è¿‡å¤šçš„æƒ…å†µ
            for port, count in port_connections.items():
                if count > 50:  # è¶…è¿‡50ä¸ªè¿æ¥
                    suspicious.append(f"ç«¯å£ {port} è¿æ¥æ•°è¿‡å¤š: {count}")
            
            # æ£€æŸ¥å¤–éƒ¨è¿æ¥
            external_connections = []
            for conn in connections:
                if conn.raddr and conn.status == 'ESTABLISHED':
                    external_connections.append(f"{conn.raddr.ip}:{conn.raddr.port}")
            
            if len(external_connections) > 100:
                suspicious.append(f"å¤–éƒ¨è¿æ¥æ•°è¿‡å¤š: {len(external_connections)}")
                
        except Exception as e:
            suspicious.append(f"æ£€æŸ¥è¿æ¥æ—¶å‡ºé”™: {e}")
        
        return suspicious
    
    def display_network_status(self, stats, speed_info, suspicious):
        """æ˜¾ç¤ºç½‘ç»œçŠ¶æ€"""
        current_time = stats["timestamp"].strftime("%Y-%m-%d %H:%M:%S")
        
        print("=" * 60)
        print(f"ğŸŒ ç½‘ç»œç›‘æ§æŠ¥å‘Š - {current_time}")
        print("=" * 60)
        
        # IOç»Ÿè®¡
        io = stats["io_stats"]
        print(f"ğŸ“Š ç½‘ç»œIOç»Ÿè®¡:")
        print(f"  å‘é€æ€»é‡: {io.bytes_sent // (1024*1024):,} MB")
        print(f"  æ¥æ”¶æ€»é‡: {io.bytes_recv // (1024*1024):,} MB")
        print(f"  å‘é€åŒ…æ•°: {io.packets_sent:,}")
        print(f"  æ¥æ”¶åŒ…æ•°: {io.packets_recv:,}")
        
        # è¿æ¥é€Ÿåº¦
        if speed_info:
            print(f"\nâš¡ å½“å‰ç½‘é€Ÿ:")
            print(f"  ä¸Šä¼ é€Ÿåº¦: {speed_info['upload_speed_mbps']:.2f} Mbps")
            print(f"  ä¸‹è½½é€Ÿåº¦: {speed_info['download_speed_mbps']:.2f} Mbps")
        
        # è¿æ¥çŠ¶æ€ç»Ÿè®¡
        print(f"\nğŸ”— è¿æ¥çŠ¶æ€ç»Ÿè®¡:")
        for status, count in stats["connections"].items():
            print(f"  {status}: {count}")
        
        # å¯ç–‘è¿æ¥
        if suspicious:
            print(f"\nâš ï¸ å¯ç–‘è¿æ¥:")
            for item in suspicious:
                print(f"  ğŸ”´ {item}")
        else:
            print(f"\nâœ… ç½‘ç»œè¿æ¥æ­£å¸¸")
    
    def run_monitoring(self, interval=30):
        """è¿è¡Œç½‘ç»œç›‘æ§"""
        print(f"ğŸš€ ç½‘ç»œç›‘æ§å¼€å§‹è¿è¡Œï¼Œæ£€æŸ¥é—´éš”: {interval}ç§’")
        print("æŒ‰ Ctrl+C åœæ­¢ç›‘æ§")
        
        try:
            while True:
                # è·å–å½“å‰ç»Ÿè®¡
                current_stats = self.get_network_stats()
                
                # è®¡ç®—é€Ÿåº¦
                speed_info = self.calculate_speed(current_stats)
                
                # æ£€æŸ¥å¯ç–‘è¿æ¥
                suspicious = self.check_suspicious_connections()
                
                # æ˜¾ç¤ºçŠ¶æ€
                self.display_network_status(current_stats, speed_info, suspicious)
                
                # æ›´æ–°ä¸Šä¸€æ¬¡çš„ç»Ÿè®¡
                self.previous_stats = current_stats
                
                time.sleep(interval)
                
        except KeyboardInterrupt:
            print("\nâ¹ï¸ ç½‘ç»œç›‘æ§å·²åœæ­¢")

# ä½¿ç”¨ç¤ºä¾‹
net_monitor = NetworkMonitor()
# net_monitor.run_monitoring(30)
```

---

## 7. ğŸš€ éƒ¨ç½²è„šæœ¬å®è·µ


### 7.1 éƒ¨ç½²è„šæœ¬çš„æ¦‚å¿µ


**ğŸ”¸ ä»€ä¹ˆæ˜¯éƒ¨ç½²è„šæœ¬**
éƒ¨ç½²è„šæœ¬å°±æ˜¯è‡ªåŠ¨åŒ–å‘å¸ƒç¨‹åºçš„è„šæœ¬ï¼Œå®ƒèƒ½å¸®ä½ ä¸€é”®å®Œæˆä»ä»£ç æ›´æ–°ã€ç¼–è¯‘æ„å»ºã€æ–‡ä»¶ä¼ è¾“åˆ°æœåŠ¡é‡å¯çš„æ•´ä¸ªå‘å¸ƒæµç¨‹ã€‚å°±åƒå·¥å‚çš„è‡ªåŠ¨åŒ–ç”Ÿäº§çº¿ä¸€æ ·ï¼Œç¡®ä¿æ¯æ¬¡éƒ¨ç½²éƒ½æ ‡å‡†åŒ–ã€å¯é‡å¤ã€‚

### 7.2 Webåº”ç”¨éƒ¨ç½²è„šæœ¬


**ğŸŒ Flaskåº”ç”¨è‡ªåŠ¨éƒ¨ç½²**
```python
import os
import subprocess
import shutil
import time
from datetime import datetime
import zipfile

class WebDeployer:
    """Webåº”ç”¨éƒ¨ç½²å™¨"""
    
    def __init__(self, config):
        """
        åˆå§‹åŒ–éƒ¨ç½²å™¨
        config: éƒ¨ç½²é…ç½®å­—å…¸
        """
        self.config = config
        self.deploy_log = []
    
    def log_step(self, message, status="INFO"):
        """è®°å½•éƒ¨ç½²æ­¥éª¤"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        log_entry = f"[{timestamp}] {status}: {message}"
        self.deploy_log.append(log_entry)
        
        # æ ¹æ®çŠ¶æ€é€‰æ‹©å›¾æ ‡
        icon = {"INFO": "â„¹ï¸", "SUCCESS": "âœ…", "ERROR": "âŒ", "WARNING": "âš ï¸"}[status]
        print(f"{icon} {log_entry}")
    
    def backup_current_version(self):
        """å¤‡ä»½å½“å‰ç‰ˆæœ¬"""
        self.log_step("å¼€å§‹å¤‡ä»½å½“å‰ç‰ˆæœ¬")
        
        app_dir = self.config["app_directory"]
        backup_dir = self.config["backup_directory"]
        
        if not os.path.exists(app_dir):
            self.log_step(f"åº”ç”¨ç›®å½•ä¸å­˜åœ¨: {app_dir}", "WARNING")
            return True
        
        # åˆ›å»ºå¤‡ä»½ç›®å½•
        os.makedirs(backup_dir, exist_ok=True)
        
        # ç”Ÿæˆå¤‡ä»½æ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_filename = f"backup_{timestamp}.zip"
        backup_path = os.path.join(backup_dir, backup_filename)
        
        try:
            # åˆ›å»ºZIPå¤‡ä»½
            with zipfile.ZipFile(backup_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                for root, dirs, files in os.walk(app_dir):
                    for file in files:
                        file_path = os.path.join(root, file)
                        arc_name = os.path.relpath(file_path, app_dir)
                        zipf.write(file_path, arc_name)
            
            self.log_step(f"å¤‡ä»½æˆåŠŸ: {backup_filename}", "SUCCESS")
            return True
            
        except Exception as e:
            self.log_step(f"å¤‡ä»½å¤±è´¥: {e}", "ERROR")
            return False
    
    def pull_latest_code(self):
        """æ‹‰å–æœ€æ–°ä»£ç """
        self.log_step("æ‹‰å–æœ€æ–°ä»£ç ")
        
        try:
            # åˆ‡æ¢åˆ°é¡¹ç›®ç›®å½•
            os.chdir(self.config["project_directory"])
            
            # æ‰§è¡Œgit pull
            result = subprocess.run(
                ["git", "pull", "origin", "main"],
                capture_output=True,
                text=True
            )
            
            if result.returncode == 0:
                self.log_step("ä»£ç æ‹‰å–æˆåŠŸ", "SUCCESS")
                return True
            else:
                self.log_step(f"ä»£ç æ‹‰å–å¤±è´¥: {result.stderr}", "ERROR")
                return False
                
        except Exception as e:
            self.log_step(f"ä»£ç æ‹‰å–å¼‚å¸¸: {e}", "ERROR")
            return False
    
    def install_dependencies(self):
        """å®‰è£…ä¾èµ–"""
        self.log_step("å®‰è£…Pythonä¾èµ–")
        
        try:
            # æ¿€æ´»è™šæ‹Ÿç¯å¢ƒå¹¶å®‰è£…ä¾èµ–
            venv_python = os.path.join(self.config["venv_path"], "bin", "python")
            if os.name == 'nt':  # Windows
                venv_python = os.path.join(self.config["venv_path"], "Scripts", "python.exe")
            
            result = subprocess.run(
                [venv_python, "-m", "pip", "install", "-r", "requirements.txt"],
                cwd=self.config["project_directory"],
                capture_output=True,
                text=True
            )
            
            if result.returncode == 0:
                self.log_step("ä¾èµ–å®‰è£…æˆåŠŸ", "SUCCESS")
                return True
            else:
                self.log_step(f"ä¾èµ–å®‰è£…å¤±è´¥: {result.stderr}", "ERROR")
                return False
                
        except Exception as e:
            self.log_step(f"ä¾èµ–å®‰è£…å¼‚å¸¸: {e}", "ERROR")
            return False
    
    def run_tests(self):
        """è¿è¡Œæµ‹è¯•"""
        self.log_step("è¿è¡Œæµ‹è¯•ç”¨ä¾‹")
        
        try:
            venv_python = os.path.join(self.config["venv_path"], "bin", "python")
            if os.name == 'nt':
                venv_python = os.path.join(self.config["venv_path"], "Scripts", "python.exe")
            
            result = subprocess.run(
                [venv_python, "-m", "pytest", "tests/"],
                cwd=self.config["project_directory"],
                capture_output=True,
                text=True
            )
            
            if result.returncode == 0:
                self.log_step("æµ‹è¯•é€šè¿‡", "SUCCESS")
                return True
            else:
                self.log_step(f"æµ‹è¯•å¤±è´¥: {result.stderr}", "ERROR")
                return False
                
        except Exception as e:
            self.log_step(f"æµ‹è¯•è¿è¡Œå¼‚å¸¸: {e}", "ERROR")
            return False
    
    def deploy_application(self):
        """éƒ¨ç½²åº”ç”¨"""
        self.log_step("éƒ¨ç½²åº”ç”¨æ–‡ä»¶")
        
        try:
            source_dir = self.config["project_directory"]
            target_dir = self.config["app_directory"]
            
            # åˆ›å»ºç›®æ ‡ç›®å½•
            os.makedirs(target_dir, exist_ok=True)
            
            # å¤åˆ¶æ–‡ä»¶ï¼ˆæ’é™¤ä¸éœ€è¦çš„æ–‡ä»¶ï¼‰
            exclude_patterns = ['.git', '__pycache__', '*.pyc', 'tests', '.pytest_cache']
            
            for item in os.listdir(source_dir):
                source_path = os.path.join(source_dir, item)
                target_path = os.path.join(target_dir, item)
                
                # æ£€æŸ¥æ˜¯å¦åº”è¯¥æ’é™¤
                should_exclude = any(pattern in item for pattern in exclude_patterns)
                if should_exclude:
                    continue
                
                if os.path.isfile(source_path):
                    shutil.copy2(source_path, target_path)
                elif os.path.isdir(source_path):
                    if os.path.exists(target_path):
                        shutil.rmtree(target_path)
                    shutil.copytree(source_path, target_path)
            
            self.log_step("åº”ç”¨éƒ¨ç½²æˆåŠŸ", "SUCCESS")
            return True
            
        except Exception as e:
            self.log_step(f"åº”ç”¨éƒ¨ç½²å¤±è´¥: {e}", "ERROR")
            return False
    
    def restart_service(self):
        """é‡å¯æœåŠ¡"""
        self.log_step("é‡å¯åº”ç”¨æœåŠ¡")
        
        try:
            service_name = self.config["service_name"]
            
            # Linuxç³»ç»Ÿä½¿ç”¨systemctl
            if os.name != 'nt':
                result = subprocess.run(
                    ["sudo", "systemctl", "restart", service_name],
                    capture_output=True,
                    text=True
                )
                
                if result.returncode == 0:
                    self.log_step("æœåŠ¡é‡å¯æˆåŠŸ", "SUCCESS")
                    return True
                else:
                    self.log_step(f"æœåŠ¡é‡å¯å¤±è´¥: {result.stderr}", "ERROR")
                    return False
            else:
                self.log_step("Windowsç³»ç»Ÿè¯·æ‰‹åŠ¨é‡å¯æœåŠ¡", "WARNING")
                return True
                
        except Exception as e:
            self.log_step(f"æœåŠ¡é‡å¯å¼‚å¸¸: {e}", "ERROR")
            return False
    
    def health_check(self):
        """å¥åº·æ£€æŸ¥"""
        self.log_step("æ‰§è¡Œå¥åº·æ£€æŸ¥")
        
        import requests
        
        try:
            url = self.config["health_check_url"]
            response = requests.get(url, timeout=10)
            
            if response.status_code == 200:
                self.log_step("å¥åº·æ£€æŸ¥é€šè¿‡", "SUCCESS")
                return True
            else:
                self.log_step(f"å¥åº·æ£€æŸ¥å¤±è´¥: HTTP {response.status_code}", "ERROR")
                return False
                
        except Exception as e:
            self.log_step(f"å¥åº·æ£€æŸ¥å¼‚å¸¸: {e}", "ERROR")
            return False
    
    def deploy(self):
        """æ‰§è¡Œå®Œæ•´éƒ¨ç½²æµç¨‹"""
        self.log_step("ğŸš€ å¼€å§‹éƒ¨ç½²æµç¨‹", "INFO")
        start_time = time.time()
        
        # éƒ¨ç½²æ­¥éª¤
        steps = [
            ("å¤‡ä»½å½“å‰ç‰ˆæœ¬", self.backup_current_version),
            ("æ‹‰å–æœ€æ–°ä»£ç ", self.pull_latest_code),
            ("å®‰è£…ä¾èµ–", self.install_dependencies),
            ("è¿è¡Œæµ‹è¯•", self.run_tests),
            ("éƒ¨ç½²åº”ç”¨", self.deploy_application),
            ("é‡å¯æœåŠ¡", self.restart_service),
            ("å¥åº·æ£€æŸ¥", self.health_check)
        ]
        
        # æ‰§è¡Œæ¯ä¸ªæ­¥éª¤
        for step_name, step_function in steps:
            if not step_function():
                self.log_step(f"âŒ éƒ¨ç½²å¤±è´¥ï¼Œåœ¨æ­¥éª¤: {step_name}", "ERROR")
                return False
        
        # éƒ¨ç½²æˆåŠŸ
        elapsed_time = time.time() - start_time
        self.log_step(f"ğŸ‰ éƒ¨ç½²æˆåŠŸå®Œæˆ! è€—æ—¶: {elapsed_time:.1f}ç§’", "SUCCESS")
        return True

# ä½¿ç”¨ç¤ºä¾‹
def create_deploy_config():
    """åˆ›å»ºéƒ¨ç½²é…ç½®"""
    return {
        "project_directory": "/home/user/myapp",           # é¡¹ç›®æºç ç›®å½•
        "app_directory": "/var/www/myapp",                 # åº”ç”¨éƒ¨ç½²ç›®å½•
        "backup_directory": "/var/backups/myapp",          # å¤‡ä»½ç›®å½•
        "venv_path": "/home/user/myapp/venv",             # è™šæ‹Ÿç¯å¢ƒè·¯å¾„
        "service_name": "myapp",                          # ç³»ç»ŸæœåŠ¡å
        "health_check_url": "http://localhost:5000/health" # å¥åº·æ£€æŸ¥URL
    }

# ç¤ºä¾‹ç”¨æ³•
config = create_deploy_config()
deployer = WebDeployer(config)
# deployer.deploy()
```

### 7.3 æ•°æ®åº“éƒ¨ç½²è„šæœ¬


**ğŸ’¾ æ•°æ®åº“è¿ç§»å’Œæ›´æ–°**
```python
import sqlite3
import mysql.connector
import os
import subprocess
from datetime import datetime

class DatabaseDeployer:
    """æ•°æ®åº“éƒ¨ç½²å™¨"""
    
    def __init__(self, db_config):
        """
        åˆå§‹åŒ–æ•°æ®åº“éƒ¨ç½²å™¨
        db_config: æ•°æ®åº“è¿æ¥é…ç½®
        """
        self.db_config = db_config
        self.migration_log = []
    
    def log_step(self, message, status="INFO"):
        """è®°å½•è¿ç§»æ­¥éª¤"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        log_entry = f"[{timestamp}] {status}: {message}"
        self.migration_log.append(log_entry)
        
        icon = {"INFO": "â„¹ï¸", "SUCCESS": "âœ…", "ERROR": "âŒ", "WARNING": "âš ï¸"}[status]
        print(f"{icon} {log_entry}")
    
    def backup_database(self):
        """å¤‡ä»½æ•°æ®åº“"""
        self.log_step("å¼€å§‹å¤‡ä»½æ•°æ®åº“")
        
        try:
            if self.db_config["type"] == "mysql":
                return self._backup_mysql()
            elif self.db_config["type"] == "sqlite":
                return self._backup_sqlite()
            else:
                self.log_step(f"ä¸æ”¯æŒçš„æ•°æ®åº“ç±»å‹: {self.db_config['type']}", "ERROR")
                return False
        except Exception as e:
            self.log_step(f"å¤‡ä»½å¤±è´¥: {e}", "ERROR")
            return False
    
    def _backup_mysql(self):
        """å¤‡ä»½MySQLæ•°æ®åº“"""
        config = self.db_config
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_file = f"backup_{config['database']}_{timestamp}.sql"
        
        cmd = [
            "mysqldump",
            "-h", config["host"],
            "-u", config["user"],
            f"-p{config['password']}" if config["password"] else "",
            config["database"]
        ]
        
        with open(backup_file, "w") as f:
            result = subprocess.run(cmd, stdout=f, stderr=subprocess.PIPE)
        
        if result.returncode == 0:
            self.log_step(f"MySQLå¤‡ä»½æˆåŠŸ: {backup_file}", "SUCCESS")
            return True
        else:
            self.log_step(f"MySQLå¤‡ä»½å¤±è´¥: {result.stderr.decode()}", "ERROR")
            return False
    
    def _backup_sqlite(self):
        """å¤‡ä»½SQLiteæ•°æ®åº“"""
        db_path = self.db_config["database"]
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_path = f"{db_path}.backup_{timestamp}"
        
        import shutil
        shutil.copy2(db_path, backup_path)
        
        self.log_step(f"SQLiteå¤‡ä»½æˆåŠŸ: {backup_path}", "SUCCESS")
        return True
    
    def run_migrations(self, migration_dir):
        """è¿è¡Œæ•°æ®åº“è¿ç§»"""
        self.log_step("å¼€å§‹è¿è¡Œæ•°æ®åº“è¿ç§»")
        
        if not os.path.exists(migration_dir):
            self.log_step(f"è¿ç§»ç›®å½•ä¸å­˜åœ¨: {migration_dir}", "ERROR")
            return False
        
        # è·å–æ‰€æœ‰è¿ç§»æ–‡ä»¶
        migration_files = [f for f in os.listdir(migration_dir) if f.endswith('.sql')]
        migration_files.sort()  # æŒ‰æ–‡ä»¶åæ’åº
        
        if not migration_files:
            self.log_step("æ²¡æœ‰æ‰¾åˆ°è¿ç§»æ–‡ä»¶", "WARNING")
            return True
        
        # è¿æ¥æ•°æ®åº“
        conn = self._get_connection()
        if not conn:
            return False
        
        try:
            cursor = conn.cursor()
            
            # åˆ›å»ºè¿ç§»è®°å½•è¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            self._create_migration_table(cursor)
            
            # æ‰§è¡Œæ¯ä¸ªè¿ç§»æ–‡ä»¶
            for migration_file in migration_files:
                if self._is_migration_applied(cursor, migration_file):
                    self.log_step(f"è·³è¿‡å·²åº”ç”¨çš„è¿ç§»: {migration_file}", "INFO")
                    continue
                
                migration_path = os.path.join(migration_dir, migration_file)
                if self._apply_migration(cursor, migration_path):
                    self._record_migration(cursor, migration_file)
                    self.log_step(f"è¿ç§»åº”ç”¨æˆåŠŸ: {migration_file}", "SUCCESS")
                else:
                    self.log_step(f"è¿ç§»åº”ç”¨å¤±è´¥: {migration_file}", "ERROR")
                    return False
            
            conn.commit()
            self.log_step("æ‰€æœ‰è¿ç§»æ‰§è¡Œå®Œæˆ", "SUCCESS")
            return True
            
        except Exception as e:
            conn.rollback()
            self.log_step(f"è¿ç§»æ‰§è¡Œå¼‚å¸¸: {e}", "ERROR")
            return False
        finally:
            conn.close()
    
    def _get_connection(self):
        """è·å–æ•°æ®åº“è¿æ¥"""
        try:
            if self.db_config["type"] == "mysql":
                return mysql.connector.connect(
                    host=self.db_config["host"],
                    user=self.db_config["user"],
                    password=self.db_config["password"],
                    database=self.db_config["database"]
                )
            elif self.db_config["type"] == "sqlite":
                return sqlite3.connect(self.db_config["database"])
        except Exception as e:
            self.log_step(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {e}", "ERROR")
            return None
    
    def _create_migration_table(self, cursor):
        """åˆ›å»ºè¿ç§»è®°å½•è¡¨"""
        if self.db_config["type"] == "mysql":
            sql = """
            CREATE TABLE IF NOT EXISTS schema_migrations (
                id INT AUTO_INCREMENT PRIMARY KEY,
                migration_name VARCHAR(255) NOT NULL,
                applied_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
            """
        else:  # SQLite
            sql = """
            CREATE TABLE IF NOT EXISTS schema_migrations (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                migration_name TEXT NOT NULL,
                applied_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
            """
        cursor.execute(sql)
    
    def _is_migration_applied(self, cursor, migration_file):
        """æ£€æŸ¥è¿ç§»æ˜¯å¦å·²åº”ç”¨"""
        cursor.execute(
            "SELECT COUNT(*) FROM schema_migrations WHERE migration_name = %s" 
            if self.db_config["type"] == "mysql" 
            else "SELECT COUNT(*) FROM schema_migrations WHERE migration_name = ?",
            (migration_file,)
        )
        return cursor.fetchone()[0] > 0
    
    def _apply_migration(self, cursor, migration_path):
        """åº”ç”¨å•ä¸ªè¿ç§»æ–‡ä»¶"""
        try:
            with open(migration_path, 'r', encoding='utf-8') as f:
                migration_sql = f.read()
            
            # æ‰§è¡Œè¿ç§»SQL
            if self.db_config["type"] == "mysql":
                # MySQLæ”¯æŒå¤šè¯­å¥æ‰§è¡Œ
                for statement in migration_sql.split(';'):
                    statement = statement.strip()
                    if statement:
                        cursor.execute(statement)
            else:
                # SQLiteéœ€è¦åˆ†åˆ«æ‰§è¡Œ
                cursor.executescript(migration_sql)
            
            return True
        except Exception as e:
            self.log_step(f"æ‰§è¡Œè¿ç§»æ–‡ä»¶å¤±è´¥ {migration_path}: {e}", "ERROR")
            return False
    
    def _record_migration(self, cursor, migration_file):
        """è®°å½•è¿ç§»åº”ç”¨"""
        cursor.execute(
            "INSERT INTO schema_migrations (migration_name) VALUES (%s)"
            if self.db_config["type"] == "mysql"
            else "INSERT INTO schema_migrations (migration_name) VALUES (?)",
            (migration_file,)
        )

# ä½¿ç”¨ç¤ºä¾‹
mysql_config = {
    "type": "mysql",
    "host": "localhost",
    "user": "root",
    "password": "password",
    "database": "myapp"
}

sqlite_config = {
    "type": "sqlite",
    "database": "myapp.db"
}

# éƒ¨ç½²ç¤ºä¾‹
# db_deployer = DatabaseDeployer(sqlite_config)
# db_deployer.backup_database()
# db_deployer.run_migrations("./migrations")
```

### 7.4 é…ç½®æ–‡ä»¶ç®¡ç†è„šæœ¬


**âš™ï¸ é…ç½®æ–‡ä»¶éƒ¨ç½²å’Œç®¡ç†**
```python
import os
import json
import yaml
import shutil
from datetime import datetime
import tempfile

class ConfigManager:
    """é…ç½®æ–‡ä»¶ç®¡ç†å™¨"""
    
    def __init__(self, config_dir):
        """
        åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨
        config_dir: é…ç½®æ–‡ä»¶ç›®å½•
        """
        self.config_dir = config_dir
        self.environments = ["development", "staging", "production"]
    
    def deploy_configs(self, environment, target_dir):
        """
        éƒ¨ç½²æŒ‡å®šç¯å¢ƒçš„é…ç½®æ–‡ä»¶
        environment: ç¯å¢ƒåç§° (development/staging/production)
        target_dir: ç›®æ ‡éƒ¨ç½²ç›®å½•
        """
        print(f"ğŸ”§ éƒ¨ç½² {environment} ç¯å¢ƒé…ç½®")
        
        if environment not in self.environments:
            print(f"âŒ ä¸æ”¯æŒçš„ç¯å¢ƒ: {environment}")
            return False
        
        env_config_dir = os.path.join(self.config_dir, environment)
        if not os.path.exists(env_config_dir):
            print(f"âŒ ç¯å¢ƒé…ç½®ç›®å½•ä¸å­˜åœ¨: {env_config_dir}")
            return False
        
        # å¤‡ä»½ç°æœ‰é…ç½®
        self._backup_existing_configs(target_dir)
        
        # å¤åˆ¶é…ç½®æ–‡ä»¶
        try:
            os.makedirs(target_dir, exist_ok=True)
            
            for config_file in os.listdir(env_config_dir):
                source_path = os.path.join(env_config_dir, config_file)
                target_path = os.path.join(target_dir, config_file)
                
                if os.path.isfile(source_path):
                    shutil.copy2(source_path, target_path)
                    print(f"âœ… éƒ¨ç½²é…ç½®æ–‡ä»¶: {config_file}")
            
            print(f"ğŸ‰ {environment} ç¯å¢ƒé…ç½®éƒ¨ç½²å®Œæˆ")
            return True
            
        except Exception as e:
            print(f"âŒ é…ç½®éƒ¨ç½²å¤±è´¥: {e}")
            return False
    
    def _backup_existing_configs(self, target_dir):
        """å¤‡ä»½ç°æœ‰é…ç½®"""
        if not os.path.exists(target_dir):
            return
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_dir = f"{target_dir}_backup_{timestamp}"
        
        try:
            shutil.copytree(target_dir, backup_dir)
            print(f"ğŸ’¾ é…ç½®å¤‡ä»½å®Œæˆ: {backup_dir}")
        except Exception as e:
            print(f"âš ï¸ é…ç½®å¤‡ä»½å¤±è´¥: {e}")
    
    def validate_configs(self, environment):
        """éªŒè¯é…ç½®æ–‡ä»¶"""
        print(f"ğŸ” éªŒè¯ {environment} ç¯å¢ƒé…ç½®")
        
        env_config_dir = os.path.join(self.config_dir, environment)
        if not os.path.exists(env_config_dir):
            print(f"âŒ é…ç½®ç›®å½•ä¸å­˜åœ¨: {env_config_dir}")
            return False
        
        validation_passed = True
        
        for config_file in os.listdir(env_config_dir):
            config_path = os.path.join(env_config_dir, config_file)
            
            if config_file.endswith('.json'):
                if not self._validate_json(config_path):
                    validation_passed = False
            elif config_file.endswith('.yaml') or config_file.endswith('.yml'):
                if not self._validate_yaml(config_path):
                    validation_passed = False
        
        if validation_passed:
            print("âœ… æ‰€æœ‰é…ç½®æ–‡ä»¶éªŒè¯é€šè¿‡")
        else:
            print("âŒ é…ç½®æ–‡ä»¶éªŒè¯å¤±è´¥")
        
        return validation_passed
    
    def _validate_json(self, config_path):
        """éªŒè¯JSONé…ç½®æ–‡ä»¶"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                json.load(f)
            print(f"âœ… JSONæ–‡ä»¶éªŒè¯é€šè¿‡: {os.path.basename(config_path)}")
            return True
        except json.JSONDecodeError as e:
            print(f"âŒ JSONæ–‡ä»¶æ ¼å¼é”™è¯¯ {os.path.basename(config_path)}: {e}")
            return False
        except Exception as e:
            print(f"âŒ JSONæ–‡ä»¶è¯»å–å¤±è´¥ {os.path.basename(config_path)}: {e}")
            return False
    
    def _validate_yaml(self, config_path):
        """éªŒè¯YAMLé…ç½®æ–‡ä»¶"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                yaml.safe_load(f)
            print(f"âœ… YAMLæ–‡ä»¶éªŒè¯é€šè¿‡: {os.path.basename(config_path)}")
            return True
        except yaml.YAMLError as e:
            print(f"âŒ YAMLæ–‡ä»¶æ ¼å¼é”™è¯¯ {os.path.basename(config_path)}: {e}")
            return False
        except Exception as e:
            print(f"âŒ YAMLæ–‡ä»¶è¯»å–å¤±è´¥ {os.path.basename(config_path)}: {e}")
            return False
    
    def generate_sample_configs(self):
        """ç”Ÿæˆç¤ºä¾‹é…ç½®æ–‡ä»¶"""
        print("ğŸ“ ç”Ÿæˆç¤ºä¾‹é…ç½®æ–‡ä»¶")
        
        sample_configs = {
            "app.json": {
                "app_name": "MyApp",
                "debug": False,
                "secret_key": "your-secret-key-here",
                "database": {
                    "host": "localhost",
                    "port": 5432,
                    "name": "myapp_db",
                    "user": "myapp_user",
                    "password": "password"
                }
            },
            "logging.yaml": {
                "version": 1,
                "formatters": {
                    "default": {
                        "format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
                    }
                },
                "handlers": {
                    "console": {
                        "class": "logging.StreamHandler",
                        "formatter": "default"
                    }
                },
                "root": {
                    "level": "INFO",
                    "handlers": ["console"]
                }
            }
        }
        
        for env in self.environments:
            env_dir = os.path.join(self.config_dir, env)
            os.makedirs(env_dir, exist_ok=True)
            
            for filename, content in sample_configs.items():
                config_path = os.path.join(env_dir, filename)
                
                # æ ¹æ®ç¯å¢ƒè°ƒæ•´é…ç½®
                if env == "development":
                    if filename == "app.json":
                        content["debug"] = True
                elif env == "production":
                    if filename == "app.json":
                        content["debug"] = False
                        content["database"]["host"] = "prod-db-server"
                
                # ä¿å­˜é…ç½®æ–‡ä»¶
                if filename.endswith('.json'):
                    with open(config_path, 'w', encoding='utf-8') as f:
                        json.dump(content, f, indent=2, ensure_ascii=False)
                elif filename.endswith('.yaml'):
                    with open(config_path, 'w', encoding='utf-8') as f:
                        yaml.dump(content, f, default_flow_style=False)
                
                print(f"âœ… ç”Ÿæˆ {env}/{filename}")

# ä½¿ç”¨ç¤ºä¾‹
config_manager = ConfigManager("./configs")
# config_manager.generate_sample_configs()
# config_manager.validate_configs("production")
# config_manager.deploy_configs("production", "/etc/myapp")
```

---

## 8. ğŸ’¾ å¤‡ä»½è„šæœ¬è®¾è®¡


### 8.1 å¤‡ä»½è„šæœ¬çš„é‡è¦æ€§


**ğŸ”¸ ä¸ºä»€ä¹ˆéœ€è¦å¤‡ä»½è„šæœ¬**
å¤‡ä»½è„šæœ¬å°±åƒç»™é‡è¦æ•°æ®ä¹°ä¿é™©ï¼Œå®ƒèƒ½è‡ªåŠ¨å®šæœŸä¿å­˜ä½ çš„æ–‡ä»¶ã€æ•°æ®åº“ã€é…ç½®ç­‰é‡è¦ä¿¡æ¯ã€‚å½“æ„å¤–å‘ç”Ÿæ—¶ï¼ˆæ¯”å¦‚ç¡¬ç›˜åäº†ã€è¯¯åˆ æ–‡ä»¶ã€ç³»ç»Ÿå´©æºƒï¼‰ï¼Œå¤‡ä»½è„šæœ¬èƒ½å¸®ä½ å¿«é€Ÿæ¢å¤æ•°æ®ï¼Œé¿å…é‡å¤§æŸå¤±ã€‚

### 8.2 æ–‡ä»¶å¤‡ä»½è„šæœ¬


**ğŸ“ æ™ºèƒ½æ–‡ä»¶å¤‡ä»½ç³»ç»Ÿ**
```python
import os
import shutil
import zipfile
import hashlib
import json
from datetime import datetime, timedelta
import schedule

class FileBackupSystem:
    """æ–‡ä»¶å¤‡ä»½ç³»ç»Ÿ"""
    
    def __init__(self, config_file="backup_config.json"):
        """åˆå§‹åŒ–å¤‡ä»½ç³»ç»Ÿ"""
        self.config_file = config_file
        self.config = self.load_config()
        self.backup_log = []
    
    def load_config(self):
        """åŠ è½½å¤‡ä»½é…ç½®"""
        default_config = {
            "backup_sources": [
                {"path": "~/Documents", "name": "æ–‡æ¡£"},
                {"path": "~/Desktop", "name": "æ¡Œé¢"},
                {"path": "~/Pictures", "name": "å›¾ç‰‡"}
            ],
            "backup_destination": "~/Backups",
            "backup_types": ["incremental", "full"],
            "retention_days": 30,
            "compression": True,
            "exclude_patterns": [
                "*.tmp", "*.log", "__pycache__", ".git"
            ]
        }
        
        if os.path.exists(self.config_file):
            try:
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    # åˆå¹¶é»˜è®¤é…ç½®
                    for key, value in default_config.items():
                        if key not in config:
                            config[key] = value
                    return config
            except Exception as e:
                print(f"âš ï¸ é…ç½®æ–‡ä»¶è¯»å–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {e}")
        
        # ä¿å­˜é»˜è®¤é…ç½®
        self.save_config(default_config)
        return default_config
    
    def save_config(self, config):
        """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶"""
        try:
            with open(self.config_file, 'w', encoding='utf-8') as f:
                json.dump(config, f, indent=2, ensure_ascii=False)
            print(f"âœ… é…ç½®å·²ä¿å­˜åˆ°: {self.config_file}")
        except Exception as e:
            print(f"âŒ é…ç½®ä¿å­˜å¤±è´¥: {e}")
    
    def should_exclude(self, file_path):
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åº”è¯¥æ’é™¤"""
        filename = os.path.basename(file_path)
        
        for pattern in self.config["exclude_patterns"]:
            if pattern.startswith("*."):
                # æ‰©å±•ååŒ¹é…
                ext = pattern[2:]
                if filename.endswith(ext):
                    return True
            elif pattern in filename or pattern in file_path:
                return True
        
        return False
    
    def calculate_file_hash(self, file_path):
        """è®¡ç®—æ–‡ä»¶MD5å“ˆå¸Œå€¼"""
        hash_md5 = hashlib.md5()
        try:
            with open(file_path, "rb") as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    hash_md5.update(chunk)
            return hash_md5.hexdigest()
        except Exception:
            return None
    
    def get_file_info(self, file_path):
        """è·å–æ–‡ä»¶ä¿¡æ¯"""
        try:
            stat = os.stat(file_path)
            return {
                "size": stat.st_size,
                "mtime": stat.st_mtime,
                "hash": self.calculate_file_hash(file_path)
            }
        except Exception:
            return None
    
    def create_full_backup(self):
        """åˆ›å»ºå®Œæ•´å¤‡ä»½"""
        print("ğŸ”„ å¼€å§‹åˆ›å»ºå®Œæ•´å¤‡ä»½...")
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_name = f"full_backup_{timestamp}"
        
        if self.config["compression"]:
            backup_path = os.path.join(
                os.path.expanduser(self.config["backup_destination"]),
                f"{backup_name}.zip"
            )
            return self._create_zip_backup(backup_path, backup_name)
        else:
            backup_path = os.path.join(
                os.path.expanduser(self.config["backup_destination"]),
                backup_name
            )
            return self._create_folder_backup(backup_path)
    
    def _create_zip_backup(self, backup_path, backup_name):
        """åˆ›å»ºZIPå‹ç¼©å¤‡ä»½"""
        os.makedirs(os.path.dirname(backup_path), exist_ok=True)
        
        try:
            with zipfile.ZipFile(backup_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                file_count = 0
                total_size = 0
                
                for source in self.config["backup_sources"]:
                    source_path = os.path.expanduser(source["path"])
                    source_name = source["name"]
                    
                    if not os.path.exists(source_path):
                        print(f"âš ï¸ è·³è¿‡ä¸å­˜åœ¨çš„è·¯å¾„: {source_path}")
                        continue
                    
                    print(f"ğŸ“ å¤‡ä»½ {source_name}: {source_path}")
                    
                    if os.path.isfile(source_path):
                        # å•ä¸ªæ–‡ä»¶
                        if not self.should_exclude(source_path):
                            arc_name = f"{source_name}/{os.path.basename(source_path)}"
                            zipf.write(source_path, arc_name)
                            file_count += 1
                            total_size += os.path.getsize(source_path)
                    else:
                        # ç›®å½•
                        for root, dirs, files in os.walk(source_path):
                            for file in files:
                                file_path = os.path.join(root, file)
                                
                                if self.should_exclude(file_path):
                                    continue
                                
                                # è®¡ç®—ç›¸å¯¹è·¯å¾„
                                rel_path = os.path.relpath(file_path, source_path)
                                arc_name = f"{source_name}/{rel_path}"
                                
                                try:
                                    zipf.write(file_path, arc_name)
                                    file_count += 1
                                    total_size += os.path.getsize(file_path)
                                except Exception as e:
                                    print(f"  âš ï¸ è·³è¿‡æ–‡ä»¶ {file}: {e}")
                
                print(f"âœ… å¤‡ä»½å®Œæˆ: {backup_path}")
                print(f"ğŸ“Š ç»Ÿè®¡: {file_count} ä¸ªæ–‡ä»¶, {total_size // (1024*1024)} MB")
                
                # è®°å½•å¤‡ä»½ä¿¡æ¯
                backup_info = {
                    "type": "full",
                    "timestamp": datetime.now().isoformat(),
                    "path": backup_path,
                    "file_count": file_count,
                    "total_size": total_size
                }
                self.backup_log.append(backup_info)
                
                return True
                
        except Exception as e:
            print(f"âŒ å¤‡ä»½å¤±è´¥: {e}")
            return False
    
    def _create_folder_backup(self, backup_path):
        """åˆ›å»ºæ–‡ä»¶å¤¹å¤‡ä»½"""
        os.makedirs(backup_path, exist_ok=True)
        
        try:
            file_count = 0
            
            for source in self.config["backup_sources"]:
                source_path = os.path.expanduser(source["path"])
                source_name = source["name"]
                
                if not os.path.exists(source_path):
                    continue
                
                target_path = os.path.join(backup_path, source_name)
                
                if os.path.isfile(source_path):
                    shutil.copy2(source_path, target_path)
                    file_count += 1
                else:
                    shutil.copytree(source_path, target_path, 
                                  ignore=lambda dir, files: [f for f in files 
                                                           if self.should_exclude(os.path.join(dir, f))])
                    # è®¡ç®—æ–‡ä»¶æ•°é‡
                    for root, dirs, files in os.walk(target_path):
                        file_count += len(files)
            
            print(f"âœ… å¤‡ä»½å®Œæˆ: {backup_path}")
            print(f"ğŸ“Š ç»Ÿè®¡: {file_count} ä¸ªæ–‡ä»¶")
            return True
            
        except Exception as e:
            print(f"âŒ å¤‡ä»½å¤±è´¥: {e}")
            return False
    
    def cleanup_old_backups(self):
        """æ¸…ç†è¿‡æœŸå¤‡ä»½"""
        print("ğŸ§¹ æ¸…ç†è¿‡æœŸå¤‡ä»½...")
        
        backup_dir = os.path.expanduser(self.config["backup_destination"])
        if not os.path.exists(backup_dir):
            return
        
        cutoff_date = datetime.now() - timedelta(days=self.config["retention_days"])
        cutoff_timestamp = cutoff_date.timestamp()
        
        cleaned_count = 0
        
        for item in os.listdir(backup_dir):
            item_path = os.path.join(backup_dir, item)
            
            try:
                # æ£€æŸ¥æ˜¯å¦æ˜¯å¤‡ä»½æ–‡ä»¶/æ–‡ä»¶å¤¹
                if not (item.startswith("full_backup_") or item.startswith("incremental_backup_")):
                    continue
                
                # æ£€æŸ¥ä¿®æ”¹æ—¶é—´
                if os.path.getmtime(item_path) < cutoff_timestamp:
                    if os.path.isfile(item_path):
                        os.remove(item_path)
                    else:
                        shutil.rmtree(item_path)
                    
                    print(f"ğŸ—‘ï¸ åˆ é™¤è¿‡æœŸå¤‡ä»½: {item}")
                    cleaned_count += 1
                    
            except Exception as e:
                print(f"âš ï¸ åˆ é™¤å¤±è´¥ {item}: {e}")
        
        if cleaned_count > 0:
            print(f"âœ… æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº† {cleaned_count} ä¸ªè¿‡æœŸå¤‡ä»½")
        else:
            print("âœ… æ²¡æœ‰å‘ç°è¿‡æœŸå¤‡ä»½")
    
    def schedule_backups(self):
        """è®¾ç½®å®šæ—¶å¤‡ä»½"""
        print("â° è®¾ç½®å®šæ—¶å¤‡ä»½ä»»åŠ¡...")
        
        # æ¯å¤©å‡Œæ™¨2ç‚¹è¿›è¡Œå®Œæ•´å¤‡ä»½
        schedule.every().day.at("02:00").do(self.create_full_backup)
        
        # æ¯å¤©å‡Œæ™¨3ç‚¹æ¸…ç†è¿‡æœŸå¤‡ä»½
        schedule.every().day.at("03:00").do(self.cleanup_old_backups)
        
        print("âœ… å®šæ—¶å¤‡ä»½ä»»åŠ¡å·²è®¾ç½®:")
        print("  â€¢ æ¯å¤© 02:00 - å®Œæ•´å¤‡ä»½")
        print("  â€¢ æ¯å¤© 03:00 - æ¸…ç†è¿‡æœŸå¤‡ä»½")
        
        # è¿è¡Œå®šæ—¶ä»»åŠ¡
        try:
            while True:
                schedule.run_pending()
                time.sleep(60)
        except KeyboardInterrupt:
            print("\nâ¹ï¸ å®šæ—¶å¤‡ä»½å·²åœæ­¢")

# ä½¿ç”¨ç¤ºä¾‹
backup_system = FileBackupSystem()
# backup_system.create_full_backup()
# backup_system.cleanup_old_backups()
```

### 8.3 æ•°æ®åº“å¤‡ä»½è„šæœ¬


**ğŸ’¾ æ•°æ®åº“è‡ªåŠ¨å¤‡ä»½**
```python
import subprocess
import os
import gzip
import shutil
from datetime import datetime, timedelta

class DatabaseBackup:
    """æ•°æ®åº“å¤‡ä»½ç±»"""
    
    def __init__(self, db_config):
        """
        åˆå§‹åŒ–æ•°æ®åº“å¤‡ä»½
        db_config: æ•°æ®åº“é…ç½®å­—å…¸
        """
        self.db_config = db_config
        self.backup_dir = db_config.get("backup_dir", "./db_backups")
        os.makedirs(self.backup_dir, exist_ok=True)
    
    def backup_mysql(self):
        """å¤‡ä»½MySQLæ•°æ®åº“"""
        print("ğŸ”„ å¼€å§‹å¤‡ä»½MySQLæ•°æ®åº“...")
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_filename = f"mysql_{self.db_config['database']}_{timestamp}.sql"
        backup_path = os.path.join(self.backup_dir, backup_filename)
        
        # æ„å»ºmysqldumpå‘½ä»¤
        cmd = [
            "mysqldump",
            "-h", self.db_config["host"],
            "-P", str(self.db_config.get("port", 3306)),
            "-u", self.db_config["user"]
        ]
        
        if self.db_config.get("password"):
            cmd.append(f"-p{self.db_config['password']}")
        
        # æ·»åŠ å¤‡ä»½é€‰é¡¹
        cmd.extend([
            "--single-transaction",  # ä¿è¯ä¸€è‡´æ€§
            "--routines",           # å¤‡ä»½å­˜å‚¨è¿‡ç¨‹
            "--triggers",           # å¤‡ä»½è§¦å‘å™¨
            self.db_config["database"]
        ])
        
        try:
            # æ‰§è¡Œå¤‡ä»½
            with open(backup_path, "w") as f:
                result = subprocess.run(cmd, stdout=f, stderr=subprocess.PIPE)
            
            if result.returncode == 0:
                # å‹ç¼©å¤‡ä»½æ–‡ä»¶
                compressed_path = f"{backup_path}.gz"
                with open(backup_path, 'rb') as f_in:
                    with gzip.open(compressed_path, 'wb') as f_out:
                        shutil.copyfileobj(f_in, f_out)
                
                # åˆ é™¤æœªå‹ç¼©æ–‡ä»¶
                os.remove(backup_path)
                
                file_size = os.path.getsize(compressed_path)
                print(f"âœ… MySQLå¤‡ä»½æˆåŠŸ: {compressed_path}")
                print(f"ğŸ“Š å¤‡ä»½å¤§å°: {file_size // (1024*1024)} MB")
                
                return compressed_path
            else:
                print(f"âŒ MySQLå¤‡ä»½å¤±è´¥: {result.stderr.decode()}")
                return None
                
        except Exception as e:
            print(f"âŒ MySQLå¤‡ä»½å¼‚å¸¸: {e}")
            return None
    
    def backup_postgresql(self):
        """å¤‡ä»½PostgreSQLæ•°æ®åº“"""
        print("ğŸ”„ å¼€å§‹å¤‡ä»½PostgreSQLæ•°æ®åº“...")
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_filename = f"postgres_{self.db_config['database']}_{timestamp}.sql"
        backup_path = os.path.join(self.backup_dir, backup_filename)
        
        # è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆé¿å…å¯†ç æç¤ºï¼‰
        env = os.environ.copy()
        if self.db_config.get("password"):
            env["PGPASSWORD"] = self.db_config["password"]
        
        cmd = [
            "pg_dump",
            "-h", self.db_config["host"],
            "-p", str(self.db_config.get("port", 5432)),
            "-U", self.db_config["user"],
            "-d", self.db_config["database"],
            "--no-password",
            "--verbose"
        ]
        
        try:
            with open(backup_path, "w") as f:
                result = subprocess.run(cmd, stdout=f, stderr=subprocess.PIPE, env=env)
            
            if result.returncode == 0:
                # å‹ç¼©å¤‡ä»½
                compressed_path = f"{backup_path}.gz"
                with open(backup_path, 'rb') as f_in:
                    with gzip.open(compressed_path, 'wb') as f_out:
                        shutil.copyfileobj(f_in, f_out)
                
                os.remove(backup_path)
                
                file_size = os.path.getsize(compressed_path)
                print(f"âœ… PostgreSQLå¤‡ä»½æˆåŠŸ: {compressed_path}")
                print(f"ğŸ“Š å¤‡ä»½å¤§å°: {file_size // (1024*1024)} MB")
                
                return compressed_path
            else:
                print(f"âŒ PostgreSQLå¤‡ä»½å¤±è´¥: {result.stderr.decode()}")
                return None
                
        except Exception as e:
            print(f"âŒ PostgreSQLå¤‡ä»½å¼‚å¸¸: {e}")
            return None
    
    def backup_sqlite(self):
        """å¤‡ä»½SQLiteæ•°æ®åº“"""
        print("ğŸ”„ å¼€å§‹å¤‡ä»½SQLiteæ•°æ®åº“...")
        
        db_path = self.db_config["database"]
        if not os.path.exists(db_path):
            print(f"âŒ SQLiteæ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {db_path}")
            return None
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_filename = f"sqlite_{os.path.basename(db_path)}_{timestamp}"
        backup_path = os.path.join(self.backup_dir, backup_filename)
        
        try:
            # ç›´æ¥å¤åˆ¶æ•°æ®åº“æ–‡ä»¶
            shutil.copy2(db_path, backup_path)
            
            # å‹ç¼©å¤‡ä»½
            compressed_path = f"{backup_path}.gz"
            with open(backup_path, 'rb') as f_in:
                with gzip.open(compressed_path, 'wb') as f_out:
                    shutil.copyfileobj(f_in, f_out)
            
            os.remove(backup_path)
            
            file_size = os.path.getsize(compressed_path)
            print(f"âœ… SQLiteå¤‡ä»½æˆåŠŸ: {compressed_path}")
            print(f"ğŸ“Š å¤‡ä»½å¤§å°: {file_size // (1024*1024)} MB")
            
            return compressed_path
            
        except Exception as e:
            print(f"âŒ SQLiteå¤‡ä»½å¼‚å¸¸: {e}")
            return None
    
    def cleanup_old_backups(self, retention_days=7):
        """æ¸…ç†è¿‡æœŸçš„æ•°æ®åº“å¤‡ä»½"""
        print(f"ğŸ§¹ æ¸…ç† {retention_days} å¤©å‰çš„æ•°æ®åº“å¤‡ä»½...")
        
        cutoff_date = datetime.now() - timedelta(days=retention_days)
        cutoff_timestamp = cutoff_date.timestamp()
        
        cleaned_count = 0
        
        for filename in os.listdir(self.backup_dir):
            if not filename.endswith('.sql.gz'):
                continue
            
            file_path = os.path.join(self.backup_dir, filename)
            
            try:
                if os.path.getmtime(file_path) < cutoff_timestamp:
                    os.remove(file_path)
                    print(f"ğŸ—‘ï¸ åˆ é™¤è¿‡æœŸå¤‡ä»½: {filename}")
                    cleaned_count += 1
            except Exception as e:
                print(f"âš ï¸ åˆ é™¤å¤±è´¥ {filename}: {e}")
        
        print(f"âœ… æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº† {cleaned_count} ä¸ªè¿‡æœŸå¤‡ä»½")
    
    def run_backup(self):
        """æ ¹æ®æ•°æ®åº“ç±»å‹è¿è¡Œå¤‡ä»½"""
        db_type = self.db_config.get("type", "").lower()
        
        if db_type == "mysql":
            return self.backup_mysql()
        elif db_type == "postgresql":
            return self.backup_postgresql()
        elif db_type == "sqlite":
            return self.backup_sqlite()
        else:
            print(f"âŒ ä¸æ”¯æŒçš„æ•°æ®åº“ç±»å‹: {db_type}")
            return None

# ä½¿ç”¨ç¤ºä¾‹
mysql_config = {
    "type": "mysql",
    "host": "localhost",
    "port": 3306,
    "user": "root",
    "password": "password",
    "database": "myapp",
    "backup_dir": "./db_backups"
}

sqlite_config = {
    "type": "sqlite",
    "database": "./myapp.db",
    "backup_dir": "./db_backups"
}

# å¤‡ä»½ç¤ºä¾‹
# mysql_backup = DatabaseBackup(mysql_config)
# mysql_backup.run_backup()
# mysql_backup.cleanup_old_backups(retention_days=7)
```

---

## 9. ğŸ› ï¸ è„šæœ¬é”™è¯¯å¤„ç†ç­–ç•¥


### 9.1 é”™è¯¯å¤„ç†çš„é‡è¦æ€§


**ğŸ”¸ ä¸ºä»€ä¹ˆéœ€è¦é”™è¯¯å¤„ç†**

è„šæœ¬åœ¨å®é™…è¿è¡Œä¸­æ€»ä¼šé‡åˆ°å„ç§æ„å¤–æƒ…å†µï¼Œæ¯”å¦‚ç½‘ç»œæ–­å¼€ã€æ–‡ä»¶ä¸å­˜åœ¨ã€æƒé™ä¸è¶³ç­‰ã€‚å¥½çš„é”™è¯¯å¤„ç†å°±åƒç»™è„šæœ¬è£…ä¸Š"ä¿é™©ä¸"ï¼Œå½“å‡ºç°é—®é¢˜æ—¶èƒ½ä¼˜é›…åœ°å¤„ç†ï¼Œè€Œä¸æ˜¯ç›´æ¥å´©æºƒã€‚

### 9.2 åŸºç¡€é”™è¯¯å¤„ç†æ¨¡å¼


**ğŸ”§ å¸¸ç”¨é”™è¯¯å¤„ç†æ¨¡å¼**
```python
import logging
import traceback
import sys
from functools import wraps
from datetime import datetime

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('script.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

def safe_execute(func):
    """
    å®‰å…¨æ‰§è¡Œè£…é¥°å™¨
    ä¸ºå‡½æ•°æ·»åŠ å¼‚å¸¸å¤„ç†å’Œæ—¥å¿—è®°å½•
    """
    @wraps(func)
    def wrapper(*args, **kwargs):
        try:
            logger.info(f"å¼€å§‹æ‰§è¡Œ: {func.__name__}")
            result = func(*args, **kwargs)
            logger.info(f"æ‰§è¡ŒæˆåŠŸ: {func.__name__}")
            return result
        except Exception as e:
            logger.error(f"æ‰§è¡Œå¤±è´¥ {func.__name__}: {str(e)}")
            logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            return None
    return wrapper

class ScriptError(Exception):
    """è‡ªå®šä¹‰è„šæœ¬å¼‚å¸¸"""
    def __init__(self, message, error_code=None):
        self.message = message
        self.error_code = error_code
        super().__init__(self.message)

class ErrorHandler:
    """é”™è¯¯å¤„ç†å™¨"""
    
    def __init__(self):
        self.error_count = 0
        self.error_log = []
    
    def handle_error(self, error, context=""):
        """å¤„ç†é”™è¯¯"""
        self.error_count += 1
        
        error_info = {
            "æ—¶é—´": datetime.now().isoformat(),
            "é”™è¯¯ç±»å‹": type(error).__name__,
            "é”™è¯¯ä¿¡æ¯": str(error),
            "ä¸Šä¸‹æ–‡": context,
            "é”™è¯¯ç¼–å·": self.error_count
        }
        
        self.error_log.append(error_info)
        
        # æ ¹æ®é”™è¯¯ç±»å‹å†³å®šå¤„ç†ç­–ç•¥
        if isinstance(error, FileNotFoundError):
            logger.warning(f"ğŸ“ æ–‡ä»¶ä¸å­˜åœ¨: {error}")
            return "file_not_found"
        elif isinstance(error, PermissionError):
            logger.error(f"ğŸ”’ æƒé™ä¸è¶³: {error}")
            return "permission_denied"
        elif isinstance(error, ConnectionError):
            logger.error(f"ğŸŒ è¿æ¥é”™è¯¯: {error}")
            return "connection_error"
        else:
            logger.error(f"âŒ æœªçŸ¥é”™è¯¯: {error}")
            return "unknown_error"
    
    def get_error_summary(self):
        """è·å–é”™è¯¯æ‘˜è¦"""
        if not self.error_log:
            return "âœ… æ²¡æœ‰å‘ç°é”™è¯¯"
        
        summary = f"âš ï¸ å…±å‘ç° {self.error_count} ä¸ªé”™è¯¯:\n"
        
        # æŒ‰é”™è¯¯ç±»å‹åˆ†ç»„
        error_types = {}
        for error in self.error_log:
            error_type = error["é”™è¯¯ç±»å‹"]
            if error_type not in error_types:
                error_types[error_type] = 0
            error_types[error_type] += 1
        
        for error_type, count in error_types.items():
            summary += f"  â€¢ {error_type}: {count} æ¬¡\n"
        
        return summary

# ä½¿ç”¨ç¤ºä¾‹
error_handler = ErrorHandler()

@safe_execute
def risky_file_operation(file_path):
    """å¯èƒ½å¤±è´¥çš„æ–‡ä»¶æ“ä½œ"""
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
    
    with open(file_path, 'r') as f:
        return f.read()

# æµ‹è¯•é”™è¯¯å¤„ç†
# result = risky_file_operation("ä¸å­˜åœ¨çš„æ–‡ä»¶.txt")
# print(error_handler.get_error_summary())
```

### 9.3 é‡è¯•æœºåˆ¶å®ç°


**ğŸ”„ æ™ºèƒ½é‡è¯•ç­–ç•¥**
```python
import time
import random
from functools import wraps

def retry_on_failure(max_retries=3, delay=1, backoff_factor=2, exceptions=(Exception,)):
    """
    é‡è¯•è£…é¥°å™¨
    max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
    delay: åˆå§‹å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰
    backoff_factor: å»¶è¿Ÿå€å¢å› å­
    exceptions: éœ€è¦é‡è¯•çš„å¼‚å¸¸ç±»å‹
    """
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            current_delay = delay
            
            for attempt in range(max_retries + 1):
                try:
                    result = func(*args, **kwargs)
                    if attempt > 0:
                        logger.info(f"âœ… {func.__name__} é‡è¯•æˆåŠŸ (ç¬¬{attempt+1}æ¬¡å°è¯•)")
                    return result
                    
                except exceptions as e:
                    if attempt == max_retries:
                        logger.error(f"âŒ {func.__name__} é‡è¯•å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•° ({max_retries+1})")
                        raise e
                    
                    logger.warning(f"âš ï¸ {func.__name__} ç¬¬{attempt+1}æ¬¡å°è¯•å¤±è´¥: {str(e)}")
                    logger.info(f"ğŸ”„ {current_delay}ç§’åè¿›è¡Œç¬¬{attempt+2}æ¬¡å°è¯•...")
                    
                    # æ·»åŠ éšæœºæŠ–åŠ¨ï¼Œé¿å…é›·è¾¾æ•ˆåº”
                    jitter = random.uniform(0.1, 0.5)
                    time.sleep(current_delay + jitter)
                    
                    # æŒ‡æ•°é€€é¿
                    current_delay *= backoff_factor
            
            return None
        return wrapper
    return decorator

@retry_on_failure(max_retries=3, delay=2, exceptions=(ConnectionError, TimeoutError))
def unreliable_network_request(url):
    """ä¸ç¨³å®šçš„ç½‘ç»œè¯·æ±‚"""
    import requests
    
    # æ¨¡æ‹Ÿç½‘ç»œä¸ç¨³å®š
    if random.random() < 0.7:  # 70%æ¦‚ç‡å¤±è´¥
        raise ConnectionError("ç½‘ç»œè¿æ¥å¤±è´¥")
    
    response = requests.get(url, timeout=5)
    return response.text

# ä½¿ç”¨ç¤ºä¾‹
# result = unreliable_network_request("https://httpbin.org/get")
```

### 9.4 å¼‚å¸¸æ¢å¤æœºåˆ¶


**ğŸ”§ ä¼˜é›…é™çº§å’Œæ¢å¤**
```python
import json
import os
from datetime import datetime

class GracefulScript:
    """ä¼˜é›…å¤„ç†å¼‚å¸¸çš„è„šæœ¬åŸºç±»"""
    
    def __init__(self, name):
        self.name = name
        self.state_file = f"{name}_state.json"
        self.error_handler = ErrorHandler()
        self.recovery_actions = {}
        
    def save_state(self, state_data):
        """ä¿å­˜è„šæœ¬çŠ¶æ€"""
        try:
            state_data["ä¿å­˜æ—¶é—´"] = datetime.now().isoformat()
            with open(self.state_file, 'w', encoding='utf-8') as f:
                json.dump(state_data, f, indent=2, ensure_ascii=False)
            logger.info(f"ğŸ’¾ çŠ¶æ€å·²ä¿å­˜: {self.state_file}")
        except Exception as e:
            logger.error(f"âŒ çŠ¶æ€ä¿å­˜å¤±è´¥: {e}")
    
    def load_state(self):
        """åŠ è½½è„šæœ¬çŠ¶æ€"""
        if not os.path.exists(self.state_file):
            return {}
        
        try:
            with open(self.state_file, 'r', encoding='utf-8') as f:
                state = json.load(f)
            logger.info(f"ğŸ“– çŠ¶æ€å·²åŠ è½½: {self.state_file}")
            return state
        except Exception as e:
            logger.error(f"âŒ çŠ¶æ€åŠ è½½å¤±è´¥: {e}")
            return {}
    
    def register_recovery_action(self, error_type, action_func):
        """æ³¨å†Œé”™è¯¯æ¢å¤åŠ¨ä½œ"""
        self.recovery_actions[error_type] = action_func
    
    def execute_with_recovery(self, task_func, task_name, *args, **kwargs):
        """æ‰§è¡Œä»»åŠ¡å¹¶æ”¯æŒé”™è¯¯æ¢å¤"""
        try:
            logger.info(f"ğŸš€ å¼€å§‹æ‰§è¡Œä»»åŠ¡: {task_name}")
            result = task_func(*args, **kwargs)
            logger.info(f"âœ… ä»»åŠ¡å®Œæˆ: {task_name}")
            return result
            
        except Exception as e:
            error_type = self.error_handler.handle_error(e, task_name)
            
            # å°è¯•æ¢å¤
            if error_type in self.recovery_actions:
                logger.info(f"ğŸ”§ å°è¯•æ¢å¤: {task_name}")
                try:
                    recovery_result = self.recovery_actions[error_type](*args, **kwargs)
                    logger.info(f"âœ… æ¢å¤æˆåŠŸ: {task_name}")
                    return recovery_result
                except Exception as recovery_error:
                    logger.error(f"âŒ æ¢å¤å¤±è´¥: {recovery_error}")
            
            # ä¿å­˜é”™è¯¯çŠ¶æ€
            error_state = {
                "å¤±è´¥ä»»åŠ¡": task_name,
                "é”™è¯¯ä¿¡æ¯": str(e),
                "å¤±è´¥æ—¶é—´": datetime.now().isoformat(),
                "å‚æ•°": {"args": str(args), "kwargs": str(kwargs)}
            }
            self.save_state(error_state)
            
            return None
    
    def cleanup_on_exit(self):
        """é€€å‡ºæ—¶çš„æ¸…ç†å·¥ä½œ"""
        logger.info(f"ğŸ§¹ æ‰§è¡Œæ¸…ç†å·¥ä½œ: {self.name}")
        
        # æ˜¾ç¤ºé”™è¯¯æ‘˜è¦
        print(self.error_handler.get_error_summary())
        
        # åˆ é™¤çŠ¶æ€æ–‡ä»¶ï¼ˆå¦‚æœä»»åŠ¡æˆåŠŸå®Œæˆï¼‰
        if self.error_handler.error_count == 0 and os.path.exists(self.state_file):
            try:
                os.remove(self.state_file)
                logger.info(f"ğŸ—‘ï¸ æ¸…ç†çŠ¶æ€æ–‡ä»¶: {self.state_file}")
            except Exception as e:
                logger.warning(f"âš ï¸ çŠ¶æ€æ–‡ä»¶æ¸…ç†å¤±è´¥: {e}")

# ä½¿ç”¨ç¤ºä¾‹
class BackupScript(GracefulScript):
    """å¤‡ä»½è„šæœ¬ç¤ºä¾‹"""
    
    def __init__(self):
        super().__init__("backup_script")
        
        # æ³¨å†Œæ¢å¤åŠ¨ä½œ
        self.register_recovery_action("file_not_found", self.create_missing_directory)
        self.register_recovery_action("permission_denied", self.request_sudo_permission)
    
    def create_missing_directory(self, source_path, target_path):
        """åˆ›å»ºç¼ºå¤±çš„ç›®å½•"""
        os.makedirs(os.path.dirname(target_path), exist_ok=True)
        return f"å·²åˆ›å»ºç›®å½•: {os.path.dirname(target_path)}"
    
    def request_sudo_permission(self, *args, **kwargs):
        """è¯·æ±‚ç®¡ç†å‘˜æƒé™"""
        logger.warning("âš ï¸ éœ€è¦ç®¡ç†å‘˜æƒé™ï¼Œè¯·æ‰‹åŠ¨å¤„ç†æƒé™é—®é¢˜")
        return "æƒé™é—®é¢˜éœ€è¦æ‰‹åŠ¨å¤„ç†"
    
    def backup_file(self, source_path, target_path):
        """å¤‡ä»½æ–‡ä»¶"""
        if not os.path.exists(source_path):
            raise FileNotFoundError(f"æºæ–‡ä»¶ä¸å­˜åœ¨: {source_path}")
        
        # æ£€æŸ¥ç›®æ ‡ç›®å½•æƒé™
        target_dir = os.path.dirname(target_path)
        if not os.access(target_dir, os.W_OK):
            raise PermissionError(f"ç›®æ ‡ç›®å½•æ— å†™æƒé™: {target_dir}")
        
        shutil.copy2(source_path, target_path)
        return f"å¤‡ä»½æˆåŠŸ: {source_path} -> {target_path}"
    
    def run_backup(self, file_list):
        """è¿è¡Œå¤‡ä»½ä»»åŠ¡"""
        for source, target in file_list:
            result = self.execute_with_recovery(
                self.backup_file, 
                f"å¤‡ä»½{os.path.basename(source)}",
                source, 
                target
            )
            if result:
                print(f"âœ… {result}")

# ä½¿ç”¨ç¤ºä¾‹
backup_script = BackupScript()
file_list = [
    ("./é‡è¦æ–‡ä»¶.txt", "./å¤‡ä»½/é‡è¦æ–‡ä»¶.txt"),
    ("./é…ç½®.json", "./å¤‡ä»½/é…ç½®.json")
]

try:
    backup_script.run_backup(file_list)
finally:
    backup_script.cleanup_on_exit()
```

### 9.5 ç›‘æ§å’Œå‘Šè­¦æœºåˆ¶


**ğŸ“Š è„šæœ¬è¿è¡Œç›‘æ§**
```python
import smtplib
import psutil
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart

class ScriptMonitor:
    """è„šæœ¬ç›‘æ§å™¨"""
    
    def __init__(self, script_name, email_config=None):
        self.script_name = script_name
        self.email_config = email_config
        self.start_time = datetime.now()
        self.alerts = []
        
    def check_system_resources(self):
        """æ£€æŸ¥ç³»ç»Ÿèµ„æº"""
        alerts = []
        
        # æ£€æŸ¥CPUä½¿ç”¨ç‡
        cpu_percent = psutil.cpu_percent(interval=1)
        if cpu_percent > 90:
            alerts.append(f"CPUä½¿ç”¨ç‡è¿‡é«˜: {cpu_percent:.1f}%")
        
        # æ£€æŸ¥å†…å­˜ä½¿ç”¨ç‡
        memory = psutil.virtual_memory()
        if memory.percent > 90:
            alerts.append(f"å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {memory.percent:.1f}%")
        
        # æ£€æŸ¥ç£ç›˜ç©ºé—´
        disk = psutil.disk_usage('/')
        disk_percent = (disk.used / disk.total) * 100
        if disk_percent > 95:
            alerts.append(f"ç£ç›˜ç©ºé—´ä¸è¶³: {disk_percent:.1f}%")
        
        return alerts
    
    def send_alert_email(self, subject, content):
        """å‘é€å‘Šè­¦é‚®ä»¶"""
        if not self.email_config:
            logger.warning("æœªé…ç½®é‚®ä»¶ï¼Œæ— æ³•å‘é€å‘Šè­¦")
            return False
        
        try:
            msg = MIMEMultipart()
            msg['From'] = self.email_config['from']
            msg['To'] = self.email_config['to']
            msg['Subject'] = f"[è„šæœ¬å‘Šè­¦] {subject}"
            
            msg.attach(MIMEText(content, 'plain', 'utf-8'))
            
            server = smtplib.SMTP(self.email_config['smtp_host'], self.email_config['smtp_port'])
            server.starttls()
            server.login(self.email_config['username'], self.email_config['password'])
            server.send_message(msg)
            server.quit()
            
            logger.info("ğŸ“§ å‘Šè­¦é‚®ä»¶å‘é€æˆåŠŸ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ é‚®ä»¶å‘é€å¤±è´¥: {e}")
            return False
    
    def generate_report(self, success=True, error_summary=""):
        """ç”Ÿæˆæ‰§è¡ŒæŠ¥å‘Š"""
        end_time = datetime.now()
        duration = end_time - self.start_time
        
        report = f"""
è„šæœ¬æ‰§è¡ŒæŠ¥å‘Š
================

è„šæœ¬åç§°: {self.script_name}
å¼€å§‹æ—¶é—´: {self.start_time.strftime('%Y-%m-%d %H:%M:%S')}
ç»“æŸæ—¶é—´: {end_time.strftime('%Y-%m-%d %H:%M:%S')}
æ‰§è¡Œæ—¶é•¿: {duration}
æ‰§è¡Œç»“æœ: {'âœ… æˆåŠŸ' if success else 'âŒ å¤±è´¥'}

"""
        
        if not success and error_summary:
            report += f"é”™è¯¯æ‘˜è¦:\n{error_summary}\n"
        
        # æ·»åŠ ç³»ç»Ÿèµ„æºä¿¡æ¯
        resource_alerts = self.check_system_resources()
        if resource_alerts:
            report += "ç³»ç»Ÿèµ„æºå‘Šè­¦:\n"
            for alert in resource_alerts:
                report += f"  âš ï¸ {alert}\n"
        
        return report
    
    def monitor_execution(self, task_func, *args, **kwargs):
        """ç›‘æ§ä»»åŠ¡æ‰§è¡Œ"""
        try:
            logger.info(f"ğŸ” å¼€å§‹ç›‘æ§è„šæœ¬: {self.script_name}")
            
            # æ£€æŸ¥åˆå§‹ç³»ç»ŸçŠ¶æ€
            initial_alerts = self.check_system_resources()
            if initial_alerts:
                logger.warning("âš ï¸ å‘ç°ç³»ç»Ÿèµ„æºé—®é¢˜:")
                for alert in initial_alerts:
                    logger.warning(f"  {alert}")
            
            # æ‰§è¡Œä»»åŠ¡
            result = task_func(*args, **kwargs)
            
            # ç”ŸæˆæˆåŠŸæŠ¥å‘Š
            report = self.generate_report(success=True)
            logger.info("âœ… è„šæœ¬æ‰§è¡ŒæˆåŠŸ")
            
            return result
            
        except Exception as e:
            error_summary = f"é”™è¯¯: {str(e)}\nè¯¦æƒ…: {traceback.format_exc()}"
            
            # ç”Ÿæˆå¤±è´¥æŠ¥å‘Š
            report = self.generate_report(success=False, error_summary=error_summary)
            logger.error("âŒ è„šæœ¬æ‰§è¡Œå¤±è´¥")
            
            # å‘é€å‘Šè­¦é‚®ä»¶
            if self.email_config:
                self.send_alert_email(
                    f"{self.script_name} æ‰§è¡Œå¤±è´¥",
                    report
                )
            
            raise e
        finally:
            # æœ€ç»ˆæ£€æŸ¥
            final_alerts = self.check_system_resources()
            if final_alerts:
                logger.warning("âš ï¸ è„šæœ¬ç»“æŸæ—¶å‘ç°ç³»ç»Ÿé—®é¢˜:")
                for alert in final_alerts:
                    logger.warning(f"  {alert}")

# ä½¿ç”¨ç¤ºä¾‹
email_config = {
    'smtp_host': 'smtp.gmail.com',
    'smtp_port': 587,
    'username': 'your_email@gmail.com',
    'password': 'your_password',
    'from': 'your_email@gmail.com',
    'to': 'admin@company.com'
}

monitor = ScriptMonitor("æ•°æ®å¤‡ä»½è„šæœ¬", email_config)

def backup_task():
    """ç¤ºä¾‹å¤‡ä»½ä»»åŠ¡"""
    print("æ‰§è¡Œå¤‡ä»½ä»»åŠ¡...")
    time.sleep(2)  # æ¨¡æ‹Ÿè€—æ—¶æ“ä½œ
    print("å¤‡ä»½å®Œæˆ")
    return "å¤‡ä»½æˆåŠŸ"

# ç›‘æ§æ‰§è¡Œ
# result = monitor.monitor_execution(backup_task)
```

---

## 10. ğŸ“‹ æ ¸å¿ƒè¦ç‚¹æ€»ç»“


### 10.1 å¿…é¡»æŒæ¡çš„åŸºæœ¬æ¦‚å¿µ


```
ğŸ”¸ è„šæœ¬è‡ªåŠ¨åŒ–ï¼šç”¨ä»£ç å®ç°é‡å¤æ€§ä»»åŠ¡çš„è‡ªåŠ¨æ‰§è¡Œ
ğŸ”¸ ç³»ç»Ÿä»»åŠ¡ï¼šæ“ä½œç³»ç»Ÿçº§åˆ«çš„ä»»åŠ¡ï¼Œå¦‚è¿›ç¨‹ç®¡ç†ã€æ–‡ä»¶æ“ä½œ
ğŸ”¸ æ–‡ä»¶æ‰¹å¤„ç†ï¼šä¸€æ¬¡æ€§å¤„ç†å¤šä¸ªæ–‡ä»¶çš„æ“ä½œæŠ€æœ¯
ğŸ”¸ æ•°æ®å¤„ç†ï¼šè‡ªåŠ¨åŒ–çš„æ•°æ®æ¸…æ´—ã€åˆ†æã€è½¬æ¢æµç¨‹
ğŸ”¸ å®šæ—¶ä»»åŠ¡ï¼šæŒ‰æ—¶é—´è§„å¾‹è‡ªåŠ¨æ‰§è¡Œçš„è„šæœ¬ç¨‹åº
ğŸ”¸ ç›‘æ§è„šæœ¬ï¼šæŒç»­è§‚å¯Ÿç³»ç»ŸçŠ¶æ€å¹¶åŠæ—¶å“åº”å¼‚å¸¸
ğŸ”¸ éƒ¨ç½²è„šæœ¬ï¼šè‡ªåŠ¨åŒ–çš„ç¨‹åºå‘å¸ƒå’Œç¯å¢ƒé…ç½®
ğŸ”¸ å¤‡ä»½è„šæœ¬ï¼šå®šæœŸä¿å­˜é‡è¦æ•°æ®çš„è‡ªåŠ¨åŒ–ç¨‹åº
ğŸ”¸ é”™è¯¯å¤„ç†ï¼šè„šæœ¬è¿è¡Œå¼‚å¸¸æ—¶çš„æ¢å¤å’Œå¤„ç†æœºåˆ¶
```

### 10.2 å…³é”®ç†è§£è¦ç‚¹


**ğŸ”¹ è„šæœ¬è‡ªåŠ¨åŒ–çš„æ ¸å¿ƒä»·å€¼**
```
æ•ˆç‡æå‡ï¼š
â€¢ 24å°æ—¶ä¸é—´æ–­å·¥ä½œ
â€¢ æ‰§è¡Œé€Ÿåº¦è¿œè¶…äººå·¥æ“ä½œ
â€¢ ä¸€æ¬¡ç¼–å†™ï¼Œå¤šæ¬¡ä½¿ç”¨

è´¨é‡ä¿è¯ï¼š
â€¢ å‡å°‘äººä¸ºæ“ä½œé”™è¯¯
â€¢ æ ‡å‡†åŒ–çš„æ‰§è¡Œæµç¨‹
â€¢ å¯é‡å¤çš„æ“ä½œç»“æœ

æˆæœ¬èŠ‚çº¦ï¼š
â€¢ å‡å°‘äººåŠ›æŠ•å…¥
â€¢ é™ä½è¿ç»´æˆæœ¬
â€¢ æé«˜èµ„æºåˆ©ç”¨ç‡
```

**ğŸ”¹ è„šæœ¬è®¾è®¡çš„åŸºæœ¬åŸåˆ™**
```
å¯é æ€§ä¼˜å…ˆï¼š
â€¢ å……åˆ†çš„é”™è¯¯å¤„ç†
â€¢ çŠ¶æ€ä¿å­˜å’Œæ¢å¤
â€¢ ä¼˜é›…çš„å¼‚å¸¸å¤„ç†

å¯ç»´æŠ¤æ€§ï¼š
â€¢ æ¸…æ™°çš„ä»£ç ç»“æ„
â€¢ è¯¦ç»†çš„æ—¥å¿—è®°å½•
â€¢ çµæ´»çš„é…ç½®ç®¡ç†

å¯ç›‘æ§æ€§ï¼š
â€¢ æ‰§è¡ŒçŠ¶æ€åé¦ˆ
â€¢ æ€§èƒ½æŒ‡æ ‡æ”¶é›†
â€¢ å¼‚å¸¸å‘Šè­¦æœºåˆ¶
```

**ğŸ”¹ å¸¸ç”¨æŠ€æœ¯æ¨¡å¼**
```
æ¨¡å—åŒ–è®¾è®¡ï¼š
â€¢ åŠŸèƒ½ç‹¬ç«‹çš„æ¨¡å—
â€¢ å¯ç»„åˆçš„åŠŸèƒ½å•å…ƒ
â€¢ ä¾¿äºæµ‹è¯•å’Œç»´æŠ¤

é…ç½®é©±åŠ¨ï¼š
â€¢ å¤–éƒ¨é…ç½®æ–‡ä»¶
â€¢ ç¯å¢ƒç›¸å…³çš„å‚æ•°
â€¢ çµæ´»çš„è¡Œä¸ºæ§åˆ¶

çŠ¶æ€ç®¡ç†ï¼š
â€¢ æ‰§è¡ŒçŠ¶æ€ä¿å­˜
â€¢ æ–­ç‚¹ç»­ä¼ æœºåˆ¶
â€¢ å¹‚ç­‰æ€§ä¿è¯
```

### 10.3 å®é™…åº”ç”¨åœºæ™¯


**ğŸ¢ ä¼ä¸šçº§åº”ç”¨**
```
è¿ç»´è‡ªåŠ¨åŒ–ï¼š
â€¢ æœåŠ¡å™¨ç›‘æ§å’Œå‘Šè­¦
â€¢ è‡ªåŠ¨åŒ–éƒ¨ç½²å’Œæ›´æ–°
â€¢ ç³»ç»Ÿæ€§èƒ½ä¼˜åŒ–

æ•°æ®ç®¡ç†ï¼š
â€¢ æ•°æ®å¤‡ä»½å’Œæ¢å¤
â€¢ æ•°æ®æ¸…æ´—å’Œåˆ†æ
â€¢ æŠ¥è¡¨è‡ªåŠ¨ç”Ÿæˆ

ä¸šåŠ¡æ”¯æŒï¼š
â€¢ æ—¥å¿—åˆ†æå’Œå¤„ç†
â€¢ ç”¨æˆ·æ•°æ®ç»Ÿè®¡
â€¢ ç³»ç»Ÿé›†æˆå¯¹æ¥
```

**ğŸ’» ä¸ªäººä½¿ç”¨åœºæ™¯**
```
æ–‡ä»¶ç®¡ç†ï¼š
â€¢ ç…§ç‰‡è‡ªåŠ¨æ•´ç†
â€¢ æ–‡æ¡£æ‰¹é‡å¤„ç†
â€¢ é‡å¤æ–‡ä»¶æ¸…ç†

ç³»ç»Ÿç»´æŠ¤ï¼š
â€¢ åƒåœ¾æ–‡ä»¶æ¸…ç†
â€¢ è½¯ä»¶è‡ªåŠ¨æ›´æ–°
â€¢ ç³»ç»ŸçŠ¶æ€ç›‘æ§

å­¦ä¹ å·¥å…·ï¼š
â€¢ è‡ªåŠ¨ä¸‹è½½èµ„æº
â€¢ æ•°æ®æ”¶é›†æ•´ç†
â€¢ è¿›åº¦è·Ÿè¸ªç»Ÿè®¡
```

### 10.4 æœ€ä½³å®è·µå»ºè®®


**ğŸ“ è„šæœ¬å¼€å‘è§„èŒƒ**
```
ä»£ç è´¨é‡ï¼š
â€¢ æ¸…æ™°çš„å‡½æ•°å‘½å
â€¢ è¯¦ç»†çš„æ³¨é‡Šè¯´æ˜
â€¢ åˆç†çš„ä»£ç ç»“æ„
â€¢ å¼‚å¸¸å¤„ç†è¦†ç›–

é…ç½®ç®¡ç†ï¼š
â€¢ ä½¿ç”¨é…ç½®æ–‡ä»¶
â€¢ ç¯å¢ƒå˜é‡æ”¯æŒ
â€¢ æ•æ„Ÿä¿¡æ¯ä¿æŠ¤
â€¢ ç‰ˆæœ¬æ§åˆ¶ç®¡ç†

æµ‹è¯•éªŒè¯ï¼š
â€¢ å•å…ƒæµ‹è¯•ç¼–å†™
â€¢ é›†æˆæµ‹è¯•éªŒè¯
â€¢ è¾¹ç•Œæ¡ä»¶æµ‹è¯•
â€¢ å›å½’æµ‹è¯•ä¿è¯
```

**ğŸ”§ è¿ç»´å®è·µå»ºè®®**
```
ç›‘æ§ä½“ç³»ï¼š
â€¢ æ‰§è¡ŒçŠ¶æ€ç›‘æ§
â€¢ æ€§èƒ½æŒ‡æ ‡æ”¶é›†
â€¢ é”™è¯¯ç‡ç»Ÿè®¡
â€¢ èµ„æºä½¿ç”¨åˆ†æ

æ—¥å¿—ç®¡ç†ï¼š
â€¢ ç»“æ„åŒ–æ—¥å¿—æ ¼å¼
â€¢ ä¸åŒçº§åˆ«çš„æ—¥å¿—
â€¢ æ—¥å¿—è½®è½¬å’Œå½’æ¡£
â€¢ é›†ä¸­åŒ–æ—¥å¿—æ”¶é›†

å®‰å…¨è€ƒè™‘ï¼š
â€¢ æƒé™æœ€å°åŒ–åŸåˆ™
â€¢ æ•æ„Ÿæ•°æ®åŠ å¯†
â€¢ æ‰§è¡Œç¯å¢ƒéš”ç¦»
â€¢ å®¡è®¡æ—¥å¿—è®°å½•
```

**âš¡ æ€§èƒ½ä¼˜åŒ–ç­–ç•¥**
```
æ‰§è¡Œæ•ˆç‡ï¼š
â€¢ æ‰¹é‡æ“ä½œä¼˜åŒ–
â€¢ å¹¶å‘å¤„ç†èƒ½åŠ›
â€¢ å†…å­˜ä½¿ç”¨æ§åˆ¶
â€¢ IOæ“ä½œä¼˜åŒ–

èµ„æºç®¡ç†ï¼š
â€¢ è¿æ¥æ± ä½¿ç”¨
â€¢ ç¼“å­˜æœºåˆ¶åº”ç”¨
â€¢ ä¸´æ—¶æ–‡ä»¶æ¸…ç†
â€¢ è¿›ç¨‹èµ„æºé‡Šæ”¾

æ‰©å±•æ€§è®¾è®¡ï¼š
â€¢ æ¨¡å—åŒ–æ¶æ„
â€¢ æ’ä»¶æœºåˆ¶æ”¯æŒ
â€¢ é…ç½®åŒ–æ‰©å±•
â€¢ æ°´å¹³æ‰©å±•èƒ½åŠ›
```

### 10.5 å­¦ä¹ è·¯å¾„å»ºè®®


**ğŸ¯ åˆå­¦è€…è·¯å¾„**
```
ç¬¬ä¸€é˜¶æ®µï¼šåŸºç¡€æŒæ¡
â€¢ å­¦ä¼šåŸºæœ¬çš„æ–‡ä»¶æ“ä½œ
â€¢ æŒæ¡å¼‚å¸¸å¤„ç†æœºåˆ¶
â€¢ äº†è§£æ—¥å¿—è®°å½•æ–¹æ³•
â€¢ ç»ƒä¹ ç®€å•çš„æ‰¹å¤„ç†è„šæœ¬

ç¬¬äºŒé˜¶æ®µï¼šåŠŸèƒ½æ‰©å±•
â€¢ å­¦ä¹ å®šæ—¶ä»»åŠ¡è®¾ç½®
â€¢ æŒæ¡æ•°æ®å¤„ç†æŠ€å·§
â€¢ äº†è§£ç³»ç»Ÿç›‘æ§æ–¹æ³•
â€¢ å®è·µé…ç½®æ–‡ä»¶ç®¡ç†

ç¬¬ä¸‰é˜¶æ®µï¼šé«˜çº§åº”ç”¨
â€¢ è®¾è®¡éƒ¨ç½²è‡ªåŠ¨åŒ–è„šæœ¬
â€¢ å®ç°å®Œæ•´çš„å¤‡ä»½æ–¹æ¡ˆ
â€¢ æ„å»ºç›‘æ§å‘Šè­¦ç³»ç»Ÿ
â€¢ å¼€å‘é”™è¯¯æ¢å¤æœºåˆ¶
```

**ğŸ“š æ¨èå­¦ä¹ èµ„æº**
```
Pythonæ ‡å‡†åº“ï¼š
â€¢ os, sys - ç³»ç»Ÿæ“ä½œ
â€¢ subprocess - è¿›ç¨‹ç®¡ç†
â€¢ logging - æ—¥å¿—è®°å½•
â€¢ schedule - å®šæ—¶ä»»åŠ¡
â€¢ psutil - ç³»ç»Ÿç›‘æ§

ç¬¬ä¸‰æ–¹åº“ï¼š
â€¢ requests - HTTPè¯·æ±‚
â€¢ pandas - æ•°æ®å¤„ç†
â€¢ pyyaml - é…ç½®æ–‡ä»¶
â€¢ click - å‘½ä»¤è¡Œç•Œé¢
â€¢ paramiko - SSHè¿æ¥

å­¦ä¹ æ–¹å¼ï¼š
â€¢ ä»ç®€å•è„šæœ¬å¼€å§‹
â€¢ é€æ­¥å¢åŠ åŠŸèƒ½å¤æ‚åº¦
â€¢ å¤šçœ‹å¼€æºé¡¹ç›®ä»£ç 
â€¢ å®é™…é¡¹ç›®ä¸­åº”ç”¨ç»ƒä¹ 
```

### 10.6 å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ


**â“ å¸¸è§é—®é¢˜åˆ—è¡¨**
```
Q: è„šæœ¬è¿è¡Œæ—¶æ€»æ˜¯å‡ºé”™æ€ä¹ˆåŠï¼Ÿ
A: åŠ å¼ºé”™è¯¯å¤„ç†ï¼Œä½¿ç”¨try-exceptåŒ…è£…å…³é”®æ“ä½œï¼Œè®°å½•è¯¦ç»†æ—¥å¿—

Q: å¦‚ä½•è®©è„šæœ¬åœ¨åå°æŒç»­è¿è¡Œï¼Ÿ
A: ä½¿ç”¨ç³»ç»ŸæœåŠ¡(systemd)æˆ–è¿›ç¨‹ç®¡ç†å·¥å…·(supervisor)

Q: è„šæœ¬æ‰§è¡Œå¤ªæ…¢å¦‚ä½•ä¼˜åŒ–ï¼Ÿ
A: ä½¿ç”¨å¹¶å‘å¤„ç†ã€ä¼˜åŒ–IOæ“ä½œã€å‡å°‘ä¸å¿…è¦çš„è®¡ç®—

Q: å¦‚ä½•ä¿è¯è„šæœ¬çš„å®‰å…¨æ€§ï¼Ÿ
A: æœ€å°æƒé™åŸåˆ™ã€è¾“å…¥éªŒè¯ã€æ•æ„Ÿä¿¡æ¯åŠ å¯†å­˜å‚¨

Q: è„šæœ¬å‡ºé”™åå¦‚ä½•å¿«é€Ÿæ¢å¤ï¼Ÿ
A: å®ç°çŠ¶æ€ä¿å­˜ã€è®¾è®¡å¹‚ç­‰æ“ä½œã€å‡†å¤‡å›æ»šæœºåˆ¶
```

**ğŸ”§ è°ƒè¯•æŠ€å·§**
```
å¼€å‘é˜¶æ®µï¼š
â€¢ ä½¿ç”¨IDEæ–­ç‚¹è°ƒè¯•
â€¢ æ·»åŠ è¯¦ç»†çš„printè¾“å‡º
â€¢ åˆ†æ­¥éª¤éªŒè¯é€»è¾‘
â€¢ æ¨¡æ‹Ÿå„ç§å¼‚å¸¸æƒ…å†µ

ç”Ÿäº§ç¯å¢ƒï¼š
â€¢ æŸ¥çœ‹è¯¦ç»†æ—¥å¿—æ–‡ä»¶
â€¢ ç›‘æ§ç³»ç»Ÿèµ„æºä½¿ç”¨
â€¢ æ£€æŸ¥æƒé™å’Œç¯å¢ƒé…ç½®
â€¢ ä½¿ç”¨è¿œç¨‹è°ƒè¯•å·¥å…·
```

### 10.7 è¿›é˜¶å‘å±•æ–¹å‘


**ğŸš€ æŠ€æœ¯è¿›é˜¶**
```
DevOpsæ–¹å‘ï¼š
â€¢ CI/CDæµæ°´çº¿è„šæœ¬
â€¢ å®¹å™¨åŒ–éƒ¨ç½²è„šæœ¬
â€¢ åŸºç¡€è®¾æ–½å³ä»£ç 
â€¢ äº‘å¹³å°è‡ªåŠ¨åŒ–

æ•°æ®å·¥ç¨‹ï¼š
â€¢ ETLæ•°æ®æµæ°´çº¿
â€¢ å¤§æ•°æ®å¤„ç†è„šæœ¬
â€¢ å®æ—¶æ•°æ®ç›‘æ§
â€¢ æ•°æ®è´¨é‡æ£€æŸ¥

è¿ç»´è‡ªåŠ¨åŒ–ï¼š
â€¢ é…ç½®ç®¡ç†è‡ªåŠ¨åŒ–
â€¢ æ•…éšœè‡ªåŠ¨æ¢å¤
â€¢ å®¹é‡è§„åˆ’è„šæœ¬
â€¢ å®‰å…¨åˆè§„æ£€æŸ¥
```

**ğŸ’¼ èŒä¸šå‘å±•**
```
æŠ€èƒ½è¦æ±‚ï¼š
â€¢ æŒæ¡å¤šç§è„šæœ¬è¯­è¨€
â€¢ ç†Ÿæ‚‰äº‘å¹³å°æ“ä½œ
â€¢ äº†è§£å®¹å™¨æŠ€æœ¯
â€¢ å…·å¤‡ç›‘æ§è¿ç»´ç»éªŒ

å‘å±•è·¯å¾„ï¼š
â€¢ åˆçº§ï¼šè„šæœ¬å¼€å‘å·¥ç¨‹å¸ˆ
â€¢ ä¸­çº§ï¼šè‡ªåŠ¨åŒ–è¿ç»´å·¥ç¨‹å¸ˆ
â€¢ é«˜çº§ï¼šDevOpså·¥ç¨‹å¸ˆ
â€¢ ä¸“å®¶ï¼šæ¶æ„å¸ˆ/æŠ€æœ¯ä¸“å®¶
```

**æ ¸å¿ƒè®°å¿†è¦ç‚¹**ï¼š
- è„šæœ¬è‡ªåŠ¨åŒ–èƒ½æ˜¾è‘—æé«˜å·¥ä½œæ•ˆç‡å’Œè´¨é‡
- è‰¯å¥½çš„é”™è¯¯å¤„ç†å’Œç›‘æ§æ˜¯è„šæœ¬å¯é æ€§çš„å…³é”®
- æ¨¡å—åŒ–è®¾è®¡å’Œé…ç½®é©±åŠ¨è®©è„šæœ¬æ›´æ˜“ç»´æŠ¤
- ä»ç®€å•åŠŸèƒ½å¼€å§‹ï¼Œé€æ­¥æ„å»ºå¤æ‚çš„è‡ªåŠ¨åŒ–ç³»ç»Ÿ
- å®‰å…¨æ€§å’Œæ€§èƒ½ä¼˜åŒ–åœ¨ç”Ÿäº§ç¯å¢ƒä¸­è‡³å…³é‡è¦