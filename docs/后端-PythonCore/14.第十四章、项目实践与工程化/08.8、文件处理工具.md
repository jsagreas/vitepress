---
title: 8ã€æ–‡ä»¶å¤„ç†å·¥å…·
---
## ğŸ“š ç›®å½•


1. [æ‰¹é‡æ–‡ä»¶é‡å‘½å](#1-æ‰¹é‡æ–‡ä»¶é‡å‘½å)
2. [æ–‡ä»¶å†…å®¹æœç´¢æ›¿æ¢](#2-æ–‡ä»¶å†…å®¹æœç´¢æ›¿æ¢)
3. [ç›®å½•ç»“æ„åˆ†æ](#3-ç›®å½•ç»“æ„åˆ†æ)
4. [é‡å¤æ–‡ä»¶æŸ¥æ‰¾](#4-é‡å¤æ–‡ä»¶æŸ¥æ‰¾)
5. [æ–‡ä»¶åŒæ­¥å·¥å…·](#5-æ–‡ä»¶åŒæ­¥å·¥å…·)
6. [æ—¥å¿—åˆ†æå·¥å…·](#6-æ—¥å¿—åˆ†æå·¥å…·)
7. [é…ç½®æ–‡ä»¶å¤„ç†](#7-é…ç½®æ–‡ä»¶å¤„ç†)
8. [æ–‡æœ¬æ ¼å¼è½¬æ¢](#8-æ–‡æœ¬æ ¼å¼è½¬æ¢)
9. [æ ¸å¿ƒè¦ç‚¹æ€»ç»“](#9-æ ¸å¿ƒè¦ç‚¹æ€»ç»“)

---

# ğŸ¯ ä»€ä¹ˆæ˜¯æ–‡ä»¶å¤„ç†å·¥å…·



**ç®€å•ç†è§£**ï¼šæ–‡ä»¶å¤„ç†å·¥å…·å°±æ˜¯å¸®æˆ‘ä»¬æ‰¹é‡æ“ä½œæ–‡ä»¶çš„å°ç¨‹åºï¼Œæ¯”å¦‚æŠŠä¸€å †æ–‡ä»¶é‡å‘½åã€åœ¨å¾ˆå¤šæ–‡ä»¶é‡ŒæŸ¥æ‰¾æ›¿æ¢å†…å®¹ã€æ‰¾å‡ºé‡å¤çš„æ–‡ä»¶ç­‰ç­‰ã€‚

**ä¸ºä»€ä¹ˆéœ€è¦**ï¼š
- æ‰‹åŠ¨å¤„ç†å‡ ç™¾ä¸ªæ–‡ä»¶å¤ªç´¯äº†
- å®¹æ˜“å‡ºé”™ï¼Œæ¯”å¦‚æ–‡ä»¶åæ”¹é”™
- é‡å¤æ€§å·¥ä½œï¼Œè®©ç¨‹åºæ¥åšæ›´å¿«æ›´å‡†ç¡®

**æ ¸å¿ƒæ€è·¯**ï¼š
```
æ‰¾åˆ°æ–‡ä»¶ â†’ åˆ¤æ–­æ¡ä»¶ â†’ æ‰§è¡Œæ“ä½œ â†’ è®°å½•ç»“æœ
```

---

## 1. ğŸ“ æ‰¹é‡æ–‡ä»¶é‡å‘½å



### 1.1 åŸºæœ¬æ¦‚å¿µç†è§£



**ä»€ä¹ˆæ˜¯æ‰¹é‡é‡å‘½å**ï¼šä¸€æ¬¡æ€§ä¿®æ”¹å¾ˆå¤šæ–‡ä»¶çš„åå­—ï¼Œæ¯”å¦‚æŠŠç…§ç‰‡ä»`IMG001.jpg`æ”¹æˆ`2024æ—…æ¸¸_001.jpg`

**å¸¸è§åœºæ™¯**ï¼š
- æ•´ç†ç…§ç‰‡ï¼šæŒ‰æ—¶é—´æˆ–äº‹ä»¶é‡å‘½å
- æ•´ç†æ–‡æ¡£ï¼šç»Ÿä¸€å‘½åæ ¼å¼
- å¤„ç†ä¸‹è½½æ–‡ä»¶ï¼šå»æ‰ä¹±ç æˆ–ç»Ÿä¸€æ ¼å¼

### 1.2 ç®€å•é‡å‘½åå®ç°



```python
import os

def rename_files(folder_path, old_pattern, new_pattern):
    """
    æ‰¹é‡é‡å‘½åæ–‡ä»¶
    folder_path: æ–‡ä»¶å¤¹è·¯å¾„
    old_pattern: è¦æ›¿æ¢çš„éƒ¨åˆ†
    new_pattern: æ–°çš„åå­—éƒ¨åˆ†
    """
    count = 0
    for filename in os.listdir(folder_path):
        if old_pattern in filename:
            old_path = os.path.join(folder_path, filename)
            new_filename = filename.replace(old_pattern, new_pattern)
            new_path = os.path.join(folder_path, new_filename)
            
            os.rename(old_path, new_path)
            print(f"é‡å‘½å: {filename} â†’ {new_filename}")
            count += 1
    
    print(f"æ€»å…±é‡å‘½åäº† {count} ä¸ªæ–‡ä»¶")

# ä½¿ç”¨ç¤ºä¾‹

rename_files("./photos", "IMG", "2024æ—…æ¸¸")
```

### 1.3 æŒ‰è§„åˆ™é‡å‘½å



```python
import os
from datetime import datetime

def rename_with_number(folder_path, prefix="file"):
    """æŒ‰åºå·é‡å‘½åæ–‡ä»¶"""
    files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]
    
    for i, filename in enumerate(files, 1):
#        # è·å–æ–‡ä»¶æ‰©å±•å
        name, ext = os.path.splitext(filename)
        
        old_path = os.path.join(folder_path, filename)
        new_filename = f"{prefix}_{i:03d}{ext}"  # 003æ ¼å¼çš„åºå·
        new_path = os.path.join(folder_path, new_filename)
        
        os.rename(old_path, new_path)
        print(f"{filename} â†’ {new_filename}")
```

**æ ¸å¿ƒç†è§£**ï¼š
- `os.path.splitext()`ï¼šåˆ†ç¦»æ–‡ä»¶åå’Œæ‰©å±•å
- `{i:03d}`ï¼šæ ¼å¼åŒ–æ•°å­—ï¼Œ003è¿™æ ·çš„å›ºå®šä½æ•°
- å…ˆè·å–æ‰€æœ‰æ–‡ä»¶åˆ—è¡¨ï¼Œå†é€ä¸€å¤„ç†

---

## 2. ğŸ” æ–‡ä»¶å†…å®¹æœç´¢æ›¿æ¢



### 2.1 ä»€ä¹ˆæ˜¯æ–‡ä»¶å†…å®¹æœç´¢æ›¿æ¢



**ç®€å•è¯´æ˜**ï¼šåœ¨å¾ˆå¤šæ–‡ä»¶é‡Œæ‰¾åˆ°ç‰¹å®šçš„æ–‡å­—ï¼Œç„¶åæ›¿æ¢æˆæ–°çš„æ–‡å­—ã€‚æ¯”å¦‚æŠŠæ‰€æœ‰`.txt`æ–‡ä»¶é‡Œçš„"æ—§é‚®ç®±"æ›¿æ¢æˆ"æ–°é‚®ç®±"ã€‚

**åº”ç”¨åœºæ™¯**ï¼š
- ä»£ç é‡æ„ï¼šæ›¿æ¢å˜é‡åæˆ–å‡½æ•°å
- æ–‡æ¡£æ›´æ–°ï¼šæ‰¹é‡æ›´æ–°è”ç³»æ–¹å¼
- é…ç½®ä¿®æ”¹ï¼šä¿®æ”¹å¤šä¸ªé…ç½®æ–‡ä»¶çš„è®¾ç½®

### 2.2 åŸºç¡€æœç´¢æ›¿æ¢



```python
import os
import re

def search_and_replace(folder_path, search_text, replace_text, file_extensions=None):
    """
    åœ¨æ–‡ä»¶ä¸­æœç´¢å¹¶æ›¿æ¢æ–‡æœ¬
    """
    if file_extensions is None:
        file_extensions = ['.txt', '.py', '.md']
    
    for root, dirs, files in os.walk(folder_path):
        for file in files:
#            # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
            if any(file.endswith(ext) for ext in file_extensions):
                file_path = os.path.join(root, file)
                
                try:
#                    # è¯»å–æ–‡ä»¶å†…å®¹
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
#                    # å¦‚æœæ‰¾åˆ°è¦æ›¿æ¢çš„å†…å®¹
                    if search_text in content:
                        new_content = content.replace(search_text, replace_text)
                        
#                        # å†™å›æ–‡ä»¶
                        with open(file_path, 'w', encoding='utf-8') as f:
                            f.write(new_content)
                        
                        print(f"å·²å¤„ç†: {file_path}")
                
                except Exception as e:
                    print(f"å¤„ç†æ–‡ä»¶å‡ºé”™ {file_path}: {e}")
```

### 2.3 é«˜çº§æœç´¢åŠŸèƒ½



```python
def find_files_with_text(folder_path, search_text):
    """æŸ¥æ‰¾åŒ…å«ç‰¹å®šæ–‡æœ¬çš„æ–‡ä»¶"""
    found_files = []
    
    for root, dirs, files in os.walk(folder_path):
        for file in files:
            if file.endswith(('.txt', '.py', '.md')):
                file_path = os.path.join(root, file)
                
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                        if search_text in content:
#                            # è®¡ç®—å‡ºç°æ¬¡æ•°
                            count = content.count(search_text)
                            found_files.append((file_path, count))
                
                except:
                    continue
    
    return found_files

# ä½¿ç”¨ç¤ºä¾‹

results = find_files_with_text("./project", "TODO")
for file_path, count in results:
    print(f"{file_path}: æ‰¾åˆ° {count} å¤„")
```

**é‡è¦æé†’**ï¼š
- æ›¿æ¢å‰æœ€å¥½å…ˆå¤‡ä»½æ–‡ä»¶
- æµ‹è¯•æ—¶å…ˆåœ¨å°èŒƒå›´è¯•éªŒ
- æ³¨æ„æ–‡ä»¶ç¼–ç é—®é¢˜ï¼ˆUTF-8æœ€å¸¸ç”¨ï¼‰

---

## 3. ğŸ“Š ç›®å½•ç»“æ„åˆ†æ



### 3.1 ä»€ä¹ˆæ˜¯ç›®å½•ç»“æ„åˆ†æ



**ç®€å•ç†è§£**ï¼šå°±æ˜¯åˆ†æä¸€ä¸ªæ–‡ä»¶å¤¹é‡Œæœ‰ä»€ä¹ˆï¼Œæ¯”å¦‚æœ‰å¤šå°‘ä¸ªå­æ–‡ä»¶å¤¹ã€å¤šå°‘ä¸ªæ–‡ä»¶ã€æ–‡ä»¶å¤§å°åˆ†å¸ƒç­‰ç­‰ï¼Œåƒç»™æ–‡ä»¶å¤¹åšä¸ª"ä½“æ£€æŠ¥å‘Š"ã€‚

### 3.2 åŸºç¡€ç›®å½•éå†



```python
import os

def analyze_directory(path):
    """åˆ†æç›®å½•åŸºæœ¬ä¿¡æ¯"""
    total_files = 0
    total_dirs = 0
    total_size = 0
    
    for root, dirs, files in os.walk(path):
        total_dirs += len(dirs)
        total_files += len(files)
        
        for file in files:
            file_path = os.path.join(root, file)
            try:
                size = os.path.getsize(file_path)
                total_size += size
            except:
                pass  # è·³è¿‡æ— æ³•è®¿é—®çš„æ–‡ä»¶
    
#    # è½¬æ¢æ–‡ä»¶å¤§å°ä¸ºå¯è¯»æ ¼å¼
    def format_size(size):
        for unit in ['B', 'KB', 'MB', 'GB']:
            if size < 1024:
                return f"{size:.1f} {unit}"
            size /= 1024
        return f"{size:.1f} TB"
    
    print(f"ç›®å½•åˆ†æç»“æœ:")
    print(f"ğŸ“ å­ç›®å½•æ•°é‡: {total_dirs}")
    print(f"ğŸ“„ æ–‡ä»¶æ•°é‡: {total_files}")
    print(f"ğŸ’¾ æ€»å¤§å°: {format_size(total_size)}")
```

### 3.3 æ ‘å½¢ç»“æ„æ˜¾ç¤º



```python
def show_tree_structure(path, max_depth=3, current_depth=0):
    """æ˜¾ç¤ºç›®å½•æ ‘å½¢ç»“æ„"""
    if current_depth > max_depth:
        return
    
    items = []
    try:
        for item in os.listdir(path):
            if not item.startswith('.'):  # è·³è¿‡éšè—æ–‡ä»¶
                items.append(item)
    except:
        return
    
    items.sort()  # æŒ‰åç§°æ’åº
    
    for i, item in enumerate(items):
        item_path = os.path.join(path, item)
        
#        # ç»˜åˆ¶æ ‘å½¢ç»“æ„
        if i == len(items) - 1:
            prefix = "â””â”€â”€ "
            next_prefix = "    "
        else:
            prefix = "â”œâ”€â”€ "
            next_prefix = "â”‚   "
        
        print("    " * current_depth + prefix + item)
        
#        # å¦‚æœæ˜¯ç›®å½•ï¼Œé€’å½’æ˜¾ç¤º
        if os.path.isdir(item_path):
            show_tree_structure(item_path, max_depth, current_depth + 1)
```

**ASCIIæ ‘å½¢å›¾ç¤ºä¾‹**ï¼š
```
é¡¹ç›®æ ¹ç›®å½•/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ file_handler.py
â”‚   â”‚   â””â”€â”€ config.py
â”‚   â””â”€â”€ tests/
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ api.md
â””â”€â”€ requirements.txt
```

### 3.4 æ–‡ä»¶ç±»å‹ç»Ÿè®¡



```python
from collections import defaultdict

def analyze_file_types(path):
    """åˆ†ææ–‡ä»¶ç±»å‹åˆ†å¸ƒ"""
    file_types = defaultdict(lambda: {'count': 0, 'size': 0})
    
    for root, dirs, files in os.walk(path):
        for file in files:
            file_path = os.path.join(root, file)
            _, ext = os.path.splitext(file)
            ext = ext.lower() or 'æ— æ‰©å±•å'
            
            try:
                size = os.path.getsize(file_path)
                file_types[ext]['count'] += 1
                file_types[ext]['size'] += size
            except:
                continue
    
#    # æ˜¾ç¤ºç»“æœ
    print(f"{'æ–‡ä»¶ç±»å‹':<15} {'æ•°é‡':<8} {'æ€»å¤§å°':<15}")
    print("-" * 40)
    
    for ext, info in sorted(file_types.items()):
        size_mb = info['size'] / (1024 * 1024)
        print(f"{ext:<15} {info['count']:<8} {size_mb:.1f} MB")
```

---

## 4. ğŸ”„ é‡å¤æ–‡ä»¶æŸ¥æ‰¾



### 4.1 ä»€ä¹ˆæ˜¯é‡å¤æ–‡ä»¶æŸ¥æ‰¾



**æ ¸å¿ƒæ¦‚å¿µ**ï¼šæ‰¾å‡ºå†…å®¹å®Œå…¨ç›¸åŒçš„æ–‡ä»¶ï¼Œå³ä½¿æ–‡ä»¶åä¸åŒã€‚æ¯”å¦‚åŒä¸€å¼ ç…§ç‰‡ä¿å­˜äº†å¤šä»½ï¼Œæˆ–è€…åŒä¸€ä¸ªæ–‡æ¡£æœ‰å¤šä¸ªå‰¯æœ¬ã€‚

**å®ç°åŸç†**ï¼š
```
æ–‡ä»¶å†…å®¹ â†’ è®¡ç®—å“ˆå¸Œå€¼ â†’ ç›¸åŒå“ˆå¸Œå€¼ = é‡å¤æ–‡ä»¶
```

### 4.2 åŸºäºæ–‡ä»¶å¤§å°çš„å¿«é€Ÿç­›é€‰



```python
import os
from collections import defaultdict

def find_duplicate_files(path):
    """æŸ¥æ‰¾é‡å¤æ–‡ä»¶"""
#    # ç¬¬ä¸€æ­¥ï¼šæŒ‰æ–‡ä»¶å¤§å°åˆ†ç»„
    size_groups = defaultdict(list)
    
    for root, dirs, files in os.walk(path):
        for file in files:
            file_path = os.path.join(root, file)
            try:
                size = os.path.getsize(file_path)
                size_groups[size].append(file_path)
            except:
                continue
    
#    # ç¬¬äºŒæ­¥ï¼šåªå¤„ç†å¤§å°ç›¸åŒä¸”æœ‰å¤šä¸ªæ–‡ä»¶çš„ç»„
    duplicates = []
    for size, files in size_groups.items():
        if len(files) > 1:
            duplicates.extend(files)
    
    return duplicates
```

### 4.3 åŸºäºå†…å®¹å“ˆå¸Œçš„ç²¾ç¡®æŸ¥æ‰¾



```python
import hashlib

def calculate_file_hash(file_path):
    """è®¡ç®—æ–‡ä»¶çš„MD5å“ˆå¸Œå€¼"""
    hash_md5 = hashlib.md5()
    try:
        with open(file_path, "rb") as f:
#            # åˆ†å—è¯»å–ï¼Œé¿å…å¤§æ–‡ä»¶å ç”¨å¤ªå¤šå†…å­˜
            for chunk in iter(lambda: f.read(4096), b""):
                hash_md5.update(chunk)
        return hash_md5.hexdigest()
    except:
        return None

def find_exact_duplicates(path):
    """æŸ¥æ‰¾å®Œå…¨ç›¸åŒçš„æ–‡ä»¶"""
    hash_groups = defaultdict(list)
    
    for root, dirs, files in os.walk(path):
        for file in files:
            file_path = os.path.join(root, file)
            file_hash = calculate_file_hash(file_path)
            
            if file_hash:
                hash_groups[file_hash].append(file_path)
    
#    # è¿”å›æœ‰é‡å¤çš„æ–‡ä»¶ç»„
    duplicates = {}
    for file_hash, files in hash_groups.items():
        if len(files) > 1:
            duplicates[file_hash] = files
    
    return duplicates

# ä½¿ç”¨ç¤ºä¾‹

duplicates = find_exact_duplicates("./documents")
for hash_val, files in duplicates.items():
    print(f"å‘ç°é‡å¤æ–‡ä»¶ç»„:")
    for file in files:
        print(f"  - {file}")
    print()
```

**ç†è§£è¦ç‚¹**ï¼š
- **å“ˆå¸Œå€¼**ï¼šæ–‡ä»¶å†…å®¹çš„"æŒ‡çº¹"ï¼Œå†…å®¹ç›¸åŒåˆ™å“ˆå¸Œå€¼ç›¸åŒ
- **åˆ†å—è¯»å–**ï¼šå¤§æ–‡ä»¶ä¸ä¸€æ¬¡æ€§è¯»å…¥å†…å­˜ï¼Œåˆ†å°å—å¤„ç†
- **ä¸¤æ­¥ç­›é€‰**ï¼šå…ˆæŒ‰å¤§å°ï¼Œå†æŒ‰å“ˆå¸Œå€¼ï¼Œæé«˜æ•ˆç‡

---

## 5. ğŸ”„ æ–‡ä»¶åŒæ­¥å·¥å…·



### 5.1 ä»€ä¹ˆæ˜¯æ–‡ä»¶åŒæ­¥



**ç®€å•è§£é‡Š**ï¼šè®©ä¸¤ä¸ªæ–‡ä»¶å¤¹ä¿æŒå†…å®¹ä¸€è‡´ï¼Œæ¯”å¦‚æŠŠå·¥ä½œæ–‡ä»¶å¤¹çš„æ›´æ–°åŒæ­¥åˆ°å¤‡ä»½æ–‡ä»¶å¤¹ï¼Œæˆ–è€…æŠŠæ–°æ–‡ä»¶å¤åˆ¶è¿‡å»ï¼Œåˆ é™¤ä¸éœ€è¦çš„æ–‡ä»¶ã€‚

**åŒæ­¥ç±»å‹**ï¼š
- **å•å‘åŒæ­¥**ï¼šA â†’ Bï¼Œåªä»æºåˆ°ç›®æ ‡
- **åŒå‘åŒæ­¥**ï¼šA â†” Bï¼Œä¸¤è¾¹éƒ½å¯èƒ½æœ‰æ›´æ–°

### 5.2 åŸºç¡€åŒæ­¥å®ç°



```python
import os
import shutil
from datetime import datetime

def sync_folders(source, target, delete_extra=False):
    """
    æ–‡ä»¶å¤¹åŒæ­¥å·¥å…·
    source: æºæ–‡ä»¶å¤¹
    target: ç›®æ ‡æ–‡ä»¶å¤¹  
    delete_extra: æ˜¯å¦åˆ é™¤ç›®æ ‡æ–‡ä»¶å¤¹ä¸­å¤šä½™çš„æ–‡ä»¶
    """
    if not os.path.exists(target):
        os.makedirs(target)
    
    copied = 0
    updated = 0
    deleted = 0
    
#    # å¤åˆ¶/æ›´æ–°æ–‡ä»¶
    for root, dirs, files in os.walk(source):
#        # è®¡ç®—ç›¸å¯¹è·¯å¾„
        rel_path = os.path.relpath(root, source)
        target_dir = os.path.join(target, rel_path) if rel_path != '.' else target
        
#        # åˆ›å»ºç›®æ ‡ç›®å½•
        if not os.path.exists(target_dir):
            os.makedirs(target_dir)
        
        for file in files:
            source_file = os.path.join(root, file)
            target_file = os.path.join(target_dir, file)
            
#            # åˆ¤æ–­æ˜¯å¦éœ€è¦å¤åˆ¶
            need_copy = False
            if not os.path.exists(target_file):
                need_copy = True
                copied += 1
            else:
#                # æ¯”è¾ƒä¿®æ”¹æ—¶é—´
                source_time = os.path.getmtime(source_file)
                target_time = os.path.getmtime(target_file)
                if source_time > target_time:
                    need_copy = True
                    updated += 1
            
            if need_copy:
                shutil.copy2(source_file, target_file)
                print(f"åŒæ­¥: {source_file}")
    
    print(f"åŒæ­¥å®Œæˆ: æ–°å¢ {copied}, æ›´æ–° {updated}")
```

### 5.3 å·®å¼‚åˆ†æ



```python
def compare_folders(folder1, folder2):
    """æ¯”è¾ƒä¸¤ä¸ªæ–‡ä»¶å¤¹çš„å·®å¼‚"""
    def get_file_list(folder):
        files = {}
        for root, dirs, filenames in os.walk(folder):
            for filename in filenames:
                file_path = os.path.join(root, filename)
                rel_path = os.path.relpath(file_path, folder)
                files[rel_path] = os.path.getmtime(file_path)
        return files
    
    files1 = get_file_list(folder1)
    files2 = get_file_list(folder2)
    
#    # åˆ†æå·®å¼‚
    only_in_1 = set(files1.keys()) - set(files2.keys())
    only_in_2 = set(files2.keys()) - set(files1.keys())
    common = set(files1.keys()) & set(files2.keys())
    
    different = []
    for file in common:
        if files1[file] != files2[file]:
            different.append(file)
    
    print(f"ğŸ“Š æ–‡ä»¶å¤¹å¯¹æ¯”ç»“æœ:")
    print(f"åªåœ¨ {folder1} ä¸­: {len(only_in_1)} ä¸ªæ–‡ä»¶")
    print(f"åªåœ¨ {folder2} ä¸­: {len(only_in_2)} ä¸ªæ–‡ä»¶")
    print(f"å†…å®¹ä¸åŒ: {len(different)} ä¸ªæ–‡ä»¶")
    
    return {
        'only_in_1': only_in_1,
        'only_in_2': only_in_2,
        'different': different
    }
```

---

## 6. ğŸ“ˆ æ—¥å¿—åˆ†æå·¥å…·



### 6.1 ä»€ä¹ˆæ˜¯æ—¥å¿—åˆ†æ



**ç®€å•ç†è§£**ï¼šç¨‹åºè¿è¡Œæ—¶ä¼šäº§ç”Ÿæ—¥å¿—æ–‡ä»¶ï¼Œè®°å½•å‘ç”Ÿäº†ä»€ä¹ˆäº‹æƒ…ã€‚æ—¥å¿—åˆ†æå°±æ˜¯ä»è¿™äº›è®°å½•ä¸­æ‰¾å‡ºæœ‰ç”¨çš„ä¿¡æ¯ï¼Œæ¯”å¦‚é”™è¯¯ç»Ÿè®¡ã€è®¿é—®é‡åˆ†æç­‰ã€‚

**å¸¸è§æ—¥å¿—æ ¼å¼**ï¼š
```
2024-01-15 10:30:25 INFO ç”¨æˆ·ç™»å½•æˆåŠŸ user_id=123
2024-01-15 10:31:12 ERROR æ•°æ®åº“è¿æ¥å¤±è´¥ error=timeout
2024-01-15 10:32:05 WARNING å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜ usage=85%
```

### 6.2 åŸºç¡€æ—¥å¿—è§£æ



```python
import re
from datetime import datetime
from collections import defaultdict

def parse_log_file(log_file):
    """è§£ææ—¥å¿—æ–‡ä»¶"""
    log_pattern = r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}) (\w+) (.+)'
    
    logs = []
    with open(log_file, 'r', encoding='utf-8') as f:
        for line in f:
            match = re.match(log_pattern, line.strip())
            if match:
                timestamp, level, message = match.groups()
                logs.append({
                    'time': datetime.strptime(timestamp, '%Y-%m-%d %H:%M:%S'),
                    'level': level,
                    'message': message
                })
    
    return logs

def analyze_logs(logs):
    """åˆ†ææ—¥å¿—ç»Ÿè®¡ä¿¡æ¯"""
    level_count = defaultdict(int)
    hourly_count = defaultdict(int)
    
    for log in logs:
        level_count[log['level']] += 1
        hour = log['time'].hour
        hourly_count[hour] += 1
    
    print("ğŸ“Š æ—¥å¿—çº§åˆ«ç»Ÿè®¡:")
    for level, count in level_count.items():
        print(f"  {level}: {count} æ¡")
    
    print("\nğŸ“ˆ å°æ—¶åˆ†å¸ƒ:")
    for hour in sorted(hourly_count.keys()):
        count = hourly_count[hour]
        bar = "â–ˆ" * (count // 10)  # ç®€å•çš„æ¡å½¢å›¾
        print(f"  {hour:02d}:00 {bar} ({count})")
```

### 6.3 é”™è¯¯åˆ†æ



```python
def find_errors(logs):
    """æŸ¥æ‰¾å’Œåˆ†æé”™è¯¯æ—¥å¿—"""
    error_logs = [log for log in logs if log['level'] == 'ERROR']
    
    if not error_logs:
        print("âœ… æ²¡æœ‰å‘ç°é”™è¯¯æ—¥å¿—")
        return
    
    print(f"âŒ å‘ç° {len(error_logs)} æ¡é”™è¯¯:")
    
#    # æŒ‰é”™è¯¯ç±»å‹åˆ†ç»„
    error_types = defaultdict(list)
    for log in error_logs:
#        # ç®€å•æå–é”™è¯¯ç±»å‹ï¼ˆç¬¬ä¸€ä¸ªå•è¯ï¼‰
        error_type = log['message'].split()[0] if log['message'] else 'Unknown'
        error_types[error_type].append(log)
    
    for error_type, logs in error_types.items():
        print(f"\nğŸ”¸ {error_type}: {len(logs)} æ¬¡")
#        # æ˜¾ç¤ºæœ€è¿‘çš„å‡ æ¡
        for log in logs[-3:]:
            print(f"   {log['time']} - {log['message'][:50]}...")
```

---

## 7. âš™ï¸ é…ç½®æ–‡ä»¶å¤„ç†



### 7.1 ä»€ä¹ˆæ˜¯é…ç½®æ–‡ä»¶å¤„ç†



**åŸºæœ¬æ¦‚å¿µ**ï¼šé…ç½®æ–‡ä»¶å­˜å‚¨ç¨‹åºçš„è®¾ç½®ä¿¡æ¯ï¼Œæ¯”å¦‚æ•°æ®åº“è¿æ¥ã€APIå¯†é’¥ç­‰ã€‚å¤„ç†é…ç½®æ–‡ä»¶å°±æ˜¯è¯»å–ã€ä¿®æ”¹ã€éªŒè¯è¿™äº›è®¾ç½®ã€‚

**å¸¸è§æ ¼å¼**ï¼š
- **JSON**ï¼š`{"host": "localhost", "port": 8080}`
- **INI**ï¼š`[database] host=localhost`
- **YAML**ï¼š`host: localhost`

### 7.2 JSONé…ç½®å¤„ç†



```python
import json

def load_config(config_file):
    """åŠ è½½JSONé…ç½®æ–‡ä»¶"""
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
        print(f"âœ… é…ç½®åŠ è½½æˆåŠŸ")
        return config
    except Exception as e:
        print(f"âŒ é…ç½®åŠ è½½å¤±è´¥: {e}")
        return None

def update_config(config_file, key, value):
    """æ›´æ–°é…ç½®é¡¹"""
    config = load_config(config_file)
    if config is None:
        return False
    
#    # æ”¯æŒåµŒå¥—é”®ï¼Œå¦‚ "database.host"
    keys = key.split('.')
    target = config
    
    for k in keys[:-1]:
        if k not in target:
            target[k] = {}
        target = target[k]
    
    target[keys[-1]] = value
    
#    # ä¿å­˜é…ç½®
    try:
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        print(f"âœ… é…ç½®æ›´æ–°æˆåŠŸ: {key} = {value}")
        return True
    except Exception as e:
        print(f"âŒ é…ç½®ä¿å­˜å¤±è´¥: {e}")
        return False
```

### 7.3 é…ç½®éªŒè¯



```python
def validate_config(config, rules):
    """éªŒè¯é…ç½®æ–‡ä»¶"""
    errors = []
    
    for key, rule in rules.items():
        value = config.get(key)
        
#        # æ£€æŸ¥å¿…éœ€é¡¹
        if rule.get('required', False) and value is None:
            errors.append(f"ç¼ºå°‘å¿…éœ€é…ç½®: {key}")
            continue
        
        if value is not None:
#            # æ£€æŸ¥ç±»å‹
            expected_type = rule.get('type')
            if expected_type and not isinstance(value, expected_type):
                errors.append(f"é…ç½®ç±»å‹é”™è¯¯ {key}: æœŸæœ› {expected_type.__name__}")
            
#            # æ£€æŸ¥èŒƒå›´
            if 'range' in rule:
                min_val, max_val = rule['range']
                if not (min_val <= value <= max_val):
                    errors.append(f"é…ç½®è¶…å‡ºèŒƒå›´ {key}: åº”åœ¨ {min_val}-{max_val}")
    
    return errors

# ä½¿ç”¨ç¤ºä¾‹

config_rules = {
    'port': {'required': True, 'type': int, 'range': (1, 65535)},
    'host': {'required': True, 'type': str},
    'debug': {'type': bool}
}

errors = validate_config(config, config_rules)
if errors:
    print("âŒ é…ç½®éªŒè¯å¤±è´¥:")
    for error in errors:
        print(f"  - {error}")
```

---

## 8. ğŸ”„ æ–‡æœ¬æ ¼å¼è½¬æ¢



### 8.1 ä»€ä¹ˆæ˜¯æ–‡æœ¬æ ¼å¼è½¬æ¢



**ç®€å•è¯´æ˜**ï¼šæŠŠä¸€ç§æ ¼å¼çš„æ–‡æœ¬è½¬æ¢æˆå¦ä¸€ç§æ ¼å¼ï¼Œæ¯”å¦‚CSVè½¬JSONã€Markdownè½¬HTMLã€æˆ–è€…ç»Ÿä¸€ç¼–ç æ ¼å¼ç­‰ã€‚

**å¸¸è§è½¬æ¢éœ€æ±‚**ï¼š
- æ•°æ®æ ¼å¼è½¬æ¢ï¼šCSV â†” JSON â†” XML
- æ–‡æ¡£æ ¼å¼è½¬æ¢ï¼šTXT â†’ Markdown
- ç¼–ç è½¬æ¢ï¼šGBK â†’ UTF-8

### 8.2 CSVä¸JSONäº’è½¬



```python
import csv
import json

def csv_to_json(csv_file, json_file):
    """CSVè½¬JSON"""
    data = []
    
    with open(csv_file, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            data.append(row)
    
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… è½¬æ¢å®Œæˆ: {csv_file} â†’ {json_file}")

def json_to_csv(json_file, csv_file):
    """JSONè½¬CSV"""
    with open(json_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    if not data:
        print("âŒ JSONæ–‡ä»¶ä¸ºç©º")
        return
    
#    # è·å–æ‰€æœ‰å­—æ®µå
    fieldnames = set()
    for item in data:
        fieldnames.update(item.keys())
    
    with open(csv_file, 'w', encoding='utf-8', newline='') as f:
        writer = csv.DictWriter(f, fieldnames=list(fieldnames))
        writer.writeheader()
        writer.writerows(data)
    
    print(f"âœ… è½¬æ¢å®Œæˆ: {json_file} â†’ {csv_file}")
```

### 8.3 ç¼–ç è½¬æ¢



```python
def convert_encoding(file_path, from_encoding, to_encoding):
    """æ–‡ä»¶ç¼–ç è½¬æ¢"""
    try:
#        # è¯»å–åŸå§‹æ–‡ä»¶
        with open(file_path, 'r', encoding=from_encoding) as f:
            content = f.read()
        
#        # å†™å…¥æ–°ç¼–ç 
        with open(file_path, 'w', encoding=to_encoding) as f:
            f.write(content)
        
        print(f"âœ… ç¼–ç è½¬æ¢æˆåŠŸ: {from_encoding} â†’ {to_encoding}")
        return True
        
    except Exception as e:
        print(f"âŒ ç¼–ç è½¬æ¢å¤±è´¥: {e}")
        return False

def detect_and_convert(file_path, target_encoding='utf-8'):
    """è‡ªåŠ¨æ£€æµ‹ç¼–ç å¹¶è½¬æ¢"""
    import chardet
    
#    # æ£€æµ‹ç¼–ç 
    with open(file_path, 'rb') as f:
        raw_data = f.read()
        result = chardet.detect(raw_data)
        detected_encoding = result['encoding']
    
    print(f"æ£€æµ‹åˆ°ç¼–ç : {detected_encoding}")
    
    if detected_encoding.lower() != target_encoding.lower():
        return convert_encoding(file_path, detected_encoding, target_encoding)
    else:
        print("ç¼–ç å·²ç»æ˜¯ç›®æ ‡æ ¼å¼ï¼Œæ— éœ€è½¬æ¢")
        return True
```

### 8.4 æ‰¹é‡æ ¼å¼è½¬æ¢



```python
def batch_convert(folder_path, converter_func, **kwargs):
    """æ‰¹é‡è½¬æ¢æ–‡ä»¶æ ¼å¼"""
    converted = 0
    failed = 0
    
    for root, dirs, files in os.walk(folder_path):
        for file in files:
            file_path = os.path.join(root, file)
            
            try:
                if converter_func(file_path, **kwargs):
                    converted += 1
                else:
                    failed += 1
            except Exception as e:
                print(f"å¤„ç†å¤±è´¥ {file_path}: {e}")
                failed += 1
    
    print(f"ğŸ“Š æ‰¹é‡è½¬æ¢ç»“æœ: æˆåŠŸ {converted}, å¤±è´¥ {failed}")

# ä½¿ç”¨ç¤ºä¾‹ï¼šæ‰¹é‡è½¬æ¢ç¼–ç 

batch_convert("./documents", detect_and_convert, target_encoding='utf-8')
```

---

## 9. ğŸ“‹ æ ¸å¿ƒè¦ç‚¹æ€»ç»“



### 9.1 å¿…é¡»æŒæ¡çš„æ ¸å¿ƒæ¦‚å¿µ



```
ğŸ”¸ æ–‡ä»¶æ“ä½œåŸºç¡€ï¼šos.walk(), os.path, shutilç­‰æ ¸å¿ƒæ¨¡å—
ğŸ”¸ æ‰¹é‡å¤„ç†æ€è·¯ï¼šéå† â†’ åˆ¤æ–­ â†’ æ“ä½œ â†’ è®°å½•ç»“æœ
ğŸ”¸ æ–‡ä»¶è·¯å¾„å¤„ç†ï¼šç»å¯¹è·¯å¾„ã€ç›¸å¯¹è·¯å¾„ã€è·¯å¾„æ‹¼æ¥
ğŸ”¸ å¼‚å¸¸å¤„ç†ï¼šæ–‡ä»¶æ“ä½œè¦è€ƒè™‘æƒé™ã€ç¼–ç ç­‰é—®é¢˜
ğŸ”¸ æ€§èƒ½ä¼˜åŒ–ï¼šå¤§æ–‡ä»¶åˆ†å—å¤„ç†ï¼Œé¿å…å†…å­˜å ç”¨è¿‡å¤š
```

### 9.2 å…³é”®ç†è§£è¦ç‚¹



**ğŸ”¹ æ–‡ä»¶å¤„ç†çš„é€šç”¨æ¨¡å¼**
```
1. éå†æ–‡ä»¶/ç›®å½•
2. ç­›é€‰ç¬¦åˆæ¡ä»¶çš„æ–‡ä»¶
3. å¯¹æ¯ä¸ªæ–‡ä»¶æ‰§è¡Œæ“ä½œ
4. è®°å½•å¤„ç†ç»“æœå’Œå¼‚å¸¸
5. æä¾›è¿›åº¦åé¦ˆ
```

**ğŸ”¹ é‡è¦æ³¨æ„äº‹é¡¹**
```
å®‰å…¨æ€§ï¼š
â€¢ æ“ä½œå‰å¤‡ä»½é‡è¦æ–‡ä»¶
â€¢ å…ˆåœ¨æµ‹è¯•ç›®å½•è¯•éªŒ
â€¢ æ·»åŠ ç¡®è®¤æœºåˆ¶

æ€§èƒ½ï¼š
â€¢ å¤§æ–‡ä»¶åˆ†å—è¯»å–
â€¢ åˆç†ä½¿ç”¨ç¼“å­˜
â€¢ é¿å…é‡å¤æ“ä½œ

å…¼å®¹æ€§ï¼š
â€¢ å¤„ç†ä¸åŒæ“ä½œç³»ç»Ÿçš„è·¯å¾„
â€¢ è€ƒè™‘æ–‡ä»¶ç¼–ç é—®é¢˜
â€¢ å¤„ç†ç‰¹æ®Šå­—ç¬¦å’Œæƒé™
```

### 9.3 å®é™…åº”ç”¨åœºæ™¯



| å·¥å…·ç±»å‹ | **åº”ç”¨åœºæ™¯** | **æ ¸å¿ƒæŠ€æœ¯** |
|---------|------------|------------|
| ğŸ·ï¸ **æ–‡ä»¶é‡å‘½å** | `ç…§ç‰‡æ•´ç†ã€æ–‡æ¡£è§„èŒƒåŒ–` | `os.rename, å­—ç¬¦ä¸²å¤„ç†` |
| ğŸ” **å†…å®¹æœç´¢æ›¿æ¢** | `ä»£ç é‡æ„ã€æ‰¹é‡æ›´æ–°` | `æ–‡ä»¶è¯»å†™ã€æ­£åˆ™è¡¨è¾¾å¼` |
| ğŸ“Š **ç›®å½•åˆ†æ** | `ç£ç›˜æ¸…ç†ã€é¡¹ç›®ç»Ÿè®¡` | `os.walk, æ–‡ä»¶å¤§å°è®¡ç®—` |
| ğŸ”„ **é‡å¤æ–‡ä»¶æŸ¥æ‰¾** | `å­˜å‚¨ä¼˜åŒ–ã€æ¸…ç†å†—ä½™` | `å“ˆå¸Œç®—æ³•ã€æ–‡ä»¶æ¯”è¾ƒ` |
| ğŸ”„ **æ–‡ä»¶åŒæ­¥** | `å¤‡ä»½ã€ç‰ˆæœ¬ç®¡ç†` | `æ—¶é—´æˆ³æ¯”è¾ƒã€å·®å¼‚åˆ†æ` |
| ğŸ“ˆ **æ—¥å¿—åˆ†æ** | `ç³»ç»Ÿç›‘æ§ã€é—®é¢˜æ’æŸ¥` | `æ­£åˆ™è¡¨è¾¾å¼ã€æ•°æ®ç»Ÿè®¡` |
| âš™ï¸ **é…ç½®å¤„ç†** | `ç¯å¢ƒç®¡ç†ã€å‚æ•°è°ƒä¼˜` | `JSON/INIå¤„ç†ã€éªŒè¯` |
| ğŸ”„ **æ ¼å¼è½¬æ¢** | `æ•°æ®è¿ç§»ã€æ ‡å‡†åŒ–` | `ç¼–ç è½¬æ¢ã€æ ¼å¼è§£æ` |

### 9.4 è¿›é˜¶å­¦ä¹ å»ºè®®



**ğŸ¯ æ‰©å±•æ–¹å‘**
- **GUIç•Œé¢**ï¼šä½¿ç”¨tkinteråˆ¶ä½œå›¾å½¢ç•Œé¢
- **å¤šçº¿ç¨‹å¤„ç†**ï¼šæé«˜å¤§æ‰¹é‡æ–‡ä»¶å¤„ç†é€Ÿåº¦
- **æ­£åˆ™è¡¨è¾¾å¼**ï¼šæ›´å¼ºå¤§çš„æ–‡æœ¬åŒ¹é…å’Œæ›¿æ¢
- **æ•°æ®åº“é›†æˆ**ï¼šå°†æ–‡ä»¶ä¿¡æ¯å­˜å‚¨åˆ°æ•°æ®åº“
- **ç½‘ç»œåŠŸèƒ½**ï¼šè¿œç¨‹æ–‡ä»¶åŒæ­¥å’Œå¤„ç†

**ğŸ› ï¸ å®è·µå»ºè®®**
- ä»ç®€å•çš„é‡å‘½åå·¥å…·å¼€å§‹ç»ƒä¹ 
- é€æ­¥æ·»åŠ æ›´å¤šåŠŸèƒ½å’Œé”™è¯¯å¤„ç†
- é‡è§†ç”¨æˆ·ä½“éªŒå’Œæ“ä½œå®‰å…¨æ€§
- å­¦ä¼šé˜…è¯»å’Œå¤„ç†å„ç§æ–‡ä»¶æ ¼å¼

**æ ¸å¿ƒè®°å¿†è¦ç‚¹**ï¼š
- æ–‡ä»¶å¤„ç†é‡åœ¨**æ‰¹é‡**å’Œ**è‡ªåŠ¨åŒ–**
- **å®‰å…¨ç¬¬ä¸€**ï¼šå¤‡ä»½ã€æµ‹è¯•ã€ç¡®è®¤
- **å¼‚å¸¸å¤„ç†**ï¼šæ–‡ä»¶æ“ä½œå¿…é¡»è€ƒè™‘å„ç§æ„å¤–æƒ…å†µ
- **ç”¨æˆ·å‹å¥½**ï¼šæä¾›è¿›åº¦æç¤ºå’Œæ“ä½œåé¦ˆ
- **æ¨¡å—åŒ–è®¾è®¡**ï¼šæ¯ä¸ªåŠŸèƒ½ç‹¬ç«‹ï¼Œä¾¿äºç»„åˆä½¿ç”¨