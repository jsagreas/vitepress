---
title: 7ã€å…¶ä»–åºåˆ—åŒ–æ ¼å¼
---
## ğŸ“š ç›®å½•

1. [marshalæ¨¡å—ï¼šPythonå†…éƒ¨åºåˆ—åŒ–](#1-marshalæ¨¡å—ï¼šPythonå†…éƒ¨åºåˆ—åŒ–)
2. [shelveæ¨¡å—ï¼šæŒä¹…åŒ–å­—å…¸å­˜å‚¨](#2-shelveæ¨¡å—ï¼šæŒä¹…åŒ–å­—å…¸å­˜å‚¨)
3. [configparseræ¨¡å—ï¼šé…ç½®æ–‡ä»¶å¤„ç†](#3-configparseræ¨¡å—ï¼šé…ç½®æ–‡ä»¶å¤„ç†)
4. [base64æ¨¡å—ï¼šæ•°æ®ç¼–ç ä¼ è¾“](#4-base64æ¨¡å—ï¼šæ•°æ®ç¼–ç ä¼ è¾“)
5. [zlibæ¨¡å—ï¼šæ•°æ®å‹ç¼©æŠ€æœ¯](#5-zlibæ¨¡å—ï¼šæ•°æ®å‹ç¼©æŠ€æœ¯)
6. [hashlibæ¨¡å—ï¼šå“ˆå¸Œç®—æ³•åº”ç”¨](#6-hashlibæ¨¡å—ï¼šå“ˆå¸Œç®—æ³•åº”ç”¨)
7. [æ•°æ®æ ¼å¼è½¬æ¢æŠ€å·§](#7-æ•°æ®æ ¼å¼è½¬æ¢æŠ€å·§)
8. [åºåˆ—åŒ–æœ€ä½³å®è·µæŒ‡å—](#8-åºåˆ—åŒ–æœ€ä½³å®è·µæŒ‡å—)
9. [æ ¸å¿ƒè¦ç‚¹æ€»ç»“](#9-æ ¸å¿ƒè¦ç‚¹æ€»ç»“)

---

## 1. ğŸ—ï¸ marshalæ¨¡å—ï¼šPythonå†…éƒ¨åºåˆ—åŒ–


### 1.1 marshalæ˜¯ä»€ä¹ˆ


ğŸ¯ **é€šä¿—ç†è§£**ï¼š
marshalå°±åƒPythonçš„"å†…éƒ¨å¿«é€’æœåŠ¡"ï¼Œä¸“é—¨ç”¨æ¥æ‰“åŒ…å’Œä¼ é€’Pythonå†…ç½®å¯¹è±¡ã€‚æƒ³è±¡ä¸€ä¸‹ï¼Œä½ æœ‰ä¸€äº›Pythonæ•°æ®éœ€è¦å¿«é€Ÿä¿å­˜æˆ–ä¼ è¾“ï¼Œmarshalå°±æ˜¯æœ€å¿«çš„æ–¹å¼ï¼Œä½†å®ƒåªè®¤è¯†Python"åŸä½æ°‘"ï¼ˆå†…ç½®ç±»å‹ï¼‰ã€‚

**ğŸ“– æ ¸å¿ƒå®šä¹‰**ï¼š
```
marshal = Pythonå†…éƒ¨ä½¿ç”¨çš„åºåˆ—åŒ–å·¥å…·
ç”¨é€”ï¼šå¿«é€Ÿåºåˆ—åŒ–PythonåŸºæœ¬æ•°æ®ç±»å‹
ç‰¹ç‚¹ï¼šé€Ÿåº¦å¿«ï¼Œä½†åŠŸèƒ½æœ‰é™
ä¸»è¦åº”ç”¨ï¼šPythonå†…éƒ¨ï¼ˆå¦‚.pycæ–‡ä»¶ï¼‰
```

### 1.2 marshal vs pickleå¯¹æ¯”


**ğŸ†š ä¸¤è€…åŒºåˆ«**ï¼š

| å¯¹æ¯”ç»´åº¦ | **marshal** | **pickle** |
|----------|-------------|------------|
| ğŸ¯ **è®¾è®¡ç›®çš„** | Pythonå†…éƒ¨ä½¿ç”¨ | é€šç”¨åºåˆ—åŒ– |
| âš¡ **é€Ÿåº¦** | å¾ˆå¿« | ç›¸å¯¹è¾ƒæ…¢ |
| ğŸ”§ **æ”¯æŒç±»å‹** | åŸºæœ¬ç±»å‹ | å‡ ä¹æ‰€æœ‰ç±»å‹ |
| ğŸ”’ **å®‰å…¨æ€§** | ä¸å®‰å…¨ | ç›¸å¯¹å®‰å…¨ |
| ğŸ“± **ç‰ˆæœ¬å…¼å®¹** | å·® | å¥½ |

### 1.3 marshalåŸºæœ¬ä½¿ç”¨


**ğŸ”¸ æ”¯æŒçš„æ•°æ®ç±»å‹**ï¼š
```python
import marshal

# âœ… æ”¯æŒçš„ç±»å‹
supported_data = {
    'numbers': [1, 2.5, 3+4j],
    'strings': 'hello',
    'collections': [1, 2, 3],
    'tuples': (1, 2, 3),
    'dicts': {'a': 1, 'b': 2},
    'sets': {1, 2, 3},
    'boolean': True,
    'none': None
}
```

**ğŸ”§ åŸºæœ¬æ“ä½œç¤ºä¾‹**ï¼š
```python
# åºåˆ—åŒ–åˆ°å­—èŠ‚
data = [1, 2, 3, "hello"]
serialized = marshal.dumps(data)
print(f"åºåˆ—åŒ–å: {serialized}")

# ååºåˆ—åŒ–
restored = marshal.loads(serialized)
print(f"è¿˜åŸå: {restored}")

# æ–‡ä»¶æ“ä½œ
with open('data.marshal', 'wb') as f:
    marshal.dump(data, f)

with open('data.marshal', 'rb') as f:
    loaded_data = marshal.load(f)
    print(f"ä»æ–‡ä»¶åŠ è½½: {loaded_data}")
```

**âš ï¸ ä½¿ç”¨æ³¨æ„äº‹é¡¹**ï¼š
```python
# âŒ ä¸æ”¯æŒè‡ªå®šä¹‰ç±»
class MyClass:
    def __init__(self, value):
        self.value = value

# è¿™ä¼šæŠ¥é”™
try:
    obj = MyClass(42)
    marshal.dumps(obj)
except ValueError as e:
    print(f"é”™è¯¯: {e}")
```

### 1.4 å®é™…åº”ç”¨åœºæ™¯


**ğŸ’¼ é€‚ç”¨åœºæ™¯**ï¼š
> ğŸ“Š **æ•°æ®ç¼“å­˜**ï¼šä¸´æ—¶ç¼“å­˜è®¡ç®—ç»“æœ
> ğŸ”„ **è¿›ç¨‹é€šä¿¡**ï¼šè¿›ç¨‹é—´ä¼ é€’åŸºæœ¬æ•°æ®
> âš¡ **å¿«é€Ÿå­˜å‚¨**ï¼šéœ€è¦æé«˜é€Ÿåº¦çš„åœºæ™¯

**å®ç”¨ç¤ºä¾‹**ï¼š
```python
import marshal
import time

def cache_calculation_result():
    """ç¼“å­˜è®¡ç®—ç»“æœç¤ºä¾‹"""
    # æ¨¡æ‹Ÿå¤æ‚è®¡ç®—
    result = sum(range(1000000))
    
    # ç¼“å­˜åˆ°æ–‡ä»¶
    with open('cache.marshal', 'wb') as f:
        marshal.dump({
            'result': result,
            'timestamp': time.time()
        }, f)
    
    return result

def load_cached_result():
    """åŠ è½½ç¼“å­˜ç»“æœ"""
    try:
        with open('cache.marshal', 'rb') as f:
            data = marshal.load(f)
            return data['result']
    except FileNotFoundError:
        return None
```

---

## 2. ğŸ—„ï¸ shelveæ¨¡å—ï¼šæŒä¹…åŒ–å­—å…¸å­˜å‚¨


### 2.1 shelveæ˜¯ä»€ä¹ˆ


ğŸ¯ **é€šä¿—ç†è§£**ï¼š
shelveå°±åƒä¸€ä¸ª"é­”æ³•å­—å…¸"ï¼Œä½ å¯ä»¥åƒä½¿ç”¨æ™®é€šå­—å…¸ä¸€æ ·æ“ä½œå®ƒï¼Œä½†å®ƒä¼šè‡ªåŠ¨æŠŠæ•°æ®ä¿å­˜åˆ°ç¡¬ç›˜ä¸Šã€‚å°±åƒæœ‰ä¸€ä¸ªéšæ—¶è‡ªåŠ¨ä¿å­˜çš„è®°äº‹æœ¬ï¼Œä½ å†™ä»€ä¹ˆå®ƒå°±è®°ä»€ä¹ˆï¼Œä¸‹æ¬¡æ‰“å¼€è¿˜åœ¨é‚£é‡Œã€‚

**ğŸ“– æ ¸å¿ƒæ¦‚å¿µ**ï¼š
```
shelve = æŒä¹…åŒ–çš„å­—å…¸
åŸç†ï¼šç±»ä¼¼å­—å…¸çš„æ¥å£ + è‡ªåŠ¨ç£ç›˜å­˜å‚¨
ä¼˜åŠ¿ï¼šä½¿ç”¨ç®€å•ï¼Œè‡ªåŠ¨æŒä¹…åŒ–
åº”ç”¨ï¼šå°å‹æ•°æ®åº“ã€é…ç½®å­˜å‚¨
```

### 2.2 shelveåŸºæœ¬ä½¿ç”¨


**ğŸ”§ åŸºç¡€æ“ä½œ**ï¼š
```python
import shelve

# æ‰“å¼€shelveæ–‡ä»¶ï¼ˆä¼šè‡ªåŠ¨åˆ›å»ºï¼‰
with shelve.open('mydata.db') as shelf:
    # åƒå­—å…¸ä¸€æ ·ä½¿ç”¨
    shelf['name'] = 'Pythonå­¦ä¹ è€…'
    shelf['scores'] = [85, 92, 78, 96]
    shelf['config'] = {'theme': 'dark', 'lang': 'zh-cn'}
    
    print("æ•°æ®å·²ä¿å­˜")

# è¯»å–æ•°æ®
with shelve.open('mydata.db') as shelf:
    print(f"å§“å: {shelf['name']}")
    print(f"æˆç»©: {shelf['scores']}")
    print(f"é…ç½®: {shelf['config']}")
```

**ğŸ”¸ shelveçš„ç‰¹æ€§**ï¼š
```python
import shelve

def shelve_features_demo():
    """å±•ç¤ºshelveçš„å„ç§ç‰¹æ€§"""
    
    with shelve.open('demo.db') as shelf:
        # 1. æ”¯æŒå„ç§æ•°æ®ç±»å‹
        shelf['string'] = "æ–‡æœ¬æ•°æ®"
        shelf['list'] = [1, 2, 3, 4, 5]
        shelf['dict'] = {'a': 1, 'b': 2}
        shelf['tuple'] = (10, 20, 30)
        
        # 2. æ£€æŸ¥é”®æ˜¯å¦å­˜åœ¨
        if 'string' in shelf:
            print("æ‰¾åˆ°äº†stringé”®")
        
        # 3. è·å–æ‰€æœ‰é”®
        print(f"æ‰€æœ‰é”®: {list(shelf.keys())}")
        
        # 4. å®‰å…¨è·å–å€¼
        value = shelf.get('nonexistent', 'é»˜è®¤å€¼')
        print(f"ä¸å­˜åœ¨çš„é”®: {value}")
        
        # 5. åˆ é™¤é”®
        if 'temp' in shelf:
            del shelf['temp']
```

### 2.3 shelveé«˜çº§ç‰¹æ€§


**ğŸ”„ åŒæ­¥æ§åˆ¶**ï¼š
```python
import shelve

# æ‰‹åŠ¨æ§åˆ¶åŒæ­¥
shelf = shelve.open('data.db', writeback=True)
try:
    # writeback=True å…è®¸ä¿®æ”¹å¯å˜å¯¹è±¡
    shelf['list'] = [1, 2, 3]
    shelf['list'].append(4)  # è¿™ä¸ªä¿®æ”¹ä¼šè¢«ä¿å­˜
    
    # æ‰‹åŠ¨åŒæ­¥
    shelf.sync()
    
finally:
    shelf.close()
```

**ğŸ’¡ å®é™…åº”ç”¨ç¤ºä¾‹**ï¼š
```python
import shelve
from datetime import datetime

class SimpleLogger:
    """ä½¿ç”¨shelveå®ç°ç®€å•æ—¥å¿—è®°å½•"""
    
    def __init__(self, db_file='logs.db'):
        self.db_file = db_file
    
    def log(self, level, message):
        """è®°å½•æ—¥å¿—"""
        with shelve.open(self.db_file) as shelf:
            # è·å–ç°æœ‰æ—¥å¿—æˆ–åˆ›å»ºæ–°åˆ—è¡¨
            logs = shelf.get('logs', [])
            
            # æ·»åŠ æ–°æ—¥å¿—
            logs.append({
                'timestamp': datetime.now().isoformat(),
                'level': level,
                'message': message
            })
            
            # ä¿å­˜å›å»
            shelf['logs'] = logs
    
    def get_logs(self, level=None):
        """è·å–æ—¥å¿—"""
        with shelve.open(self.db_file) as shelf:
            logs = shelf.get('logs', [])
            
            if level:
                return [log for log in logs if log['level'] == level]
            return logs

# ä½¿ç”¨ç¤ºä¾‹
logger = SimpleLogger()
logger.log('INFO', 'ç¨‹åºå¯åŠ¨')
logger.log('ERROR', 'å‘ç”Ÿé”™è¯¯')

print("æ‰€æœ‰æ—¥å¿—:", logger.get_logs())
print("é”™è¯¯æ—¥å¿—:", logger.get_logs('ERROR'))
```

### 2.4 shelveä½¿ç”¨æ³¨æ„äº‹é¡¹


**âš ï¸ é‡è¦æé†’**ï¼š

```python
import shelve

# âŒ é”™è¯¯ç”¨æ³•
with shelve.open('data.db') as shelf:
    shelf['list'] = [1, 2, 3]
    shelf['list'].append(4)  # ä¿®æ”¹ä¸ä¼šä¿å­˜ï¼

# âœ… æ­£ç¡®ç”¨æ³•1ï¼šé‡æ–°èµ‹å€¼
with shelve.open('data.db') as shelf:
    temp_list = shelf['list']
    temp_list.append(4)
    shelf['list'] = temp_list  # é‡æ–°èµ‹å€¼

# âœ… æ­£ç¡®ç”¨æ³•2ï¼šä½¿ç”¨writeback
with shelve.open('data.db', writeback=True) as shelf:
    shelf['list'].append(4)  # ä¼šè‡ªåŠ¨ä¿å­˜
```

**ğŸ¯ æœ€ä½³å®è·µ**ï¼š
- é€‚åˆå°åˆ°ä¸­ç­‰è§„æ¨¡çš„æ•°æ®å­˜å‚¨
- ä¸é€‚åˆå¤šè¿›ç¨‹å¹¶å‘è®¿é—®
- è®°å¾—å¤„ç†å¼‚å¸¸å’Œèµ„æºæ¸…ç†
- å¯¹äºå¤§æ•°æ®é‡è€ƒè™‘ä½¿ç”¨æ•°æ®åº“

---

## 3. âš™ï¸ configparseræ¨¡å—ï¼šé…ç½®æ–‡ä»¶å¤„ç†


### 3.1 é…ç½®æ–‡ä»¶æ˜¯ä»€ä¹ˆ


ğŸ¯ **é€šä¿—ç†è§£**ï¼š
é…ç½®æ–‡ä»¶å°±åƒç¨‹åºçš„"è®¾ç½®é¢æ¿"ã€‚ä½ çŸ¥é“æ‰‹æœºè®¾ç½®é‡Œå¯ä»¥è°ƒæ•´é“ƒå£°ã€äº®åº¦ã€è¯­è¨€å—ï¼Ÿé…ç½®æ–‡ä»¶å°±æ˜¯ç¨‹åºç‰ˆçš„è®¾ç½®ï¼Œè®©ç¨‹åºçŸ¥é“ç”¨ä»€ä¹ˆæ•°æ®åº“ã€ç›‘å¬å“ªä¸ªç«¯å£ã€ä½¿ç”¨ä»€ä¹ˆä¸»é¢˜ç­‰ç­‰ã€‚

**ğŸ“– INIæ ¼å¼ä»‹ç»**ï¼š
```ini
# è¿™æ˜¯æ³¨é‡Š
[æ•°æ®åº“é…ç½®]
host = localhost
port = 3306
username = admin
password = secret123

[åº”ç”¨è®¾ç½®]
debug = true
theme = dark
language = zh-cn
max_users = 100
```

### 3.2 configparseråŸºæœ¬ä½¿ç”¨


**ğŸ”§ è¯»å–é…ç½®æ–‡ä»¶**ï¼š
```python
import configparser

# åˆ›å»ºé…ç½®è§£æå™¨
config = configparser.ConfigParser()

# è¯»å–é…ç½®æ–‡ä»¶
config.read('app_config.ini', encoding='utf-8')

# è·å–é…ç½®å€¼
db_host = config['æ•°æ®åº“é…ç½®']['host']
db_port = config.getint('æ•°æ®åº“é…ç½®', 'port')  # è‡ªåŠ¨è½¬æ¢ä¸ºæ•´æ•°
debug_mode = config.getboolean('åº”ç”¨è®¾ç½®', 'debug')  # è‡ªåŠ¨è½¬æ¢ä¸ºå¸ƒå°”å€¼

print(f"æ•°æ®åº“: {db_host}:{db_port}")
print(f"è°ƒè¯•æ¨¡å¼: {debug_mode}")
```

**ğŸ”¸ ä¸åŒæ•°æ®ç±»å‹å¤„ç†**ï¼š
```python
import configparser

config = configparser.ConfigParser()
config.read('config.ini')

# ä¸åŒç±»å‹çš„è·å–æ–¹æ³•
host = config.get('database', 'host')              # å­—ç¬¦ä¸²ï¼ˆé»˜è®¤ï¼‰
port = config.getint('database', 'port')           # æ•´æ•°
timeout = config.getfloat('database', 'timeout')   # æµ®ç‚¹æ•°
debug = config.getboolean('app', 'debug')          # å¸ƒå°”å€¼

# æä¾›é»˜è®¤å€¼
max_conn = config.getint('database', 'max_connections', fallback=10)
```

### 3.3 åˆ›å»ºå’Œä¿®æ”¹é…ç½®æ–‡ä»¶


**ğŸ”§ åˆ›å»ºé…ç½®æ–‡ä»¶**ï¼š
```python
import configparser

def create_config_file():
    """åˆ›å»ºä¸€ä¸ªå®Œæ•´çš„é…ç½®æ–‡ä»¶"""
    config = configparser.ConfigParser()
    
    # æ·»åŠ æ•°æ®åº“é…ç½®æ®µ
    config['æ•°æ®åº“'] = {
        'host': 'localhost',
        'port': '5432',
        'database': 'myapp',
        'username': 'admin',
        'password': 'secret'
    }
    
    # æ·»åŠ åº”ç”¨é…ç½®æ®µ
    config['åº”ç”¨'] = {
        'debug': 'False',
        'log_level': 'INFO',
        'max_users': '1000',
        'theme': 'light'
    }
    
    # æ·»åŠ åŠŸèƒ½å¼€å…³æ®µ
    config['åŠŸèƒ½å¼€å…³'] = {
        'enable_cache': 'True',
        'enable_logging': 'True',
        'enable_metrics': 'False'
    }
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    with open('app_config.ini', 'w', encoding='utf-8') as f:
        config.write(f)
    
    print("é…ç½®æ–‡ä»¶åˆ›å»ºå®Œæˆ")

create_config_file()
```

**ğŸ”„ ä¿®æ”¹ç°æœ‰é…ç½®**ï¼š
```python
import configparser

def update_config():
    """ä¿®æ”¹ç°æœ‰é…ç½®"""
    config = configparser.ConfigParser()
    config.read('app_config.ini', encoding='utf-8')
    
    # ä¿®æ”¹ç°æœ‰å€¼
    config['åº”ç”¨']['debug'] = 'True'
    config['åº”ç”¨']['log_level'] = 'DEBUG'
    
    # æ·»åŠ æ–°çš„é…ç½®é¡¹
    config['åº”ç”¨']['new_feature'] = 'enabled'
    
    # æ·»åŠ æ–°çš„æ®µ
    if 'APIé…ç½®' not in config:
        config['APIé…ç½®'] = {}
    
    config['APIé…ç½®']['base_url'] = 'https://api.example.com'
    config['APIé…ç½®']['timeout'] = '30'
    
    # ä¿å­˜ä¿®æ”¹
    with open('app_config.ini', 'w', encoding='utf-8') as f:
        config.write(f)
    
    print("é…ç½®æ›´æ–°å®Œæˆ")
```

### 3.4 å®é™…åº”ç”¨ç¤ºä¾‹


**ğŸ’¼ Webåº”ç”¨é…ç½®ç®¡ç†å™¨**ï¼š
```python
import configparser
import os

class AppConfig:
    """åº”ç”¨é…ç½®ç®¡ç†å™¨"""
    
    def __init__(self, config_file='app.ini'):
        self.config_file = config_file
        self.config = configparser.ConfigParser()
        self.load_config()
    
    def load_config(self):
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        if os.path.exists(self.config_file):
            self.config.read(self.config_file, encoding='utf-8')
        else:
            self.create_default_config()
    
    def create_default_config(self):
        """åˆ›å»ºé»˜è®¤é…ç½®"""
        self.config['åº”ç”¨'] = {
            'name': 'MyApp',
            'version': '1.0.0',
            'debug': 'False'
        }
        
        self.config['æ•°æ®åº“'] = {
            'host': 'localhost',
            'port': '3306',
            'name': 'myapp_db'
        }
        
        self.save_config()
    
    def get_database_config(self):
        """è·å–æ•°æ®åº“é…ç½®"""
        db_section = self.config['æ•°æ®åº“']
        return {
            'host': db_section.get('host'),
            'port': db_section.getint('port'),
            'database': db_section.get('name'),
            'username': db_section.get('username', ''),
            'password': db_section.get('password', '')
        }
    
    def is_debug_mode(self):
        """æ£€æŸ¥æ˜¯å¦ä¸ºè°ƒè¯•æ¨¡å¼"""
        return self.config.getboolean('åº”ç”¨', 'debug', fallback=False)
    
    def update_setting(self, section, key, value):
        """æ›´æ–°é…ç½®é¡¹"""
        if section not in self.config:
            self.config[section] = {}
        
        self.config[section][key] = str(value)
        self.save_config()
    
    def save_config(self):
        """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶"""
        with open(self.config_file, 'w', encoding='utf-8') as f:
            self.config.write(f)

# ä½¿ç”¨ç¤ºä¾‹
app_config = AppConfig()
print(f"è°ƒè¯•æ¨¡å¼: {app_config.is_debug_mode()}")
print(f"æ•°æ®åº“é…ç½®: {app_config.get_database_config()}")

app_config.update_setting('åº”ç”¨', 'debug', 'True')
```

---

## 4. ğŸ” base64æ¨¡å—ï¼šæ•°æ®ç¼–ç ä¼ è¾“


### 4.1 base64æ˜¯ä»€ä¹ˆ


ğŸ¯ **é€šä¿—ç†è§£**ï¼š
base64å°±åƒæ˜¯æ•°æ®çš„"ç¿»è¯‘å™¨"ã€‚æƒ³è±¡ä½ è¦ç»™åªè®¤è¯†è‹±æ–‡å­—æ¯çš„é‚®é€’å‘˜é€ä¸€ä¸ªåŒ…å«ä¸­æ–‡çš„ä¿¡ä»¶ï¼Œbase64å°±æ˜¯æŠŠä¸­æ–‡ç¿»è¯‘æˆç‰¹æ®Šçš„è‹±æ–‡å­—æ¯ç»„åˆï¼Œè®©é‚®é€’å‘˜èƒ½å¤Ÿå®‰å…¨ä¼ é€’ï¼Œåˆ°äº†ç›®çš„åœ°å†ç¿»è¯‘å›ä¸­æ–‡ã€‚

**ğŸ“– æ ¸å¿ƒæ¦‚å¿µ**ï¼š
```
base64 = äºŒè¿›åˆ¶æ•°æ®çš„æ–‡æœ¬ç¼–ç æ–¹å¼
ç›®çš„ï¼šè®©äºŒè¿›åˆ¶æ•°æ®å¯ä»¥åœ¨æ–‡æœ¬ç¯å¢ƒä¸­ä¼ è¾“
åŸç†ï¼šç”¨64ä¸ªå¯æ‰“å°å­—ç¬¦è¡¨ç¤ºæ‰€æœ‰å¯èƒ½çš„æ•°æ®
åº”ç”¨ï¼šé‚®ä»¶é™„ä»¶ã€ç½‘é¡µå›¾ç‰‡ã€APIä¼ è¾“
```

**ğŸ”¸ ç¼–ç å­—ç¬¦é›†**ï¼š
```
A-Z (26ä¸ª) + a-z (26ä¸ª) + 0-9 (10ä¸ª) + / + = 
æ€»å…±64ä¸ªå­—ç¬¦ï¼Œè¿™å°±æ˜¯"base64"åå­—çš„ç”±æ¥
```

### 4.2 base64åŸºæœ¬ä½¿ç”¨


**ğŸ”§ åŸºç¡€ç¼–ç è§£ç **ï¼š
```python
import base64

# å­—ç¬¦ä¸²ç¼–ç 
text = "Hello, Pythonå­¦ä¹ è€…!"
# å…ˆè½¬ä¸ºå­—èŠ‚ï¼Œå†ç¼–ç 
encoded = base64.b64encode(text.encode('utf-8'))
print(f"ç¼–ç å: {encoded}")
print(f"ç¼–ç å(å­—ç¬¦ä¸²): {encoded.decode('ascii')}")

# è§£ç 
decoded_bytes = base64.b64decode(encoded)
decoded_text = decoded_bytes.decode('utf-8')
print(f"è§£ç å: {decoded_text}")
```

**ğŸ”¸ ä¸åŒç¼–ç æ–¹å¼**ï¼š
```python
import base64

data = b"Pythonæ•°æ®ç¼–ç "

# æ ‡å‡†base64ç¼–ç 
standard = base64.b64encode(data)
print(f"æ ‡å‡†ç¼–ç : {standard}")

# URLå®‰å…¨çš„base64ç¼–ç ï¼ˆç”¨-å’Œ_æ›¿æ¢+å’Œ/ï¼‰
urlsafe = base64.urlsafe_b64encode(data)
print(f"URLå®‰å…¨ç¼–ç : {urlsafe}")

# base32ç¼–ç ï¼ˆæ›´å®‰å…¨ï¼Œä½†æ›´é•¿ï¼‰
b32 = base64.b32encode(data)
print(f"Base32ç¼–ç : {b32}")

# base16ç¼–ç ï¼ˆåå…­è¿›åˆ¶ï¼‰
b16 = base64.b16encode(data)
print(f"Base16ç¼–ç : {b16}")
```

### 4.3 å®é™…åº”ç”¨åœºæ™¯


**ğŸ’Œ é‚®ä»¶é™„ä»¶æ¨¡æ‹Ÿ**ï¼š
```python
import base64
import mimetypes

def encode_file_for_email(filename):
    """æ¨¡æ‹Ÿé‚®ä»¶é™„ä»¶ç¼–ç """
    try:
        with open(filename, 'rb') as f:
            file_data = f.read()
        
        # ç¼–ç æ–‡ä»¶å†…å®¹
        encoded_data = base64.b64encode(file_data)
        
        # è·å–æ–‡ä»¶ç±»å‹
        mime_type, _ = mimetypes.guess_type(filename)
        
        return {
            'filename': filename,
            'mime_type': mime_type or 'application/octet-stream',
            'encoded_data': encoded_data.decode('ascii'),
            'size': len(file_data)
        }
    
    except FileNotFoundError:
        return None

def decode_email_attachment(attachment_info, output_filename):
    """è§£ç é‚®ä»¶é™„ä»¶"""
    try:
        # è§£ç æ•°æ®
        decoded_data = base64.b64decode(attachment_info['encoded_data'])
        
        # å†™å…¥æ–‡ä»¶
        with open(output_filename, 'wb') as f:
            f.write(decoded_data)
        
        print(f"æ–‡ä»¶å·²ä¿å­˜ä¸º: {output_filename}")
        return True
    
    except Exception as e:
        print(f"è§£ç å¤±è´¥: {e}")
        return False

# ä½¿ç”¨ç¤ºä¾‹ï¼ˆéœ€è¦æœ‰test.txtæ–‡ä»¶ï¼‰
# attachment = encode_file_for_email('test.txt')
# if attachment:
#     print(f"é™„ä»¶ä¿¡æ¯: {attachment['filename']}, å¤§å°: {attachment['size']} å­—èŠ‚")
#     decode_email_attachment(attachment, 'decoded_test.txt')
```

**ğŸ–¼ï¸ ç½‘é¡µåµŒå…¥å›¾ç‰‡**ï¼š
```python
import base64

def image_to_data_url(image_path):
    """å°†å›¾ç‰‡è½¬æ¢ä¸ºData URLæ ¼å¼ï¼ˆå¯ç›´æ¥åœ¨HTMLä¸­ä½¿ç”¨ï¼‰"""
    try:
        with open(image_path, 'rb') as f:
            image_data = f.read()
        
        # ç¼–ç å›¾ç‰‡æ•°æ®
        encoded_image = base64.b64encode(image_data).decode('ascii')
        
        # æ ¹æ®æ–‡ä»¶æ‰©å±•åç¡®å®šMIMEç±»å‹
        extension = image_path.lower().split('.')[-1]
        mime_types = {
            'jpg': 'image/jpeg',
            'jpeg': 'image/jpeg',
            'png': 'image/png',
            'gif': 'image/gif',
            'svg': 'image/svg+xml'
        }
        
        mime_type = mime_types.get(extension, 'image/png')
        
        # ç”ŸæˆData URL
        data_url = f"data:{mime_type};base64,{encoded_image}"
        
        return data_url
    
    except Exception as e:
        print(f"è½¬æ¢å¤±è´¥: {e}")
        return None

def generate_html_with_embedded_image(image_path, html_file):
    """ç”ŸæˆåŒ…å«åµŒå…¥å›¾ç‰‡çš„HTMLæ–‡ä»¶"""
    data_url = image_to_data_url(image_path)
    
    if data_url:
        html_content = f"""
<!DOCTYPE html>
<html>
<head>
    <title>åµŒå…¥å›¾ç‰‡ç¤ºä¾‹</title>
</head>
<body>
    <h1>Base64åµŒå…¥å›¾ç‰‡</h1>
    <img src="{data_url}" alt="åµŒå…¥çš„å›¾ç‰‡" style="max-width: 500px;">
    <p>è¿™å¼ å›¾ç‰‡ç›´æ¥åµŒå…¥åœ¨HTMLä¸­ï¼Œä¸éœ€è¦å•ç‹¬çš„å›¾ç‰‡æ–‡ä»¶ã€‚</p>
</body>
</html>
"""
        
        with open(html_file, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        print(f"HTMLæ–‡ä»¶å·²ç”Ÿæˆ: {html_file}")

# ä½¿ç”¨ç¤ºä¾‹
# generate_html_with_embedded_image('logo.png', 'embedded_image.html')
```

### 4.4 ä½¿ç”¨æ³¨æ„äº‹é¡¹


**âš ï¸ é‡è¦æé†’**ï¼š

| æ³¨æ„äº‹é¡¹ | è¯´æ˜ | å»ºè®® |
|----------|------|------|
| ğŸ“ˆ **å¤§å°å¢åŠ ** | ç¼–ç åå¤§å°çº¦ä¸ºåŸæ¥çš„1.33å€ | å¤§æ–‡ä»¶è€ƒè™‘å…¶ä»–æ–¹æ¡ˆ |
| ğŸ”’ **ä¸æ˜¯åŠ å¯†** | base64æ˜¯ç¼–ç ï¼Œä¸æ˜¯åŠ å¯† | æ•æ„Ÿæ•°æ®éœ€è¦é¢å¤–åŠ å¯† |
| ğŸŒ **å­—ç¬¦é™åˆ¶** | æŸäº›ç³»ç»Ÿå¯¹é•¿åº¦æœ‰é™åˆ¶ | è¶…é•¿æ•°æ®è¦åˆ†å—å¤„ç† |
| âš¡ **æ€§èƒ½è€ƒè™‘** | ç¼–ç è§£ç æœ‰è®¡ç®—å¼€é”€ | é¢‘ç¹æ“ä½œè€ƒè™‘ç¼“å­˜ |

---

## 5. ğŸ—œï¸ zlibæ¨¡å—ï¼šæ•°æ®å‹ç¼©æŠ€æœ¯


### 5.1 æ•°æ®å‹ç¼©æ˜¯ä»€ä¹ˆ


ğŸ¯ **é€šä¿—ç†è§£**ï¼š
æ•°æ®å‹ç¼©å°±åƒæ•´ç†æˆ¿é—´æ—¶çš„"çœŸç©ºæ”¶çº³è¢‹"ã€‚ä½ æŠŠè¡£æœæ”¾è¿›å»ï¼ŒæŠ½æ‰ç©ºæ°”ï¼ŒåŸæ¥å ä¸€ä¸ªè¡£æŸœçš„è¡£æœç°åœ¨åªå ä¸€ä¸ªæŠ½å±‰ã€‚zlibå°±æ˜¯æ•°æ®çš„çœŸç©ºæ”¶çº³è¢‹ï¼ŒæŠŠé‡å¤ã€å†—ä½™çš„ä¿¡æ¯"æŒ¤æ‰"ï¼Œè®©æ•°æ®å˜å°ã€‚

**ğŸ“– æ ¸å¿ƒæ¦‚å¿µ**ï¼š
```
zlib = Pythonå†…ç½®çš„å‹ç¼©åº“
åŸç†ï¼šæ‰¾å‡ºæ•°æ®ä¸­çš„é‡å¤æ¨¡å¼ï¼Œç”¨æ›´çŸ­çš„æ–¹å¼è¡¨ç¤º
ä¼˜åŠ¿ï¼šå‡å°‘å­˜å‚¨ç©ºé—´ï¼ŒåŠ å¿«ä¼ è¾“é€Ÿåº¦
åº”ç”¨ï¼šæ–‡ä»¶å‹ç¼©ã€ç½‘ç»œä¼ è¾“ã€å†…å­˜ä¼˜åŒ–
```

### 5.2 zlibåŸºæœ¬ä½¿ç”¨


**ğŸ”§ åŸºç¡€å‹ç¼©è§£å‹**ï¼š
```python
import zlib

# åŸå§‹æ•°æ®
text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ï¼ŒåŒ…å«é‡å¤çš„å†…å®¹ã€‚é‡å¤çš„å†…å®¹å¯ä»¥è¢«å¾ˆå¥½åœ°å‹ç¼©ã€‚" * 10
original_data = text.encode('utf-8')

print(f"åŸå§‹å¤§å°: {len(original_data)} å­—èŠ‚")

# å‹ç¼©æ•°æ®
compressed = zlib.compress(original_data)
print(f"å‹ç¼©åå¤§å°: {len(compressed)} å­—èŠ‚")
print(f"å‹ç¼©æ¯”: {len(compressed) / len(original_data):.2%}")

# è§£å‹æ•°æ®
decompressed = zlib.decompress(compressed)
print(f"è§£å‹åæ˜¯å¦ç›¸åŒ: {decompressed == original_data}")
```

**ğŸ›ï¸ å‹ç¼©çº§åˆ«æ§åˆ¶**ï¼š
```python
import zlib

data = b"Hello World! " * 1000

# ä¸åŒå‹ç¼©çº§åˆ«çš„å¯¹æ¯”
for level in [1, 6, 9]:
    compressed = zlib.compress(data, level)
    ratio = len(compressed) / len(data)
    
    print(f"çº§åˆ«{level}: å¤§å°{len(compressed)}, å‹ç¼©æ¯”{ratio:.2%}")

# çº§åˆ«è¯´æ˜ï¼š
# 1 = æœ€å¿«å‹ç¼©ï¼Œå‹ç¼©æ¯”è¾ƒä½
# 6 = é»˜è®¤çº§åˆ«ï¼Œå¹³è¡¡é€Ÿåº¦å’Œå‹ç¼©æ¯”
# 9 = æœ€é«˜å‹ç¼©ï¼Œé€Ÿåº¦è¾ƒæ…¢
```

### 5.3 æµå¼å‹ç¼©ï¼ˆå¤§æ–‡ä»¶å¤„ç†ï¼‰


**ğŸŒŠ å¤„ç†å¤§æ–‡ä»¶**ï¼š
```python
import zlib

def compress_large_file(input_file, output_file):
    """å‹ç¼©å¤§æ–‡ä»¶ï¼Œåˆ†å—å¤„ç†"""
    compressor = zlib.compressobj()
    
    try:
        with open(input_file, 'rb') as infile, \
             open(output_file, 'wb') as outfile:
            
            # åˆ†å—è¯»å–å’Œå‹ç¼©
            while True:
                chunk = infile.read(8192)  # æ¯æ¬¡è¯»8KB
                if not chunk:
                    break
                
                # å‹ç¼©å½“å‰å—
                compressed_chunk = compressor.compress(chunk)
                if compressed_chunk:
                    outfile.write(compressed_chunk)
            
            # å†™å…¥æœ€åçš„æ•°æ®
            final_chunk = compressor.flush()
            if final_chunk:
                outfile.write(final_chunk)
        
        print(f"æ–‡ä»¶å‹ç¼©å®Œæˆ: {input_file} -> {output_file}")
        
    except Exception as e:
        print(f"å‹ç¼©å¤±è´¥: {e}")

def decompress_large_file(input_file, output_file):
    """è§£å‹å¤§æ–‡ä»¶"""
    decompressor = zlib.decompressobj()
    
    try:
        with open(input_file, 'rb') as infile, \
             open(output_file, 'wb') as outfile:
            
            while True:
                chunk = infile.read(8192)
                if not chunk:
                    break
                
                # è§£å‹å½“å‰å—
                decompressed_chunk = decompressor.decompress(chunk)
                if decompressed_chunk:
                    outfile.write(decompressed_chunk)
            
            # å¤„ç†å‰©ä½™æ•°æ®
            final_chunk = decompressor.flush()
            if final_chunk:
                outfile.write(final_chunk)
        
        print(f"æ–‡ä»¶è§£å‹å®Œæˆ: {input_file} -> {output_file}")
        
    except Exception as e:
        print(f"è§£å‹å¤±è´¥: {e}")
```

### 5.4 å®é™…åº”ç”¨åœºæ™¯


**ğŸ’¾ æ•°æ®ç¼“å­˜ä¼˜åŒ–**ï¼š
```python
import zlib
import json
import time

class CompressedCache:
    """å‹ç¼©ç¼“å­˜ç±»"""
    
    def __init__(self):
        self.cache = {}
    
    def set(self, key, data, compress_threshold=1024):
        """è®¾ç½®ç¼“å­˜ï¼Œå¤§äºé˜ˆå€¼è‡ªåŠ¨å‹ç¼©"""
        # åºåˆ—åŒ–æ•°æ®
        serialized = json.dumps(data, ensure_ascii=False).encode('utf-8')
        
        # åˆ¤æ–­æ˜¯å¦éœ€è¦å‹ç¼©
        if len(serialized) > compress_threshold:
            compressed = zlib.compress(serialized)
            self.cache[key] = {
                'data': compressed,
                'compressed': True,
                'original_size': len(serialized),
                'compressed_size': len(compressed)
            }
            print(f"ç¼“å­˜ {key}: å‹ç¼© {len(serialized)} -> {len(compressed)} å­—èŠ‚")
        else:
            self.cache[key] = {
                'data': serialized,
                'compressed': False
            }
    
    def get(self, key):
        """è·å–ç¼“å­˜æ•°æ®"""
        if key not in self.cache:
            return None
        
        cache_item = self.cache[key]
        
        if cache_item['compressed']:
            # è§£å‹æ•°æ®
            decompressed = zlib.decompress(cache_item['data'])
            return json.loads(decompressed.decode('utf-8'))
        else:
            # ç›´æ¥è¿”å›
            return json.loads(cache_item['data'].decode('utf-8'))
    
    def stats(self):
        """ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        total_items = len(self.cache)
        compressed_items = sum(1 for item in self.cache.values() if item['compressed'])
        
        return {
            'total_items': total_items,
            'compressed_items': compressed_items,
            'compression_ratio': compressed_items / total_items if total_items > 0 else 0
        }

# ä½¿ç”¨ç¤ºä¾‹
cache = CompressedCache()

# å°æ•°æ®ï¼ˆä¸ä¼šå‹ç¼©ï¼‰
cache.set('small', {'name': 'test', 'value': 123})

# å¤§æ•°æ®ï¼ˆä¼šå‹ç¼©ï¼‰
large_data = {'data': list(range(1000)), 'text': "é‡å¤æ–‡æœ¬" * 100}
cache.set('large', large_data)

print("ç¼“å­˜ç»Ÿè®¡:", cache.stats())
print("è·å–æ•°æ®:", cache.get('large')['data'][:5])  # åªæ˜¾ç¤ºå‰5ä¸ªæ•°å­—
```

**ğŸŒ ç½‘ç»œä¼ è¾“ä¼˜åŒ–**ï¼š
```python
import zlib
import json

class NetworkDataHandler:
    """ç½‘ç»œæ•°æ®ä¼ è¾“ä¼˜åŒ–"""
    
    @staticmethod
    def prepare_for_transmission(data, compress=True):
        """å‡†å¤‡ä¼ è¾“æ•°æ®"""
        # åºåˆ—åŒ–
        json_data = json.dumps(data, ensure_ascii=False).encode('utf-8')
        
        if compress:
            # å‹ç¼©
            compressed = zlib.compress(json_data)
            return {
                'data': compressed,
                'compressed': True,
                'original_size': len(json_data),
                'compressed_size': len(compressed)
            }
        else:
            return {
                'data': json_data,
                'compressed': False
            }
    
    @staticmethod
    def process_received_data(received_data):
        """å¤„ç†æ¥æ”¶åˆ°çš„æ•°æ®"""
        if received_data['compressed']:
            # è§£å‹
            decompressed = zlib.decompress(received_data['data'])
            return json.loads(decompressed.decode('utf-8'))
        else:
            return json.loads(received_data['data'].decode('utf-8'))

# æ¨¡æ‹Ÿç½‘ç»œä¼ è¾“
def simulate_network_transfer():
    """æ¨¡æ‹Ÿç½‘ç»œä¼ è¾“è¿‡ç¨‹"""
    # è¦ä¼ è¾“çš„æ•°æ®
    data = {
        'user_list': [f'user_{i}' for i in range(1000)],
        'message': 'è¿™æ˜¯ä¸€æ¡é‡è¦æ¶ˆæ¯' * 50,
        'timestamp': time.time()
    }
    
    # å‡†å¤‡ä¼ è¾“ï¼ˆå‹ç¼©ï¼‰
    compressed_packet = NetworkDataHandler.prepare_for_transmission(data, compress=True)
    print(f"å‹ç¼©ä¼ è¾“: {compressed_packet['original_size']} -> {compressed_packet['compressed_size']} å­—èŠ‚")
    
    # å‡†å¤‡ä¼ è¾“ï¼ˆä¸å‹ç¼©ï¼‰
    uncompressed_packet = NetworkDataHandler.prepare_for_transmission(data, compress=False)
    print(f"ä¸å‹ç¼©ä¼ è¾“: {len(uncompressed_packet['data'])} å­—èŠ‚")
    
    # æ¨¡æ‹Ÿç½‘ç»œä¼ è¾“ï¼ˆè¿™é‡Œåªæ˜¯èµ‹å€¼ï¼Œå®é™…ä¼šé€šè¿‡ç½‘ç»œå‘é€ï¼‰
    received_data = compressed_packet
    
    # å¤„ç†æ¥æ”¶åˆ°çš„æ•°æ®
    recovered_data = NetworkDataHandler.process_received_data(received_data)
    
    # éªŒè¯æ•°æ®å®Œæ•´æ€§
    print(f"æ•°æ®æ¢å¤æˆåŠŸ: {recovered_data['user_list'][:3]}...")

simulate_network_transfer()
```

---

## 6. ğŸ” hashlibæ¨¡å—ï¼šå“ˆå¸Œç®—æ³•åº”ç”¨


### 6.1 å“ˆå¸Œç®—æ³•æ˜¯ä»€ä¹ˆ


ğŸ¯ **é€šä¿—ç†è§£**ï¼š
å“ˆå¸Œç®—æ³•å°±åƒç»™æ•°æ®åˆ¶ä½œ"æŒ‡çº¹"ã€‚æ¯ä¸ªäººçš„æŒ‡çº¹éƒ½æ˜¯ç‹¬ä¸€æ— äºŒçš„ï¼Œå“ˆå¸Œç®—æ³•ç»™ä»»ä½•æ•°æ®éƒ½èƒ½ç”Ÿæˆä¸€ä¸ªç‹¬ç‰¹çš„"æŒ‡çº¹"ï¼ˆå“ˆå¸Œå€¼ï¼‰ã€‚ç›¸åŒçš„æ•°æ®æ€»æ˜¯äº§ç”Ÿç›¸åŒçš„æŒ‡çº¹ï¼Œä½†ä¸åŒçš„æ•°æ®å‡ ä¹ä¸å¯èƒ½äº§ç”Ÿç›¸åŒçš„æŒ‡çº¹ã€‚

**ğŸ“– æ ¸å¿ƒæ¦‚å¿µ**ï¼š
```
å“ˆå¸Œç®—æ³• = æ•°æ® â†’ å›ºå®šé•¿åº¦çš„"æŒ‡çº¹"
ç‰¹ç‚¹ï¼š
â€¢ ç¡®å®šæ€§ï¼šç›¸åŒè¾“å…¥æ€»æ˜¯å¾—åˆ°ç›¸åŒè¾“å‡º
â€¢ é›ªå´©æ•ˆåº”ï¼šè¾“å…¥å¾®å°å˜åŒ–ï¼Œè¾“å‡ºå®Œå…¨ä¸åŒ
â€¢ ä¸å¯é€†ï¼šä»å“ˆå¸Œå€¼æ— æ³•è¿˜åŸåŸå§‹æ•°æ®
â€¢ å†²çªä½ï¼šä¸åŒè¾“å…¥äº§ç”Ÿç›¸åŒè¾“å‡ºçš„æ¦‚ç‡æä½
```

**ğŸ”¸ å¸¸è§å“ˆå¸Œç®—æ³•**ï¼š
```
MD5ï¼š128ä½ï¼Œé€Ÿåº¦å¿«ï¼Œä½†å®‰å…¨æ€§ä¸è¶³
SHA-1ï¼š160ä½ï¼Œæ¯”MD5å®‰å…¨ï¼Œä½†ä¹Ÿæœ‰æ¼æ´
SHA-256ï¼š256ä½ï¼Œç›®å‰æœ€å¸¸ç”¨ï¼Œå®‰å…¨æ€§é«˜
SHA-512ï¼š512ä½ï¼Œå®‰å…¨æ€§æœ€é«˜ï¼Œè®¡ç®—ç¨æ…¢
```

### 6.2 hashlibåŸºæœ¬ä½¿ç”¨


**ğŸ”§ åŸºç¡€å“ˆå¸Œè®¡ç®—**ï¼š
```python
import hashlib

def calculate_hash(data, algorithm='sha256'):
    """è®¡ç®—æ•°æ®çš„å“ˆå¸Œå€¼"""
    # åˆ›å»ºå“ˆå¸Œå¯¹è±¡
    hash_obj = hashlib.new(algorithm)
    
    # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå…ˆç¼–ç 
    if isinstance(data, str):
        data = data.encode('utf-8')
    
    # æ›´æ–°å“ˆå¸Œ
    hash_obj.update(data)
    
    # è·å–ç»“æœ
    return hash_obj.hexdigest()

# æµ‹è¯•ä¸åŒç®—æ³•
text = "Hello, Pythonå­¦ä¹ è€…!"

print("åŸå§‹æ–‡æœ¬:", text)
print("MD5:    ", calculate_hash(text, 'md5'))
print("SHA-1:  ", calculate_hash(text, 'sha1'))
print("SHA-256:", calculate_hash(text, 'sha256'))
print("SHA-512:", calculate_hash(text, 'sha512'))
```

**ğŸ”¸ éªŒè¯é›ªå´©æ•ˆåº”**ï¼š
```python
import hashlib

def demonstrate_avalanche_effect():
    """æ¼”ç¤ºé›ªå´©æ•ˆåº”"""
    original = "Hello World"
    modified = "Hello world"  # åªæ”¹äº†ä¸€ä¸ªå­—æ¯å¤§å°å†™
    
    original_hash = hashlib.sha256(original.encode()).hexdigest()
    modified_hash = hashlib.sha256(modified.encode()).hexdigest()
    
    print(f"åŸæ–‡: {original}")
    print(f"å“ˆå¸Œ: {original_hash}")
    print()
    print(f"æ”¹æ–‡: {modified}")
    print(f"å“ˆå¸Œ: {modified_hash}")
    print()
    print("ç›¸åŒä½æ•°:", sum(a == b for a, b in zip(original_hash, modified_hash)))
    print("æ€»ä½æ•°:", len(original_hash))

demonstrate_avalanche_effect()
```

### 6.3 æ–‡ä»¶å®Œæ•´æ€§éªŒè¯


**ğŸ“ æ–‡ä»¶å“ˆå¸Œè®¡ç®—**ï¼š
```python
import hashlib
import os

def calculate_file_hash(filename, algorithm='sha256', chunk_size=8192):
    """è®¡ç®—æ–‡ä»¶çš„å“ˆå¸Œå€¼"""
    hash_obj = hashlib.new(algorithm)
    
    try:
        with open(filename, 'rb') as f:
            # åˆ†å—è¯»å–ï¼Œé¿å…å¤§æ–‡ä»¶å ç”¨è¿‡å¤šå†…å­˜
            while chunk := f.read(chunk_size):
                hash_obj.update(chunk)
        
        return hash_obj.hexdigest()
    
    except FileNotFoundError:
        print(f"æ–‡ä»¶ä¸å­˜åœ¨: {filename}")
        return None
    except Exception as e:
        print(f"è®¡ç®—å“ˆå¸Œå¤±è´¥: {e}")
        return None

def verify_file_integrity(filename, expected_hash, algorithm='sha256'):
    """éªŒè¯æ–‡ä»¶å®Œæ•´æ€§"""
    actual_hash = calculate_file_hash(filename, algorithm)
    
    if actual_hash is None:
        return False
    
    if actual_hash.lower() == expected_hash.lower():
        print(f"âœ… æ–‡ä»¶ {filename} å®Œæ•´æ€§éªŒè¯é€šè¿‡")
        return True
    else:
        print(f"âŒ æ–‡ä»¶ {filename} å®Œæ•´æ€§éªŒè¯å¤±è´¥")
        print(f"æœŸæœ›: {expected_hash}")
        print(f"å®é™…: {actual_hash}")
        return False

# ä½¿ç”¨ç¤ºä¾‹
def file_integrity_demo():
    """æ–‡ä»¶å®Œæ•´æ€§æ¼”ç¤º"""
    # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
    test_file = 'test_file.txt'
    test_content = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡ä»¶ï¼Œç”¨äºæ¼”ç¤ºå“ˆå¸ŒéªŒè¯ã€‚"
    
    with open(test_file, 'w', encoding='utf-8') as f:
        f.write(test_content)
    
    # è®¡ç®—åŸå§‹å“ˆå¸Œ
    original_hash = calculate_file_hash(test_file)
    print(f"æ–‡ä»¶å“ˆå¸Œ: {original_hash}")
    
    # éªŒè¯å®Œæ•´æ€§
    verify_file_integrity(test_file, original_hash)
    
    # ä¿®æ”¹æ–‡ä»¶
    with open(test_file, 'a', encoding='utf-8') as f:
        f.write("é¢å¤–å†…å®¹")
    
    # å†æ¬¡éªŒè¯
    print("\nä¿®æ”¹æ–‡ä»¶å:")
    verify_file_integrity(test_file, original_hash)
    
    # æ¸…ç†
    os.remove(test_file)

# file_integrity_demo()
```

### 6.4 å¯†ç å®‰å…¨å­˜å‚¨


**ğŸ”’ å¯†ç å“ˆå¸Œæœ€ä½³å®è·µ**ï¼š
```python
import hashlib
import secrets
import time

class SecurePasswordManager:
    """å®‰å…¨å¯†ç ç®¡ç†å™¨"""
    
    @staticmethod
    def generate_salt(length=16):
        """ç”Ÿæˆéšæœºç›å€¼"""
        return secrets.token_hex(length)
    
    @staticmethod
    def hash_password(password, salt=None, iterations=100000):
        """å®‰å…¨åœ°å“ˆå¸Œå¯†ç """
        if salt is None:
            salt = SecurePasswordManager.generate_salt()
        
        # ä½¿ç”¨PBKDF2ç®—æ³•ï¼ˆæ…¢å“ˆå¸Œï¼ŒæŠ—æš´åŠ›ç ´è§£ï¼‰
        password_hash = hashlib.pbkdf2_hmac(
            'sha256',
            password.encode('utf-8'),
            salt.encode('utf-8'),
            iterations
        )
        
        return {
            'hash': password_hash.hex(),
            'salt': salt,
            'iterations': iterations
        }
    
    @staticmethod
    def verify_password(password, stored_hash_info):
        """éªŒè¯å¯†ç """
        # ä½¿ç”¨ç›¸åŒçš„ç›å’Œè¿­ä»£æ¬¡æ•°é‡æ–°è®¡ç®—å“ˆå¸Œ
        computed = SecurePasswordManager.hash_password(
            password,
            stored_hash_info['salt'],
            stored_hash_info['iterations']
        )
        
        # æ¯”è¾ƒå“ˆå¸Œå€¼
        return computed['hash'] == stored_hash_info['hash']

# ä½¿ç”¨ç¤ºä¾‹
def password_security_demo():
    """å¯†ç å®‰å…¨æ¼”ç¤º"""
    pm = SecurePasswordManager()
    
    # ç”¨æˆ·æ³¨å†Œ
    user_password = "MySecurePassword123!"
    stored_info = pm.hash_password(user_password)
    
    print("ç”¨æˆ·æ³¨å†Œ:")
    print(f"åŸå§‹å¯†ç : {user_password}")
    print(f"å­˜å‚¨ä¿¡æ¯: {stored_info}")
    print()
    
    # ç”¨æˆ·ç™»å½•ï¼ˆæ­£ç¡®å¯†ç ï¼‰
    login_password = "MySecurePassword123!"
    is_valid = pm.verify_password(login_password, stored_info)
    print(f"ç™»å½•éªŒè¯ï¼ˆæ­£ç¡®å¯†ç ï¼‰: {'âœ… æˆåŠŸ' if is_valid else 'âŒ å¤±è´¥'}")
    
    # ç”¨æˆ·ç™»å½•ï¼ˆé”™è¯¯å¯†ç ï¼‰
    wrong_password = "WrongPassword"
    is_valid = pm.verify_password(wrong_password, stored_info)
    print(f"ç™»å½•éªŒè¯ï¼ˆé”™è¯¯å¯†ç ï¼‰: {'âœ… æˆåŠŸ' if is_valid else 'âŒ å¤±è´¥'}")
    
    # æ¼”ç¤ºæ—¶é—´å¼€é”€ï¼ˆå®‰å…¨æ€§ä»£ä»·ï¼‰
    start_time = time.time()
    pm.hash_password("test", iterations=100000)
    elapsed = time.time() - start_time
    print(f"\nå¯†ç å“ˆå¸Œè€—æ—¶: {elapsed:.3f} ç§’")

password_security_demo()
```

**ğŸ›¡ï¸ ç®€å•å“ˆå¸Œå·¥å…·ç±»**ï¼š
```python
import hashlib

class HashUtils:
    """å“ˆå¸Œå·¥å…·ç±»"""
    
    @staticmethod
    def quick_hash(data, algorithm='sha256'):
        """å¿«é€Ÿè®¡ç®—å“ˆå¸Œ"""
        if isinstance(data, str):
            data = data.encode('utf-8')
        
        return hashlib.new(algorithm, data).hexdigest()
    
    @staticmethod
    def compare_files(file1, file2):
        """æ¯”è¾ƒä¸¤ä¸ªæ–‡ä»¶æ˜¯å¦ç›¸åŒ"""
        hash1 = calculate_file_hash(file1)
        hash2 = calculate_file_hash(file2)
        
        if hash1 and hash2:
            return hash1 == hash2
        return False
    
    @staticmethod
    def detect_duplicates(file_list):
        """æ£€æµ‹æ–‡ä»¶åˆ—è¡¨ä¸­çš„é‡å¤æ–‡ä»¶"""
        hash_map = {}
        duplicates = []
        
        for filename in file_list:
            file_hash = calculate_file_hash(filename)
            if file_hash:
                if file_hash in hash_map:
                    duplicates.append((filename, hash_map[file_hash]))
                else:
                    hash_map[file_hash] = filename
        
        return duplicates

# ä½¿ç”¨å·¥å…·ç±»
utils = HashUtils()
print("å­—ç¬¦ä¸²å“ˆå¸Œ:", utils.quick_hash("æµ‹è¯•æ•°æ®"))
```

---

## 7. ğŸ”„ æ•°æ®æ ¼å¼è½¬æ¢æŠ€å·§


### 7.1 æ ¼å¼è½¬æ¢æ¦‚è¿°


ğŸ¯ **é€šä¿—ç†è§£**ï¼š
æ•°æ®æ ¼å¼è½¬æ¢å°±åƒ"ç¿»è¯‘"å·¥ä½œã€‚ä½ æœ‰ä¸€ä»½ä¸­æ–‡èµ„æ–™è¦ç»™ç¾å›½æœ‹å‹çœ‹ï¼Œå°±éœ€è¦ç¿»è¯‘æˆè‹±æ–‡ï¼›åŒæ ·ï¼Œä½ æœ‰JSONæ ¼å¼çš„æ•°æ®è¦å­˜åˆ°æ•°æ®åº“ï¼Œå¯èƒ½éœ€è¦è½¬æ¢æˆSQLè¯­å¥ï¼Œæˆ–è€…è¦ä¼ è¾“ç»™å…¶ä»–ç³»ç»Ÿï¼Œéœ€è¦è½¬æ¢æˆXMLæ ¼å¼ã€‚

**ğŸ“– å¸¸è§è½¬æ¢åœºæ™¯**ï¼š
```
æ•°æ®äº¤æ¢ï¼šJSON â†” XML â†” CSV â†” YAML
æ•°æ®å­˜å‚¨ï¼šPythonå¯¹è±¡ â†” æ•°æ®åº“è®°å½•
æ•°æ®ä¼ è¾“ï¼šå¯¹è±¡ â†” å­—èŠ‚æµ â†” Base64
é…ç½®ç®¡ç†ï¼šINI â†” JSON â†” YAML
```

### 7.2 JSONä¸å…¶ä»–æ ¼å¼è½¬æ¢


**ğŸ”§ JSON â†” CSV è½¬æ¢**ï¼š
```python
import json
import csv
import io

def json_to_csv(json_data, csv_file=None):
    """JSONè½¬CSV"""
    # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå…ˆè§£æ
    if isinstance(json_data, str):
        data = json.loads(json_data)
    else:
        data = json_data
    
    # ç¡®ä¿æ˜¯åˆ—è¡¨æ ¼å¼
    if not isinstance(data, list):
        data = [data]
    
    if not data:
        return ""
    
    # è·å–æ‰€æœ‰å­—æ®µ
    fieldnames = set()
    for item in data:
        if isinstance(item, dict):
            fieldnames.update(item.keys())
    
    fieldnames = sorted(fieldnames)
    
    # å†™å…¥CSV
    if csv_file:
        with open(csv_file, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(data)
        print(f"CSVæ–‡ä»¶å·²ä¿å­˜: {csv_file}")
    else:
        # è¿”å›CSVå­—ç¬¦ä¸²
        output = io.StringIO()
        writer = csv.DictWriter(output, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(data)
        return output.getvalue()

def csv_to_json(csv_file, json_file=None):
    """CSVè½¬JSON"""
    data = []
    
    with open(csv_file, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            data.append(row)
    
    if json_file:
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"JSONæ–‡ä»¶å·²ä¿å­˜: {json_file}")
    else:
        return json.dumps(data, ensure_ascii=False, indent=2)

# ç¤ºä¾‹æ•°æ®
sample_data = [
    {"å§“å": "å¼ ä¸‰", "å¹´é¾„": 25, "åŸå¸‚": "åŒ—äº¬"},
    {"å§“å": "æå››", "å¹´é¾„": 30, "åŸå¸‚": "ä¸Šæµ·"},
    {"å§“å": "ç‹äº”", "å¹´é¾„": 28, "åŸå¸‚": "å¹¿å·"}
]

# è½¬æ¢æ¼”ç¤º
csv_content = json_to_csv(sample_data)
print("JSONè½¬CSVç»“æœ:")
print(csv_content)
```

**ğŸ”§ JSON â†” XML è½¬æ¢**ï¼š
```python
import json
import xml.etree.ElementTree as ET

def json_to_xml(json_data, root_name="root"):
    """JSONè½¬XML"""
    if isinstance(json_data, str):
        data = json.loads(json_data)
    else:
        data = json_data
    
    def dict_to_element(parent, key, value):
        """é€’å½’è½¬æ¢å­—å…¸ä¸ºXMLå…ƒç´ """
        if isinstance(value, dict):
            element = ET.SubElement(parent, key)
            for k, v in value.items():
                dict_to_element(element, k, v)
        elif isinstance(value, list):
            for item in value:
                dict_to_element(parent, key, item)
        else:
            element = ET.SubElement(parent, key)
            element.text = str(value)
    
    root = ET.Element(root_name)
    
    if isinstance(data, dict):
        for key, value in data.items():
            dict_to_element(root, key, value)
    elif isinstance(data, list):
        for item in data:
            dict_to_element(root, "item", item)
    
    return ET.tostring(root, encoding='unicode')

def xml_to_json(xml_content):
    """XMLè½¬JSONï¼ˆç®€åŒ–ç‰ˆï¼‰"""
    def element_to_dict(element):
        """é€’å½’è½¬æ¢XMLå…ƒç´ ä¸ºå­—å…¸"""
        result = {}
        
        # å¤„ç†å­å…ƒç´ 
        for child in element:
            if child.tag in result:
                # å¦‚æœå·²å­˜åœ¨ï¼Œè½¬ä¸ºåˆ—è¡¨
                if not isinstance(result[child.tag], list):
                    result[child.tag] = [result[child.tag]]
                result[child.tag].append(element_to_dict(child))
            else:
                result[child.tag] = element_to_dict(child)
        
        # å¦‚æœæ²¡æœ‰å­å…ƒç´ ï¼Œè¿”å›æ–‡æœ¬å†…å®¹
        if not result and element.text:
            return element.text.strip()
        
        return result
    
    root = ET.fromstring(xml_content)
    return json.dumps(element_to_dict(root), ensure_ascii=False, indent=2)

# è½¬æ¢æ¼”ç¤º
sample_json = {"ç”¨æˆ·": {"å§“å": "å¼ ä¸‰", "ä¿¡æ¯": {"å¹´é¾„": 25, "åŸå¸‚": "åŒ—äº¬"}}}
xml_content = json_to_xml(sample_json)
print("JSONè½¬XMLç»“æœ:")
print(xml_content)
print()

back_to_json = xml_to_json(xml_content)
print("XMLè½¬å›JSON:")
print(back_to_json)
```

### 7.3 é…ç½®æ ¼å¼äº’è½¬


**âš™ï¸ é…ç½®æ–‡ä»¶æ ¼å¼è½¬æ¢å™¨**ï¼š
```python
import json
import configparser
import io

class ConfigConverter:
    """é…ç½®æ–‡ä»¶æ ¼å¼è½¬æ¢å™¨"""
    
    @staticmethod
    def ini_to_dict(ini_file):
        """INIæ–‡ä»¶è½¬å­—å…¸"""
        config = configparser.ConfigParser()
        config.read(ini_file, encoding='utf-8')
        
        result = {}
        for section_name in config.sections():
            result[section_name] = dict(config[section_name])
        
        return result
    
    @staticmethod
    def dict_to_ini(data, ini_file=None):
        """å­—å…¸è½¬INIæ ¼å¼"""
        config = configparser.ConfigParser()
        
        for section_name, section_data in data.items():
            config[section_name] = {}
            for key, value in section_data.items():
                config[section_name][key] = str(value)
        
        if ini_file:
            with open(ini_file, 'w', encoding='utf-8') as f:
                config.write(f)
        else:
            output = io.StringIO()
            config.write(output)
            return output.getvalue()
    
    @staticmethod
    def json_to_ini(json_file, ini_file):
        """JSONè½¬INI"""
        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        ConfigConverter.dict_to_ini(data, ini_file)
        print(f"è½¬æ¢å®Œæˆ: {json_file} -> {ini_file}")
    
    @staticmethod
    def ini_to_json(ini_file, json_file):
        """INIè½¬JSON"""
        data = ConfigConverter.ini_to_dict(ini_file)
        
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        print(f"è½¬æ¢å®Œæˆ: {ini_file} -> {json_file}")

# ä½¿ç”¨ç¤ºä¾‹
def config_conversion_demo():
    """é…ç½®è½¬æ¢æ¼”ç¤º"""
    # åˆ›å»ºç¤ºä¾‹é…ç½®
    config_data = {
        "æ•°æ®åº“": {
            "host": "localhost",
            "port": "3306",
            "username": "admin"
        },
        "åº”ç”¨": {
            "debug": "true",
            "log_level": "INFO"
        }
    }
    
    # è½¬æ¢ä¸ºINIæ ¼å¼
    ini_content = ConfigConverter.dict_to_ini(config_data)
    print("å­—å…¸è½¬INI:")
    print(ini_content)

config_conversion_demo()
```

### 7.4 æ•°æ®åºåˆ—åŒ–æ ¼å¼é€‰æ‹©æŒ‡å—


**ğŸ“Š æ ¼å¼é€‰æ‹©çŸ©é˜µ**ï¼š

| æ ¼å¼ | **å¯è¯»æ€§** | **ç´§å‡‘æ€§** | **è§£æé€Ÿåº¦** | **è·¨è¯­è¨€** | **é€‚ç”¨åœºæ™¯** |
|------|------------|------------|--------------|------------|--------------|
| ğŸ”¸ **JSON** | â­â­â­â­ | â­â­â­ | â­â­â­â­ | â­â­â­â­â­ | Web APIã€é…ç½®æ–‡ä»¶ |
| ğŸ”¸ **XML** | â­â­â­ | â­â­ | â­â­ | â­â­â­â­â­ | ä¼ä¸šç³»ç»Ÿã€æ–‡æ¡£ç»“æ„ |
| ğŸ”¸ **CSV** | â­â­â­â­â­ | â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­â­ | è¡¨æ ¼æ•°æ®ã€æ•°æ®åˆ†æ |
| ğŸ”¸ **Pickle** | â­ | â­â­â­â­ | â­â­â­â­â­ | â­ | Pythonå†…éƒ¨å­˜å‚¨ |
| ğŸ”¸ **Marshal** | â­ | â­â­â­â­â­ | â­â­â­â­â­ | â­ | Pythonå†…éƒ¨é«˜é€Ÿ |

**ğŸ¯ é€‰æ‹©å»ºè®®**ï¼š
```
Webå¼€å‘ï¼šé¦–é€‰JSON
ä¼ä¸šé›†æˆï¼šè€ƒè™‘XML
æ•°æ®åˆ†æï¼šä½¿ç”¨CSV
Pythonå†…éƒ¨ï¼špickleæˆ–marshal
é…ç½®æ–‡ä»¶ï¼šINIæˆ–JSON
è·¨å¹³å°ï¼šJSONæˆ–XML
```

---

## 8. ğŸ† åºåˆ—åŒ–æœ€ä½³å®è·µæŒ‡å—


### 8.1 æ€§èƒ½ä¼˜åŒ–ç­–ç•¥


**âš¡ é€‰æ‹©åˆé€‚çš„å·¥å…·**ï¼š
```python
import time
import json
import pickle
import marshal

def performance_comparison():
    """æ€§èƒ½å¯¹æ¯”æµ‹è¯•"""
    # æµ‹è¯•æ•°æ®
    test_data = {
        'numbers': list(range(10000)),
        'text': 'æµ‹è¯•æ–‡æœ¬' * 1000,
        'nested': {'a': [1, 2, 3] * 100, 'b': {'c': 'value'}}
    }
    
    # æµ‹è¯•åºåˆ—åŒ–æ€§èƒ½
    print("ğŸ“Š åºåˆ—åŒ–æ€§èƒ½å¯¹æ¯”:")
    
    # JSON
    start = time.time()
    json_data = json.dumps(test_data)
    json_time = time.time() - start
    print(f"JSON: {json_time:.4f}ç§’, å¤§å°: {len(json_data)} å­—èŠ‚")
    
    # Pickle
    start = time.time()
    pickle_data = pickle.dumps(test_data)
    pickle_time = time.time() - start
    print(f"Pickle: {pickle_time:.4f}ç§’, å¤§å°: {len(pickle_data)} å­—èŠ‚")
    
    # Marshalï¼ˆåªæµ‹è¯•æ”¯æŒçš„æ•°æ®ï¼‰
    marshal_data = {'numbers': list(range(10000))}
    start = time.time()
    marshal_bytes = marshal.dumps(marshal_data)
    marshal_time = time.time() - start
    print(f"Marshal: {marshal_time:.4f}ç§’, å¤§å°: {len(marshal_bytes)} å­—èŠ‚")

performance_comparison()
```

**ğŸ”§ ä¼˜åŒ–æŠ€å·§**ï¼š
```python
import json
import gzip

class OptimizedSerializer:
    """ä¼˜åŒ–çš„åºåˆ—åŒ–å™¨"""
    
    @staticmethod
    def smart_serialize(data, use_compression=True, compression_threshold=1024):
        """æ™ºèƒ½åºåˆ—åŒ–ï¼šæ ¹æ®å¤§å°å†³å®šæ˜¯å¦å‹ç¼©"""
        # å…ˆåºåˆ—åŒ–
        json_data = json.dumps(data, ensure_ascii=False, separators=(',', ':')).encode('utf-8')
        
        # åˆ¤æ–­æ˜¯å¦éœ€è¦å‹ç¼©
        if use_compression and len(json_data) > compression_threshold:
            compressed = gzip.compress(json_data)
            return {
                'data': compressed,
                'compressed': True,
                'original_size': len(json_data),
                'compressed_size': len(compressed)
            }
        else:
            return {
                'data': json_data,
                'compressed': False,
                'size': len(json_data)
            }
    
    @staticmethod
    def smart_deserialize(serialized_info):
        """æ™ºèƒ½ååºåˆ—åŒ–"""
        if serialized_info['compressed']:
            json_data = gzip.decompress(serialized_info['data'])
        else:
            json_data = serialized_info['data']
        
        return json.loads(json_data.decode('utf-8'))

# ä½¿ç”¨ç¤ºä¾‹
optimizer = OptimizedSerializer()
large_data = {'data': list(range(5000)), 'text': 'é‡å¤å†…å®¹' * 200}

serialized = optimizer.smart_serialize(large_data)
print(f"åºåˆ—åŒ–ç»“æœ: {serialized}")

recovered = optimizer.smart_deserialize(serialized)
print(f"æ•°æ®æ¢å¤: é•¿åº¦ {len(recovered['data'])}")
```

### 8.2 å®‰å…¨æ€§è€ƒè™‘


**ğŸ”’ å®‰å…¨åºåˆ—åŒ–å®è·µ**ï¼š
```python
import json
import hmac
import hashlib
import secrets

class SecureSerializer:
    """å®‰å…¨çš„åºåˆ—åŒ–å™¨"""
    
    def __init__(self, secret_key=None):
        self.secret_key = secret_key or secrets.token_bytes(32)
    
    def secure_serialize(self, data):
        """å®‰å…¨åºåˆ—åŒ–ï¼šæ·»åŠ ç­¾åé˜²ç¯¡æ”¹"""
        # åºåˆ—åŒ–æ•°æ®
        json_data = json.dumps(data, ensure_ascii=False, sort_keys=True)
        
        # è®¡ç®—ç­¾å
        signature = hmac.new(
            self.secret_key,
            json_data.encode('utf-8'),
            hashlib.sha256
        ).hexdigest()
        
        # è¿”å›æ•°æ®å’Œç­¾å
        return {
            'data': json_data,
            'signature': signature
        }
    
    def secure_deserialize(self, secured_data):
        """å®‰å…¨ååºåˆ—åŒ–ï¼šéªŒè¯ç­¾å"""
        # éªŒè¯ç­¾å
        expected_signature = hmac.new(
            self.secret_key,
            secured_data['data'].encode('utf-8'),
            hashlib.sha256
        ).hexdigest()
        
        if not hmac.compare_digest(secured_data['signature'], expected_signature):
            raise ValueError("æ•°æ®ç­¾åéªŒè¯å¤±è´¥ï¼Œå¯èƒ½è¢«ç¯¡æ”¹")
        
        # ååºåˆ—åŒ–æ•°æ®
        return json.loads(secured_data['data'])

# ä½¿ç”¨ç¤ºä¾‹
secure_serializer = SecureSerializer()

original_data = {'user': 'admin', 'permissions': ['read', 'write'], 'token': 'abc123'}

# å®‰å…¨åºåˆ—åŒ–
secured = secure_serializer.secure_serialize(original_data)
print(f"å®‰å…¨åºåˆ—åŒ–å®Œæˆï¼Œç­¾å: {secured['signature'][:16]}...")

# å®‰å…¨ååºåˆ—åŒ–
try:
    recovered = secure_serializer.secure_deserialize(secured)
    print("âœ… æ•°æ®éªŒè¯é€šè¿‡ï¼Œååºåˆ—åŒ–æˆåŠŸ")
except ValueError as e:
    print(f"âŒ {e}")

# æ¨¡æ‹Ÿæ•°æ®è¢«ç¯¡æ”¹
secured['data'] = secured['data'].replace('admin', 'hacker')
try:
    recovered = secure_serializer.secure_deserialize(secured)
except ValueError as e:
    print(f"ğŸ›¡ï¸ æ£€æµ‹åˆ°ç¯¡æ”¹: {e}")
```

### 8.3 è·¨å¹³å°å…¼å®¹æ€§


**ğŸŒ å…¼å®¹æ€§å¤„ç†**ï¼š
```python
import json
import sys
from datetime import datetime, date
import decimal

class CompatibleSerializer:
    """è·¨å¹³å°å…¼å®¹çš„åºåˆ—åŒ–å™¨"""
    
    @staticmethod
    def serialize_with_types(obj):
        """ä¿ç•™ç±»å‹ä¿¡æ¯çš„åºåˆ—åŒ–"""
        def convert_obj(o):
            if isinstance(o, datetime):
                return {'__type__': 'datetime', 'value': o.isoformat()}
            elif isinstance(o, date):
                return {'__type__': 'date', 'value': o.isoformat()}
            elif isinstance(o, decimal.Decimal):
                return {'__type__': 'decimal', 'value': str(o)}
            elif isinstance(o, set):
                return {'__type__': 'set', 'value': list(o)}
            elif isinstance(o, bytes):
                return {'__type__': 'bytes', 'value': o.hex()}
            elif isinstance(o, complex):
                return {'__type__': 'complex', 'real': o.real, 'imag': o.imag}
            else:
                return o
        
        return json.dumps(obj, default=convert_obj, ensure_ascii=False, indent=2)
    
    @staticmethod
    def deserialize_with_types(json_str):
        """è¿˜åŸç±»å‹ä¿¡æ¯çš„ååºåˆ—åŒ–"""
        def restore_obj(obj):
            if isinstance(obj, dict) and '__type__' in obj:
                type_name = obj['__type__']
                if type_name == 'datetime':
                    return datetime.fromisoformat(obj['value'])
                elif type_name == 'date':
                    return date.fromisoformat(obj['value'])
                elif type_name == 'decimal':
                    return decimal.Decimal(obj['value'])
                elif type_name == 'set':
                    return set(obj['value'])
                elif type_name == 'bytes':
                    return bytes.fromhex(obj['value'])
                elif type_name == 'complex':
                    return complex(obj['real'], obj['imag'])
            
            return obj
        
        # é€’å½’å¤„ç†åµŒå¥—å¯¹è±¡
        def recursive_restore(obj):
            if isinstance(obj, dict):
                restored = restore_obj(obj)
                if restored is obj:  # æ²¡æœ‰è¢«è¿˜åŸï¼Œé€’å½’å¤„ç†å€¼
                    return {k: recursive_restore(v) for k, v in obj.items()}
                return restored
            elif isinstance(obj, list):
                return [recursive_restore(item) for item in obj]
            else:
                return obj
        
        data = json.loads(json_str)
        return recursive_restore(data)

# ä½¿ç”¨ç¤ºä¾‹
def compatibility_demo():
    """å…¼å®¹æ€§æ¼”ç¤º"""
    import decimal
    from datetime import datetime, date
    
    # åŒ…å«å„ç§Pythonç±»å‹çš„æ•°æ®
    complex_data = {
        'string': 'æ–‡æœ¬æ•°æ®',
        'number': 42,
        'float': 3.14,
        'boolean': True,
        'null': None,
        'list': [1, 2, 3],
        'datetime': datetime.now(),
        'date': date.today(),
        'decimal': decimal.Decimal('19.99'),
        'set': {1, 2, 3, 4},
        'bytes': b'binary data',
        'complex': 3 + 4j,
        'nested': {
            'inner_datetime': datetime(2023, 1, 1, 12, 0, 0),
            'inner_set': {'a', 'b', 'c'}
        }
    }
    
    # åºåˆ—åŒ–
    serialized = CompatibleSerializer.serialize_with_types(complex_data)
    print("ğŸ”„ åºåˆ—åŒ–å®Œæˆï¼ˆä¿ç•™ç±»å‹ä¿¡æ¯ï¼‰")
    
    # ååºåˆ—åŒ–
    restored = CompatibleSerializer.deserialize_with_types(serialized)
    
    # éªŒè¯ç±»å‹
    print("\nğŸ“‹ ç±»å‹éªŒè¯:")
    print(f"datetimeç±»å‹: {type(restored['datetime'])}")
    print(f"setç±»å‹: {type(restored['set'])}")
    print(f"decimalç±»å‹: {type(restored['decimal'])}")
    print(f"complexç±»å‹: {type(restored['complex'])}")
    
    # éªŒè¯å€¼
    print(f"\nâœ… æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥:")
    print(f"æ—¥æœŸæ—¶é—´: {restored['datetime']}")
    print(f"é›†åˆ: {restored['set']}")
    print(f"å°æ•°: {restored['decimal']}")

compatibility_demo()
```

### 8.4 é”™è¯¯å¤„ç†ä¸æ¢å¤


**ğŸ› ï¸ å¥å£®çš„åºåˆ—åŒ–å¤„ç†**ï¼š
```python
import json
import logging
from typing import Any, Optional

class RobustSerializer:
    """å¥å£®çš„åºåˆ—åŒ–å™¨"""
    
    def __init__(self, logger=None):
        self.logger = logger or logging.getLogger(__name__)
    
    def safe_serialize(self, data: Any, fallback_format='json') -> Optional[str]:
        """å®‰å…¨åºåˆ—åŒ–ï¼Œæ”¯æŒå›é€€æœºåˆ¶"""
        try:
            # é¦–å…ˆå°è¯•JSONåºåˆ—åŒ–
            return json.dumps(data, ensure_ascii=False, default=str)
        
        except TypeError as e:
            self.logger.warning(f"JSONåºåˆ—åŒ–å¤±è´¥: {e}")
            
            # å›é€€åˆ°pickleï¼ˆå¦‚æœå…è®¸ï¼‰
            if fallback_format == 'pickle':
                try:
                    import pickle
                    import base64
                    pickled = pickle.dumps(data)
                    return base64.b64encode(pickled).decode('ascii')
                except Exception as e2:
                    self.logger.error(f"Pickleåºåˆ—åŒ–ä¹Ÿå¤±è´¥: {e2}")
            
            # æœ€åå›é€€ï¼šè½¬æ¢ä¸ºå­—ç¬¦ä¸²
            try:
                return json.dumps(str(data), ensure_ascii=False)
            except Exception as e3:
                self.logger.error(f"å­—ç¬¦ä¸²åºåˆ—åŒ–å¤±è´¥: {e3}")
                return None
    
    def safe_deserialize(self, data: str, expected_format='json') -> Optional[Any]:
        """å®‰å…¨ååºåˆ—åŒ–"""
        if not data:
            return None
        
        try:
            # å°è¯•JSONååºåˆ—åŒ–
            if expected_format == 'json':
                return json.loads(data)
            
            # å°è¯•pickleååºåˆ—åŒ–
            elif expected_format == 'pickle':
                import pickle
                import base64
                decoded = base64.b64decode(data.encode('ascii'))
                return pickle.loads(decoded)
        
        except json.JSONDecodeError as e:
            self.logger.warning(f"JSONè§£æå¤±è´¥: {e}")
        except Exception as e:
            self.logger.error(f"ååºåˆ—åŒ–å¤±è´¥: {e}")
        
        return None
    
    def validate_data_integrity(self, original: Any, serialized: str) -> bool:
        """éªŒè¯æ•°æ®å®Œæ•´æ€§"""
        try:
            restored = self.safe_deserialize(serialized)
            return original == restored
        except Exception:
            return False

# ä½¿ç”¨ç¤ºä¾‹
def robustness_demo():
    """å¥å£®æ€§æ¼”ç¤º"""
    serializer = RobustSerializer()
    
    # æµ‹è¯•å„ç§æ•°æ®
    test_cases = [
        "ç®€å•å­—ç¬¦ä¸²",
        {"dict": "å­—å…¸æ•°æ®"},
        [1, 2, 3, "åˆ—è¡¨"],
        42,
        None,
        # ä¸€ä¸ªåŒ…å«ä¸å¯åºåˆ—åŒ–å¯¹è±¡çš„å¤æ‚æ•°æ®
        {"function": len, "normal": "æ­£å¸¸æ•°æ®"}
    ]
    
    for i, data in enumerate(test_cases):
        print(f"\nğŸ§ª æµ‹è¯•ç”¨ä¾‹ {i+1}: {type(data).__name__}")
        
        # åºåˆ—åŒ–
        serialized = serializer.safe_serialize(data)
        if serialized:
            print(f"âœ… åºåˆ—åŒ–æˆåŠŸ")
            
            # ååºåˆ—åŒ–
            restored = serializer.safe_deserialize(serialized)
            if restored is not None:
                print(f"âœ… ååºåˆ—åŒ–æˆåŠŸ")
                
                # éªŒè¯å®Œæ•´æ€§
                if serializer.validate_data_integrity(data, serialized):
                    print(f"âœ… æ•°æ®å®Œæ•´æ€§éªŒè¯é€šè¿‡")
                else:
                    print(f"âš ï¸ æ•°æ®å¯èƒ½æœ‰å˜åŒ–ï¼ˆå¦‚å‡½æ•°å¯¹è±¡è½¬ä¸ºå­—ç¬¦ä¸²ï¼‰")
            else:
                print(f"âŒ ååºåˆ—åŒ–å¤±è´¥")
        else:
            print(f"âŒ åºåˆ—åŒ–å¤±è´¥")

robustness_demo()
```

### 8.5 ç›‘æ§ä¸è°ƒè¯•


**ğŸ“Š åºåˆ—åŒ–ç›‘æ§å·¥å…·**ï¼š
```python
import time
import json
import functools
from collections import defaultdict

class SerializationMonitor:
    """åºåˆ—åŒ–æ€§èƒ½ç›‘æ§å™¨"""
    
    def __init__(self):
        self.stats = defaultdict(list)
        self.total_calls = 0
    
    def monitor_serialize(self, func):
        """è£…é¥°å™¨ï¼šç›‘æ§åºåˆ—åŒ–å‡½æ•°"""
        @functools.wraps(func)
        def wrapper(data, *args, **kwargs):
            start_time = time.time()
            
            try:
                result = func(data, *args, **kwargs)
                success = True
                error = None
            except Exception as e:
                result = None
                success = False
                error = str(e)
            
            end_time = time.time()
            duration = end_time - start_time
            
            # è®°å½•ç»Ÿè®¡ä¿¡æ¯
            self.stats[func.__name__].append({
                'duration': duration,
                'success': success,
                'error': error,
                'data_size': len(str(data)) if data else 0,
                'result_size': len(result) if result else 0,
                'timestamp': start_time
            })
            
            self.total_calls += 1
            
            if not success:
                print(f"âš ï¸ {func.__name__} æ‰§è¡Œå¤±è´¥: {error}")
            
            return result
        
        return wrapper
    
    def get_performance_report(self):
        """è·å–æ€§èƒ½æŠ¥å‘Š"""
        report = {"æ€»è°ƒç”¨æ¬¡æ•°": self.total_calls, "å‡½æ•°ç»Ÿè®¡": {}}
        
        for func_name, calls in self.stats.items():
            successful_calls = [c for c in calls if c['success']]
            failed_calls = [c for c in calls if not c['success']]
            
            if successful_calls:
                durations = [c['duration'] for c in successful_calls]
                avg_duration = sum(durations) / len(durations)
                max_duration = max(durations)
                min_duration = min(durations)
            else:
                avg_duration = max_duration = min_duration = 0
            
            report["å‡½æ•°ç»Ÿè®¡"][func_name] = {
                "æ€»è°ƒç”¨": len(calls),
                "æˆåŠŸæ¬¡æ•°": len(successful_calls),
                "å¤±è´¥æ¬¡æ•°": len(failed_calls),
                "å¹³å‡è€—æ—¶": f"{avg_duration:.4f}ç§’",
                "æœ€å¤§è€—æ—¶": f"{max_duration:.4f}ç§’",
                "æœ€å°è€—æ—¶": f"{min_duration:.4f}ç§’",
                "æˆåŠŸç‡": f"{len(successful_calls)/len(calls)*100:.1f}%" if calls else "0%"
            }
        
        return report

# ä½¿ç”¨ç¤ºä¾‹
monitor = SerializationMonitor()

@monitor.monitor_serialize
def monitored_json_dumps(data):
    """è¢«ç›‘æ§çš„JSONåºåˆ—åŒ–"""
    return json.dumps(data, ensure_ascii=False)

@monitor.monitor_serialize
def monitored_json_loads(data):
    """è¢«ç›‘æ§çš„JSONååºåˆ—åŒ–"""
    return json.loads(data)

# æµ‹è¯•ç›‘æ§
def monitoring_demo():
    """ç›‘æ§æ¼”ç¤º"""
    # æ‰§è¡Œä¸€äº›åºåˆ—åŒ–æ“ä½œ
    test_data = [
        {"small": "data"},
        {"large": list(range(1000))},
        "simple string",
        None
    ]
    
    for data in test_data:
        # åºåˆ—åŒ–
        serialized = monitored_json_dumps(data)
        
        if serialized:
            # ååºåˆ—åŒ–
            monitored_json_loads(serialized)
    
    # æµ‹è¯•é”™è¯¯æƒ…å†µ
    try:
        monitored_json_loads("invalid json")
    except:
        pass
    
    # è·å–æ€§èƒ½æŠ¥å‘Š
    report = monitor.get_performance_report()
    print("\nğŸ“Š æ€§èƒ½ç›‘æ§æŠ¥å‘Š:")
    for key, value in report.items():
        if key == "å‡½æ•°ç»Ÿè®¡":
            for func_name, stats in value.items():
                print(f"\nğŸ”§ {func_name}:")
                for stat_name, stat_value in stats.items():
                    print(f"  {stat_name}: {stat_value}")
        else:
            print(f"{key}: {value}")

monitoring_demo()
```

---

## 9. ğŸ“‹ æ ¸å¿ƒè¦ç‚¹æ€»ç»“


### 9.1 å¿…é¡»æŒæ¡çš„æ ¸å¿ƒæ¦‚å¿µ


```
ğŸ”¸ marshalï¼šPythonå†…éƒ¨é«˜é€Ÿåºåˆ—åŒ–ï¼Œä»…æ”¯æŒåŸºæœ¬ç±»å‹
ğŸ”¸ shelveï¼šæŒä¹…åŒ–å­—å…¸ï¼Œä½¿ç”¨ç®€å•ï¼Œé€‚åˆå°å‹æ•°æ®å­˜å‚¨
ğŸ”¸ configparserï¼šINIé…ç½®æ–‡ä»¶å¤„ç†ï¼Œä¼ä¸šåº”ç”¨å¸¸ç”¨
ğŸ”¸ base64ï¼šäºŒè¿›åˆ¶æ•°æ®æ–‡æœ¬ç¼–ç ï¼Œç½‘ç»œä¼ è¾“å¿…å¤‡
ğŸ”¸ zlibï¼šæ•°æ®å‹ç¼©æŠ€æœ¯ï¼ŒèŠ‚çœå­˜å‚¨å’Œä¼ è¾“å¸¦å®½
ğŸ”¸ hashlibï¼šå“ˆå¸Œç®—æ³•å·¥å…·ï¼Œæ•°æ®å®Œæ•´æ€§å’Œå®‰å…¨éªŒè¯
```

### 9.2 å…³é”®ç†è§£è¦ç‚¹


**ğŸ”¹ ä¸åŒåºåˆ—åŒ–æ–¹å¼çš„é€‰æ‹©**ï¼š
```
é€Ÿåº¦ä¼˜å…ˆ â†’ marshalï¼ˆä»…Pythonå†…éƒ¨ï¼‰
é€šç”¨æ€§ä¼˜å…ˆ â†’ pickleï¼ˆPythonå¯¹è±¡ï¼‰
è·¨è¯­è¨€ â†’ JSON/XML
å¤§æ•°æ® â†’ è€ƒè™‘å‹ç¼©ï¼ˆzlibï¼‰
å®‰å…¨æ•æ„Ÿ â†’ åŠ å“ˆå¸ŒéªŒè¯ï¼ˆhashlibï¼‰
```

**ğŸ”¹ å®é™…åº”ç”¨çš„æƒè¡¡**ï¼š
```
æ€§èƒ½ vs å…¼å®¹æ€§ï¼šmarshalå¿«ä½†é™åˆ¶å¤šï¼ŒJSONæ…¢ä½†é€šç”¨
å®‰å…¨ vs ä¾¿åˆ©ï¼šbase64ç¼–ç éåŠ å¯†ï¼Œéœ€è¦é¢å¤–å®‰å…¨æªæ–½
ç©ºé—´ vs æ—¶é—´ï¼šå‹ç¼©èŠ‚çœç©ºé—´ä½†å¢åŠ CPUå¼€é”€
åŠŸèƒ½ vs å¤æ‚åº¦ï¼šshelveç®€å•ä½†åŠŸèƒ½æœ‰é™
```

### 9.3 å®é™…åº”ç”¨ä»·å€¼


**ğŸ’¼ å…¸å‹åº”ç”¨åœºæ™¯**ï¼š

| åœºæ™¯ | æ¨èæŠ€æœ¯ | ç†ç”± |
|------|----------|------|
| ğŸ”§ **é…ç½®ç®¡ç†** | configparser + JSON | æ˜“è¯»æ˜“å†™ï¼Œæ”¯æŒå±‚æ¬¡ç»“æ„ |
| ğŸ“Š **æ•°æ®ç¼“å­˜** | pickle + zlib | å®Œæ•´ä¿å­˜Pythonå¯¹è±¡ä¸”å‹ç¼© |
| ğŸŒ **Web API** | JSON + base64 | è·¨è¯­è¨€ï¼Œæ”¯æŒäºŒè¿›åˆ¶æ•°æ® |
| ğŸ”’ **å®‰å…¨å­˜å‚¨** | pickle + hashlib | æ•°æ®å®Œæ•´æ€§éªŒè¯ |
| âš¡ **é«˜æ€§èƒ½åœºæ™¯** | marshal | æé€Ÿåºåˆ—åŒ–PythonåŸºæœ¬ç±»å‹ |
| ğŸ’¾ **å°å‹æ•°æ®åº“** | shelve | ç±»å­—å…¸æ¥å£ï¼Œè‡ªåŠ¨æŒä¹…åŒ– |

**ğŸ¯ æœ€ä½³å®è·µåŸåˆ™**ï¼š
- **é€‰æ‹©åˆé€‚å·¥å…·**ï¼šæ ¹æ®æ•°æ®ç±»å‹ã€æ€§èƒ½è¦æ±‚ã€å®‰å…¨éœ€æ±‚é€‰æ‹©
- **è€ƒè™‘å…¼å®¹æ€§**ï¼šè·¨å¹³å°åº”ç”¨ä¼˜å…ˆè€ƒè™‘JSONã€XMLç­‰æ ‡å‡†æ ¼å¼
- **å®‰å…¨ç¬¬ä¸€**ï¼šæ•æ„Ÿæ•°æ®å¿…é¡»åŠ å¯†ï¼Œä¼ è¾“æ•°æ®è¦éªŒè¯å®Œæ•´æ€§
- **æ€§èƒ½ä¼˜åŒ–**ï¼šå¤§æ•°æ®è€ƒè™‘å‹ç¼©ï¼Œé«˜é¢‘æ“ä½œè€ƒè™‘ç¼“å­˜
- **é”™è¯¯å¤„ç†**ï¼šåºåˆ—åŒ–æ“ä½œè¦æœ‰å®Œå–„çš„å¼‚å¸¸å¤„ç†æœºåˆ¶
- **ç›‘æ§è°ƒè¯•**ï¼šç”Ÿäº§ç¯å¢ƒè¦ç›‘æ§åºåˆ—åŒ–æ€§èƒ½å’Œé”™è¯¯ç‡

**ğŸ§  è®°å¿†è¦ç‚¹**ï¼š
```
marshalå¿«é€Ÿå†…éƒ¨ç”¨ï¼Œshelveå­—å…¸èƒ½æŒä¹…
é…ç½®æ–‡ä»¶ç”¨configparserï¼Œç½‘ç»œä¼ è¾“base64æŠ¤
æ•°æ®å‹ç¼©æ‰¾zlibï¼Œå“ˆå¸ŒéªŒè¯hashlibåŠ©
æ ¼å¼è½¬æ¢æœ‰æŠ€å·§ï¼Œå®‰å…¨æ€§èƒ½è¦å…¼é¡¾
é”™è¯¯å¤„ç†ä¸èƒ½å°‘ï¼Œç›‘æ§è°ƒè¯•æ˜¯å¸®æ‰‹
```

**æ ¸å¿ƒè®°å¿†**ï¼šPythonçš„é«˜çº§åºåˆ—åŒ–æŠ€æœ¯ä¸ºä¸åŒåœºæ™¯æä¾›äº†ä¸“é—¨çš„è§£å†³æ–¹æ¡ˆã€‚marshalè¿½æ±‚æè‡´é€Ÿåº¦ï¼Œshelveæä¾›æŒä¹…åŒ–ä¾¿åˆ©ï¼Œconfigparserç®€åŒ–é…ç½®ç®¡ç†ï¼Œbase64å®ç°å®‰å…¨ä¼ è¾“ï¼Œzlibä¼˜åŒ–å­˜å‚¨ç©ºé—´ï¼Œhashlibä¿éšœæ•°æ®å®‰å…¨ã€‚æŒæ¡è¿™äº›å·¥å…·çš„ç‰¹ç‚¹å’Œé€‚ç”¨åœºæ™¯ï¼Œèƒ½è®©æ•°æ®å¤„ç†æ›´é«˜æ•ˆã€æ›´å®‰å…¨ã€æ›´å¯é ã€‚