---
title: 4、特殊文件处理
---
## 📚 目录

1. [文本文件与二进制文件理解](#1-文本文件与二进制文件理解)
2. [字符编码处理](#2-字符编码处理)
3. [CSV文件操作](#3-CSV文件操作)
4. [JSON文件处理](#4-JSON文件处理)
5. [XML文件基础](#5-XML文件基础)
6. [配置文件读写](#6-配置文件读写)
7. [临时文件处理](#7-临时文件处理)
8. [大文件处理策略](#8-大文件处理策略)
9. [核心要点总结](#9-核心要点总结)

---

## 1. 📄 文本文件与二进制文件理解


### 1.1 什么是文本文件和二进制文件

🎯 **通俗理解**：就像书籍的两种读法

```
文本文件 = 普通书籍
- 人类可以直接阅读理解
- 内容是文字、数字、符号
- 例如：.txt、.py、.html、.csv

二进制文件 = 密码本
- 需要特定程序才能理解
- 内容是0和1的组合
- 例如：.jpg、.exe、.pdf、.mp3
```

**🔸 生活中的类比**
- **文本文件**：就像我们写的日记本，打开就能看懂
- **二进制文件**：就像DVD光盘，需要播放器才能播放

### 1.2 Python中的文件打开模式

**📋 文件模式对比表**

| 模式 | **用途** | **适用文件** | **特点** |
|------|---------|-------------|---------|
| `'r'` | 文本读取 | 文本文件 | 默认模式，按字符读取 |
| `'rb'` | 二进制读取 | 二进制文件 | 按字节读取 |
| `'w'` | 文本写入 | 文本文件 | 覆盖原内容 |
| `'wb'` | 二进制写入 | 二进制文件 | 覆盖原内容 |
| `'a'` | 文本追加 | 文本文件 | 在末尾添加内容 |

### 1.3 实际操作对比

**📝 文本文件操作**
```python
# 读取文本文件
with open('diary.txt', 'r', encoding='utf-8') as f:
    content = f.read()
    print(content)  # 直接显示文字内容

# 写入文本文件
with open('note.txt', 'w', encoding='utf-8') as f:
    f.write('今天学习了Python文件操作')
```

**🖼️ 二进制文件操作**
```python
# 复制图片文件（二进制）
with open('original.jpg', 'rb') as source:
    with open('copy.jpg', 'wb') as target:
        target.write(source.read())

# 注意：如果用文本模式打开图片，会出现乱码
```

### 1.4 如何判断文件类型

**🔍 简单判断方法**
```python
def is_text_file(filename):
    """简单判断是否为文本文件"""
    text_extensions = ['.txt', '.py', '.html', '.css', '.js', '.csv']
    return any(filename.endswith(ext) for ext in text_extensions)

# 使用示例
print(is_text_file('data.csv'))    # True
print(is_text_file('photo.jpg'))   # False
```

---

## 2. 🔤 字符编码处理


### 2.1 什么是字符编码

🎯 **生活类比**：编码就像翻译规则

```
想象你在国外旅行：
英文 → 国际通用语言（ASCII）
中文 → 需要特殊翻译（UTF-8）
韩文 → 需要另一种翻译（UTF-8）

计算机世界：
英文字符 → ASCII编码就够用
中文字符 → 需要UTF-8编码
不同国家 → 有不同的编码标准
```

### 2.2 常见编码问题与解决

**🚨 编码错误的常见场景**

| 问题现象 | **可能原因** | **解决方案** |
|---------|-------------|-------------|
| 乱码显示 | 编码不匹配 | 指定正确的encoding |
| UnicodeDecodeError | 编码解析失败 | 尝试不同编码或使用errors参数 |
| 文件无法保存中文 | 默认编码不支持 | 使用UTF-8编码 |

**💡 实用解决方案**
```python
# 处理编码问题的万能方法
def safe_read_file(filename):
    """安全读取可能有编码问题的文件"""
    encodings = ['utf-8', 'gbk', 'gb2312', 'utf-16']
    
    for encoding in encodings:
        try:
            with open(filename, 'r', encoding=encoding) as f:
                return f.read()
        except UnicodeDecodeError:
            continue
    
    # 如果都失败，用忽略错误的方式读取
    with open(filename, 'r', encoding='utf-8', errors='ignore') as f:
        return f.read()

# 使用示例
content = safe_read_file('可能有编码问题的文件.txt')
```

### 2.3 中文处理最佳实践

**📝 处理中文文件的标准做法**
```python
# 推荐做法：始终指定UTF-8编码
with open('中文文件.txt', 'w', encoding='utf-8') as f:
    f.write('你好，世界！Python很有趣。')

with open('中文文件.txt', 'r', encoding='utf-8') as f:
    content = f.read()
    print(content)
```

**⚠️ 编码检测工具**
```python
# 安装：pip install chardet
import chardet

def detect_encoding(filename):
    """自动检测文件编码"""
    with open(filename, 'rb') as f:
        raw_data = f.read()
        result = chardet.detect(raw_data)
        return result['encoding']

# 使用示例
encoding = detect_encoding('unknown_encoding.txt')
print(f"检测到的编码：{encoding}")
```

---

## 3. 📊 CSV文件操作


### 3.1 什么是CSV文件

🎯 **简单理解**：CSV就像Excel的简化版

```
CSV = Comma Separated Values（逗号分隔值）

想象成一个简单的表格：
姓名,年龄,城市
张三,25,北京
李四,30,上海
王五,28,广州

特点：
- 用逗号分隔不同列
- 每行代表一条记录
- 第一行通常是标题
```

### 3.2 CSV基础操作

**📖 读取CSV文件**
```python
import csv

# 方法1：基础读取
with open('students.csv', 'r', encoding='utf-8') as f:
    reader = csv.reader(f)
    for row in reader:
        print(row)  # 每行是一个列表

# 方法2：字典形式读取（推荐）
with open('students.csv', 'r', encoding='utf-8') as f:
    reader = csv.DictReader(f)
    for row in reader:
        print(f"姓名：{row['姓名']}, 年龄：{row['年龄']}")
```

**✏️ 写入CSV文件**
```python
# 写入学生信息
students = [
    ['张三', 25, '北京'],
    ['李四', 30, '上海'],
    ['王五', 28, '广州']
]

with open('new_students.csv', 'w', newline='', encoding='utf-8') as f:
    writer = csv.writer(f)
    writer.writerow(['姓名', '年龄', '城市'])  # 写入标题
    writer.writerows(students)  # 写入所有数据
```

### 3.3 实用CSV处理技巧

**🛠️ 处理复杂CSV数据**
```python
def analyze_csv(filename):
    """分析CSV文件内容"""
    with open(filename, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        
        total_count = 0
        age_sum = 0
        
        for row in reader:
            total_count += 1
            age_sum += int(row['年龄'])
        
        average_age = age_sum / total_count if total_count > 0 else 0
        
        print(f"总人数：{total_count}")
        print(f"平均年龄：{average_age:.1f}岁")

# 处理包含中文逗号的数据
def handle_chinese_csv():
    """处理包含中文标点的CSV"""
    data = [
        ['产品名称', '价格', '描述'],
        ['苹果手机', '5999', '性能强劲，外观精美'],
        ['笔记本电脑', '8999', '轻薄便携，续航持久']
    ]
    
    with open('products.csv', 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f, quoting=csv.QUOTE_ALL)  # 所有字段加引号
        writer.writerows(data)
```

---

## 4. 📄 JSON文件处理


### 4.1 什么是JSON

🎯 **形象理解**：JSON就像有结构的购物清单

```
普通清单：
苹果
香蕉
牛奶

JSON格式清单：
{
    "水果": ["苹果", "香蕉"],
    "饮品": ["牛奶", "果汁"],
    "数量": {
        "苹果": 3,
        "牛奶": 2
    }
}

特点：
- 有层次结构
- 键值对形式
- 支持嵌套
- 人类和机器都容易理解
```

### 4.2 JSON基础操作

**📖 读取JSON文件**
```python
import json

# 读取JSON文件
with open('config.json', 'r', encoding='utf-8') as f:
    data = json.load(f)
    print(data['database']['host'])

# 从字符串解析JSON
json_string = '{"name": "张三", "age": 25}'
person = json.loads(json_string)
print(person['name'])
```

**✏️ 写入JSON文件**
```python
# 创建配置数据
config = {
    "database": {
        "host": "localhost",
        "port": 3306,
        "username": "admin"
    },
    "settings": {
        "debug": True,
        "language": "zh-CN"
    }
}

# 写入JSON文件
with open('app_config.json', 'w', encoding='utf-8') as f:
    json.dump(config, f, ensure_ascii=False, indent=2)
```

### 4.3 JSON实用技巧

**🎨 JSON格式化与美化**
```python
def pretty_print_json(data):
    """美化打印JSON数据"""
    print(json.dumps(data, ensure_ascii=False, indent=2))

# 处理复杂数据结构
student_data = {
    "班级": "计算机1班",
    "学生": [
        {"姓名": "张三", "成绩": {"数学": 95, "英语": 87}},
        {"姓名": "李四", "成绩": {"数学": 88, "英语": 92}}
    ]
}

pretty_print_json(student_data)
```

**🔧 JSON数据处理工具**
```python
def update_json_file(filename, updates):
    """更新JSON文件中的数据"""
    # 读取现有数据
    with open(filename, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # 更新数据
    data.update(updates)
    
    # 保存回文件
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

# 使用示例
updates = {"version": "2.0", "last_updated": "2024-01-11"}
update_json_file('app_config.json', updates)
```

---

## 5. 🏷️ XML文件基础


### 5.1 什么是XML

🎯 **形象比喻**：XML就像带标签的收纳盒

```
想象整理衣橱：
<衣橱>
  <上衣>
    <衬衫 颜色="白色">商务衬衫</衬衫>
    <T恤 颜色="蓝色">休闲T恤</T恤>
  </上衣>
  <裤子>
    <牛仔裤>经典款</牛仔裤>
  </裤子>
</衣橱>

特点：
- 用标签包围内容
- 可以有属性
- 层次分明
- 自描述性强
```

### 5.2 XML基础操作

**📖 读取XML文件**
```python
import xml.etree.ElementTree as ET

# 解析XML文件
tree = ET.parse('books.xml')
root = tree.getroot()

# 遍历所有书籍
for book in root.findall('book'):
    title = book.find('title').text
    author = book.find('author').text
    price = book.get('price')  # 获取属性
    print(f"《{title}》 - {author} - ¥{price}")
```

**✏️ 创建XML文件**
```python
# 创建图书馆XML
root = ET.Element("图书馆")

# 添加书籍信息
book1 = ET.SubElement(root, "书籍", price="39.8")
ET.SubElement(book1, "标题").text = "Python编程入门"
ET.SubElement(book1, "作者").text = "张三"
ET.SubElement(book1, "类别").text = "编程"

book2 = ET.SubElement(root, "书籍", price="45.0")
ET.SubElement(book2, "标题").text = "数据分析实战"
ET.SubElement(book2, "作者").text = "李四"

# 保存XML文件
tree = ET.ElementTree(root)
tree.write("library.xml", encoding="utf-8", xml_declaration=True)
```

### 5.3 XML实用技巧

**🔍 XML查找与修改**
```python
def search_books_by_author(xml_file, author_name):
    """根据作者查找书籍"""
    tree = ET.parse(xml_file)
    root = tree.getroot()
    
    found_books = []
    for book in root.findall('书籍'):
        author = book.find('作者').text
        if author == author_name:
            title = book.find('标题').text
            found_books.append(title)
    
    return found_books

# 使用示例
books = search_books_by_author('library.xml', '张三')
print(f"张三的著作：{books}")
```

---

## 6. ⚙️ 配置文件读写


### 6.1 什么是配置文件

🎯 **生活类比**：配置文件就像电器的设置菜单

```
就像空调遥控器的设置：
温度 = 26度
模式 = 制冷
风速 = 自动
定时 = 关闭

程序的配置文件：
[数据库设置]
主机 = localhost
端口 = 3306
用户名 = admin

[界面设置]
语言 = 中文
主题 = 深色模式
```

### 6.2 INI配置文件操作

**📝 使用ConfigParser处理INI文件**
```python
import configparser

# 创建配置文件
config = configparser.ConfigParser()

config['DATABASE'] = {
    'host': 'localhost',
    'port': '3306',
    'username': 'admin',
    'password': 'secret123'
}

config['UI'] = {
    'language': 'zh-CN',
    'theme': 'dark',
    'auto_save': 'true'
}

# 保存配置
with open('app.ini', 'w', encoding='utf-8') as f:
    config.write(f)

# 读取配置
config.read('app.ini', encoding='utf-8')
db_host = config['DATABASE']['host']
ui_theme = config['UI']['theme']
print(f"数据库主机：{db_host}")
print(f"界面主题：{ui_theme}")
```

### 6.3 配置文件管理工具

**🛠️ 实用配置管理器**
```python
class ConfigManager:
    """简单的配置管理器"""
    
    def __init__(self, config_file):
        self.config_file = config_file
        self.config = configparser.ConfigParser()
        self.load_config()
    
    def load_config(self):
        """加载配置文件"""
        try:
            self.config.read(self.config_file, encoding='utf-8')
        except FileNotFoundError:
            print(f"配置文件 {self.config_file} 不存在，将创建默认配置")
            self.create_default_config()
    
    def get(self, section, key, default=None):
        """获取配置值"""
        try:
            return self.config[section][key]
        except KeyError:
            return default
    
    def set(self, section, key, value):
        """设置配置值"""
        if section not in self.config:
            self.config[section] = {}
        self.config[section][key] = str(value)
        self.save_config()
    
    def save_config(self):
        """保存配置到文件"""
        with open(self.config_file, 'w', encoding='utf-8') as f:
            self.config.write(f)
    
    def create_default_config(self):
        """创建默认配置"""
        self.config['GENERAL'] = {
            'version': '1.0',
            'debug': 'false'
        }
        self.save_config()

# 使用示例
config_mgr = ConfigManager('my_app.ini')
config_mgr.set('DATABASE', 'host', 'localhost')
db_host = config_mgr.get('DATABASE', 'host', 'default_host')
```

---

## 7. 🗂️ 临时文件处理


### 7.1 为什么需要临时文件

🎯 **生活类比**：临时文件就像草稿纸

```
写作文时：
1. 先在草稿纸上写初稿
2. 修改完善后写到正式作业本
3. 草稿纸用完就扔掉

程序中的临时文件：
1. 处理大量数据时的中间结果
2. 下载文件的临时存储
3. 程序运行时的缓存数据
4. 用完就自动删除
```

### 7.2 tempfile模块详解

**📁 创建临时文件和目录**
```python
import tempfile
import os

# 创建临时文件
with tempfile.NamedTemporaryFile(mode='w+', delete=False, suffix='.txt') as temp_file:
    temp_file.write('这是临时文件的内容')
    temp_filename = temp_file.name
    print(f"临时文件位置：{temp_filename}")

# 使用完后手动删除
os.unlink(temp_filename)

# 创建临时目录
with tempfile.TemporaryDirectory() as temp_dir:
    print(f"临时目录：{temp_dir}")
    
    # 在临时目录中创建文件
    temp_file_path = os.path.join(temp_dir, 'data.txt')
    with open(temp_file_path, 'w') as f:
        f.write('临时数据')
    
    # 离开with语句时，整个目录会被自动删除
```

### 7.3 临时文件实用场景

**💡 实际应用示例**
```python
def process_large_file(input_file, output_file):
    """处理大文件，使用临时文件作为中间存储"""
    
    with tempfile.NamedTemporaryFile(mode='w+', encoding='utf-8') as temp_file:
        # 第一步：预处理数据
        with open(input_file, 'r', encoding='utf-8') as f:
            for line in f:
                processed_line = line.strip().upper()  # 简单处理
                temp_file.write(processed_line + '\n')
        
        # 第二步：从临时文件读取并最终处理
        temp_file.seek(0)  # 回到文件开头
        with open(output_file, 'w', encoding='utf-8') as output:
            for line in temp_file:
                final_line = f"处理完成：{line}"
                output.write(final_line)

def download_with_temp_file(url, target_file):
    """模拟下载文件，先保存到临时位置"""
    
    with tempfile.NamedTemporaryFile(delete=False) as temp_file:
        # 模拟下载过程
        temp_file.write(b"模拟下载的文件内容")
        temp_filename = temp_file.name
    
    try:
        # 下载完成后移动到目标位置
        os.rename(temp_filename, target_file)
        print(f"文件下载完成：{target_file}")
    except Exception as e:
        # 如果出错，清理临时文件
        if os.path.exists(temp_filename):
            os.unlink(temp_filename)
        print(f"下载失败：{e}")
```

---

## 8. 📈 大文件处理策略


### 8.1 为什么需要特殊处理大文件

🎯 **形象比喻**：大文件就像搬家

```
搬小物件：
- 一次拿完，简单直接
- 像普通文件，直接read()读取

搬大家具：
- 需要分块搬运
- 可能需要拆解再组装
- 像大文件，需要分块处理

如果强行一次性处理大文件：
- 内存不够用（OutOfMemoryError）
- 程序卡死
- 电脑变慢
```

### 8.2 逐行读取大文件

**📖 内存友好的文件读取**
```python
def process_large_text_file(filename):
    """逐行处理大文本文件"""
    line_count = 0
    total_chars = 0
    
    with open(filename, 'r', encoding='utf-8') as f:
        for line in f:  # 逐行读取，不会一次性加载整个文件
            line_count += 1
            total_chars += len(line)
            
            # 每处理1000行显示一次进度
            if line_count % 1000 == 0:
                print(f"已处理 {line_count} 行...")
    
    print(f"处理完成：总共 {line_count} 行，{total_chars} 个字符")

def find_in_large_file(filename, search_text):
    """在大文件中查找特定内容"""
    matches = []
    
    with open(filename, 'r', encoding='utf-8') as f:
        for line_num, line in enumerate(f, 1):
            if search_text in line:
                matches.append((line_num, line.strip()))
                
                # 找到前10个匹配就停止
                if len(matches) >= 10:
                    break
    
    return matches
```

### 8.3 分块处理大文件

**🔄 分块读取策略**
```python
def copy_large_file(source, target, chunk_size=1024*1024):  # 1MB块
    """分块复制大文件"""
    
    total_size = os.path.getsize(source)
    copied_size = 0
    
    with open(source, 'rb') as src, open(target, 'wb') as tgt:
        while True:
            chunk = src.read(chunk_size)
            if not chunk:
                break
            
            tgt.write(chunk)
            copied_size += len(chunk)
            
            # 显示进度
            progress = (copied_size / total_size) * 100
            print(f"\r复制进度: {progress:.1f}%", end='', flush=True)
    
    print(f"\n复制完成：{total_size} 字节")

def process_large_csv_by_chunks(filename, chunk_size=1000):
    """分块处理大CSV文件"""
    import pandas as pd
    
    # 分块读取CSV
    chunk_iter = pd.read_csv(filename, chunksize=chunk_size)
    
    total_rows = 0
    for chunk_num, chunk in enumerate(chunk_iter):
        print(f"处理第 {chunk_num + 1} 块数据，包含 {len(chunk)} 行")
        
        # 对每个块进行处理
        # 例如：数据清洗、统计分析等
        processed_chunk = chunk.dropna()  # 删除空值
        
        total_rows += len(processed_chunk)
        
        # 可以将处理结果保存到新文件
        output_filename = f'processed_chunk_{chunk_num}.csv'
        processed_chunk.to_csv(output_filename, index=False)
    
    print(f"总共处理了 {total_rows} 行数据")
```

### 8.4 大文件处理工具类

**🛠️ 通用大文件处理器**
```python
class LargeFileProcessor:
    """大文件处理工具类"""
    
    def __init__(self, chunk_size=1024*1024):  # 默认1MB
        self.chunk_size = chunk_size
    
    def get_file_info(self, filename):
        """获取文件基本信息"""
        size = os.path.getsize(filename)
        size_mb = size / (1024 * 1024)
        
        return {
            'filename': filename,
            'size_bytes': size,
            'size_mb': round(size_mb, 2),
            'is_large': size_mb > 100  # 超过100MB算大文件
        }
    
    def count_lines(self, filename):
        """快速统计文件行数"""
        line_count = 0
        
        with open(filename, 'rb') as f:
            while True:
                chunk = f.read(self.chunk_size)
                if not chunk:
                    break
                line_count += chunk.count(b'\n')
        
        return line_count
    
    def split_file(self, filename, lines_per_file=10000):
        """将大文件分割成小文件"""
        base_name = os.path.splitext(filename)[0]
        file_num = 1
        line_count = 0
        
        with open(filename, 'r', encoding='utf-8') as source:
            output_file = None
            
            for line in source:
                if line_count % lines_per_file == 0:
                    if output_file:
                        output_file.close()
                    
                    output_filename = f"{base_name}_part_{file_num}.txt"
                    output_file = open(output_filename, 'w', encoding='utf-8')
                    file_num += 1
                
                output_file.write(line)
                line_count += 1
            
            if output_file:
                output_file.close()
        
        print(f"文件分割完成，共生成 {file_num - 1} 个文件")

# 使用示例
processor = LargeFileProcessor()
file_info = processor.get_file_info('large_data.txt')

if file_info['is_large']:
    print(f"检测到大文件：{file_info['size_mb']} MB")
    processor.split_file('large_data.txt', lines_per_file=5000)
```

---

## 9. 📋 核心要点总结


### 9.1 必须掌握的核心概念


```
🔸 文件类型：文本文件可直接阅读，二进制文件需要特殊程序
🔸 字符编码：UTF-8是处理中文的最佳选择，注意编码一致性
🔸 CSV处理：表格数据的简单格式，适合数据交换
🔸 JSON处理：结构化数据的现代格式，易读易写
🔸 XML基础：标签式数据格式，适合配置和数据交换
🔸 配置文件：程序设置的外部化存储方式
🔸 临时文件：程序运行时的临时存储，用完自动清理
🔸 大文件策略：分块处理，避免内存溢出
```

### 9.2 关键理解要点


**🔹 选择合适的文件格式**
```
数据类型选择：
- 简单表格数据 → CSV格式
- 复杂结构数据 → JSON格式
- 配置信息 → INI或JSON格式
- 需要属性和层次 → XML格式

处理策略选择：
- 小文件（<100MB） → 直接读取
- 大文件（>100MB） → 分块处理
- 临时数据 → 使用tempfile模块
- 需要编码转换 → 明确指定encoding
```

**🔹 文件操作的最佳实践**
```
安全原则：
- 始终使用with语句确保文件正确关闭
- 明确指定字符编码，特别是处理中文
- 处理大文件时监控内存使用
- 重要操作前备份原文件

性能原则：
- 逐行读取代替一次性读取大文件
- 使用生成器处理大数据集
- 合理设置分块大小
- 及时清理临时文件
```

**🔹 错误处理和调试**
```
常见问题解决：
- 编码错误：尝试不同编码或使用检测工具
- 文件不存在：检查路径和权限
- 内存不足：改用分块处理
- 数据格式错误：增加数据验证

调试技巧：
- 先处理小样本数据
- 添加进度显示和日志
- 使用try-except捕获异常
- 分步骤验证处理结果
```

### 9.3 实际应用价值


**🎯 生活中的应用场景**
- **数据分析**：处理Excel导出的CSV文件进行统计分析
- **网站开发**：读写JSON配置文件，处理API数据
- **文档处理**：批量处理Word、PDF等文档的文本内容
- **系统管理**：解析日志文件，生成报告

**🔧 工作中的实用技能**
- **数据迁移**：不同系统间的数据格式转换
- **配置管理**：程序配置的外部化和版本控制
- **日志分析**：大型日志文件的分析和统计
- **文件处理**：批量文件操作和格式转换

**📈 进阶学习方向**
- **数据库操作**：将文件数据导入数据库
- **网络编程**：文件的上传下载功能
- **并发处理**：多线程/多进程文件处理
- **数据可视化**：将文件数据转换为图表

**🎓 学习建议**
```
循序渐进的学习路径：
1. 掌握基本文件读写操作
2. 理解不同文件格式的特点
3. 学会处理字符编码问题
4. 掌握大文件的处理技巧
5. 实践综合项目应用

动手练习项目：
- 制作个人通讯录管理程序（CSV）
- 创建程序配置管理工具（JSON/INI）
- 开发日志分析工具（大文件处理）
- 实现文件格式转换器（多格式支持）
```

**核心记忆口诀**：
- 文本二进制要分清，编码UTF-8最通用
- CSV表格JSON结构，XML标签配置灵
- 大文件分块来处理，临时文件用完清
- 实践练习多动手，文件操作变轻松