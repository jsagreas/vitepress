---
title: 5ã€è¿›ç¨‹åŒæ­¥ä¸å…±äº«
---
## ğŸ“š ç›®å½•

1. [è¿›ç¨‹åŒæ­¥æœºåˆ¶æ¦‚è¿°](#1-è¿›ç¨‹åŒæ­¥æœºåˆ¶æ¦‚è¿°)
2. [Lockè¿›ç¨‹é”](#2-Lockè¿›ç¨‹é”)
3. [Semaphoreè¿›ç¨‹ä¿¡å·é‡](#3-Semaphoreè¿›ç¨‹ä¿¡å·é‡)
4. [Eventè¿›ç¨‹äº‹ä»¶](#4-Eventè¿›ç¨‹äº‹ä»¶)
5. [å…±äº«å†…å­˜æŠ€æœ¯](#5-å…±äº«å†…å­˜æŠ€æœ¯)
6. [Valueå’ŒArrayå…±äº«å˜é‡](#6-Valueå’ŒArrayå…±äº«å˜é‡)
7. [è¿›ç¨‹é—´æ•°æ®äº¤æ¢](#7-è¿›ç¨‹é—´æ•°æ®äº¤æ¢)
8. [è¿›ç¨‹ç›‘æ§ä¸ç®¡ç†](#8-è¿›ç¨‹ç›‘æ§ä¸ç®¡ç†)
9. [è¿›ç¨‹ç¼–ç¨‹æœ€ä½³å®è·µ](#9-è¿›ç¨‹ç¼–ç¨‹æœ€ä½³å®è·µ)
10. [æ ¸å¿ƒè¦ç‚¹æ€»ç»“](#10-æ ¸å¿ƒè¦ç‚¹æ€»ç»“)

---

## 1. ğŸŒ è¿›ç¨‹åŒæ­¥æœºåˆ¶æ¦‚è¿°


### 1.1 ä»€ä¹ˆæ˜¯è¿›ç¨‹åŒæ­¥


**ğŸ’¡ é€šä¿—ç†è§£**ï¼š
æƒ³è±¡ä¸€ä¸ªå¨æˆ¿é‡Œæœ‰å¤šä¸ªå¨å¸ˆåŒæ—¶åšèœï¼Œå¦‚æœå¤§å®¶éƒ½éšæ„ä½¿ç”¨ç‚‰å­ã€é”…å…·ï¼Œå°±ä¼šå‘ç”Ÿå†²çªã€‚è¿›ç¨‹åŒæ­¥å°±åƒæ˜¯åˆ¶å®šå¨æˆ¿ä½¿ç”¨è§„åˆ™ï¼Œè®©å¤šä¸ªå¨å¸ˆï¼ˆè¿›ç¨‹ï¼‰åè°ƒå·¥ä½œï¼Œé¿å…å†²çªã€‚

**ğŸ” æŠ€æœ¯å®šä¹‰**ï¼š
```
è¿›ç¨‹åŒæ­¥ï¼šå¤šä¸ªè¿›ç¨‹æŒ‰ç…§ä¸€å®šçš„é¡ºåºæ‰§è¡Œï¼Œç¡®ä¿å…±äº«èµ„æºçš„æ­£ç¡®è®¿é—®
æ ¸å¿ƒé—®é¢˜ï¼šç«æ€æ¡ä»¶ï¼ˆRace Conditionï¼‰- å¤šä¸ªè¿›ç¨‹åŒæ—¶è®¿é—®å…±äº«èµ„æº
è§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨åŒæ­¥æœºåˆ¶æ§åˆ¶è¿›ç¨‹æ‰§è¡Œé¡ºåº
```

### 1.2 ä¸ºä»€ä¹ˆéœ€è¦è¿›ç¨‹åŒæ­¥


**ğŸ¯ å®é™…é—®é¢˜åœºæ™¯**ï¼š
```
é“¶è¡Œè½¬è´¦é—®é¢˜ï¼š
è¿›ç¨‹Aï¼šè¯»å–ä½™é¢1000 â†’ è½¬å‡º500 â†’ å†™å…¥ä½™é¢500
è¿›ç¨‹Bï¼šè¯»å–ä½™é¢1000 â†’ å­˜å…¥200 â†’ å†™å…¥ä½™é¢1200

æ²¡æœ‰åŒæ­¥ï¼šæœ€ç»ˆä½™é¢å¯èƒ½æ˜¯500æˆ–1200ï¼ˆé”™è¯¯ï¼ï¼‰
æœ‰åŒæ­¥æœºåˆ¶ï¼šæœ€ç»ˆä½™é¢æ­£ç¡®ä¸º700
```

**âš ï¸ å¸¸è§é—®é¢˜ç±»å‹**ï¼š
- **æ•°æ®ç«äº‰**ï¼šå¤šä¸ªè¿›ç¨‹åŒæ—¶ä¿®æ”¹æ•°æ®
- **æ­»é”**ï¼šè¿›ç¨‹ç›¸äº’ç­‰å¾…ï¼Œè°éƒ½æ— æ³•ç»§ç»­
- **é¥¥é¥¿**ï¼šæŸä¸ªè¿›ç¨‹ä¸€ç›´å¾—ä¸åˆ°èµ„æº
- **ä¼˜å…ˆçº§åè½¬**ï¼šä½ä¼˜å…ˆçº§è¿›ç¨‹é˜»å¡é«˜ä¼˜å…ˆçº§è¿›ç¨‹

### 1.3 Pythonå¤šè¿›ç¨‹åŒæ­¥å·¥å…·ç®±


```
ğŸ”§ åŒæ­¥å·¥å…·åˆ†ç±»ï¼š

äº’æ–¥ç±»ï¼š
â€¢ Lockï¼ˆé”ï¼‰- æœ€åŸºæœ¬çš„äº’æ–¥æœºåˆ¶
â€¢ RLockï¼ˆé€’å½’é”ï¼‰- å¯é‡å…¥é”

è®¡æ•°ç±»ï¼š
â€¢ Semaphoreï¼ˆä¿¡å·é‡ï¼‰- é™åˆ¶èµ„æºè®¿é—®æ•°é‡
â€¢ BoundedSemaphoreï¼ˆæœ‰ç•Œä¿¡å·é‡ï¼‰- é˜²æ­¢ä¿¡å·é‡è¿‡åº¦é‡Šæ”¾

äº‹ä»¶ç±»ï¼š
â€¢ Eventï¼ˆäº‹ä»¶ï¼‰- ç®€å•çš„è¿›ç¨‹é—´é€šçŸ¥æœºåˆ¶
â€¢ Conditionï¼ˆæ¡ä»¶å˜é‡ï¼‰- å¤æ‚æ¡ä»¶ç­‰å¾…

æ•°æ®å…±äº«ç±»ï¼š
â€¢ Value/Arrayï¼ˆå…±äº«å˜é‡ï¼‰- ç®€å•æ•°æ®å…±äº«
â€¢ shared_memoryï¼ˆå…±äº«å†…å­˜ï¼‰- å¤§æ•°æ®é‡å…±äº«
```

---

## 2. ğŸ”’ Lockè¿›ç¨‹é”


### 2.1 Lockçš„åŸºæœ¬æ¦‚å¿µ


**ğŸ”‘ ä»€ä¹ˆæ˜¯Lock**ï¼š
Lockå°±åƒä¸€æŠŠé’¥åŒ™ï¼ŒåŒä¸€æ—¶é—´åªèƒ½è¢«ä¸€ä¸ªè¿›ç¨‹æ‹¿åˆ°ã€‚æ‹¿åˆ°é’¥åŒ™çš„è¿›ç¨‹å¯ä»¥è¿›å…¥"å…³é”®åŒºåŸŸ"æ‰§è¡Œæ“ä½œï¼Œå…¶ä»–è¿›ç¨‹å¿…é¡»ç­‰å¾…ã€‚

**ğŸ“‹ Lockçš„çŠ¶æ€**ï¼š
```
ğŸŸ¢ æœªé”å®šï¼ˆunlockedï¼‰ï¼šå¯ä»¥è¢«ä»»ä½•è¿›ç¨‹è·å–
ğŸ”´ å·²é”å®šï¼ˆlockedï¼‰ï¼šå·²è¢«æŸä¸ªè¿›ç¨‹æŒæœ‰ï¼Œå…¶ä»–è¿›ç¨‹éœ€ç­‰å¾…
```

### 2.2 Lockçš„åŸºæœ¬ä½¿ç”¨


**ğŸ”§ åˆ›å»ºå’Œä½¿ç”¨Lock**ï¼š
```python
from multiprocessing import Process, Lock
import time

# åˆ›å»ºè¿›ç¨‹é”
lock = Lock()

def worker_with_lock(name, lock, shared_resource):
    """ä½¿ç”¨é”çš„å·¥ä½œè¿›ç¨‹"""
    for i in range(3):
        # è·å–é”
        lock.acquire()
        try:
            print(f"{name} å¼€å§‹å·¥ä½œ...")
            # æ¨¡æ‹Ÿè®¿é—®å…±äº«èµ„æº
            print(f"{name} æ­£åœ¨ä½¿ç”¨å…±äº«èµ„æº")
            time.sleep(1)  # æ¨¡æ‹Ÿå·¥ä½œæ—¶é—´
            print(f"{name} å·¥ä½œå®Œæˆ")
        finally:
            # é‡Šæ”¾é”ï¼ˆéå¸¸é‡è¦ï¼ï¼‰
            lock.release()
        
        time.sleep(0.5)  # ä¼‘æ¯ä¸€ä¸‹

# æ¨èçš„withè¯­å¥ä½¿ç”¨æ–¹å¼
def worker_with_context(name, lock):
    """ä½¿ç”¨withè¯­å¥çš„å·¥ä½œè¿›ç¨‹ï¼ˆæ¨èï¼‰"""
    for i in range(3):
        with lock:  # è‡ªåŠ¨è·å–å’Œé‡Šæ”¾é”
            print(f"{name} å¼€å§‹å·¥ä½œ...")
            time.sleep(1)
            print(f"{name} å·¥ä½œå®Œæˆ")
```

### 2.3 Lockè§£å†³ç«æ€æ¡ä»¶


**ğŸš¨ æ²¡æœ‰é”çš„é—®é¢˜ç¤ºä¾‹**ï¼š
```python
import multiprocessing
import time

# å…¨å±€è®¡æ•°å™¨ï¼ˆæ¨¡æ‹Ÿå…±äº«èµ„æºï¼‰
counter = 0

def increment_without_lock():
    """æ²¡æœ‰é”ä¿æŠ¤çš„è®¡æ•°å™¨é€’å¢"""
    global counter
    for _ in range(100000):
        # å±é™©ï¼å¤šä¸ªè¿›ç¨‹å¯èƒ½åŒæ—¶æ‰§è¡Œè¿™è¡Œä»£ç 
        counter += 1

# æµ‹è¯•æ— é”æƒ…å†µ
if __name__ == "__main__":
    processes = []
    for i in range(4):
        p = Process(target=increment_without_lock)
        processes.append(p)
        p.start()
    
    for p in processes:
        p.join()
    
    print(f"æœ€ç»ˆè®¡æ•°å™¨å€¼: {counter}")  # æœŸæœ›400000ï¼Œå®é™…å¯èƒ½å°äº
```

**âœ… ä½¿ç”¨é”çš„æ­£ç¡®ç¤ºä¾‹**ï¼š
```python
def increment_with_lock(lock, shared_value):
    """ä½¿ç”¨é”ä¿æŠ¤çš„è®¡æ•°å™¨é€’å¢"""
    for _ in range(100000):
        with lock:
            # å®‰å…¨ï¼åŒæ—¶åªæœ‰ä¸€ä¸ªè¿›ç¨‹èƒ½æ‰§è¡Œè¿™é‡Œ
            shared_value.value += 1

# ä½¿ç”¨Manageråˆ›å»ºå…±äº«å¯¹è±¡
from multiprocessing import Manager

if __name__ == "__main__":
    manager = Manager()
    shared_value = manager.Value('i', 0)  # å…±äº«æ•´æ•°
    lock = Lock()
    
    processes = []
    for i in range(4):
        p = Process(target=increment_with_lock, 
                   args=(lock, shared_value))
        processes.append(p)
        p.start()
    
    for p in processes:
        p.join()
    
    print(f"æœ€ç»ˆè®¡æ•°å™¨å€¼: {shared_value.value}")  # æ­£ç¡®ç»“æœ400000
```

### 2.4 Lockä½¿ç”¨çš„æ³¨æ„äº‹é¡¹


**âš ï¸ é‡è¦æé†’**ï¼š

> **æ­»é”é˜²èŒƒ**
> 
> ğŸ”´ **é”™è¯¯åšæ³•**ï¼šå¿˜è®°é‡Šæ”¾é”
> ```python
> lock.acquire()
> # å¦‚æœè¿™é‡Œå‘ç”Ÿå¼‚å¸¸ï¼Œé”æ°¸è¿œä¸ä¼šé‡Šæ”¾ï¼
> do_something()
> lock.release()
> ```
> 
> âœ… **æ­£ç¡®åšæ³•**ï¼šä½¿ç”¨try-finallyæˆ–withè¯­å¥
> ```python
> with lock:  # è‡ªåŠ¨å¤„ç†å¼‚å¸¸æƒ…å†µ
>     do_something()
> ```

**ğŸ¯ Lockä½¿ç”¨æœ€ä½³å®è·µ**ï¼š
```
1. æ€»æ˜¯ä½¿ç”¨withè¯­å¥ - è‡ªåŠ¨é‡Šæ”¾é”
2. é”çš„ç²’åº¦è¦åˆé€‚ - ä¸è¦é”å¤ªä¹…ï¼Œä¹Ÿä¸è¦é”å¤ªç»†
3. é¿å…åµŒå¥—é” - å®¹æ˜“å¯¼è‡´æ­»é”
4. é”çš„æ•°é‡è¦å°‘ - è¿‡å¤šé”å½±å“æ€§èƒ½
```

---

## 3. ğŸ“Š Semaphoreè¿›ç¨‹ä¿¡å·é‡


### 3.1 Semaphoreçš„åŸºæœ¬æ¦‚å¿µ


**ğŸ« ä»€ä¹ˆæ˜¯ä¿¡å·é‡**ï¼š
ä¿¡å·é‡å°±åƒç”µå½±é™¢çš„é—¨ç¥¨ï¼Œæœ‰å›ºå®šæ•°é‡ï¼ˆæ¯”å¦‚100å¼ ç¥¨ï¼‰ã€‚æ¯ä¸ªè¿›ç¨‹è¿›å…¥éœ€è¦ä¸€å¼ ç¥¨ï¼Œç¦»å¼€æ—¶é€€è¿˜ç¥¨ã€‚å½“ç¥¨ç”¨å®Œæ—¶ï¼Œæ–°æ¥çš„è¿›ç¨‹å¿…é¡»ç­‰å¾…ã€‚

**ğŸ“ˆ ä¿¡å·é‡ vs é”çš„åŒºåˆ«**ï¼š
```
ğŸ”’ Lockï¼ˆé”ï¼‰ï¼š
â€¢ åŒæ—¶åªå…è®¸1ä¸ªè¿›ç¨‹è®¿é—®
â€¢ ç±»ä¼¼å•äººæ´—æ‰‹é—´ï¼ŒåŒæ—¶åªèƒ½1äººä½¿ç”¨

ğŸ« Semaphoreï¼ˆä¿¡å·é‡ï¼‰ï¼š
â€¢ åŒæ—¶å…è®¸Nä¸ªè¿›ç¨‹è®¿é—®
â€¢ ç±»ä¼¼åœè½¦åœºï¼Œå¯ä»¥åœNè¾†è½¦
```

### 3.2 SemaphoreåŸºæœ¬ä½¿ç”¨


**ğŸ”§ åˆ›å»ºå’Œä½¿ç”¨ä¿¡å·é‡**ï¼š
```python
from multiprocessing import Process, Semaphore
import time
import random

def download_task(task_id, semaphore, max_concurrent=3):
    """æ¨¡æ‹Ÿä¸‹è½½ä»»åŠ¡ï¼Œé™åˆ¶å¹¶å‘æ•°"""
    # è·å–ä¿¡å·é‡
    semaphore.acquire()
    try:
        print(f"ğŸ“¥ ä»»åŠ¡{task_id} å¼€å§‹ä¸‹è½½...")
        # æ¨¡æ‹Ÿä¸‹è½½æ—¶é—´
        download_time = random.uniform(2, 5)
        time.sleep(download_time)
        print(f"âœ… ä»»åŠ¡{task_id} ä¸‹è½½å®Œæˆï¼Œè€—æ—¶{download_time:.1f}ç§’")
    finally:
        # é‡Šæ”¾ä¿¡å·é‡
        semaphore.release()

# ä½¿ç”¨withè¯­å¥çš„æ¨èæ–¹å¼
def download_with_context(task_id, semaphore):
    """ä½¿ç”¨withè¯­å¥ç®¡ç†ä¿¡å·é‡"""
    with semaphore:
        print(f"ğŸ“¥ ä»»åŠ¡{task_id} å¼€å§‹ä¸‹è½½...")
        time.sleep(random.uniform(2, 5))
        print(f"âœ… ä»»åŠ¡{task_id} ä¸‹è½½å®Œæˆ")

if __name__ == "__main__":
    # åˆ›å»ºä¿¡å·é‡ï¼Œå…è®¸3ä¸ªå¹¶å‘ä¸‹è½½
    download_semaphore = Semaphore(3)
    
    # åˆ›å»º10ä¸ªä¸‹è½½ä»»åŠ¡
    processes = []
    for i in range(10):
        p = Process(target=download_with_context, 
                   args=(i+1, download_semaphore))
        processes.append(p)
        p.start()
    
    # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
    for p in processes:
        p.join()
    
    print("ğŸ‰ æ‰€æœ‰ä¸‹è½½ä»»åŠ¡å®Œæˆï¼")
```

### 3.3 ä¿¡å·é‡çš„å®é™…åº”ç”¨åœºæ™¯


**ğŸŒ æ•°æ®åº“è¿æ¥æ± ç®¡ç†**ï¼š
```python
import time
from multiprocessing import Process, Semaphore

class DatabasePool:
    """æ¨¡æ‹Ÿæ•°æ®åº“è¿æ¥æ± """
    def __init__(self, max_connections=5):
        self.semaphore = Semaphore(max_connections)
        self.max_connections = max_connections
    
    def get_connection(self, user_id):
        """è·å–æ•°æ®åº“è¿æ¥"""
        print(f"ğŸ‘¤ ç”¨æˆ·{user_id} è¯·æ±‚æ•°æ®åº“è¿æ¥...")
        
        with self.semaphore:
            print(f"ğŸ”— ç”¨æˆ·{user_id} è·å¾—è¿æ¥ï¼Œå¼€å§‹æŸ¥è¯¢")
            # æ¨¡æ‹Ÿæ•°æ®åº“æŸ¥è¯¢
            time.sleep(random.uniform(1, 3))
            print(f"âœ… ç”¨æˆ·{user_id} æŸ¥è¯¢å®Œæˆï¼Œé‡Šæ”¾è¿æ¥")

def user_query(user_id, db_pool):
    """ç”¨æˆ·æŸ¥è¯¢æ•°æ®åº“"""
    db_pool.get_connection(user_id)

if __name__ == "__main__":
    # åˆ›å»ºæ•°æ®åº“è¿æ¥æ± ï¼ˆæœ€å¤š5ä¸ªè¿æ¥ï¼‰
    db_pool = DatabasePool(max_connections=5)
    
    # æ¨¡æ‹Ÿ10ä¸ªç”¨æˆ·åŒæ—¶æŸ¥è¯¢
    processes = []
    for user_id in range(1, 11):
        p = Process(target=user_query, args=(user_id, db_pool))
        processes.append(p)
        p.start()
    
    for p in processes:
        p.join()
```

### 3.4 BoundedSemaphoreæœ‰ç•Œä¿¡å·é‡


**ğŸ›¡ï¸ ä¸ºä»€ä¹ˆéœ€è¦æœ‰ç•Œä¿¡å·é‡**ï¼š
```python
from multiprocessing import Semaphore, BoundedSemaphore

# æ™®é€šä¿¡å·é‡çš„é—®é¢˜
normal_sem = Semaphore(2)
normal_sem.release()  # å¯ä»¥æ— é™é‡Šæ”¾ï¼Œè®¡æ•°å™¨å¯èƒ½è¶…è¿‡åˆå§‹å€¼
normal_sem.release()
normal_sem.release()  # å±é™©ï¼ä¿¡å·é‡è®¡æ•°å™¨å˜æˆ5

# æœ‰ç•Œä¿¡å·é‡çš„ä¿æŠ¤
bounded_sem = BoundedSemaphore(2)  # æœ€å¤§å€¼ä¸º2
bounded_sem.release()  # æ­£å¸¸é‡Šæ”¾
# bounded_sem.release()  # è¿™é‡Œä¼šæŠ›å‡ºValueErrorå¼‚å¸¸ï¼
```

**ğŸ’¡ æœ‰ç•Œä¿¡å·é‡ä½¿ç”¨å»ºè®®**ï¼š
> ğŸ¯ **ä½¿ç”¨åœºæ™¯**
> 
> - **æ™®é€šSemaphore**ï¼šä¿¡ä»»ä»£ç ä¸ä¼šè¿‡åº¦é‡Šæ”¾
> - **BoundedSemaphore**ï¼šéœ€è¦ä¸¥æ ¼æ§åˆ¶èµ„æºæ•°é‡
> - **ç”Ÿäº§ç¯å¢ƒ**ï¼šæ¨èä½¿ç”¨BoundedSemaphoreæ›´å®‰å…¨

---

## 4. ğŸ“¢ Eventè¿›ç¨‹äº‹ä»¶


### 4.1 Eventçš„åŸºæœ¬æ¦‚å¿µ


**ğŸš¦ ä»€ä¹ˆæ˜¯Event**ï¼š
Eventå°±åƒäº¤é€šçº¢ç»¿ç¯ï¼Œæœ‰ä¸¤ç§çŠ¶æ€ï¼šçº¢ç¯ï¼ˆæœªè®¾ç½®ï¼‰å’Œç»¿ç¯ï¼ˆå·²è®¾ç½®ï¼‰ã€‚è¿›ç¨‹å¯ä»¥ç­‰å¾…ç»¿ç¯äº®èµ·ï¼Œä¹Ÿå¯ä»¥æ§åˆ¶çº¢ç»¿ç¯çš„çŠ¶æ€ã€‚

**ğŸ“‹ Eventçš„çŠ¶æ€å’Œæ“ä½œ**ï¼š
```
çŠ¶æ€ï¼š
ğŸ”´ Falseï¼ˆæ¸…é™¤çŠ¶æ€ï¼‰- è¿›ç¨‹ç­‰å¾…
ğŸŸ¢ Trueï¼ˆè®¾ç½®çŠ¶æ€ï¼‰- è¿›ç¨‹ç»§ç»­

æ“ä½œæ–¹æ³•ï¼š
â€¢ set() - è®¾ç½®äº‹ä»¶ä¸ºTrueï¼Œå”¤é†’æ‰€æœ‰ç­‰å¾…çš„è¿›ç¨‹
â€¢ clear() - æ¸…é™¤äº‹ä»¶ä¸ºFalse
â€¢ wait() - ç­‰å¾…äº‹ä»¶å˜ä¸ºTrue
â€¢ is_set() - æ£€æŸ¥äº‹ä»¶çŠ¶æ€
```

### 4.2 EventåŸºæœ¬ä½¿ç”¨


**ğŸ”§ ç®€å•çš„Eventç¤ºä¾‹**ï¼š
```python
from multiprocessing import Process, Event
import time

def waiter(name, event):
    """ç­‰å¾…è€…è¿›ç¨‹"""
    print(f"ğŸ”´ {name} ç­‰å¾…ä¿¡å·...")
    event.wait()  # ç­‰å¾…äº‹ä»¶è¢«è®¾ç½®
    print(f"ğŸŸ¢ {name} æ”¶åˆ°ä¿¡å·ï¼Œå¼€å§‹å·¥ä½œï¼")

def setter(event):
    """è®¾ç½®è€…è¿›ç¨‹"""
    print("â° è®¾ç½®è€…ï¼šå‡†å¤‡å‘é€ä¿¡å·...")
    time.sleep(3)  # ç­‰å¾…3ç§’
    print("ğŸ“¢ è®¾ç½®è€…ï¼šå‘é€ä¿¡å·ï¼")
    event.set()  # è®¾ç½®äº‹ä»¶

if __name__ == "__main__":
    # åˆ›å»ºäº‹ä»¶å¯¹è±¡
    signal_event = Event()
    
    # åˆ›å»ºç­‰å¾…è¿›ç¨‹
    waiters = []
    for i in range(3):
        p = Process(target=waiter, args=(f"å·¥äºº{i+1}", signal_event))
        waiters.append(p)
        p.start()
    
    # åˆ›å»ºè®¾ç½®è¿›ç¨‹
    setter_process = Process(target=setter, args=(signal_event,))
    setter_process.start()
    
    # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹å®Œæˆ
    for p in waiters:
        p.join()
    setter_process.join()
```

### 4.3 Eventçš„å®é™…åº”ç”¨


**ğŸ­ ç”Ÿäº§è€…-æ¶ˆè´¹è€…åè°ƒ**ï¼š
```python
import time
import random
from multiprocessing import Process, Event, Queue

def producer(name, queue, start_event, stop_event):
    """ç”Ÿäº§è€…è¿›ç¨‹"""
    # ç­‰å¾…å¼€å§‹ä¿¡å·
    start_event.wait()
    print(f"ğŸ­ {name} å¼€å§‹ç”Ÿäº§...")
    
    while not stop_event.is_set():
        # ç”Ÿäº§äº§å“
        product = f"{name}_äº§å“_{random.randint(1000, 9999)}"
        queue.put(product)
        print(f"âœ… {name} ç”Ÿäº§äº† {product}")
        time.sleep(1)
    
    print(f"ğŸ›‘ {name} åœæ­¢ç”Ÿäº§")

def consumer(name, queue, start_event, stop_event):
    """æ¶ˆè´¹è€…è¿›ç¨‹"""
    # ç­‰å¾…å¼€å§‹ä¿¡å·
    start_event.wait()
    print(f"ğŸ›’ {name} å¼€å§‹æ¶ˆè´¹...")
    
    while not stop_event.is_set() or not queue.empty():
        try:
            # æ¶ˆè´¹äº§å“
            product = queue.get(timeout=1)
            print(f"ğŸ½ï¸ {name} æ¶ˆè´¹äº† {product}")
            time.sleep(1.5)
        except:
            continue
    
    print(f"ğŸ›‘ {name} åœæ­¢æ¶ˆè´¹")

def controller(start_event, stop_event):
    """æ§åˆ¶å™¨è¿›ç¨‹"""
    print("â° æ§åˆ¶å™¨ï¼š3ç§’åå¼€å§‹ç”Ÿäº§...")
    time.sleep(3)
    
    print("ğŸŸ¢ æ§åˆ¶å™¨ï¼šå‘é€å¼€å§‹ä¿¡å·ï¼")
    start_event.set()
    
    # è¿è¡Œ10ç§’
    time.sleep(10)
    
    print("ğŸ”´ æ§åˆ¶å™¨ï¼šå‘é€åœæ­¢ä¿¡å·ï¼")
    stop_event.set()

if __name__ == "__main__":
    # åˆ›å»ºäº‹ä»¶å’Œé˜Ÿåˆ—
    start_event = Event()
    stop_event = Event()
    product_queue = Queue()
    
    # åˆ›å»ºè¿›ç¨‹
    processes = []
    
    # ç”Ÿäº§è€…
    for i in range(2):
        p = Process(target=producer, 
                   args=(f"ç”Ÿäº§è€…{i+1}", product_queue, start_event, stop_event))
        processes.append(p)
        p.start()
    
    # æ¶ˆè´¹è€…
    for i in range(3):
        p = Process(target=consumer, 
                   args=(f"æ¶ˆè´¹è€…{i+1}", product_queue, start_event, stop_event))
        processes.append(p)
        p.start()
    
    # æ§åˆ¶å™¨
    controller_process = Process(target=controller, args=(start_event, stop_event))
    controller_process.start()
    processes.append(controller_process)
    
    # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹å®Œæˆ
    for p in processes:
        p.join()
    
    print("ğŸ‰ æ‰€æœ‰è¿›ç¨‹æ‰§è¡Œå®Œæ¯•ï¼")
```

### 4.4 Eventçš„é«˜çº§ç”¨æ³•


**â° å¸¦è¶…æ—¶çš„äº‹ä»¶ç­‰å¾…**ï¼š
```python
def smart_waiter(name, event, timeout=5):
    """æ™ºèƒ½ç­‰å¾…è€…ï¼Œæ”¯æŒè¶…æ—¶"""
    print(f"â° {name} ç­‰å¾…ä¿¡å·ï¼Œæœ€å¤šç­‰{timeout}ç§’...")
    
    if event.wait(timeout):
        print(f"ğŸŸ¢ {name} æ”¶åˆ°ä¿¡å·ï¼")
    else:
        print(f"â° {name} ç­‰å¾…è¶…æ—¶ï¼Œç»§ç»­å…¶ä»–å·¥ä½œ...")

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    event = Event()
    
    # è¿™ä¸ªè¿›ç¨‹ä¼šè¶…æ—¶
    p1 = Process(target=smart_waiter, args=("è¿›ç¨‹1", event, 3))
    p1.start()
    
    time.sleep(5)  # 5ç§’åæ‰è®¾ç½®äº‹ä»¶
    event.set()
    
    p1.join()
```

---

## 5. ğŸ’¾ å…±äº«å†…å­˜æŠ€æœ¯


### 5.1 shared_memoryåŸºæœ¬æ¦‚å¿µ


**ğŸ§  ä»€ä¹ˆæ˜¯å…±äº«å†…å­˜**ï¼š
æƒ³è±¡è¿›ç¨‹æ˜¯ä¸åŒçš„æˆ¿é—´ï¼Œé€šå¸¸æ¯ä¸ªæˆ¿é—´çš„ä¸œè¥¿åˆ«äººçœ‹ä¸åˆ°ã€‚å…±äº«å†…å­˜å°±åƒåœ¨æ‰€æœ‰æˆ¿é—´ä¹‹é—´å¼€äº†ä¸€ä¸ªå…¬å…±å‚¨ç‰©æŸœï¼Œå¤§å®¶éƒ½èƒ½å­˜å–åŒæ ·çš„ä¸œè¥¿ã€‚

**âš¡ ä¸ºä»€ä¹ˆéœ€è¦å…±äº«å†…å­˜**ï¼š
```
ä¼ ç»Ÿè¿›ç¨‹é—´é€šä¿¡é—®é¢˜ï¼š
ğŸ¢ æ…¢ï¼šæ•°æ®éœ€è¦å¤åˆ¶æ¥å¤åˆ¶å»
ğŸ’¾ å å†…å­˜ï¼šæ¯ä¸ªè¿›ç¨‹éƒ½ä¿å­˜ä¸€ä»½å‰¯æœ¬
ğŸ”„ å¤æ‚ï¼šéœ€è¦åºåˆ—åŒ–å’Œååºåˆ—åŒ–

å…±äº«å†…å­˜ä¼˜åŠ¿ï¼š
âš¡ å¿«ï¼šç›´æ¥åœ¨å†…å­˜ä¸­å…±äº«ï¼Œæ— éœ€å¤åˆ¶
ğŸ’¾ çœå†…å­˜ï¼šæ‰€æœ‰è¿›ç¨‹å…±äº«åŒä¸€ä»½æ•°æ®
ğŸ¯ ç®€å•ï¼šåƒè®¿é—®æ™®é€šå˜é‡ä¸€æ ·ç®€å•
```

### 5.2 SharedMemoryåŸºæœ¬ä½¿ç”¨


**ğŸ”§ åˆ›å»ºå’Œä½¿ç”¨å…±äº«å†…å­˜**ï¼š
```python
from multiprocessing import shared_memory, Process
import numpy as np
import time

def create_shared_array():
    """åˆ›å»ºå…±äº«å†…å­˜æ•°ç»„"""
    # åˆ›å»ºä¸€ä¸ªåŒ…å«1000ä¸ªæ•´æ•°çš„æ•°ç»„
    array_size = 1000
    shm = shared_memory.SharedMemory(create=True, size=array_size * 4)  # intå 4å­—èŠ‚
    
    # å°†å…±äº«å†…å­˜è½¬æ¢ä¸ºnumpyæ•°ç»„
    shared_array = np.ndarray((array_size,), dtype=np.int32, buffer=shm.buf)
    
    # åˆå§‹åŒ–æ•°æ®
    shared_array[:] = range(array_size)
    
    print(f"ğŸ“ åˆ›å»ºå…±äº«å†…å­˜ï¼š{shm.name}")
    print(f"ğŸ”¢ åˆå§‹æ•°æ®å‰10ä¸ªï¼š{shared_array[:10]}")
    
    return shm.name, shm

def worker_process(shm_name, worker_id):
    """å·¥ä½œè¿›ç¨‹ï¼Œä¿®æ”¹å…±äº«å†…å­˜"""
    # è¿æ¥åˆ°å·²å­˜åœ¨çš„å…±äº«å†…å­˜
    existing_shm = shared_memory.SharedMemory(name=shm_name)
    
    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    shared_array = np.ndarray((1000,), dtype=np.int32, buffer=existing_shm.buf)
    
    print(f"ğŸ‘· å·¥äºº{worker_id} å¼€å§‹å·¥ä½œ...")
    
    # ä¿®æ”¹æ•°æ®ï¼ˆæ¯ä¸ªå·¥äººè´Ÿè´£ä¸åŒçš„åŒºåŸŸï¼‰
    start_idx = worker_id * 250
    end_idx = (worker_id + 1) * 250
    
    for i in range(start_idx, end_idx):
        shared_array[i] = shared_array[i] * 2  # æ•°æ®ç¿»å€
    
    print(f"âœ… å·¥äºº{worker_id} å®Œæˆå·¥ä½œï¼Œå¤„ç†äº†ç´¢å¼• {start_idx}-{end_idx-1}")
    
    # æ¸…ç†
    existing_shm.close()

if __name__ == "__main__":
    # ä¸»è¿›ç¨‹åˆ›å»ºå…±äº«å†…å­˜
    shm_name, shm = create_shared_array()
    
    try:
        # åˆ›å»º4ä¸ªå·¥ä½œè¿›ç¨‹
        processes = []
        for i in range(4):
            p = Process(target=worker_process, args=(shm_name, i))
            processes.append(p)
            p.start()
        
        # ç­‰å¾…æ‰€æœ‰å·¥ä½œè¿›ç¨‹å®Œæˆ
        for p in processes:
            p.join()
        
        # æŸ¥çœ‹ç»“æœ
        shared_array = np.ndarray((1000,), dtype=np.int32, buffer=shm.buf)
        print(f"ğŸ‰ å¤„ç†åæ•°æ®å‰10ä¸ªï¼š{shared_array[:10]}")
        print(f"ğŸ‰ å¤„ç†åæ•°æ®å10ä¸ªï¼š{shared_array[-10:]}")
        
    finally:
        # æ¸…ç†å…±äº«å†…å­˜
        shm.close()
        shm.unlink()  # åˆ é™¤å…±äº«å†…å­˜
        print("ğŸ§¹ å…±äº«å†…å­˜å·²æ¸…ç†")
```

### 5.3 å¤§æ•°æ®å¤„ç†åº”ç”¨


**ğŸ“Š å›¾åƒå¤„ç†ç¤ºä¾‹**ï¼š
```python
import numpy as np
from multiprocessing import shared_memory, Process
import time

def create_shared_image(width=1000, height=1000):
    """åˆ›å»ºå…±äº«å›¾åƒæ•°ç»„"""
    # RGBå›¾åƒï¼Œæ¯ä¸ªåƒç´ 3ä¸ªå­—èŠ‚
    image_size = width * height * 3
    shm = shared_memory.SharedMemory(create=True, size=image_size)
    
    # åˆ›å»ºå›¾åƒæ•°ç»„
    image_array = np.ndarray((height, width, 3), dtype=np.uint8, buffer=shm.buf)
    
    # åˆå§‹åŒ–ä¸ºéšæœºå›¾åƒ
    image_array[:] = np.random.randint(0, 256, (height, width, 3))
    
    print(f"ğŸ–¼ï¸ åˆ›å»º {width}x{height} å›¾åƒï¼Œå¤§å°ï¼š{image_size/1024/1024:.1f}MB")
    
    return shm.name, shm, (height, width, 3)

def image_filter_worker(shm_name, shape, worker_id, total_workers):
    """å›¾åƒæ»¤é•œå¤„ç†å·¥äºº"""
    # è¿æ¥å…±äº«å†…å­˜
    existing_shm = shared_memory.SharedMemory(name=shm_name)
    image_array = np.ndarray(shape, dtype=np.uint8, buffer=existing_shm.buf)
    
    # è®¡ç®—è¿™ä¸ªå·¥äººè´Ÿè´£çš„è¡ŒèŒƒå›´
    height = shape[0]
    rows_per_worker = height // total_workers
    start_row = worker_id * rows_per_worker
    end_row = start_row + rows_per_worker if worker_id < total_workers - 1 else height
    
    print(f"ğŸ¨ å·¥äºº{worker_id} å¤„ç†è¡Œ {start_row}-{end_row-1}")
    
    # åº”ç”¨ç°åº¦æ»¤é•œ
    for row in range(start_row, end_row):
        for col in range(shape[1]):
            # ç°åº¦å…¬å¼ï¼š0.299*R + 0.587*G + 0.114*B
            r, g, b = image_array[row, col]
            gray = int(0.299 * r + 0.587 * g + 0.114 * b)
            image_array[row, col] = [gray, gray, gray]
    
    print(f"âœ… å·¥äºº{worker_id} å®Œæˆå¤„ç†")
    existing_shm.close()

if __name__ == "__main__":
    start_time = time.time()
    
    # åˆ›å»ºå…±äº«å›¾åƒ
    shm_name, shm, shape = create_shared_image(1000, 1000)
    
    try:
        # ä½¿ç”¨4ä¸ªè¿›ç¨‹å¹¶è¡Œå¤„ç†
        processes = []
        for i in range(4):
            p = Process(target=image_filter_worker, 
                       args=(shm_name, shape, i, 4))
            processes.append(p)
            p.start()
        
        # ç­‰å¾…å¤„ç†å®Œæˆ
        for p in processes:
            p.join()
        
        end_time = time.time()
        print(f"ğŸ‰ å›¾åƒå¤„ç†å®Œæˆï¼Œè€—æ—¶ï¼š{end_time - start_time:.2f}ç§’")
        
    finally:
        shm.close()
        shm.unlink()
```

### 5.4 å…±äº«å†…å­˜çš„æ³¨æ„äº‹é¡¹


**âš ï¸ é‡è¦æé†’**ï¼š

> **å†…å­˜ç®¡ç†**
> 
> ğŸ”´ **å¸¸è§é”™è¯¯**ï¼šå¿˜è®°æ¸…ç†å…±äº«å†…å­˜
> ```python
> # é”™è¯¯ï¼šåˆ›å»ºåä¸æ¸…ç†
> shm = shared_memory.SharedMemory(create=True, size=1000)
> # ç¨‹åºç»“æŸåï¼Œå†…å­˜å¯èƒ½è¿˜åœ¨ç³»ç»Ÿä¸­å ç”¨ï¼
> ```
> 
> âœ… **æ­£ç¡®åšæ³•**ï¼šæ€»æ˜¯æ¸…ç†èµ„æº
> ```python
> shm = shared_memory.SharedMemory(create=True, size=1000)
> try:
>     # ä½¿ç”¨å…±äº«å†…å­˜
>     pass
> finally:
>     shm.close()   # å…³é—­è¿æ¥
>     shm.unlink()  # åˆ é™¤å…±äº«å†…å­˜
> ```

**ğŸ¯ å…±äº«å†…å­˜æœ€ä½³å®è·µ**ï¼š
```
1. æ€»æ˜¯é…å¯¹ä½¿ç”¨ close() å’Œ unlink()
2. ä½¿ç”¨ try-finally ç¡®ä¿æ¸…ç†
3. å¤§æ•°æ®å¤„ç†ä¼˜å…ˆè€ƒè™‘å…±äº«å†…å­˜
4. é…åˆé”æœºåˆ¶é¿å…ç«æ€æ¡ä»¶
5. æ³¨æ„æ•°æ®ç±»å‹å’Œå­—èŠ‚å¯¹é½
```

---

## 6. ğŸ”¢ Valueå’ŒArrayå…±äº«å˜é‡


### 6.1 Valueå’ŒArrayåŸºæœ¬æ¦‚å¿µ


**ğŸ¯ ä»€ä¹ˆæ˜¯Valueå’ŒArray**ï¼š
å¦‚æœè¯´å…±äº«å†…å­˜æ˜¯"å¤§ä»“åº“"ï¼Œé‚£ä¹ˆValueå’ŒArrayå°±æ˜¯"å°ç›’å­"ã€‚å®ƒä»¬ä¸“é—¨ç”¨æ¥åœ¨è¿›ç¨‹é—´å…±äº«ç®€å•çš„æ•°å€¼å’Œå°æ•°ç»„ï¼Œä½¿ç”¨æ›´ç®€å•ï¼Œè‡ªå¸¦åŒæ­¥ä¿æŠ¤ã€‚

**ğŸ“‹ ç±»å‹å¯¹ç…§è¡¨**ï¼š
```
Pythonç±»å‹ â†’ Cç±»å‹æ ‡è¯† â†’ è¯´æ˜
bool       â†’ 'b'        â†’ å¸ƒå°”å€¼ï¼ˆ1å­—èŠ‚ï¼‰
int        â†’ 'i'        â†’ æœ‰ç¬¦å·æ•´æ•°ï¼ˆ4å­—èŠ‚ï¼‰
float      â†’ 'd'        â†’ åŒç²¾åº¦æµ®ç‚¹æ•°ï¼ˆ8å­—èŠ‚ï¼‰
str        â†’ 'c'        â†’ å­—ç¬¦ï¼ˆéœ€è¦æŒ‡å®šé•¿åº¦ï¼‰

å¸¸ç”¨ç±»å‹ï¼š
'b' - signed char      'B' - unsigned char
'h' - signed short     'H' - unsigned short  
'i' - signed int       'I' - unsigned int
'l' - signed long      'L' - unsigned long
'f' - float            'd' - double
```

### 6.2 Valueå…±äº«å•å€¼


**ğŸ”§ ValueåŸºæœ¬ä½¿ç”¨**ï¼š
```python
from multiprocessing import Process, Value, Lock
import time

def counter_worker(name, shared_counter, lock):
    """è®¡æ•°å™¨å·¥ä½œè¿›ç¨‹"""
    for i in range(5):
        with lock:  # ä½¿ç”¨é”ä¿æŠ¤å…±äº«å˜é‡
            current = shared_counter.value
            print(f"ğŸ“Š {name} è¯»å–è®¡æ•°å™¨ï¼š{current}")
            
            # æ¨¡æ‹Ÿä¸€äº›å¤„ç†æ—¶é—´
            time.sleep(0.1)
            
            shared_counter.value = current + 1
            print(f"âœ… {name} æ›´æ–°è®¡æ•°å™¨ï¼š{shared_counter.value}")

def temperature_monitor(sensor_id, shared_temp, lock):
    """æ¸©åº¦ç›‘æ§è¿›ç¨‹"""
    import random
    
    for _ in range(3):
        # æ¨¡æ‹Ÿè¯»å–ä¼ æ„Ÿå™¨
        new_temp = random.uniform(20.0, 30.0)
        
        with lock:
            shared_temp.value = new_temp
            print(f"ğŸŒ¡ï¸ ä¼ æ„Ÿå™¨{sensor_id} æ›´æ–°æ¸©åº¦ï¼š{new_temp:.1f}Â°C")
        
        time.sleep(1)

if __name__ == "__main__":
    # åˆ›å»ºå…±äº«å˜é‡ï¼ˆæ•´æ•°è®¡æ•°å™¨ï¼‰
    counter = Value('i', 0)  # 'i'è¡¨ç¤ºæœ‰ç¬¦å·æ•´æ•°ï¼Œåˆå§‹å€¼0
    counter_lock = Lock()
    
    # åˆ›å»ºå…±äº«å˜é‡ï¼ˆæµ®ç‚¹æ¸©åº¦ï¼‰
    temperature = Value('d', 25.0)  # 'd'è¡¨ç¤ºdoubleï¼Œåˆå§‹å€¼25.0
    temp_lock = Lock()
    
    processes = []
    
    # å¯åŠ¨è®¡æ•°å™¨è¿›ç¨‹
    for i in range(3):
        p = Process(target=counter_worker, 
                   args=(f"å·¥äºº{i+1}", counter, counter_lock))
        processes.append(p)
        p.start()
    
    # å¯åŠ¨æ¸©åº¦ç›‘æ§è¿›ç¨‹
    for i in range(2):
        p = Process(target=temperature_monitor, 
                   args=(i+1, temperature, temp_lock))
        processes.append(p)
        p.start()
    
    # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹å®Œæˆ
    for p in processes:
        p.join()
    
    print(f"ğŸ‰ æœ€ç»ˆè®¡æ•°å™¨å€¼ï¼š{counter.value}")
    print(f"ğŸ‰ æœ€ç»ˆæ¸©åº¦å€¼ï¼š{temperature.value:.1f}Â°C")
```

### 6.3 Arrayå…±äº«æ•°ç»„


**ğŸ“Š ArrayåŸºæœ¬ä½¿ç”¨**ï¼š
```python
from multiprocessing import Process, Array, Lock
import time
import random

def array_processor(worker_id, shared_array, lock, start_idx, end_idx):
    """æ•°ç»„å¤„ç†è¿›ç¨‹"""
    print(f"ğŸ”¢ å·¥äºº{worker_id} å¤„ç†ç´¢å¼• {start_idx}-{end_idx}")
    
    for i in range(start_idx, end_idx):
        with lock:
            # è¯»å–å½“å‰å€¼
            current_value = shared_array[i]
            
            # æ¨¡æ‹Ÿå¤æ‚è®¡ç®—
            new_value = current_value * 2 + random.randint(1, 10)
            
            # æ›´æ–°æ•°ç»„
            shared_array[i] = new_value
            
            print(f"ğŸ“ å·¥äºº{worker_id} æ›´æ–° array[{i}]: {current_value} -> {new_value}")
        
        time.sleep(0.1)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´

def statistics_monitor(shared_array, lock):
    """ç»Ÿè®¡ç›‘æ§è¿›ç¨‹"""
    for _ in range(5):
        with lock:
            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            array_list = list(shared_array[:])  # è½¬æ¢ä¸ºPythonåˆ—è¡¨
            total = sum(array_list)
            avg = total / len(array_list)
            max_val = max(array_list)
            min_val = min(array_list)
            
            print(f"ğŸ“Š ç»Ÿè®¡ - æ€»å’Œ:{total}, å¹³å‡:{avg:.1f}, æœ€å¤§:{max_val}, æœ€å°:{min_val}")
        
        time.sleep(2)

if __name__ == "__main__":
    # åˆ›å»ºå…±äº«æ•°ç»„ï¼ˆ10ä¸ªæ•´æ•°ï¼‰
    shared_array = Array('i', [i * 10 for i in range(10)])  # åˆå§‹åŒ–ä¸º [0,10,20,...,90]
    array_lock = Lock()
    
    print(f"ğŸ”¢ åˆå§‹æ•°ç»„ï¼š{list(shared_array[:])}")
    
    processes = []
    
    # åˆ›å»ºæ•°æ®å¤„ç†è¿›ç¨‹ï¼ˆæ¯ä¸ªå¤„ç†ä¸€éƒ¨åˆ†æ•°ç»„ï¼‰
    array_size = len(shared_array)
    workers = 3
    chunk_size = array_size // workers
    
    for i in range(workers):
        start_idx = i * chunk_size
        end_idx = start_idx + chunk_size if i < workers - 1 else array_size
        
        p = Process(target=array_processor, 
                   args=(i+1, shared_array, array_lock, start_idx, end_idx))
        processes.append(p)
        p.start()
    
    # åˆ›å»ºç»Ÿè®¡ç›‘æ§è¿›ç¨‹
    stats_process = Process(target=statistics_monitor, 
                           args=(shared_array, array_lock))
    processes.append(stats_process)
    stats_process.start()
    
    # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹å®Œæˆ
    for p in processes:
        p.join()
    
    print(f"ğŸ‰ æœ€ç»ˆæ•°ç»„ï¼š{list(shared_array[:])}")
```

### 6.4 Valueå’ŒArrayçš„é«˜çº§ç‰¹æ€§


**ğŸ”’ å†…ç½®é”æœºåˆ¶**ï¼š
```python
from multiprocessing import Process, Value, Array

def worker_with_builtin_lock(name, shared_value):
    """ä½¿ç”¨å†…ç½®é”çš„å·¥ä½œè¿›ç¨‹"""
    for i in range(3):
        # Valueå’ŒArrayè‡ªå¸¦é”ï¼Œå¯ä»¥å®‰å…¨è®¿é—®
        with shared_value.get_lock():
            current = shared_value.value
            print(f"{name} è¯»å–ï¼š{current}")
            shared_value.value = current + 1
            print(f"{name} æ›´æ–°ï¼š{shared_value.value}")

def worker_without_lock(name, shared_value):
    """ä¸ä½¿ç”¨é”çš„å·¥ä½œè¿›ç¨‹ï¼ˆä»…è¯»å–ï¼‰"""
    # åªè¯»å–ï¼Œä¸ä¿®æ”¹ï¼Œå¯ä»¥ä¸ç”¨é”
    for i in range(3):
        print(f"{name} è¯»å–ï¼ˆæ— é”ï¼‰ï¼š{shared_value.value}")
        time.sleep(0.5)

if __name__ == "__main__":
    # åˆ›å»ºå¸¦é”çš„å…±äº«å€¼
    shared_value = Value('i', 0, lock=True)  # æ˜ç¡®æŒ‡å®šä½¿ç”¨é”
    
    processes = []
    
    # ä¿®æ”¹è¿›ç¨‹éœ€è¦ä½¿ç”¨é”
    for i in range(2):
        p = Process(target=worker_with_builtin_lock, 
                   args=(f"ä¿®æ”¹è€…{i+1}", shared_value))
        processes.append(p)
        p.start()
    
    # åªè¯»è¿›ç¨‹å¯ä»¥ä¸ç”¨é”
    for i in range(2):
        p = Process(target=worker_without_lock, 
                   args=(f"è¯»å–è€…{i+1}", shared_value))
        processes.append(p)
        p.start()
    
    for p in processes:
        p.join()
```

**ğŸ¯ Valueå’ŒArrayä½¿ç”¨åœºæ™¯**ï¼š
```
âœ… é€‚åˆä½¿ç”¨ Value/Arrayï¼š
â€¢ å…±äº«ç®€å•æ•°å€¼ï¼ˆè®¡æ•°å™¨ã€çŠ¶æ€æ ‡å¿—ï¼‰
â€¢ å°å‹æ•°ç»„ï¼ˆé…ç½®å‚æ•°ã€ç»Ÿè®¡æ•°æ®ï¼‰  
â€¢ éœ€è¦é¢‘ç¹è¯»å†™çš„å…±äº«å˜é‡
â€¢ è¿›ç¨‹é—´ç®€å•çš„æ•°æ®äº¤æ¢

âŒ ä¸é€‚åˆä½¿ç”¨ Value/Arrayï¼š
â€¢ å¤§å‹æ•°æ®é›†ï¼ˆ> å‡ MBï¼‰
â€¢ å¤æ‚æ•°æ®ç»“æ„ï¼ˆå­—å…¸ã€å¯¹è±¡ï¼‰
â€¢ åŠ¨æ€å¤§å°çš„æ•°æ®
â€¢ éœ€è¦å¤æ‚æ“ä½œçš„æ•°æ®
```

---

## 7. ğŸ”„ è¿›ç¨‹é—´æ•°æ®äº¤æ¢


### 7.1 æ•°æ®äº¤æ¢æ–¹å¼æ¦‚è§ˆ


**ğŸ“Š è¿›ç¨‹é—´é€šä¿¡æ–¹å¼å¯¹æ¯”**ï¼š

```
é€šä¿¡æ–¹å¼å¯¹æ¯”è¡¨ï¼š

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    é€šä¿¡æ–¹å¼     â”‚   é€Ÿåº¦   â”‚  å†…å­˜å ç”¨â”‚  ä½¿ç”¨éš¾åº¦â”‚  é€‚ç”¨åœºæ™¯â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Queueé˜Ÿåˆ—       â”‚    ä¸­    â”‚    é«˜    â”‚    ä½    â”‚ å¼‚æ­¥æ¶ˆæ¯ â”‚
â”‚ Pipeç®¡é“        â”‚    é«˜    â”‚    ä½    â”‚    ä¸­    â”‚ åŒå‘é€šä¿¡ â”‚
â”‚ shared_memory   â”‚   æé«˜   â”‚   æä½   â”‚    é«˜    â”‚ å¤§æ•°æ®   â”‚
â”‚ Value/Array     â”‚    é«˜    â”‚    ä½    â”‚    ä½    â”‚ ç®€å•æ•°æ® â”‚
â”‚ Managerå¯¹è±¡     â”‚    ä½    â”‚    é«˜    â”‚    ä½    â”‚ å¤æ‚æ•°æ® â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 7.2 Queueé˜Ÿåˆ—é€šä¿¡


**ğŸ“® Queueçš„åŸºæœ¬æ¦‚å¿µ**ï¼š
Queueå°±åƒé‚®å±€çš„é‚®ç®±ï¼Œè¿›ç¨‹å¯ä»¥å¾€é‡ŒæŠ•é€’æ¶ˆæ¯ï¼ˆputï¼‰ï¼Œä¹Ÿå¯ä»¥å–å‡ºæ¶ˆæ¯ï¼ˆgetï¼‰ã€‚æ”¯æŒå…ˆè¿›å…ˆå‡ºï¼ˆFIFOï¼‰çš„é¡ºåºã€‚

**ğŸ”§ QueueåŸºæœ¬ä½¿ç”¨**ï¼š
```python
from multiprocessing import Process, Queue
import time
import random

def producer(name, queue, num_items):
    """ç”Ÿäº§è€…è¿›ç¨‹"""
    print(f"ğŸ­ {name} å¼€å§‹ç”Ÿäº§...")
    
    for i in range(num_items):
        # ç”Ÿäº§å•†å“
        item = f"{name}_å•†å“_{i+1}"
        queue.put(item)
        print(f"ğŸ“¦ {name} ç”Ÿäº§ï¼š{item}")
        time.sleep(random.uniform(0.5, 1.5))
    
    # å‘é€ç»“æŸä¿¡å·
    queue.put(None)
    print(f"ğŸ›‘ {name} ç”Ÿäº§ç»“æŸ")

def consumer(name, queue):
    """æ¶ˆè´¹è€…è¿›ç¨‹"""
    print(f"ğŸ›’ {name} å¼€å§‹æ¶ˆè´¹...")
    
    while True:
        # è·å–å•†å“
        item = queue.get()
        
        if item is None:
            # æ”¶åˆ°ç»“æŸä¿¡å·
            queue.put(None)  # ä¼ é€’ç»™ä¸‹ä¸€ä¸ªæ¶ˆè´¹è€…
            break
        
        print(f"ğŸ½ï¸ {name} æ¶ˆè´¹ï¼š{item}")
        time.sleep(random.uniform(1, 2))
    
    print(f"ğŸ›‘ {name} æ¶ˆè´¹ç»“æŸ")

def quality_inspector(queue, result_queue):
    """è´¨é‡æ£€æŸ¥è¿›ç¨‹"""
    print("ğŸ” è´¨æ£€å‘˜å¼€å§‹å·¥ä½œ...")
    checked_count = 0
    
    while True:
        try:
            item = queue.get(timeout=3)  # 3ç§’è¶…æ—¶
            
            if item is None:
                break
            
            # æ¨¡æ‹Ÿè´¨é‡æ£€æŸ¥
            time.sleep(0.5)
            checked_count += 1
            
            # å‡è®¾90%é€šè¿‡æ£€æŸ¥
            if random.random() < 0.9:
                result_queue.put(f"âœ… {item} æ£€æŸ¥é€šè¿‡")
            else:
                result_queue.put(f"âŒ {item} æ£€æŸ¥å¤±è´¥")
                
        except:
            break  # è¶…æ—¶ï¼Œç»“æŸæ£€æŸ¥
    
    result_queue.put(f"ğŸ“Š è´¨æ£€å®Œæˆï¼Œå…±æ£€æŸ¥ {checked_count} ä»¶å•†å“")
    print("ğŸ” è´¨æ£€å‘˜å·¥ä½œç»“æŸ")

if __name__ == "__main__":
    # åˆ›å»ºé˜Ÿåˆ—
    product_queue = Queue(maxsize=10)  # é™åˆ¶é˜Ÿåˆ—å¤§å°
    result_queue = Queue()
    
    processes = []
    
    # åˆ›å»ºç”Ÿäº§è€…
    for i in range(2):
        p = Process(target=producer, 
                   args=(f"ç”Ÿäº§è€…{i+1}", product_queue, 5))
        processes.append(p)
        p.start()
    
    # åˆ›å»ºæ¶ˆè´¹è€…
    for i in range(3):
        p = Process(target=consumer, 
                   args=(f"æ¶ˆè´¹è€…{i+1}", product_queue))
        processes.append(p)
        p.start()
    
    # åˆ›å»ºè´¨æ£€å‘˜
    inspector = Process(target=quality_inspector, 
                       args=(product_queue, result_queue))
    processes.append(inspector)
    inspector.start()
    
    # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹å®Œæˆ
    for p in processes:
        p.join()
    
    # æ˜¾ç¤ºè´¨æ£€ç»“æœ
    print("\nğŸ“‹ è´¨æ£€ç»“æœï¼š")
    while not result_queue.empty():
        result = result_queue.get()
        print(result)
```

### 7.3 Pipeç®¡é“é€šä¿¡


**ğŸ”— Pipeçš„åŸºæœ¬æ¦‚å¿µ**ï¼š
Pipeå°±åƒä¸¤ä¸ªæˆ¿é—´ä¹‹é—´çš„å¯¹è®²æœºï¼Œå¯ä»¥åŒå‘é€šè¯ã€‚æ¯”Queueæ›´è½»é‡ï¼Œé€‚åˆä¸¤ä¸ªè¿›ç¨‹ä¹‹é—´çš„ç›´æ¥é€šä¿¡ã€‚

**ğŸ”§ PipeåŸºæœ¬ä½¿ç”¨**ï¼š
```python
from multiprocessing import Process, Pipe
import time
import random

def child_process(child_conn, child_name):
    """å­è¿›ç¨‹"""
    print(f"ğŸ‘¶ {child_name} å¯åŠ¨")
    
    # å‘é€é—®å€™æ¶ˆæ¯
    child_conn.send(f"ä½ å¥½ï¼Œæˆ‘æ˜¯ {child_name}")
    
    # æ¥æ”¶çˆ¶è¿›ç¨‹çš„æ¶ˆæ¯
    message = child_conn.recv()
    print(f"ğŸ‘¶ {child_name} æ”¶åˆ°æ¶ˆæ¯ï¼š{message}")
    
    # è¿›è¡Œä¸€äº›å·¥ä½œï¼Œå®šæœŸæ±‡æŠ¥
    for i in range(3):
        time.sleep(random.uniform(1, 2))
        progress = (i + 1) * 33.3
        child_conn.send(f"{child_name} å·¥ä½œè¿›åº¦ï¼š{progress:.1f}%")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ–°æ¶ˆæ¯
        if child_conn.poll():  # éé˜»å¡æ£€æŸ¥
            msg = child_conn.recv()
            print(f"ğŸ‘¶ {child_name} æ”¶åˆ°æŒ‡ä»¤ï¼š{msg}")
    
    # å‘é€å®Œæˆæ¶ˆæ¯
    child_conn.send(f"{child_name} å·¥ä½œå®Œæˆï¼")
    child_conn.close()

def parent_process():
    """çˆ¶è¿›ç¨‹"""
    print("ğŸ‘¨ çˆ¶è¿›ç¨‹å¯åŠ¨")
    
    # åˆ›å»ºç®¡é“
    parent_conn, child_conn = Pipe()
    
    # å¯åŠ¨å­è¿›ç¨‹
    child = Process(target=child_process, 
                   args=(child_conn, "å·¥ä½œè¿›ç¨‹"))
    child.start()
    
    # æ¥æ”¶å­è¿›ç¨‹çš„é—®å€™
    greeting = parent_conn.recv()
    print(f"ğŸ‘¨ çˆ¶è¿›ç¨‹æ”¶åˆ°ï¼š{greeting}")
    
    # å‘é€å·¥ä½œæŒ‡ä»¤
    parent_conn.send("å¼€å§‹ä½ çš„å·¥ä½œå§ï¼")
    
    # ç›‘æ§å­è¿›ç¨‹å·¥ä½œè¿›åº¦
    while True:
        try:
            # ç­‰å¾…æ¶ˆæ¯ï¼Œæœ€å¤šç­‰2ç§’
            if parent_conn.poll(2):
                message = parent_conn.recv()
                print(f"ğŸ‘¨ çˆ¶è¿›ç¨‹æ”¶åˆ°ï¼š{message}")
                
                if "å®Œæˆ" in message:
                    break
                elif "è¿›åº¦" in message:
                    # æ ¹æ®è¿›åº¦ç»™å‡ºåé¦ˆ
                    if "66.6%" in message:
                        parent_conn.send("åšå¾—å¾ˆå¥½ï¼Œç»§ç»­åŠ æ²¹ï¼")
            else:
                print("ğŸ‘¨ çˆ¶è¿›ç¨‹ï¼šç­‰å¾…ä¸­...")
        except:
            break
    
    child.join()
    parent_conn.close()
    print("ğŸ‘¨ çˆ¶è¿›ç¨‹ç»“æŸ")

if __name__ == "__main__":
    parent_process()
```

### 7.4 Managerå¯¹è±¡é€šä¿¡


**ğŸ›ï¸ Managerçš„åŸºæœ¬æ¦‚å¿µ**ï¼š
Managerå°±åƒä¸€ä¸ª"æ•°æ®ç®¡å®¶"ï¼Œå¯ä»¥åˆ›å»ºå’Œç®¡ç†å„ç§å¯ä»¥åœ¨è¿›ç¨‹é—´å…±äº«çš„Pythonå¯¹è±¡ï¼Œå¦‚å­—å…¸ã€åˆ—è¡¨ç­‰ã€‚

**ğŸ”§ ManageråŸºæœ¬ä½¿ç”¨**ï¼š
```python
from multiprocessing import Process, Manager
import time
import random

def task_worker(worker_id, shared_dict, shared_list, task_queue):
    """ä»»åŠ¡å·¥ä½œè¿›ç¨‹"""
    print(f"ğŸ‘· å·¥äºº{worker_id} å¼€å§‹å·¥ä½œ")
    
    # åœ¨å…±äº«å­—å…¸ä¸­æ³¨å†Œè‡ªå·±
    shared_dict[f'worker_{worker_id}'] = {
        'status': 'å·¥ä½œä¸­',
        'tasks_completed': 0,
        'start_time': time.time()
    }
    
    while True:
        try:
            # ä»ä»»åŠ¡é˜Ÿåˆ—è·å–ä»»åŠ¡
            task = task_queue.get(timeout=2)
            
            if task is None:  # ç»“æŸä¿¡å·
                break
            
            print(f"ğŸ‘· å·¥äºº{worker_id} å¤„ç†ä»»åŠ¡ï¼š{task}")
            
            # æ¨¡æ‹Ÿä»»åŠ¡å¤„ç†
            processing_time = random.uniform(1, 3)
            time.sleep(processing_time)
            
            # æ›´æ–°è¿›åº¦
            shared_dict[f'worker_{worker_id}']['tasks_completed'] += 1
            
            # æ·»åŠ ç»“æœåˆ°å…±äº«åˆ—è¡¨
            result = f"ä»»åŠ¡{task}_ç»“æœ_byå·¥äºº{worker_id}"
            shared_list.append(result)
            
            print(f"âœ… å·¥äºº{worker_id} å®Œæˆä»»åŠ¡ï¼š{task}")
            
        except:
            # è¶…æ—¶ï¼Œæ²¡æœ‰æ›´å¤šä»»åŠ¡
            break
    
    # æ›´æ–°çŠ¶æ€ä¸ºå®Œæˆ
    shared_dict[f'worker_{worker_id}']['status'] = 'å·²å®Œæˆ'
    shared_dict[f'worker_{worker_id}']['end_time'] = time.time()
    print(f"ğŸ›‘ å·¥äºº{worker_id} ç»“æŸå·¥ä½œ")

def task_dispatcher(task_queue, num_tasks):
    """ä»»åŠ¡åˆ†å‘è¿›ç¨‹"""
    print(f"ğŸ“‹ å¼€å§‹åˆ†å‘ {num_tasks} ä¸ªä»»åŠ¡")
    
    for i in range(num_tasks):
        task_queue.put(f"Task_{i+1}")
        time.sleep(0.5)  # æ¨¡æ‹Ÿä»»åŠ¡äº§ç”Ÿé€Ÿåº¦
    
    print("ğŸ“‹ ä»»åŠ¡åˆ†å‘å®Œæˆ")

def monitor_process(shared_dict, shared_list):
    """ç›‘æ§è¿›ç¨‹"""
    print("ğŸ“Š ç›‘æ§å™¨å¯åŠ¨")
    
    for _ in range(10):
        time.sleep(2)
        
        print("\n" + "="*50)
        print("ğŸ“Š å½“å‰çŠ¶æ€æŠ¥å‘Šï¼š")
        
        # æ˜¾ç¤ºå·¥äººçŠ¶æ€
        for worker_name, info in shared_dict.items():
            if worker_name.startswith('worker_'):
                status = info['status']
                completed = info['tasks_completed']
                print(f"   {worker_name}: {status}, å®Œæˆä»»åŠ¡: {completed}")
        
        # æ˜¾ç¤ºç»“æœæ•°é‡
        print(f"   å·²å®Œæˆç»“æœ: {len(shared_list)} ä¸ª")
        
        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å·¥äººéƒ½å®Œæˆäº†
        all_done = all(info['status'] == 'å·²å®Œæˆ' 
                      for name, info in shared_dict.items() 
                      if name.startswith('worker_'))
        
        if all_done:
            print("ğŸ‰ æ‰€æœ‰å·¥äººéƒ½å®Œæˆäº†å·¥ä½œï¼")
            break
    
    print("ğŸ“Š ç›‘æ§å™¨ç»“æŸ")

if __name__ == "__main__":
    # åˆ›å»ºManagerå¯¹è±¡
    with Manager() as manager:
        # åˆ›å»ºå…±äº«å¯¹è±¡
        shared_dict = manager.dict()     # å…±äº«å­—å…¸
        shared_list = manager.list()     # å…±äº«åˆ—è¡¨  
        task_queue = manager.Queue()     # å…±äº«é˜Ÿåˆ—
        
        processes = []
        
        # åˆ›å»ºä»»åŠ¡åˆ†å‘è¿›ç¨‹
        dispatcher = Process(target=task_dispatcher, 
                           args=(task_queue, 15))
        processes.append(dispatcher)
        dispatcher.start()
        
        # åˆ›å»ºå·¥ä½œè¿›ç¨‹
        for i in range(3):
            worker = Process(target=task_worker, 
                           args=(i+1, shared_dict, shared_list, task_queue))
            processes.append(worker)
            worker.start()
        
        # åˆ›å»ºç›‘æ§è¿›ç¨‹
        monitor = Process(target=monitor_process, 
                        args=(shared_dict, shared_list))
        processes.append(monitor)
        monitor.start()
        
        # ç­‰å¾…åˆ†å‘å®Œæˆ
        dispatcher.join()
        
        # å‘é€ç»“æŸä¿¡å·ç»™å·¥ä½œè¿›ç¨‹
        for _ in range(3):
            task_queue.put(None)
        
        # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹å®Œæˆ
        for p in processes[1:]:  # é™¤äº†å·²ç»å®Œæˆçš„dispatcher
            p.join()
        
        # æ˜¾ç¤ºæœ€ç»ˆç»“æœ
        print("\n" + "="*50)
        print("ğŸ‰ æœ€ç»ˆç»Ÿè®¡ï¼š")
        for worker_name, info in shared_dict.items():
            if worker_name.startswith('worker_'):
                duration = info.get('end_time', time.time()) - info['start_time']
                print(f"{worker_name}: å®Œæˆ {info['tasks_completed']} ä¸ªä»»åŠ¡ï¼Œè€—æ—¶ {duration:.1f} ç§’")
        
        print(f"æ€»å…±äº§ç”Ÿ {len(shared_list)} ä¸ªç»“æœ")
```

### 7.5 æ•°æ®äº¤æ¢æ–¹å¼é€‰æ‹©æŒ‡å—


**ğŸ¯ é€‰æ‹©å»ºè®®**ï¼š

> **ğŸ“Š æ•°æ®é‡å°ï¼ˆ< 1MBï¼‰**
> - **ç®€å•æ•°å€¼**ï¼šä½¿ç”¨ Value/Array
> - **æ¶ˆæ¯ä¼ é€’**ï¼šä½¿ç”¨ Queue
> - **åŒå‘é€šä¿¡**ï¼šä½¿ç”¨ Pipe
> 
> **ğŸ“Š æ•°æ®é‡å¤§ï¼ˆ> 1MBï¼‰**
> - **å¤§å‹æ•°ç»„**ï¼šä½¿ç”¨ shared_memory
> - **å¤æ‚å¯¹è±¡**ï¼šä½¿ç”¨ Managerï¼ˆè°¨æ…ï¼‰
> 
> **ğŸ“Š é€šä¿¡æ¨¡å¼**
> - **ä¸€å¯¹ä¸€**ï¼šPipe æœ€é«˜æ•ˆ
> - **ä¸€å¯¹å¤š**ï¼šQueue æœ€åˆé€‚
> - **å¤šå¯¹å¤š**ï¼šManager æœ€çµæ´»

---

## 8. ğŸ“ˆ è¿›ç¨‹ç›‘æ§ä¸ç®¡ç†


### 8.1 è¿›ç¨‹çŠ¶æ€ç›‘æ§


**ğŸ“Š è¿›ç¨‹ç”Ÿå‘½å‘¨æœŸç›‘æ§**ï¼š
```python
import multiprocessing as mp
import psutil  # éœ€è¦å®‰è£…ï¼špip install psutil
import time
import os

class ProcessMonitor:
    """è¿›ç¨‹ç›‘æ§å™¨"""
    
    def __init__(self):
        self.processes = {}  # å­˜å‚¨è¿›ç¨‹ä¿¡æ¯
        self.start_time = time.time()
    
    def register_process(self, process, name):
        """æ³¨å†Œè¦ç›‘æ§çš„è¿›ç¨‹"""
        self.processes[name] = {
            'process': process,
            'pid': process.pid,
            'start_time': time.time(),
            'status': 'running'
        }
        print(f"ğŸ“ æ³¨å†Œè¿›ç¨‹ï¼š{name} (PID: {process.pid})")
    
    def get_process_info(self, name):
        """è·å–è¿›ç¨‹è¯¦ç»†ä¿¡æ¯"""
        if name not in self.processes:
            return None
        
        process_info = self.processes[name]
        pid = process_info['pid']
        
        try:
            # ä½¿ç”¨psutilè·å–è¯¦ç»†ä¿¡æ¯
            proc = psutil.Process(pid)
            
            cpu_percent = proc.cpu_percent()
            memory_info = proc.memory_info()
            memory_mb = memory_info.rss / 1024 / 1024  # è½¬æ¢ä¸ºMB
            
            status = proc.status()
            running_time = time.time() - process_info['start_time']
            
            return {
                'name': name,
                'pid': pid,
                'status': status,
                'cpu_percent': cpu_percent,
                'memory_mb': memory_mb,
                'running_time': running_time
            }
        except psutil.NoSuchProcess:
            return {
                'name': name,
                'pid': pid,
                'status': 'terminated',
                'cpu_percent': 0,
                'memory_mb': 0,
                'running_time': time.time() - process_info['start_time']
            }
    
    def print_status_report(self):
        """æ‰“å°çŠ¶æ€æŠ¥å‘Š"""
        print("\n" + "="*60)
        print("ğŸ“Š è¿›ç¨‹ç›‘æ§æŠ¥å‘Š")
        print("="*60)
        
        total_cpu = 0
        total_memory = 0
        
        for name in self.processes:
            info = self.get_process_info(name)
            if info:
                status_emoji = "ğŸŸ¢" if info['status'] == 'running' else "ğŸ”´"
                print(f"{status_emoji} {info['name']:15} "
                      f"PID:{info['pid']:6} "
                      f"CPU:{info['cpu_percent']:5.1f}% "
                      f"å†…å­˜:{info['memory_mb']:6.1f}MB "
                      f"è¿è¡Œ:{info['running_time']:6.1f}s")
                
                if info['status'] == 'running':
                    total_cpu += info['cpu_percent']
                    total_memory += info['memory_mb']
        
        print("-" * 60)
        print(f"ğŸ“ˆ æ€»è®¡ - CPU: {total_cpu:.1f}%  å†…å­˜: {total_memory:.1f}MB")
        print(f"â±ï¸ ç›‘æ§å™¨è¿è¡Œæ—¶é—´: {time.time() - self.start_time:.1f}ç§’")

def cpu_intensive_task(name, duration):
    """CPUå¯†é›†å‹ä»»åŠ¡"""
    print(f"ğŸ’» {name} å¼€å§‹CPUå¯†é›†ä»»åŠ¡...")
    start_time = time.time()
    
    # CPUå¯†é›†å‹è®¡ç®—
    while time.time() - start_time < duration:
        # è®¡ç®—è´¨æ•°
        for num in range(2, 1000):
            for i in range(2, int(num**0.5) + 1):
                if num % i == 0:
                    break
    
    print(f"âœ… {name} CPUä»»åŠ¡å®Œæˆ")

def memory_intensive_task(name, duration):
    """å†…å­˜å¯†é›†å‹ä»»åŠ¡"""
    print(f"ğŸ’¾ {name} å¼€å§‹å†…å­˜å¯†é›†ä»»åŠ¡...")
    
    # é€æ¸åˆ†é…æ›´å¤šå†…å­˜
    data_chunks = []
    for i in range(duration):
        # æ¯ç§’åˆ†é…10MBå†…å­˜
        chunk = [0] * (10 * 1024 * 1024 // 8)  # 10MBçš„æ•´æ•°åˆ—è¡¨
        data_chunks.append(chunk)
        print(f"ğŸ’¾ {name} åˆ†é…äº† {(i+1)*10}MB å†…å­˜")
        time.sleep(1)
    
    print(f"âœ… {name} å†…å­˜ä»»åŠ¡å®Œæˆ")

def io_intensive_task(name, duration):
    """IOå¯†é›†å‹ä»»åŠ¡"""
    print(f"ğŸ’¿ {name} å¼€å§‹IOå¯†é›†ä»»åŠ¡...")
    
    for i in range(duration):
        # æ¨¡æ‹Ÿæ–‡ä»¶IOæ“ä½œ
        filename = f"temp_{name}_{i}.txt"
        with open(filename, 'w') as f:
            f.write("x" * 1024 * 1024)  # å†™å…¥1MBæ•°æ®
        
        # è¯»å–æ–‡ä»¶
        with open(filename, 'r') as f:
            content = f.read()
        
        # åˆ é™¤æ–‡ä»¶
        os.remove(filename)
        
        print(f"ğŸ’¿ {name} å®Œæˆç¬¬{i+1}æ¬¡IOæ“ä½œ")
        time.sleep(1)
    
    print(f"âœ… {name} IOä»»åŠ¡å®Œæˆ")

if __name__ == "__main__":
    monitor = ProcessMonitor()
    
    # åˆ›å»ºä¸åŒç±»å‹çš„è¿›ç¨‹
    processes = []
    
    # CPUå¯†é›†å‹è¿›ç¨‹
    cpu_proc = mp.Process(target=cpu_intensive_task, 
                         args=("CPUè¿›ç¨‹", 8))
    cpu_proc.start()
    monitor.register_process(cpu_proc, "CPUå¯†é›†ä»»åŠ¡")
    processes.append(cpu_proc)
    
    # å†…å­˜å¯†é›†å‹è¿›ç¨‹
    mem_proc = mp.Process(target=memory_intensive_task, 
                         args=("å†…å­˜è¿›ç¨‹", 6))
    mem_proc.start()
    monitor.register_process(mem_proc, "å†…å­˜å¯†é›†ä»»åŠ¡")
    processes.append(mem_proc)
    
    # IOå¯†é›†å‹è¿›ç¨‹
    io_proc = mp.Process(target=io_intensive_task, 
                        args=("IOè¿›ç¨‹", 5))
    io_proc.start()
    monitor.register_process(io_proc, "IOå¯†é›†ä»»åŠ¡")
    processes.append(io_proc)
    
    # å®šæœŸæ‰“å°ç›‘æ§æŠ¥å‘Š
    try:
        while any(p.is_alive() for p in processes):
            monitor.print_status_report()
            time.sleep(3)
    except KeyboardInterrupt:
        print("\nâš ï¸ æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨ç»ˆæ­¢è¿›ç¨‹...")
        for p in processes:
            if p.is_alive():
                p.terminate()
    
    # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹å®Œæˆ
    for p in processes:
        p.join()
    
    print("\nğŸ‰ æ‰€æœ‰è¿›ç¨‹å·²å®Œæˆ")
    monitor.print_status_report()
```

### 8.2 è¿›ç¨‹æ± ç®¡ç†


**ğŸŠ è¿›ç¨‹æ± çš„æ¦‚å¿µå’Œä½¿ç”¨**ï¼š
```python
from multiprocessing import Pool, current_process
import time
import random

def long_running_task(task_id):
    """é•¿æ—¶é—´è¿è¡Œçš„ä»»åŠ¡"""
    process_name = current_process().name
    pid = current_process().pid
    
    print(f"ğŸš€ ä»»åŠ¡{task_id} å¼€å§‹æ‰§è¡Œ (è¿›ç¨‹: {process_name}, PID: {pid})")
    
    # æ¨¡æ‹Ÿå¤æ‚è®¡ç®—
    work_time = random.uniform(2, 6)
    time.sleep(work_time)
    
    # æ¨¡æ‹Ÿè®¡ç®—ç»“æœ
    result = task_id * task_id + random.randint(1, 100)
    
    print(f"âœ… ä»»åŠ¡{task_id} å®Œæˆï¼Œè€—æ—¶ {work_time:.1f}ç§’ï¼Œç»“æœ: {result}")
    
    return {
        'task_id': task_id,
        'result': result,
        'process_name': process_name,
        'work_time': work_time
    }

def batch_processor():
    """æ‰¹é‡å¤„ç†ä»»åŠ¡çš„ç¤ºä¾‹"""
    print("ğŸŠ åˆ›å»ºè¿›ç¨‹æ± ...")
    
    # åˆ›å»ºè¿›ç¨‹æ± ï¼ŒæŒ‡å®šè¿›ç¨‹æ•°é‡
    with Pool(processes=4) as pool:
        print(f"ğŸ“Š è¿›ç¨‹æ± ä¿¡æ¯ï¼š{pool._processes} ä¸ªå·¥ä½œè¿›ç¨‹")
        
        # æ–¹æ³•1ï¼šmap - æ‰¹é‡æäº¤ä»»åŠ¡
        print("\nğŸš€ æ–¹æ³•1ï¼šä½¿ç”¨ map æ‰¹é‡å¤„ç†")
        start_time = time.time()
        
        task_ids = list(range(1, 9))  # 8ä¸ªä»»åŠ¡
        results = pool.map(long_running_task, task_ids)
        
        end_time = time.time()
        print(f"â±ï¸ æ‰¹é‡å¤„ç†å®Œæˆï¼Œæ€»è€—æ—¶: {end_time - start_time:.1f}ç§’")
        
        # æ˜¾ç¤ºç»“æœ
        for result in results:
            print(f"ğŸ“‹ ä»»åŠ¡{result['task_id']}: ç»“æœ={result['result']}, "
                  f"è¿›ç¨‹={result['process_name']}")
        
        print("\n" + "="*50)
        
        # æ–¹æ³•2ï¼šapply_async - å¼‚æ­¥æäº¤ä»»åŠ¡
        print("ğŸš€ æ–¹æ³•2ï¼šä½¿ç”¨ apply_async å¼‚æ­¥å¤„ç†")
        start_time = time.time()
        
        # æäº¤å¼‚æ­¥ä»»åŠ¡
        async_results = []
        for i in range(10, 16):  # 6ä¸ªä»»åŠ¡
            async_result = pool.apply_async(long_running_task, (i,))
            async_results.append(async_result)
        
        # è·å–ç»“æœ
        final_results = []
        for async_result in async_results:
            result = async_result.get()  # é˜»å¡ç­‰å¾…ç»“æœ
            final_results.append(result)
        
        end_time = time.time()
        print(f"â±ï¸ å¼‚æ­¥å¤„ç†å®Œæˆï¼Œæ€»è€—æ—¶: {end_time - start_time:.1f}ç§’")

class AdvancedProcessManager:
    """é«˜çº§è¿›ç¨‹ç®¡ç†å™¨"""
    
    def __init__(self, max_workers=4):
        self.max_workers = max_workers
        self.active_processes = {}
        self.completed_tasks = []
        
    def submit_task_with_callback(self, func, args, callback=None):
        """æäº¤ä»»åŠ¡å¹¶è®¾ç½®å›è°ƒå‡½æ•°"""
        with Pool(processes=self.max_workers) as pool:
            
            def success_callback(result):
                """æˆåŠŸå›è°ƒ"""
                self.completed_tasks.append(result)
                print(f"ğŸ‰ ä»»åŠ¡å®Œæˆå›è°ƒï¼š{result['task_id']}")
                if callback:
                    callback(result)
            
            def error_callback(error):
                """é”™è¯¯å›è°ƒ"""
                print(f"âŒ ä»»åŠ¡å¤±è´¥ï¼š{error}")
            
            # æäº¤ä»»åŠ¡
            async_results = []
            for arg in args:
                result = pool.apply_async(
                    func, 
                    (arg,),
                    callback=success_callback,
                    error_callback=error_callback
                )
                async_results.append(result)
            
            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            for result in async_results:
                result.wait()
    
    def get_progress_report(self):
        """è·å–è¿›åº¦æŠ¥å‘Š"""
        total_tasks = len(self.completed_tasks)
        if total_tasks == 0:
            return "ğŸ“Š æš‚æ— å®Œæˆçš„ä»»åŠ¡"
        
        total_time = sum(task['work_time'] for task in self.completed_tasks)
        avg_time = total_time / total_tasks
        
        return f"ğŸ“Š å®Œæˆ {total_tasks} ä¸ªä»»åŠ¡ï¼Œå¹³å‡è€—æ—¶ {avg_time:.1f}ç§’"

if __name__ == "__main__":
    # åŸºç¡€è¿›ç¨‹æ± ä½¿ç”¨
    batch_processor()
    
    print("\n" + "="*60)
    print("ğŸ”§ é«˜çº§è¿›ç¨‹ç®¡ç†å™¨ç¤ºä¾‹")
    
    # é«˜çº§è¿›ç¨‹ç®¡ç†å™¨ä½¿ç”¨
    manager = AdvancedProcessManager(max_workers=3)
    
    def task_complete_handler(result):
        """ä»»åŠ¡å®Œæˆå¤„ç†å‡½æ•°"""
        print(f"ğŸ”” å¤„ç†å®Œæˆé€šçŸ¥ï¼šä»»åŠ¡{result['task_id']} "
              f"åœ¨è¿›ç¨‹ {result['process_name']} ä¸­å®Œæˆ")
    
    # æäº¤ä»»åŠ¡
    task_args = list(range(20, 26))
    manager.submit_task_with_callback(
        long_running_task, 
        task_args, 
        callback=task_complete_handler
    )
    
    # æ˜¾ç¤ºè¿›åº¦æŠ¥å‘Š
    print(manager.get_progress_report())
```

### 8.3 è¿›ç¨‹å¥åº·æ£€æŸ¥å’Œé‡å¯


**ğŸ¥ è¿›ç¨‹å¥åº·ç›‘æ§ç³»ç»Ÿ**ï¼š
```python
import multiprocessing as mp
import time
import signal
import os
from enum import Enum

class ProcessStatus(Enum):
    """è¿›ç¨‹çŠ¶æ€æšä¸¾"""
    STARTING = "å¯åŠ¨ä¸­"
    RUNNING = "è¿è¡Œä¸­" 
    UNHEALTHY = "ä¸å¥åº·"
    CRASHED = "å·²å´©æºƒ"
    STOPPED = "å·²åœæ­¢"

class HealthChecker:
    """è¿›ç¨‹å¥åº·æ£€æŸ¥å™¨"""
    
    def __init__(self, check_interval=5):
        self.check_interval = check_interval
        self.managed_processes = {}
        self.health_reports = {}
    
    def register_process(self, name, process, health_check_func=None):
        """æ³¨å†Œéœ€è¦ç›‘æ§çš„è¿›ç¨‹"""
        self.managed_processes[name] = {
            'process': process,
            'health_check': health_check_func,
            'status': ProcessStatus.STARTING,
            'restart_count': 0,
            'last_check': time.time(),
            'consecutive_failures': 0
        }
        print(f"ğŸ¥ æ³¨å†Œè¿›ç¨‹ç›‘æ§ï¼š{name} (PID: {process.pid})")
    
    def check_process_health(self, name):
        """æ£€æŸ¥å•ä¸ªè¿›ç¨‹å¥åº·çŠ¶æ€"""
        if name not in self.managed_processes:
            return False
        
        process_info = self.managed_processes[name]
        process = process_info['process']
        
        # åŸºç¡€å­˜æ´»æ£€æŸ¥
        if not process.is_alive():
            process_info['status'] = ProcessStatus.CRASHED
            return False
        
        # è‡ªå®šä¹‰å¥åº·æ£€æŸ¥
        health_check_func = process_info['health_check']
        if health_check_func:
            try:
                is_healthy = health_check_func(process)
                if not is_healthy:
                    process_info['consecutive_failures'] += 1
                    if process_info['consecutive_failures'] >= 3:
                        process_info['status'] = ProcessStatus.UNHEALTHY
                        return False
                else:
                    process_info['consecutive_failures'] = 0
                    process_info['status'] = ProcessStatus.RUNNING
            except Exception as e:
                print(f"âŒ å¥åº·æ£€æŸ¥å¼‚å¸¸ï¼š{name} - {e}")
                process_info['status'] = ProcessStatus.UNHEALTHY
                return False
        
        process_info['last_check'] = time.time()
        return True
    
    def restart_process(self, name, target_func, args=None):
        """é‡å¯è¿›ç¨‹"""
        if name not in self.managed_processes:
            return False
        
        process_info = self.managed_processes[name]
        old_process = process_info['process']
        
        print(f"ğŸ”„ é‡å¯è¿›ç¨‹ï¼š{name}")
        
        # ç»ˆæ­¢æ—§è¿›ç¨‹
        if old_process.is_alive():
            old_process.terminate()
            old_process.join(timeout=5)
            if old_process.is_alive():
                old_process.kill()
        
        # åˆ›å»ºæ–°è¿›ç¨‹
        new_process = mp.Process(target=target_func, args=args or ())
        new_process.start()
        
        # æ›´æ–°è¿›ç¨‹ä¿¡æ¯
        process_info['process'] = new_process
        process_info['status'] = ProcessStatus.STARTING
        process_info['restart_count'] += 1
        process_info['consecutive_failures'] = 0
        
        print(f"âœ… è¿›ç¨‹é‡å¯å®Œæˆï¼š{name} (æ–°PID: {new_process.pid}, "
              f"é‡å¯æ¬¡æ•°: {process_info['restart_count']})")
        
        return True
    
    def health_monitor_loop(self, restart_targets=None):
        """å¥åº·ç›‘æ§ä¸»å¾ªç¯"""
        print("ğŸ¥ å¯åŠ¨å¥åº·ç›‘æ§...")
        restart_targets = restart_targets or {}
        
        try:
            while True:
                print(f"\nğŸ” æ‰§è¡Œå¥åº·æ£€æŸ¥... (é—´éš”{self.check_interval}ç§’)")
                
                for name in list(self.managed_processes.keys()):
                    is_healthy = self.check_process_health(name)
                    process_info = self.managed_processes[name]
                    status = process_info['status']
                    
                    status_emoji = {
                        ProcessStatus.RUNNING: "ğŸŸ¢",
                        ProcessStatus.STARTING: "ğŸŸ¡", 
                        ProcessStatus.UNHEALTHY: "ğŸŸ ",
                        ProcessStatus.CRASHED: "ğŸ”´",
                        ProcessStatus.STOPPED: "âš«"
                    }
                    
                    print(f"{status_emoji[status]} {name}: {status.value}")
                    
                    # è‡ªåŠ¨é‡å¯ä¸å¥åº·çš„è¿›ç¨‹
                    if not is_healthy and name in restart_targets:
                        target_func, args = restart_targets[name]
                        if process_info['restart_count'] < 3:  # æœ€å¤šé‡å¯3æ¬¡
                            self.restart_process(name, target_func, args)
                        else:
                            print(f"âš ï¸ è¿›ç¨‹ {name} é‡å¯æ¬¡æ•°è¿‡å¤šï¼Œåœæ­¢è‡ªåŠ¨é‡å¯")
                
                time.sleep(self.check_interval)
                
        except KeyboardInterrupt:
            print("\nâš ï¸ æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œåœæ­¢å¥åº·ç›‘æ§")

def unstable_worker(name, crash_probability=0.1):
    """ä¸ç¨³å®šçš„å·¥ä½œè¿›ç¨‹ï¼ˆå¯èƒ½å´©æºƒï¼‰"""
    print(f"ğŸ’¼ {name} å¼€å§‹å·¥ä½œ...")
    
    try:
        for i in range(100):
            # æ¨¡æ‹Ÿå·¥ä½œ
            time.sleep(1)
            
            # éšæœºå´©æºƒ
            if random.random() < crash_probability:
                print(f"ğŸ’¥ {name} é‡åˆ°é”™è¯¯ï¼Œå³å°†å´©æºƒ...")
                raise Exception(f"{name} æ¨¡æ‹Ÿå´©æºƒ")
            
            if i % 10 == 0:
                print(f"ğŸ’¼ {name} å®Œæˆ {i}% å·¥ä½œ")
        
        print(f"âœ… {name} å®Œæˆæ‰€æœ‰å·¥ä½œ")
        
    except Exception as e:
        print(f"âŒ {name} å¼‚å¸¸é€€å‡ºï¼š{e}")
        raise

def worker_health_check(process):
    """å·¥ä½œè¿›ç¨‹å¥åº·æ£€æŸ¥å‡½æ•°"""
    # ç®€å•çš„å¥åº·æ£€æŸ¥ï¼šæ£€æŸ¥è¿›ç¨‹æ˜¯å¦è¿˜æ´»ç€ä¸”CPUä½¿ç”¨ç‡æ­£å¸¸
    try:
        import psutil
        proc = psutil.Process(process.pid)
        cpu_percent = proc.cpu_percent()
        
        # å¦‚æœCPUä½¿ç”¨ç‡å¼‚å¸¸é«˜ï¼Œè®¤ä¸ºä¸å¥åº·
        if cpu_percent > 90:
            print(f"âš ï¸ è¿›ç¨‹ {process.pid} CPUä½¿ç”¨ç‡è¿‡é«˜: {cpu_percent}%")
            return False
        
        return True
    except:
        return False

if __name__ == "__main__":
    health_checker = HealthChecker(check_interval=3)
    
    # åˆ›å»ºä¸ç¨³å®šçš„å·¥ä½œè¿›ç¨‹
    processes = []
    restart_targets = {}
    
    for i in range(2):
        worker_name = f"ä¸ç¨³å®šå·¥äºº{i+1}"
        process = mp.Process(target=unstable_worker, 
                           args=(worker_name, 0.05))  # 5%å´©æºƒæ¦‚ç‡
        process.start()
        processes.append(process)
        
        # æ³¨å†Œåˆ°å¥åº·æ£€æŸ¥å™¨
        health_checker.register_process(
            worker_name, 
            process, 
            health_check_func=worker_health_check
        )
        
        # è®¾ç½®é‡å¯ç›®æ ‡
        restart_targets[worker_name] = (unstable_worker, (worker_name, 0.05))
    
    # å¯åŠ¨å¥åº·ç›‘æ§
    try:
        health_checker.health_monitor_loop(restart_targets)
    except KeyboardInterrupt:
        print("\nğŸ›‘ æ­£åœ¨åœæ­¢æ‰€æœ‰è¿›ç¨‹...")
        for p in processes:
            if p.is_alive():
                p.terminate()
        
        for p in processes:
            p.join()
        
        print("ğŸ‰ æ‰€æœ‰è¿›ç¨‹å·²åœæ­¢")
```

---

## 9. ğŸ¯ è¿›ç¨‹ç¼–ç¨‹æœ€ä½³å®è·µ


### 9.1 è®¾è®¡åŸåˆ™å’Œæ¨¡å¼


**ğŸ—ï¸ è¿›ç¨‹è®¾è®¡åŸåˆ™**ï¼š

```
ğŸ¯ æ ¸å¿ƒè®¾è®¡åŸåˆ™ï¼š

1. å•ä¸€èŒè´£åŸåˆ™
   æ¯ä¸ªè¿›ç¨‹åªè´Ÿè´£ä¸€ä¸ªæ˜ç¡®çš„åŠŸèƒ½
   âœ… å¥½ï¼šæ•°æ®å¤„ç†è¿›ç¨‹ã€æ–‡ä»¶ç›‘æ§è¿›ç¨‹
   âŒ å·®ï¼šæ—¢å¤„ç†æ•°æ®åˆç›‘æ§æ–‡ä»¶åˆå‘é€é‚®ä»¶

2. æœ€å°å…±äº«åŸåˆ™  
   å°½é‡å‡å°‘è¿›ç¨‹é—´çš„æ•°æ®å…±äº«
   âœ… å¥½ï¼šé€šè¿‡æ¶ˆæ¯ä¼ é€’äº¤æ¢æ•°æ®
   âŒ å·®ï¼šå¤§é‡ä½¿ç”¨å…±äº«å˜é‡

3. æ•…éšœéš”ç¦»åŸåˆ™
   ä¸€ä¸ªè¿›ç¨‹çš„å´©æºƒä¸åº”å½±å“å…¶ä»–è¿›ç¨‹
   âœ… å¥½ï¼šç‹¬ç«‹çš„å·¥ä½œè¿›ç¨‹
   âŒ å·®ï¼šæ‰€æœ‰åŠŸèƒ½åœ¨ä¸€ä¸ªè¿›ç¨‹ä¸­

4. èµ„æºæ¸…ç†åŸåˆ™
   ç¡®ä¿æ‰€æœ‰èµ„æºéƒ½èƒ½æ­£ç¡®é‡Šæ”¾
   âœ… å¥½ï¼šä½¿ç”¨try-finallyæˆ–withè¯­å¥
   âŒ å·®ï¼šå¿˜è®°é‡Šæ”¾é”ã€å…³é—­æ–‡ä»¶
```

**ğŸ”§ å¸¸ç”¨è®¾è®¡æ¨¡å¼**ï¼š
```python
from multiprocessing import Process, Queue, Pool, Manager
import time
import logging

# 1. ç”Ÿäº§è€…-æ¶ˆè´¹è€…æ¨¡å¼
class ProducerConsumerPattern:
    """ç”Ÿäº§è€…-æ¶ˆè´¹è€…æ¨¡å¼å®ç°"""
    
    def __init__(self, num_producers=2, num_consumers=3, queue_size=10):
        self.task_queue = Queue(maxsize=queue_size)
        self.result_queue = Queue()
        self.num_producers = num_producers
        self.num_consumers = num_consumers
        self.shutdown_event = Manager().Event()
    
    def producer(self, producer_id):
        """ç”Ÿäº§è€…è¿›ç¨‹"""
        for i in range(10):
            if self.shutdown_event.is_set():
                break
            
            task = f"ä»»åŠ¡_{producer_id}_{i}"
            self.task_queue.put(task)
            print(f"ğŸ­ ç”Ÿäº§è€…{producer_id} äº§ç”Ÿ: {task}")
            time.sleep(0.5)
        
        print(f"ğŸ›‘ ç”Ÿäº§è€…{producer_id} å®Œæˆ")
    
    def consumer(self, consumer_id):
        """æ¶ˆè´¹è€…è¿›ç¨‹"""
        while not self.shutdown_event.is_set():
            try:
                task = self.task_queue.get(timeout=2)
                
                # å¤„ç†ä»»åŠ¡
                print(f"ğŸ”¨ æ¶ˆè´¹è€…{consumer_id} å¤„ç†: {task}")
                time.sleep(1)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
                
                result = f"{task}_ç»“æœ"
                self.result_queue.put(result)
                
            except:
                continue
        
        print(f"ğŸ›‘ æ¶ˆè´¹è€…{consumer_id} å®Œæˆ")
    
    def run(self):
        """è¿è¡Œç”Ÿäº§è€…-æ¶ˆè´¹è€…ç³»ç»Ÿ"""
        processes = []
        
        # å¯åŠ¨ç”Ÿäº§è€…
        for i in range(self.num_producers):
            p = Process(target=self.producer, args=(i+1,))
            processes.append(p)
            p.start()
        
        # å¯åŠ¨æ¶ˆè´¹è€…
        for i in range(self.num_consumers):
            p = Process(target=self.consumer, args=(i+1,))
            processes.append(p)
            p.start()
        
        # ç­‰å¾…ç”Ÿäº§è€…å®Œæˆ
        for p in processes[:self.num_producers]:
            p.join()
        
        # ç­‰å¾…é˜Ÿåˆ—æ¸…ç©º
        while not self.task_queue.empty():
            time.sleep(0.1)
        
        # åœæ­¢æ¶ˆè´¹è€…
        self.shutdown_event.set()
        
        # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹å®Œæˆ
        for p in processes:
            p.join()
        
        # æ”¶é›†ç»“æœ
        results = []
        while not self.result_queue.empty():
            results.append(self.result_queue.get())
        
        return results

# 2. å·¥ä½œæ± æ¨¡å¼
class WorkerPoolPattern:
    """å·¥ä½œæ± æ¨¡å¼å®ç°"""
    
    def __init__(self, pool_size=4):
        self.pool_size = pool_size
    
    def process_task(self, task_data):
        """å¤„ç†å•ä¸ªä»»åŠ¡"""
        task_id, data = task_data
        print(f"âš™ï¸ å¤„ç†ä»»åŠ¡ {task_id}...")
        
        # æ¨¡æ‹Ÿå¤æ‚å¤„ç†
        result = sum(data) if data else 0
        time.sleep(1)
        
        return {'task_id': task_id, 'result': result, 'status': 'completed'}
    
    def run_batch(self, tasks):
        """æ‰¹é‡å¤„ç†ä»»åŠ¡"""
        print(f"ğŸŠ å¯åŠ¨å·¥ä½œæ± ï¼Œå¤§å°: {self.pool_size}")
        
        with Pool(processes=self.pool_size) as pool:
            # å¹¶è¡Œå¤„ç†æ‰€æœ‰ä»»åŠ¡
            results = pool.map(self.process_task, tasks)
        
        return results

# 3. ç®¡é“æ¨¡å¼
class PipelinePattern:
    """ç®¡é“æ¨¡å¼å®ç°"""
    
    def __init__(self):
        self.stage_queues = [Queue() for _ in range(4)]  # 3ä¸ªå¤„ç†é˜¶æ®µ
    
    def stage1_reader(self, input_data):
        """é˜¶æ®µ1ï¼šæ•°æ®è¯»å–"""
        for i, data in enumerate(input_data):
            processed = {'id': i, 'raw_data': data, 'stage': 1}
            self.stage_queues[0].put(processed)
            print(f"ğŸ“– é˜¶æ®µ1å¤„ç†: {data}")
            time.sleep(0.2)
        
        self.stage_queues[0].put(None)  # ç»“æŸä¿¡å·
    
    def stage2_processor(self):
        """é˜¶æ®µ2ï¼šæ•°æ®å¤„ç†"""
        while True:
            item = self.stage_queues[0].get()
            if item is None:
                self.stage_queues[1].put(None)
                break
            
            # æ•°æ®å¤„ç†
            item['processed_data'] = item['raw_data'] * 2
            item['stage'] = 2
            self.stage_queues[1].put(item)
            print(f"âš™ï¸ é˜¶æ®µ2å¤„ç†: ID={item['id']}")
            time.sleep(0.3)
    
    def stage3_writer(self):
        """é˜¶æ®µ3ï¼šæ•°æ®å†™å…¥"""
        results = []
        while True:
            item = self.stage_queues[1].get()
            if item is None:
                break
            
            # æ•°æ®å†™å…¥
            item['final_result'] = item['processed_data'] + 10
            item['stage'] = 3
            results.append(item)
            print(f"ğŸ’¾ é˜¶æ®µ3å®Œæˆ: ID={item['id']}, ç»“æœ={item['final_result']}")
            time.sleep(0.1)
        
        return results
    
    def run_pipeline(self, input_data):
        """è¿è¡Œç®¡é“"""
        processes = []
        
        # å¯åŠ¨å„ä¸ªé˜¶æ®µ
        p1 = Process(target=self.stage1_reader, args=(input_data,))
        p2 = Process(target=self.stage2_processor)
        p3 = Process(target=self.stage3_writer)
        
        processes = [p1, p2, p3]
        
        for p in processes:
            p.start()
        
        for p in processes:
            p.join()

if __name__ == "__main__":
    print("ğŸ¯ è¿›ç¨‹è®¾è®¡æ¨¡å¼ç¤ºä¾‹\n")
    
    # ç¤ºä¾‹1ï¼šç”Ÿäº§è€…-æ¶ˆè´¹è€…æ¨¡å¼
    print("=" * 50)
    print("ğŸ“¦ ç”Ÿäº§è€…-æ¶ˆè´¹è€…æ¨¡å¼")
    pc_system = ProducerConsumerPattern(num_producers=2, num_consumers=2)
    results = pc_system.run()
    print(f"âœ… æ”¶é›†åˆ° {len(results)} ä¸ªç»“æœ")
    
    # ç¤ºä¾‹2ï¼šå·¥ä½œæ± æ¨¡å¼
    print("\n" + "=" * 50)
    print("ğŸŠ å·¥ä½œæ± æ¨¡å¼")
    worker_pool = WorkerPoolPattern(pool_size=3)
    tasks = [(f"task_{i}", [i, i*2, i*3]) for i in range(10)]
    pool_results = worker_pool.run_batch(tasks)
    print(f"âœ… å·¥ä½œæ± å¤„ç†å®Œæˆï¼Œå…± {len(pool_results)} ä¸ªä»»åŠ¡")
    
    # ç¤ºä¾‹3ï¼šç®¡é“æ¨¡å¼
    print("\n" + "=" * 50)
    print("ğŸ”— ç®¡é“æ¨¡å¼")
    pipeline = PipelinePattern()
    input_data = [10, 20, 30, 40, 50]
    pipeline.run_pipeline(input_data)
    print("âœ… ç®¡é“å¤„ç†å®Œæˆ")
```

### 9.2 æ€§èƒ½ä¼˜åŒ–å»ºè®®


**âš¡ æ€§èƒ½ä¼˜åŒ–è¦ç‚¹**ï¼š

> **ğŸ¯ è¿›ç¨‹æ•°é‡ä¼˜åŒ–**
> 
> ```python
> import os
> 
> # æ ¹æ®CPUæ ¸å¿ƒæ•°ç¡®å®šè¿›ç¨‹æ•°é‡
> cpu_count = os.cpu_count()
> 
> # CPUå¯†é›†å‹ä»»åŠ¡ï¼šè¿›ç¨‹æ•° = CPUæ ¸å¿ƒæ•°
> cpu_intensive_processes = cpu_count
> 
> # IOå¯†é›†å‹ä»»åŠ¡ï¼šè¿›ç¨‹æ•° = CPUæ ¸å¿ƒæ•° * 2-4
> io_intensive_processes = cpu_count * 2
> 
> print(f"ğŸ’» CPUæ ¸å¿ƒæ•°: {cpu_count}")
> print(f"ğŸ”¥ CPUå¯†é›†å‹æ¨èè¿›ç¨‹æ•°: {cpu_intensive_processes}")
> print(f"ğŸ’¿ IOå¯†é›†å‹æ¨èè¿›ç¨‹æ•°: {io_intensive_processes}")
> ```

**ğŸ“Š æ€§èƒ½æµ‹è¯•å’Œå¯¹æ¯”**ï¼š
```python
import time
import multiprocessing as mp
from concurrent.futures import ProcessPoolExecutor
import statistics

def cpu_bound_task(n):
    """CPUå¯†é›†å‹ä»»åŠ¡"""
    total = 0
    for i in range(n):
        total += i ** 2
    return total

def io_bound_task(duration):
    """IOå¯†é›†å‹ä»»åŠ¡æ¨¡æ‹Ÿ"""
    time.sleep(duration)
    return f"IOä»»åŠ¡å®Œæˆï¼Œè€—æ—¶{duration}ç§’"

class PerformanceTester:
    """æ€§èƒ½æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.results = {}
    
    def test_serial_execution(self, task_func, task_args, test_name):
        """æµ‹è¯•ä¸²è¡Œæ‰§è¡Œ"""
        print(f"ğŸ”„ æµ‹è¯•ä¸²è¡Œæ‰§è¡Œ: {test_name}")
        start_time = time.time()
        
        results = []
        for arg in task_args:
            result = task_func(arg)
            results.append(result)
        
        end_time = time.time()
        execution_time = end_time - start_time
        
        self.results[f"{test_name}_ä¸²è¡Œ"] = execution_time
        print(f"â±ï¸ ä¸²è¡Œæ‰§è¡Œè€—æ—¶: {execution_time:.2f}ç§’")
        return results, execution_time
    
    def test_multiprocess_execution(self, task_func, task_args, test_name, num_processes=None):
        """æµ‹è¯•å¤šè¿›ç¨‹æ‰§è¡Œ"""
        if num_processes is None:
            num_processes = mp.cpu_count()
        
        print(f"ğŸš€ æµ‹è¯•å¤šè¿›ç¨‹æ‰§è¡Œ: {test_name} (è¿›ç¨‹æ•°: {num_processes})")
        start_time = time.time()
        
        with ProcessPoolExecutor(max_workers=num_processes) as executor:
            results = list(executor.map(task_func, task_args))
        
        end_time = time.time()
        execution_time = end_time - start_time
        
        self.results[f"{test_name}_å¤šè¿›ç¨‹({num_processes})"] = execution_time
        print(f"â±ï¸ å¤šè¿›ç¨‹æ‰§è¡Œè€—æ—¶: {execution_time:.2f}ç§’")
        return results, execution_time
    
    def compare_performance(self):
        """æ€§èƒ½å¯¹æ¯”åˆ†æ"""
        print("\n" + "="*60)
        print("ğŸ“Š æ€§èƒ½å¯¹æ¯”æŠ¥å‘Š")
        print("="*60)
        
        for test_name, execution_time in self.results.items():
            print(f"{test_name:25}: {execution_time:8.2f}ç§’")
        
        # è®¡ç®—åŠ é€Ÿæ¯”
        serial_times = {k: v for k, v in self.results.items() if "ä¸²è¡Œ" in k}
        parallel_times = {k: v for k, v in self.results.items() if "å¤šè¿›ç¨‹" in k}
        
        print("\nğŸ“ˆ åŠ é€Ÿæ¯”åˆ†æ:")
        for serial_key, serial_time in serial_times.items():
            test_base = serial_key.replace("_ä¸²è¡Œ", "")
            for parallel_key, parallel_time in parallel_times.items():
                if test_base in parallel_key:
                    speedup = serial_time / parallel_time
                    efficiency = speedup / mp.cpu_count() * 100
                    print(f"{parallel_key:25}: {speedup:5.2f}x "
                          f"(æ•ˆç‡: {efficiency:5.1f}%)")

if __name__ == "__main__":
    tester = PerformanceTester()
    
    # æµ‹è¯•CPUå¯†é›†å‹ä»»åŠ¡
    print("ğŸ”¥ CPUå¯†é›†å‹ä»»åŠ¡æµ‹è¯•")
    cpu_tasks = [100000] * 8  # 8ä¸ªç›¸åŒçš„CPUä»»åŠ¡
    
    tester.test_serial_execution(cpu_bound_task, cpu_tasks, "CPUå¯†é›†")
    tester.test_multiprocess_execution(cpu_bound_task, cpu_tasks, "CPUå¯†é›†", 2)
    tester.test_multiprocess_execution(cpu_bound_task, cpu_tasks, "CPUå¯†é›†", 4)
    tester.test_multiprocess_execution(cpu_bound_task, cpu_tasks, "CPUå¯†é›†", 8)
    
    # æµ‹è¯•IOå¯†é›†å‹ä»»åŠ¡
    print(f"\nğŸ’¿ IOå¯†é›†å‹ä»»åŠ¡æµ‹è¯•")
    io_tasks = [1] * 8  # 8ä¸ªIOä»»åŠ¡ï¼Œæ¯ä¸ª1ç§’
    
    tester.test_serial_execution(io_bound_task, io_tasks, "IOå¯†é›†")
    tester.test_multiprocess_execution(io_bound_task, io_tasks, "IOå¯†é›†", 2)
    tester.test_multiprocess_execution(io_bound_task, io_tasks, "IOå¯†é›†", 4)
    tester.test_multiprocess_execution(io_bound_task, io_tasks, "IOå¯†é›†", 8)
    
    # æ€§èƒ½å¯¹æ¯”
    tester.compare_performance()
```

### 9.3 é”™è¯¯å¤„ç†å’Œè°ƒè¯•


**ğŸ› å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ**ï¼š

```python
import multiprocessing as mp
import traceback
import logging
import sys
from functools import wraps

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(processName)s - %(levelname)s - %(message)s'
)

def safe_process(func):
    """è¿›ç¨‹å®‰å…¨è£…é¥°å™¨"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except Exception as e:
            # è®°å½•è¯¦ç»†é”™è¯¯ä¿¡æ¯
            error_info = {
                'function': func.__name__,
                'args': str(args),
                'kwargs': str(kwargs),
                'error': str(e),
                'traceback': traceback.format_exc()
            }
            logging.error(f"è¿›ç¨‹å¼‚å¸¸: {error_info}")
            raise
    return wrapper

class ProcessErrorHandler:
    """è¿›ç¨‹é”™è¯¯å¤„ç†å™¨"""
    
    def __init__(self):
        self.error_log = []
    
    @safe_process
    def risky_worker(self, task_id, should_fail=False):
        """å¯èƒ½å‡ºé”™çš„å·¥ä½œè¿›ç¨‹"""
        logging.info(f"å¼€å§‹å¤„ç†ä»»åŠ¡ {task_id}")
        
        if should_fail and task_id % 3 == 0:
            # æ¨¡æ‹Ÿé”™è¯¯
            raise ValueError(f"ä»»åŠ¡ {task_id} æ¨¡æ‹Ÿå¤±è´¥")
        
        # æ­£å¸¸å¤„ç†
        time.sleep(1)
        result = task_id * 2
        
        logging.info(f"ä»»åŠ¡ {task_id} å®Œæˆï¼Œç»“æœ: {result}")
        return result
    
    def error_callback(self, error):
        """é”™è¯¯å›è°ƒå‡½æ•°"""
        error_msg = f"è¿›ç¨‹æ‰§è¡Œå¤±è´¥: {error}"
        self.error_log.append(error_msg)
        logging.error(error_msg)
    
    def success_callback(self, result):
        """æˆåŠŸå›è°ƒå‡½æ•°"""
        logging.info(f"ä»»åŠ¡æˆåŠŸå®Œæˆï¼Œç»“æœ: {result}")
    
    def run_with_error_handling(self):
        """å¸¦é”™è¯¯å¤„ç†çš„è¿›ç¨‹æ‰§è¡Œ"""
        print("ğŸ›¡ï¸ å¯åŠ¨å¸¦é”™è¯¯å¤„ç†çš„è¿›ç¨‹æ± ...")
        
        with mp.Pool(processes=3) as pool:
            async_results = []
            
            # æäº¤ä»»åŠ¡ï¼ˆå…¶ä¸­ä¸€äº›ä¼šå¤±è´¥ï¼‰
            for i in range(10):
                result = pool.apply_async(
                    self.risky_worker,
                    args=(i, True),  # should_fail=True
                    callback=self.success_callback,
                    error_callback=self.error_callback
                )
                async_results.append(result)
            
            # æ”¶é›†ç»“æœ
            successful_results = []
            failed_count = 0
            
            for result in async_results:
                try:
                    value = result.get(timeout=10)
                    successful_results.append(value)
                except Exception as e:
                    failed_count += 1
                    logging.error(f"è·å–ç»“æœå¤±è´¥: {e}")
            
            print(f"âœ… æˆåŠŸä»»åŠ¡: {len(successful_results)}")
            print(f"âŒ å¤±è´¥ä»»åŠ¡: {failed_count}")
            print(f"ğŸ“‹ é”™è¯¯æ—¥å¿—æ¡æ•°: {len(self.error_log)}")

class ProcessDebuggingTools:
    """è¿›ç¨‹è°ƒè¯•å·¥å…·"""
    
    @staticmethod
    def debug_process_info():
        """æ‰“å°è¿›ç¨‹è°ƒè¯•ä¿¡æ¯"""
        current = mp.current_process()
        parent = mp.parent_process()
        
        debug_info = {
            'å½“å‰è¿›ç¨‹å': current.name,
            'å½“å‰è¿›ç¨‹PID': current.pid,
            'çˆ¶è¿›ç¨‹PID': parent.pid if parent else 'None',
            'CPUæ ¸å¿ƒæ•°': mp.cpu_count(),
            'æ´»è·ƒå­è¿›ç¨‹æ•°': len(mp.active_children())
        }
        
        print("ğŸ” è¿›ç¨‹è°ƒè¯•ä¿¡æ¯:")
        for key, value in debug_info.items():
            print(f"  {key}: {value}")
    
    @staticmethod
    def monitor_process_resources(duration=10):
        """ç›‘æ§è¿›ç¨‹èµ„æºä½¿ç”¨"""
        try:
            import psutil
        except ImportError:
            print("âŒ éœ€è¦å®‰è£…psutil: pip install psutil")
            return
        
        print(f"ğŸ“Š ç›‘æ§è¿›ç¨‹èµ„æº {duration} ç§’...")
        
        start_time = time.time()
        while time.time() - start_time < duration:
            # è·å–å½“å‰è¿›ç¨‹ä¿¡æ¯
            process = psutil.Process()
            
            cpu_percent = process.cpu_percent()
            memory_info = process.memory_info()
            memory_mb = memory_info.rss / 1024 / 1024
            
            print(f"â±ï¸ {time.time() - start_time:5.1f}s | "
                  f"CPU: {cpu_percent:5.1f}% | "
                  f"å†…å­˜: {memory_mb:6.1f}MB")
            
            time.sleep(1)

if __name__ == "__main__":
    print("ğŸ›¡ï¸ è¿›ç¨‹é”™è¯¯å¤„ç†å’Œè°ƒè¯•ç¤ºä¾‹\n")
    
    # è°ƒè¯•ä¿¡æ¯
    ProcessDebuggingTools.debug_process_info()
    
    # é”™è¯¯å¤„ç†ç¤ºä¾‹
    print("\n" + "="*50)
    error_handler = ProcessErrorHandler()
    error_handler.run_with_error_handling()
    
    # èµ„æºç›‘æ§ï¼ˆå¯é€‰ï¼‰
    print("\n" + "="*50)
    print("æ˜¯å¦è¦å¯åŠ¨èµ„æºç›‘æ§ï¼Ÿ(è¾“å…¥yç¡®è®¤ï¼Œå…¶ä»–é”®è·³è¿‡)")
    if input().lower() == 'y':
        ProcessDebuggingTools.monitor_process_resources(5)
```

---

## 10. ğŸ“‹ æ ¸å¿ƒè¦ç‚¹æ€»ç»“


### 10.1 å¿…é¡»æŒæ¡çš„åŸºæœ¬æ¦‚å¿µ


```
ğŸ”¸ è¿›ç¨‹åŒæ­¥æœ¬è´¨ï¼šè§£å†³å¤šè¿›ç¨‹è®¿é—®å…±äº«èµ„æºçš„å†²çªé—®é¢˜
ğŸ”¸ Lockï¼ˆé”ï¼‰ï¼šæœ€åŸºæœ¬çš„äº’æ–¥æœºåˆ¶ï¼ŒåŒæ—¶åªå…è®¸ä¸€ä¸ªè¿›ç¨‹è®¿é—®
ğŸ”¸ Semaphoreï¼ˆä¿¡å·é‡ï¼‰ï¼šæ§åˆ¶åŒæ—¶è®¿é—®èµ„æºçš„è¿›ç¨‹æ•°é‡
ğŸ”¸ Eventï¼ˆäº‹ä»¶ï¼‰ï¼šç®€å•çš„è¿›ç¨‹é—´é€šçŸ¥å’Œåè°ƒæœºåˆ¶
ğŸ”¸ å…±äº«å†…å­˜ï¼šé«˜æ•ˆçš„å¤§æ•°æ®é‡è¿›ç¨‹é—´å…±äº«æ–¹å¼
ğŸ”¸ Value/Arrayï¼šç®€å•æ•°æ®çš„è¿›ç¨‹é—´å…±äº«å˜é‡
```

### 10.2 å…³é”®ç†è§£è¦ç‚¹


**ğŸ”¹ åŒæ­¥æœºåˆ¶çš„é€‰æ‹©åŸåˆ™**ï¼š
```
Lockï¼š
âœ… é€‚ç”¨ï¼šä¸¥æ ¼äº’æ–¥ï¼ŒåŒæ—¶åªèƒ½ä¸€ä¸ªè¿›ç¨‹
ğŸ¯ åœºæ™¯ï¼šä¿®æ”¹å…±äº«å˜é‡ã€æ–‡ä»¶å†™å…¥

Semaphoreï¼š  
âœ… é€‚ç”¨ï¼šé™åˆ¶å¹¶å‘æ•°é‡ï¼Œå¦‚è¿æ¥æ± 
ğŸ¯ åœºæ™¯ï¼šæ•°æ®åº“è¿æ¥ã€ä¸‹è½½é™åˆ¶

Eventï¼š
âœ… é€‚ç”¨ï¼šç®€å•çš„å¯åŠ¨/åœæ­¢ä¿¡å·
ğŸ¯ åœºæ™¯ï¼šè¿›ç¨‹åè°ƒã€æ‰¹é‡æ§åˆ¶

å…±äº«å†…å­˜ï¼š
âœ… é€‚ç”¨ï¼šå¤§æ•°æ®é‡ã€é«˜æ€§èƒ½è¦æ±‚
ğŸ¯ åœºæ™¯ï¼šå›¾åƒå¤„ç†ã€ç§‘å­¦è®¡ç®—

Value/Arrayï¼š
âœ… é€‚ç”¨ï¼šç®€å•æ•°å€¼ã€å°æ•°ç»„
ğŸ¯ åœºæ™¯ï¼šè®¡æ•°å™¨ã€é…ç½®å‚æ•°
```

**ğŸ”¹ æ•°æ®äº¤æ¢æ–¹å¼å¯¹æ¯”**ï¼š
```
é€Ÿåº¦æ’åºï¼šshared_memory > Pipe > Value/Array > Queue > Manager
æ˜“ç”¨æ’åºï¼šManager > Queue > Value/Array > Pipe > shared_memory
å®‰å…¨æ’åºï¼šQueue > Manager > Value/Array > Pipe > shared_memory
```

**ğŸ”¹ æ€§èƒ½ä¼˜åŒ–è¦ç‚¹**ï¼š
```
è¿›ç¨‹æ•°é‡ï¼š
â€¢ CPUå¯†é›†å‹ = CPUæ ¸å¿ƒæ•°
â€¢ IOå¯†é›†å‹ = CPUæ ¸å¿ƒæ•° Ã— 2-4

èµ„æºç®¡ç†ï¼š
â€¢ æ€»æ˜¯é‡Šæ”¾é”å’Œå…±äº«å†…å­˜
â€¢ ä½¿ç”¨withè¯­å¥è‡ªåŠ¨ç®¡ç†èµ„æº
â€¢ é¿å…è¿›ç¨‹æ•°é‡è¿‡å¤šçš„å¼€é”€

é€šä¿¡é€‰æ‹©ï¼š
â€¢ å¤§æ•°æ®ä¼˜å…ˆå…±äº«å†…å­˜
â€¢ ç®€å•æ¶ˆæ¯ä¼˜å…ˆQueue
â€¢ åŒå‘é€šä¿¡ä¼˜å…ˆPipe
```

### 10.3 æœ€ä½³å®è·µæ€»ç»“


**ğŸ¯ è®¾è®¡åŸåˆ™**ï¼š
- **å•ä¸€èŒè´£**ï¼šæ¯ä¸ªè¿›ç¨‹åªåšä¸€ä»¶äº‹
- **æœ€å°å…±äº«**ï¼šå‡å°‘è¿›ç¨‹é—´æ•°æ®ä¾èµ–
- **æ•…éšœéš”ç¦»**ï¼šè¿›ç¨‹å´©æºƒä¸å½±å“å…¶ä»–è¿›ç¨‹
- **èµ„æºæ¸…ç†**ï¼šç¡®ä¿æ‰€æœ‰èµ„æºæ­£ç¡®é‡Šæ”¾

**ğŸ›¡ï¸ é”™è¯¯å¤„ç†**ï¼š
- **å¼‚å¸¸æ•è·**ï¼šä½¿ç”¨try-exceptå¤„ç†è¿›ç¨‹å¼‚å¸¸
- **è¶…æ—¶æœºåˆ¶**ï¼šé¿å…è¿›ç¨‹æ— é™ç­‰å¾…
- **é‡è¯•ç­–ç•¥**ï¼šå¯¹å¤±è´¥çš„æ“ä½œè¿›è¡Œé€‚å½“é‡è¯•
- **ç›‘æ§æŠ¥è­¦**ï¼šå®æ—¶ç›‘æ§è¿›ç¨‹å¥åº·çŠ¶æ€

**âš¡ æ€§èƒ½å»ºè®®**ï¼š
- **åˆç†è®¾ç½®è¿›ç¨‹æ•°é‡**ï¼šæ ¹æ®ä»»åŠ¡ç±»å‹è°ƒæ•´
- **é€‰æ‹©åˆé€‚çš„é€šä¿¡æ–¹å¼**ï¼šå¹³è¡¡æ€§èƒ½å’Œæ˜“ç”¨æ€§
- **é¿å…é¢‘ç¹åˆ›å»ºé”€æ¯è¿›ç¨‹**ï¼šä½¿ç”¨è¿›ç¨‹æ± 
- **ç›‘æ§èµ„æºä½¿ç”¨**ï¼šCPUã€å†…å­˜ã€IOä½¿ç”¨æƒ…å†µ

### 10.4 å®é™…åº”ç”¨ä»·å€¼


**ğŸ’¼ ä¸šåŠ¡åœºæ™¯åº”ç”¨**ï¼š
- **WebæœåŠ¡å™¨**ï¼šå¤šè¿›ç¨‹å¤„ç†HTTPè¯·æ±‚
- **æ•°æ®å¤„ç†**ï¼šå¹¶è¡Œå¤„ç†å¤§æ•°æ®é›†
- **åå°ä»»åŠ¡**ï¼šå¼‚æ­¥æ‰§è¡Œè€—æ—¶æ“ä½œ
- **å®æ—¶ç³»ç»Ÿ**ï¼šè¿›ç¨‹é—´åè°ƒå’Œé€šä¿¡
- **ç§‘å­¦è®¡ç®—**ï¼šå¹¶è¡Œç®—æ³•å’ŒçŸ©é˜µè¿ç®—

**ğŸ”§ å¼€å‘å®è·µ**ï¼š
- **æµ‹è¯•é©±åŠ¨**ï¼šç¼–å†™å•å…ƒæµ‹è¯•éªŒè¯åŒæ­¥é€»è¾‘
- **æ¸è¿›å¼€å‘**ï¼šå…ˆå•è¿›ç¨‹åå¤šè¿›ç¨‹
- **æ€§èƒ½åˆ†æ**ï¼šä½¿ç”¨å·¥å…·æµ‹é‡å’Œä¼˜åŒ–æ€§èƒ½
- **æ–‡æ¡£è®°å½•**ï¼šè¯¦ç»†è®°å½•è¿›ç¨‹é—´äº¤äº’é€»è¾‘

**ğŸ“ å­¦ä¹ è·¯å¾„å»ºè®®**ï¼š
```
ğŸŒ± å…¥é—¨é˜¶æ®µï¼šæŒæ¡Lockã€EventåŸºæœ¬ç”¨æ³•
ğŸŒ¿ è¿›é˜¶é˜¶æ®µï¼šç†è§£å…±äº«å†…å­˜ã€ä¿¡å·é‡æœºåˆ¶  
ğŸŒ³ é«˜çº§é˜¶æ®µï¼šè®¾è®¡å¤æ‚çš„å¤šè¿›ç¨‹ç³»ç»Ÿ
ğŸŒ² ä¸“å®¶é˜¶æ®µï¼šä¼˜åŒ–æ€§èƒ½ã€å¤„ç†è¾¹ç•Œæƒ…å†µ
```

**ğŸ§  æ ¸å¿ƒè®°å¿†å£è¯€**ï¼š
```
é”ä¿äº’æ–¥ä¸€å¯¹ä¸€ï¼Œä¿¡å·é‡æ¥é™æ•°é‡
äº‹ä»¶é€šçŸ¥ç®€å•ç”¨ï¼Œå…±äº«å†…å­˜æœ€é«˜æ•ˆ  
Queueç®¡é“ä¼ æ¶ˆæ¯ï¼ŒValueæ•°ç»„å­˜æ•°æ®
è®¾è®¡åŸåˆ™è¦ç‰¢è®°ï¼Œèµ„æºæ¸…ç†åˆ«å¿˜è®°
```

---

**ğŸ’¡ å­¦ä¹ å»ºè®®**ï¼š
1. **åŠ¨æ‰‹å®è·µ**ï¼šæ¯ä¸ªæ¦‚å¿µéƒ½è¦å†™ä»£ç éªŒè¯
2. **å¾ªåºæ¸è¿›**ï¼šä»ç®€å•ç¤ºä¾‹åˆ°å¤æ‚åº”ç”¨
3. **ç†è§£åŸç†**ï¼šä¸ä»…çŸ¥é“æ€ä¹ˆç”¨ï¼Œè¿˜è¦çŸ¥é“ä¸ºä»€ä¹ˆ
4. **æ€§èƒ½æµ‹è¯•**ï¼šå®é™…æµ‹é‡ä¸åŒæ–¹æ¡ˆçš„æ€§èƒ½å·®å¼‚
5. **é”™è¯¯å¤„ç†**ï¼šé‡è§†å¼‚å¸¸æƒ…å†µçš„å¤„ç†å’Œè°ƒè¯•

