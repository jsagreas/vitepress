---
title: 6、日志系统
---
## 📚 目录

1. [日志系统基础概念](#1-日志系统基础概念)
2. [logging模块详解](#2-logging模块详解)
3. [日志级别设置](#3-日志级别设置)
4. [日志格式化](#4-日志格式化)
5. [日志输出目标](#5-日志输出目标)
6. [日志轮转管理](#6-日志轮转管理)
7. [结构化日志](#7-结构化日志)
8. [分布式日志](#8-分布式日志)
9. [日志性能优化](#9-日志性能优化)
10. [核心要点总结](#10-核心要点总结)

---

## 1. 📝 日志系统基础概念


### 1.1 什么是日志系统


**通俗理解**：日志就像程序的"日记本"，记录程序运行时发生的各种事情。

```
想象一下你的日记：
今天8点起床 ← 普通信息
今天忘带钥匙了 ← 警告信息  
今天摔了一跤 ← 错误信息
今天考试得了满分 ← 重要信息

程序的日志也是这样，记录程序的"生活轨迹"
```

**为什么需要日志**：
- 🔍 **问题排查**：当程序出错时，通过日志找到原因
- 📊 **运行监控**：了解程序是否正常运行
- 📈 **性能分析**：分析程序哪里运行慢
- 🛡️ **安全审计**：记录谁做了什么操作

### 1.2 日志vs打印的区别


| 方面 | print() | logging |
|------|---------|---------|
| **用途** | 调试时临时查看 | 正式的信息记录 |
| **输出控制** | 难以控制 | 可以精确控制 |
| **信息分类** | 无分类 | 有级别分类 |
| **格式** | 简单 | 可定制格式 |
| **性能** | 一般 | 可优化 |

**简单对比示例**：
```python
# 用print方式 - 不推荐
def calculate(a, b):
    print(f"开始计算: {a} + {b}")
    result = a + b
    print(f"计算结果: {result}")
    return result

# 用logging方式 - 推荐
import logging
def calculate(a, b):
    logging.info(f"开始计算: {a} + {b}")
    result = a + b
    logging.info(f"计算结果: {result}")
    return result
```

---

## 2. 🔧 logging模块详解


### 2.1 logging模块的核心组件


**四大核心组件**：
```
Logger (记录器) ← 程序的"笔"，用来写日志
Handler (处理器) ← 日志的"去处"，决定日志写到哪里
Formatter (格式器) ← 日志的"样式"，决定日志长什么样
Filter (过滤器) ← 日志的"筛子"，决定哪些日志要记录
```

**组件关系图**：
```
你的程序 → Logger → Handler → 输出目标
            ↓        ↓
        Formatter  Filter
```

### 2.2 最简单的日志使用


**入门级使用**：
```python
import logging

# 直接使用，最简单
logging.debug("这是调试信息")
logging.info("这是一般信息") 
logging.warning("这是警告信息")
logging.error("这是错误信息")
logging.critical("这是严重错误")
```

> **💡 注意**：默认情况下，只有WARNING及以上级别的日志会显示

### 2.3 配置基础日志


**基础配置方法**：
```python
import logging

# 配置日志的基本设置
logging.basicConfig(
    level=logging.INFO,           # 设置最低级别
    format='%(asctime)s - %(levelname)s - %(message)s',  # 设置格式
    filename='app.log'            # 输出到文件
)

logging.info("程序开始运行")
logging.warning("这是一个警告")
```

**运行结果**：
```
2025-01-21 10:30:15,123 - INFO - 程序开始运行
2025-01-21 10:30:15,124 - WARNING - 这是一个警告
```

---

## 3. 📊 日志级别设置


### 3.1 五大日志级别详解


| 级别 | 数值 | 使用场景 | 生活类比 |
|------|------|----------|----------|
| **DEBUG** | 10 | 程序调试时的详细信息 | 📝 记录每个小动作 |
| **INFO** | 20 | 程序正常运行的信息 | 📰 记录重要事件 |
| **WARNING** | 30 | 可能有问题，但不影响运行 | ⚠️ 提醒注意 |
| **ERROR** | 40 | 程序出错，但还能继续 | ❌ 记录失败 |
| **CRITICAL** | 50 | 严重错误，程序可能崩溃 | 🚨 紧急情况 |

### 3.2 级别的实际应用


**不同场景的级别选择**：
```python
import logging

logging.basicConfig(level=logging.DEBUG)

def user_login(username, password):
    logging.debug(f"尝试登录用户: {username}")  # 调试信息
    
    if not username:
        logging.error("用户名不能为空")  # 错误
        return False
        
    if len(password) < 6:
        logging.warning(f"用户 {username} 密码长度不足")  # 警告
        return False
        
    # 模拟登录成功
    logging.info(f"用户 {username} 登录成功")  # 正常信息
    return True

# 测试
user_login("", "123")
user_login("alice", "123")  
user_login("bob", "123456")
```

### 3.3 动态调整日志级别


**运行时调整级别**：
```python
import logging

logger = logging.getLogger()

# 开发阶段：查看所有信息
logger.setLevel(logging.DEBUG)
logging.debug("这是调试信息")  # 会显示

# 生产阶段：只关注重要信息
logger.setLevel(logging.WARNING)
logging.debug("这是调试信息")  # 不会显示
logging.warning("这是警告")    # 会显示
```

**环境变量控制级别**：
```python
import os
import logging

# 从环境变量读取日志级别
log_level = os.getenv('LOG_LEVEL', 'INFO')
logging.basicConfig(level=getattr(logging, log_level.upper()))
```

---

## 4. 🎨 日志格式化


### 4.1 格式化基础概念


**格式化就是"美化"日志**，让日志更容易阅读和分析。

**常用格式化字段**：
```python
%(asctime)s     # 时间：2025-01-21 10:30:15
%(name)s        # 记录器名字
%(levelname)s   # 级别名：INFO, ERROR等
%(message)s     # 日志消息内容
%(filename)s    # 文件名
%(lineno)d      # 行号
%(funcName)s    # 函数名
```

### 4.2 自定义日志格式


**基础格式示例**：
```python
import logging

# 简单格式
simple_format = '%(levelname)s: %(message)s'

# 详细格式  
detailed_format = '%(asctime)s - %(name)s - %(levelname)s - %(filename)s:%(lineno)d - %(message)s'

# 应用格式
logging.basicConfig(
    level=logging.INFO,
    format=detailed_format
)

logging.info("这是测试消息")
```

**输出效果对比**：
```
# 简单格式
INFO: 这是测试消息

# 详细格式  
2025-01-21 10:30:15,123 - root - INFO - test.py:15 - 这是测试消息
```

### 4.3 时间格式定制


**自定义时间显示**：
```python
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'  # 自定义时间格式
)

logging.info("测试时间格式")
# 输出: 2025-01-21 10:30:15 [INFO] 测试时间格式
```

**常用时间格式**：
```python
'%Y-%m-%d %H:%M:%S'        # 2025-01-21 10:30:15
'%Y/%m/%d %I:%M:%S %p'     # 2025/01/21 10:30:15 AM  
'%m-%d %H:%M'              # 01-21 10:30
```

### 4.4 彩色日志格式


**为不同级别添加颜色**：
```python
import logging

class ColorFormatter(logging.Formatter):
    """彩色日志格式器"""
    
    # ANSI颜色代码
    COLORS = {
        'DEBUG': '\033[36m',    # 青色
        'INFO': '\033[32m',     # 绿色
        'WARNING': '\033[33m',  # 黄色
        'ERROR': '\033[31m',    # 红色
        'CRITICAL': '\033[35m', # 紫色
        'RESET': '\033[0m'      # 重置
    }
    
    def format(self, record):
        log_color = self.COLORS.get(record.levelname, self.COLORS['RESET'])
        record.levelname = f"{log_color}{record.levelname}{self.COLORS['RESET']}"
        return super().format(record)

# 使用彩色格式器
logger = logging.getLogger()
handler = logging.StreamHandler()
handler.setFormatter(ColorFormatter('%(asctime)s - %(levelname)s - %(message)s'))
logger.addHandler(handler)
logger.setLevel(logging.DEBUG)
```

---

## 5. 📤 日志输出目标


### 5.1 输出目标类型


**三种主要输出方式**：
```
控制台输出 ← 开发调试时使用
文件输出   ← 生产环境保存日志
网络输出   ← 集中化日志管理
```

### 5.2 控制台输出 (StreamHandler)


**基础控制台输出**：
```python
import logging

# 创建记录器
logger = logging.getLogger('my_app')
logger.setLevel(logging.DEBUG)

# 创建控制台处理器
console_handler = logging.StreamHandler()
console_handler.setLevel(logging.INFO)

# 设置格式
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
console_handler.setFormatter(formatter)

# 添加处理器到记录器
logger.addHandler(console_handler)

# 测试
logger.info("这会显示在控制台")
logger.debug("这不会显示(级别太低)")
```

### 5.3 文件输出 (FileHandler)


**基础文件输出**：
```python
import logging

logger = logging.getLogger('file_logger')
logger.setLevel(logging.DEBUG)

# 创建文件处理器
file_handler = logging.FileHandler('app.log', encoding='utf-8')
file_handler.setLevel(logging.DEBUG)

# 设置格式
formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
file_handler.setFormatter(formatter)

logger.addHandler(file_handler)

# 测试
logger.info("这会写入文件")
logger.error("错误也会写入文件")
```

### 5.4 同时输出到多个目标


**控制台+文件双输出**：
```python
import logging

def setup_logger(name, log_file, level=logging.INFO):
    """配置一个同时输出到控制台和文件的记录器"""
    
    logger = logging.getLogger(name)
    logger.setLevel(level)
    
    # 文件处理器
    file_handler = logging.FileHandler(log_file, encoding='utf-8')
    file_handler.setLevel(level)
    
    # 控制台处理器
    console_handler = logging.StreamHandler()
    console_handler.setLevel(level)
    
    # 设置格式
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    file_handler.setFormatter(formatter)
    console_handler.setFormatter(formatter)
    
    # 添加处理器
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    
    return logger

# 使用
app_logger = setup_logger('app', 'app.log')
app_logger.info("这条日志会同时显示在控制台和保存到文件")
```

---

## 6. 🔄 日志轮转管理


### 6.1 为什么需要日志轮转


**问题**：程序长时间运行，日志文件会越来越大，最终可能：
- 💾 占满磁盘空间
- 🐌 文件太大难以打开
- 🔍 查找信息困难

**解决方案**：日志轮转 = 自动管理日志文件大小和数量

### 6.2 按大小轮转 (RotatingFileHandler)


**当文件达到指定大小时自动切换**：
```python
import logging
from logging.handlers import RotatingFileHandler

logger = logging.getLogger('rotating_logger')
logger.setLevel(logging.DEBUG)

# 创建轮转处理器
# maxBytes: 单个文件最大字节数
# backupCount: 保留的备份文件数量
rotating_handler = RotatingFileHandler(
    'app.log',
    maxBytes=1024*1024,  # 1MB
    backupCount=5,       # 保留5个备份
    encoding='utf-8'
)

formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
rotating_handler.setFormatter(formatter)
logger.addHandler(rotating_handler)

# 测试：生成大量日志
for i in range(10000):
    logger.info(f"这是第 {i} 条日志消息")
```

**文件轮转效果**：
```
app.log        ← 当前日志文件
app.log.1      ← 第1个备份  
app.log.2      ← 第2个备份
app.log.3      ← 第3个备份
app.log.4      ← 第4个备份
app.log.5      ← 第5个备份 (最老的)
```

### 6.3 按时间轮转 (TimedRotatingFileHandler)


**按时间间隔自动切换日志文件**：
```python
import logging
from logging.handlers import TimedRotatingFileHandler

logger = logging.getLogger('timed_logger')
logger.setLevel(logging.DEBUG)

# 创建时间轮转处理器
timed_handler = TimedRotatingFileHandler(
    'daily.log',
    when='midnight',     # 每天午夜轮转
    interval=1,          # 间隔1个单位
    backupCount=30,      # 保留30天
    encoding='utf-8'
)

formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
timed_handler.setFormatter(formatter)
logger.addHandler(timed_handler)

logger.info("每天都会有新的日志文件")
```

**轮转时间选项**：
```python
'S'          # 秒
'M'          # 分钟  
'H'          # 小时
'D'          # 天
'midnight'   # 每天午夜
'W0'-'W6'    # 每周的某一天 (0=Monday)
```

**轮转后的文件名**：
```
daily.log                    ← 当前文件
daily.log.2025-01-20         ← 昨天的日志
daily.log.2025-01-19         ← 前天的日志
```

---

## 7. 📋 结构化日志


### 7.1 什么是结构化日志


**传统日志**：像一篇文章，人类容易读，机器难分析
```
2025-01-21 10:30:15 - INFO - 用户 alice 登录成功，IP: 192.168.1.100
```

**结构化日志**：像表格数据，机器容易分析
```json
{
    "timestamp": "2025-01-21T10:30:15",
    "level": "INFO", 
    "event": "user_login",
    "user": "alice",
    "ip": "192.168.1.100",
    "success": true
}
```

### 7.2 JSON格式日志


**使用字典记录结构化信息**：
```python
import logging
import json
from datetime import datetime

class JSONFormatter(logging.Formatter):
    """JSON格式的日志格式器"""
    
    def format(self, record):
        log_data = {
            'timestamp': datetime.fromtimestamp(record.created).isoformat(),
            'level': record.levelname,
            'logger': record.name,
            'message': record.getMessage(),
            'filename': record.filename,
            'line_number': record.lineno
        }
        
        # 添加额外字段
        if hasattr(record, 'user_id'):
            log_data['user_id'] = record.user_id
        if hasattr(record, 'request_id'):
            log_data['request_id'] = record.request_id
            
        return json.dumps(log_data, ensure_ascii=False)

# 使用JSON格式器
logger = logging.getLogger('json_logger')
handler = logging.StreamHandler()
handler.setFormatter(JSONFormatter())
logger.addHandler(handler)
logger.setLevel(logging.INFO)

# 记录结构化日志
def user_action(user_id, action, result):
    # 创建带额外字段的日志记录
    logger.info(
        f"用户操作: {action}",
        extra={'user_id': user_id, 'action': action, 'result': result}
    )

user_action('alice', 'login', 'success')
```

### 7.3 使用 structlog 库


**安装和基础使用**：
```bash
pip install structlog
```

```python
import structlog

# 配置structlog
structlog.configure(
    processors=[
        structlog.stdlib.filter_by_level,
        structlog.stdlib.add_logger_name,
        structlog.stdlib.add_log_level,
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.dev.ConsoleRenderer()  # 开发环境用彩色输出
    ],
    wrapper_class=structlog.stdlib.BoundLogger,
    logger_factory=structlog.stdlib.LoggerFactory(),
    cache_logger_on_first_use=True,
)

logger = structlog.get_logger()

# 使用结构化日志
logger.info("用户登录", user_id="alice", ip="192.168.1.100", success=True)
logger.error("数据库连接失败", database="user_db", retry_count=3)
```

---

## 8. 🌐 分布式日志


### 8.1 分布式日志的挑战


**多服务环境的问题**：
```
服务A产生日志 → 文件A
服务B产生日志 → 文件B  
服务C产生日志 → 文件C

问题：
🔍 查问题要看多个文件
📊 统计分析很困难
🕐 时间不同步
🔗 请求链路难追踪
```

### 8.2 统一日志收集


**HTTP日志发送器**：
```python
import logging
import requests
import json

class HTTPHandler(logging.Handler):
    """HTTP日志处理器 - 发送日志到远程服务器"""
    
    def __init__(self, url, method='POST'):
        super().__init__()
        self.url = url
        self.method = method
    
    def emit(self, record):
        try:
            log_data = {
                'timestamp': record.created,
                'level': record.levelname,
                'message': record.getMessage(),
                'logger': record.name,
                'service': 'user-service'  # 服务标识
            }
            
            requests.post(self.url, json=log_data, timeout=5)
        except Exception:
            # 日志发送失败不应该影响主程序
            pass

# 使用HTTP处理器
logger = logging.getLogger('distributed_logger')
logger.addHandler(HTTPHandler('http://log-server:8080/logs'))
logger.setLevel(logging.INFO)

logger.info("这条日志会发送到远程日志服务器")
```

### 8.3 请求链路追踪


**为每个请求生成唯一ID**：
```python
import logging
import uuid
import threading

# 线程本地存储，保存请求ID
request_local = threading.local()

class RequestFilter(logging.Filter):
    """为日志添加请求ID"""
    
    def filter(self, record):
        # 从线程本地存储获取请求ID
        request_id = getattr(request_local, 'request_id', 'no-request')
        record.request_id = request_id
        return True

def set_request_id():
    """为当前请求设置唯一ID"""
    request_local.request_id = str(uuid.uuid4())[:8]

def get_request_id():
    """获取当前请求ID"""
    return getattr(request_local, 'request_id', 'no-request')

# 配置日志
logger = logging.getLogger('traced_logger')
handler = logging.StreamHandler()
handler.setFormatter(logging.Formatter(
    '%(asctime)s [%(request_id)s] %(levelname)s - %(message)s'
))
handler.addFilter(RequestFilter())
logger.addHandler(handler)
logger.setLevel(logging.INFO)

# 模拟处理请求
def handle_request():
    set_request_id()  # 为这个请求设置ID
    
    logger.info("开始处理用户请求")
    logger.info("查询数据库")
    logger.info("返回结果")

# 测试
handle_request()
# 输出：
# 2025-01-21 10:30:15,123 [a1b2c3d4] INFO - 开始处理用户请求
# 2025-01-21 10:30:15,124 [a1b2c3d4] INFO - 查询数据库  
# 2025-01-21 10:30:15,125 [a1b2c3d4] INFO - 返回结果
```

---

## 9. ⚡ 日志性能优化


### 9.1 日志性能问题


**常见性能问题**：
- 🐌 **IO阻塞**：写文件会阻塞程序
- 💾 **内存占用**：大量日志占用内存  
- 🔄 **频繁格式化**：每条日志都要格式化
- 🌐 **网络延迟**：远程日志发送慢

### 9.2 异步日志处理


**使用QueueHandler异步处理**：
```python
import logging
import logging.handlers
import queue
import threading

def setup_async_logger():
    """设置异步日志处理器"""
    
    # 创建队列
    log_queue = queue.Queue()
    
    # 创建队列处理器 (主线程用)
    queue_handler = logging.handlers.QueueHandler(log_queue)
    
    # 创建实际的文件处理器 (后台线程用)
    file_handler = logging.FileHandler('async.log', encoding='utf-8')
    file_handler.setFormatter(
        logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
    )
    
    # 创建队列监听器 (后台线程处理队列中的日志)
    queue_listener = logging.handlers.QueueListener(
        log_queue, file_handler
    )
    
    # 配置主记录器
    logger = logging.getLogger('async_logger')
    logger.addHandler(queue_handler)
    logger.setLevel(logging.INFO)
    
    # 启动后台监听器
    queue_listener.start()
    
    return logger, queue_listener

# 使用异步日志
logger, listener = setup_async_logger()

# 这些日志调用不会阻塞主程序
for i in range(1000):
    logger.info(f"异步日志消息 {i}")

print("日志已提交到队列，程序继续执行")

# 程序结束时停止监听器
# listener.stop()
```

### 9.3 条件日志记录


**避免不必要的字符串格式化**：
```python
import logging

logger = logging.getLogger()
logger.setLevel(logging.WARNING)  # 只记录WARNING及以上

# ❌ 错误方式：即使不记录也会格式化字符串
expensive_data = "计算很耗时的数据..."
logger.debug(f"调试信息: {expensive_data}")  # 浪费CPU

# ✅ 正确方式1：先检查级别
if logger.isEnabledFor(logging.DEBUG):
    expensive_data = "计算很耗时的数据..."
    logger.debug(f"调试信息: {expensive_data}")

# ✅ 正确方式2：使用延迟格式化
logger.debug("调试信息: %s", expensive_data)  # 只在需要时格式化
```

### 9.4 日志级别动态控制


**根据环境动态调整日志级别**：
```python
import os
import logging

class PerformanceLogger:
    """性能优化的日志器"""
    
    def __init__(self, name):
        self.logger = logging.getLogger(name)
        
        # 根据环境变量设置级别
        env = os.getenv('ENV', 'development')
        if env == 'production':
            self.logger.setLevel(logging.WARNING)  # 生产环境少记录
        else:
            self.logger.setLevel(logging.DEBUG)    # 开发环境多记录
    
    def debug(self, msg, *args):
        if self.logger.isEnabledFor(logging.DEBUG):
            self.logger.debug(msg, *args)
    
    def info(self, msg, *args):
        if self.logger.isEnabledFor(logging.INFO):
            self.logger.info(msg, *args)

# 使用
perf_logger = PerformanceLogger('app')
perf_logger.debug("这在生产环境不会记录")  # 节省性能
```

### 9.5 批量日志处理


**批量写入减少IO次数**：
```python
import logging
import time
import threading

class BatchHandler(logging.Handler):
    """批量日志处理器"""
    
    def __init__(self, target_handler, batch_size=100, flush_interval=5):
        super().__init__()
        self.target_handler = target_handler
        self.batch_size = batch_size
        self.flush_interval = flush_interval
        self.buffer = []
        self.last_flush = time.time()
        self.lock = threading.Lock()
        
        # 启动定时刷新线程
        self.flush_thread = threading.Thread(target=self._flush_periodically, daemon=True)
        self.flush_thread.start()
    
    def emit(self, record):
        with self.lock:
            self.buffer.append(record)
            
            # 缓冲区满了就刷新
            if len(self.buffer) >= self.batch_size:
                self._flush()
    
    def _flush(self):
        """刷新缓冲区到目标处理器"""
        if not self.buffer:
            return
            
        for record in self.buffer:
            self.target_handler.emit(record)
        
        self.buffer.clear()
        self.last_flush = time.time()
    
    def _flush_periodically(self):
        """定期刷新缓冲区"""
        while True:
            time.sleep(1)
            with self.lock:
                if (time.time() - self.last_flush) >= self.flush_interval:
                    self._flush()

# 使用批量处理器
file_handler = logging.FileHandler('batch.log', encoding='utf-8')
batch_handler = BatchHandler(file_handler, batch_size=50, flush_interval=3)

logger = logging.getLogger('batch_logger')
logger.addHandler(batch_handler)
logger.setLevel(logging.INFO)

# 快速生成大量日志
for i in range(200):
    logger.info(f"批量日志 {i}")
```

---

## 10. 📋 核心要点总结


### 10.1 必须掌握的核心概念


```
🔸 日志系统：程序的"日记本"，记录运行时的各种信息
🔸 logging模块：Python的标准日志库，四大组件协同工作
🔸 日志级别：DEBUG < INFO < WARNING < ERROR < CRITICAL
🔸 格式化：让日志更易读，支持时间、文件名、行号等信息
🔸 输出目标：控制台、文件、网络等多种输出方式
🔸 日志轮转：自动管理日志文件大小，防止占满磁盘
```

### 10.2 实用记忆技巧


**日志级别记忆法**：
```
🟢 DEBUG   - 调试时用，像放大镜看细节
🔵 INFO    - 正常信息，像新闻报道  
🟡 WARNING - 警告提醒，像黄色警示灯
🔴 ERROR   - 出错了，像红色报警灯
🟣 CRITICAL- 严重错误，像紧急警报
```

**配置顺序记忆**：
```
Logger → Handler → Formatter
记录器 → 处理器 → 格式器
 (笔)  →  (纸)  →  (样式)
```

### 10.3 最佳实践建议


**开发阶段**：
- ✅ 使用DEBUG级别，查看详细信息
- ✅ 同时输出到控制台和文件
- ✅ 添加文件名和行号信息

**生产阶段**：
- ✅ 使用WARNING及以上级别
- ✅ 启用日志轮转，控制文件大小
- ✅ 考虑异步日志提升性能
- ✅ 添加请求ID便于问题追踪

**通用原则**：
- 🎯 **合适的级别**：不要滥用ERROR级别记录普通信息
- 🎨 **清晰的格式**：包含时间、级别、消息等关键信息  
- 🔒 **敏感信息**：不要记录密码、密钥等敏感数据
- ⚡ **性能考虑**：大量日志时使用异步处理

### 10.4 常见错误避免


```python
# ❌ 错误做法
print("用户登录了")  # 应该用logging
logging.error("正常的用户操作")  # 级别使用错误
logger.debug(f"数据: {expensive_function()}")  # 会无条件执行函数

# ✅ 正确做法  
logging.info("用户登录了")  # 使用合适的级别
logging.info("正常的用户操作")  # 正常操作用INFO
if logger.isEnabledFor(logging.DEBUG):  # 条件执行
    logger.debug(f"数据: {expensive_function()}")
```

**核心记忆口诀**：
- 日志记录很重要，级别选择要合适
- 格式清晰易分析，轮转管理防爆盘
- 生产环境要优化，异步处理提性能
- 结构化日志利分析，分布式追踪好排查