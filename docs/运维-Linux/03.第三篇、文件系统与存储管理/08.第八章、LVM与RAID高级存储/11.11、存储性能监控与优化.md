---
title: 11、存储性能监控与优化
---
## 📚 目录

1. [存储性能监控基础](#1-存储性能监控基础)
2. [iostat磁盘I/O监控详解](#2-iostat磁盘io监控详解)
3. [iotop进程I/O分析](#3-iotop进程io分析)
4. [存储队列深度调优](#4-存储队列深度调优)
5. [I/O调度器选择优化](#5-io调度器选择优化)
6. [文件系统挂载选项调优](#6-文件系统挂载选项调优)
7. [存储性能基准测试](#7-存储性能基准测试)
8. [瓶颈识别与解决方案](#8-瓶颈识别与解决方案)
9. [核心要点总结](#9-核心要点总结)

---

## 1. 💾 存储性能监控基础


### 1.1 什么是存储性能监控


**简单理解**：就像体检一样，定期检查磁盘的"健康状况"

```
现实生活类比：
体检看身体 ← → 监控看磁盘
- 血压心率    - IOPS吞吐量
- 血糖指标    - 响应时间
- 体温变化    - CPU使用率
- 异常症状    - 错误日志
```

> 💡 **核心目的**：及早发现存储系统的性能问题，避免影响整个系统运行

### 1.2 为什么存储性能如此重要


**瓶颈效应**：存储通常是整个系统最慢的环节
```
系统性能对比（相对速度）：
CPU运算    ████████████████████ 100倍
内存访问   ████████████ 60倍  
网络传输   ████ 20倍
磁盘访问   █ 1倍（最慢）

一个慢磁盘 = 拖累整个系统！
```

### 1.3 存储性能的核心指标


**🔑 必知的5个关键指标**：

┌────────────────────────────────────┐
│ 📊 指标名称   │ 📖 通俗解释        │
├────────────────────────────────────┤
│ IOPS         │ 每秒读写次数        │
│ 吞吐量       │ 每秒传输数据量      │
│ 响应时间     │ 完成一次操作耗时    │
│ 队列深度     │ 等待处理的请求数量  │
│ 使用率       │ 磁盘忙碌程度       │
└────────────────────────────────────┘

---

## 2. 📈 iostat磁盘I/O监控详解


### 2.1 iostat是什么


**简单解释**：iostat就像是磁盘的"实时体检报告"

```
安装iostat：
# CentOS/RHEL
yum install sysstat
# Ubuntu/Debian  
apt install sysstat
```

### 2.2 iostat基本用法


**常用命令格式**：
```bash
# 每2秒刷新一次，总共显示5次
iostat -x 2 5

# 只显示磁盘统计，不显示CPU
iostat -d 2

# 以MB为单位显示
iostat -m 2
```

### 2.3 读懂iostat输出结果


**典型输出解读**：
```
Device    r/s   w/s   rMB/s   wMB/s  %util   await   svctm
sda      120    80     15.2     8.4     85     12.5    4.2
sdb       45    25      5.8     3.1     35      8.2    2.8
```

**🔍 每列含义详解**：

> 📌 **r/s 和 w/s**：每秒读写次数
> - 数值越高 = 磁盘越繁忙
> - 通常读比写多（大部分应用特点）

> 📌 **rMB/s 和 wMB/s**：每秒读写的数据量
> - 衡量数据传输能力
> - 大文件操作时这个值会很高

> 📌 **%util**：磁盘使用率（最重要指标）
> - 0-100%，越高越繁忙
> - **超过80%需要关注，超过90%有问题**

> 📌 **await**：平均等待时间（毫秒）
> - 包括排队时间 + 服务时间
> - **超过10ms需要关注，超过50ms有问题**

> 📌 **svctm**：平均服务时间（毫秒）
> - 纯粹的磁盘响应时间
> - **SSD通常<2ms，机械硬盘<10ms**

### 2.4 实战案例分析


**案例1：正常状态**
```
Device    r/s   w/s   rMB/s   wMB/s  %util   await   svctm
sda        50    30      6.2     3.8     45      5.2    2.1
```
✅ **分析**：各项指标都在正常范围，系统运行良好

**案例2：高负载状态**
```  
Device    r/s   w/s   rMB/s   wMB/s  %util   await   svctm
sda       450   280     58.6    35.2     95     45.8    2.8
```
⚠️ **分析**：
- `%util=95%` → 磁盘接近饱和
- `await=45.8ms` → 响应时间过长
- **建议**：需要优化I/O或扩容

### 2.5 iostat监控脚本


**自动化监控脚本**：
```bash
#!/bin/bash
# 磁盘性能监控脚本

while true; do
    echo "=== $(date) ==="
    iostat -x 1 1 | awk '
    NR>3 && NF>1 {
        if ($10 > 80) 
            printf "警告: %s 磁盘使用率 %.1f%%\n", $1, $10
        if ($9 > 20) 
            printf "警告: %s 响应时间 %.1fms\n", $1, $9
    }'
    sleep 30
done
```

---

## 3. 🔍 iotop进程I/O分析


### 3.1 iotop是什么


**通俗解释**：如果说iostat看的是"整个医院的忙碌程度"，那iotop看的就是"每个科室具体在干什么"

```
iostat vs iotop：
iostat → 磁盘整体性能  （医院总体情况）
iotop  → 每个进程I/O   （每个科室详情）
```

### 3.2 iotop安装与基本用法


**安装iotop**：
```bash
# CentOS/RHEL
yum install iotop
# Ubuntu/Debian
apt install iotop
```

**常用命令**：
```bash
# 基本使用（需要root权限）
iotop

# 只显示有I/O活动的进程
iotop -o  

# 按I/O使用率排序
iotop -P

# 显示累计I/O而不是实时速率
iotop -a
```

### 3.3 读懂iotop输出


**典型输出界面**：
```
Total DISK READ:    15.2 MB/s | Total DISK WRITE:    8.4 MB/s
Current DISK READ:  12.8 MB/s | Current DISK WRITE:   6.2 MB/s

  TID  PRIO  USER   DISK READ  DISK WRITE   SWAPIN    IO    COMMAND
 2341  be/4  mysql    5.2 MB/s    2.1 MB/s   0.0%   85%   mysqld
 1205  be/4  root     3.8 MB/s    1.5 MB/s   0.0%   45%   rsync
  892  be/4  nginx    1.2 MB/s    0.8 MB/s   0.0%   15%   nginx
```

**🔍 重要字段解释**：

> 📊 **Total vs Current**：
> - Total：从系统启动开始的平均值
> - Current：当前时刻的实时值

> 🎯 **TID**：线程ID（比进程ID更精确）

> 📈 **DISK READ/WRITE**：该进程的读写速度

> ⚡ **IO%**：该进程占用的I/O百分比

### 3.4 实战问题定位


**案例：系统突然变慢，用iotop找元凶**

步骤1️⃣：运行iotop观察
```bash
iotop -o  # 只显示有I/O的进程
```

步骤2️⃣：找到问题进程
```
发现mysqld进程 DISK READ: 25 MB/s，IO占用 90%
```

步骤3️⃣：进一步分析
```bash
# 查看mysql正在执行什么查询
mysql> show processlist;

# 查看mysql慢日志
tail -f /var/log/mysql/slow.log
```

> 💡 **经验技巧**：结合iotop + 应用日志，能快速定位I/O瓶颈的根因

---

## 4. ⚙️ 存储队列深度调优


### 4.1 什么是队列深度


**生活化理解**：就像银行排队一样

```
银行排队 vs 磁盘队列：
┌─────────────────────────────────────┐
│ 🏦 银行柜台                         │
│                                     │
│ 客户1 → 客户2 → 客户3 → [柜员]      │
│   ↓       ↓       ↓                 │
│ 请求1 → 请求2 → 请求3 → [磁盘]      │
└─────────────────────────────────────┘

队列深度 = 排队等候的客户数量
```

> 🔑 **关键理解**：队列深度影响磁盘的工作效率和响应时间

### 4.2 队列深度的影响


**队列深度 vs 性能关系**：

```
队列深度太小（1-2）：
优点：响应时间快
缺点：磁盘吃不饱，性能浪费

队列深度适中（8-32）：
优点：性能和响应时间平衡 ✅
缺点：需要根据磁盘类型调整

队列深度太大（>64）：
优点：磁盘吃得很饱
缺点：响应时间很慢，用户体验差
```

### 4.3 查看和调整队列深度


**查看当前队列深度**：
```bash
# 方法1：查看系统默认值
cat /sys/block/sda/queue/nr_requests

# 方法2：通过iostat查看平均队列长度  
iostat -x 1 1 | grep -E "(Device|sda)"
```

**调整队列深度**：
```bash
# 临时调整（重启后失效）
echo 128 > /sys/block/sda/queue/nr_requests

# 永久调整（写入配置文件）
echo 'echo 128 > /sys/block/sda/queue/nr_requests' >> /etc/rc.local
```

### 4.4 不同存储类型的推荐设置


**📋 推荐队列深度配置**：

┌──────────────────────────────────────────┐
│ 💿 存储类型    │ 🎯 推荐队列深度 │ 📝 说明    │
├──────────────────────────────────────────┤
│ SSD固态硬盘    │ 32-128         │ 响应快     │
│ 机械硬盘       │ 8-32           │ 寻道慢     │
│ 企业级SSD      │ 128-256        │ 高性能     │
│ 网络存储       │ 64-128         │ 有网络延迟 │
└──────────────────────────────────────────┘

---

## 5. 🚀 I/O调度器选择优化


### 5.1 什么是I/O调度器


**通俗解释**：I/O调度器就像交通指挥员，决定哪个请求先通过

```
交通指挥 vs I/O调度：
🚦 红绿灯路口              💾 磁盘I/O请求
   ↓                         ↓
多条车道汇聚 ←→ 多个进程I/O请求
指挥员决定  ←→ 调度器决定顺序
通行顺序     ←→ 处理顺序
```

### 5.2 Linux常见I/O调度器类型


**🔍 四种主要调度器**：

**1️⃣ noop (No Operation)**
```
特点：先进先出，最简单
适用：SSD、虚拟化环境
原理：不做重排序，直接传给硬件

类比：超市单队列，先到先服务
```

**2️⃣ deadline**  
```
特点：保证响应时间
适用：服务器、数据库
原理：读请求优先，有超时保护

类比：VIP客户优先，但普通客户也不能等太久
```

**3️⃣ cfq (Complete Fair Queuing)**
```
特点：公平调度，每个进程分时间片
适用：桌面系统
原理：轮流给每个进程服务时间

类比：每个人都有发言时间的会议
```

**4️⃣ mq-deadline (多队列版本)**
```
特点：现代SSD优化版deadline
适用：高性能SSD
原理：支持多队列并行处理

类比：多个VIP通道同时服务
```

### 5.3 查看和切换I/O调度器


**查看当前调度器**：
```bash
# 查看所有磁盘的调度器
cat /sys/block/*/queue/scheduler

# 查看特定磁盘
cat /sys/block/sda/queue/scheduler
# 输出：noop deadline [cfq] mq-deadline
# 方括号表示当前使用的调度器
```

**临时切换调度器**：
```bash
# 切换到deadline
echo deadline > /sys/block/sda/queue/scheduler

# 切换到noop  
echo noop > /sys/block/sda/queue/scheduler
```

**永久设置调度器**：
```bash
# 编辑grub配置
vi /etc/default/grub

# 添加内核参数
GRUB_CMDLINE_LINUX="elevator=deadline"

# 更新grub配置
grub2-mkconfig -o /boot/grub2/grub.cfg

# 重启生效
reboot
```

### 5.4 不同场景的调度器选择


**🎯 选择指南**：

> 🖥️ **桌面系统**：cfq
> - 多个应用公平使用
> - 响应体验均衡

> 🗄️ **数据库服务器**：deadline  
> - 保证响应时间
> - 读写优化平衡

> ☁️ **虚拟化环境**：noop
> - 宿主机已经调度
> - 减少额外开销

> ⚡ **高性能SSD**：mq-deadline
> - 发挥多队列优势
> - 现代硬件适配

---

## 6. 🔧 文件系统挂载选项调优


### 6.1 挂载选项对性能的影响


**通俗理解**：挂载选项就像汽车的驾驶模式

```
汽车驾驶模式 vs 挂载选项：
🚗 经济模式  ←→  sync（安全但慢）
🏃 运动模式  ←→  async（快但有风险）  
⚖️ 平衡模式  ←→  默认配置（折中）
```

### 6.2 重要的性能相关挂载选项


**📋 常用优化选项详解**：

**1️⃣ noatime / relatime**
```bash
# 不更新访问时间（性能提升明显）
mount -o noatime /dev/sda1 /data

# 或者使用relatime（折中方案）
mount -o relatime /dev/sda1 /data
```
> 💡 **效果**：减少写入操作，特别适合读多写少的场景

**2️⃣ commit 间隔调整**
```bash  
# ext4文件系统提交间隔（默认5秒）
mount -o commit=30 /dev/sda1 /data
```
> ⚠️ **注意**：间隔越长性能越好，但断电丢失数据风险越大

**3️⃣ 预读优化**
```bash
# 设置预读大小（单位KB，默认128KB）
mount -o readahead=256 /dev/sda1 /data
```

**4️⃣ 禁用日志（高风险高性能）**
```bash
# ext4禁用日志（仅限特殊场景）
tune2fs -O ^has_journal /dev/sda1
```
> ⚠️ **警告**：只适合临时数据或有其他备份保障的场景

### 6.3 实战配置示例


**高性能数据库挂载**：
```bash
# /etc/fstab配置
/dev/sda1 /data ext4 noatime,nobarrier,commit=30 0 0
```

**高安全性挂载**：
```bash  
# /etc/fstab配置
/dev/sda1 /data ext4 sync,barrier,commit=5 0 0
```

**平衡性能与安全**：
```bash
# /etc/fstab配置  
/dev/sda1 /data ext4 relatime,barrier,commit=15 0 0
```

### 6.4 文件系统优化测试


**测试挂载选项效果**：
```bash
# 测试脚本
#!/bin/bash
echo "=== 测试不同挂载选项的性能 ==="

# 默认挂载
echo "默认挂载测试..."
time dd if=/dev/zero of=/data/test1 bs=1M count=1000

# noatime挂载  
umount /data
mount -o noatime /dev/sda1 /data
echo "noatime挂载测试..."
time dd if=/dev/zero of=/data/test2 bs=1M count=1000
```

---

## 7. 📊 存储性能基准测试


### 7.1 为什么需要基准测试


**简单理解**：就像跑分测试一样，了解硬件的真实能力

```
手机跑分 vs 存储测试：
📱 安兔兔跑分  ←→  💾 磁盘基准测试
   ↓                 ↓
了解手机性能   ←→  了解存储性能
对比不同型号   ←→  对比不同配置
```

### 7.2 常用测试工具介绍


**🛠️ 三大主流测试工具**：

**1️⃣ dd命令（简单粗暴）**
```bash
# 测试写入性能
dd if=/dev/zero of=/data/testfile bs=1M count=1000

# 测试读取性能  
dd if=/data/testfile of=/dev/null bs=1M
```
> 📝 **特点**：系统自带，但测试结果不够专业

**2️⃣ fio（专业全面）**
```bash
# 安装fio
yum install fio  # CentOS
apt install fio  # Ubuntu
```
> 🏆 **优势**：业界标准，功能强大，结果准确

**3️⃣ hdparm（快速测试）**  
```bash
# 安装hdparm
yum install hdparm

# 简单测试
hdparm -t /dev/sda
```

### 7.3 fio详细使用指南


**基础读写测试**：
```bash
# 顺序读测试
fio --name=seqread --rw=read --bs=1M --size=4G --filename=/data/testfile

# 顺序写测试
fio --name=seqwrite --rw=write --bs=1M --size=4G --filename=/data/testfile

# 随机读测试（重要指标）
fio --name=randread --rw=randread --bs=4K --size=1G --filename=/data/testfile

# 随机写测试（重要指标）
fio --name=randwrite --rw=randwrite --bs=4K --size=1G --filename=/data/testfile
```

**综合测试配置文件**：
```ini
# 保存为test.fio
[global]
filename=/data/fiotest
size=4G
runtime=60
ioengine=libaio
direct=1
group_reporting

[seqread]
rw=read
bs=1M

[seqwrite]  
rw=write
bs=1M

[randread]
rw=randread
bs=4K
iodepth=32

[randwrite]
rw=randwrite
bs=4K  
iodepth=32
```

**运行测试**：
```bash
fio test.fio
```

### 7.4 测试结果解读


**典型fio输出解读**：
```
Jobs: 1 (f=1): [r(1)] [100.0% done] [1024MB/0KB/s] [256/0 iops] [eta 00m:00s]
randread: (g=0): rw=randread, bs=4K-4K/4K-4K/4K-4K, ioengine=libaio, iodepth=32

read : io=1024MB, bw=85.3MB/s, iops=21845, runt= 12007msec
  clat (usec): min=142, max=89123, avg=1463.2, stdev=1894.3
```

**🔍 关键指标含义**：

> 📈 **bw（带宽）**：85.3MB/s = 每秒传输85.3MB数据
> 📊 **iops**：21845 = 每秒完成21845次I/O操作  
> ⏱️ **clat（完成延迟）**：平均1463.2微秒 = 1.46毫秒

### 7.5 性能基准参考值


**🎯 常见存储设备性能参考**：

┌─────────────────────────────────────────────────────┐
│ 💾 设备类型      │ 📊 4K随机读IOPS │ 📈 顺序读MB/s │
├─────────────────────────────────────────────────────┤  
│ 机械硬盘7200rpm  │ 100-200        │ 100-150      │
│ SSD SATA3       │ 10,000-50,000  │ 400-550      │
│ SSD NVMe        │ 50,000-500,000 │ 1500-3500    │
│ 企业级NVMe      │ 100,000-1M     │ 3000-7000    │
└─────────────────────────────────────────────────────┘

---

## 8. 🔎 瓶颈识别与解决方案


### 8.1 常见存储瓶颈类型


**🚨 四大类存储瓶颈**：

```
瓶颈分类图：
          存储瓶颈
              │
    ┌─────────┼─────────┐
    │         │         │
 硬件瓶颈   软件瓶颈   网络瓶颈
    │         │         │
磁盘/接口   系统配置   网络存储
```

### 8.2 瓶颈识别流程


**🔍 系统化排查步骤**：

步骤1️⃣：**收集基础信息**
```bash
# 查看磁盘基本信息
lsblk
fdisk -l

# 查看挂载情况
df -h
mount | grep -E "(sda|sdb)"

# 查看I/O统计
iostat -x 2 5
```

步骤2️⃣：**定位问题进程**
```bash  
# 找出I/O占用高的进程
iotop -o

# 查看进程详细信息
ps aux | grep <进程名>
```

步骤3️⃣：**分析系统配置**
```bash
# 检查I/O调度器
cat /sys/block/sda/queue/scheduler

# 检查队列深度
cat /sys/block/sda/queue/nr_requests

# 检查挂载选项
mount | grep /data
```

### 8.3 典型瓶颈场景与解决方案


**场景1：数据库响应慢** 

🔍 **症状**：
```
iostat显示：
%util = 95%, await = 50ms
应用表现：数据库查询超时
```

✅ **解决方案**：
```bash
# 1. 优化I/O调度器
echo deadline > /sys/block/sda/queue/scheduler

# 2. 调整数据库配置
# MySQL innodb_buffer_pool_size 增大
# PostgreSQL shared_buffers 增大

# 3. 添加索引优化查询
```

**场景2：大文件传输缓慢**

🔍 **症状**：
```
iostat显示：
读写速度远低于硬件规格
队列深度很低
```

✅ **解决方案**：
```bash
# 1. 调整队列深度
echo 128 > /sys/block/sda/queue/nr_requests

# 2. 优化挂载选项
mount -o remount,noatime,readahead=2048 /data

# 3. 使用多线程传输
rsync -av --progress --partial -P source/ dest/
```

**场景3：虚拟机存储性能差**

🔍 **症状**：
```
物理机性能正常，虚拟机内部慢
随机I/O性能特别差
```

✅ **解决方案**：  
```bash
# 1. 虚拟机使用noop调度器
echo noop > /sys/block/vda/queue/scheduler

# 2. 宿主机优化
# - 使用SSD存储虚拟机镜像
# - 调整宿主机I/O调度器为deadline

# 3. 虚拟机配置优化
# - 增加虚拟机内存
# - 使用virtio驱动
```

### 8.4 监控告警设置


**自动化监控脚本**：
```bash
#!/bin/bash
# storage-monitor.sh

ALERT_UTIL=85    # 使用率告警阈值
ALERT_AWAIT=30   # 响应时间告警阈值

iostat -x 1 1 | awk -v util=$ALERT_UTIL -v await=$ALERT_AWAIT '
NR>3 && NF>1 {
    if ($10 > util) {
        printf "ALERT: 磁盘 %s 使用率过高: %.1f%%\n", $1, $10
        system("logger -p local0.warning \"磁盘告警: " $1 " 使用率 " $10 "%\"")
    }
    if ($9 > await) {
        printf "ALERT: 磁盘 %s 响应时间过长: %.1fms\n", $1, $9  
        system("logger -p local0.warning \"磁盘告警: " $1 " 响应时间 " $9 "ms\"")
    }
}'
```

**crontab定时执行**：
```bash
# 每分钟检查一次
echo "* * * * * /usr/local/bin/storage-monitor.sh" | crontab -
```

---

## 9. 📋 核心要点总结


### 9.1 必须掌握的核心工具


```
🔧 监控工具：
├─ iostat：磁盘整体性能监控（必会）
├─ iotop：进程级I/O分析（必会）  
├─ fio：专业性能测试（重要）
└─ hdparm：快速性能检测（了解）
```

### 9.2 关键性能指标记忆


**🎯 告警阈值速记**：

┌─────────────────────────────────────┐
│ 📊 指标       │ 🚨 告警阈值     │ 📝 说明 │
├─────────────────────────────────────┤
│ %util        │ > 80%          │ 磁盘繁忙 │
│ await        │ > 20ms         │ 响应慢   │
│ IOPS         │ 依硬件而定      │ 吞吐能力 │
│ 队列深度     │ SSD:32 HDD:16  │ 并发优化 │
└─────────────────────────────────────┘

### 9.3 优化策略选择指南


**🎪 场景化优化建议**：

> 🗄️ **数据库服务器**：
> - I/O调度器：deadline
> - 挂载选项：noatime,barrier
> - 队列深度：32-64

> 🖥️ **Web服务器**：
> - I/O调度器：cfq
> - 挂载选项：relatime
> - 队列深度：16-32

> ☁️ **虚拟化环境**：
> - I/O调度器：noop
> - 挂载选项：noatime
> - 队列深度：32

### 9.4 故障排查思路


**🔍 标准排查流程**：
```
1️⃣ 查看整体性能 → iostat -x 2
2️⃣ 定位问题进程 → iotop -o  
3️⃣ 检查系统配置 → scheduler/mount options
4️⃣ 基准测试对比 → fio测试
5️⃣ 针对性优化 → 调整配置参数
6️⃣ 验证优化效果 → 再次测试
```

### 9.5 实际应用价值


**💼 工作中的实用技能**：
- **性能调优**：基于监控数据进行针对性优化
- **故障排查**：快速定位和解决I/O性能问题
- **容量规划**：通过测试数据做存储扩容决策
- **选型决策**：不同存储方案的性能评估

**🧠 核心记忆口诀**：
- iostat看整体，iotop找进程
- 队列调度挂载选项，三管齐下性能升
- 基准测试知底线，监控告警防问题
- 瓶颈识别有套路，对症下药效果好

> 💡 **学习建议**：多在测试环境实践这些工具和优化方法，积累实战经验比理论学习更重要！