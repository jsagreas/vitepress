---
title: 10ã€å¤§è§„æ¨¡æ–‡ä»¶ç›‘æ§ä¼˜åŒ–
---
## ğŸ“š ç›®å½•

1. [ç›‘æ§ç³»ç»Ÿèµ„æºé™åˆ¶](#1-ç›‘æ§ç³»ç»Ÿèµ„æºé™åˆ¶)
2. [å†…å­˜ä½¿ç”¨ä¼˜åŒ–ç­–ç•¥](#2-å†…å­˜ä½¿ç”¨ä¼˜åŒ–ç­–ç•¥)
3. [CPUå¼€é”€æ§åˆ¶æ–¹æ³•](#3-CPUå¼€é”€æ§åˆ¶æ–¹æ³•)
4. [äº‹ä»¶é˜Ÿåˆ—æ·±åº¦è°ƒä¼˜](#4-äº‹ä»¶é˜Ÿåˆ—æ·±åº¦è°ƒä¼˜)
5. [æ‰¹é‡äº‹ä»¶å¤„ç†æœºåˆ¶](#5-æ‰¹é‡äº‹ä»¶å¤„ç†æœºåˆ¶)
6. [ç›‘æ§å±‚æ¬¡ç»“æ„è®¾è®¡](#6-ç›‘æ§å±‚æ¬¡ç»“æ„è®¾è®¡)
7. [è´Ÿè½½å‡è¡¡ç›‘æ§åˆ†å¸ƒ](#7-è´Ÿè½½å‡è¡¡ç›‘æ§åˆ†å¸ƒ)
8. [èµ„æºä½¿ç”¨ç‡ç›‘æ§](#8-èµ„æºä½¿ç”¨ç‡ç›‘æ§)
9. [æ‰©å±•æ€§æ¶æ„è®¾è®¡](#9-æ‰©å±•æ€§æ¶æ„è®¾è®¡)
10. [æ ¸å¿ƒè¦ç‚¹æ€»ç»“](#10-æ ¸å¿ƒè¦ç‚¹æ€»ç»“)

---

## 1. ğŸ”¢ ç›‘æ§ç³»ç»Ÿèµ„æºé™åˆ¶


### 1.1 inotifyç³»ç»Ÿé™åˆ¶è¯¦è§£


**ä»€ä¹ˆæ˜¯inotifyé™åˆ¶ï¼Ÿ**
```
inotifyæ˜¯Linuxå†…æ ¸æä¾›çš„æ–‡ä»¶ç³»ç»Ÿç›‘æ§æœºåˆ¶
ä½†å®ƒæœ‰ä¸¥æ ¼çš„èµ„æºé™åˆ¶ï¼Œé˜²æ­¢ç³»ç»Ÿèµ„æºè€—å°½
å°±åƒåœè½¦åœºæœ‰è½¦ä½é™åˆ¶ï¼Œç›‘æ§ä¹Ÿæœ‰"ä½ç½®"é™åˆ¶
```

**æ ¸å¿ƒé™åˆ¶å‚æ•°**ï¼š
```bash
# æŸ¥çœ‹å½“å‰é™åˆ¶å€¼
cat /proc/sys/fs/inotify/max_user_instances  # æ¯ä¸ªç”¨æˆ·æœ€å¤§å®ä¾‹æ•°
cat /proc/sys/fs/inotify/max_user_watches    # æ¯ä¸ªç”¨æˆ·æœ€å¤§ç›‘æ§æ•°
cat /proc/sys/fs/inotify/max_queued_events   # æœ€å¤§é˜Ÿåˆ—äº‹ä»¶æ•°

# å…¸å‹é»˜è®¤å€¼ï¼š
max_user_instances: 128     # æ¯ä¸ªç”¨æˆ·æœ€å¤š128ä¸ªinotifyå®ä¾‹
max_user_watches: 8192     # æ¯ä¸ªç”¨æˆ·æœ€å¤šç›‘æ§8192ä¸ªæ–‡ä»¶/ç›®å½•
max_queued_events: 16384   # æœ€å¤šæ’é˜Ÿ16384ä¸ªäº‹ä»¶
```

**é™åˆ¶çš„å®é™…æ„ä¹‰**ï¼š
```
ğŸ”¸ å®ä¾‹é™åˆ¶ï¼šæ§åˆ¶ç¨‹åºæ•°é‡
â€¢ ä¸€ä¸ªç¨‹åºé€šå¸¸åˆ›å»º1ä¸ªå®ä¾‹
â€¢ 128ä¸ªå®ä¾‹ = æœ€å¤š128ä¸ªç›‘æ§ç¨‹åºåŒæ—¶è¿è¡Œ

ğŸ”¸ ç›‘æ§æ•°é™åˆ¶ï¼šæ§åˆ¶ç›‘æ§è§„æ¨¡
â€¢ 8192ä¸ªç›‘æ§ç‚¹ = æœ€å¤šåŒæ—¶ç›‘æ§8192ä¸ªæ–‡ä»¶/ç›®å½•
â€¢ ç›‘æ§æ•´ä¸ªç›®å½•æ ‘æ—¶å¾ˆå®¹æ˜“è¶…é™

ğŸ”¸ äº‹ä»¶é˜Ÿåˆ—é™åˆ¶ï¼šæ§åˆ¶å†…å­˜ä½¿ç”¨
â€¢ é˜²æ­¢äº‹ä»¶ç§¯å‹è¿‡å¤šå ç”¨å†…å­˜
â€¢ äº‹ä»¶å¤„ç†ä¸åŠæ—¶ä¼šå¯¼è‡´é˜Ÿåˆ—æº¢å‡º
```

### 1.2 é™åˆ¶è°ƒæ•´ç­–ç•¥


**ä¸´æ—¶è°ƒæ•´æ–¹æ³•**ï¼š
```bash
# ä¸´æ—¶æé«˜é™åˆ¶ï¼ˆé‡å¯åå¤±æ•ˆï¼‰
echo 512 > /proc/sys/fs/inotify/max_user_instances
echo 65536 > /proc/sys/fs/inotify/max_user_watches
echo 32768 > /proc/sys/fs/inotify/max_queued_events
```

**æ°¸ä¹…è°ƒæ•´æ–¹æ³•**ï¼š
```bash
# ç¼–è¾‘ç³»ç»Ÿé…ç½®æ–‡ä»¶
vim /etc/sysctl.conf

# æ·»åŠ ä»¥ä¸‹é…ç½®
fs.inotify.max_user_instances = 512
fs.inotify.max_user_watches = 65536
fs.inotify.max_queued_events = 32768

# åº”ç”¨é…ç½®
sysctl -p
```

**åˆç†è®¾ç½®å»ºè®®**ï¼š
```
ğŸ¯ å°è§„æ¨¡ç›‘æ§ï¼ˆ<1000æ–‡ä»¶ï¼‰ï¼š
max_user_watches = 8192    # é»˜è®¤å€¼è¶³å¤Ÿ

ğŸ¯ ä¸­è§„æ¨¡ç›‘æ§ï¼ˆ1000-10000æ–‡ä»¶ï¼‰ï¼š
max_user_watches = 32768   # 4å€æ‰©å®¹

ğŸ¯ å¤§è§„æ¨¡ç›‘æ§ï¼ˆ>10000æ–‡ä»¶ï¼‰ï¼š
max_user_watches = 131072  # 16å€æ‰©å®¹
max_queued_events = 65536  # åŒæ—¶å¢åŠ é˜Ÿåˆ—æ·±åº¦
```

---

## 2. ğŸ’¾ å†…å­˜ä½¿ç”¨ä¼˜åŒ–ç­–ç•¥


### 2.1 å†…å­˜å ç”¨åˆ†æ


**inotifyå†…å­˜å¼€é”€æ„æˆ**ï¼š
```
å†…å­˜ä½¿ç”¨ = ç›‘æ§ç»“æ„ä½“ + äº‹ä»¶é˜Ÿåˆ— + è·¯å¾„ç¼“å­˜

ğŸ”¸ ç›‘æ§ç»“æ„ä½“ï¼šæ¯ä¸ªç›‘æ§ç‚¹çº¦256å­—èŠ‚
ğŸ”¸ äº‹ä»¶é˜Ÿåˆ—ï¼šæ¯ä¸ªäº‹ä»¶çº¦32å­—èŠ‚
ğŸ”¸ è·¯å¾„ç¼“å­˜ï¼šå­˜å‚¨æ–‡ä»¶è·¯å¾„ä¿¡æ¯

è®¡ç®—ç¤ºä¾‹ï¼š
ç›‘æ§10000ä¸ªæ–‡ä»¶ = 10000 Ã— 256å­—èŠ‚ â‰ˆ 2.5MB
äº‹ä»¶é˜Ÿåˆ—16384ä¸ª = 16384 Ã— 32å­—èŠ‚ â‰ˆ 512KB
æ€»å†…å­˜å ç”¨ â‰ˆ 3MBï¼ˆä»…å†…æ ¸éƒ¨åˆ†ï¼‰
```

### 2.2 å†…å­˜ä¼˜åŒ–æŠ€æœ¯


**é€‰æ‹©æ€§ç›‘æ§ç­–ç•¥**ï¼š
```python
import os
import inotify.adapters

class OptimizedFileMonitor:
    def __init__(self, root_path, file_patterns=None):
        self.root_path = root_path
        self.file_patterns = file_patterns or ['*.log', '*.txt']
        self.i = inotify.adapters.Inotify()
        
    def should_monitor(self, path):
        """åªç›‘æ§ç¬¦åˆæ¡ä»¶çš„æ–‡ä»¶"""
        # è·³è¿‡éšè—æ–‡ä»¶
        if os.path.basename(path).startswith('.'):
            return False
            
        # åªç›‘æ§ç‰¹å®šæ‰©å±•å
        for pattern in self.file_patterns:
            if path.endswith(pattern.replace('*', '')):
                return True
        return False
        
    def setup_monitoring(self):
        """æ™ºèƒ½è®¾ç½®ç›‘æ§ç‚¹"""
        monitored_count = 0
        
        for root, dirs, files in os.walk(self.root_path):
            # è·³è¿‡ä¸éœ€è¦çš„ç›®å½•
            dirs[:] = [d for d in dirs if not d.startswith('.')]
            
            for file in files:
                filepath = os.path.join(root, file)
                if self.should_monitor(filepath):
                    self.i.add_watch(filepath)
                    monitored_count += 1
                    
        print(f"å®é™…ç›‘æ§æ–‡ä»¶æ•°: {monitored_count}")
```

**å†…å­˜ä½¿ç”¨ç›‘æ§**ï¼š
```bash
# ç›‘æ§ç¨‹åºå†…å­˜ä½¿ç”¨
ps aux | grep your_monitor_program

# æŸ¥çœ‹inotifyå†…æ ¸å†…å­˜ä½¿ç”¨
grep -r inotify /proc/slabinfo

# å®æ—¶ç›‘æ§ç³»ç»Ÿå†…å­˜
watch -n 1 'free -h'
```

---

## 3. âš¡ CPUå¼€é”€æ§åˆ¶æ–¹æ³•


### 3.1 CPUå¼€é”€æ¥æºåˆ†æ


**ä¸»è¦CPUæ¶ˆè€—ç‚¹**ï¼š
```
ğŸ”¸ äº‹ä»¶æ¥æ”¶å¤„ç†ï¼šå†…æ ¸åˆ°ç”¨æˆ·ç©ºé—´çš„æ•°æ®ä¼ è¾“
ğŸ”¸ è·¯å¾„è§£æï¼šå°†ç›‘æ§æè¿°ç¬¦è½¬æ¢ä¸ºæ–‡ä»¶è·¯å¾„
ğŸ”¸ äº‹ä»¶è¿‡æ»¤ï¼šåˆ¤æ–­äº‹ä»¶æ˜¯å¦éœ€è¦å¤„ç†
ğŸ”¸ ä¸šåŠ¡é€»è¾‘ï¼šå®é™…çš„äº‹ä»¶å¤„ç†ä»£ç 
```

**CPUä½¿ç”¨ä¼˜åŒ–å›¾ç¤º**ï¼š
```
äº‹ä»¶äº§ç”Ÿé¢‘ç‡ vs CPUä½¿ç”¨ç‡

é«˜é¢‘äº‹ä»¶ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â”‚ 90% CPU
        â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â”‚
ä¸­é¢‘äº‹ä»¶ â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         â”‚ 50% CPU  
        â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         â”‚
ä½é¢‘äº‹ä»¶ â”‚ â–ˆâ–ˆ               â”‚ 10% CPU
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         ä¼˜åŒ–å‰    ä¼˜åŒ–å
```

### 3.2 CPUä¼˜åŒ–æŠ€æœ¯


**äº‹ä»¶è¿‡æ»¤ä¼˜åŒ–**ï¼š
```python
import select
import struct

class EfficientMonitor:
    def __init__(self):
        self.fd = inotify_init()
        self.watch_map = {}  # ç¼“å­˜ç›‘æ§æè¿°ç¬¦åˆ°è·¯å¾„çš„æ˜ å°„
        
    def add_efficient_watch(self, path, mask):
        """é«˜æ•ˆæ·»åŠ ç›‘æ§ï¼Œç¼“å­˜è·¯å¾„æ˜ å°„"""
        wd = inotify_add_watch(self.fd, path, mask)
        self.watch_map[wd] = path
        return wd
        
    def process_events_batch(self, timeout=1):
        """æ‰¹é‡å¤„ç†äº‹ä»¶ï¼Œå‡å°‘ç³»ç»Ÿè°ƒç”¨"""
        ready, _, _ = select.select([self.fd], [], [], timeout)
        
        if ready:
            # ä¸€æ¬¡æ€§è¯»å–å¤šä¸ªäº‹ä»¶
            data = os.read(self.fd, 4096)  # è¯»å–4KBæ•°æ®
            events = self.parse_events(data)
            
            # æ‰¹é‡å¤„ç†
            return self.filter_and_process(events)
        return []
        
    def filter_and_process(self, events):
        """é«˜æ•ˆè¿‡æ»¤å’Œå¤„ç†äº‹ä»¶"""
        important_events = []
        
        for event in events:
            # å¿«é€Ÿè¿‡æ»¤ä¸å…³å¿ƒçš„äº‹ä»¶
            if event.mask & (IN_MODIFY | IN_CREATE | IN_DELETE):
                # ä½¿ç”¨ç¼“å­˜çš„è·¯å¾„ä¿¡æ¯
                path = self.watch_map.get(event.wd)
                if path and self.is_important_file(path):
                    important_events.append((path, event))
                    
        return important_events
        
    def is_important_file(self, path):
        """å¿«é€Ÿåˆ¤æ–­æ–‡ä»¶é‡è¦æ€§"""
        # ä½¿ç”¨ç®€å•çš„å­—ç¬¦ä¸²æ“ä½œï¼Œé¿å…å¤æ‚æ­£åˆ™
        return (path.endswith('.log') or 
                path.endswith('.conf') or
                'important' in path)
```

**CPUä½¿ç”¨ç‡ç›‘æ§**ï¼š
```bash
# ç›‘æ§ç‰¹å®šè¿›ç¨‹CPUä½¿ç”¨
top -p $(pidof your_monitor)

# ä½¿ç”¨perfåˆ†ææ€§èƒ½çƒ­ç‚¹
perf top -p $(pidof your_monitor)

# æŸ¥çœ‹ç³»ç»Ÿè°ƒç”¨é¢‘ç‡
strace -c -p $(pidof your_monitor)
```

---

## 4. ğŸ“¤ äº‹ä»¶é˜Ÿåˆ—æ·±åº¦è°ƒä¼˜


### 4.1 é˜Ÿåˆ—å·¥ä½œåŸç†


**äº‹ä»¶é˜Ÿåˆ—æœºåˆ¶è§£é‡Š**ï¼š
```
äº‹ä»¶äº§ç”Ÿ â†’ å†…æ ¸é˜Ÿåˆ— â†’ ç”¨æˆ·ç¨‹åºè¯»å–

å†…æ ¸é˜Ÿåˆ—ç»“æ„ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [äº‹ä»¶1] [äº‹ä»¶2] [äº‹ä»¶3] ... [äº‹ä»¶N] â”‚
â”‚  â†‘å¤´éƒ¨                    å°¾éƒ¨â†‘  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   è¯»å–                      å†™å…¥

é˜Ÿåˆ—æ»¡äº†ä¼šæ€æ ·ï¼Ÿ
â€¢ æ–°äº‹ä»¶è¢«ä¸¢å¼ƒï¼ˆIN_Q_OVERFLOWæ ‡å¿—ï¼‰
â€¢ ç¨‹åºæ”¶åˆ°é˜Ÿåˆ—æº¢å‡ºé€šçŸ¥
â€¢ å¯èƒ½é”™è¿‡é‡è¦æ–‡ä»¶å˜åŒ–
```

### 4.2 é˜Ÿåˆ—æ·±åº¦è°ƒä¼˜


**é˜Ÿåˆ—å¤§å°è®¡ç®—**ï¼š
```python
def calculate_optimal_queue_size():
    """è®¡ç®—æœ€ä½³é˜Ÿåˆ—æ·±åº¦"""
    
    # ä¼°ç®—å‚æ•°
    events_per_second = 1000    # æ¯ç§’äº‹ä»¶æ•°
    processing_time = 0.01      # å¤„ç†ä¸€ä¸ªäº‹ä»¶çš„æ—¶é—´ï¼ˆç§’ï¼‰
    safety_factor = 2.0         # å®‰å…¨ç³»æ•°
    
    # è®¡ç®—æ‰€éœ€é˜Ÿåˆ—æ·±åº¦
    required_depth = int(events_per_second * processing_time * safety_factor)
    
    print(f"å»ºè®®é˜Ÿåˆ—æ·±åº¦: {required_depth}")
    return required_depth

# åŠ¨æ€è°ƒæ•´é˜Ÿåˆ—å¤„ç†
class AdaptiveQueueHandler:
    def __init__(self, initial_batch_size=100):
        self.batch_size = initial_batch_size
        self.overflow_count = 0
        
    def handle_events(self, fd):
        """è‡ªé€‚åº”äº‹ä»¶å¤„ç†"""
        while True:
            try:
                # åŠ¨æ€è°ƒæ•´è¯»å–å¤§å°
                buffer_size = self.batch_size * 32  # æ¯ä¸ªäº‹ä»¶çº¦32å­—èŠ‚
                data = os.read(fd, buffer_size)
                
                if not data:
                    break
                    
                events = self.parse_events(data)
                
                # æ£€æŸ¥é˜Ÿåˆ—æº¢å‡º
                for event in events:
                    if event.mask & IN_Q_OVERFLOW:
                        self.overflow_count += 1
                        self.adjust_batch_size()
                        
            except OSError:
                break
                
    def adjust_batch_size(self):
        """æ ¹æ®æº¢å‡ºæƒ…å†µè°ƒæ•´æ‰¹æ¬¡å¤§å°"""
        if self.overflow_count > 10:
            self.batch_size *= 2  # å¢åŠ æ‰¹æ¬¡å¤§å°
            print(f"é˜Ÿåˆ—æº¢å‡ºè¿‡å¤šï¼Œæ‰¹æ¬¡å¤§å°è°ƒæ•´ä¸º: {self.batch_size}")
```

**é˜Ÿåˆ—ç›‘æ§è„šæœ¬**ï¼š
```bash
#!/bin/bash
# ç›‘æ§inotifyé˜Ÿåˆ—çŠ¶æ€

monitor_queue_status() {
    while true; do
        # æ£€æŸ¥é˜Ÿåˆ—ä½¿ç”¨æƒ…å†µ
        queue_size=$(cat /proc/sys/fs/inotify/max_queued_events)
        echo "é˜Ÿåˆ—æœ€å¤§æ·±åº¦: $queue_size"
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æº¢å‡º
        dmesg | tail -10 | grep -i "inotify" | grep -i "overflow"
        
        sleep 5
    done
}

monitor_queue_status
```

---

## 5. ğŸ”„ æ‰¹é‡äº‹ä»¶å¤„ç†æœºåˆ¶


### 5.1 æ‰¹é‡å¤„ç†åŸç†


**ä¸ºä»€ä¹ˆéœ€è¦æ‰¹é‡å¤„ç†ï¼Ÿ**
```
å•ä¸ªå¤„ç† vs æ‰¹é‡å¤„ç†ï¼š

å•ä¸ªå¤„ç†ï¼š
äº‹ä»¶1 â†’ å¤„ç†1 â†’ äº‹ä»¶2 â†’ å¤„ç†2 â†’ ...
å¼€é”€ï¼šNä¸ªäº‹ä»¶ = Næ¬¡å¤„ç†è°ƒç”¨

æ‰¹é‡å¤„ç†ï¼š
äº‹ä»¶1,2,3...N â†’ ä¸€æ¬¡æ‰¹é‡å¤„ç†
å¼€é”€ï¼šNä¸ªäº‹ä»¶ = 1æ¬¡å¤„ç†è°ƒç”¨ + æ‰¹é‡é€»è¾‘

æ•ˆç‡æå‡ï¼šå‡å°‘ç³»ç»Ÿè°ƒç”¨ï¼Œæé«˜ååé‡
```

### 5.2 æ‰¹é‡å¤„ç†å®ç°


**æ—¶é—´çª—å£æ‰¹é‡å¤„ç†**ï¼š
```python
import time
import threading
from collections import defaultdict

class BatchEventProcessor:
    def __init__(self, batch_size=100, timeout=1.0):
        self.batch_size = batch_size
        self.timeout = timeout
        self.event_buffer = []
        self.last_process_time = time.time()
        self.lock = threading.Lock()
        
    def add_event(self, event):
        """æ·»åŠ äº‹ä»¶åˆ°æ‰¹æ¬¡ç¼“å†²åŒº"""
        with self.lock:
            self.event_buffer.append(event)
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦å¤„ç†
            should_process = (
                len(self.event_buffer) >= self.batch_size or
                time.time() - self.last_process_time >= self.timeout
            )
            
            if should_process:
                self._process_batch()
                
    def _process_batch(self):
        """å¤„ç†å½“å‰æ‰¹æ¬¡çš„æ‰€æœ‰äº‹ä»¶"""
        if not self.event_buffer:
            return
            
        # å¤åˆ¶å¹¶æ¸…ç©ºç¼“å†²åŒº
        batch = self.event_buffer[:]
        self.event_buffer.clear()
        self.last_process_time = time.time()
        
        # æŒ‰æ–‡ä»¶åˆ†ç»„å¤„ç†
        file_events = defaultdict(list)
        for event in batch:
            file_events[event.path].append(event)
            
        # æ‰¹é‡å¤„ç†æ¯ä¸ªæ–‡ä»¶çš„äº‹ä»¶
        for filepath, events in file_events.items():
            self._process_file_events(filepath, events)
            
    def _process_file_events(self, filepath, events):
        """å¤„ç†å•ä¸ªæ–‡ä»¶çš„å¤šä¸ªäº‹ä»¶"""
        # äº‹ä»¶å»é‡å’Œåˆå¹¶
        has_modify = any(e.mask & IN_MODIFY for e in events)
        has_delete = any(e.mask & IN_DELETE for e in events)
        has_create = any(e.mask & IN_CREATE for e in events)
        
        # æ™ºèƒ½å¤„ç†ï¼šåˆ é™¤ååˆ›å»ºå¯èƒ½æ˜¯é‡å‘½å
        if has_delete and has_create:
            print(f"æ–‡ä»¶å¯èƒ½è¢«é‡å‘½å: {filepath}")
        elif has_modify:
            print(f"æ–‡ä»¶è¢«ä¿®æ”¹: {filepath}")
        elif has_create:
            print(f"æ–‡ä»¶è¢«åˆ›å»º: {filepath}")
        elif has_delete:
            print(f"æ–‡ä»¶è¢«åˆ é™¤: {filepath}")
```

**åˆ†ç±»æ‰¹é‡å¤„ç†**ï¼š
```python
class CategoryBatchProcessor:
    def __init__(self):
        self.processors = {
            'log': self.process_log_files,
            'config': self.process_config_files,
            'data': self.process_data_files,
        }
        
    def categorize_event(self, event):
        """æ ¹æ®æ–‡ä»¶ç±»å‹åˆ†ç±»äº‹ä»¶"""
        path = event.path.lower()
        if path.endswith('.log'):
            return 'log'
        elif path.endswith(('.conf', '.ini', '.yaml')):
            return 'config'
        elif path.endswith(('.data', '.db')):
            return 'data'
        return 'other'
        
    def process_batch_by_category(self, events):
        """æŒ‰ç±»åˆ«æ‰¹é‡å¤„ç†äº‹ä»¶"""
        categorized = defaultdict(list)
        
        # äº‹ä»¶åˆ†ç±»
        for event in events:
            category = self.categorize_event(event)
            categorized[category].append(event)
            
        # åˆ†ç±»å¤„ç†
        for category, category_events in categorized.items():
            processor = self.processors.get(category)
            if processor:
                processor(category_events)
                
    def process_log_files(self, events):
        """ä¸“é—¨å¤„ç†æ—¥å¿—æ–‡ä»¶äº‹ä»¶"""
        print(f"æ‰¹é‡å¤„ç† {len(events)} ä¸ªæ—¥å¿—æ–‡ä»¶äº‹ä»¶")
        # æ—¥å¿—æ–‡ä»¶ç‰¹æ®Šå¤„ç†é€»è¾‘
        
    def process_config_files(self, events):
        """ä¸“é—¨å¤„ç†é…ç½®æ–‡ä»¶äº‹ä»¶"""
        print(f"æ‰¹é‡å¤„ç† {len(events)} ä¸ªé…ç½®æ–‡ä»¶äº‹ä»¶")
        # é…ç½®æ–‡ä»¶ç‰¹æ®Šå¤„ç†é€»è¾‘
```

---

## 6. ğŸ—ï¸ ç›‘æ§å±‚æ¬¡ç»“æ„è®¾è®¡


### 6.1 å±‚æ¬¡ç›‘æ§ç­–ç•¥


**ç›‘æ§å±‚æ¬¡è®¾è®¡åŸåˆ™**ï¼š
```
å±‚æ¬¡åŒ–ç›‘æ§ç»“æ„ï¼š

æ ¹ç›®å½•ç›‘æ§
â”œâ”€â”€ åº”ç”¨ç›®å½•ç›‘æ§
â”‚   â”œâ”€â”€ æ—¥å¿—ç›®å½•
â”‚   â”œâ”€â”€ é…ç½®ç›®å½•
â”‚   â””â”€â”€ æ•°æ®ç›®å½•
â”œâ”€â”€ ç³»ç»Ÿç›®å½•ç›‘æ§
â”‚   â”œâ”€â”€ /etcï¼ˆé…ç½®ç›‘æ§ï¼‰
â”‚   â”œâ”€â”€ /var/logï¼ˆæ—¥å¿—ç›‘æ§ï¼‰
â”‚   â””â”€â”€ /tmpï¼ˆä¸´æ—¶æ–‡ä»¶ç›‘æ§ï¼‰
â””â”€â”€ ç”¨æˆ·ç›®å½•ç›‘æ§

è®¾è®¡è€ƒè™‘ï¼š
â€¢ é‡è¦ç¨‹åº¦ï¼šæ ¸å¿ƒç›®å½•æ·±åº¦ç›‘æ§ï¼Œä¸€èˆ¬ç›®å½•æµ…å±‚ç›‘æ§
â€¢ é¢‘ç‡æ§åˆ¶ï¼šé«˜é¢‘ç›®å½•ä½¿ç”¨è¿‡æ»¤å™¨
â€¢ èµ„æºåˆ†é…ï¼šæŒ‰é‡è¦æ€§åˆ†é…ç›‘æ§èµ„æº
```

### 6.2 å±‚æ¬¡ç›‘æ§å®ç°


**åˆ†å±‚ç›‘æ§ç®¡ç†å™¨**ï¼š
```python
class HierarchicalMonitor:
    def __init__(self):
        self.monitors = {}
        self.hierarchy = {
            'critical': {  # å…³é”®ç›®å½•ï¼šæ·±åº¦ç›‘æ§
                'paths': ['/etc', '/var/log'],
                'depth': -1,  # æ— é™æ·±åº¦
                'events': 'all',
            },
            'important': {  # é‡è¦ç›®å½•ï¼šä¸­åº¦ç›‘æ§
                'paths': ['/home', '/opt'],
                'depth': 3,   # ç›‘æ§3å±‚æ·±åº¦
                'events': ['modify', 'create', 'delete'],
            },
            'normal': {    # ä¸€èˆ¬ç›®å½•ï¼šæµ…å±‚ç›‘æ§
                'paths': ['/tmp', '/var/tmp'],
                'depth': 1,   # åªç›‘æ§1å±‚
                'events': ['create', 'delete'],
            }
        }
        
    def setup_hierarchical_monitoring(self):
        """è®¾ç½®åˆ†å±‚ç›‘æ§"""
        for level, config in self.hierarchy.items():
            monitor = self.create_level_monitor(level, config)
            self.monitors[level] = monitor
            
    def create_level_monitor(self, level, config):
        """ä¸ºç‰¹å®šå±‚çº§åˆ›å»ºç›‘æ§å™¨"""
        monitor = inotify.adapters.Inotify()
        
        for base_path in config['paths']:
            if os.path.exists(base_path):
                self.add_hierarchical_watches(
                    monitor, base_path, 
                    config['depth'], config['events']
                )
                
        return monitor
        
    def add_hierarchical_watches(self, monitor, path, max_depth, event_types):
        """é€’å½’æ·»åŠ åˆ†å±‚ç›‘æ§"""
        if max_depth == 0:
            return
            
        # æ„å»ºäº‹ä»¶æ©ç 
        mask = self.build_event_mask(event_types)
        
        try:
            monitor.add_watch(path, mask)
            print(f"ç›‘æ§å·²æ·»åŠ : {path} (æ·±åº¦: {max_depth})")
        except OSError as e:
            print(f"ç›‘æ§æ·»åŠ å¤±è´¥: {path}, é”™è¯¯: {e}")
            return
            
        # é€’å½’ç›‘æ§å­ç›®å½•
        if max_depth > 1 or max_depth == -1:
            try:
                for item in os.listdir(path):
                    item_path = os.path.join(path, item)
                    if os.path.isdir(item_path):
                        next_depth = max_depth - 1 if max_depth > 0 else -1
                        self.add_hierarchical_watches(
                            monitor, item_path, next_depth, event_types
                        )
            except PermissionError:
                print(f"æƒé™ä¸è¶³ï¼Œè·³è¿‡ç›®å½•: {path}")
                
    def build_event_mask(self, event_types):
        """æ ¹æ®äº‹ä»¶ç±»å‹æ„å»ºæ©ç """
        mask_map = {
            'modify': 0x002,    # IN_MODIFY
            'create': 0x100,    # IN_CREATE
            'delete': 0x200,    # IN_DELETE
            'move': 0x080,      # IN_MOVE
        }
        
        if event_types == 'all':
            return 0x002 | 0x100 | 0x200 | 0x080
            
        mask = 0
        for event_type in event_types:
            mask |= mask_map.get(event_type, 0)
        return mask
```

**åŠ¨æ€å±‚æ¬¡è°ƒæ•´**ï¼š
```python
class DynamicHierarchyManager:
    def __init__(self):
        self.load_stats = {}  # è®°å½•å„è·¯å¾„çš„è´Ÿè½½ç»Ÿè®¡
        
    def monitor_load(self, path, event_count):
        """ç›‘æ§è·¯å¾„è´Ÿè½½"""
        if path not in self.load_stats:
            self.load_stats[path] = {'count': 0, 'last_check': time.time()}
            
        stats = self.load_stats[path]
        stats['count'] += event_count
        
        # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡è´Ÿè½½
        if time.time() - stats['last_check'] > 60:
            self.adjust_monitoring_level(path, stats['count'])
            stats['count'] = 0
            stats['last_check'] = time.time()
            
    def adjust_monitoring_level(self, path, event_count):
        """æ ¹æ®è´Ÿè½½åŠ¨æ€è°ƒæ•´ç›‘æ§çº§åˆ«"""
        if event_count > 1000:  # é«˜è´Ÿè½½
            print(f"è·¯å¾„ {path} è´Ÿè½½è¿‡é«˜({event_count}äº‹ä»¶/åˆ†é’Ÿ)ï¼Œé™ä½ç›‘æ§æ·±åº¦")
            # å®æ–½é™çº§ç­–ç•¥
        elif event_count < 10:  # ä½è´Ÿè½½
            print(f"è·¯å¾„ {path} è´Ÿè½½è¾ƒä½({event_count}äº‹ä»¶/åˆ†é’Ÿ)ï¼Œå¯ä»¥æé«˜ç›‘æ§æ·±åº¦")
            # å®æ–½å‡çº§ç­–ç•¥
```

---

## 7. âš–ï¸ è´Ÿè½½å‡è¡¡ç›‘æ§åˆ†å¸ƒ


### 7.1 ç›‘æ§è´Ÿè½½åˆ†å¸ƒåŸç†


**è´Ÿè½½å‡è¡¡çš„å¿…è¦æ€§**ï¼š
```
å•è¿›ç¨‹ç›‘æ§é—®é¢˜ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å•ä¸ªè¿›ç¨‹å¤„ç†æ‰€æœ‰ç›‘æ§ç‚¹           â”‚
â”‚ â”œâ”€â”€ ç›‘æ§ç‚¹1 (é«˜é¢‘)              â”‚
â”‚ â”œâ”€â”€ ç›‘æ§ç‚¹2 (ä¸­é¢‘)              â”‚
â”‚ â”œâ”€â”€ ç›‘æ§ç‚¹3 (ä½é¢‘)              â”‚
â”‚ â””â”€â”€ ... ç›‘æ§ç‚¹N                 â”‚
â”‚ é—®é¢˜ï¼šé«˜é¢‘ç›‘æ§å½±å“æ•´ä½“æ€§èƒ½       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

å¤šè¿›ç¨‹è´Ÿè½½å‡è¡¡ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   è¿›ç¨‹1     â”‚ â”‚   è¿›ç¨‹2     â”‚ â”‚   è¿›ç¨‹3     â”‚
â”‚ ç›‘æ§ç‚¹1,4,7 â”‚ â”‚ ç›‘æ§ç‚¹2,5,8 â”‚ â”‚ ç›‘æ§ç‚¹3,6,9 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ä¼˜åŠ¿ï¼šè´Ÿè½½åˆ†æ•£ï¼Œæ€§èƒ½æ›´å¥½ï¼Œæ•…éšœéš”ç¦»
```

### 7.2 è´Ÿè½½å‡è¡¡å®ç°


**åŸºäºå“ˆå¸Œçš„åˆ†å¸ƒç­–ç•¥**ï¼š
```python
import hashlib
import multiprocessing
from multiprocessing import Manager

class LoadBalancedMonitor:
    def __init__(self, worker_count=4):
        self.worker_count = worker_count
        self.workers = []
        self.shared_queue = Manager().Queue()
        
    def distribute_paths(self, paths):
        """æ ¹æ®è·¯å¾„å“ˆå¸Œåˆ†å¸ƒç›‘æ§ä»»åŠ¡"""
        distributed = [[] for _ in range(self.worker_count)]
        
        for path in paths:
            # ä½¿ç”¨è·¯å¾„å“ˆå¸Œç¡®å®šåˆ†é…ç»™å“ªä¸ªè¿›ç¨‹
            hash_value = hashlib.md5(path.encode()).hexdigest()
            worker_index = int(hash_value, 16) % self.worker_count
            distributed[worker_index].append(path)
            
        return distributed
        
    def create_worker(self, worker_id, paths):
        """åˆ›å»ºç›‘æ§å·¥ä½œè¿›ç¨‹"""
        def worker_process():
            print(f"å·¥ä½œè¿›ç¨‹ {worker_id} å¯åŠ¨ï¼Œç›‘æ§ {len(paths)} ä¸ªè·¯å¾„")
            
            monitor = inotify.adapters.Inotify()
            
            # ä¸ºåˆ†é…çš„è·¯å¾„æ·»åŠ ç›‘æ§
            for path in paths:
                try:
                    monitor.add_watch(path, 0x002 | 0x100 | 0x200)
                except OSError as e:
                    print(f"å·¥ä½œè¿›ç¨‹ {worker_id} æ·»åŠ ç›‘æ§å¤±è´¥: {path}, {e}")
                    continue
                    
            # ç›‘æ§äº‹ä»¶å¤„ç†å¾ªç¯
            for event in monitor.event_gen():
                if event is not None:
                    # å°†äº‹ä»¶æ”¾å…¥å…±äº«é˜Ÿåˆ—
                    self.shared_queue.put({
                        'worker_id': worker_id,
                        'event': event,
                        'timestamp': time.time()
                    })
                    
        return multiprocessing.Process(target=worker_process)
        
    def start_balanced_monitoring(self, all_paths):
        """å¯åŠ¨è´Ÿè½½å‡è¡¡ç›‘æ§"""
        # åˆ†å¸ƒè·¯å¾„åˆ°å„ä¸ªå·¥ä½œè¿›ç¨‹
        distributed_paths = self.distribute_paths(all_paths)
        
        # åˆ›å»ºå¹¶å¯åŠ¨å·¥ä½œè¿›ç¨‹
        for worker_id, paths in enumerate(distributed_paths):
            if paths:  # åªä¸ºæœ‰ä»»åŠ¡çš„è¿›ç¨‹åˆ›å»ºå·¥ä½œè¿›ç¨‹
                worker = self.create_worker(worker_id, paths)
                self.workers.append(worker)
                worker.start()
                
        print(f"å¯åŠ¨äº† {len(self.workers)} ä¸ªå·¥ä½œè¿›ç¨‹")
        
        # å¯åŠ¨äº‹ä»¶æ”¶é›†çº¿ç¨‹
        collector_thread = threading.Thread(target=self.collect_events)
        collector_thread.daemon = True
        collector_thread.start()
        
    def collect_events(self):
        """æ”¶é›†æ‰€æœ‰å·¥ä½œè¿›ç¨‹çš„äº‹ä»¶"""
        while True:
            try:
                event_data = self.shared_queue.get(timeout=1)
                self.process_collected_event(event_data)
            except:
                continue
                
    def process_collected_event(self, event_data):
        """å¤„ç†æ”¶é›†åˆ°çš„äº‹ä»¶"""
        worker_id = event_data['worker_id']
        event = event_data['event']
        timestamp = event_data['timestamp']
        
        print(f"å·¥ä½œè¿›ç¨‹ {worker_id} æŠ¥å‘Šäº‹ä»¶: {event[1].name} åœ¨ {event[2]}")
```

**åŠ¨æ€è´Ÿè½½é‡å¹³è¡¡**ï¼š
```python
class DynamicLoadBalancer:
    def __init__(self):
        self.worker_loads = {}  # è®°å½•å„å·¥ä½œè¿›ç¨‹çš„è´Ÿè½½
        self.rebalance_threshold = 100  # è´Ÿè½½ä¸å¹³è¡¡é˜ˆå€¼
        
    def monitor_worker_load(self, worker_id):
        """ç›‘æ§å·¥ä½œè¿›ç¨‹è´Ÿè½½"""
        if worker_id not in self.worker_loads:
            self.worker_loads[worker_id] = {
                'event_count': 0,
                'last_reset': time.time()
            }
            
        load_info = self.worker_loads[worker_id]
        load_info['event_count'] += 1
        
        # æ¯åˆ†é’Ÿæ£€æŸ¥è´Ÿè½½å¹³è¡¡
        if time.time() - load_info['last_reset'] > 60:
            self.check_load_balance()
            # é‡ç½®è®¡æ•°å™¨
            for worker_id in self.worker_loads:
                self.worker_loads[worker_id]['event_count'] = 0
                self.worker_loads[worker_id]['last_reset'] = time.time()
                
    def check_load_balance(self):
        """æ£€æŸ¥è´Ÿè½½å¹³è¡¡çŠ¶å†µ"""
        if len(self.worker_loads) < 2:
            return
            
        loads = [info['event_count'] for info in self.worker_loads.values()]
        max_load = max(loads)
        min_load = min(loads)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡å¹³è¡¡
        if max_load - min_load > self.rebalance_threshold:
            print(f"æ£€æµ‹åˆ°è´Ÿè½½ä¸å¹³è¡¡: æœ€é«˜{max_load}, æœ€ä½{min_load}")
            self.trigger_rebalance()
            
    def trigger_rebalance(self):
        """è§¦å‘è´Ÿè½½é‡å¹³è¡¡"""
        print("å¼€å§‹è´Ÿè½½é‡å¹³è¡¡...")
        # å®æ–½é‡å¹³è¡¡ç­–ç•¥ï¼š
        # 1. æš‚åœé«˜è´Ÿè½½è¿›ç¨‹çš„éƒ¨åˆ†ç›‘æ§
        # 2. å°†ç›‘æ§ä»»åŠ¡è¿ç§»åˆ°ä½è´Ÿè½½è¿›ç¨‹
        # 3. é‡æ–°å¯åŠ¨ç›¸å…³è¿›ç¨‹
```

---

## 8. ğŸ“Š èµ„æºä½¿ç”¨ç‡ç›‘æ§


### 8.1 ç›‘æ§æŒ‡æ ‡ä½“ç³»


**æ ¸å¿ƒç›‘æ§æŒ‡æ ‡**ï¼š
```
ç³»ç»Ÿèµ„æºæŒ‡æ ‡ï¼š
â”œâ”€â”€ CPUä½¿ç”¨ç‡ï¼šç›‘æ§è¿›ç¨‹CPUå ç”¨
â”œâ”€â”€ å†…å­˜ä½¿ç”¨é‡ï¼šç‰©ç†å†…å­˜å’Œè™šæ‹Ÿå†…å­˜
â”œâ”€â”€ æ–‡ä»¶æè¿°ç¬¦ï¼šæ‰“å¼€çš„æ–‡ä»¶å¥æŸ„æ•°é‡
â””â”€â”€ ç½‘ç»œIOï¼šå¦‚æœæ¶‰åŠè¿œç¨‹ç›‘æ§

inotifyä¸“ç”¨æŒ‡æ ‡ï¼š
â”œâ”€â”€ ç›‘æ§å®ä¾‹æ•°ï¼šå½“å‰åˆ›å»ºçš„å®ä¾‹æ•°é‡
â”œâ”€â”€ ç›‘æ§ç‚¹æ•°é‡ï¼šå®é™…ç›‘æ§çš„æ–‡ä»¶/ç›®å½•æ•°
â”œâ”€â”€ äº‹ä»¶é˜Ÿåˆ—æ·±åº¦ï¼šå¾…å¤„ç†äº‹ä»¶æ•°é‡
â””â”€â”€ äº‹ä»¶å¤„ç†é€Ÿåº¦ï¼šæ¯ç§’å¤„ç†çš„äº‹ä»¶æ•°
```

### 8.2 èµ„æºç›‘æ§å®ç°


**ç³»ç»Ÿèµ„æºç›‘æ§å™¨**ï¼š
```python
import psutil
import time

class ResourceMonitor:
    def __init__(self, monitor_pid=None):
        self.monitor_pid = monitor_pid or os.getpid()
        self.process = psutil.Process(self.monitor_pid)
        self.stats_history = []
        
    def collect_system_stats(self):
        """æ”¶é›†ç³»ç»Ÿèµ„æºç»Ÿè®¡"""
        try:
            stats = {
                'timestamp': time.time(),
                'cpu_percent': self.process.cpu_percent(),
                'memory_mb': self.process.memory_info().rss / 1024 / 1024,
                'open_files': len(self.process.open_files()),
                'threads': self.process.num_threads(),
            }
            
            # æ·»åŠ åˆ°å†å²è®°å½•
            self.stats_history.append(stats)
            
            # ä¿ç•™æœ€è¿‘100æ¡è®°å½•
            if len(self.stats_history) > 100:
                self.stats_history.pop(0)
                
            return stats
            
        except psutil.NoSuchProcess:
            return None
            
    def get_resource_usage_report(self):
        """ç”Ÿæˆèµ„æºä½¿ç”¨æŠ¥å‘Š"""
        if not self.stats_history:
            return "æš‚æ— ç»Ÿè®¡æ•°æ®"
            
        recent_stats = self.stats_history[-10:]  # æœ€è¿‘10æ¡è®°å½•
        
        avg_cpu = sum(s['cpu_percent'] for s in recent_stats) / len(recent_stats)
        avg_memory = sum(s['memory_mb'] for s in recent_stats) / len(recent_stats)
        max_files = max(s['open_files'] for s in recent_stats)
        
        report = f"""
ğŸ“Š èµ„æºä½¿ç”¨ç»Ÿè®¡æŠ¥å‘Š
====================
âš¡ å¹³å‡CPUä½¿ç”¨ç‡: {avg_cpu:.1f}%
ğŸ’¾ å¹³å‡å†…å­˜ä½¿ç”¨: {avg_memory:.1f} MB
ğŸ“ æœ€å¤§æ–‡ä»¶å¥æŸ„: {max_files}
ğŸ§µ çº¿ç¨‹æ•°é‡: {recent_stats[-1]['threads']}
ğŸ“ˆ ç›‘æ§æ—¶é•¿: {len(self.stats_history)} åˆ†é’Ÿ
        """
        
        return report
        
    def check_resource_alerts(self):
        """æ£€æŸ¥èµ„æºä½¿ç”¨è­¦æŠ¥"""
        if not self.stats_history:
            return []
            
        alerts = []
        latest = self.stats_history[-1]
        
        # CPUä½¿ç”¨ç‡è­¦æŠ¥
        if latest['cpu_percent'] > 80:
            alerts.append(f"âš ï¸ CPUä½¿ç”¨ç‡è¿‡é«˜: {latest['cpu_percent']:.1f}%")
            
        # å†…å­˜ä½¿ç”¨è­¦æŠ¥
        if latest['memory_mb'] > 500:
            alerts.append(f"âš ï¸ å†…å­˜ä½¿ç”¨è¿‡å¤š: {latest['memory_mb']:.1f} MB")
            
        # æ–‡ä»¶å¥æŸ„è­¦æŠ¥
        if latest['open_files'] > 1000:
            alerts.append(f"âš ï¸ æ–‡ä»¶å¥æŸ„è¿‡å¤š: {latest['open_files']}")
            
        return alerts
```

**inotifyä¸“ç”¨ç›‘æ§**ï¼š
```python
class InotifyMonitor:
    def __init__(self):
        self.stats = {
            'total_watches': 0,
            'active_instances': 0,
            'events_processed': 0,
            'queue_overflows': 0,
            'start_time': time.time()
        }
        
    def get_inotify_limits(self):
        """è·å–inotifyç³»ç»Ÿé™åˆ¶"""
        limits = {}
        try:
            with open('/proc/sys/fs/inotify/max_user_instances') as f:
                limits['max_instances'] = int(f.read().strip())
            with open('/proc/sys/fs/inotify/max_user_watches') as f:
                limits['max_watches'] = int(f.read().strip())
            with open('/proc/sys/fs/inotify/max_queued_events') as f:
                limits['max_events'] = int(f.read().strip())
        except:
            limits = {'max_instances': 0, 'max_watches': 0, 'max_events': 0}
            
        return limits
        
    def check_inotify_usage(self):
        """æ£€æŸ¥inotifyä½¿ç”¨æƒ…å†µ"""
        limits = self.get_inotify_limits()
        
        usage_report = f"""
ğŸ” inotifyä½¿ç”¨æƒ…å†µ
===================
ğŸ“Š ç›‘æ§å®ä¾‹: {self.stats['active_instances']}/{limits['max_instances']}
ğŸ‘ï¸ ç›‘æ§ç‚¹æ•°: {self.stats['total_watches']}/{limits['max_watches']}
âš¡ å¤„ç†äº‹ä»¶: {self.stats['events_processed']}
âš ï¸ é˜Ÿåˆ—æº¢å‡º: {self.stats['queue_overflows']}
â±ï¸ è¿è¡Œæ—¶é—´: {(time.time() - self.stats['start_time'])/3600:.1f} å°æ—¶
        """
        
        # ä½¿ç”¨ç‡è®¡ç®—
        instance_usage = (self.stats['active_instances'] / limits['max_instances'] * 100) if limits['max_instances'] > 0 else 0
        watch_usage = (self.stats['total_watches'] / limits['max_watches'] * 100) if limits['max_watches'] > 0 else 0
        
        usage_report += f"""
ğŸ“ˆ ä½¿ç”¨ç‡åˆ†æ
=============
å®ä¾‹ä½¿ç”¨ç‡: {instance_usage:.1f}%
ç›‘æ§ç‚¹ä½¿ç”¨ç‡: {watch_usage:.1f}%
        """
        
        return usage_report
```

---

## 9. ğŸš€ æ‰©å±•æ€§æ¶æ„è®¾è®¡


### 9.1 å¯æ‰©å±•æ¶æ„åŸåˆ™


**æ¶æ„è®¾è®¡æ€æƒ³**ï¼š
```
åˆ†å±‚æ‰©å±•æ¶æ„ï¼š

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            åº”ç”¨å±‚                   â”‚ â† ä¸šåŠ¡é€»è¾‘ï¼Œå¯æ’æ‹”æ¨¡å—
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚            åˆ†å‘å±‚                   â”‚ â† äº‹ä»¶è·¯ç”±ï¼Œè´Ÿè½½å‡è¡¡
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚            æ”¶é›†å±‚                   â”‚ â† äº‹ä»¶æ”¶é›†ï¼Œæ•°æ®èšåˆ
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚            ç›‘æ§å±‚                   â”‚ â† inotifyå®ä¾‹ï¼Œæ–‡ä»¶ç›‘æ§
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

è®¾è®¡åŸåˆ™ï¼š
ğŸ”¸ æ¨¡å—åŒ–ï¼šæ¯å±‚ç‹¬ç«‹ï¼Œæ¥å£æ¸…æ™°
ğŸ”¸ å¯æ›¿æ¢ï¼šç»„ä»¶å¯ç‹¬ç«‹å‡çº§æ›¿æ¢
ğŸ”¸ å¯æ‰©å±•ï¼šæ”¯æŒæ°´å¹³å’Œå‚ç›´æ‰©å±•
ğŸ”¸ å®¹é”™æ€§ï¼šå•ç‚¹æ•…éšœä¸å½±å“æ•´ä½“
```

### 9.2 æ‰©å±•æ€§æ¶æ„å®ç°


**æ’ä»¶åŒ–äº‹ä»¶å¤„ç†**ï¼š
```python
from abc import ABC, abstractmethod

class EventProcessor(ABC):
    """äº‹ä»¶å¤„ç†å™¨åŸºç±»"""
    
    @abstractmethod
    def can_handle(self, event):
        """åˆ¤æ–­æ˜¯å¦èƒ½å¤„ç†è¯¥äº‹ä»¶"""
        pass
        
    @abstractmethod
    def process(self, event):
        """å¤„ç†äº‹ä»¶"""
        pass
        
    @property
    @abstractmethod
    def priority(self):
        """å¤„ç†ä¼˜å…ˆçº§"""
        pass

class LogFileProcessor(EventProcessor):
    """æ—¥å¿—æ–‡ä»¶äº‹ä»¶å¤„ç†å™¨"""
    
    def can_handle(self, event):
        return event.path.endswith('.log')
        
    def process(self, event):
        print(f"å¤„ç†æ—¥å¿—æ–‡ä»¶äº‹ä»¶: {event.path}")
        # æ—¥å¿—æ–‡ä»¶ç‰¹æ®Šå¤„ç†é€»è¾‘
        
    @property
    def priority(self):
        return 1  # é«˜ä¼˜å…ˆçº§

class ConfigFileProcessor(EventProcessor):
    """é…ç½®æ–‡ä»¶äº‹ä»¶å¤„ç†å™¨"""
    
    def can_handle(self, event):
        return event.path.endswith(('.conf', '.ini', '.yaml'))
        
    def process(self, event):
        print(f"å¤„ç†é…ç½®æ–‡ä»¶äº‹ä»¶: {event.path}")
        # é…ç½®æ–‡ä»¶ç‰¹æ®Šå¤„ç†é€»è¾‘
        
    @property
    def priority(self):
        return 2  # ä¸­ä¼˜å…ˆçº§

class ExtensibleMonitor:
    def __init__(self):
        self.processors = []
        
    def register_processor(self, processor):
        """æ³¨å†Œäº‹ä»¶å¤„ç†å™¨"""
        self.processors.append(processor)
        # æŒ‰ä¼˜å…ˆçº§æ’åº
        self.processors.sort(key=lambda p: p.priority)
        
    def process_event(self, event):
        """ä½¿ç”¨åˆé€‚çš„å¤„ç†å™¨å¤„ç†äº‹ä»¶"""
        for processor in self.processors:
            if processor.can_handle(event):
                processor.process(event)
                break
```

**åˆ†å¸ƒå¼æ‰©å±•æ¶æ„**ï¼š
```python
import zmq
import json
import threading

class DistributedMonitorNode:
    """åˆ†å¸ƒå¼ç›‘æ§èŠ‚ç‚¹"""
    
    def __init__(self, node_id, coordinator_address="tcp://localhost:5555"):
        self.node_id = node_id
        self.coordinator_address = coordinator_address
        self.context = zmq.Context()
        
        # ä¸åè°ƒå™¨é€šä¿¡
        self.coordinator_socket = self.context.socket(zmq.REQ)
        self.coordinator_socket.connect(coordinator_address)
        
        # æ¥æ”¶ä»»åŠ¡çš„socket
        self.task_socket = self.context.socket(zmq.PULL)
        self.task_port = self.task_socket.bind_to_random_port("tcp://*")
        
        # å‘é€ç»“æœçš„socket
        self.result_socket = self.context.socket(zmq.PUSH)
        
    def register_with_coordinator(self):
        """å‘åè°ƒå™¨æ³¨å†ŒèŠ‚ç‚¹"""
        registration = {
            'action': 'register',
            'node_id': self.node_id,
            'task_port': self.task_port,
            'capabilities': ['inotify', 'file_monitor']
        }
        
        self.coordinator_socket.send_string(json.dumps(registration))
        response = self.coordinator_socket.recv_string()
        
        response_data = json.loads(response)
        if response_data.get('status') == 'registered':
            self.result_socket.connect(response_data['result_address'])
            print(f"èŠ‚ç‚¹ {self.node_id} æ³¨å†ŒæˆåŠŸ")
            return True
        return False
        
    def start_monitoring(self):
        """å¼€å§‹ç›‘æ§ä»»åŠ¡"""
        while True:
            # æ¥æ”¶ç›‘æ§ä»»åŠ¡
            task_data = self.task_socket.recv_string()
            task = json.loads(task_data)
            
            # å¤„ç†ä»»åŠ¡
            result = self.execute_monitor_task(task)
            
            # å‘é€ç»“æœ
            self.result_socket.send_string(json.dumps(result))
            
    def execute_monitor_task(self, task):
        """æ‰§è¡Œç›‘æ§ä»»åŠ¡"""
        path = task['path']
        events = task.get('events', ['modify', 'create', 'delete'])
        
        print(f"èŠ‚ç‚¹ {self.node_id} å¼€å§‹ç›‘æ§ {path}")
        
        # åˆ›å»ºinotifyç›‘æ§
        monitor = inotify.adapters.Inotify()
        try:
            monitor.add_watch(path, self.build_mask(events))
            
            # ç›‘æ§äº‹ä»¶
            for event in monitor.event_gen():
                if event:
                    return {
                        'node_id': self.node_id,
                        'path': path,
                        'event': {
                            'type': event[1].name,
                            'file': event[2],
                            'timestamp': time.time()
                        }
                    }
        except Exception as e:
            return {
                'node_id': self.node_id,
                'error': str(e),
                'path': path
            }

class MonitorCoordinator:
    """ç›‘æ§åè°ƒå™¨"""
    
    def __init__(self, port=5555):
        self.context = zmq.Context()
        self.nodes = {}  # æ³¨å†Œçš„èŠ‚ç‚¹
        
        # å¤„ç†èŠ‚ç‚¹æ³¨å†Œçš„socket
        self.register_socket = self.context.socket(zmq.REP)
        self.register_socket.bind(f"tcp://*:{port}")
        
        # åˆ†å‘ä»»åŠ¡çš„socket
        self.task_sockets = {}
        
        # æ”¶é›†ç»“æœçš„socket
        self.result_socket = self.context.socket(zmq.PULL)
        self.result_port = self.result_socket.bind_to_random_port("tcp://*")
        
    def handle_registrations(self):
        """å¤„ç†èŠ‚ç‚¹æ³¨å†Œ"""
        while True:
            message = self.register_socket.recv_string()
            request = json.loads(message)
            
            if request['action'] == 'register':
                node_id = request['node_id']
                task_port = request['task_port']
                
                # æ³¨å†ŒèŠ‚ç‚¹
                self.nodes[node_id] = {
                    'task_port': task_port,
                    'capabilities': request.get('capabilities', [])
                }
                
                # åˆ›å»ºä»»åŠ¡åˆ†å‘socket
                task_socket = self.context.socket(zmq.PUSH)
                task_socket.connect(f"tcp://localhost:{task_port}")
                self.task_sockets[node_id] = task_socket
                
                # å“åº”æ³¨å†ŒæˆåŠŸ
                response = {
                    'status': 'registered',
                    'result_address': f"tcp://localhost:{self.result_port}"
                }
                self.register_socket.send_string(json.dumps(response))
                
                print(f"èŠ‚ç‚¹ {node_id} å·²æ³¨å†Œ")
                
    def distribute_monitor_tasks(self, paths):
        """åˆ†å‘ç›‘æ§ä»»åŠ¡åˆ°å„ä¸ªèŠ‚ç‚¹"""
        if not self.nodes:
            print("æ²¡æœ‰å¯ç”¨çš„ç›‘æ§èŠ‚ç‚¹")
            return
            
        node_ids = list(self.nodes.keys())
        
        for i, path in enumerate(paths):
            # è½®è¯¢åˆ†é…ä»»åŠ¡
            node_id = node_ids[i % len(node_ids)]
            task = {
                'path': path,
                'events': ['modify', 'create', 'delete']
            }
            
            self.task_sockets[node_id].send_string(json.dumps(task))
            print(f"ä»»åŠ¡å·²åˆ†å‘åˆ°èŠ‚ç‚¹ {node_id}: {path}")
```

**äº‘åŸç”Ÿæ‰©å±•æ”¯æŒ**ï¼š
```yaml
# docker-compose.yml for scalable monitoring
version: '3.8'
services:
  coordinator:
    build: .
    command: python coordinator.py
    ports:
      - "5555:5555"
    environment:
      - ROLE=coordinator
      
  monitor-node:
    build: .
    command: python monitor_node.py
    environment:
      - ROLE=node
      - COORDINATOR_URL=tcp://coordinator:5555
    volumes:
      - /path/to/monitor:/monitor
    deploy:
      replicas: 3  # å¯åŠ¨æ€æ‰©å±•èŠ‚ç‚¹æ•°é‡
      
  result-collector:
    build: .
    command: python result_collector.py
    environment:
      - ROLE=collector
    depends_on:
      - coordinator
```

---

## 10. ğŸ“‹ æ ¸å¿ƒè¦ç‚¹æ€»ç»“


### 10.1 å¿…é¡»æŒæ¡çš„ä¼˜åŒ–è¦ç‚¹


```
ğŸ”¸ èµ„æºé™åˆ¶ç®¡ç†ï¼šäº†è§£å¹¶åˆç†é…ç½®inotifyç³»ç»Ÿé™åˆ¶
ğŸ”¸ å†…å­˜ä¼˜åŒ–ï¼šé€‰æ‹©æ€§ç›‘æ§ï¼Œé¿å…ç›‘æ§ä¸å¿…è¦çš„æ–‡ä»¶
ğŸ”¸ CPUæ§åˆ¶ï¼šæ‰¹é‡å¤„ç†äº‹ä»¶ï¼Œå‡å°‘ç³»ç»Ÿè°ƒç”¨å¼€é”€
ğŸ”¸ é˜Ÿåˆ—è°ƒä¼˜ï¼šæ ¹æ®äº‹ä»¶é¢‘ç‡è°ƒæ•´é˜Ÿåˆ—æ·±åº¦
ğŸ”¸ åˆ†å±‚ç›‘æ§ï¼šæŒ‰é‡è¦æ€§è®¾ç½®ä¸åŒçš„ç›‘æ§ç­–ç•¥
ğŸ”¸ è´Ÿè½½å‡è¡¡ï¼šå¤šè¿›ç¨‹åˆ†æ‹…ç›‘æ§è´Ÿè½½
ğŸ”¸ èµ„æºç›‘æ§ï¼šå®æ—¶ç›‘æ§ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ
ğŸ”¸ æ‰©å±•æ¶æ„ï¼šæ”¯æŒåˆ†å¸ƒå¼å’Œæ’ä»¶åŒ–æ‰©å±•
```

### 10.2 ä¼˜åŒ–æ•ˆæœå¯¹æ¯”


| ä¼˜åŒ–æ–¹æ¡ˆ | **èµ„æºèŠ‚çœ** | **æ€§èƒ½æå‡** | **å¤æ‚åº¦** | **é€‚ç”¨åœºæ™¯** |
|----------|-------------|-------------|-----------|-------------|
| ğŸ¯ **é€‰æ‹©æ€§ç›‘æ§** | `å†…å­˜èŠ‚çœ60%` | `CPUé™ä½40%` | `ä½` | `æ–‡ä»¶ç±»å‹æ˜ç¡®` |
| âš¡ **æ‰¹é‡å¤„ç†** | `å†…å­˜èŠ‚çœ20%` | `ååé‡æå‡3å€` | `ä¸­` | `é«˜é¢‘äº‹ä»¶` |
| ğŸ—ï¸ **åˆ†å±‚ç›‘æ§** | `èµ„æºä¼˜åŒ–50%` | `å“åº”é€Ÿåº¦æå‡2å€` | `ä¸­` | `ç›®å½•ç»“æ„æ¸…æ™°` |
| âš–ï¸ **è´Ÿè½½å‡è¡¡** | `CPUå‡åŒ€åˆ†å¸ƒ` | `å¹¶å‘æ€§æå‡4å€` | `é«˜` | `å¤§è§„æ¨¡ç›‘æ§` |
| ğŸš€ **åˆ†å¸ƒå¼æ¶æ„** | `æ°´å¹³æ‰©å±•` | `æ— ä¸Šé™æ‰©å±•` | `å¾ˆé«˜` | `ä¼ä¸šçº§åº”ç”¨` |

### 10.3 å®æ–½å»ºè®®


**ğŸ”¹ æ¸è¿›å¼ä¼˜åŒ–ç­–ç•¥**ï¼š
```
ç¬¬ä¸€é˜¶æ®µï¼šåŸºç¡€ä¼˜åŒ–
â€¢ è°ƒæ•´ç³»ç»Ÿé™åˆ¶å‚æ•°
â€¢ å®æ–½é€‰æ‹©æ€§ç›‘æ§ç­–ç•¥
â€¢ ä¼˜åŒ–äº‹ä»¶å¤„ç†é€»è¾‘

ç¬¬äºŒé˜¶æ®µï¼šç»“æ„ä¼˜åŒ–
â€¢ å¼•å…¥åˆ†å±‚ç›‘æ§è®¾è®¡
â€¢ å®æ–½æ‰¹é‡å¤„ç†æœºåˆ¶
â€¢ æ·»åŠ èµ„æºç›‘æ§

ç¬¬ä¸‰é˜¶æ®µï¼šæ‰©å±•ä¼˜åŒ–
â€¢ å¤šè¿›ç¨‹è´Ÿè½½å‡è¡¡
â€¢ æ’ä»¶åŒ–æ¶æ„è®¾è®¡
â€¢ åˆ†å¸ƒå¼æ‰©å±•æ”¯æŒ
```

**ğŸ”¹ å¸¸è§ä¼˜åŒ–è¯¯åŒº**ï¼š
```
âŒ è¿‡åº¦ä¼˜åŒ–ï¼šä¸è€ƒè™‘å®é™…éœ€æ±‚ç›²ç›®ä¼˜åŒ–
âŒ å¿½ç•¥ç›‘æ§ï¼šä¸ç›‘æ§ä¼˜åŒ–æ•ˆæœ
âŒ å¤æ‚åŒ–è®¾è®¡ï¼šç®€å•åœºæ™¯ä½¿ç”¨å¤æ‚æ–¹æ¡ˆ
âŒ èµ„æºæµªè´¹ï¼šä¼˜åŒ–åä¸å›æ”¶å¤šä½™èµ„æº
```

### 10.4 æœ€ä½³å®è·µæ¸…å•


```
ğŸ“‹ ä¼˜åŒ–å®æ–½æ£€æŸ¥æ¸…å•ï¼š

ç³»ç»Ÿé…ç½® âœ…
â”œâ”€â”€ [ ] æ ¹æ®éœ€æ±‚è°ƒæ•´inotifyé™åˆ¶å‚æ•°
â”œâ”€â”€ [ ] è®¾ç½®åˆç†çš„äº‹ä»¶é˜Ÿåˆ—æ·±åº¦
â””â”€â”€ [ ] é…ç½®ç³»ç»Ÿèµ„æºç›‘æ§

ä»£ç ä¼˜åŒ– âœ…
â”œâ”€â”€ [ ] å®æ–½é€‰æ‹©æ€§ç›‘æ§ç­–ç•¥
â”œâ”€â”€ [ ] å¼•å…¥æ‰¹é‡äº‹ä»¶å¤„ç†
â”œâ”€â”€ [ ] æ·»åŠ äº‹ä»¶è¿‡æ»¤é€»è¾‘
â””â”€â”€ [ ] ä¼˜åŒ–å†…å­˜ä½¿ç”¨æ¨¡å¼

æ¶æ„è®¾è®¡ âœ…
â”œâ”€â”€ [ ] è®¾è®¡åˆç†çš„ç›‘æ§å±‚æ¬¡ç»“æ„
â”œâ”€â”€ [ ] å®æ–½è´Ÿè½½å‡è¡¡æœºåˆ¶
â”œâ”€â”€ [ ] æ·»åŠ èµ„æºä½¿ç”¨ç‡ç›‘æ§
â””â”€â”€ [ ] è€ƒè™‘æ‰©å±•æ€§éœ€æ±‚

è¿ç»´ç›‘æ§ âœ…
â”œâ”€â”€ [ ] ç›‘æ§ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ
â”œâ”€â”€ [ ] è·Ÿè¸ªä¼˜åŒ–æ•ˆæœæŒ‡æ ‡
â”œâ”€â”€ [ ] å»ºç«‹å‘Šè­¦æœºåˆ¶
â””â”€â”€ [ ] å®šæœŸæ€§èƒ½è°ƒä¼˜
```

**æ ¸å¿ƒè®°å¿†è¦ç‚¹**ï¼š
- å¤§è§„æ¨¡ç›‘æ§éœ€è¦ç³»ç»Ÿæ€§ä¼˜åŒ–ï¼Œä¸æ˜¯å•ç‚¹æ”¹è¿›
- èµ„æºé™åˆ¶æ˜¯ç¡¬çº¦æŸï¼Œå¿…é¡»åˆç†é…ç½®å’Œç®¡ç†
- æ‰¹é‡å¤„ç†å’Œè´Ÿè½½å‡è¡¡æ˜¯æå‡æ€§èƒ½çš„å…³é”®æ‰‹æ®µ
- ç›‘æ§ä¼˜åŒ–æ•ˆæœï¼ŒæŒç»­æ”¹è¿›æ˜¯é•¿æœŸä»»åŠ¡
- æ‰©å±•æ€§è®¾è®¡è¦è€ƒè™‘æœªæ¥å¢é•¿éœ€æ±‚