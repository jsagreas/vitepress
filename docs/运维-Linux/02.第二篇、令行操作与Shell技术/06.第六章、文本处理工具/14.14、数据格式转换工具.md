---
title: 14、数据格式转换工具
---
## 📚 目录

1. [数据格式转换概述](#1-数据格式转换概述)
2. [CSV数据处理技巧](#2-CSV数据处理技巧)
3. [TSV与固定宽度格式](#3-TSV与固定宽度格式)
4. [XML数据提取xmlstarlet](#4-XML数据提取xmlstarlet)
5. [日期时间格式转换](#5-日期时间格式转换)
6. [数字格式标准化](#6-数字格式标准化)
7. [字符编码转换iconv](#7-字符编码转换iconv)
8. [行列转置技巧](#8-行列转置技巧)
9. [数据验证与清洗](#9-数据验证与清洗)
10. [格式标准化流程](#10-格式标准化流程)
11. [核心要点总结](#11-核心要点总结)

---

## 1. 📊 数据格式转换概述


### 1.1 什么是数据格式转换

**简单理解**：就像把不同"方言"的数据翻译成统一的"普通话"

```
现实场景：
- 从Excel文件导出的CSV
- 网页抓取的XML数据  
- 日志文件的时间戳
- 不同系统的编码格式

目标：让所有数据都能"说同一种话"
```

### 1.2 为什么需要格式转换

**实际问题**：
- **数据来源多样** - Excel、数据库、API、日志文件格式各不相同
- **系统兼容需要** - 不同程序要求的输入格式不一样
- **分析处理需要** - 统计分析工具通常只认特定格式
- **存储优化需要** - 某些格式更节省空间或更易读取

┌─ 数据转换的价值 ─────────────────┐
│ **原始状态**：多种格式，无法统一处理   │
│ **转换后**：标准格式，工具通用        │
│ **结果**：提升效率，减少错误          │
└──────────────────────────────────────┘

---

## 2. 📄 CSV数据处理技巧


### 2.1 CSV格式基础

**什么是CSV**：逗号分隔值(Comma-Separated Values)，最常见的表格数据格式

```
基本格式：
姓名,年龄,城市
张三,25,北京
李四,30,上海
王五,28,广州
```

### 2.2 CSV处理常见问题


**🔸 字段包含逗号的问题**
```bash
# 原始数据（有问题）
姓名,描述,年龄
张三,喜欢编程,数据分析,25

# 正确格式（用双引号包围）
姓名,描述,年龄
张三,"喜欢编程,数据分析",25
```

**🔸 处理CSV的核心工具**
```bash
# 1. 查看CSV文件结构
head -5 data.csv
column -t -s, data.csv  # 格式化显示

# 2. 统计行数和列数
wc -l data.csv                    # 行数
head -1 data.csv | tr ',' '\n' | wc -l  # 列数

# 3. 提取特定列
cut -d',' -f2,4 data.csv         # 提取第2和第4列
awk -F',' '{print $1,$3}' data.csv  # 使用awk提取
```

### 2.3 CSV数据清洗技巧


**数据清洗实例**：
```bash
# 去除空行
sed '/^$/d' data.csv > clean_data.csv

# 去除BOM标记（Excel导出常见问题）
sed 's/^\xEF\xBB\xBF//' data.csv > no_bom.csv

# 处理Windows换行符
tr -d '\r' < windows_data.csv > unix_data.csv

# 统一字段分隔符
sed 's/;/,/g' semicolon_data.csv > comma_data.csv
```

**💡 实用技巧**：
```bash
# 快速预览大CSV文件
head -20 big_data.csv | column -t -s,

# 查找包含特定内容的行
grep "北京" data.csv

# 按某列排序（第3列）
sort -t, -k3 data.csv
```

### 2.4 CSV格式转换


**转换为其他格式**：
```bash
# CSV转为TSV（制表符分隔）
sed 's/,/\t/g' data.csv > data.tsv

# CSV转为固定宽度格式
column -t -s, data.csv > fixed_width.txt

# 提取CSV为JSON格式（需要额外工具）
# 简单的转换思路
awk -F, 'NR==1{for(i=1;i<=NF;i++)h[i]=$i;next}{print "{";for(i=1;i<=NF;i++)printf "\"%s\":\"%s\"%s",h[i],$i,(i==NF?"}":",");print ""}' data.csv
```

---

## 3. 📋 TSV与固定宽度格式


### 3.1 TSV格式处理

**TSV**：制表符分隔值(Tab-Separated Values)

```bash
# TSV文件示例
姓名	年龄	城市
张三	25	北京
李四	30	上海

# TSV处理命令
cut -f2,3 data.tsv              # 提取第2、3列
awk -F'\t' '{print $1,$2}' data.tsv  # awk处理TSV
```

**TSV vs CSV 对比**：
```
优点：字段内容很少包含制表符，分隔更可靠
缺点：不如CSV通用，某些工具支持有限
使用场景：日志文件、数据库导出
```

### 3.2 固定宽度格式处理

**什么是固定宽度**：每个字段占用固定的字符位数

```
示例数据：
姓名    年龄城市  
张三    25  北京  
李四    30  上海  
王五    28  广州  
```

**处理固定宽度数据**：
```bash
# 使用cut按位置提取
cut -c1-8 fixed_data.txt      # 提取1-8字符位置
cut -c9-12 fixed_data.txt     # 提取9-12字符位置

# 使用awk按位置处理
awk '{print substr($0,1,8), substr($0,9,4), substr($0,13)}' fixed_data.txt
```

**固定宽度转CSV**：
```bash
# 将固定宽度转为CSV
awk '{
    name = substr($0,1,8);
    age = substr($0,9,4);
    city = substr($0,13);
    gsub(/[ \t]+$/, "", name);  # 去除尾部空格
    gsub(/[ \t]+$/, "", age);
    gsub(/[ \t]+$/, "", city);
    printf "%s,%s,%s\n", name, age, city
}' fixed_data.txt > converted.csv
```

---

## 4. 🔍 XML数据提取xmlstarlet


### 4.1 XML基础理解

**XML**：标记语言，用标签包围数据，结构化存储信息

```xml
<!-- 示例XML -->
<users>
  <user id="1">
    <name>张三</name>
    <age>25</age>
    <city>北京</city>
  </user>
  <user id="2">
    <name>李四</name>
    <age>30</age>
    <city>上海</city>
  </user>
</users>
```

### 4.2 xmlstarlet工具使用


**安装xmlstarlet**：
```bash
# Ubuntu/Debian
sudo apt-get install xmlstarlet

# CentOS/RHEL
sudo yum install xmlstarlet

# macOS
brew install xmlstarlet
```

**基本语法**：
```bash
# 查看XML结构
xmlstarlet el data.xml           # 列出所有元素路径
xmlstarlet el -a data.xml        # 包含属性信息

# 提取数据
xmlstarlet sel -t -v "//user/name" data.xml        # 提取所有姓名
xmlstarlet sel -t -v "//user[@id='1']/name" data.xml  # 提取ID为1的姓名
```

### 4.3 XML数据提取实例


**提取用户信息**：
```bash
# 提取所有用户姓名
xmlstarlet sel -t -v "//name" -n data.xml

# 提取姓名和年龄（格式化输出）
xmlstarlet sel -t -m "//user" -v "name" -o "," -v "age" -n data.xml

# 转换为CSV格式
xmlstarlet sel -t -o "姓名,年龄,城市" -n \
  -m "//user" -v "name" -o "," -v "age" -o "," -v "city" -n data.xml
```

**处理复杂XML**：
```bash
# 处理有命名空间的XML
xmlstarlet sel -N ns="http://example.com/namespace" \
  -t -v "//ns:user/ns:name" data.xml

# 使用条件筛选
xmlstarlet sel -t -m "//user[age>25]" \
  -v "name" -o " (年龄:" -v "age" -o ")" -n data.xml
```

### 4.4 XML转换技巧


**XML转JSON（概念示例）**：
```bash
# 简单的XML到JSON转换思路
xmlstarlet sel -t -o "[" -n \
  -m "//user" -o "{" \
  -o "\"name\":\"" -v "name" -o "\"," \
  -o "\"age\":" -v "age" -o "," \
  -o "\"city\":\"" -v "city" -o "\"" \
  -o "}," -n \
  data.xml | sed '$ s/,$//' | sed '$ a]'
```

---

## 5. 🕐 日期时间格式转换


### 5.1 常见日期格式问题

**现实中的日期格式混乱**：
```
2024-01-15         # ISO格式
01/15/2024         # 美式格式
15/01/2024         # 欧式格式
2024年1月15日      # 中文格式
1642204800         # Unix时间戳
```

### 5.2 date命令的强大功能


**基本日期转换**：
```bash
# 显示当前时间的不同格式
date                           # 默认格式
date +"%Y-%m-%d"              # 2024-01-15
date +"%Y/%m/%d %H:%M:%S"     # 2024/01/15 14:30:25
date +"%s"                    # Unix时间戳

# 解析特定格式的日期
date -d "2024-01-15" +"%s"    # 转为时间戳
date -d "01/15/2024" +"%Y-%m-%d"  # 美式转ISO格式
```

**处理文件中的日期**：
```bash
# 假设有日志文件，日期格式为 "Jan 15 14:30:25"
# 转换为标准格式
sed 's/Jan/01/g; s/Feb/02/g; s/Mar/03/g' log.txt | \
awk '{print "2024-"$1"-"$2" "$3}'
```

### 5.3 批量日期转换技巧


**实用转换脚本**：
```bash
# 转换CSV文件中的日期列（第2列）
awk -F, '{
    if(NR==1) print $0;  # 保留表头
    else {
        # 假设日期格式为 MM/DD/YYYY
        split($2, date_parts, "/");
        new_date = date_parts[3] "-" sprintf("%02d", date_parts[1]) "-" sprintf("%02d", date_parts[2]);
        $2 = new_date;
        print $0
    }
}' OFS=, input.csv > output.csv
```

**时间戳转换**：
```bash
# Unix时间戳转可读格式
echo "1642204800" | awk '{print strftime("%Y-%m-%d %H:%M:%S", $1)}'

# 批量转换文件中的时间戳
awk '{$1=strftime("%Y-%m-%d %H:%M:%S", $1); print}' timestamp_file.txt
```

---

## 6. 🔢 数字格式标准化


### 6.1 数字格式常见问题

**数字格式的混乱**：
```
1,234.56          # 英式千位分隔符
1.234,56          # 欧式小数点
1 234.56          # 空格分隔
$1,234.56         # 带货币符号
123.456E+3        # 科学计数法
```

### 6.2 数字格式清理


**去除千位分隔符**：
```bash
# 去除逗号分隔符
sed 's/,//g' numbers.txt

# 处理不同的分隔符
sed 's/[, ]//g' numbers.txt    # 同时去除逗号和空格
```

**货币符号处理**：
```bash
# 去除货币符号
sed 's/[$￥€£¥]//g' money.txt

# 提取纯数字（包括小数点）
grep -o '[0-9]*\.[0-9]*' mixed_data.txt
```

### 6.3 数字格式统一


**标准化数字格式**：
```bash
# 将所有数字转为标准小数格式
awk '{
    gsub(/,/, "");          # 去除逗号
    gsub(/[$￥€£¥]/, "");  # 去除货币符号
    printf "%.2f\n", $1    # 保留两位小数
}' numbers.txt
```

**科学计数法处理**：
```bash
# 将科学计数法转为普通数字
awk '{printf "%.6f\n", $1}' scientific.txt
```

---

## 7. 🔤 字符编码转换iconv


### 7.1 编码问题的现实场景

**编码混乱的典型情况**：
- Windows文件在Linux上显示乱码
- 网页抓取的数据编码不统一  
- 不同数据库导出的文件编码不同
- 老系统使用GBK，新系统用UTF-8

### 7.2 iconv命令使用


**查看和转换编码**：
```bash
# 查看文件编码（需要file命令支持）
file -i filename.txt

# 基本转换语法
iconv -f 原编码 -t 目标编码 输入文件 > 输出文件

# 常见转换示例
iconv -f gbk -t utf-8 chinese.txt > chinese_utf8.txt
iconv -f iso-8859-1 -t utf-8 european.txt > european_utf8.txt
```

**批量编码转换**：
```bash
# 转换目录下所有txt文件
for file in *.txt; do
    iconv -f gbk -t utf-8 "$file" > "utf8_$file"
done

# 或者就地转换（更安全的做法）
for file in *.txt; do
    iconv -f gbk -t utf-8 "$file" > temp.txt && mv temp.txt "$file"
done
```

### 7.3 编码检测与处理


**自动检测编码**：
```bash
# 使用chardet工具（Python包）
chardet filename.txt

# 或者使用file命令粗略判断
file -i *.txt
```

**处理编码错误**：
```bash
# 忽略无法转换的字符
iconv -f gbk -t utf-8//IGNORE problematic.txt > clean.txt

# 用替换符号处理错误字符
iconv -f gbk -t utf-8//TRANSLIT problematic.txt > clean.txt
```

---

## 8. 🔄 行列转置技巧


### 8.1 什么是行列转置

**转置概念**：把行变成列，列变成行

```
原始数据：
姓名,张三,李四,王五
年龄,25,30,28
城市,北京,上海,广州

转置后：
姓名,年龄,城市
张三,25,北京
李四,30,上海
王五,28,广州
```

### 8.2 使用awk实现转置


**简单转置**：
```bash
# 基本转置功能
awk '
{
    for (i=1; i<=NF; i++) {
        a[NR,i] = $i
    }
}
NF > p { p = NF }
END {
    for(j=1; j<=p; j++) {
        str=a[1,j]
        for(i=2; i<=NR; i++){
            str=str","a[i,j];
        }
        print str
    }
}' data.csv
```

**使用现成工具**：
```bash
# 如果系统有datamash工具
datamash -t, transpose < data.csv

# 使用rs命令（BSD系统）
rs -c, -C, -T data.csv
```

### 8.3 处理不规则数据


**处理缺失值的转置**：
```bash
# 处理行长度不一致的情况
awk -F, '
{
    for (i=1; i<=NF; i++) {
        a[NR,i] = $i
    }
    if (NF > max_nf) max_nf = NF
}
END {
    for (j=1; j<=max_nf; j++) {
        for (i=1; i<=NR; i++) {
            printf "%s", (a[i,j] ? a[i,j] : "")
            if (i < NR) printf ","
        }
        print ""
    }
}' irregular_data.csv
```

---

## 9. ✅ 数据验证与清洗


### 9.1 数据质量问题识别


**常见数据问题**：
- **重复数据** - 相同记录出现多次
- **缺失值** - 空字段或NULL值
- **格式不统一** - 同一类数据有不同格式
- **异常值** - 明显不合理的数值
- **编码问题** - 乱码或编码不一致

### 9.2 重复数据处理


**查找重复数据**：
```bash
# 查找完全重复的行
sort data.txt | uniq -d

# 统计重复次数
sort data.txt | uniq -c | sort -nr

# 根据特定列查找重复（第1列）
sort -k1,1 data.csv | awk -F, 'a[$1]++{print "重复:"$0}'
```

**去除重复数据**：
```bash
# 去除完全相同的行
sort data.txt | uniq > dedup_data.txt

# 根据第一列去重，保留第一次出现的
awk -F, '!seen[$1]++' data.csv > unique_data.csv
```

### 9.3 缺失值处理


**识别缺失值**：
```bash
# 查找空字段
awk -F, '{
    for(i=1; i<=NF; i++) {
        if($i == "" || $i == "NULL" || $i == "null") {
            print "第"NR"行第"i"列缺失值"
        }
    }
}' data.csv

# 统计每列缺失值数量
awk -F, '{
    for(i=1; i<=NF; i++) {
        if($i == "" || $i == "NULL") missing[i]++
    }
}
END {
    for(i in missing) print "第"i"列缺失:"missing[i]"个"
}' data.csv
```

**处理缺失值**：
```bash
# 删除包含缺失值的行
awk -F, 'NF==3 && $1!="" && $2!="" && $3!=""' data.csv

# 用默认值填充缺失值
awk -F, '{
    if($1=="") $1="未知";
    if($2=="") $2="0";
    if($3=="") $3="无";
    print $1","$2","$3
}' data.csv
```

### 9.4 数据格式验证


**验证数据格式**：
```bash
# 验证邮箱格式
awk '/^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$/' emails.txt

# 验证手机号格式（中国）
awk '/^1[3-9][0-9]{9}$/' phones.txt

# 验证日期格式（YYYY-MM-DD）
awk '/^[0-9]{4}-[0-9]{2}-[0-9]{2}$/' dates.txt

# 验证数字格式
awk '/^[0-9]+(\.[0-9]+)?$/' numbers.txt
```

---

## 10. 🔧 格式标准化流程


### 10.1 标准化流程设计


**典型的数据处理流程**：
```
原始数据 → 编码转换 → 格式清理 → 验证检查 → 标准输出
```

**流程图示**：
```
┌─────────────┐    ┌─────────────┐    ┌─────────────┐
│   原始数据   │ -> │  编码统一   │ -> │  格式清理   │
│ (各种格式)  │    │ (UTF-8)    │    │ (标准化)   │
└─────────────┘    └─────────────┘    └─────────────┘
       |                   |                   |
       v                   v                   v
┌─────────────┐    ┌─────────────┐    ┌─────────────┐
│  质量检查   │ -> │  错误修复   │ -> │  最终输出   │
│ (找问题)   │    │ (清洗数据)  │    │ (标准格式)  │
└─────────────┘    └─────────────┘    └─────────────┘
```

### 10.2 标准化脚本示例


**完整的数据处理脚本**：
```bash
#!/bin/bash
# 数据标准化处理脚本

input_file="$1"
output_file="$2"

echo "开始处理数据文件: $input_file"

# 步骤1: 编码转换
echo "1. 转换编码为UTF-8..."
iconv -f gbk -t utf-8 "$input_file" > temp1.csv

# 步骤2: 清理格式
echo "2. 清理数据格式..."
sed 's/\r//g' temp1.csv |          # 去除Windows换行符
sed 's/[ \t]*,[ \t]*/,/g' |        # 标准化分隔符
sed '/^$/d' > temp2.csv             # 去除空行

# 步骤3: 处理重复数据
echo "3. 去除重复数据..."
awk -F, '!seen[$0]++' temp2.csv > temp3.csv

# 步骤4: 数据验证
echo "4. 验证数据质量..."
total_lines=$(wc -l < temp3.csv)
echo "总行数: $total_lines"

# 检查缺失值
missing_count=$(awk -F, '{for(i=1;i<=NF;i++) if($i=="") missing++} END {print missing+0}' temp3.csv)
echo "缺失值数量: $missing_count"

# 步骤5: 生成最终文件
echo "5. 生成最终结果..."
cp temp3.csv "$output_file"

# 清理临时文件
rm -f temp*.csv

echo "数据处理完成: $output_file"
echo "处理统计: $total_lines 行数据，$missing_count 个缺失值"
```

### 10.3 批量处理技巧


**批量处理多个文件**：
```bash
# 处理目录下所有CSV文件
for file in *.csv; do
    echo "处理文件: $file"
    
    # 标准化文件名（去除空格，统一扩展名）
    new_name=$(echo "$file" | tr ' ' '_' | sed 's/\.CSV$/.csv/')
    
    # 执行标准化处理
    ./standardize_data.sh "$file" "processed_$new_name"
    
    echo "完成: $new_name"
done
```

**监控处理质量**：
```bash
# 生成处理报告
echo "数据处理质量报告" > report.txt
echo "==================" >> report.txt

for file in processed_*.csv; do
    echo "文件: $file" >> report.txt
    echo "行数: $(wc -l < "$file")" >> report.txt
    echo "列数: $(head -1 "$file" | tr ',' '\n' | wc -l)" >> report.txt
    echo "---" >> report.txt
done
```

---

## 11. 📋 核心要点总结


### 11.1 必须掌握的核心技能


```
🔸 CSV处理：使用cut、awk、sed处理逗号分隔数据
🔸 编码转换：用iconv解决字符编码问题
🔸 格式转换：在CSV、TSV、XML等格式间转换
🔸 数据清洗：去重、处理缺失值、格式标准化
🔸 质量验证：检查数据完整性和格式正确性
```

### 11.2 关键理解要点


**🔹 数据格式转换的本质**：
```
核心思想：统一数据"语言"，让不同来源的数据能够互相理解
实现方式：识别模式 → 转换规则 → 验证结果
关键技能：正则表达式、文本处理、编码理解
```

**🔹 工具选择原则**：
```
简单数据：cut、sed就够用
复杂数据：awk更灵活
XML数据：xmlstarlet专业工具
编码问题：iconv是标准选择
批量处理：shell脚本自动化
```

**🔹 数据质量管理**：
```
预防为主：源头控制格式
及时发现：建立检查机制  
快速修复：自动化清洗流程
持续监控：定期质量检查
```

### 11.3 实际应用场景


**💼 业务场景应用**：
- **数据迁移** - 系统升级时的数据格式转换
- **报表处理** - 将各部门数据统一为分析格式
- **接口对接** - 不同系统间的数据格式适配
- **数据清洗** - 提升数据质量，支持精准分析

**🔧 运维场景应用**：
- **日志处理** - 统一不同服务的日志格式
- **监控数据** - 转换监控系统的输出格式
- **备份恢复** - 处理不同版本间的格式差异

### 11.4 学习建议


**📚 学习路径**：
```
第一步：掌握基础文本处理命令
第二步：理解常见数据格式特点
第三步：练习编码转换和格式转换
第四步：学会设计数据处理流程
第五步：编写自动化处理脚本
```

**💡 实践建议**：
```
多练习：用真实数据做转换练习
建模板：总结常用的处理模式
写脚本：将重复工作自动化
做监控：建立数据质量检查机制
```

**⚠️ 常见误区**：
- 忽视编码问题导致乱码
- 不验证转换结果的正确性
- 没有备份原始数据就直接修改
- 过度复杂化简单的转换需求

**核心记忆**：
- 数据格式转换就是让不同"方言"的数据说同一种"普通话"
- 编码转换用iconv，格式转换用awk/sed
- 处理前先备份，处理后要验证
- 建立标准流程，实现批量自动化