---
title: 6、线程同步与互斥
---
## 📚 目录

1. [线程同步基础概念](#1-线程同步基础概念)
2. [互斥锁pthread_mutex_t详解](#2-互斥锁pthread_mutex_t详解)
3. [条件变量pthread_cond_t机制](#3-条件变量pthread_cond_t机制)
4. [读写锁pthread_rwlock_t优化](#4-读写锁pthread_rwlock_t优化)
5. [屏障同步pthread_barrier_t](#5-屏障同步pthread_barrier_t)
6. [死锁问题与防范策略](#6-死锁问题与防范策略)
7. [线程安全与可重入函数](#7-线程安全与可重入函数)
8. [原子操作与内存屏障](#8-原子操作与内存屏障)
9. [锁粒度设计与性能优化](#9-锁粒度设计与性能优化)
10. [核心要点总结](#10-核心要点总结)

---

## 1. 🔄 线程同步基础概念


### 1.1 为什么需要线程同步


**问题场景**：多个线程同时访问共享资源时会发生什么？

```
银行账户转账问题：
账户余额: 1000元

线程A: 取款500元        线程B: 存款300元
读取余额: 1000         读取余额: 1000  
计算结果: 500          计算结果: 1300
写回余额: 500          写回余额: 1300

最终结果: 1300元 (应该是800元!)
```

> 💡 **核心问题**：多线程并发访问共享数据时，如果没有同步机制，会导致数据不一致、竞态条件等问题

### 1.2 竞态条件的本质


**竞态条件（Race Condition）**：多个线程的执行结果依赖于它们执行的相对时序

```
经典的计数器问题：
int counter = 0;

线程1执行: counter++     线程2执行: counter++
┌─读取counter(0)        ┌─读取counter(0)  
├─加1 (0+1=1)          ├─加1 (0+1=1)
└─写回counter=1        └─写回counter=1

期望结果: 2    实际结果: 1
```

### 1.3 同步机制的分类


**Linux提供的主要同步工具**：

```
┌─互斥机制─────────────────────────────┐
│ • 互斥锁(mutex)    - 独占访问        │
│ • 读写锁(rwlock)   - 读写分离        │
│ • 自旋锁(spinlock) - 忙等待         │
└────────────────────────────────────┘

┌─协调机制─────────────────────────────┐
│ • 条件变量(cond)   - 等待通知        │
│ • 信号量(semaphore)- 资源计数        │
│ • 屏障(barrier)    - 集体同步        │
└────────────────────────────────────┘
```

---

## 2. 🔒 互斥锁pthread_mutex_t详解


### 2.1 互斥锁的工作原理


**互斥锁（Mutex）**：确保同一时刻只有一个线程能访问临界区

```
互斥锁状态转换：
    未锁定 ────lock()────→ 已锁定
      ↑                     │
      └────unlock()─────────┘

临界区访问过程：
线程A: 获取锁 → 访问资源 → 释放锁
线程B:   等待    →    等待   → 获取锁 → 访问资源
```

### 2.2 基本使用方法


**互斥锁操作接口**：

| 函数名 | **功能说明** | **返回值** |
|--------|-------------|-----------|
| `pthread_mutex_init()` | `初始化互斥锁` | `成功返回0` |
| `pthread_mutex_lock()` | `加锁（阻塞）` | `成功返回0` |
| `pthread_mutex_trylock()` | `尝试加锁（非阻塞）` | `成功返回0，忙碌返回EBUSY` |
| `pthread_mutex_unlock()` | `解锁` | `成功返回0` |
| `pthread_mutex_destroy()` | `销毁互斥锁` | `成功返回0` |

**实际应用示例**：

```c
#include <pthread.h>
#include <stdio.h>

pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;  // 静态初始化
int shared_counter = 0;

void* worker_thread(void* arg) {
    int thread_id = *(int*)arg;
    
    for (int i = 0; i < 1000; i++) {
        pthread_mutex_lock(&mutex);        // 进入临界区
        shared_counter++;                  // 修改共享数据
        printf("线程%d: counter = %d\n", thread_id, shared_counter);
        pthread_mutex_unlock(&mutex);      // 离开临界区
    }
    return NULL;
}
```

### 2.3 互斥锁类型详解


**Linux支持四种互斥锁类型**：

```c
// 设置互斥锁类型
pthread_mutexattr_t attr;
pthread_mutexattr_init(&attr);
pthread_mutexattr_settype(&attr, PTHREAD_MUTEX_NORMAL);

pthread_mutex_t mutex;
pthread_mutex_init(&mutex, &attr);
```

**各类型特点对比**：

| 类型 | **重复加锁行为** | **性能** | **适用场景** |
|------|-----------------|---------|-------------|
| `NORMAL` | `未定义行为（可能死锁）` | `最快` | `简单互斥` |
| `RECURSIVE` | `允许重复加锁` | `较慢` | `递归调用` |
| `ERRORCHECK` | `返回错误码` | `中等` | `调试模式` |
| `DEFAULT` | `等同于NORMAL` | `最快` | `默认选择` |

> ⚠️ **注意**：`NORMAL`类型的互斥锁如果被同一线程重复加锁，会导致未定义行为，通常是死锁

### 2.4 递归锁的应用场景


**递归锁示例**：函数递归调用时需要多次获取同一个锁

```c
pthread_mutex_t recursive_mutex;

void recursive_function(int depth) {
    pthread_mutex_lock(&recursive_mutex);
    
    printf("递归深度: %d\n", depth);
    
    if (depth > 0) {
        recursive_function(depth - 1);  // 递归调用，再次需要锁
    }
    
    pthread_mutex_unlock(&recursive_mutex);
}

// 初始化为递归锁
pthread_mutexattr_t attr;
pthread_mutexattr_init(&attr);
pthread_mutexattr_settype(&attr, PTHREAD_MUTEX_RECURSIVE);
pthread_mutex_init(&recursive_mutex, &attr);
```

---

## 3. 📢 条件变量pthread_cond_t机制


### 3.1 条件变量的设计思想


**条件变量（Condition Variable）**：线程间的等待-通知机制

```
生产者-消费者问题：
生产者: 生产数据 → 通知消费者
消费者: 等待数据 → 收到通知 → 消费数据

传统轮询方式:               条件变量方式:
while (buffer_empty) {     pthread_cond_wait(&cond, &mutex);
    sleep(1);              // 直接休眠，等待通知
}                          // 收到通知后自动唤醒
```

> 💡 **核心优势**：避免忙等待，节省CPU资源，提供精确的同步时机

### 3.2 条件变量基本操作


**条件变量函数接口**：

| 函数名 | **功能说明** | **关键特点** |
|--------|-------------|-------------|
| `pthread_cond_init()` | `初始化条件变量` | `可静态或动态初始化` |
| `pthread_cond_wait()` | `等待条件满足` | `自动释放互斥锁并等待` |
| `pthread_cond_timedwait()` | `限时等待` | `超时后返回ETIMEDOUT` |
| `pthread_cond_signal()` | `唤醒一个等待线程` | `精确控制唤醒数量` |
| `pthread_cond_broadcast()` | `唤醒所有等待线程` | `广播通知` |
| `pthread_cond_destroy()` | `销毁条件变量` | `释放资源` |

### 3.3 经典的生产者消费者实现


```c
#include <pthread.h>
#include <stdio.h>

typedef struct {
    int buffer[10];
    int count;           // 缓冲区中的数据量
    int in, out;         // 生产和消费的位置
    pthread_mutex_t mutex;
    pthread_cond_t not_full;   // 缓冲区不满条件
    pthread_cond_t not_empty;  // 缓冲区不空条件
} Buffer;

Buffer buf = {
    .count = 0, .in = 0, .out = 0,
    .mutex = PTHREAD_MUTEX_INITIALIZER,
    .not_full = PTHREAD_COND_INITIALIZER,
    .not_empty = PTHREAD_COND_INITIALIZER
};

void* producer(void* arg) {
    int item = 1;
    while (1) {
        pthread_mutex_lock(&buf.mutex);
        
        // 等待缓冲区不满
        while (buf.count == 10) {
            pthread_cond_wait(&buf.not_full, &buf.mutex);
        }
        
        // 生产数据
        buf.buffer[buf.in] = item++;
        buf.in = (buf.in + 1) % 10;
        buf.count++;
        
        printf("生产: %d (缓冲区数量: %d)\n", item-1, buf.count);
        
        // 通知消费者
        pthread_cond_signal(&buf.not_empty);
        pthread_mutex_unlock(&buf.mutex);
        
        usleep(100000);  // 模拟生产时间
    }
}

void* consumer(void* arg) {
    while (1) {
        pthread_mutex_lock(&buf.mutex);
        
        // 等待缓冲区不空
        while (buf.count == 0) {
            pthread_cond_wait(&buf.not_empty, &buf.mutex);
        }
        
        // 消费数据
        int item = buf.buffer[buf.out];
        buf.out = (buf.out + 1) % 10;
        buf.count--;
        
        printf("消费: %d (缓冲区数量: %d)\n", item, buf.count);
        
        // 通知生产者
        pthread_cond_signal(&buf.not_full);
        pthread_mutex_unlock(&buf.mutex);
        
        usleep(150000);  // 模拟消费时间
    }
}
```

### 3.4 条件变量使用要点


> ⚠️ **重要原则**：
> 1. **必须配合互斥锁使用** - 条件变量本身不提供互斥功能
> 2. **使用while循环而非if** - 防止虚假唤醒问题
> 3. **先锁定再检查条件** - 保证检查和等待的原子性
> 4. **signal vs broadcast选择** - 根据唤醒需求选择合适的函数

**虚假唤醒问题**：

```c
// 错误写法
if (condition_not_met) {
    pthread_cond_wait(&cond, &mutex);
}

// 正确写法  
while (condition_not_met) {
    pthread_cond_wait(&cond, &mutex);
}
```

---

## 4. 📖 读写锁pthread_rwlock_t优化


### 4.1 读写锁的性能优势


**读写锁（Reader-Writer Lock）**：区分读操作和写操作的锁机制

```
传统互斥锁:                    读写锁:
读操作1 ──┐                   读操作1 ────┐
         │ 串行执行             读操作2 ────┤ 并行执行
读操作2 ──┘                   读操作3 ────┘
写操作  ── 独占                写操作  ──── 独占

性能提升: 多读少写场景下显著提升并发性能
```

**访问规则**：
- **多个读者可以同时访问** - 读操作不会修改数据
- **写者独占访问** - 写操作需要排他性
- **读写互斥** - 读写不能同时进行

### 4.2 读写锁操作接口


**读写锁函数对比**：

| 操作类型 | **函数名** | **功能说明** |
|---------|-----------|-------------|
| **初始化** | `pthread_rwlock_init()` | `初始化读写锁` |
| **读锁定** | `pthread_rwlock_rdlock()` | `获取读锁（可并发）` |
| **写锁定** | `pthread_rwlock_wrlock()` | `获取写锁（独占）` |
| **尝试读** | `pthread_rwlock_tryrdlock()` | `非阻塞获取读锁` |
| **尝试写** | `pthread_rwlock_trywrlock()` | `非阻塞获取写锁` |
| **解锁** | `pthread_rwlock_unlock()` | `释放读锁或写锁` |
| **销毁** | `pthread_rwlock_destroy()` | `销毁读写锁` |

### 4.3 读写锁应用示例


**缓存系统实现**：

```c
#include <pthread.h>
#include <string.h>

typedef struct {
    char key[64];
    char value[256];
} CacheItem;

typedef struct {
    CacheItem items[100];
    int count;
    pthread_rwlock_t rwlock;
} Cache;

Cache cache = {
    .count = 0,
    .rwlock = PTHREAD_RWLOCK_INITIALIZER
};

// 读操作：查找缓存项
char* cache_get(const char* key) {
    pthread_rwlock_rdlock(&cache.rwlock);  // 获取读锁
    
    for (int i = 0; i < cache.count; i++) {
        if (strcmp(cache.items[i].key, key) == 0) {
            char* result = strdup(cache.items[i].value);
            pthread_rwlock_unlock(&cache.rwlock);
            return result;
        }
    }
    
    pthread_rwlock_unlock(&cache.rwlock);
    return NULL;
}

// 写操作：添加缓存项
int cache_put(const char* key, const char* value) {
    pthread_rwlock_wrlock(&cache.rwlock);  // 获取写锁
    
    if (cache.count >= 100) {
        pthread_rwlock_unlock(&cache.rwlock);
        return -1;  // 缓存已满
    }
    
    strcpy(cache.items[cache.count].key, key);
    strcpy(cache.items[cache.count].value, value);
    cache.count++;
    
    printf("缓存添加: %s = %s\n", key, value);
    
    pthread_rwlock_unlock(&cache.rwlock);
    return 0;
}
```

### 4.4 读写锁的注意事项


> 📊 **性能权衡**：
> - **读多写少场景** → 读写锁性能优异
> - **写操作频繁场景** → 普通互斥锁可能更简单
> - **锁竞争激烈场景** → 需要考虑写者饥饿问题

**写者饥饿问题**：连续的读者可能导致写者永远等待

```
解决方案：
1. 写者优先策略 - 新的读者需要等待写者完成
2. 公平策略     - 按照请求顺序服务
3. 超时机制     - 写者等待超时后强制获取锁
```

---

## 5. 🚧 屏障同步pthread_barrier_t


### 5.1 屏障同步的应用场景


**屏障（Barrier）**：让多个线程在某个同步点集合，所有线程都到达后再继续执行

```
并行计算场景：
线程1: 计算A部分 ──┐
线程2: 计算B部分 ──┤ 等待所有线程完成
线程3: 计算C部分 ──┤
线程4: 计算D部分 ──┘
                   ↓ 屏障点
所有线程: 汇总结果 → 下一阶段计算
```

**典型应用**：
- **并行算法** - 矩阵运算、图像处理
- **仿真系统** - 时间步进同步  
- **流水线处理** - 阶段间同步

### 5.2 屏障操作接口


**屏障同步函数**：

| 函数名 | **功能说明** | **参数说明** |
|--------|-------------|-------------|
| `pthread_barrier_init()` | `初始化屏障` | `count: 等待的线程数量` |
| `pthread_barrier_wait()` | `等待在屏障点` | `返回0或PTHREAD_BARRIER_SERIAL_THREAD` |
| `pthread_barrier_destroy()` | `销毁屏障` | `释放屏障资源` |

### 5.3 矩阵并行计算示例


```c
#include <pthread.h>
#include <stdio.h>

#define THREADS 4
#define MATRIX_SIZE 1000

typedef struct {
    int thread_id;
    int start_row;
    int end_row;
    double (*matrix_a)[MATRIX_SIZE];
    double (*matrix_b)[MATRIX_SIZE]; 
    double (*result)[MATRIX_SIZE];
} ThreadData;

pthread_barrier_t barrier;

void* matrix_multiply(void* arg) {
    ThreadData* data = (ThreadData*)arg;
    
    // 第一阶段：计算分配的行
    for (int i = data->start_row; i < data->end_row; i++) {
        for (int j = 0; j < MATRIX_SIZE; j++) {
            data->result[i][j] = 0;
            for (int k = 0; k < MATRIX_SIZE; k++) {
                data->result[i][j] += data->matrix_a[i][k] * data->matrix_b[k][j];
            }
        }
    }
    
    printf("线程 %d 完成计算\n", data->thread_id);
    
    // 等待所有线程完成第一阶段
    int barrier_result = pthread_barrier_wait(&barrier);
    
    // 只有一个线程执行清理工作
    if (barrier_result == PTHREAD_BARRIER_SERIAL_THREAD) {
        printf("所有线程完成，开始验证结果...\n");
        // 执行结果验证或其他收尾工作
    }
    
    // 第二阶段：所有线程继续执行其他任务
    printf("线程 %d 进入第二阶段\n", data->thread_id);
    
    return NULL;
}

int main() {
    pthread_t threads[THREADS];
    ThreadData thread_data[THREADS];
    
    // 初始化屏障，等待4个线程
    pthread_barrier_init(&barrier, NULL, THREADS);
    
    // 创建线程执行并行计算
    for (int i = 0; i < THREADS; i++) {
        thread_data[i].thread_id = i;
        thread_data[i].start_row = i * (MATRIX_SIZE / THREADS);
        thread_data[i].end_row = (i + 1) * (MATRIX_SIZE / THREADS);
        // 设置矩阵指针...
        
        pthread_create(&threads[i], NULL, matrix_multiply, &thread_data[i]);
    }
    
    // 等待所有线程完成
    for (int i = 0; i < THREADS; i++) {
        pthread_join(threads[i], NULL);
    }
    
    pthread_barrier_destroy(&barrier);
    return 0;
}
```

### 5.4 屏障的实现原理


```
屏障内部机制：
计数器: 初始值 = 等待线程数
条件变量: 用于阻塞和唤醒线程

线程到达屏障:
1. 计数器减1
2. 如果计数器 > 0: 等待条件变量
3. 如果计数器 = 0: 广播唤醒所有等待线程
```

---

## 6. ☠️ 死锁问题与防范策略


### 6.1 死锁的四个必要条件


**死锁（Deadlock）**：两个或多个线程相互等待对方释放资源，导致程序永久阻塞

```
经典死锁场景：
线程A: 持有锁1，等待锁2
线程B: 持有锁2，等待锁1

时间线：
T1: 线程A获取锁1     线程B获取锁2
T2: 线程A等待锁2     线程B等待锁1
T3: ← 死锁状态，永久等待 →
```

**死锁的四个必要条件**：

| 条件 | **含义** | **示例** |
|------|---------|---------|
| **互斥条件** | `资源不能同时被多个线程使用` | `互斥锁的排他性` |
| **占有并等待** | `持有资源的同时等待其他资源` | `持有锁A等待锁B` |
| **不可剥夺** | `资源不能被强制取走` | `锁只能由持有者释放` |
| **循环等待** | `存在线程等待环路` | `A等B，B等A` |

### 6.2 死锁检测工具


**编译时检测**：
```bash
# 使用ThreadSanitizer检测竞态条件和死锁
gcc -fsanitize=thread -g -o program program.c -lpthread

# 使用Helgrind检测线程问题
valgrind --tool=helgrind ./program
```

**运行时检测**：
```c
// 设置互斥锁为错误检查类型
pthread_mutexattr_t attr;
pthread_mutexattr_init(&attr);
pthread_mutexattr_settype(&attr, PTHREAD_MUTEX_ERRORCHECK);
pthread_mutex_init(&mutex, &attr);

// 尝试加锁时检查返回值
int result = pthread_mutex_lock(&mutex);
if (result == EDEADLK) {
    printf("检测到死锁！\n");
}
```

### 6.3 死锁预防策略


**策略1：固定锁顺序**
```c
pthread_mutex_t lock1, lock2;

// 错误：可能导致死锁
void thread_func1() {
    pthread_mutex_lock(&lock1);
    pthread_mutex_lock(&lock2);  // A->B
    // 临界区代码
    pthread_mutex_unlock(&lock2);
    pthread_mutex_unlock(&lock1);
}

void thread_func2() {
    pthread_mutex_lock(&lock2);
    pthread_mutex_lock(&lock1);  // B->A，形成环路
    // 临界区代码  
    pthread_mutex_unlock(&lock1);
    pthread_mutex_unlock(&lock2);
}

// 正确：统一锁顺序
void safe_thread_func() {
    // 总是按照lock1 -> lock2的顺序获取
    pthread_mutex_lock(&lock1);
    pthread_mutex_lock(&lock2);
    // 临界区代码
    pthread_mutex_unlock(&lock2);
    pthread_mutex_unlock(&lock1);
}
```

**策略2：超时机制**
```c
struct timespec timeout;
clock_gettime(CLOCK_REALTIME, &timeout);
timeout.tv_sec += 5;  // 5秒超时

int result = pthread_mutex_timedlock(&mutex, &timeout);
if (result == ETIMEDOUT) {
    printf("获取锁超时，可能存在死锁\n");
    return -1;
}
```

**策略3：try_lock避免阻塞**
```c
int acquire_both_locks(pthread_mutex_t* lock1, pthread_mutex_t* lock2) {
    if (pthread_mutex_trylock(lock1) != 0) {
        return -1;  // 第一个锁获取失败
    }
    
    if (pthread_mutex_trylock(lock2) != 0) {
        pthread_mutex_unlock(lock1);  // 释放第一个锁
        return -1;  // 第二个锁获取失败
    }
    
    return 0;  // 成功获取两个锁
}
```

### 6.4 银行家算法简化应用


```c
// 简化的资源分配检查
typedef struct {
    int available[3];    // 可用资源
    int allocation[5][3]; // 已分配资源
    int max[5][3];       // 最大需求
} ResourceManager;

int is_safe_state(ResourceManager* rm) {
    int work[3];
    int finish[5] = {0};
    
    // 复制可用资源
    memcpy(work, rm->available, sizeof(work));
    
    // 查找安全序列
    for (int count = 0; count < 5; count++) {
        int found = 0;
        for (int i = 0; i < 5; i++) {
            if (!finish[i]) {
                int can_allocate = 1;
                for (int j = 0; j < 3; j++) {
                    if (rm->max[i][j] - rm->allocation[i][j] > work[j]) {
                        can_allocate = 0;
                        break;
                    }
                }
                
                if (can_allocate) {
                    for (int j = 0; j < 3; j++) {
                        work[j] += rm->allocation[i][j];
                    }
                    finish[i] = 1;
                    found = 1;
                    break;
                }
            }
        }
        
        if (!found) return 0;  // 不安全状态
    }
    
    return 1;  // 安全状态
}
```

---

## 7. 🛡️ 线程安全与可重入函数


### 7.1 线程安全性概念


**线程安全（Thread Safety）**：函数在多线程环境下能够正确执行的特性

**线程安全的分类**：

```
┌─不可变对象────────────────────────────┐
│ • 只读数据（const变量、字符串常量）    │
│ • 特点：天然线程安全，无需同步         │
└─────────────────────────────────────┘

┌─绝对线程安全──────────────────────────┐ 
│ • 任何情况下都能正确执行              │
│ • 特点：性能开销大，实现复杂          │
└─────────────────────────────────────┘

┌─相对线程安全──────────────────────────┐
│ • 大部分操作线程安全                  │
│ • 特点：需要外部同步某些操作序列       │
└─────────────────────────────────────┘

┌─线程兼容────────────────────────────┐
│ • 可以通过同步机制实现线程安全         │ 
│ • 特点：需要调用者负责同步            │
└─────────────────────────────────────┘
```

### 7.2 可重入函数详解


**可重入函数（Reentrant Function）**：函数可以被多个线程同时调用而不会产生数据竞争

**可重入的条件**：
- **不使用静态变量或全局变量**
- **不调用不可重入函数**
- **不修改传入的指针参数指向的内容**
- **所有数据都在栈上或通过参数传递**

```c
// 不可重入函数示例
int counter = 0;
int not_reentrant() {
    counter++;           // 修改全局变量
    return counter;
}

// 可重入函数示例  
int reentrant_add(int a, int b) {
    int result = a + b;  // 只使用局部变量
    return result;       // 栈上数据，每个线程独立
}

// 条件可重入函数
int conditional_reentrant(int* value) {
    return (*value) * 2; // 只读取，不修改指针内容
}
```

### 7.3 常见函数的线程安全性


**C标准库函数分类**：

| 函数类型 | **线程安全性** | **示例函数** | **注意事项** |
|---------|---------------|-------------|-------------|
| **不安全** | `❌ 使用静态缓冲区` | `strtok(), ctime(), gmtime()` | `需要使用_r版本` |
| **安全版本** | `✅ 使用调用者缓冲区` | `strtok_r(), ctime_r(), gmtime_r()` | `推荐使用` |
| **原子操作** | `✅ 硬件保证原子性` | `atomic_*系列函数` | `C11标准` |
| **数学函数** | `✅ 只读操作` | `sin(), cos(), sqrt()` | `天然线程安全` |

**线程安全函数使用示例**：

```c
#include <time.h>
#include <string.h>

// 不安全的时间函数
void unsafe_time_usage() {
    time_t now = time(NULL);
    char* time_str = ctime(&now);  // 返回静态缓冲区
    printf("当前时间: %s", time_str);
    // 多线程调用时可能得到错误结果
}

// 安全的时间函数
void safe_time_usage() {
    time_t now = time(NULL);
    char time_buffer[26];
    ctime_r(&now, time_buffer);    // 使用调用者提供的缓冲区
    printf("当前时间: %s", time_buffer);
}

// 不安全的字符串分割
void unsafe_string_split(char* str) {
    char* token = strtok(str, ",");  // 使用静态变量
    while (token != NULL) {
        printf("Token: %s\n", token);
        token = strtok(NULL, ",");
    }
}

// 安全的字符串分割
void safe_string_split(char* str) {
    char* saveptr;
    char* token = strtok_r(str, ",", &saveptr);  // 状态保存在saveptr中
    while (token != NULL) {
        printf("Token: %s\n", token);
        token = strtok_r(NULL, ",", &saveptr);
    }
}
```

### 7.4 构建线程安全的数据结构


**线程安全的链表实现**：

```c
typedef struct Node {
    int data;
    struct Node* next;
} Node;

typedef struct {
    Node* head;
    pthread_mutex_t mutex;
    size_t size;
} ThreadSafeList;

// 初始化线程安全链表
void list_init(ThreadSafeList* list) {
    list->head = NULL;
    list->size = 0;
    pthread_mutex_init(&list->mutex, NULL);
}

// 线程安全的插入操作
int list_insert(ThreadSafeList* list, int value) {
    Node* new_node = malloc(sizeof(Node));
    if (!new_node) return -1;
    
    new_node->data = value;
    
    pthread_mutex_lock(&list->mutex);
    new_node->next = list->head;
    list->head = new_node;
    list->size++;
    pthread_mutex_unlock(&list->mutex);
    
    return 0;
}

// 线程安全的查找操作
int list_find(ThreadSafeList* list, int value) {
    pthread_mutex_lock(&list->mutex);
    
    Node* current = list->head;
    while (current != NULL) {
        if (current->data == value) {
            pthread_mutex_unlock(&list->mutex);
            return 1;  // 找到
        }
        current = current->next;
    }
    
    pthread_mutex_unlock(&list->mutex);
    return 0;  // 未找到
}
```

---

## 8. ⚛️ 原子操作与内存屏障


### 8.1 原子操作的基本概念


**原子操作（Atomic Operation）**：不可分割的操作，要么完全执行，要么完全不执行

```
非原子操作的问题：
int counter = 0;
counter++;  // 实际上是三个步骤：
            // 1. 从内存读取counter值到寄存器
            // 2. 寄存器值加1  
            // 3. 将寄存器值写回内存

原子操作的保证：
atomic_int counter = 0;
atomic_fetch_add(&counter, 1);  // 硬件保证原子性
```

**GCC内建原子操作**：

| 操作类型 | **函数名** | **功能说明** |
|---------|-----------|-------------|
| **加法** | `__atomic_add_fetch()` | `原子加法并返回新值` |
| **减法** | `__atomic_sub_fetch()` | `原子减法并返回新值` |
| **比较交换** | `__atomic_compare_exchange()` | `CAS操作` |
| **交换** | `__atomic_exchange()` | `原子交换值` |
| **载入** | `__atomic_load()` | `原子读取` |
| **存储** | `__atomic_store()` | `原子写入` |

### 8.2 原子操作实现无锁数据结构


**无锁栈实现**：

```c
#include <stdatomic.h>

typedef struct StackNode {
    int data;
    struct StackNode* next;
} StackNode;

typedef struct {
    atomic_uintptr_t top;  // 原子指针
} LockFreeStack;

void stack_init(LockFreeStack* stack) {
    atomic_store(&stack->top, (uintptr_t)NULL);
}

void stack_push(LockFreeStack* stack, int value) {
    StackNode* new_node = malloc(sizeof(StackNode));
    new_node->data = value;
    
    uintptr_t old_top;
    do {
        old_top = atomic_load(&stack->top);
        new_node->next = (StackNode*)old_top;
        // CAS操作：如果top还是old_top，就更新为new_node
    } while (!atomic_compare_exchange_weak(&stack->top, &old_top, (uintptr_t)new_node));
}

int stack_pop(LockFreeStack* stack, int* value) {
    uintptr_t old_top;
    StackNode* next;
    
    do {
        old_top = atomic_load(&stack->top);
        if (old_top == (uintptr_t)NULL) {
            return 0;  // 栈为空
        }
        
        next = ((StackNode*)old_top)->next;
        // CAS操作：如果top还是old_top，就更新为next
    } while (!atomic_compare_exchange_weak(&stack->top, &old_top, (uintptr_t)next));
    
    *value = ((StackNode*)old_top)->data;
    free((StackNode*)old_top);
    return 1;
}
```

### 8.3 内存屏障与内存序


**内存屏障（Memory Barrier）**：防止编译器和CPU重排序指令，确保内存操作的顺序性

```
内存序类型：
┌─memory_order_relaxed─────────────────┐
│ • 最宽松的内存序，只保证原子性        │
│ • 不保证与其他内存操作的顺序关系      │
└────────────────────────────────────┘

┌─memory_order_acquire─────────────────┐
│ • 获取语义，用于读操作                │
│ • 保证后续操作不会重排到此操作之前     │
└────────────────────────────────────┘

┌─memory_order_release─────────────────┐
│ • 释放语义，用于写操作                │
│ • 保证前面操作不会重排到此操作之后     │
└────────────────────────────────────┘

┌─memory_order_seq_cst─────────────────┐
│ • 顺序一致性，最严格的内存序          │
│ • 保证全局顺序一致，性能开销最大      │
└────────────────────────────────────┘
```

**生产者-消费者的内存屏障使用**：

```c
atomic_int data = 0;
atomic_int flag = 0;

// 生产者线程
void producer() {
    atomic_store(&data, 42);                    // 写数据
    atomic_store(&flag, 1);                     // 设置标志
    // release语义确保数据写入在标志设置之前完成
}

// 消费者线程  
void consumer() {
    while (atomic_load(&flag) == 0) {           // 等待标志
        // acquire语义确保后续读取在标志检查之后
    }
    int value = atomic_load(&data);             // 读取数据
    printf("收到数据: %d\n", value);
}
```

### 8.4 原子操作的性能考虑


> 📊 **性能对比**：
> - **互斥锁** - 系统调用开销，上下文切换
> - **自旋锁** - CPU忙等待，适合短时间持有
> - **原子操作** - 硬件级别支持，最低延迟
> - **无锁算法** - 高并发性能，但实现复杂

**使用场景选择**：

```c
// 简单计数器：优选原子操作
atomic_int counter = 0;
atomic_fetch_add(&counter, 1);

// 复杂数据结构：使用互斥锁
pthread_mutex_t mutex;
// 复杂的临界区操作

// 高频短操作：考虑自旋锁
pthread_spinlock_t spinlock;
```

---

## 9. 🎯 锁粒度设计与性能优化


### 9.1 锁粒度的权衡


**锁粒度（Lock Granularity）**：锁保护的数据范围大小

```
粗粒度锁:                     细粒度锁:
┌──────────────────────┐     ┌─────┬─────┬─────┬─────┐
│    全局锁保护         │     │ 锁1 │ 锁2 │ 锁3 │ 锁4 │
│  所有数据结构         │     │     │     │     │     │
└──────────────────────┘     └─────┴─────┴─────┴─────┘

优点: 实现简单，避免死锁      优点: 并发性高，锁竞争少
缺点: 并发性差，性能瓶颈      缺点: 复杂度高，容易死锁
```

### 9.2 数据库表级锁设计


**分层锁策略**：

```c
// 数据库表的分级锁设计
typedef struct {
    pthread_rwlock_t table_lock;     // 表级读写锁
    pthread_mutex_t* row_locks;      // 行级互斥锁数组
    int row_count;
    char table_name[64];
} DatabaseTable;

// 表级操作（如DDL）
int table_alter_schema(DatabaseTable* table) {
    pthread_rwlock_wrlock(&table->table_lock);  // 获取表级写锁
    
    printf("正在修改表结构: %s\n", table->table_name);
    // 执行结构修改操作
    usleep(100000);  // 模拟操作时间
    
    pthread_rwlock_unlock(&table->table_lock);
    return 0;
}

// 行级操作（如DML）
int row_update(DatabaseTable* table, int row_id, const char* new_value) {
    pthread_rwlock_rdlock(&table->table_lock);  // 获取表级读锁
    
    if (row_id >= table->row_count) {
        pthread_rwlock_unlock(&table->table_lock);
        return -1;
    }
    
    pthread_mutex_lock(&table->row_locks[row_id]);  // 获取行级锁
    
    printf("更新行 %d: %s\n", row_id, new_value);
    // 执行行更新操作
    usleep(10000);
    
    pthread_mutex_unlock(&table->row_locks[row_id]);
    pthread_rwlock_unlock(&table->table_lock);
    
    return 0;
}
```

### 9.3 缓存系统的锁分段


**分段锁技术**：将数据分成多个段，每段使用独立的锁

```c
#define CACHE_SEGMENTS 16

typedef struct {
    char key[64];
    char value[256];
    time_t expire_time;
} CacheEntry;

typedef struct {
    CacheEntry* entries;
    int capacity;
    int count;
    pthread_rwlock_t rwlock;
} CacheSegment;

typedef struct {
    CacheSegment segments[CACHE_SEGMENTS];
    int total_capacity;
} SegmentedCache;

// 哈希函数决定使用哪个段
int get_segment_index(const char* key) {
    unsigned int hash = 0;
    for (int i = 0; key[i]; i++) {
        hash = hash * 31 + key[i];
    }
    return hash % CACHE_SEGMENTS;
}

// 获取缓存项
char* cache_get_segmented(SegmentedCache* cache, const char* key) {
    int segment_idx = get_segment_index(key);
    CacheSegment* segment = &cache->segments[segment_idx];
    
    pthread_rwlock_rdlock(&segment->rwlock);
    
    // 在指定段中查找
    for (int i = 0; i < segment->count; i++) {
        if (strcmp(segment->entries[i].key, key) == 0) {
            // 检查是否过期
            if (time(NULL) < segment->entries[i].expire_time) {
                char* result = strdup(segment->entries[i].value);
                pthread_rwlock_unlock(&segment->rwlock);
                return result;
            }
        }
    }
    
    pthread_rwlock_unlock(&segment->rwlock);
    return NULL;
}

// 设置缓存项
int cache_set_segmented(SegmentedCache* cache, const char* key, 
                       const char* value, int ttl) {
    int segment_idx = get_segment_index(key);
    CacheSegment* segment = &cache->segments[segment_idx];
    
    pthread_rwlock_wrlock(&segment->rwlock);
    
    // 在指定段中添加或更新
    for (int i = 0; i < segment->count; i++) {
        if (strcmp(segment->entries[i].key, key) == 0) {
            // 更新现有项
            strcpy(segment->entries[i].value, value);
            segment->entries[i].expire_time = time(NULL) + ttl;
            pthread_rwlock_unlock(&segment->rwlock);
            return 0;
        }
    }
    
    // 添加新项
    if (segment->count < segment->capacity) {
        strcpy(segment->entries[segment->count].key, key);
        strcpy(segment->entries[segment->count].value, value);
        segment->entries[segment->count].expire_time = time(NULL) + ttl;
        segment->count++;
    }
    
    pthread_rwlock_unlock(&segment->rwlock);
    return 0;
}
```

### 9.4 锁优化技巧


**优化策略总结**：

> 🚀 **锁消除优化**：
> - **逃逸分析** - 如果对象不会被其他线程访问，消除锁
> - **锁粗化** - 合并连续的加锁解锁操作
> - **锁偏向** - 对于只被一个线程访问的锁，优化为偏向锁

**实用优化技巧**：

```c
// 技巧1：减小临界区
void optimized_function() {
    // 预处理工作
    int local_result = expensive_computation();
    
    pthread_mutex_lock(&mutex);
    shared_variable = local_result;  // 只在临界区内做必要操作
    pthread_mutex_unlock(&mutex);
}

// 技巧2：读写分离
void read_optimized() {
    // 先尝试读锁
    pthread_rwlock_rdlock(&rwlock);
    if (check_condition()) {
        char* result = get_data();
        pthread_rwlock_unlock(&rwlock);
        return result;
    }
    pthread_rwlock_unlock(&rwlock);
    
    // 需要写操作时才获取写锁
    pthread_rwlock_wrlock(&rwlock);
    modify_data();
    pthread_rwlock_unlock(&rwlock);
}

// 技巧3：双重检查锁
static int initialized = 0;
static pthread_mutex_t init_mutex = PTHREAD_MUTEX_INITIALIZER;

void lazy_initialization() {
    if (!initialized) {  // 第一次检查，无锁
        pthread_mutex_lock(&init_mutex);
        if (!initialized) {  // 第二次检查，有锁
            // 执行初始化
            expensive_init_function();
            initialized = 1;
        }
        pthread_mutex_unlock(&init_mutex);
    }
}
```

**性能测试建议**：

```bash
# 使用perf工具分析锁竞争
perf record -e cpu-clock,context-switches ./program
perf report

# 使用pstack查看线程状态
pstack <pid>

# 监控锁等待时间
time ./program
```

---

## 10. 📋 核心要点总结


### 10.1 必须掌握的基本概念


```
🔸 互斥锁(mutex)：最基础的同步原语，确保临界区独占访问
🔸 条件变量(cond)：线程间的等待-通知机制，避免忙等待
🔸 读写锁(rwlock)：读写分离优化，提高并发读性能
🔸 屏障同步(barrier)：多线程集合点，适用于并行算法
🔸 原子操作：硬件级别的不可分割操作，构建无锁数据结构
🔸 死锁预防：固定锁顺序、超时机制、银行家算法
🔸 线程安全：函数在多线程环境下的正确性保证
🔸 锁粒度：平衡并发性和复杂度的关键设计决策
```

### 10.2 关键理解要点


**🔹 同步机制的选择原则**：
```
数据访问模式分析：
• 读多写少 → 读写锁提升并发性
• 频繁修改 → 普通互斥锁更简单
• 简单计数 → 原子操作性能最佳
• 复杂逻辑 → 互斥锁保证安全性

性能 vs 复杂度权衡：
• 无锁编程：性能最佳，实现最复杂
• 细粒度锁：高并发，易死锁
• 粗粒度锁：实现简单，可能瓶颈
• 混合策略：分层设计，渐进优化
```

**🔹 常见问题的解决思路**：
```
竞态条件 → 识别临界区 + 合适的锁
死锁问题 → 锁顺序 + 超时 + 检测工具
性能瓶颈 → 锁粒度优化 + 读写分离
可扩展性 → 分段锁 + 无锁算法
```

### 10.3 实际应用指导


**工程实践要点**：
- **先正确性，后性能** - 确保程序正确后再优化性能
- **工具辅助调试** - 使用ThreadSanitizer、Valgrind等工具
- **渐进式优化** - 从粗粒度锁开始，逐步细化
- **性能测试验证** - 实际负载下验证优化效果

**设计模式应用**：
- **生产者-消费者** - 条件变量实现缓冲区管理
- **读者-写者** - 读写锁优化数据库/缓存访问
- **线程池** - 工作队列 + 条件变量调度
- **并行计算** - 屏障同步协调计算阶段

**性能优化建议**：
- **锁消除** - 分析数据逃逸，去除不必要的锁
- **锁粗化** - 合并细碎的锁操作
- **分段策略** - 将数据分段降低锁竞争
- **无锁设计** - 关键路径使用原子操作

**核心记忆要点**：
- 线程同步的本质是协调多线程对共享资源的访问
- 不同同步机制适用于不同的访问模式和性能需求
- 死锁预防重于检测，工具辅助重于人工排查
- 性能优化需要基于实际负载的测试验证
- 正确性永远比性能更重要，过早优化是万恶之源