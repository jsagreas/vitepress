---
title: 12ã€é›†ç¾¤æ‰©ç¼©å®¹ä¸è‡ªåŠ¨åŒ–
---
## ğŸ“š ç›®å½•

1. [è‡ªåŠ¨æ‰©ç¼©å®¹æ¦‚è¿°](#1-è‡ªåŠ¨æ‰©ç¼©å®¹æ¦‚è¿°)
2. [æ°´å¹³Podè‡ªåŠ¨æ‰©ç¼©å®¹HPA](#2-æ°´å¹³Podè‡ªåŠ¨æ‰©ç¼©å®¹HPA)
3. [å‚ç›´Podè‡ªåŠ¨æ‰©ç¼©å®¹VPA](#3-å‚ç›´Podè‡ªåŠ¨æ‰©ç¼©å®¹VPA)
4. [é›†ç¾¤è‡ªåŠ¨æ‰©ç¼©å®¹Cluster Autoscaler](#4-é›†ç¾¤è‡ªåŠ¨æ‰©ç¼©å®¹Cluster-Autoscaler)
5. [è‡ªå®šä¹‰æŒ‡æ ‡æ‰©ç¼©å®¹é…ç½®](#5-è‡ªå®šä¹‰æŒ‡æ ‡æ‰©ç¼©å®¹é…ç½®)
6. [èŠ‚ç‚¹æ± ç®¡ç†ä¸è°ƒåº¦ç­–ç•¥](#6-èŠ‚ç‚¹æ± ç®¡ç†ä¸è°ƒåº¦ç­–ç•¥)
7. [èµ„æºé¢„ç•™ä¸èŠ‚ç‚¹äº²å’Œæ€§](#7-èµ„æºé¢„ç•™ä¸èŠ‚ç‚¹äº²å’Œæ€§)
8. [æ‰©ç¼©å®¹ç­–ç•¥ä¸é˜ˆå€¼é…ç½®](#8-æ‰©ç¼©å®¹ç­–ç•¥ä¸é˜ˆå€¼é…ç½®)
9. [æˆæœ¬ä¼˜åŒ–ä¸èµ„æºæ•ˆç‡](#9-æˆæœ¬ä¼˜åŒ–ä¸èµ„æºæ•ˆç‡)
10. [å¼¹æ€§ä¼¸ç¼©æœ€ä½³å®è·µ](#10-å¼¹æ€§ä¼¸ç¼©æœ€ä½³å®è·µ)
11. [æ ¸å¿ƒè¦ç‚¹æ€»ç»“](#11-æ ¸å¿ƒè¦ç‚¹æ€»ç»“)

---

## 1. ğŸ¯ è‡ªåŠ¨æ‰©ç¼©å®¹æ¦‚è¿°


### 1.1 ä»€ä¹ˆæ˜¯è‡ªåŠ¨æ‰©ç¼©å®¹


**é€šä¿—ç†è§£**ï¼šæƒ³è±¡ä¸€ä¸ªè‡ªåŠ©é¤å…ï¼Œå½“å®¢äººå¤šçš„æ—¶å€™è‡ªåŠ¨å¢åŠ æœåŠ¡å‘˜ï¼Œå®¢äººå°‘çš„æ—¶å€™å‡å°‘æœåŠ¡å‘˜ã€‚Kubernetesçš„è‡ªåŠ¨æ‰©ç¼©å®¹å°±æ˜¯è¿™ä¸ªé“ç†ï¼Œæ ¹æ®å®é™…è´Ÿè½½è‡ªåŠ¨è°ƒæ•´èµ„æºã€‚

**æ ¸å¿ƒæ¦‚å¿µ**ï¼š
```
è‡ªåŠ¨æ‰©ç¼©å®¹å°±åƒæ™ºèƒ½ç®¡å®¶ï¼š
â€¢ ç›‘æ§ç³»ç»Ÿè´Ÿè½½çŠ¶æ€
â€¢ æ ¹æ®é¢„è®¾è§„åˆ™è‡ªåŠ¨è°ƒæ•´
â€¢ ä¿è¯æœåŠ¡è´¨é‡ä¸ä¸‹é™
â€¢ é¿å…èµ„æºæµªè´¹
```

### 1.2 ä¸‰ç§æ‰©ç¼©å®¹ç±»å‹


```
Kubernetesæ‰©ç¼©å®¹ä¸‰å…„å¼Ÿï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   HPA (æ°´å¹³)    â”‚ â† å¢å‡Podæ•°é‡
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   VPA (å‚ç›´)    â”‚ â† è°ƒæ•´Podèµ„æº
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  CA (é›†ç¾¤çº§)    â”‚ â† å¢å‡å·¥ä½œèŠ‚ç‚¹
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ç”Ÿæ´»ç±»æ¯”ï¼š
â€¢ HPAï¼šé¤å…å¿™æ—¶å¤šå¼€å‡ ä¸ªçª—å£
â€¢ VPAï¼šç»™å¨å¸ˆé…æ›´å¤§çš„é”…å­
â€¢ CAï¼šç”Ÿæ„å¥½æ—¶ç§Ÿæ›´å¤šåº—é¢
```

### 1.3 æ‰©ç¼©å®¹çš„æ„ä¹‰


**ä¸šåŠ¡ä»·å€¼**ï¼š
- **æˆæœ¬æ§åˆ¶**ï¼šæŒ‰éœ€åˆ†é…ï¼Œé¿å…èµ„æºæµªè´¹
- **æ€§èƒ½ä¿éšœ**ï¼šè´Ÿè½½é«˜å³°æ—¶è‡ªåŠ¨æ‰©å®¹
- **è¿ç»´ç®€åŒ–**ï¼šå‡å°‘äººå·¥å¹²é¢„
- **ç”¨æˆ·ä½“éªŒ**ï¼šä¿æŒæœåŠ¡å“åº”é€Ÿåº¦

---

## 2. âš–ï¸ æ°´å¹³Podè‡ªåŠ¨æ‰©ç¼©å®¹HPA


### 2.1 HPAå·¥ä½œåŸç†


**é€šä¿—è§£é‡Š**ï¼šHPAå°±åƒé¤å…çš„æœåŠ¡ç”Ÿè°ƒåº¦å‘˜ï¼Œå½“é¡¾å®¢å¤šçš„æ—¶å€™å«æ›´å¤šæœåŠ¡ç”Ÿä¸Šå²—ï¼Œé¡¾å®¢å°‘çš„æ—¶å€™è®©ä¸€äº›æœåŠ¡ç”Ÿä¼‘æ¯ã€‚

```
HPAå·¥ä½œæµç¨‹ï¼š
å®¢æˆ·è¯·æ±‚å¢å¤š â†’ CPUä½¿ç”¨ç‡ä¸Šå‡ â†’ HPAæ£€æµ‹åˆ°æŒ‡æ ‡è¶…æ ‡ 
â†’ åˆ›å»ºæ›´å¤šPod â†’ è´Ÿè½½åˆ†æ•£ â†’ ç³»ç»Ÿæ¢å¤æ­£å¸¸

ç›‘æ§å‘¨æœŸï¼šé»˜è®¤15ç§’æ£€æŸ¥ä¸€æ¬¡æŒ‡æ ‡
å†³ç­–å‘¨æœŸï¼šé»˜è®¤3åˆ†é’Ÿå†…ä¸ä¼šè¿ç»­æ‰©ç¼©å®¹
```

### 2.2 HPAåŸºç¡€é…ç½®


**CPUä½¿ç”¨ç‡æ‰©ç¼©å®¹**ï¼š

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: webapp-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: webapp
  minReplicas: 2        # æœ€å°‘2ä¸ªPod
  maxReplicas: 10       # æœ€å¤š10ä¸ªPod
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70  # CPUè¶…è¿‡70%å¼€å§‹æ‰©å®¹
```

**å†…å­˜ä½¿ç”¨ç‡æ‰©ç¼©å®¹**ï¼š

```yaml
metrics:
- type: Resource
  resource:
    name: memory
    target:
      type: Utilization
      averageUtilization: 80  # å†…å­˜è¶…è¿‡80%æ‰©å®¹
```

### 2.3 HPAå¤šæŒ‡æ ‡é…ç½®


**ç»„åˆæŒ‡æ ‡ç­–ç•¥**ï¼š

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: multi-metric-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: web-service
  minReplicas: 3
  maxReplicas: 20
  metrics:
  # CPUæŒ‡æ ‡
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 60
  # å†…å­˜æŒ‡æ ‡  
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 75
  # QPSæŒ‡æ ‡ï¼ˆæ¯ç§’è¯·æ±‚æ•°ï¼‰
  - type: Pods
    pods:
      metric:
        name: requests_per_second
      target:
        type: AverageValue
        averageValue: "100"  # æ¯ä¸ªPodå¤„ç†100QPS
```

### 2.4 HPAæ‰©ç¼©å®¹è¡Œä¸ºæ§åˆ¶


**ç²¾ç»†åŒ–æ§åˆ¶ç­–ç•¥**ï¼š

```yaml
spec:
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 60    # æ‰©å®¹ç¨³å®šçª—å£1åˆ†é’Ÿ
      policies:
      - type: Percent
        value: 100           # æ¯æ¬¡æœ€å¤šæ‰©å®¹100%
        periodSeconds: 60    # 1åˆ†é’Ÿå†…
      - type: Pods
        value: 2             # æˆ–è€…æ¯æ¬¡æœ€å¤šå¢åŠ 2ä¸ªPod
        periodSeconds: 60
      selectPolicy: Min      # é€‰æ‹©æ›´ä¿å®ˆçš„ç­–ç•¥
    scaleDown:
      stabilizationWindowSeconds: 300   # ç¼©å®¹ç¨³å®šçª—å£5åˆ†é’Ÿ
      policies:
      - type: Percent
        value: 50            # æ¯æ¬¡æœ€å¤šç¼©å®¹50%
        periodSeconds: 60
```

---

## 3. ğŸ“Š å‚ç›´Podè‡ªåŠ¨æ‰©ç¼©å®¹VPA


### 3.1 VPAåŸºæœ¬æ¦‚å¿µ


**é€šä¿—ç†è§£**ï¼šå¦‚æœHPAæ˜¯å¢åŠ æœåŠ¡å‘˜æ•°é‡ï¼Œé‚£ä¹ˆVPAå°±æ˜¯ç»™ç°æœ‰æœåŠ¡å‘˜é…å¤‡æ›´å¥½çš„å·¥å…·ã€‚VPAä¸æ˜¯å¢åŠ Podæ•°é‡ï¼Œè€Œæ˜¯è°ƒæ•´æ¯ä¸ªPodçš„CPUå’Œå†…å­˜é…ç½®ã€‚

```
VPAçš„ä¸‰ç§å·¥ä½œæ¨¡å¼ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Off (å…³é—­)      â”‚ â† åªæ¨èï¼Œä¸æ‰§è¡Œ
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Initial (åˆå§‹)  â”‚ â† ä»…åœ¨Podåˆ›å»ºæ—¶è®¾ç½®
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Auto (è‡ªåŠ¨)     â”‚ â† è‡ªåŠ¨è°ƒæ•´å¹¶é‡å¯Pod
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 VPAé…ç½®ç¤ºä¾‹


**åŸºç¡€VPAé…ç½®**ï¼š

```yaml
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: webapp-vpa
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: webapp
  updatePolicy:
    updateMode: "Auto"      # è‡ªåŠ¨æ¨¡å¼
  resourcePolicy:
    containerPolicies:
    - containerName: webapp
      minAllowed:
        cpu: 100m           # æœ€å°CPU 100æ¯«æ ¸
        memory: 128Mi       # æœ€å°å†…å­˜ 128MB
      maxAllowed:
        cpu: 2              # æœ€å¤§CPU 2æ ¸
        memory: 4Gi         # æœ€å¤§å†…å­˜ 4GB
```

**æ¨èæ¨¡å¼VPA**ï¼ˆé€‚åˆè§‚å¯Ÿå­¦ä¹ ï¼‰ï¼š

```yaml
spec:
  updatePolicy:
    updateMode: "Off"       # åªæ¨èä¸æ‰§è¡Œ
```

### 3.3 VPAä½¿ç”¨æ³¨æ„äº‹é¡¹


> **âš ï¸ é‡è¦æé†’ï¼š**
> VPAè°ƒæ•´èµ„æºæ—¶ä¼šé‡å¯Podï¼Œè¿™å¯èƒ½å½±å“æœåŠ¡å¯ç”¨æ€§ã€‚å»ºè®®ï¼š
> - å…ˆåœ¨æµ‹è¯•ç¯å¢ƒéªŒè¯
> - ç¡®ä¿åº”ç”¨æ”¯æŒä¼˜é›…é‡å¯
> - é¿å…ä¸HPAåŒæ—¶ä½¿ç”¨åŒä¸€ä¸ªDeployment

**VPAä¸HPAå†²çªè§£å†³**ï¼š

```
è§£å†³æ–¹æ¡ˆé€‰æ‹©ï¼š
æƒ…å†µ1ï¼šåº”ç”¨å¯æ°´å¹³æ‰©å±• â†’ ä¼˜å…ˆé€‰æ‹©HPA
æƒ…å†µ2ï¼šåº”ç”¨èµ„æºéœ€æ±‚ä¸ç¨³å®š â†’ é€‰æ‹©VPA  
æƒ…å†µ3ï¼šä¸¤è€…éƒ½éœ€è¦ â†’ ä½¿ç”¨ä¸åŒçš„èµ„æºæŒ‡æ ‡åˆ†ç¦»
```

---

## 4. ğŸ—ï¸ é›†ç¾¤è‡ªåŠ¨æ‰©ç¼©å®¹Cluster Autoscaler


### 4.1 Cluster Autoscalerå·¥ä½œæœºåˆ¶


**é€šä¿—è§£é‡Š**ï¼šCAå°±åƒå»ºç­‘å·¥åœ°çš„é¡¹ç›®ç»ç†ï¼Œå½“å·¥äººä¸å¤Ÿç”¨çš„æ—¶å€™å°±æ‹›è˜æ–°å·¥äººï¼Œé¡¹ç›®ç»“æŸåå°±è®©å¤šä½™çš„å·¥äººç¦»å¼€ã€‚

```
CAå†³ç­–æµç¨‹ï¼š
Podè°ƒåº¦å¤±è´¥ â†’ æ£€æŸ¥èŠ‚ç‚¹èµ„æºä¸è¶³ â†’ å‘äº‘å‚å•†ç”³è¯·æ–°èŠ‚ç‚¹
â†’ æ–°èŠ‚ç‚¹åŠ å…¥é›†ç¾¤ â†’ PodæˆåŠŸè°ƒåº¦

èŠ‚ç‚¹ç©ºé—²æ£€æµ‹ â†’ å®‰å…¨æ£€æŸ¥(æ— å…³é”®Pod) â†’ æ ‡è®°èŠ‚ç‚¹åˆ é™¤
â†’ é©±é€Podåˆ°å…¶ä»–èŠ‚ç‚¹ â†’ é‡Šæ”¾ç©ºé—²èŠ‚ç‚¹
```

### 4.2 CAéƒ¨ç½²é…ç½®


**AWSç¯å¢ƒCAé…ç½®**ï¼š

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: cluster-autoscaler
  namespace: kube-system
spec:
  replicas: 1
  selector:
    matchLabels:
      app: cluster-autoscaler
  template:
    spec:
      containers:
      - image: k8s.gcr.io/autoscaling/cluster-autoscaler:v1.21.0
        name: cluster-autoscaler
        command:
        - ./cluster-autoscaler
        - --v=4
        - --stderrthreshold=info
        - --cloud-provider=aws
        - --skip-nodes-with-local-storage=false
        - --expander=least-waste      # æ‰©å®¹ç­–ç•¥ï¼šæœ€å°‘æµªè´¹
        - --node-group-auto-discovery=asg:tag=k8s.io/cluster-autoscaler/enabled,k8s.io/cluster-autoscaler/k8s-cluster
        - --balance-similar-node-groups
        - --scale-down-enabled=true   # å¯ç”¨ç¼©å®¹
        - --scale-down-delay-after-add=10m        # æ–°èŠ‚ç‚¹10åˆ†é’Ÿåæ‰èƒ½ç¼©å®¹
        - --scale-down-unneeded-time=10m          # èŠ‚ç‚¹ç©ºé—²10åˆ†é’Ÿåç¼©å®¹
        - --scale-down-utilization-threshold=0.5  # èŠ‚ç‚¹ä½¿ç”¨ç‡50%ä»¥ä¸‹å¯ç¼©å®¹
```

### 4.3 èŠ‚ç‚¹ç»„æ ‡ç­¾é…ç½®


**Auto Scaling Groupæ ‡ç­¾è®¾ç½®**ï¼š

| æ ‡ç­¾Key | æ ‡ç­¾Value | è¯´æ˜ |
|---------|-----------|------|
| `k8s.io/cluster-autoscaler/enabled` | `true` | å¯ç”¨è‡ªåŠ¨æ‰©ç¼©å®¹ |
| `k8s.io/cluster-autoscaler/cluster-name` | `your-cluster` | æŒ‡å®šé›†ç¾¤åç§° |
| `k8s.io/cluster-autoscaler/node-template/label/node-type` | `worker` | èŠ‚ç‚¹ç±»å‹æ ‡è¯† |

### 4.4 CAæ‰©ç¼©å®¹ç­–ç•¥


**æ‰©å®¹ç­–ç•¥å¯¹æ¯”**ï¼š

| ç­–ç•¥åç§° | è¯´æ˜ | é€‚ç”¨åœºæ™¯ |
|----------|------|----------|
| `random` | éšæœºé€‰æ‹©èŠ‚ç‚¹ç»„ | èŠ‚ç‚¹ç»„é…ç½®ç›¸ä¼¼æ—¶ |
| `most-pods` | é€‰æ‹©èƒ½è°ƒåº¦æœ€å¤šPodçš„ç»„ | ä¼˜åŒ–Podå¯†åº¦ |
| `least-waste` | é€‰æ‹©èµ„æºæµªè´¹æœ€å°‘çš„ç»„ | æˆæœ¬æ•æ„Ÿåœºæ™¯ |
| `price` | é€‰æ‹©ä»·æ ¼æœ€ä½çš„èŠ‚ç‚¹ç»„ | æˆæœ¬ä¼˜åŒ–ä¼˜å…ˆ |

---

## 5. ğŸ“ˆ è‡ªå®šä¹‰æŒ‡æ ‡æ‰©ç¼©å®¹é…ç½®


### 5.1 è‡ªå®šä¹‰æŒ‡æ ‡æ¦‚å¿µ


**ä¸šåŠ¡åœºæ™¯ä¸¾ä¾‹**ï¼š
- **æ¶ˆæ¯é˜Ÿåˆ—é•¿åº¦**ï¼šé˜Ÿåˆ—ç§¯å‹è¶…è¿‡1000æ¡æ¶ˆæ¯æ—¶æ‰©å®¹
- **æ•°æ®åº“è¿æ¥æ•°**ï¼šè¿æ¥æ± ä½¿ç”¨ç‡è¶…è¿‡80%æ—¶æ‰©å®¹  
- **å“åº”æ—¶é—´**ï¼šAPIå“åº”æ—¶é—´è¶…è¿‡500msæ—¶æ‰©å®¹
- **ä¸šåŠ¡æŒ‡æ ‡**ï¼šè®¢å•å¤„ç†é€Ÿåº¦ã€ç”¨æˆ·ç™»å½•æ•°ç­‰

### 5.2 Prometheusé€‚é…å™¨é…ç½®


**å®‰è£…Prometheus Adapter**ï¼š

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: adapter-config
  namespace: custom-metrics
data:
  config.yaml: |
    rules:
    # HTTPè¯·æ±‚é€Ÿç‡æŒ‡æ ‡
    - seriesQuery: 'http_requests_per_second{namespace!="",pod!=""}'
      resources:
        overrides:
          namespace: {resource: "namespace"}
          pod: {resource: "pod"}
      name:
        matches: "^(.*)"
        as: "http_requests_per_second"
      metricsQuery: 'sum(rate(<<.Series>>{<<.LabelMatchers>>}[2m])) by (<<.GroupBy>>)'
    # é˜Ÿåˆ—é•¿åº¦æŒ‡æ ‡  
    - seriesQuery: 'rabbitmq_queue_messages{namespace!="",pod!=""}'
      resources:
        overrides:
          namespace: {resource: "namespace"}
          pod: {resource: "pod"}
      name:
        matches: "^(.*)"
        as: "queue_messages"
      metricsQuery: 'avg(<<.Series>>{<<.LabelMatchers>>}) by (<<.GroupBy>>)'
```

### 5.3 åŸºäºè‡ªå®šä¹‰æŒ‡æ ‡çš„HPA


**æ¶ˆæ¯é˜Ÿåˆ—é•¿åº¦æ‰©ç¼©å®¹**ï¼š

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: queue-consumer-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: queue-consumer
  minReplicas: 2
  maxReplicas: 20
  metrics:
  # é˜Ÿåˆ—æ¶ˆæ¯æ•°é‡
  - type: Pods
    pods:
      metric:
        name: queue_messages
      target:
        type: AverageValue
        averageValue: "50"      # æ¯ä¸ªPodå¤„ç†50æ¡æ¶ˆæ¯
  # HTTPè¯·æ±‚é€Ÿç‡
  - type: Pods  
    pods:
      metric:
        name: http_requests_per_second
      target:
        type: AverageValue
        averageValue: "100"     # æ¯ä¸ªPodå¤„ç†100 QPS
```

### 5.4 å¤–éƒ¨æŒ‡æ ‡é…ç½®


**åŸºäºå¤–éƒ¨APIçš„æ‰©ç¼©å®¹**ï¼š

```yaml
metrics:
# åŸºäºAWS SQSé˜Ÿåˆ—é•¿åº¦
- type: External
  external:
    metric:
      name: sqs_messages_visible
      selector:
        matchLabels:
          queue: "order-processing"
    target:
      type: AverageValue
      averageValue: "30"
```

---

## 6. ğŸ¯ èŠ‚ç‚¹æ± ç®¡ç†ä¸è°ƒåº¦ç­–ç•¥


### 6.1 èŠ‚ç‚¹æ± æ¦‚å¿µä¸é…ç½®


**èŠ‚ç‚¹æ± åˆ†ç±»ç­–ç•¥**ï¼š

```
èŠ‚ç‚¹æ± è®¾è®¡æ€è·¯ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  é€šç”¨è®¡ç®—æ±       â”‚ â† CPUå¯†é›†å‹åº”ç”¨
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  å†…å­˜ä¼˜åŒ–æ±       â”‚ â† å†…å­˜å¯†é›†å‹åº”ç”¨  
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  GPUè®¡ç®—æ±        â”‚ â† AI/MLå·¥ä½œè´Ÿè½½
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  çªå‘è®¡ç®—æ±       â”‚ â† Spotå®ä¾‹ï¼Œä¸´æ—¶ä»»åŠ¡
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**å¤šèŠ‚ç‚¹æ± é…ç½®ç¤ºä¾‹**ï¼š

```yaml
# é€šç”¨èŠ‚ç‚¹æ± 
apiVersion: v1
kind: Node
metadata:
  name: general-node-pool
  labels:
    node-type: "general"
    instance-type: "m5.large"
    cost-type: "on-demand"
spec:
  taints:
  - key: "node-type"
    value: "general" 
    effect: "NoSchedule"

# GPUèŠ‚ç‚¹æ± 
apiVersion: v1
kind: Node  
metadata:
  name: gpu-node-pool
  labels:
    node-type: "gpu"
    instance-type: "p3.2xlarge"
    accelerator: "nvidia-tesla-v100"
spec:
  taints:
  - key: "nvidia.com/gpu"
    value: "true"
    effect: "NoSchedule"
```

### 6.2 PodèŠ‚ç‚¹äº²å’Œæ€§é…ç½®


**é€‰æ‹©ç‰¹å®šèŠ‚ç‚¹æ± **ï¼š

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ml-training
spec:
  template:
    spec:
      # èŠ‚ç‚¹äº²å’Œæ€§ï¼šå¿…é¡»è°ƒåº¦åˆ°GPUèŠ‚ç‚¹
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: accelerator
                operator: In
                values: ["nvidia-tesla-v100"]
          # åå¥½è°ƒåº¦åˆ°æ–°èŠ‚ç‚¹
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            preference:
              matchExpressions:
              - key: node.kubernetes.io/instance-type
                operator: In
                values: ["p3.2xlarge"]
      # å®¹å¿GPUèŠ‚ç‚¹æ±¡ç‚¹
      tolerations:
      - key: "nvidia.com/gpu"
        operator: "Equal"
        value: "true"
        effect: "NoSchedule"
```

### 6.3 Podé—´äº²å’Œæ€§ä¸åäº²å’Œæ€§


**é«˜å¯ç”¨éƒ¨ç½²ç­–ç•¥**ï¼š

```yaml
spec:
  template:
    spec:
      affinity:
        # Podåäº²å’Œæ€§ï¼šä¸è¦è°ƒåº¦åˆ°åŒä¸€èŠ‚ç‚¹
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values: ["web-server"]
              topologyKey: kubernetes.io/hostname
        # Podäº²å’Œæ€§ï¼šå°½é‡é è¿‘ç¼“å­˜æœåŠ¡
        podAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 50
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values: ["redis-cache"]
              topologyKey: kubernetes.io/hostname
```

---

## 7. ğŸ”§ èµ„æºé¢„ç•™ä¸èŠ‚ç‚¹äº²å’Œæ€§


### 7.1 ç³»ç»Ÿèµ„æºé¢„ç•™


**èŠ‚ç‚¹èµ„æºé¢„ç•™é…ç½®**ï¼š

```yaml
# kubeleté…ç½®æ–‡ä»¶
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
systemReserved:
  cpu: "500m"        # ä¸ºç³»ç»Ÿè¿›ç¨‹é¢„ç•™500æ¯«æ ¸CPU
  memory: "1Gi"      # ä¸ºç³»ç»Ÿè¿›ç¨‹é¢„ç•™1GBå†…å­˜  
  ephemeral-storage: "10Gi"  # é¢„ç•™ä¸´æ—¶å­˜å‚¨
kubeReserved:
  cpu: "200m"        # ä¸ºkubeletç­‰K8sç»„ä»¶é¢„ç•™CPU
  memory: "512Mi"    # ä¸ºK8sç»„ä»¶é¢„ç•™å†…å­˜
  ephemeral-storage: "5Gi"
evictionHard:
  memory.available: "5%"     # å¯ç”¨å†…å­˜ä½äº5%æ—¶é©±é€Pod
  nodefs.available: "10%"    # ç£ç›˜ç©ºé—´ä½äº10%æ—¶é©±é€
```

### 7.2 QoSæœåŠ¡è´¨é‡ç­‰çº§


**Pod QoSåˆ†ç±»æœºåˆ¶**ï¼š

```
QoSç­‰çº§ä¼˜å…ˆçº§(é«˜â†’ä½)ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Guaranteed     â”‚ â† CPU/å†…å­˜æœ‰æ˜ç¡®requests=limits
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  
â”‚  Burstable      â”‚ â† æœ‰requestsä½†requests<limits
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  BestEffort     â”‚ â† æ²¡æœ‰resourcesé…ç½®
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

èµ„æºä¸è¶³æ—¶é©±é€é¡ºåºï¼šBestEffort â†’ Burstable â†’ Guaranteed
```

**QoSé…ç½®ç¤ºä¾‹**ï¼š

```yaml
# Guaranteedçº§åˆ«Pod
spec:
  containers:
  - name: app
    resources:
      requests:
        cpu: "1"
        memory: "2Gi"
      limits:
        cpu: "1"          # limits = requests
        memory: "2Gi"     # limits = requests

# Burstableçº§åˆ«Pod  
spec:
  containers:
  - name: app
    resources:
      requests:
        cpu: "500m"
        memory: "1Gi"
      limits:
        cpu: "2"          # limits > requests
        memory: "4Gi"     # å…è®¸çªå‘ä½¿ç”¨

# BestEffortçº§åˆ«Pod
spec:
  containers:
  - name: app
    # ä¸é…ç½®resourcesï¼Œä¼˜å…ˆçº§æœ€ä½
```

### 7.3 Podä¼˜å…ˆçº§ä¸æŠ¢å 


**ä¼˜å…ˆçº§ç±»é…ç½®**ï¼š

```yaml
# å®šä¹‰é«˜ä¼˜å…ˆçº§ç±»
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: high-priority
value: 1000               # ä¼˜å…ˆçº§æ•°å€¼ï¼Œè¶Šå¤§ä¼˜å…ˆçº§è¶Šé«˜
globalDefault: false
description: "é«˜ä¼˜å…ˆçº§åº”ç”¨ä¸“ç”¨"

---
# å®šä¹‰ä½ä¼˜å…ˆçº§ç±»  
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: low-priority  
value: 100
globalDefault: false
description: "æ‰¹å¤„ç†ä»»åŠ¡ä¸“ç”¨"
```

**åº”ç”¨ä¼˜å…ˆçº§é…ç½®**ï¼š

```yaml
# å…³é”®ä¸šåŠ¡åº”ç”¨
apiVersion: apps/v1
kind: Deployment
metadata:
  name: critical-service
spec:
  template:
    spec:
      priorityClassName: high-priority  # ä½¿ç”¨é«˜ä¼˜å…ˆçº§
      containers:
      - name: app
        image: critical-app:latest

# æ‰¹å¤„ç†ä»»åŠ¡
apiVersion: batch/v1
kind: Job
metadata:
  name: batch-job
spec:
  template:
    spec:
      priorityClassName: low-priority   # ä½¿ç”¨ä½ä¼˜å…ˆçº§
      restartPolicy: Never
```

---

## 8. âš™ï¸ æ‰©ç¼©å®¹ç­–ç•¥ä¸é˜ˆå€¼é…ç½®


### 8.1 æ‰©ç¼©å®¹æ—¶æœºæ§åˆ¶


**æ‰©å®¹è§¦å‘æ¡ä»¶è®¾è®¡**ï¼š

```yaml
# å¤šå±‚æ‰©å®¹é˜ˆå€¼è®¾è®¡
metrics:
- type: Resource
  resource:
    name: cpu
    target:
      type: Utilization
      averageUtilization: 70    # CPU 70%å¼€å§‹æ‰©å®¹

behavior:
  scaleUp:
    # åˆ†é˜¶æ®µæ‰©å®¹ç­–ç•¥
    policies:
    # ç¬¬ä¸€é˜¶æ®µï¼šå¿«é€Ÿå“åº”
    - type: Percent
      value: 100               # è´Ÿè½½çªå¢æ—¶ï¼Œç«‹å³ç¿»å€
      periodSeconds: 60
    # ç¬¬äºŒé˜¶æ®µï¼šç¨³å®šå¢é•¿  
    - type: Pods
      value: 3                 # åç»­æ¯åˆ†é’Ÿæœ€å¤šå¢åŠ 3ä¸ªPod
      periodSeconds: 60
    selectPolicy: Max          # é€‰æ‹©æ›´æ¿€è¿›çš„æ‰©å®¹ç­–ç•¥
    stabilizationWindowSeconds: 30   # 30ç§’å†…è§‚å¯Ÿæ˜¯å¦éœ€è¦æ‰©å®¹
```

### 8.2 ç¼©å®¹ä¿æŠ¤ç­–ç•¥


**é˜²æ­¢é¢‘ç¹éœ‡è¡é…ç½®**ï¼š

```yaml
behavior:
  scaleDown:
    stabilizationWindowSeconds: 300    # 5åˆ†é’Ÿç¨³å®šçª—å£
    policies:
    - type: Percent
      value: 50                        # æ¯æ¬¡æœ€å¤šç¼©å®¹50%
      periodSeconds: 120               # 2åˆ†é’Ÿé—´éš”
    - type: Pods  
      value: 2                         # æˆ–æ¯æ¬¡æœ€å¤šå‡å°‘2ä¸ªPod
      periodSeconds: 120
    selectPolicy: Min                  # é€‰æ‹©æ›´ä¿å®ˆçš„ç¼©å®¹ç­–ç•¥
```

### 8.3 å¤šæŒ‡æ ‡æ‰©ç¼©å®¹é€»è¾‘


**æŒ‡æ ‡æƒé‡ä¸ç»„åˆç­–ç•¥**ï¼š

```yaml
metrics:
# ä¸»è¦æŒ‡æ ‡ï¼šCPUä½¿ç”¨ç‡
- type: Resource
  resource:
    name: cpu
    target:
      type: Utilization  
      averageUtilization: 60

# æ¬¡è¦æŒ‡æ ‡ï¼šå†…å­˜ä½¿ç”¨ç‡
- type: Resource
  resource:
    name: memory
    target:
      type: Utilization
      averageUtilization: 75

# ä¸šåŠ¡æŒ‡æ ‡ï¼šæ¯ä¸ªPodçš„QPS
- type: Pods
  pods:
    metric:
      name: requests_per_second
    target:
      type: AverageValue
      averageValue: "200"

# æ‰©ç¼©å®¹å†³ç­–é€»è¾‘ï¼š
# 1. ä»»ä½•ä¸€ä¸ªæŒ‡æ ‡è¶…è¿‡é˜ˆå€¼å°±æ‰©å®¹
# 2. æ‰€æœ‰æŒ‡æ ‡éƒ½ä½äºé˜ˆå€¼æ‰ç¼©å®¹
# 3. CPUæƒé‡æœ€é«˜ï¼Œä¸šåŠ¡æŒ‡æ ‡æ¬¡ä¹‹
```

### 8.4 é¢„æµ‹æ€§æ‰©ç¼©å®¹


> **ğŸ’¡ é«˜çº§æŠ€å·§ï¼š**
> ç»“åˆå†å²æ•°æ®å’Œä¸šåŠ¡æ¨¡å¼ï¼Œå¯ä»¥é…ç½®é¢„æµ‹æ€§æ‰©ç¼©å®¹ï¼š
> - å®šæ—¶æ‰©ç¼©å®¹ï¼šæå‰ä¸ºé«˜å³°æœŸå‡†å¤‡èµ„æº
> - åŸºäºç›‘æ§æ•°æ®çš„è¶‹åŠ¿é¢„æµ‹
> - ç»“åˆä¸šåŠ¡æ—¥å†çš„å®¹é‡è§„åˆ’

**å®šæ—¶æ‰©ç¼©å®¹é…ç½®**ï¼š

```yaml
# ä½¿ç”¨CronJobå®ç°å®šæ—¶æ‰©ç¼©å®¹
apiVersion: batch/v1
kind: CronJob
metadata:
  name: peak-time-scaler
spec:
  # æ¯å¤©æ—©ä¸Š8ç‚¹æ‰©å®¹åˆ°10ä¸ªå®ä¾‹
  schedule: "0 8 * * *"
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: scaler
            image: bitnami/kubectl
            command:
            - /bin/sh
            - -c
            - |
              kubectl patch hpa webapp-hpa -p '{"spec":{"minReplicas":10}}'
          restartPolicy: Never
```

---

## 9. ğŸ’° æˆæœ¬ä¼˜åŒ–ä¸èµ„æºæ•ˆç‡


### 9.1 æˆæœ¬ä¼˜åŒ–ç­–ç•¥


**å¤šå±‚èŠ‚ç‚¹æˆæœ¬é…ç½®**ï¼š

```
æˆæœ¬ä¼˜åŒ–èŠ‚ç‚¹æ± è®¾è®¡ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  å…³é”®ä¸šåŠ¡æ±           â”‚ â† On-Demandå®ä¾‹ï¼Œç¨³å®šå¯é 
â”‚  (On-Demand)        â”‚   ä»·æ ¼ï¼š100%
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ä¸€èˆ¬ä¸šåŠ¡æ±           â”‚ â† é¢„ç•™å®ä¾‹ï¼Œ75%æŠ˜æ‰£  
â”‚  (Reserved)         â”‚   ä»·æ ¼ï¼š25%
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  çªå‘ä»»åŠ¡æ±           â”‚ â† Spotå®ä¾‹ï¼Œ90%æŠ˜æ‰£
â”‚  (Spot Instance)    â”‚   ä»·æ ¼ï¼š10%ï¼Œå¯èƒ½ä¸­æ–­
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 9.2 Spotå®ä¾‹é…ç½®ä¸å¤„ç†


**Spotå®ä¾‹èŠ‚ç‚¹ç»„é…ç½®**ï¼š

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: batch-processor
spec:
  template:
    spec:
      # å®¹å¿Spotå®ä¾‹ä¸­æ–­
      tolerations:
      - key: "node.kubernetes.io/unschedulable"
        operator: "Exists"
        effect: "NoSchedule"
      - key: "aws.amazon.com/spot"
        operator: "Exists"
        effect: "NoSchedule"
      
      # åå¥½è°ƒåº¦åˆ°SpotèŠ‚ç‚¹  
      affinity:
        nodeAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            preference:
              matchExpressions:
              - key: node-lifecycle
                operator: In
                values: ["spot"]
      
      # Spotå®ä¾‹ä¸­æ–­å¤„ç†
      terminationGracePeriodSeconds: 30
```

**Spotä¸­æ–­å¤„ç†è„šæœ¬**ï¼š

```bash
#!/bin/bash
# éƒ¨ç½²åœ¨SpotèŠ‚ç‚¹çš„ä¸­æ–­å¤„ç†è„šæœ¬

# ç›‘å¬AWS Spotä¸­æ–­é€šçŸ¥
while true; do
    if curl -s http://169.254.169.254/latest/meta-data/spot/instance-action; then
        echo "Spot instance interruption detected"
        
        # ä¼˜é›…å…³é—­åº”ç”¨
        kubectl drain $(hostname) --ignore-daemonsets --force
        
        # é€šçŸ¥ç›‘æ§ç³»ç»Ÿ
        curl -X POST https://alerts.company.com/webhook \
             -d "node=$(hostname) spot_interruption"
        break
    fi
    sleep 5
done
```

### 9.3 èµ„æºåˆ©ç”¨ç‡ç›‘æ§


**èµ„æºæ•ˆç‡ç›‘æ§æŒ‡æ ‡**ï¼š

```yaml
# Prometheusç›‘æ§è§„åˆ™
groups:
- name: resource-efficiency
  rules:
  # èŠ‚ç‚¹CPUåˆ©ç”¨ç‡
  - alert: NodeCPUUtilizationLow
    expr: (1 - avg(rate(node_cpu_seconds_total{mode="idle"}[5m])) by (instance)) < 0.2
    for: 30m
    labels:
      severity: warning
    annotations:
      summary: "èŠ‚ç‚¹CPUåˆ©ç”¨ç‡è¿‡ä½"
      description: "èŠ‚ç‚¹ {{ $labels.instance }} CPUåˆ©ç”¨ç‡ä½äº20%è¶…è¿‡30åˆ†é’Ÿ"

  # Podèµ„æºè¯·æ±‚vså®é™…ä½¿ç”¨
  - alert: PodResourceWaste  
    expr: |
      (
        container_spec_cpu_quota / container_spec_cpu_period 
        - rate(container_cpu_usage_seconds_total[5m])
      ) / (container_spec_cpu_quota / container_spec_cpu_period) > 0.5
    for: 15m
    annotations:
      summary: "Podèµ„æºé…ç½®è¿‡é«˜"
      description: "Pod {{ $labels.pod }} CPUè¯·æ±‚è¶…è¿‡å®é™…ä½¿ç”¨50%ä»¥ä¸Š"
```

### 9.4 å³è°ƒå¤§å°å»ºè®®ç³»ç»Ÿ


**èµ„æºå»ºè®®é…ç½®**ï¼š

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: rightsizing-recommendations
data:
  config.yaml: |
    # èµ„æºå»ºè®®è§„åˆ™
    cpu_recommendations:
      # CPUä½¿ç”¨ç‡ä½äº30%ï¼Œå»ºè®®å‡å°‘é…ç½®
      underutilized_threshold: 0.3
      underutilized_action: "reduce"
      reduce_factor: 0.7
      
      # CPUä½¿ç”¨ç‡è¶…è¿‡80%ï¼Œå»ºè®®å¢åŠ é…ç½®  
      overutilized_threshold: 0.8
      overutilized_action: "increase"
      increase_factor: 1.3

    memory_recommendations:
      underutilized_threshold: 0.4
      overutilized_threshold: 0.85
```

---

## 10. ğŸš€ å¼¹æ€§ä¼¸ç¼©æœ€ä½³å®è·µ


### 10.1 åº”ç”¨è®¾è®¡æœ€ä½³å®è·µ


**äº‘åŸç”Ÿåº”ç”¨ç‰¹å¾**ï¼š

```
å¼¹æ€§å‹å¥½çš„åº”ç”¨è®¾è®¡ï¼š
âœ… æ— çŠ¶æ€è®¾è®¡ â†’ å¯éšæ„æ‰©ç¼©å®¹
âœ… å¿«é€Ÿå¯åŠ¨ â†’ å‡å°‘æ‰©å®¹ç­‰å¾…æ—¶é—´  
âœ… ä¼˜é›…å…³é—­ â†’ å¤„ç†SIGTERMä¿¡å·
âœ… å¥åº·æ£€æŸ¥ â†’ è‡ªåŠ¨æ•…éšœæ¢å¤
âœ… é…ç½®å¤–éƒ¨åŒ– â†’ é¿å…ç¡¬ç¼–ç 
```

**åº”ç”¨å¯åŠ¨ä¼˜åŒ–**ï¼š

```yaml
spec:
  containers:
  - name: webapp
    image: webapp:v1.2
    # å¿«é€Ÿå¯åŠ¨é…ç½®
    readinessProbe:
      httpGet:
        path: /health
        port: 8080
      initialDelaySeconds: 10    # å¯åŠ¨å10ç§’å¼€å§‹æ£€æŸ¥
      periodSeconds: 5           # æ¯5ç§’æ£€æŸ¥ä¸€æ¬¡
      timeoutSeconds: 3          # 3ç§’è¶…æ—¶
      
    livenessProbe:
      httpGet:
        path: /health  
        port: 8080
      initialDelaySeconds: 60    # å¯åŠ¨å1åˆ†é’Ÿå¼€å§‹æ£€æŸ¥
      periodSeconds: 30          # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡
      
    # ä¼˜é›…å…³é—­é…ç½®  
    lifecycle:
      preStop:
        exec:
          command: ["/bin/sh", "-c", "sleep 10"]  # ç»™è¿æ¥å…³é—­æ—¶é—´
```

### 10.2 ç›‘æ§ä¸å‘Šè­¦é…ç½®


**å…³é”®ç›‘æ§æŒ‡æ ‡**ï¼š

| æŒ‡æ ‡ç±»åˆ« | å…·ä½“æŒ‡æ ‡ | å‘Šè­¦é˜ˆå€¼ | è¯´æ˜ |
|----------|----------|----------|------|
| **æ‰©ç¼©å®¹é¢‘ç‡** | HPAæ‰©ç¼©å®¹æ¬¡æ•°/å°æ—¶ | >10æ¬¡ | é¿å…é¢‘ç¹éœ‡è¡ |
| **Podå¯åŠ¨æ—¶é—´** | å¹³å‡Podå¯åŠ¨è€—æ—¶ | >60ç§’ | å½±å“æ‰©å®¹æ•ˆæœ |
| **èµ„æºåˆ©ç”¨ç‡** | èŠ‚ç‚¹CPU/å†…å­˜åˆ©ç”¨ç‡ | <20% æˆ– >90% | æˆæœ¬ä¸æ€§èƒ½å¹³è¡¡ |
| **æœåŠ¡è´¨é‡** | APIå“åº”æ—¶é—´ | >500ms | æ‰©å®¹æ•ˆæœéªŒè¯ |
| **æˆæœ¬æ•ˆç‡** | å•ä½ä¸šåŠ¡æˆæœ¬ | ç¯æ¯”å¢é•¿>20% | æˆæœ¬æ§åˆ¶ |

### 10.3 æ‰©ç¼©å®¹æµ‹è¯•éªŒè¯


**å‹åŠ›æµ‹è¯•è„šæœ¬**ï¼š

```bash
#!/bin/bash
# è‡ªåŠ¨æ‰©ç¼©å®¹æµ‹è¯•è„šæœ¬

echo "å¼€å§‹æ‰©ç¼©å®¹åŠŸèƒ½æµ‹è¯•..."

# 1. åŸºçº¿æ£€æŸ¥
initial_pods=$(kubectl get pods -l app=webapp --no-headers | wc -l)
echo "åˆå§‹Podæ•°é‡: $initial_pods"

# 2. æ¨¡æ‹Ÿè´Ÿè½½å¢åŠ 
echo "å¯åŠ¨å‹åŠ›æµ‹è¯•..."
kubectl run load-generator --image=busybox --restart=Never -- \
  sh -c 'while true; do wget -q -O- http://webapp-service/api/test; done'

# 3. ç›‘æ§æ‰©å®¹è¿‡ç¨‹
echo "ç›‘æ§æ‰©å®¹è¿‡ç¨‹..."
for i in {1..20}; do
    current_pods=$(kubectl get pods -l app=webapp --no-headers | wc -l)
    cpu_usage=$(kubectl top pods -l app=webapp --no-headers | awk '{sum+=$2} END {print sum}')
    echo "ç¬¬${i}åˆ†é’Ÿ: Podæ•°é‡=$current_pods, CPUä½¿ç”¨=${cpu_usage}m"
    sleep 60
done

# 4. åœæ­¢è´Ÿè½½æµ‹è¯•
kubectl delete pod load-generator

# 5. ç›‘æ§ç¼©å®¹è¿‡ç¨‹
echo "ç›‘æ§ç¼©å®¹è¿‡ç¨‹..."
for i in {1..10}; do
    current_pods=$(kubectl get pods -l app=webapp --no-headers | wc -l)
    echo "ç¼©å®¹ç¬¬${i}åˆ†é’Ÿ: Podæ•°é‡=$current_pods"  
    sleep 60
done

echo "æ‰©ç¼©å®¹æµ‹è¯•å®Œæˆ"
```

### 10.4 æ•…éšœåœºæ™¯å¤„ç†


**å¸¸è§æ•…éšœä¸åº”å¯¹**ï¼š

```yaml
# æ‰©å®¹å¤±è´¥å¤„ç†
apiVersion: v1
kind: Event
reason: FailedCreatePod
message: "nodes are available: 3 Insufficient cpu, 2 node(s) had volume node affinity conflict"

# è§£å†³æ–¹æ¡ˆé…ç½®
spec:
  tolerations:
  # å®¹å¿èµ„æºä¸è¶³çš„æƒ…å†µ
  - key: "node.kubernetes.io/memory-pressure"
    operator: "Exists"
    effect: "NoSchedule"
    tolerationSeconds: 300
  - key: "node.kubernetes.io/disk-pressure"  
    operator: "Exists"
    effect: "NoSchedule"
    tolerationSeconds: 300
```

**åº”æ€¥æ‰©å®¹è„šæœ¬**ï¼š

```bash
#!/bin/bash
# åº”æ€¥æ‰‹åŠ¨æ‰©å®¹è„šæœ¬

NAMESPACE=${1:-default}
DEPLOYMENT=${2:-webapp}
TARGET_REPLICAS=${3:-20}

echo "åº”æ€¥æ‰©å®¹: $DEPLOYMENT åˆ° $TARGET_REPLICAS ä¸ªå‰¯æœ¬"

# ä¸´æ—¶è°ƒæ•´HPAèŒƒå›´
kubectl patch hpa $DEPLOYMENT-hpa -p "{\"spec\":{\"maxReplicas\":$TARGET_REPLICAS}}"

# ç›´æ¥è®¾ç½®å‰¯æœ¬æ•°
kubectl scale deployment/$DEPLOYMENT --replicas=$TARGET_REPLICAS -n $NAMESPACE

# ç›‘æ§æ‰©å®¹çŠ¶æ€
kubectl rollout status deployment/$DEPLOYMENT -n $NAMESPACE

echo "åº”æ€¥æ‰©å®¹å®Œæˆ"
```

---

## 11. ğŸ“‹ æ ¸å¿ƒè¦ç‚¹æ€»ç»“


### 11.1 å¿…é¡»æŒæ¡çš„æ ¸å¿ƒæ¦‚å¿µ


```
ğŸ”¸ ä¸‰ç§æ‰©ç¼©å®¹ç±»å‹ï¼šHPAè°ƒPodæ•°é‡ï¼ŒVPAè°ƒèµ„æºé…ç½®ï¼ŒCAè°ƒèŠ‚ç‚¹æ•°é‡
ğŸ”¸ HPAå·¥ä½œåŸç†ï¼šç›‘æ§æŒ‡æ ‡â†’åˆ¤æ–­é˜ˆå€¼â†’è°ƒæ•´å‰¯æœ¬â†’è´Ÿè½½å‡è¡¡
ğŸ”¸ èŠ‚ç‚¹æ± ç®¡ç†ï¼šæŒ‰ç”¨é€”åˆ†ç±»èŠ‚ç‚¹ï¼Œåˆç†é…ç½®äº²å’Œæ€§ä¸æ±¡ç‚¹
ğŸ”¸ æˆæœ¬ä¼˜åŒ–ï¼šæ··åˆä½¿ç”¨On-Demandã€Reservedã€Spotå®ä¾‹
ğŸ”¸ ç›‘æ§å‘Šè­¦ï¼šå…³æ³¨æ‰©ç¼©å®¹é¢‘ç‡ã€èµ„æºåˆ©ç”¨ç‡ã€æœåŠ¡è´¨é‡
```

### 11.2 å…³é”®ç†è§£è¦ç‚¹


**ğŸ”¹ æ‰©ç¼©å®¹çš„æœ¬è´¨ç›®çš„**
```
æ€§èƒ½ä¿éšœï¼šç¡®ä¿æœåŠ¡å“åº”æ—¶é—´ç¨³å®š
æˆæœ¬æ§åˆ¶ï¼šé¿å…èµ„æºæµªè´¹ï¼ŒæŒ‰éœ€åˆ†é…
è¿ç»´ç®€åŒ–ï¼šå‡å°‘äººå·¥å¹²é¢„ï¼Œè‡ªåŠ¨åŒ–ç®¡ç†
ç”¨æˆ·ä½“éªŒï¼šä¿æŒæœåŠ¡å¯ç”¨æ€§å’Œå“åº”é€Ÿåº¦
```

**ğŸ”¹ é€‰æ‹©åˆé€‚çš„æ‰©ç¼©å®¹ç­–ç•¥**
```
åº”ç”¨ç‰¹å¾åˆ†æï¼š
â€¢ æ— çŠ¶æ€åº”ç”¨ â†’ ä¼˜é€‰HPAæ°´å¹³æ‰©ç¼©å®¹
â€¢ èµ„æºéœ€æ±‚ä¸ç¨³å®š â†’ è€ƒè™‘VPAå‚ç›´æ‰©ç¼©å®¹  
â€¢ é›†ç¾¤è´Ÿè½½å˜åŒ–å¤§ â†’ é…ç½®CAé›†ç¾¤æ‰©ç¼©å®¹
â€¢ æˆæœ¬æ•æ„Ÿåœºæ™¯ â†’ ä½¿ç”¨Spotå®ä¾‹+å¤šèŠ‚ç‚¹æ± 
```

**ğŸ”¹ é¿å…å¸¸è§çš„é…ç½®é™·é˜±**
```
æ‰©ç¼©å®¹éœ‡è¡ï¼šè®¾ç½®åˆç†çš„ç¨³å®šçª—å£æœŸ
èµ„æºç«äº‰ï¼šé¿å…VPAä¸HPAåŒæ—¶ä½œç”¨
èŠ‚ç‚¹èµ„æºä¸è¶³ï¼šé¢„ç•™ç³»ç»Ÿèµ„æºï¼Œé…ç½®QoS
æˆæœ¬å¤±æ§ï¼šè®¾ç½®åˆç†çš„maxReplicasä¸Šé™
```

### 11.3 å®é™…åº”ç”¨ä»·å€¼


**ä¸šåŠ¡åœºæ™¯åº”ç”¨**ï¼š
- **ç”µå•†ä¿ƒé”€**ï¼šæå‰æ‰©å®¹+è‡ªåŠ¨å¼¹æ€§+æˆæœ¬æ§åˆ¶
- **è§†é¢‘ç›´æ’­**ï¼šåŸºäºè§‚çœ‹äººæ•°çš„åŠ¨æ€æ‰©ç¼©å®¹
- **æ‰¹å¤„ç†ä»»åŠ¡**ï¼šä½¿ç”¨Spotå®ä¾‹+VPAä¼˜åŒ–èµ„æº
- **å¾®æœåŠ¡æ¶æ„**ï¼šå¤šç»´åº¦æŒ‡æ ‡+æ™ºèƒ½è°ƒåº¦ç­–ç•¥

**è¿ç»´å®è·µè¦ç‚¹**ï¼š
- **é€æ­¥ä¼˜åŒ–**ï¼šå…ˆè§‚å¯Ÿæ¨¡å¼ï¼Œå†è°ƒæ•´å‚æ•°
- **æµ‹è¯•éªŒè¯**ï¼šå‹åŠ›æµ‹è¯•éªŒè¯æ‰©ç¼©å®¹æ•ˆæœ
- **ç›‘æ§å‘Šè­¦**ï¼šå»ºç«‹å®Œå–„çš„å¯è§‚æµ‹æ€§ä½“ç³»
- **æˆæœ¬ç®¡ç†**ï¼šå®šæœŸè¯„ä¼°èµ„æºåˆ©ç”¨ç‡å’Œæˆæœ¬æ•ˆç‡

### 11.4 è¿›é˜¶å­¦ä¹ æ–¹å‘


**æ‰©å±•æŠ€æœ¯æ ˆ**ï¼š
- **KEDA**ï¼šåŸºäºäº‹ä»¶é©±åŠ¨çš„æ‰©ç¼©å®¹
- **Vertical Pod Autoscaler**ï¼šæ™ºèƒ½èµ„æºæ¨è
- **Cluster Proportional Autoscaler**ï¼šé›†ç¾¤æ¯”ä¾‹æ‰©ç¼©å®¹
- **Custom Resource Definitions**ï¼šè‡ªå®šä¹‰æ‰©ç¼©å®¹èµ„æº

**é«˜çº§å®è·µ**ï¼š
- **å¤šé›†ç¾¤å¼¹æ€§**ï¼šè·¨åŒºåŸŸçš„æµé‡è°ƒåº¦å’Œæ‰©ç¼©å®¹
- **æœºå™¨å­¦ä¹ **ï¼šåŸºäºå†å²æ•°æ®çš„é¢„æµ‹æ€§æ‰©ç¼©å®¹
- **GitOps**ï¼šå£°æ˜å¼çš„æ‰©ç¼©å®¹é…ç½®ç®¡ç†
- **FinOps**ï¼šç»†ç²’åº¦çš„æˆæœ¬åˆ†æå’Œä¼˜åŒ–

**æ ¸å¿ƒè®°å¿†å£è¯€**ï¼š
- æ°´å¹³æ‰©Podæ•°é‡å¤šï¼Œå‚ç›´æ‰©å®¹èµ„æºè¶³
- é›†ç¾¤æ‰©å®¹åŠ èŠ‚ç‚¹ï¼Œä¸‰ç§ç­–ç•¥é…åˆå¥½
- ç›‘æ§æŒ‡æ ‡è¦ç²¾å‡†ï¼Œæˆæœ¬ä¼˜åŒ–ä¸èƒ½æ¾
- æµ‹è¯•éªŒè¯ä¿è´¨é‡ï¼Œè¿ç»´è‡ªåŠ¨åŒ–ç¨‹åº¦é«˜