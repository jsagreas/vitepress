---
title: 14、故障排查与性能优化
---
## 📚 目录

1. [kubectl命令行调试技巧](#1-kubectl命令行调试技巧)
2. [Pod状态异常诊断方法](#2-pod状态异常诊断方法)
3. [网络连通性问题排查](#3-网络连通性问题排查)
4. [存储挂载失败处理](#4-存储挂载失败处理)
5. [资源不足问题分析](#5-资源不足问题分析)
6. [日志查看与事件追踪](#6-日志查看与事件追踪)
7. [性能瓶颈识别与优化](#7-性能瓶颈识别与优化)
8. [集群健康检查流程](#8-集群健康检查流程)
9. [常见故障处理预案](#9-常见故障处理预案)
10. [核心要点总结](#10-核心要点总结)

---

## 1. 🔍 kubectl命令行调试技巧


### 1.1 kubectl调试基本概念


**为什么kubectl是故障排查的核心工具？**
> kubectl就像医生的"听诊器"，通过它可以"听到"集群内部的各种声音，了解每个组件的健康状况。

```
kubectl的调试思维模式：
观察现象 → 收集信息 → 分析原因 → 定位问题 → 验证修复

就像侦探破案：
🔍 现场勘察（查看资源状态）
🔍 收集证据（获取日志和事件）
🔍 分析线索（理解错误信息）
🔍 找到真凶（定位根本原因）
```

### 1.2 核心调试命令详解


#### 🔸 查看资源状态

**基础状态查看：**
```bash
# 查看所有Pod状态
kubectl get pods -o wide

# 查看特定命名空间的资源
kubectl get all -n production

# 查看资源详细信息
kubectl describe pod nginx-pod
kubectl describe service nginx-svc
```

**高级状态查看：**
```bash
# 使用标签筛选
kubectl get pods -l app=nginx --show-labels

# 按节点查看Pod分布
kubectl get pods -o wide --sort-by=".spec.nodeName"

# 查看资源使用情况
kubectl top pods
kubectl top nodes
```

#### 🔸 详细信息获取

**describe命令是故障排查的利器：**
```bash
kubectl describe pod problem-pod
```

**describe输出解读：**
```yaml
Name:         nginx-pod
Namespace:    default
Status:       Pending    # ← 关键状态信息
Events:       # ← 最重要的故障线索
  Warning  FailedScheduling  pod has unbound immediate PersistentVolumeClaims
```

> **💡 调试技巧：** Events部分通常包含最直接的错误原因，是故障排查的第一优先级。

#### 🔸 实时监控命令

```bash
# 实时观察资源变化
kubectl get pods -w
kubectl get events -w

# 持续查看日志
kubectl logs -f pod-name

# 多容器Pod日志
kubectl logs pod-name -c container-name
```

### 1.3 kubectl高级调试技巧


#### 🔸 JSON路径查询

**什么是JSONPath？**
> JSONPath就像"GPS导航"，帮你在复杂的Kubernetes资源数据中快速找到需要的信息。

```bash
# 查看Pod的重启次数
kubectl get pods -o jsonpath='{.items[*].status.containerStatuses[*].restartCount}'

# 查看节点的可分配资源
kubectl get nodes -o jsonpath='{.items[*].status.allocatable.cpu}'

# 自定义输出格式
kubectl get pods -o custom-columns=NAME:.metadata.name,STATUS:.status.phase,NODE:.spec.nodeName
```

#### 🔸 调试模式运行

```bash
# 以调试模式创建临时Pod
kubectl run debug-pod --image=busybox --rm -it --restart=Never -- /bin/sh

# 在特定节点上创建调试Pod
kubectl run debug-pod --image=busybox --overrides='{"spec":{"nodeSelector":{"kubernetes.io/hostname":"node1"}}}' --rm -it
```

#### 🔸 网络调试工具

```bash
# 创建网络调试工具Pod
kubectl apply -f - <<EOF
apiVersion: v1
kind: Pod
metadata:
  name: netshoot
spec:
  containers:
  - name: netshoot
    image: nicolaka/netshoot
    command: ["/bin/bash"]
    args: ["-c", "while true; do ping localhost; sleep 60;done"]
EOF

# 进入调试Pod进行网络测试
kubectl exec -it netshoot -- /bin/bash
```

### 1.4 kubectl配置优化


#### 🔸 别名和快捷方式

**提高调试效率的配置：**
```bash
# ~/.bashrc 或 ~/.zshrc
alias k='kubectl'
alias kgp='kubectl get pods'
alias kgs='kubectl get svc'
alias kd='kubectl describe'
alias kl='kubectl logs'

# 设置默认命名空间
kubectl config set-context --current --namespace=production
```

#### 🔸 输出格式定制

```bash
# 设置默认输出格式
export KUBE_EDITOR="vim"
export KUBECTL_EXTERNAL_DIFF="colordiff -N -u"

# 使用不同的输出格式
kubectl get pods -o yaml    # YAML格式
kubectl get pods -o json    # JSON格式  
kubectl get pods -o wide    # 扩展表格格式
```

---

## 2. 🚨 Pod状态异常诊断方法


### 2.1 Pod生命周期理解


**Pod状态转换图：**
```
Pod创建流程：
Pending → ContainerCreating → Running → (Terminating) → Succeeded/Failed

各状态含义：
Pending:        Pod已创建，但容器未启动
ContainerCreating: 正在拉取镜像或创建容器
Running:        Pod正常运行中
Succeeded:      Pod成功完成任务
Failed:         Pod执行失败
Unknown:        无法获取Pod状态
```

### 2.2 常见异常状态诊断


#### 🔸 Pending状态问题

**Pending状态表示Pod"排队等待"，通常原因如下：**

| 问题类型 | **表现** | **解决方法** |
|---------|---------|------------|
| 🔸 **资源不足** | `Insufficient cpu/memory` | `增加节点资源或降低Pod资源请求` |
| 🔸 **调度约束** | `No nodes available` | `检查nodeSelector、污点容忍` |
| 🔸 **存储问题** | `unbound PersistentVolumeClaims` | `检查PV/PVC配置` |
| 🔸 **镜像拉取** | `ImagePullBackOff` | `检查镜像名称和仓库访问` |

**诊断步骤：**
```bash
# 第1步：查看Pod事件
kubectl describe pod pending-pod

# 第2步：检查节点资源
kubectl describe nodes

# 第3步：检查调度器日志
kubectl logs -n kube-system -l component=kube-scheduler
```

#### 🔸 CrashLoopBackOff状态

**什么是CrashLoopBackOff？**
> 就像"自动重启的故障设备"，容器启动后立即崩溃，Kubernetes不断尝试重启，但每次都失败。

**诊断方法：**
```bash
# 查看容器退出原因
kubectl describe pod crash-pod

# 查看应用日志
kubectl logs crash-pod --previous  # 查看上次崩溃的日志

# 检查启动命令
kubectl get pod crash-pod -o yaml | grep -A 5 command
```

**常见原因和解决方案：**
```
应用启动失败：
原因：配置错误、依赖缺失
解决：检查应用配置和环境变量

健康检查失败：
原因：livenessProbe配置过于严格
解决：调整健康检查参数或禁用

资源限制：
原因：内存不足被OOMKilled
解决：增加memory limit或优化应用
```

#### 🔸 ImagePullBackOff状态

**镜像拉取失败的排查思路：**

**第1步：验证镜像名称**
```bash
# 检查镜像配置
kubectl get pod image-pull-pod -o yaml | grep image

# 手动拉取镜像测试
docker pull nginx:1.20-alpine
```

**第2步：检查仓库访问**
```bash
# 查看镜像拉取事件
kubectl describe pod image-pull-pod

# 检查Secret配置
kubectl get secrets
kubectl describe secret regcred
```

**第3步：网络连通性测试**
```bash
# 在节点上测试仓库连通性
curl -I https://registry.hub.docker.com/v2/
```

### 2.3 Pod健康检查配置


#### 🔸 健康检查类型理解

**三种健康检查的区别：**

```yaml
livenessProbe:    # "还活着吗？" - 决定是否重启容器
  httpGet:
    path: /health
    port: 8080
  initialDelaySeconds: 10
  periodSeconds: 5

readinessProbe:   # "准备好了吗？" - 决定是否接收流量  
  httpGet:
    path: /ready
    port: 8080
  initialDelaySeconds: 5
  periodSeconds: 3

startupProbe:     # "启动完成了吗？" - 给慢启动应用更多时间
  httpGet:
    path: /startup
    port: 8080
  failureThreshold: 30
  periodSeconds: 10
```

#### 🔸 健康检查调优

**避免健康检查引起的问题：**

```
⚠️ 常见配置错误：
• initialDelaySeconds设置过短
• periodSeconds检查过于频繁
• failureThreshold设置过低
• 探针端点响应慢

✅ 最佳实践配置：
• 根据应用启动时间设置延迟
• 探针端点要快速响应（<1秒）
• 失败阈值至少为3次
• 区分不同探针的检查内容
```

---

## 3. 🌐 网络连通性问题排查


### 3.1 Kubernetes网络模型理解


**Kubernetes网络的"四层结构"：**
```
应用层访问链路：
客户端 → Service → Endpoint → Pod IP → 容器端口

网络组件关系：
┌─────────────┐    ┌──────────────┐    ┌─────────────┐
│   Service   │───▶│   Endpoint   │───▶│    Pod      │
│ (ClusterIP) │    │(Pod IP:Port) │    │ (Container) │
└─────────────┘    └──────────────┘    └─────────────┘
       ▲                   ▲                   ▲
   kube-proxy          kube-proxy          CNI插件
```

### 3.2 Service网络问题排查


#### 🔸 Service基础排查

**Service不通的常见原因：**

**第1步：检查Service配置**
```bash
# 查看Service详细信息
kubectl describe svc problem-service

# 检查Endpoint是否正确
kubectl get endpoints problem-service
```

**第2步：验证标签匹配**
```bash
# 查看Service标签选择器
kubectl get svc problem-service -o yaml | grep -A 3 selector

# 查看Pod标签
kubectl get pods --show-labels | grep app=problem-app
```

**第3步：端口映射确认**
```bash
# 检查端口配置
kubectl get svc problem-service -o yaml | grep -A 10 ports
```

#### 🔸 网络连通性测试

**系统性的网络测试方法：**

```bash
# 在调试Pod内测试连通性
kubectl exec -it netshoot -- /bin/bash

# 1. 测试Pod IP直连
ping 10.244.1.10

# 2. 测试Service ClusterIP
curl http://10.96.0.100:80

# 3. 测试Service DNS名称
nslookup problem-service.default.svc.cluster.local
curl http://problem-service.default.svc.cluster.local
```

**DNS解析问题排查：**
```bash
# 检查DNS配置
kubectl get svc -n kube-system | grep dns

# 测试DNS解析
kubectl exec -it test-pod -- nslookup kubernetes.default

# 查看DNS解析日志
kubectl logs -n kube-system -l k8s-app=kube-dns
```

### 3.3 跨节点网络问题


#### 🔸 CNI网络插件排查

**常见CNI插件问题：**

| 问题类型 | **症状** | **排查方法** |
|---------|---------|------------|
| 🔸 **IP分配冲突** | `Pod无法获取IP` | `检查IPAM配置和IP池` |
| 🔸 **路由表错误** | `跨节点Pod不通` | `检查节点路由表` |
| 🔸 **防火墙规则** | `端口不通` | `检查iptables规则` |
| 🔸 **网卡配置** | `网络接口异常` | `检查CNI网卡状态` |

**网络插件日志查看：**
```bash
# Flannel网络插件
kubectl logs -n kube-system -l app=flannel

# Calico网络插件  
kubectl logs -n kube-system -l k8s-app=calico-node

# 查看CNI配置
cat /etc/cni/net.d/*
```

#### 🔸 网络策略问题

**NetworkPolicy导致的访问问题：**
```bash
# 查看当前网络策略
kubectl get networkpolicy

# 检查策略规则详情
kubectl describe networkpolicy deny-all

# 测试网络策略效果
kubectl exec -it source-pod -- curl target-service
```

### 3.4 Ingress网络问题


#### 🔸 Ingress Controller排查

```bash
# 查看Ingress Controller状态
kubectl get pods -n ingress-nginx

# 查看Ingress规则
kubectl describe ingress web-ingress

# 检查域名解析
nslookup example.com
curl -H "Host: example.com" http://nginx-controller-ip
```

#### 🔸 LoadBalancer服务问题

```bash
# 查看LoadBalancer状态
kubectl get svc -o wide | grep LoadBalancer

# 检查云服务商负载均衡器
kubectl describe svc loadbalancer-service

# 测试外部访问
curl http://external-ip:port
```

---

## 4. 💾 存储挂载失败处理


### 4.1 Kubernetes存储架构理解


**存储组件关系图：**
```
存储访问链路：
Pod → PVC (请求) → PV (实际存储) → StorageClass (动态分配)

存储绑定过程：
┌─────────┐    ┌─────────┐    ┌──────────────┐
│   Pod   │───▶│   PVC   │───▶│      PV      │
│(Volume) │    │(Claim)  │    │(Physical Vol)│
└─────────┘    └─────────┘    └──────────────┘
     ▲              ▲               ▲
   kubelet    volume-controller   CSI Driver
```

### 4.2 PVC挂载失败诊断


#### 🔸 常见挂载失败原因


**第1类：PVC无法绑定PV**
```bash
# 查看PVC状态
kubectl get pvc

# PVC状态为Pending的原因分析
kubectl describe pvc problem-pvc
```

**常见错误和解决方案：**
```
no persistent volumes available:
原因：没有合适的PV可用
解决：创建PV或配置StorageClass

volume size mismatch:
原因：PVC请求的容量大于可用PV
解决：调整PVC容量或创建更大的PV

access mode mismatch:
原因：访问模式不匹配
解决：检查PV和PVC的accessModes配置
```

#### 🔸 动态存储问题

**StorageClass相关问题：**
```bash
# 查看可用的StorageClass
kubectl get storageclass

# 检查默认StorageClass
kubectl get storageclass -o yaml | grep "is-default-class"

# 查看CSI驱动状态
kubectl get csidriver
```

**动态分配失败排查：**
```bash
# 查看存储控制器日志
kubectl logs -n kube-system -l app=csi-provisioner

# 检查存储事件
kubectl get events | grep -i volume
```

### 4.3 存储性能问题


#### 🔸 存储I/O问题诊断

**存储性能测试方法：**
```bash
# 在Pod内测试磁盘性能
kubectl exec -it test-pod -- dd if=/dev/zero of=/data/test bs=1M count=100

# 查看存储使用情况
kubectl exec -it test-pod -- df -h

# 监控存储I/O
kubectl top pods --containers
```

#### 🔸 存储配额问题

```bash
# 查看资源配额
kubectl get resourcequota

# 检查存储使用量
kubectl describe resourcequota storage-quota

# 查看PVC使用情况
kubectl get pvc -o custom-columns=NAME:.metadata.name,SIZE:.spec.resources.requests.storage,USED:.status.capacity.storage
```

### 4.4 不同存储类型问题


#### 🔸 本地存储问题

```yaml
# Local PV配置检查要点
apiVersion: v1
kind: PersistentVolume
metadata:
  name: local-pv
spec:
  capacity:
    storage: 10Gi
  accessModes:
  - ReadWriteOnce
  persistentVolumeReclaimPolicy: Delete
  local:
    path: /mnt/disks/vol1    # 路径必须存在
  nodeAffinity:              # 必须指定节点
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - node1
```

**本地存储常见问题：**
- 路径不存在或权限不足
- 节点亲和性配置错误
- 磁盘空间不足

#### 🔸 网络存储问题

```bash
# NFS存储问题排查
showmount -e nfs-server-ip
mount -t nfs nfs-server-ip:/path /mnt/test

# 检查网络连通性
telnet nfs-server-ip 2049

# 查看mount错误
kubectl describe pod nfs-pod | grep -A 10 Events
```

---

## 5. 📊 资源不足问题分析


### 5.1 资源管理基本概念


**Kubernetes资源配额的"三层管理"：**
```
集群级别：Node总资源
命名空间级别：ResourceQuota限制  
Pod级别：requests和limits设置

资源分配优先级：
requests (预留) → limits (上限) → 节点总量

就像酒店订房：
requests = 已预订的房间（保证有）
limits = 房间最大容纳人数（不能超过）
节点总量= 酒店总房间数
```

### 5.2 CPU资源问题分析


#### 🔸 CPU资源不足诊断

**CPU问题的表现形式：**
- Pod调度失败（Insufficient cpu）
- 应用响应缓慢
- CPU限流（throttling）

**诊断步骤：**
```bash
# 第1步：查看节点CPU使用率
kubectl top nodes

# 第2步：查看Pod CPU使用
kubectl top pods --all-namespaces

# 第3步：检查CPU请求和限制
kubectl describe pod cpu-hungry-pod | grep -A 5 Requests
```

#### 🔸 CPU限流问题

**什么是CPU限流？**
> CPU限流就像"限速行驶"，当Pod使用CPU超过limits时，系统会强制降低其CPU使用率。

```bash
# 查看CPU限流统计
kubectl exec -it pod-name -- cat /sys/fs/cgroup/cpu/cpu.stat

# 监控CPU限流事件
kubectl get events | grep -i throttl
```

**CPU配置优化建议：**
```yaml
resources:
  requests:
    cpu: 100m      # 预留CPU，影响调度
  limits:
    cpu: 500m      # CPU上限，防止无限制使用

# CPU配置经验值：
# Web应用：requests=100m, limits=500m  
# 数据库：requests=500m, limits=2000m
# 批处理：可以不设limits，允许突发使用
```

### 5.3 内存资源问题分析


#### 🔸 内存不足的表现

**内存问题比CPU更严重：**
- OOMKilled（内存溢出被杀）
- 节点内存压力驱逐
- 应用性能急剧下降

```bash
# 查看内存使用情况
kubectl top nodes
kubectl top pods --sort-by=memory

# 检查OOM事件
kubectl get events | grep -i oom
kubectl describe pod oom-pod | grep -i oom
```

#### 🔸 内存泄漏检测

**内存使用趋势监控：**
```bash
# 持续监控内存使用
watch -n 5 'kubectl top pod memory-leak-pod'

# 查看容器内存详细信息
kubectl exec -it pod-name -- cat /proc/meminfo
kubectl exec -it pod-name -- free -h
```

**内存配置最佳实践：**
```yaml
resources:
  requests:
    memory: 256Mi    # 预留内存
  limits:
    memory: 512Mi    # 内存上限，超过会被OOM Kill

# 内存配置注意事项：
# requests ≈ 应用正常运行所需内存
# limits = requests × 1.5~2 (给突发使用留余量)
# Java应用需要考虑JVM堆内存设置
```

### 5.4 存储资源问题


#### 🔸 磁盘空间不足

```bash
# 查看节点磁盘使用
kubectl describe nodes | grep -A 5 "Allocated resources"

# 检查Pod存储使用
kubectl exec -it pod-name -- df -h

# 查看PV使用情况
kubectl get pv -o custom-columns=NAME:.metadata.name,SIZE:.spec.capacity.storage,STATUS:.status.phase
```

#### 🔸 存储I/O限制

**存储性能问题排查：**
```bash
# 监控磁盘I/O
kubectl exec -it pod-name -- iostat -x 1

# 查看存储延迟
kubectl exec -it pod-name -- dd if=/dev/zero of=/tmp/test bs=1M count=100 conv=fdatasync
```

### 5.5 资源配额管理


#### 🔸 ResourceQuota配置

```yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: compute-quota
  namespace: production
spec:
  hard:
    requests.cpu: "10"
    requests.memory: 20Gi
    limits.cpu: "20" 
    limits.memory: 40Gi
    persistentvolumeclaims: "4"
```

**配额监控和调整：**
```bash
# 查看配额使用情况
kubectl describe resourcequota -n production

# 配额使用趋势分析
kubectl get resourcequota -n production -o yaml | grep -A 10 status
```

---

## 6. 📋 日志查看与事件追踪


### 6.1 日志系统架构理解


**Kubernetes日志的"三个层次"：**
```
应用日志层：应用程序输出的日志
容器日志层：容器运行时收集的日志  
系统日志层：K8s组件和节点系统日志

日志流转过程：
应用stdout/stderr → 容器日志 → 节点日志文件 → 日志收集系统
```

### 6.2 Pod日志查看技巧


#### 🔸 基础日志查看

```bash
# 查看Pod日志
kubectl logs pod-name

# 多容器Pod指定容器
kubectl logs pod-name -c container-name

# 实时跟踪日志
kubectl logs -f pod-name

# 查看最近的日志
kubectl logs pod-name --tail=100
```

#### 🔸 高级日志查看

```bash
# 查看前一次容器的日志（容器重启后）
kubectl logs pod-name --previous

# 指定时间范围的日志
kubectl logs pod-name --since=1h
kubectl logs pod-name --since-time=2023-09-14T10:00:00Z

# 多个Pod的日志聚合查看
kubectl logs -l app=nginx -f --prefix=true
```

#### 🔸 日志过滤和分析

**使用管道命令进行日志分析：**
```bash
# 过滤错误日志
kubectl logs app-pod | grep -i error

# 统计错误数量
kubectl logs app-pod | grep -c "ERROR"

# 查看访问频率
kubectl logs web-pod | grep "GET /" | wc -l

# 实时监控关键词
kubectl logs -f app-pod | grep --line-buffered "WARN\|ERROR"
```

### 6.3 事件追踪系统


#### 🔸 Kubernetes事件理解

**什么是Kubernetes事件？**
> 事件就像系统的"日记本"，记录了集群内发生的重要变化，比如Pod创建、调度、启动失败等。

```bash
# 查看所有事件
kubectl get events

# 按时间排序查看事件
kubectl get events --sort-by='.lastTimestamp'

# 查看特定资源的事件
kubectl get events --field-selector involvedObject.name=pod-name

# 实时监控事件
kubectl get events -w
```

#### 🔸 事件过滤和分析

**根据事件类型过滤：**
```bash
# 查看警告事件
kubectl get events --field-selector type=Warning

# 查看特定原因的事件
kubectl get events --field-selector reason=Failed

# 查看特定命名空间的事件
kubectl get events -n production

# 组合过滤条件
kubectl get events --field-selector type=Warning,reason=FailedScheduling
```

**事件信息解读：**
```bash
# 事件详细信息格式
LAST SEEN   TYPE      REASON           OBJECT      MESSAGE
2m          Warning   FailedScheduling  pod/nginx   0/3 nodes are available

解读要点：
TYPE: Normal/Warning - 事件严重程度
REASON: 事件原因分类
OBJECT: 涉及的K8s对象  
MESSAGE: 详细描述信息
```

### 6.4 系统组件日志


#### 🔸 Control Plane组件日志

```bash
# API Server日志
kubectl logs -n kube-system kube-apiserver-master

# Scheduler日志
kubectl logs -n kube-system kube-scheduler-master

# Controller Manager日志  
kubectl logs -n kube-system kube-controller-manager-master

# etcd日志
kubectl logs -n kube-system etcd-master
```

#### 🔸 Node组件日志

```bash
# kubelet日志（在节点上查看）
journalctl -u kubelet -f

# kube-proxy日志
kubectl logs -n kube-system -l k8s-app=kube-proxy

# 容器运行时日志
journalctl -u docker -f
# 或
journalctl -u containerd -f
```

### 6.5 日志聚合和分析


#### 🔸 集中日志收集

**常见日志收集架构：**
```
ELK Stack架构：
Filebeat → Logstash → Elasticsearch → Kibana

EFK Stack架构：  
Fluentd → Elasticsearch → Kibana

Prometheus + Grafana:
应用 → Prometheus → Grafana仪表板
```

#### 🔸 日志告警配置

**基于日志的告警规则示例：**
```yaml
# 错误日志告警
groups:
- name: application.rules
  rules:
  - alert: HighErrorRate
    expr: rate(log_entries{level="error"}[5m]) > 0.1
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "High error rate detected"
```

---

## 7. ⚡ 性能瓶颈识别与优化


### 7.1 性能监控体系架构


**Kubernetes性能监控的"四个维度"：**
```
资源维度：CPU、内存、网络、存储
应用维度：请求延迟、吞吐量、错误率
集群维度：节点状态、Pod分布、调度效率
用户维度：页面响应时间、业务成功率

监控数据流：
应用指标 → Metrics Server → Prometheus → Grafana
系统指标 → Node Exporter → Prometheus → 告警规则
```

### 7.2 资源性能瓶颈识别


#### 🔸 CPU性能分析

**CPU瓶颈的识别方法：**
```bash
# 查看集群CPU使用率
kubectl top nodes
kubectl top pods --all-namespaces --sort-by=cpu

# 深入分析高CPU使用的Pod
kubectl exec -it high-cpu-pod -- top
kubectl exec -it high-cpu-pod -- ps aux --sort=-%cpu
```

**CPU使用模式分析：**
```
CPU使用率 > 80%：可能存在CPU瓶颈
CPU使用率波动大：可能有突发负载
CPU请求率低但使用率高：资源配置需优化
多核CPU单核使用率高：应用可能不支持多线程
```

#### 🔸 内存性能分析

```bash
# 内存使用详细分析
kubectl exec -it memory-test-pod -- cat /proc/meminfo
kubectl exec -it memory-test-pod -- free -h

# 查看内存使用趋势
watch -n 5 'kubectl top pod memory-intensive-app'

# JVM应用内存分析
kubectl exec -it java-app -- jstat -gc 1 5s
```

**内存性能指标解读：**
```
RSS (Resident Set Size)：实际物理内存使用
VSZ (Virtual Size)：虚拟内存使用  
Cache：文件系统缓存
Buffer：磁盘I/O缓存

内存压力信号：
• 可用内存 < 20%
• Swap使用率上升  
• 频繁的OOM事件
```

#### 🔸 网络性能分析

```bash
# 网络吞吐量测试
kubectl exec -it netshoot -- iperf3 -s
kubectl exec -it client-pod -- iperf3 -c server-ip

# 网络延迟测试
kubectl exec -it test-pod -- ping -c 10 target-ip
kubectl exec -it test-pod -- curl -w "@curl-format.txt" http://service-url

# 网络连接统计
kubectl exec -it app-pod -- netstat -an | grep ESTABLISHED | wc -l
```

### 7.3 应用性能优化


#### 🔸 容器资源配置优化

**资源配置的"黄金比例"：**

| 应用类型 | **CPU配置** | **内存配置** | **说明** |
|---------|------------|-------------|----------|
| **Web应用** | `requests=100m, limits=500m` | `requests=256Mi, limits=512Mi` | `响应式负载，突发CPU需求` |
| **数据库** | `requests=500m, limits=2000m` | `requests=1Gi, limits=2Gi` | `稳定负载，需要足够资源` |
| **缓存服务** | `requests=200m, limits=1000m` | `requests=512Mi, limits=1Gi` | `内存密集型应用` |
| **批处理** | `无limits` | `requests=1Gi, limits=4Gi` | `可以充分利用节点资源` |

#### 🔸 Pod调度优化

```yaml
# 节点亲和性配置
apiVersion: v1
kind: Pod
spec:
  affinity:
    nodeAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        preference:
          matchExpressions:
          - key: node-type
            operator: In
            values:
            - high-performance
    podAntiAffinity:    # 避免Pod集中在同一节点
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: app
            operator: In
            values:
            - web
        topologyKey: kubernetes.io/hostname
```

#### 🔸 水平扩展优化

**HPA（水平Pod自动扩展）配置：**
```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: web-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: web-app
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70    # CPU使用率70%时扩容
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80    # 内存使用率80%时扩容
```

### 7.4 网络性能优化


#### 🔸 Service性能优化

```yaml
# 选择合适的Service类型
apiVersion: v1
kind: Service
metadata:
  name: high-perf-svc
spec:
  type: ClusterIP
  sessionAffinity: ClientIP    # 会话保持
  ports:
  - port: 80
    targetPort: 8080
    protocol: TCP
  selector:
    app: web
```

**Service性能考虑因素：**
```
ClusterIP：集群内部访问，性能最好
NodePort：通过节点端口访问，额外的网络跳转  
LoadBalancer：外部访问，依赖云服务商实现
Ingress：七层负载均衡，功能丰富但开销较大
```

#### 🔸 网络策略优化

```bash
# 避免过于复杂的网络策略
kubectl get networkpolicy
kubectl describe networkpolicy complex-policy

# 优化DNS查询
# 在Pod中配置DNS缓存
```

### 7.5 存储性能优化


#### 🔸 存储类选择

**不同存储类型的性能特点：**

| 存储类型 | **IOPS** | **延迟** | **适用场景** |
|---------|---------|---------|-------------|
| **本地SSD** | `>10,000` | `<1ms` | `数据库、高性能应用` |
| **云盘SSD** | `3,000-5,000` | `1-3ms` | `一般应用` |
| **网络存储** | `1,000-3,000` | `3-10ms` | `文件共享、备份` |
| **对象存储** | `100-500` | `10-50ms` | `静态文件、归档` |

#### 🔸 存储配置优化

```yaml
# 高性能存储配置
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: high-iops-ssd
provisioner: kubernetes.io/aws-ebs
parameters:
  type: io1
  iopsPerGB: "50"    # 高IOPS配置
  fsType: ext4
volumeBindingMode: WaitForFirstConsumer    # 延迟绑定优化
```

---

## 8. 🏥 集群健康检查流程


### 8.1 集群健康检查体系


**集群健康检查的"五个层次"：**
```
基础设施层：节点硬件、网络、存储
容器运行时层：Docker/containerd状态
Kubernetes组件层：API Server、etcd、scheduler等
应用服务层：业务Pod、Service状态  
监控告警层：指标收集、异常检测

健康检查金字塔：
       ┌─────────────┐
       │  监控告警层   │
       ├─────────────┤
       │  应用服务层   │
       ├─────────────┤
       │ K8s组件层   │
       ├─────────────┤
       │ 容器运行时层  │
       ├─────────────┤
       │ 基础设施层   │
       └─────────────┘
```

### 8.2 节点健康检查


#### 🔸 节点状态诊断

```bash
# 查看节点整体状态
kubectl get nodes -o wide

# 节点详细信息检查
kubectl describe node worker-node-1

# 检查节点资源使用
kubectl top nodes

# 节点标签和污点检查
kubectl get nodes --show-labels
kubectl describe node node-1 | grep Taints
```

**节点状态解读：**
```
Ready：节点正常，可以接收Pod调度
NotReady：节点异常，不会调度新Pod
SchedulingDisabled：节点被手动禁用调度  
Unknown：节点状态未知，通常是网络问题

常见节点问题：
• 磁盘空间不足
• 内存压力过大  
• Docker/containerd异常
• kubelet服务故障
```

#### 🔸 节点组件健康检查

```bash
# kubelet服务状态（在节点上执行）
systemctl status kubelet
journalctl -u kubelet --no-pager

# 容器运行时状态
systemctl status docker
docker system info

# 网络组件状态
kubectl get pods -n kube-system | grep -E "(flannel|calico|weave)"
```

### 8.3 控制平面健康检查


#### 🔸 API Server健康检查

```bash
# API Server可用性测试
kubectl get --raw='/readyz'
kubectl get --raw='/livez'
kubectl get --raw='/healthz'

# API Server详细状态
kubectl get componentstatus
kubectl get pods -n kube-system | grep apiserver
```

#### 🔸 etcd健康检查

```bash
# etcd集群状态
kubectl exec -n kube-system etcd-master -- etcdctl --endpoints=127.0.0.1:2379 endpoint health

# etcd数据完整性检查
kubectl exec -n kube-system etcd-master -- etcdctl --endpoints=127.0.0.1:2379 endpoint status --write-out=table
```

#### 🔸 调度器和控制器健康检查

```bash
# 调度器状态
kubectl get pods -n kube-system | grep scheduler
kubectl logs -n kube-system kube-scheduler-master

# 控制器管理器状态
kubectl get pods -n kube-system | grep controller-manager
kubectl logs -n kube-system kube-controller-manager-master
```

### 8.4 应用层健康检查


#### 🔸 Service可用性检查

```bash
# Service端点检查
kubectl get endpoints

# DNS解析测试
kubectl exec -it test-pod -- nslookup kubernetes.default

# 服务连通性测试
kubectl exec -it test-pod -- curl -I http://service-name
```

#### 🔸 负载均衡检查

```bash
# Ingress Controller状态
kubectl get pods -n ingress-nginx
kubectl get ingress

# LoadBalancer服务检查
kubectl get svc -o wide | grep LoadBalancer
```

### 8.5 自动化健康检查


#### 🔸 健康检查脚本

```bash
#!/bin/bash
# cluster-health-check.sh

echo "=== Cluster Health Check ==="

# 1. 节点检查
echo "1. Node Status:"
kubectl get nodes

# 2. 系统Pod检查  
echo "2. System Pods:"
kubectl get pods -n kube-system

# 3. 资源使用检查
echo "3. Resource Usage:"
kubectl top nodes

# 4. 存储检查
echo "4. Storage Status:"
kubectl get pv,pvc

# 5. 网络检查
echo "5. Network Status:"
kubectl get svc
kubectl get ingress

echo "=== Health Check Complete ==="
```

#### 🔸 监控指标配置

**Prometheus监控规则示例：**
```yaml
groups:
- name: kubernetes.rules
  rules:
  - alert: NodeNotReady
    expr: kube_node_status_condition{condition="Ready",status="true"} == 0
    for: 2m
    labels:
      severity: critical
    annotations:
      summary: "Node {{ $labels.node }} is not ready"
      
  - alert: PodCrashLooping  
    expr: rate(kube_pod_container_status_restarts_total[15m]) > 0
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Pod {{ $labels.pod }} is crash looping"
```

---

## 9. 🚨 常见故障处理预案


### 9.1 故障分类与处理流程


**Kubernetes故障的"四个层级"：**
```
P0级故障：集群完全不可用
P1级故障：核心功能受影响
P2级故障：部分服务异常  
P3级故障：性能下降或警告

故障处理流程：
发现故障 → 快速评估 → 应急处理 → 根因分析 → 预防改进
```

### 9.2 集群级别故障预案


#### 🔸 API Server不可用

**故障现象：** kubectl命令无响应，Pod无法调度

**应急处理步骤：**
```bash
# 1. 检查API Server进程
ps aux | grep kube-apiserver

# 2. 重启API Server
systemctl restart kube-apiserver
# 或 kubectl delete pod -n kube-system kube-apiserver-master

# 3. 检查证书有效性
openssl x509 -in /etc/kubernetes/pki/apiserver.crt -text -noout | grep -A 2 Validity

# 4. 验证恢复
kubectl get nodes
```

#### 🔸 etcd集群故障

**故障现象：** 数据读写失败，集群状态异常

```bash
# 紧急恢复步骤
# 1. 检查etcd集群状态
etcdctl --endpoints=127.0.0.1:2379 member list

# 2. 从备份恢复（最后手段）
etcdctl snapshot restore backup.db --data-dir=/var/lib/etcd-restore

# 3. 重启etcd服务
systemctl restart etcd
```

#### 🔸 网络插件故障

**故障现象：** Pod间无法通信，DNS解析失败

```bash
# 网络修复步骤
# 1. 重启网络插件
kubectl delete pods -n kube-system -l k8s-app=flannel
kubectl delete pods -n kube-system -l k8s-app=calico-node

# 2. 检查网络配置
cat /etc/cni/net.d/*

# 3. 验证网络恢复
kubectl exec -it test-pod -- ping 8.8.8.8
```

### 9.3 节点级别故障预案


#### 🔸 节点NotReady故障

**故障现象：** 节点状态显示NotReady，Pod无法调度

**处理步骤：**
```bash
# 1. 检查kubelet状态
systemctl status kubelet
journalctl -u kubelet --no-pager -l

# 2. 检查容器运行时
systemctl status docker
docker system info

# 3. 清理节点资源（谨慎操作）
kubectl drain node-name --ignore-daemonsets --delete-emptydir-data
kubectl uncordon node-name
```

#### 🔸 磁盘空间不足

**故障现象：** 节点磁盘使用率>85%，Pod创建失败

```bash
# 清理步骤
# 1. 清理Docker镜像
docker system prune -a -f

# 2. 清理日志文件
find /var/log -name "*.log" -size +100M -delete

# 3. 清理临时文件
kubectl exec -it pod-name -- find /tmp -type f -atime +7 -delete
```

### 9.4 应用级别故障预案


#### 🔸 Pod反复重启

**故障现象：** CrashLoopBackOff状态

**诊断和修复：**
```bash
# 1. 查看重启原因
kubectl describe pod crash-pod

# 2. 检查应用日志
kubectl logs crash-pod --previous

# 3. 调整健康检查
kubectl edit deployment app-deployment
# 增加initialDelaySeconds，调整failureThreshold

# 4. 临时禁用健康检查
kubectl patch deployment app-deployment -p '{"spec":{"template":{"spec":{"containers":[{"name":"app","livenessProbe":null}]}}}}'
```

#### 🔸 服务不可访问

**故障现象：** Service无法正常访问

```bash
# 排查步骤
# 1. 检查Service配置
kubectl describe svc problem-service

# 2. 验证Endpoint
kubectl get endpoints problem-service

# 3. 测试Pod直接访问
kubectl get pods -o wide -l app=problem-app
kubectl exec -it test-pod -- curl http://pod-ip:port

# 4. 检查网络策略
kubectl get networkpolicy
```

### 9.5 存储故障预案


#### 🔸 PVC无法挂载

**故障现象：** Pod一直处于Pending状态

```bash
# 处理步骤
# 1. 检查PVC状态
kubectl describe pvc problem-pvc

# 2. 查看存储类
kubectl get storageclass
kubectl describe storageclass standard

# 3. 手动创建PV（如果需要）
kubectl apply -f manual-pv.yaml

# 4. 检查CSI驱动
kubectl get csidriver
kubectl logs -n kube-system -l app=csi-driver
```

### 9.6 故障预防和监控


#### 🔸 预防性监控规则

```yaml
# 关键监控指标
groups:
- name: prevention.rules
  rules:
  - alert: HighMemoryUsage
    expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes > 0.9
    for: 5m
    
  - alert: HighDiskUsage  
    expr: (node_filesystem_size_bytes - node_filesystem_avail_bytes) / node_filesystem_size_bytes > 0.85
    for: 5m
    
  - alert: PodRestartTooMuch
    expr: rate(kube_pod_container_status_restarts_total[1h]) > 0.1
    for: 10m
```

#### 🔸 故障演练计划

**定期进行故障演练：**
- **每月演练：** 节点故障恢复
- **每季度演练：** API Server故障恢复
- **每年演练：** 完整集群灾难恢复

---

## 10. 📋 核心要点总结


### 10.1 必须掌握的核心概念


```
🔸 kubectl调试：掌握describe、logs、events等核心命令
🔸 Pod状态诊断：理解Pod生命周期和异常状态处理
🔸 网络问题排查：掌握Service、DNS、CNI网络调试
🔸 存储故障处理：理解PV/PVC绑定和挂载问题
🔸 资源管理：掌握CPU、内存资源分析和优化
🔸 日志系统：熟练使用日志和事件进行故障定位
🔸 性能优化：识别瓶颈并进行针对性优化
🔸 健康检查：建立完整的集群健康监控体系
🔸 故障预案：制定和执行标准化故障处理流程
```

### 10.2 关键理解要点


**🔹 故障排查的系统方法**
```
分层诊断法：
基础设施 → K8s组件 → 应用服务 → 用户体验
每一层都有特定的工具和方法

信息收集优先级：
1. Events事件（最直接的错误信息）
2. Pod状态和日志（应用层问题）
3. 资源使用情况（性能问题）
4. 网络连通性（通信问题）
```

**🔹 性能优化的平衡原则**
```
资源配置平衡：
requests确保调度成功
limits防止资源耗尽
二者需要根据实际使用情况调优

扩展策略选择：
垂直扩展：增加单Pod资源
水平扩展：增加Pod副本数
根据应用特性选择合适策略
```

**🔹 监控和告警体系**
```
指标收集：基础设施 + 应用指标
阈值设置：根据业务SLA确定
告警分级：Critical > Warning > Info
响应流程：自动化处理 + 人工干预
```

### 10.3 实际应用指导


**🎯 不同环境的故障处理策略**

```
开发环境：
重点：快速定位问题，便于调试
工具：详细日志、调试Pod、宽松的健康检查
策略：可以容忍短暂服务中断

测试环境：
重点：模拟生产问题，验证修复效果  
工具：性能监控、压力测试、故障注入
策略：接近生产的配置和处理流程

生产环境：
重点：最小化服务影响，快速恢复
工具：完整监控、自动告警、故障预案
策略：高可用设计、渐进式修复
```

**🎯 团队协作和知识传承**

```yaml
# 故障处理文档模板
故障记录:
  时间: "2023-09-14 10:30"
  影响范围: "用户登录服务不可用"
  故障现象: "API返回500错误"
  
排查过程:
  - 检查Pod状态: "发现auth-service Pod重启"
  - 查看日志: "发现数据库连接超时"
  - 资源检查: "数据库Pod内存不足"
  
解决方案:
  - 临时措施: "增加数据库内存限制"
  - 根本解决: "优化数据库查询，减少内存使用"
  
预防措施:
  - 监控改进: "增加数据库内存使用监控"
  - 配置优化: "调整数据库连接池参数"
```

### 10.4 最佳实践总结


**🚀 故障排查最佳实践**

```
排查顺序：
1. 快速确认影响范围
2. 查看Events获取直接线索
3. 检查资源状态和使用情况
4. 分析日志找到详细错误
5. 验证修复效果

工具使用技巧：
• kubectl describe是故障排查的首选工具
• 日志分析要结合时间线
• 网络问题要从连通性开始排查
• 存储问题要检查PV/PVC绑定关系
```

**🚀 性能优化最佳实践**

```
优化策略：
• 基于实际监控数据进行优化
• 先解决明显的资源瓶颈
• 逐步调整，避免过度优化
• 建立基线，量化优化效果

配置管理：
• 使用ConfigMap管理应用配置
• 通过资源配额控制集群资源使用
• 定期审核和调整资源分配
• 建立不同环境的标准化配置
```

**核心记忆要点：**
- 故障排查要有系统性方法，分层诊断更高效
- Events和日志是故障定位的最重要信息源
- 性能优化需要基于实际监控数据，避免盲目调整
- 建立标准化的故障处理流程和预案是关键
- 监控和告警体系是预防故障的重要手段