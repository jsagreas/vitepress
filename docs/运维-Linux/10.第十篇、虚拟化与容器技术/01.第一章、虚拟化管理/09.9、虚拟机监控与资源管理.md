---
title: 9、虚拟机监控与资源管理
---
## 📚 目录

1. [虚拟机资源监控概述](#1-虚拟机资源监控概述)
2. [监控工具详解](#2-监控工具详解)
3. [CPU与内存监控](#3-CPU与内存监控)
4. [I/O性能监控](#4-IO性能监控)
5. [资源限制配置](#5-资源限制配置)
6. [热添加资源管理](#6-热添加资源管理)
7. [NUMA与CPU亲和性](#7-NUMA与CPU亲和性)
8. [性能调优实践](#8-性能调优实践)
9. [核心要点总结](#9-核心要点总结)

---

## 1. 📊 虚拟机资源监控概述


### 1.1 为什么需要虚拟机监控


**核心问题**：虚拟化环境中如何确保资源合理分配？

虚拟化让多个虚拟机共享物理硬件资源，这就像一栋公寓楼里住着多户人家，每户都需要用水、用电。如果没有监控和管理，就可能出现：
- 某个虚拟机占用过多CPU，导致其他虚拟机卡顿
- 内存不够用，系统开始频繁交换，性能急剧下降
- 磁盘I/O被某个虚拟机独占，其他虚拟机读写变慢

> 💡 **通俗理解**：虚拟机监控就像小区物业管理，需要监控每户的资源使用情况，确保大家都能正常生活。

### 1.2 监控体系架构


```
宿主机监控层级结构：

┌─────────────────────────────────────┐
│           物理硬件资源               │
│  CPU | Memory | Disk | Network      │
└──────────────┬──────────────────────┘
               │
┌──────────────▼──────────────────────┐
│          Hypervisor层              │
│     (KVM/QEMU + libvirt)           │
└──────────────┬──────────────────────┘
               │
┌──────────────▼──────────────────────┐
│         虚拟机监控工具               │
│  virt-top | virsh | qemu-monitor    │
└─────────────────────────────────────┘

监控数据流向：
硬件 → Hypervisor → 监控工具 → 管理决策
```

### 1.3 监控关键指标


| 资源类型 | **核心指标** | **监控目的** | **告警阈值建议** |
|---------|-------------|-------------|-----------------|
| 🖥️ **CPU** | `使用率、等待时间` | `防止CPU瓶颈` | `> 80%持续5分钟` |
| 🧠 **内存** | `使用率、交换使用` | `避免内存不足` | `> 90%或有交换` |
| 💾 **磁盘** | `IOPS、吞吐量、延迟` | `保证I/O性能` | `延迟 > 100ms` |
| 🌐 **网络** | `带宽、包转发率` | `确保网络畅通` | `丢包率 > 1%` |

---

## 2. 🔧 监控工具详解


### 2.1 virt-top - 虚拟机界的top命令


**概念解释**：`virt-top`是专门为虚拟化环境设计的实时监控工具，就像Linux系统的`top`命令一样，但它显示的是各个虚拟机的资源使用情况。

**基本使用**：
```bash
# 启动virt-top监控
virt-top

# 连接到远程libvirt
virt-top -c qemu+ssh://user@host/system

# 延迟更新间隔（秒）
virt-top -d 5
```

**界面解读**：
```
virt-top显示界面：
17:42:43 - 3 domains, 1 active, 1 running, 0 inactive, 0 disabled
%CPU(s):  2.1 us,  0.8 sy,  0.0 ni, 97.1 id,  0.0 wa
%Mem: 8192 total, 4096 used, 4096 free

    ID S RDRQ WRRQ RXBY TXBY %CPU %MEM    TIME   NAME
     2 R    0    4    0  648  2.1 25.0   0:42.71 web-server
     3 S    0    0    0    0  0.0 12.5   0:01.23 database
```

> 📖 **界面含义**：
> - **ID**：虚拟机的域ID号
> - **S**：虚拟机状态（R=运行，S=休眠）
> - **RDRQ/WRRQ**：读写请求次数
> - **%CPU/%MEM**：CPU和内存使用百分比

### 2.2 virsh domstats - 详细统计信息


**概念解释**：`virsh domstats`是libvirt提供的统计命令，能够获取虚拟机的详细性能数据，比virt-top提供更全面的信息。

```bash
# 获取所有虚拟机统计信息
virsh domstats

# 获取特定虚拟机的统计
virsh domstats web-server

# 只显示CPU统计
virsh domstats --cpu-total web-server

# 实时监控（每3秒更新）
watch -n 3 'virsh domstats web-server'
```

**输出解析**：
```bash
Domain: 'web-server'
  cpu.time=1234567890      # CPU总使用时间（纳秒）
  cpu.user=987654321       # 用户态CPU时间
  cpu.system=246813579     # 内核态CPU时间
  balloon.current=2097152  # 当前分配内存（KB）
  balloon.maximum=4194304  # 最大可用内存（KB）
  vcpu.current=2           # 当前vCPU数量
  vcpu.maximum=4           # 最大vCPU数量
```

### 2.3 其他常用监控命令


**快速检查命令合集**：

```bash
# 查看虚拟机列表和状态
virsh list --all

# 查看虚拟机基本信息
virsh dominfo web-server

# 查看CPU使用情况
virsh cpu-stats web-server

# 查看内存统计
virsh dommemstat web-server

# 查看块设备统计
virsh domblkstat web-server vda
```

---

## 3. 🖥️ CPU与内存监控


### 3.1 CPU使用率监控深度解析


**CPU监控的核心概念**：

虚拟机的CPU监控不同于物理机，因为涉及到CPU时间片的分配和调度。理解几个关键概念：

- **vCPU**：虚拟CPU，是分配给虚拟机的逻辑CPU核心
- **CPU时间片**：虚拟机实际占用物理CPU的时间
- **CPU等待时间**：虚拟机等待被调度的时间

```
CPU监控层次图：

物理CPU核心 (8核心)
    ┌─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┐
    │ C0  │ C1  │ C2  │ C3  │ C4  │ C5  │ C6  │ C7  │
    └─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┘
         ↓
    Hypervisor调度器
         ↓
    虚拟机vCPU分配
    ┌─────────┬─────────┬─────────┐
    │VM1(2核) │VM2(2核) │VM3(4核) │
    └─────────┴─────────┴─────────┘
```

**实际监控操作**：

```bash
# 详细CPU统计
virsh cpu-stats web-server --total
# 输出：
# cpu_time     12345678900 ns    # 总CPU时间
# user_time     8765432100 ns    # 用户态时间  
# system_time   3580246800 ns    # 系统态时间
# vcpu_time     12345678900 ns   # vCPU使用时间

# 计算CPU使用率
# 使用率 = (当前cpu_time - 上次cpu_time) / 时间间隔 / vCPU数量
```

> ⚠️ **监控要点**：
> - CPU使用率持续超过80%需要关注
> - CPU等待时间过长说明物理CPU不够用
> - 频繁的上下文切换会影响性能

### 3.2 内存使用监控详解


**内存监控的复杂性**：

虚拟机内存管理比物理机更复杂，因为涉及多层内存映射：

```
内存层次结构：

虚拟机应用内存
    ↓
虚拟机操作系统内存管理
    ↓
Guest物理内存 (虚拟机看到的)
    ↓
Host虚拟内存 (宿主机分配的)
    ↓  
Host物理内存 (实际硬件)
```

**关键监控指标**：

```bash
# 获取内存详细统计
virsh dommemstat web-server

# 典型输出解析：
actual 2097152        # 实际分配给虚拟机的内存(KB)
swap_in 0            # 从交换区读入的页数
swap_out 0           # 写入交换区的页数
major_fault 245      # 主要页错误（需要从磁盘读取）
minor_fault 175432   # 次要页错误（在内存中处理）
unused 524288        # 未使用的内存
available 1835008    # 可用内存
usable 1572864      # 实际可用内存
```

**内存气球技术**：

内存气球(Memory Balloon)是一种动态调整虚拟机内存的技术：

```bash
# 查看气球设备状态
virsh qemu-monitor-command web-server --hmp 'info balloon'

# 动态调整内存（将内存调整为3GB）
virsh setmem web-server 3145728 --live

# 设置内存气球目标值
virsh qemu-monitor-command web-server --hmp 'balloon 2048'
```

> 💡 **内存优化建议**：
> - 避免内存过度分配，总分配不要超过物理内存的80%
> - 监控交换使用情况，有交换说明内存不够
> - 使用内存气球技术动态调整内存分配

---

## 4. 💾 I/O性能监控


### 4.1 磁盘I/O监控核心概念


**什么是I/O性能**：

I/O性能衡量虚拟机读写磁盘的效率。在虚拟化环境中，I/O路径更复杂：

```
I/O数据流向：

虚拟机应用
    ↓
Guest OS文件系统
    ↓
虚拟磁盘驱动 (virtio-blk)
    ↓
QEMU磁盘模拟层
    ↓
Host OS文件系统
    ↓
物理磁盘硬件
```

**关键I/O指标**：

- **IOPS**：每秒输入输出操作次数
- **吞吐量**：每秒传输的数据量(MB/s)
- **延迟**：单次I/O操作的时间
- **队列深度**：等待处理的I/O请求数量

### 4.2 I/O监控实战


**基础I/O统计**：

```bash
# 查看块设备I/O统计
virsh domblkstat web-server vda

# 输出解释：
vda rd_req 125420        # 读请求次数
vda rd_bytes 2847391744  # 读取字节数
vda wr_req 67234         # 写请求次数  
vda wr_bytes 1456789120  # 写入字节数
vda flush_operations 892 # 刷新操作次数
vda rd_total_times 45673123456  # 读操作总时间(纳秒)
vda wr_total_times 23456781234  # 写操作总时间(纳秒)
```

**计算I/O性能指标**：

```bash
# 计算IOPS (每5秒采样一次)
#!/bin/bash
get_iops() {
    local domain=$1
    local device=$2
    local interval=${3:-5}
    
    # 获取初始统计
    stats1=$(virsh domblkstat $domain $device)
    rd1=$(echo "$stats1" | awk '/rd_req/ {print $3}')
    wr1=$(echo "$stats1" | awk '/wr_req/ {print $3}')
    
    sleep $interval
    
    # 获取第二次统计
    stats2=$(virsh domblkstat $domain $device)
    rd2=$(echo "$stats2" | awk '/rd_req/ {print $3}')
    wr2=$(echo "$stats2" | awk '/wr_req/ {print $3}')
    
    # 计算IOPS
    read_iops=$(( (rd2 - rd1) / interval ))
    write_iops=$(( (wr2 - wr1) / interval ))
    total_iops=$(( read_iops + write_iops ))
    
    echo "读IOPS: $read_iops"
    echo "写IOPS: $write_iops" 
    echo "总IOPS: $total_iops"
}

# 使用方法
get_iops web-server vda 5
```

### 4.3 I/O性能调优


**I/O调度器优化**：

```bash
# 查看当前I/O调度器
cat /sys/block/sda/queue/scheduler

# 设置I/O调度器为deadline（适合虚拟化）
echo deadline > /sys/block/sda/queue/scheduler

# 在虚拟机配置中指定I/O调度
virsh edit web-server
# 在<disk>标签中添加：
# <driver name='qemu' type='qcow2' io='threads' iothread='1'/>
```

> 🔧 **I/O优化技巧**：
> - 使用SSD存储提高随机I/O性能
> - 启用virtio-blk驱动获得更好性能
> - 合理设置I/O队列深度
> - 使用多个I/O线程处理并发请求

---

## 5. ⚙️ 资源限制配置


### 5.1 CPU资源限制


**CPU份额控制原理**：

CPU份额(CPU Shares)决定虚拟机在CPU竞争时的优先级。就像排队买票，份额高的虚拟机能够获得更多的CPU时间。

```
CPU份额分配示例：

总CPU份额池: 3072份额
┌─────────────┬─────────────┬─────────────┐
│VM1: 1024份额│VM2: 1024份额│VM3: 1024份额│
│  (33.3%)   │  (33.3%)   │  (33.3%)   │
└─────────────┴─────────────┴─────────────┘

如果VM3空闲，VM1和VM2各获得50% CPU
如果只有VM1活跃，VM1获得100% CPU
```

**CPU限制配置**：

```bash
# 设置CPU份额（默认1024）
virsh schedinfo web-server --set cpu_shares=2048

# 设置CPU配额（限制最大使用率）
# period: 调度周期（微秒，通常100000=100ms）
# quota: 配额时间（微秒）
# 例如：限制使用50% CPU
virsh schedinfo web-server --set vcpu_period=100000 --set vcpu_quota=50000

# 查看当前CPU调度参数
virsh schedinfo web-server
```

**CPU绑定(CPU Pinning)**：

```bash
# 将虚拟机vCPU绑定到特定物理CPU
virsh vcpupin web-server 0 1-2    # vCPU0绑定到物理CPU1-2
virsh vcpupin web-server 1 3-4    # vCPU1绑定到物理CPU3-4

# 查看CPU绑定情况
virsh vcpuinfo web-server

# 在XML配置中设置CPU绑定
virsh edit web-server
# 添加：
# <vcpu placement='static' cpuset='1-4'>2</vcpu>
# <cputune>
#   <vcpupin vcpu='0' cpuset='1-2'/>
#   <vcpupin vcpu='1' cpuset='3-4'/>
# </cputune>
```

### 5.2 内存资源限制


**内存限制的几种方式**：

```bash
# 设置内存硬限制（KB）
virsh memtune web-server --hard-limit 4194304  # 4GB硬限制

# 设置内存软限制
virsh memtune web-server --soft-limit 3145728  # 3GB软限制

# 设置交换限制
virsh memtune web-server --swap-hard-limit 2097152  # 2GB交换限制

# 查看内存限制设置
virsh memtune web-server
```

> ⚠️ **内存限制注意事项**：
> - **硬限制**：绝对不能超过的内存上限
> - **软限制**：建议的内存使用上限，在资源紧张时强制执行
> - **交换限制**：限制虚拟机使用的交换空间

### 5.3 磁盘I/O限制


**磁盘I/O节流控制**：

```bash
# 设置磁盘I/O限制
virsh blkdeviotune web-server vda --total-iops-sec 1000  # 限制总IOPS为1000
virsh blkdeviotune web-server vda --read-iops-sec 600   # 限制读IOPS为600  
virsh blkdeviotune web-server vda --write-iops-sec 400  # 限制写IOPS为400

# 设置带宽限制
virsh blkdeviotune web-server vda --total-bytes-sec $((100*1024*1024))  # 限制100MB/s

# 查看当前I/O限制
virsh blkdeviotune web-server vda
```

**I/O权重控制**：

```bash
# 设置块设备权重（100-1000，默认500）
virsh blkdeviotune web-server vda --weight 800

# 在XML中配置I/O限制
virsh edit web-server
# 在<disk>中添加：
# <iotune>
#   <total_iops_sec>1000</total_iops_sec>
#   <read_iops_sec>600</read_iops_sec>
#   <write_iops_sec>400</write_iops_sec>
# </iotune>
```

---

## 6. 🔥 热添加资源管理


### 6.1 CPU热添加


**什么是CPU热添加**：

CPU热添加允许在虚拟机运行时动态增加vCPU数量，无需重启虚拟机。这就像给正在运行的发动机加缸一样。

**CPU热添加操作**：

```bash
# 查看当前vCPU配置
virsh vcpucount web-server
# 输出：
# maximum      config         4    # 配置的最大vCPU数
# maximum      live           2    # 当前实际vCPU数
# current      config         2    # 配置的当前vCPU数
# current      live           2    # 运行时的vCPU数

# 热添加vCPU（将vCPU从2个增加到4个）
virsh setvcpus web-server 4 --live

# 验证添加结果
virsh vcpucount web-server

# 在虚拟机内部查看CPU变化（需要支持CPU热插拔的操作系统）
# 虚拟机内执行：
lscpu
cat /proc/cpuinfo | grep processor | wc -l
```

**配置最大vCPU数**：

```bash
# 设置最大vCPU数（需要关机状态）
virsh shutdown web-server
virsh setvcpus web-server 8 --maximum --config
virsh start web-server

# 或者直接编辑XML配置
virsh edit web-server
# 修改：<vcpu placement='static' current='2'>8</vcpu>
```

### 6.2 内存热添加


**内存热添加原理**：

内存热添加通过内存气球技术实现，可以在运行时动态调整虚拟机的可用内存。

```
内存热添加流程：

宿主机物理内存池
        ↓
   分配给虚拟机
        ↓
   内存气球驱动调整
        ↓
   虚拟机可用内存变化

注意：只能在最大内存范围内调整
```

**内存热添加操作**：

```bash
# 查看内存配置
virsh dominfo web-server | grep -E "Max memory|Used memory"

# 热添加内存（增加到4GB）
virsh setmem web-server 4194304 --live

# 设置最大内存（需要关机）
virsh shutdown web-server  
virsh setmaxmem web-server 8388608  # 设置最大8GB
virsh start web-server

# 验证内存变化
virsh dominfo web-server
```

**内存气球详细控制**：

```bash
# 使用QEMU monitor控制内存气球
virsh qemu-monitor-command web-server --hmp 'info balloon'

# 设置气球目标（动态调整可用内存）
virsh qemu-monitor-command web-server --hmp 'balloon 3072'

# 在虚拟机内查看内存变化
free -h
```

### 6.3 磁盘热添加


**磁盘热添加场景**：

当虚拟机存储空间不足时，可以在不停机的情况下添加新的虚拟磁盘。

```bash
# 创建新的虚拟磁盘
qemu-img create -f qcow2 /var/lib/libvirt/images/web-server-data.qcow2 50G

# 热添加磁盘到虚拟机
virsh attach-disk web-server \
    /var/lib/libvirt/images/web-server-data.qcow2 \
    vdb --driver qemu --subdriver qcow2 --live

# 验证磁盘添加
virsh domblklist web-server

# 在虚拟机内查看新磁盘
lsblk
fdisk -l
```

**磁盘热移除**：

```bash
# 热移除磁盘（确保磁盘未被使用）
virsh detach-disk web-server vdb --live

# 永久移除（修改配置文件）
virsh detach-disk web-server vdb --config
```

> ⚠️ **热添加注意事项**：
> - 虚拟机操作系统必须支持热插拔
> - CPU热添加容易，CPU热移除困难
> - 内存只能在最大内存范围内调整
> - 磁盘热添加前确保有足够的宿主机存储空间

---

## 7. 🏗️ NUMA与CPU亲和性


### 7.1 NUMA架构理解


**什么是NUMA**：

NUMA(Non-Uniform Memory Access)是一种内存访问架构，在多处理器系统中，每个处理器都有自己的本地内存，访问本地内存比访问远程内存更快。

```
NUMA架构示意图：

    NUMA Node 0              NUMA Node 1
┌─────────────────┐      ┌─────────────────┐
│ CPU 0-7         │      │ CPU 8-15        │
│ Local Memory    │<────>│ Local Memory    │
│ (0-32GB)        │      │ (32-64GB)       │
└─────────────────┘      └─────────────────┘
        │                        │
        └────────QPI总线──────────┘

访问延迟差异：
- 本地内存访问：~100ns
- 远程内存访问：~300ns
```

**查看NUMA拓扑**：

```bash
# 查看NUMA节点信息
numactl --hardware
lstopo-no-graphics  # 需要安装hwloc包

# 查看进程NUMA亲和性
numactl --show

# 查看虚拟机NUMA配置
virsh numatune web-server
```

### 7.2 虚拟机NUMA配置


**NUMA配置策略**：

为了获得最佳性能，应该将虚拟机的vCPU和内存绑定到同一个NUMA节点上。

```bash
# 设置虚拟机NUMA策略
virsh numatune web-server --mode strict --nodeset 0-1

# 查看设置结果  
virsh numatune web-server

# 在XML配置中设置NUMA
virsh edit web-server
# 添加NUMA配置：
# <numatune>
#   <memory mode='strict' nodeset='0-1'/>
# </numatune>
# 
# <cpu mode='host-passthrough'>
#   <numa>
#     <cell id='0' cpus='0-1' memory='2097152'/>
#     <cell id='1' cpus='2-3' memory='2097152'/>
#   </numa>
# </cpu>
```

**NUMA亲和性模式**：

| 模式 | **含义** | **适用场景** |
|------|---------|-------------|
| **strict** | `严格绑定到指定节点` | `高性能要求` |
| **interleave** | `内存在节点间交替分配` | `内存密集型应用` |
| **preferred** | `优先使用指定节点` | `一般性能要求` |

### 7.3 CPU亲和性高级配置


**vCPU与物理CPU绑定策略**：

```bash
# 查看物理CPU拓扑
virsh nodeinfo
lscpu | grep -E "CPU\(s\)|Thread|Core|Socket|NUMA"

# 高级CPU绑定配置
virsh edit web-server
# CPU配置示例：
# <vcpu placement='static' cpuset='0-7'>4</vcpu>
# <cputune>
#   <!-- 将vCPU绑定到物理CPU -->
#   <vcpupin vcpu='0' cpuset='0'/>
#   <vcpupin vcpu='1' cpuset='1'/>  
#   <vcpupin vcpu='2' cpuset='2'/>
#   <vcpupin vcpu='3' cpuset='3'/>
#   
#   <!-- I/O线程绑定 -->
#   <iothreadpin iothread='1' cpuset='4-5'/>
#   
#   <!-- 模拟器线程绑定 -->
#   <emulatorpin cpuset='6-7'/>
# </cputune>
```

**CPU隔离配置**：

```bash
# 在宿主机上隔离CPU（启动参数）
# 编辑 /etc/default/grub
GRUB_CMDLINE_LINUX="isolcpus=2-7 nohz_full=2-7 rcu_nocbs=2-7"

# 更新grub配置
update-grub
reboot

# 将隔离的CPU专门分配给虚拟机
virsh edit web-server
# <vcpu placement='static' cpuset='2-7'>6</vcpu>
```

> 🔧 **NUMA优化建议**：
> - 虚拟机的vCPU和内存尽量在同一NUMA节点
> - 避免跨NUMA节点的内存访问
> - 大内存虚拟机可以跨多个NUMA节点均衡分布
> - 使用`lstopo`工具可视化NUMA拓扑

---

## 8. 🚀 性能调优实践


### 8.1 系统级性能调优


**宿主机性能调优**：

虚拟化性能的基础是宿主机的优化配置。

```bash
# 1. 内核参数调优
cat >> /etc/sysctl.conf << EOF
# 虚拟化优化参数
vm.swappiness = 1                    # 减少交换使用
vm.dirty_ratio = 15                  # 脏页比例
vm.dirty_background_ratio = 5        # 后台写入阈值
kernel.sched_min_granularity_ns = 10000000   # 调度粒度
kernel.sched_wakeup_granularity_ns = 15000000 # 唤醒粒度
net.core.busy_read = 50             # 网络轮询优化
EOF

sysctl -p

# 2. CPU频率控制
cpupower frequency-set -g performance  # 设置为高性能模式

# 3. 透明大页配置
echo always > /sys/kernel/mm/transparent_hugepage/enabled
echo always > /sys/kernel/mm/transparent_hugepage/defrag
```

**存储优化配置**：

```bash
# SSD优化（如果使用SSD存储）
# 启用SSD的TRIM支持
echo deadline > /sys/block/sda/queue/scheduler
echo 0 > /sys/block/sda/queue/add_random
echo 2 > /sys/block/sda/queue/rq_affinity

# 磁盘预读调整
blockdev --setra 4096 /dev/sda

# 文件系统挂载优化
mount -o remount,noatime,barrier=0 /var/lib/libvirt/images
```

### 8.2 虚拟机配置优化


**虚拟机XML优化配置**：

```xml
<!-- 高性能虚拟机配置模板 -->
<domain type='kvm'>
  <name>web-server-optimized</name>
  
  <!-- CPU优化配置 -->
  <vcpu placement='static' cpuset='2-5'>4</vcpu>
  <cpu mode='host-passthrough' check='none'>
    <topology sockets='1' cores='4' threads='1'/>
    <feature policy='require' name='invtsc'/>
  </cpu>
  
  <!-- 内存优化配置 -->
  <memory unit='KiB'>8388608</memory>
  <memoryBacking>
    <hugepages>
      <page size='1048576' unit='KiB'/>
    </hugepages>
    <locked/>
  </memoryBacking>
  
  <!-- 时钟优化 -->
  <clock offset='localtime'>
    <timer name='rtc' tickpolicy='catchup'/>
    <timer name='pit' tickpolicy='delay'/>
    <timer name='hpet' present='no'/>
    <timer name='hypervclock' present='yes'/>
  </clock>
  
  <!-- 磁盘优化配置 -->
  <disk type='file' device='disk'>
    <driver name='qemu' type='qcow2' cache='none' io='native' 
            discard='unmap' iothread='1'/>
    <source file='/var/lib/libvirt/images/web-server.qcow2'/>
    <target dev='vda' bus='virtio'/>
  </disk>
  
  <!-- 网络优化配置 -->
  <interface type='bridge'>
    <source bridge='br0'/>
    <model type='virtio'/>
    <driver name='vhost' queues='4'/>
  </interface>
  
  <!-- IO线程配置 -->
  <iothreads>2</iothreads>
  <cputune>
    <iothreadpin iothread='1' cpuset='6'/>
    <iothreadpin iothread='2' cpuset='7'/>
  </cputune>
</domain>
```

### 8.3 应用层面性能优化


**虚拟机内部优化**：

```bash
# 1. 虚拟化感知驱动安装
# CentOS/RHEL系统
yum install qemu-guest-agent

# Ubuntu/Debian系统  
apt-get install qemu-guest-agent

systemctl enable qemu-guest-agent
systemctl start qemu-guest-agent

# 2. 网络优化
# 启用多队列网络
echo 'ETHTOOL_OPTIONS="-L ${DEVICE} combined 4"' >> /etc/sysconfig/network-scripts/ifcfg-eth0

# 3. 内核参数调优（虚拟机内部）
cat >> /etc/sysctl.conf << EOF
net.core.rmem_default = 262144
net.core.rmem_max = 16777216
net.core.wmem_default = 262144
net.core.wmem_max = 16777216
net.ipv4.tcp_rmem = 4096 65536 16777216
net.ipv4.tcp_wmem = 4096 65536 16777216
EOF
```

### 8.4 性能监控与基准测试


**建立性能基准**：

```bash
#!/bin/bash
# 虚拟机性能基准测试脚本

echo "=== 虚拟机性能基准测试 ==="
echo "测试时间: $(date)"

# CPU性能测试
echo "1. CPU性能测试"
sysbench cpu --cpu-max-prime=10000 --threads=4 run

# 内存性能测试  
echo "2. 内存性能测试"
sysbench memory --memory-total-size=10G --threads=4 run

# 磁盘I/O测试
echo "3. 磁盘I/O性能测试"
sysbench fileio --file-total-size=5G prepare
sysbench fileio --file-total-size=5G --file-test-mode=rndrw \
         --max-time=60 --threads=4 run
sysbench fileio cleanup

# 网络性能测试（需要iperf3）
echo "4. 网络性能测试"
# 服务器端: iperf3 -s
# 客户端: iperf3 -c server_ip -t 30

echo "=== 测试完成 ==="
```

**持续性能监控**：

```bash
#!/bin/bash
# 虚拟机性能监控脚本

DOMAIN="web-server"
LOG_FILE="/var/log/vm-performance.log"

while true; do
    timestamp=$(date '+%Y-%m-%d %H:%M:%S')
    
    # CPU统计
    cpu_stats=$(virsh cpu-stats $DOMAIN --total 2>/dev/null)
    cpu_time=$(echo "$cpu_stats" | awk '/cpu_time/ {print $2}')
    
    # 内存统计
    mem_stats=$(virsh dommemstat $DOMAIN 2>/dev/null)
    mem_used=$(echo "$mem_stats" | awk '/actual/ {print $2}')
    mem_available=$(echo "$mem_stats" | awk '/available/ {print $2}')
    
    # I/O统计
    io_stats=$(virsh domblkstat $DOMAIN vda 2>/dev/null)
    read_req=$(echo "$io_stats" | awk '/rd_req/ {print $3}')
    write_req=$(echo "$io_stats" | awk '/wr_req/ {print $3}')
    
    # 记录到日志
    echo "$timestamp,CPU:$cpu_time,MEM:$mem_used/$mem_available,IO:$read_req/$write_req" >> $LOG_FILE
    
    sleep 60
done
```

> 📊 **性能调优检查清单**：
> - [ ] 宿主机CPU频率设置为性能模式
> - [ ] 启用透明大页支持
> - [ ] 虚拟机使用virtio驱动
> - [ ] 配置合适的NUMA亲和性
> - [ ] 磁盘使用SSD，启用直接I/O
> - [ ] 网络使用桥接模式，启用多队列
> - [ ] 安装qemu-guest-agent
> - [ ] 建立性能基准和监控

---

## 9. 📋 核心要点总结


### 9.1 必须掌握的核心概念


```
🔸 监控体系：virt-top实时监控，virsh domstats详细统计
🔸 资源监控：CPU使用率、内存占用、I/O性能、网络带宽  
🔸 资源限制：CPU份额、内存限制、I/O节流控制
🔸 热添加：运行时动态调整CPU、内存、磁盘资源
🔸 NUMA优化：CPU和内存绑定到同一节点提升性能
🔸 性能调优：宿主机优化、虚拟机配置、应用层调优
```

### 9.2 关键理解要点


**🔹 监控的层次性**
```
理解要点：
- 物理层：宿主机硬件资源使用情况
- 虚拟化层：Hypervisor的资源分配和调度  
- 虚拟机层：单个虚拟机的资源使用情况
- 应用层：虚拟机内应用的性能表现
```

**🔹 资源竞争与隔离**
```
核心概念：
- 资源共享：多个虚拟机共享物理资源
- 资源隔离：确保虚拟机间不相互干扰
- 资源保证：关键虚拟机的资源保证机制
- 超分配：谨慎使用资源超分配策略
```

**🔹 性能调优的平衡艺术**
```
平衡考量：
- 性能 vs 密度：高性能 vs 高虚拟机密度
- 隔离 vs 效率：资源隔离 vs 资源利用效率
- 简单 vs 优化：配置简单 vs 性能优化
- 稳定 vs 极致：系统稳定 vs 极致性能
```

### 9.3 实际应用指导


**📊 监控策略建议**：
```
日常监控：
- 使用virt-top进行实时监控
- 定期检查domstats统计信息
- 设置关键指标的告警阈值
- 建立性能历史数据库

问题诊断：
- CPU等待时间过长 → 检查CPU绑定和调度
- 内存交换频繁 → 调整内存分配或限制
- I/O延迟过高 → 优化存储配置和调度器
- 网络丢包严重 → 检查网络配置和带宽
```

**🎯 资源配置原则**：
```
CPU配置：
- 避免CPU过度分配超过物理核心数的4倍
- 关键虚拟机使用CPU绑定
- 合理设置CPU份额权重

内存配置：  
- 总内存分配不超过物理内存的80%
- 为宿主机预留足够内存
- 使用内存气球技术动态调整

存储配置：
- 优先使用SSD存储提升I/O性能
- 配置合适的I/O调度器
- 使用多路径提高可靠性
```

**🚀 性能优化路径**：
```
初级优化：
- 安装virtio驱动
- 启用qemu-guest-agent
- 设置CPU为性能模式

中级优化：
- 配置NUMA亲和性
- 优化磁盘缓存策略
- 调整网络多队列

高级优化：
- CPU隔离和绑定
- 大页内存配置
- SR-IOV网络直通
```

### 9.4 最佳实践总结


```
🔧 运维最佳实践：
- 建立完善的监控体系和告警机制
- 定期进行性能基准测试
- 制定资源配置标准和模板
- 建立性能问题的快速诊断流程

📈 容量规划原则：
- 基于历史数据进行容量预测  
- 考虑业务增长和峰值需求
- 预留足够的资源缓冲空间
- 定期评估和调整资源配置

⚠️ 常见陷阱避免：
- 避免过度的资源超分配
- 不要忽视NUMA拓扑的影响
- 注意虚拟机间的资源竞争
- 警惕存储I/O成为性能瓶颈
```

**核心记忆**：
- 虚拟化监控需要多层次全方位覆盖
- 资源限制与隔离是保证性能的关键
- 热添加技术提供了灵活的资源管理能力
- NUMA感知配置显著提升大内存虚拟机性能  
- 持续监控和调优是虚拟化运维的核心工作