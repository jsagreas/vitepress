---
title: 11、grep在脚本编程中的使用
---
## 📚 目录

1. [条件判断中的grep](#1-条件判断中的grep)
2. [管道组合使用](#2-管道组合使用)
3. [变量内容搜索](#3-变量内容搜索)
4. [搜索结果处理](#4-搜索结果处理)
5. [错误处理机制](#5-错误处理机制)
6. [脚本性能优化](#6-脚本性能优化)
7. [自动化任务集成](#7-自动化任务集成)
8. [核心要点总结](#8-核心要点总结)

---

## 1. 🎯 条件判断中的grep


### 1.1 基本条件判断原理


**什么是条件判断中的grep**：
在Shell脚本中，我们经常需要判断某个文件或输出中是否包含特定内容，这时候grep就成了最得力的助手。grep的退出状态码能直接告诉我们搜索是否成功。

```
grep的退出状态码含义：
0  → 找到匹配内容 (成功)
1  → 没找到匹配内容 (未找到)
2  → 发生错误 (语法错误或文件不存在)
```

### 1.2 if语句中的grep应用


**基础语法结构**：
```bash
# 检查文件中是否包含某个关键词
if grep -q "关键词" 文件名; then
    echo "找到了!"
else
    echo "没找到"
fi
```

**实际应用示例**：
```bash
#!/bin/bash

# 检查系统是否有特定用户
if grep -q "^mysql:" /etc/passwd; then
    echo "MySQL用户存在"
    # 执行相关MySQL操作
else
    echo "MySQL用户不存在，需要创建"
    # 创建MySQL用户的代码
fi

# 检查配置文件中的设置
if grep -q "^DEBUG=true" /etc/myapp/config; then
    echo "调试模式已启用"
    # 启用详细日志
else
    echo "生产模式运行"
    # 使用标准日志
fi
```

### 1.3 条件判断的高级技巧


**多条件组合判断**：
```bash
#!/bin/bash

LOG_FILE="/var/log/system.log"

# 检查是否有错误且不是网络错误
if grep -q "ERROR" "$LOG_FILE" && ! grep -q "Network timeout" "$LOG_FILE"; then
    echo "发现系统错误，但不是网络问题"
    # 执行系统检查
fi

# 检查多个关键词
if grep -E "CRITICAL|FATAL|EMERGENCY" "$LOG_FILE" > /dev/null; then
    echo "发现严重错误！"
    # 发送告警
fi
```

**使用变量存储匹配结果**：
```bash
#!/bin/bash

# 先搜索，再根据结果判断
SEARCH_RESULT=$(grep -c "failed login" /var/log/auth.log)

if [ "$SEARCH_RESULT" -gt 10 ]; then
    echo "检测到大量登录失败：$SEARCH_RESULT 次"
    echo "可能存在暴力破解攻击"
elif [ "$SEARCH_RESULT" -gt 0 ]; then
    echo "有少量登录失败：$SEARCH_RESULT 次"
else
    echo "没有登录失败记录"
fi
```

---

## 2. 🔗 管道组合使用


### 2.1 管道的基本概念


**什么是管道**：
管道就像是数据的传输带，把前一个命令的输出直接传给后一个命令作为输入。grep经常作为管道链中的重要环节，用来过滤和筛选数据。

```
命令流程示意：
前置命令 → | → grep过滤 → | → 后续处理

实例：
ps aux | grep "apache" | grep -v grep
   ↑        ↑           ↑
 进程列表   找apache   排除grep本身
```

### 2.2 常用管道组合模式


**系统进程监控**：
```bash
#!/bin/bash

# 检查特定进程是否运行
check_process() {
    local process_name=$1
    
    # 使用管道组合检查进程
    if ps aux | grep "$process_name" | grep -v grep > /dev/null; then
        echo "进程 $process_name 正在运行"
        
        # 显示进程详细信息
        echo "进程详情："
        ps aux | grep "$process_name" | grep -v grep | awk '{print "PID:", $2, "CPU:", $3"%", "内存:", $4"%"}'
    else
        echo "进程 $process_name 未运行"
    fi
}

# 使用函数
check_process "nginx"
check_process "mysql"
```

**日志分析管道**：
```bash
#!/bin/bash

# 分析访问日志中的热门页面
echo "=== 今日访问量前10的页面 ==="
cat /var/log/nginx/access.log | \
grep "$(date '+%d/%b/%Y')" | \
grep -E "\.(html|php|jsp)" | \
awk '{print $7}' | \
sort | \
uniq -c | \
sort -nr | \
head -10

# 分析错误日志
echo "=== 今日错误统计 ==="
tail -1000 /var/log/nginx/error.log | \
grep "$(date '+%Y/%m/%d')" | \
grep -oE "error|warning|critical" | \
sort | \
uniq -c
```

### 2.3 管道组合的性能优化


**提前过滤原则**：
```bash
# ❌ 低效写法 - 处理大量不需要的数据
cat huge_file.log | sort | uniq | grep "ERROR"

# ✅ 高效写法 - 先过滤再处理
grep "ERROR" huge_file.log | sort | uniq
```

**合理使用grep选项**：
```bash
#!/bin/bash

# 多阶段过滤
analyze_logs() {
    local log_file=$1
    local date_pattern=$2
    
    # 第一阶段：时间过滤
    grep "$date_pattern" "$log_file" | \
    # 第二阶段：错误级别过滤
    grep -E "ERROR|WARN|FATAL" | \
    # 第三阶段：排除已知的无害错误
    grep -v "connection timeout" | \
    # 第四阶段：统计分析
    awk '{print $4}' | sort | uniq -c | sort -nr
}
```

---

## 3. 💾 变量内容搜索


### 3.1 变量搜索的基本方法


**什么是变量内容搜索**：
有时候我们需要在脚本变量存储的文本内容中搜索特定模式，而不是在文件中搜索。这需要特殊的技巧来处理。

**基础搜索语法**：
```bash
#!/bin/bash

# 在变量中搜索内容
TEXT="这是一段测试文本，包含ERROR信息和WARNING提示"

# 方法1：使用echo配合管道
if echo "$TEXT" | grep -q "ERROR"; then
    echo "变量中包含错误信息"
fi

# 方法2：使用here string (推荐)
if grep -q "WARNING" <<< "$TEXT"; then
    echo "变量中包含警告信息"
fi
```

### 3.2 多行变量的处理


**处理多行内容**：
```bash
#!/bin/bash

# 读取多行配置到变量
CONFIG=$(cat /etc/myapp/settings.conf)

echo "检查配置内容："

# 检查数据库配置
if grep -q "^database.host=" <<< "$CONFIG"; then
    DB_HOST=$(echo "$CONFIG" | grep "^database.host=" | cut -d'=' -f2)
    echo "数据库主机：$DB_HOST"
else
    echo "❌ 缺少数据库主机配置"
fi

# 检查端口配置
if echo "$CONFIG" | grep -qE "^port=[0-9]+"; then
    PORT=$(echo "$CONFIG" | grep "^port=" | cut -d'=' -f2)
    echo "端口号：$PORT"
else
    echo "❌ 端口配置有误"
fi
```

### 3.3 变量搜索的实用函数


**封装常用搜索函数**：
```bash
#!/bin/bash

# 检查变量是否包含特定模式
contains_pattern() {
    local text="$1"
    local pattern="$2"
    
    if grep -q "$pattern" <<< "$text"; then
        return 0  # 找到了
    else
        return 1  # 没找到
    fi
}

# 从变量中提取匹配的行
extract_matching_lines() {
    local text="$1"
    local pattern="$2"
    
    echo "$text" | grep "$pattern"
}

# 统计变量中的匹配次数
count_matches() {
    local text="$1"
    local pattern="$2"
    
    echo "$text" | grep -c "$pattern"
}

# 使用示例
LOG_CONTENT=$(tail -100 /var/log/system.log)

if contains_pattern "$LOG_CONTENT" "CRITICAL"; then
    echo "发现严重错误！"
    echo "错误详情："
    extract_matching_lines "$LOG_CONTENT" "CRITICAL"
    
    CRITICAL_COUNT=$(count_matches "$LOG_CONTENT" "CRITICAL")
    echo "严重错误总数：$CRITICAL_COUNT"
fi
```

---

## 4. 📊 搜索结果处理


### 4.1 结果格式化输出


**美化搜索结果**：
```bash
#!/bin/bash

# 格式化日志搜索结果
format_log_search() {
    local log_file=$1
    local search_term=$2
    
    echo "===================="
    echo "搜索关键词: $search_term"
    echo "搜索文件: $log_file"
    echo "===================="
    
    # 搜索并添加行号和上下文
    grep -n -A 2 -B 1 --color=never "$search_term" "$log_file" | \
    while IFS= read -r line; do
        if [[ $line =~ ^[0-9]+-.*$ ]]; then
            # 匹配行，用★标记
            echo "★ $line"
        elif [[ $line =~ ^[0-9]+:.*$ ]]; then
            # 上下文行
            echo "  $line"
        else
            # 分隔符
            echo "  ---"
        fi
    done
}

# 使用示例
format_log_search "/var/log/system.log" "ERROR"
```

### 4.2 结果统计和分析


**统计分析功能**：
```bash
#!/bin/bash

# 综合日志分析函数
analyze_log_patterns() {
    local log_file=$1
    
    echo "📊 日志文件分析报告: $(basename $log_file)"
    echo "======================================="
    
    # 总行数
    TOTAL_LINES=$(wc -l < "$log_file")
    echo "📄 总行数: $TOTAL_LINES"
    
    # 错误统计
    ERROR_COUNT=$(grep -c -i "error" "$log_file" 2>/dev/null || echo "0")
    WARNING_COUNT=$(grep -c -i "warning" "$log_file" 2>/dev/null || echo "0")
    INFO_COUNT=$(grep -c -i "info" "$log_file" 2>/dev/null || echo "0")
    
    echo "❌ 错误数量: $ERROR_COUNT"
    echo "⚠️  警告数量: $WARNING_COUNT"
    echo "ℹ️  信息数量: $INFO_COUNT"
    
    # 计算比例
    if [ "$TOTAL_LINES" -gt 0 ]; then
        ERROR_PERCENT=$(( ERROR_COUNT * 100 / TOTAL_LINES ))
        echo "📈 错误率: ${ERROR_PERCENT}%"
    fi
    
    # 显示最常见的错误
    echo ""
    echo "🔍 最常见的错误类型:"
    grep -i "error" "$log_file" 2>/dev/null | \
    sed 's/.*error[: ]*//' | \
    head -20 | \
    sort | \
    uniq -c | \
    sort -nr | \
    head -5 | \
    awk '{print "   " $1 "次: " substr($0, index($0,$2))}'
}
```

### 4.3 结果导出和报告


**生成搜索报告**：
```bash
#!/bin/bash

# 生成搜索报告
generate_search_report() {
    local search_pattern=$1
    local target_files=("${@:2}")
    local report_file="search_report_$(date +%Y%m%d_%H%M%S).txt"
    
    {
        echo "🔍 搜索报告"
        echo "========================================="
        echo "搜索模式: $search_pattern"
        echo "搜索时间: $(date)"
        echo "搜索文件: ${target_files[*]}"
        echo ""
        
        local total_matches=0
        
        for file in "${target_files[@]}"; do
            if [[ -f "$file" ]]; then
                echo "📁 文件: $file"
                echo "---------"
                
                local file_matches=$(grep -c "$search_pattern" "$file" 2>/dev/null || echo "0")
                total_matches=$((total_matches + file_matches))
                
                echo "匹配数量: $file_matches"
                
                if [ "$file_matches" -gt 0 ]; then
                    echo "匹配内容:"
                    grep -n -H "$search_pattern" "$file" | head -10
                    
                    if [ "$file_matches" -gt 10 ]; then
                        echo "... (还有 $((file_matches - 10)) 条匹配)"
                    fi
                fi
                echo ""
            else
                echo "⚠️ 文件不存在: $file"
            fi
        done
        
        echo "========================================="
        echo "📊 总计匹配: $total_matches 条"
        
    } > "$report_file"
    
    echo "报告已生成: $report_file"
}

# 使用示例
generate_search_report "ERROR" "/var/log/system.log" "/var/log/application.log"
```

---

## 5. 🛡️ 错误处理机制


### 5.1 常见错误类型


**grep使用中的常见错误**：

| 错误类型 | 错误原因 | 解决方案 |
|---------|---------|---------|
| **文件不存在** | 指定的文件路径错误 | 先检查文件是否存在 |
| **权限不足** | 没有读取文件的权限 | 使用sudo或修改权限 |
| **正则表达式错误** | 正则语法不正确 | 验证正则表达式语法 |
| **字符编码问题** | 文件编码与系统不匹配 | 指定正确的编码格式 |

### 5.2 错误检测和处理


**健壮的错误处理**：
```bash
#!/bin/bash

# 安全的文件搜索函数
safe_grep() {
    local pattern=$1
    local file=$2
    local options=${3:-}
    
    # 检查参数
    if [[ -z "$pattern" ]]; then
        echo "错误: 搜索模式不能为空" >&2
        return 1
    fi
    
    if [[ -z "$file" ]]; then
        echo "错误: 文件名不能为空" >&2
        return 1
    fi
    
    # 检查文件存在性
    if [[ ! -f "$file" ]]; then
        echo "错误: 文件 '$file' 不存在" >&2
        return 1
    fi
    
    # 检查文件可读性
    if [[ ! -r "$file" ]]; then
        echo "错误: 文件 '$file' 无法读取" >&2
        return 1
    fi
    
    # 执行搜索，捕获错误
    local result
    local exit_code
    
    result=$(grep $options "$pattern" "$file" 2>&1)
    exit_code=$?
    
    case $exit_code in
        0)
            # 找到匹配
            echo "$result"
            return 0
            ;;
        1)
            # 没找到匹配，这不是错误
            return 1
            ;;
        2)
            # grep命令错误
            echo "grep命令错误: $result" >&2
            return 2
            ;;
        *)
            # 其他未知错误
            echo "未知错误(退出码: $exit_code): $result" >&2
            return $exit_code
            ;;
    esac
}
```

### 5.3 日志记录和调试


**调试和日志记录**：
```bash
#!/bin/bash

# 调试开关
DEBUG=${DEBUG:-false}

# 日志函数
log_message() {
    local level=$1
    local message=$2
    local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
    
    echo "[$timestamp] [$level] $message" >&2
    
    # 可选：写入日志文件
    if [[ -n "$LOG_FILE" ]]; then
        echo "[$timestamp] [$level] $message" >> "$LOG_FILE"
    fi
}

# 调试信息输出
debug_log() {
    if [[ "$DEBUG" == "true" ]]; then
        log_message "DEBUG" "$1"
    fi
}

# 带错误处理的搜索函数
robust_search() {
    local pattern=$1
    local file=$2
    
    debug_log "开始搜索: 模式='$pattern', 文件='$file'"
    
    # 验证输入
    if [[ -z "$pattern" ]] || [[ -z "$file" ]]; then
        log_message "ERROR" "参数不完整: pattern='$pattern', file='$file'"
        return 1
    fi
    
    # 执行搜索
    if grep -q "$pattern" "$file" 2>/dev/null; then
        debug_log "搜索成功，找到匹配"
        log_message "INFO" "在 $file 中找到了 '$pattern'"
        
        # 获取匹配数量
        local count=$(grep -c "$pattern" "$file" 2>/dev/null)
        log_message "INFO" "匹配数量: $count"
        
        return 0
    else
        local exit_code=$?
        if [[ $exit_code -eq 1 ]]; then
            debug_log "搜索完成，未找到匹配"
            log_message "INFO" "在 $file 中未找到 '$pattern'"
        else
            log_message "ERROR" "搜索过程中出现错误 (退出码: $exit_code)"
        fi
        return $exit_code
    fi
}

# 使用示例
DEBUG=true robust_search "ERROR" "/var/log/system.log"
```

---

## 6. ⚡ 脚本性能优化


### 6.1 性能优化原则


**grep性能优化的关键点**：

```
优化策略说明：

1. 减少数据量 → 先过滤再处理
2. 避免重复搜索 → 缓存搜索结果
3. 选择合适的grep选项 → 根据需求选择
4. 并行处理 → 利用多核CPU
5. 内存管理 → 避免处理过大文件
```

### 6.2 高效搜索技巧


**优化搜索性能**：
```bash
#!/bin/bash

# 高效的多文件搜索
efficient_multi_search() {
    local pattern=$1
    shift
    local files=("$@")
    
    # 检查文件数量，决定策略
    if [[ ${#files[@]} -gt 10 ]]; then
        echo "处理大量文件，使用批量搜索..."
        
        # 批量处理，避免过多的进程创建
        printf '%s\n' "${files[@]}" | \
        xargs -I {} -P 4 grep -l "$pattern" {} 2>/dev/null
    else
        echo "处理少量文件，使用单个grep命令..."
        
        # 单个grep命令处理所有文件
        grep -l "$pattern" "${files[@]}" 2>/dev/null
    fi
}

# 大文件的增量搜索
incremental_search() {
    local pattern=$1
    local large_file=$2
    local last_position_file="/tmp/grep_position_${RANDOM}"
    
    # 读取上次的位置
    local start_line=1
    if [[ -f "$last_position_file" ]]; then
        start_line=$(cat "$last_position_file")
    fi
    
    # 获取文件当前总行数
    local total_lines=$(wc -l < "$large_file")
    
    if [[ $total_lines -gt $start_line ]]; then
        echo "搜索新增内容 (从第 $start_line 行开始)..."
        
        # 只搜索新增的部分
        tail -n +$start_line "$large_file" | \
        grep -n "$pattern" | \
        while IFS=: read -r line_num content; do
            actual_line_num=$((start_line + line_num - 1))
            echo "$actual_line_num: $content"
        done
        
        # 更新位置记录
        echo $total_lines > "$last_position_file"
    else
        echo "文件没有新内容"
    fi
}
```

### 6.3 内存和CPU优化


**资源使用优化**：
```bash
#!/bin/bash

# 智能的搜索策略选择
smart_grep_strategy() {
    local pattern=$1
    local file=$2
    
    # 获取文件大小（MB）
    local file_size_mb=$(du -m "$file" 2>/dev/null | cut -f1)
    
    if [[ -z "$file_size_mb" ]]; then
        echo "无法获取文件大小" >&2
        return 1
    fi
    
    echo "文件大小: ${file_size_mb}MB"
    
    if [[ $file_size_mb -lt 10 ]]; then
        # 小文件：直接搜索
        echo "使用标准搜索策略"
        grep "$pattern" "$file"
        
    elif [[ $file_size_mb -lt 100 ]]; then
        # 中等文件：使用缓冲搜索
        echo "使用缓冲搜索策略"
        grep --line-buffered "$pattern" "$file"
        
    else
        # 大文件：分块处理
        echo "使用分块搜索策略"
        
        # 分块大小（行数）
        local chunk_size=10000
        local temp_dir="/tmp/grep_chunks_$$"
        mkdir -p "$temp_dir"
        
        # 分割文件
        split -l $chunk_size "$file" "$temp_dir/chunk_"
        
        # 并行搜索各个块
        for chunk in "$temp_dir"/chunk_*; do
            if [[ -f "$chunk" ]]; then
                grep -H "$pattern" "$chunk" &
            fi
        done
        
        # 等待所有后台任务完成
        wait
        
        # 清理临时文件
        rm -rf "$temp_dir"
    fi
}

# 内存监控函数
monitor_memory_usage() {
    local process_name=$1
    
    while true; do
        local memory_usage=$(ps aux | grep "$process_name" | grep -v grep | awk '{sum+=$6} END {print sum/1024}')
        
        if [[ -n "$memory_usage" && $(echo "$memory_usage > 500" | bc -l) -eq 1 ]]; then
            echo "⚠️ 内存使用过高: ${memory_usage}MB"
        fi
        
        sleep 5
    done
}
```

---

## 7. 🤖 自动化任务集成


### 7.1 定时任务集成


**cron任务中的grep应用**：
```bash
#!/bin/bash
# 文件名: log_monitor.sh

# 日志监控脚本 - 适合放入crontab

LOG_DIR="/var/log"
ALERT_EMAIL="admin@example.com"
TEMP_DIR="/tmp/log_alerts"

mkdir -p "$TEMP_DIR"

# 检查系统错误
check_system_errors() {
    local today=$(date '+%b %d')
    local error_count=0
    
    # 检查系统日志
    if [[ -f "/var/log/syslog" ]]; then
        error_count=$(grep "$today" /var/log/syslog | grep -ci "error\|critical\|fatal" || echo "0")
    fi
    
    if [[ $error_count -gt 10 ]]; then
        {
            echo "🚨 系统错误告警"
            echo "时间: $(date)"
            echo "错误数量: $error_count"
            echo ""
            echo "错误详情:"
            grep "$today" /var/log/syslog | grep -i "error\|critical\|fatal" | tail -10
        } > "$TEMP_DIR/system_errors.txt"
        
        # 发送邮件 (需要配置邮件系统)
        # mail -s "系统错误告警" "$ALERT_EMAIL" < "$TEMP_DIR/system_errors.txt"
        
        echo "发现系统错误 $error_count 个，已生成报告"
    else
        echo "系统日志正常，错误数量: $error_count"
    fi
}

# 检查磁盘空间告警
check_disk_alerts() {
    # 查找磁盘空间相关错误
    local disk_errors=$(grep -i "no space left\|disk full\|filesystem full" /var/log/syslog 2>/dev/null | wc -l)
    
    if [[ $disk_errors -gt 0 ]]; then
        echo "⚠️ 发现磁盘空间问题: $disk_errors 条"
        df -h > "$TEMP_DIR/disk_status.txt"
    fi
}

# 主执行逻辑
main() {
    echo "=== 日志监控开始 $(date) ==="
    
    check_system_errors
    check_disk_alerts
    
    echo "=== 日志监控结束 $(date) ==="
}

# 如果脚本被直接执行
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi

# crontab 设置示例:
# */10 * * * * /path/to/log_monitor.sh >> /var/log/monitor.log 2>&1
```

### 7.2 系统监控集成


**系统健康检查脚本**：
```bash
#!/bin/bash
# 综合系统监控脚本

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
CONFIG_FILE="$SCRIPT_DIR/monitor.conf"
REPORT_FILE="/tmp/system_health_$(date +%Y%m%d_%H%M%S).txt"

# 默认配置
DEFAULT_MAX_CPU=80
DEFAULT_MAX_MEM=85
DEFAULT_MAX_DISK=90

# 读取配置文件
load_config() {
    if [[ -f "$CONFIG_FILE" ]]; then
        source "$CONFIG_FILE"
    fi
    
    MAX_CPU=${MAX_CPU:-$DEFAULT_MAX_CPU}
    MAX_MEM=${MAX_MEM:-$DEFAULT_MAX_MEM}
    MAX_DISK=${MAX_DISK:-$DEFAULT_MAX_DISK}
}

# 检查CPU使用率
check_cpu() {
    local cpu_usage=$(top -bn1 | grep "Cpu(s)" | awk '{print $2}' | cut -d'%' -f1)
    cpu_usage=${cpu_usage%us}
    
    echo "🖥️ CPU使用率: ${cpu_usage}%"
    
    if (( $(echo "$cpu_usage > $MAX_CPU" | bc -l) )); then
        echo "⚠️ CPU使用率过高！"
        
        # 找出占用CPU最多的进程
        echo "CPU占用前5的进程:"
        ps aux --sort=-%cpu | head -6 | grep -v "PID"
        
        # 检查是否有异常进程
        if ps aux | grep -E "100\.0.*[^]]$" | grep -v grep > /dev/null; then
            echo "❌ 发现CPU占用100%的异常进程!"
            ps aux | grep -E "100\.0.*[^]]$" | grep -v grep
        fi
    fi
}

# 检查内存使用率
check_memory() {
    local mem_info=$(free | grep "Mem:")
    local total_mem=$(echo $mem_info | awk '{print $2}')
    local used_mem=$(echo $mem_info | awk '{print $3}')
    local mem_usage=$(( used_mem * 100 / total_mem ))
    
    echo "💾 内存使用率: ${mem_usage}%"
    
    if [[ $mem_usage -gt $MAX_MEM ]]; then
        echo "⚠️ 内存使用率过高！"
        
        # 显示内存占用前5的进程
        echo "内存占用前5的进程:"
        ps aux --sort=-%mem | head -6 | grep -v "PID"
        
        # 检查是否有内存泄漏的迹象
        echo "检查可能的内存泄漏进程:"
        ps aux --sort=-%mem | head -10 | grep -v "PID" | \
        while read line; do
            local process_mem=$(echo $line | awk '{print $6}')
            local process_name=$(echo $line | awk '{print $11}')
            
            # 如果单个进程占用超过1GB内存
            if [[ $process_mem -gt 1048576 ]]; then
                echo "  🚨 $process_name 占用 $(($process_mem/1024))MB 内存"
            fi
        done
    fi
}

# 检查磁盘使用率
check_disk() {
    echo "💽 磁盘使用情况:"
    
    df -h | grep -v "Filesystem" | while read line; do
        local usage=$(echo $line | awk '{print $5}' | cut -d'%' -f1)
        local mount_point=$(echo $line | awk '{print $6}')
        local filesystem=$(echo $line | awk '{print $1}')
        
        echo "  $mount_point: ${usage}%"
        
        if [[ $usage -gt $MAX_DISK ]]; then
            echo "  ⚠️ $mount_point 磁盘空间不足！"
            
            # 找出占用空间最大的目录
            echo "  占用空间最大的目录："
            du -sh "$mount_point"/* 2>/dev/null | sort -hr | head -5 | \
            while read size dir; do
                echo "    $size - $dir"
            done
        fi
    done
}

# 检查系统负载
check_load() {
    local load_avg=$(uptime | awk -F'load average:' '{print $2}')
    local cpu_cores=$(nproc)
    
    echo "📊 系统负载: $load_avg (CPU核数: $cpu_cores)"
    
    # 获取1分钟负载
    local load_1min=$(echo $load_avg | cut -d',' -f1 | tr -d ' ')
    
    # 如果负载超过CPU核数的2倍，认为过高
    if (( $(echo "$load_1min > $cpu_cores * 2" | bc -l) )); then
        echo "⚠️ 系统负载过高！"
        
        # 显示负载高的原因
        echo "当前活跃进程:"
        ps aux --sort=-%cpu | head -10 | grep -v "PID"
    fi
}

# 生成报告
generate_report() {
    {
        echo "🏥 系统健康检查报告"
        echo "======================="
        echo "检查时间: $(date)"
        echo "主机名: $(hostname)"
        echo "系统版本: $(cat /etc/os-release | grep "PRETTY_NAME" | cut -d'"' -f2)"
        echo "运行时间: $(uptime)"
        echo ""
        
        check_cpu
        echo ""
        check_memory  
        echo ""
        check_disk
        echo ""
        check_load
        echo ""
        
        echo "======================="
        echo "检查完成: $(date)"
        
    } | tee "$REPORT_FILE"
    
    echo "报告已保存到: $REPORT_FILE"
}

# 主函数
main() {
    load_config
    generate_report
    
    # 如果有严重问题，可以发送告警
    if grep -q "⚠️\|❌\|🚨" "$REPORT_FILE"; then
        echo "发现系统问题，建议检查报告"
        # 这里可以添加发送邮件或其他告警逻辑
    else
        echo "✅ 系统状态正常"
    fi
}

# 执行主函数
main "$@"
```

### 7.3 应用程序监控


**应用服务监控脚本**：
```bash
#!/bin/bash
# 应用程序监控和自动恢复脚本

# 配置区域
SERVICES=("nginx" "mysql" "redis" "php-fpm")
LOG_FILE="/var/log/service_monitor.log"
RESTART_THRESHOLD=3  # 3次检查失败后重启
NOTIFICATION_EMAIL="admin@example.com"

# 创建状态文件目录
STATUS_DIR="/tmp/service_status"
mkdir -p "$STATUS_DIR"

# 日志记录函数
log_event() {
    local message="$1"
    local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
    echo "[$timestamp] $message" | tee -a "$LOG_FILE"
}

# 检查服务状态
check_service_status() {
    local service_name=$1
    local status_file="$STATUS_DIR/${service_name}_status"
    
    log_event "检查服务: $service_name"
    
    # 检查进程是否运行
    if pgrep -f "$service_name" > /dev/null; then
        log_event "✅ $service_name 进程正在运行"
        
        # 重置失败计数
        echo "0" > "$status_file"
        
        # 额外的健康检查
        case "$service_name" in
            "nginx")
                check_nginx_health
                ;;
            "mysql")
                check_mysql_health
                ;;
            "redis")
                check_redis_health
                ;;
        esac
        
        return 0
    else
        log_event "❌ $service_name 进程未运行"
        
        # 增加失败计数
        local fail_count=0
        if [[ -f "$status_file" ]]; then
            fail_count=$(cat "$status_file")
        fi
        fail_count=$((fail_count + 1))
        echo "$fail_count" > "$status_file"
        
        log_event "$service_name 失败次数: $fail_count"
        
        # 如果失败次数达到阈值，尝试重启
        if [[ $fail_count -ge $RESTART_THRESHOLD ]]; then
            restart_service "$service_name"
        fi
        
        return 1
    fi
}

# Nginx健康检查
check_nginx_health() {
    # 检查配置文件语法
    if ! nginx -t 2>/dev/null; then
        log_event "⚠️ Nginx配置文件有语法错误"
        return 1
    fi
    
    # 检查端口监听
    if ! netstat -tlnp | grep -q ":80.*nginx"; then
        log_event "⚠️ Nginx未监听80端口"
        return 1
    fi
    
    # HTTP响应检查
    if command -v curl >/dev/null; then
        if ! curl -sf http://localhost/ > /dev/null; then
            log_event "⚠️ Nginx HTTP响应异常"
            return 1
        fi
    fi
    
    log_event "✅ Nginx健康检查通过"
    return 0
}

# MySQL健康检查
check_mysql_health() {
    # 检查MySQL连接
    if command -v mysql >/dev/null; then
        if ! mysql -e "SELECT 1;" 2>/dev/null; then
            log_event "⚠️ MySQL连接失败"
            return 1
        fi
    fi
    
    # 检查MySQL端口
    if ! netstat -tlnp | grep -q ":3306.*mysql"; then
        log_event "⚠️ MySQL未监听3306端口"
        return 1
    fi
    
    log_event "✅ MySQL健康检查通过"
    return 0
}

# Redis健康检查
check_redis_health() {
    # 检查Redis连接
    if command -v redis-cli >/dev/null; then
        if ! redis-cli ping 2>/dev/null | grep -q "PONG"; then
            log_event "⚠️ Redis连接失败"
            return 1
        fi
    fi
    
    log_event "✅ Redis健康检查通过"
    return 0
}

# 重启服务
restart_service() {
    local service_name=$1
    local status_file="$STATUS_DIR/${service_name}_status"
    
    log_event "🔄 正在重启服务: $service_name"
    
    # 使用systemctl重启服务
    if systemctl restart "$service_name" 2>/dev/null; then
        log_event "✅ $service_name 重启成功"
        
        # 等待几秒让服务完全启动
        sleep 5
        
        # 验证重启是否成功
        if pgrep -f "$service_name" > /dev/null; then
            log_event "✅ $service_name 重启后运行正常"
            echo "0" > "$status_file"
            
            # 发送成功通知
            send_notification "$service_name 已成功重启并运行正常"
        else
            log_event "❌ $service_name 重启后仍未运行"
            send_critical_notification "$service_name 重启失败，需要人工干预"
        fi
    else
        log_event "❌ $service_name 重启失败"
        send_critical_notification "$service_name 重启失败，需要人工干预"
    fi
}

# 发送通知
send_notification() {
    local message=$1
    log_event "📧 发送通知: $message"
    
    # 这里可以集成邮件、短信、钉钉等通知方式
    # echo "$message" | mail -s "服务监控通知" "$NOTIFICATION_EMAIL"
}

# 发送紧急通知
send_critical_notification() {
    local message=$1
    log_event "🚨 发送紧急通知: $message"
    
    # 紧急情况的通知，可能需要更紧急的通知方式
    # echo "紧急：$message" | mail -s "【紧急】服务监控告警" "$NOTIFICATION_EMAIL"
}

# 主监控循环
main_monitor() {
    log_event "🚀 开始服务监控"
    
    for service in "${SERVICES[@]}"; do
        check_service_status "$service"
        sleep 1  # 避免对系统造成过大压力
    done
    
    log_event "✅ 本轮监控检查完成"
}

# 清理旧状态文件
cleanup_old_status() {
    find "$STATUS_DIR" -name "*_status" -mtime +7 -delete
}

# 主入口
main() {
    case "${1:-monitor}" in
        "monitor")
            main_monitor
            ;;
        "cleanup")
            cleanup_old_status
            ;;
        "test")
            # 测试模式，只检查一次
            for service in "${SERVICES[@]}"; do
                check_service_status "$service"
            done
            ;;
        *)
            echo "用法: $0 [monitor|cleanup|test]"
            exit 1
            ;;
    esac
}

# 执行主函数
main "$@"

# 可以通过cron定期执行
# */5 * * * * /path/to/app_monitor.sh monitor
# 0 2 * * * /path/to/app_monitor.sh cleanup
```

---

## 8. 📋 核心要点总结


### 8.1 必须掌握的核心概念


```
🔸 条件判断：掌握grep的退出状态码，灵活运用if语句
🔸 管道组合：理解数据流处理，合理设计过滤链条
🔸 变量搜索：学会在脚本变量中搜索内容的方法
🔸 结果处理：美化输出，统计分析，生成报告
🔸 错误处理：预防常见错误，建立健壮的错误处理机制
🔸 性能优化：根据文件大小选择合适的搜索策略
🔸 自动化集成：将grep融入监控和定时任务系统
```

### 8.2 关键理解要点


**🔹 grep在脚本中的核心价值**
```
文本过滤器：从大量数据中提取关键信息
条件判断器：基于内容存在性做逻辑判断  
状态监测器：检查系统和应用程序状态
数据分析器：统计和分析文本内容
```

**🔹 脚本编程中的最佳实践**
```
输入验证：
- 检查文件存在性和可读性
- 验证搜索模式的合法性
- 处理特殊字符和编码问题

错误处理：
- 捕获和处理grep的不同退出状态
- 提供有意义的错误信息
- 实现优雅的降级处理

性能考虑：
- 先过滤后处理，减少数据量
- 合理使用grep选项
- 避免不必要的重复搜索
```

**🔹 实际应用中的设计原则**
```
模块化设计：将搜索逻辑封装成函数
可配置性：通过配置文件控制行为
可监控性：添加日志记录和状态报告
可维护性：代码清晰，注释完整
```

### 8.3 实际应用价值


- **系统运维**：日志分析、状态监控、故障诊断
- **自动化运维**：定时检查、自动告警、服务恢复
- **数据处理**：文本分析、内容过滤、格式转换
- **开发调试**：配置验证、错误检查、测试辅助

### 8.4 进阶学习方向


**🔸 高级应用场景**
- 结合其他Linux命令构建复杂的数据处理管道
- 集成到CI/CD流程中进行自动化测试和部署检查
- 构建实时日志监控和告警系统
- 开发智能化的系统健康检查工具

**🔸 扩展技能方向**
- 学习正则表达式的高级用法
- 掌握sed和awk的配合使用
- 了解大数据处理工具(如ElasticSearch)的日志分析
- 学习现代监控工具(如Prometheus)的集成

**核心记忆**：
- grep不仅是搜索工具，更是脚本编程的逻辑判断器
- 善用退出状态码，让grep成为条件判断的利器
- 合理设计管道，提高数据处理效率
- 完善错误处理，构建健壮的自动化系统