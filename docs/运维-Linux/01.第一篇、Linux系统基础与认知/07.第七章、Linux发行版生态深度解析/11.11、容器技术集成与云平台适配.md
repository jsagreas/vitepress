---
title: 11、容器技术集成与云平台适配
---
## 📚 目录

1. [容器技术基础与发行版集成](#1-容器技术基础与发行版集成)
2. [Docker与Podman预装配置差异](#2-Docker与Podman预装配置差异)
3. [容器运行时深度解析](#3-容器运行时深度解析)
4. [Kubernetes集成与优化策略](#4-Kubernetes集成与优化策略)
5. [云平台镜像适配机制](#5-云平台镜像适配机制)
6. [容器优化内核配置详解](#6-容器优化内核配置详解)
7. [微服务与边缘计算场景适配](#7-微服务与边缘计算场景适配)
8. [核心要点总结](#8-核心要点总结)

---

## 1. 🐳 容器技术基础与发行版集成


### 1.1 什么是容器技术


**通俗理解**：容器就像是一个**轻量级的"虚拟机"**，但比虚拟机更高效

```
传统部署方式：
物理服务器 → 操作系统 → 应用程序
问题：环境冲突、资源浪费、部署复杂

虚拟机方式：
物理服务器 → 宿主OS → 虚拟机(完整OS) → 应用程序
问题：资源开销大、启动慢

容器方式：
物理服务器 → 宿主OS → 容器引擎 → 容器(只包含应用) → 应用程序
优势：轻量、快速、资源利用率高
```

**容器的核心价值**：
- **环境一致性**：开发、测试、生产环境完全一致
- **快速部署**：秒级启动，比虚拟机快几十倍
- **资源高效**：共享宿主机内核，资源占用小
- **易于管理**：标准化的打包、分发、运行方式

### 1.2 Linux发行版与容器技术的关系


**为什么Linux是容器的最佳平台**：

```
Linux内核特性支持：
• Namespace：进程隔离（看不到其他进程）
• Cgroups：资源限制（CPU、内存、网络等）
• Union FS：分层文件系统（镜像分层存储）
• SELinux/AppArmor：安全控制

这些特性让容器能够：
安全隔离 + 资源控制 + 高效存储 = 完美的容器运行环境
```

**不同发行版的容器支持策略**：
- **Red Hat系（RHEL、CentOS、Fedora）**：重点推广Podman，强调无daemon架构
- **Ubuntu**：Docker和Podman并重，注重云原生集成
- **SUSE**：企业级容器解决方案，注重稳定性
- **Alpine Linux**：专为容器优化的轻量级发行版

---

## 2. 🔧 Docker与Podman预装配置差异


### 2.1 Docker与Podman的本质区别


**架构对比**：
```
Docker架构：
客户端 → Docker守护进程(root权限) → 容器

Docker CLI → dockerd (daemon) → containerd → runc → 容器
    ↓           ↓                ↓         ↓
   命令行    守护进程服务      运行时      容器进程

Podman架构：
客户端 → 直接管理容器（无守护进程）

Podman CLI → 直接调用 → runc → 容器
    ↓                    ↓       ↓
   命令行              运行时   容器进程
```

**核心差异解释**：
- **Docker**：有个"管家"守护进程，所有容器操作都通过它
- **Podman**：没有"管家"，直接管理容器，更安全

### 2.2 预装配置差异详解


**🔸 RHEL/CentOS 8+ 配置**
```bash
# 默认预装Podman，不预装Docker
# 查看预装状态
podman --version  # 通常已安装
docker --version  # 通常未安装

# Podman配置位置
/etc/containers/containers.conf     # 主配置文件
/etc/containers/registries.conf    # 镜像仓库配置
/etc/containers/storage.conf       # 存储配置

# 关键配置项
[engine]
runtime = "runc"                    # 容器运行时
events_logger = "journald"          # 日志系统集成
```

**🔸 Ubuntu配置**
```bash
# 默认两者都不预装，需要手动安装
# Docker安装
apt update
apt install docker.io

# Podman安装  
apt install podman

# Docker配置位置
/etc/docker/daemon.json             # Docker守护进程配置
/var/lib/docker/                    # Docker数据目录

# Ubuntu特有优化
{
  "storage-driver": "overlay2",      # 存储驱动
  "log-driver": "journald",          # 日志集成systemd
  "live-restore": true               # 守护进程重启不影响容器
}
```

### 2.3 命令兼容性与使用差异


**🔹 基本操作对比**
```bash
# 运行容器
docker run -d --name web nginx     # Docker方式
podman run -d --name web nginx     # Podman方式（命令几乎相同）

# 查看容器
docker ps                          # Docker方式
podman ps                          # Podman方式

# 关键差异：权限管理
docker run nginx                   # 需要root权限或加入docker组
podman run nginx                   # 普通用户即可运行（rootless）
```

**🔹 rootless容器的重要意义**
```
传统Docker问题：
• 守护进程需要root权限
• 安全风险：容器逃逸可能获得主机root权限
• 多用户环境复杂

Podman rootless优势：
• 普通用户直接运行容器
• 容器进程的用户就是宿主机用户
• 更安全：即使容器被攻破，攻击者也只是普通用户权限
```

---

## 3. ⚙️ 容器运行时深度解析


### 3.1 容器运行时的分层架构


**什么是容器运行时**：
容器运行时就是**真正负责启动和管理容器进程**的底层组件

```
容器技术分层架构：

    应用层               应用层
      ↓                   ↓
   Docker CLI          Podman CLI       ← 用户接口层
      ↓                   ↓
   dockerd              (无守护进程)     ← 管理层  
      ↓                   ↓
  containerd            conmon          ← 高级运行时
      ↓                   ↓  
    runc                runc            ← 低级运行时
      ↓                   ↓
   Linux内核           Linux内核        ← 系统层
```

### 3.2 containerd运行时详解


**containerd是什么**：
containerd是Docker公司开发的**高级容器运行时**，专门负责容器的生命周期管理

**🔸 containerd的核心功能**
```
镜像管理：
• 镜像拉取、存储、分发
• 镜像层的管理和优化
• 垃圾回收和清理

容器管理：
• 容器创建、启动、停止、删除
• 容器网络配置
• 存储卷挂载

运行时集成：
• 调用runc创建容器
• 监控容器状态
• 处理容器事件
```

**🔸 containerd配置示例**
```toml
# /etc/containerd/config.toml
version = 2

# 根目录配置
root = "/var/lib/containerd"
state = "/run/containerd"

# 运行时配置
[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc]
  runtime_type = "io.containerd.runc.v2"
  [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc.options]
    BinaryName = "runc"
```

### 3.3 CRI-O运行时详解


**CRI-O是什么**：
CRI-O是专门为**Kubernetes设计的容器运行时**，实现了Kubernetes的CRI（容器运行时接口）

**🔸 CRI-O的特点**
```
专为Kubernetes设计：
• 严格按照CRI接口规范实现
• 只包含Kubernetes需要的功能
• 更轻量、更安全

OCI标准支持：
• 完全兼容OCI容器格式
• 支持OCI运行时规范
• 可以运行Docker镜像
```

**🔸 containerd vs CRI-O对比**

| 特性对比 | **containerd** | **CRI-O** |
|---------|---------------|-----------|
| **设计目标** | 通用容器运行时 | 专为Kubernetes设计 |
| **功能范围** | 功能全面，支持多种用途 | 功能精简，专注K8s |
| **性能** | 稍重一些 | 更轻量 |
| **兼容性** | Docker生态兼容性好 | 严格OCI标准 |
| **维护者** | Docker公司 | Red Hat主导 |

### 3.4 运行时选择指导


**🎯 选择建议**
```
选择containerd的场景：
✅ 需要Docker兼容性
✅ 混合容器环境（Docker + K8s）
✅ 需要丰富的镜像管理功能
✅ 已有Docker工作流程

选择CRI-O的场景：
✅ 纯Kubernetes环境  
✅ 追求最小化安全攻击面
✅ 红帽生态环境
✅ 严格的安全合规要求
```

---

## 4. ☸️ Kubernetes集成与优化策略


### 4.1 Kubernetes与Linux发行版的深度集成


**什么是Kubernetes**：
Kubernetes（K8s）是**容器编排平台**，就像是管理大量容器的"指挥官"

```
没有Kubernetes的问题：
容器1  容器2  容器3  ... 容器100
  ↓     ↓      ↓         ↓
手动管理、手动扩展、手动恢复、手动负载均衡

有了Kubernetes：
     Kubernetes控制平面
           ↓
自动管理、自动扩展、自动恢复、自动负载均衡
```

### 4.2 发行版的K8s集成差异


**🔸 Red Hat OpenShift集成**
```bash
# RHEL/CentOS的企业级K8s发行版
# 预配置的安全策略
apiVersion: security.openshift.io/v1
kind: SecurityContextConstraints
metadata:
  name: restricted
spec:
  allowHostDirVolumePlugin: false
  allowHostPorts: false
  allowPrivilegedContainer: false
```

**优势**：
- **企业级安全**：内置安全策略和审计
- **运维友好**：Web控制台和自动化运维
- **生态完整**：从操作系统到应用的完整堆栈

**🔸 Ubuntu Canonical K8s**
```bash
# 通过snap安装，简化部署
sudo snap install microk8s --classic

# 内置常用插件
microk8s enable dns dashboard ingress
```

**优势**：
- **部署简单**：一键安装和配置
- **插件丰富**：开箱即用的常用功能
- **社区活跃**：丰富的社区资源

### 4.3 容器网络优化


**什么是容器网络**：
容器网络解决**容器之间如何通信**的问题

```
容器网络的挑战：
容器A(IP: 172.17.0.2) ←→ 容器B(IP: 172.17.0.3)
                ↓
        如何高效、安全地通信？

解决方案：
• CNI (Container Network Interface) - 网络接口标准
• 各种网络插件：Flannel、Calico、Weave等
```

**🔸 主流网络插件对比**

| 网络插件 | **实现方式** | **性能** | **功能特点** | **适用场景** |
|---------|-------------|---------|-------------|-------------|
| **Flannel** | VXLAN隧道 | 中等 | 简单易用 | 小规模集群 |
| **Calico** | BGP路由 | 高 | 网络策略丰富 | 大规模、安全要求高 |
| **Weave** | 网格网络 | 中等 | 自动发现 | 混合云环境 |

**🔸 网络优化配置示例**
```yaml
# Calico网络策略示例
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: deny-all
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress
  # 默认拒绝所有流量，只允许显式授权的通信
```

### 4.4 存储集成优化


**容器存储的挑战**：
容器是**临时的**，但数据需要**持久化**

```
存储层次：
临时存储 → 容器删除时数据丢失
卷存储   → 数据保留，但绑定到特定节点  
持久卷   → 数据保留，可在集群中移动
```

**🔸 存储解决方案**
```yaml
# 持久卷声明示例
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mysql-pvc
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
  storageClassName: fast-ssd
```

---

## 5. ☁️ 云平台镜像适配机制


### 5.1 云平台适配的核心需求


**为什么需要云平台适配**：
云平台有**自己的特殊要求**，标准Linux镜像无法直接完美运行

```
云平台的特殊需求：
🔸 动态配置：IP地址、主机名、用户信息等需要动态获取
🔸 监控集成：需要与云平台监控系统对接
🔸 安全合规：符合云平台的安全策略
🔸 性能优化：针对云平台硬件特性优化
🔸 服务集成：与云平台其他服务（负载均衡、存储等）集成
```

### 5.2 cloud-init配置详解


**什么是cloud-init**：
cloud-init是**云平台的"开机自动配置工具"**，类似于传统的开机启动脚本，但更智能

**🔸 cloud-init工作流程**
```
虚拟机启动流程：
1. 虚拟机启动 → BIOS/UEFI → 加载操作系统
                     ↓
2. cloud-init启动 → 从云平台获取元数据
                     ↓  
3. 应用配置 → 网络、用户、软件包、脚本等
                     ↓
4. 系统就绪 → 开始提供服务
```

**🔸 cloud-init配置示例**
```yaml
# /etc/cloud/cloud.cfg
# 基础系统配置
users:
  - name: ubuntu
    sudo: ALL=(ALL) NOPASSWD:ALL
    ssh_authorized_keys:
      - ssh-rsa AAAAB3NzaC1yc2E... # 公钥

# 软件包管理
packages:
  - docker.io
  - kubernetes-node

# 服务启动
runcmd:
  - systemctl start docker
  - systemctl enable docker
```

### 5.3 主要云平台适配差异


**🔸 AWS适配特性**
```bash
# AWS特有的元数据服务
curl http://169.254.169.254/latest/meta-data/instance-id
curl http://169.254.169.254/latest/meta-data/public-ipv4

# AWS专用工具预装
awscli                    # AWS命令行工具
amazon-ssm-agent         # 系统管理代理
amazon-cloudwatch-agent  # 监控代理

# 存储优化
# 自动检测和配置EBS卷
# 支持实例存储优化
```

**🔸 Azure适配特性**  
```bash
# Azure元数据服务
curl -H "Metadata: true" \
  "http://169.254.169.254/metadata/instance?api-version=2021-02-01"

# Azure专用工具
walinuxagent            # Azure Linux代理
azure-cli              # Azure命令行工具

# 网络优化
# 加速网络支持(SR-IOV)
# Azure负载均衡器集成
```

**🔸 GCP适配特性**
```bash
# GCP元数据服务  
curl "http://metadata.google.internal/computeMetadata/v1/instance/name" \
  -H "Metadata-Flavor: Google"

# GCP专用工具
google-cloud-sdk        # Google Cloud SDK
google-compute-engine   # 计算引擎工具

# 特色功能
# 抢占式实例支持
# 自定义机器类型优化
```

### 5.4 多云适配策略


**🎯 镜像构建最佳实践**
```bash
# 基础镜像构建脚本
#!/bin/bash
# 通用云平台适配

# 安装cloud-init
apt-get update
apt-get install -y cloud-init

# 配置cloud-init支持多云平台
cat > /etc/cloud/cloud.cfg << EOF
datasource_list: [
  'ConfigDrive',    # OpenStack
  'Ec2',            # AWS  
  'Azure',          # Microsoft Azure
  'GCE',            # Google Cloud
  'None'            # 本地配置
]
EOF

# 清理缓存，准备镜像
cloud-init clean
rm -rf /var/lib/cloud/*
```

---

## 6. 🔧 容器优化内核配置详解


### 6.1 容器对内核的特殊需求


**为什么需要内核优化**：
容器虽然共享内核，但对内核有**特殊的性能和安全要求**

```
容器场景的内核压力：
🔸 大量进程：一台主机可能运行数百个容器
🔸 频繁创建销毁：容器生命周期短，创建销毁频繁
🔸 网络密集：容器间网络通信多
🔸 存储密集：镜像分层、卷挂载等存储操作多
🔸 安全隔离：需要强隔离但不能影响性能
```

### 6.2 关键内核参数优化


**🔸 进程和内存优化**
```bash
# /etc/sysctl.d/99-container-optimize.conf

# 进程优化
kernel.pid_max = 4194304              # 增大最大进程数
kernel.threads-max = 2097152          # 增大最大线程数

# 内存优化  
vm.max_map_count = 655360            # 增大内存映射数量(Elasticsearch等需要)
vm.swappiness = 1                    # 减少swap使用，容器环境优先使用内存
vm.overcommit_memory = 1             # 允许内存过量分配

# 文件句柄优化
fs.file-max = 2097152                # 增大最大文件句柄数
fs.nr_open = 2097152                 # 增大进程最大打开文件数
```

**为什么需要这些优化**：
```
解释每个参数的意义：

kernel.pid_max：
• 默认值通常是32768，容器场景可能不够用
• 每个容器都是独立进程，大规模部署需要更多PID

vm.max_map_count：
• Elasticsearch、MongoDB等应用需要大量内存映射
• 默认值65530可能导致应用启动失败

fs.file-max：
• 容器应用通常需要大量网络连接和文件操作
• 增大限制避免"too many open files"错误
```

**🔸 网络优化参数**
```bash
# 网络连接优化
net.core.somaxconn = 32768              # 增大socket监听队列
net.ipv4.tcp_max_syn_backlog = 8192     # 增大SYN队列长度
net.core.netdev_max_backlog = 16384     # 增大网络设备接收队列

# TCP优化
net.ipv4.tcp_fin_timeout = 30           # 减少FIN等待时间
net.ipv4.tcp_keepalive_time = 120       # TCP保活时间
net.ipv4.tcp_tw_reuse = 1               # 允许TIME_WAIT重用

# 缓冲区优化
net.core.rmem_max = 16777216            # 接收缓冲区最大值
net.core.wmem_max = 16777216            # 发送缓冲区最大值
```

### 6.3 cgroups配置优化


**什么是cgroups**：
cgroups是Linux内核的**资源控制机制**，让容器能够限制和监控资源使用

```
cgroups的作用：
没有cgroups → 容器可以无限制使用主机资源
有了cgroups → 每个容器都有资源"配额"

资源类型：
• CPU：限制CPU使用率和时间片
• Memory：限制内存使用量
• Block I/O：限制磁盘读写速度  
• Network：限制网络带宽（需要额外工具）
```

**🔸 cgroups v2配置**
```bash
# 启用cgroups v2（现代Linux发行版推荐）
# 编辑 /etc/default/grub
GRUB_CMDLINE_LINUX="systemd.unified_cgroup_hierarchy=1"

# 更新grub配置
update-grub
reboot

# 验证cgroups v2启用
mount | grep cgroup2
# 应该看到：cgroup2 on /sys/fs/cgroup type cgroup2
```

### 6.4 安全增强配置


**🔸 Namespace隔离优化**
```bash
# 用户命名空间支持
echo 1 > /proc/sys/kernel/unprivileged_userns_clone

# 网络命名空间优化
# 增加网络命名空间数量限制
echo 1024 > /proc/sys/user/max_net_namespaces
```

**🔸 SELinux/AppArmor集成**
```bash
# RHEL/CentOS: SELinux容器策略
setsebool -P container_manage_cgroup on
setsebool -P virt_use_fusefs on

# Ubuntu: AppArmor容器配置
aa-status | grep docker    # 检查Docker相关配置文件
```

---

## 7. 🚀 微服务与边缘计算场景适配


### 7.1 微服务架构支持特性


**什么是微服务**：
微服务就是把**一个大应用拆分成很多小服务**，每个服务独立部署和扩展

```
传统单体应用：
    大应用
  ┌─────────┐
  │用户管理  │
  │订单处理  │  ← 所有功能打包在一起
  │支付系统  │
  │商品管理  │
  └─────────┘

微服务架构：
用户服务  订单服务  支付服务  商品服务
┌─────┐  ┌─────┐  ┌─────┐  ┌─────┐
│ 用户 │  │ 订单 │  │ 支付 │  │ 商品 │ ← 每个功能独立服务
│ 管理 │  │ 处理 │  │ 系统 │  │ 管理 │
└─────┘  └─────┘  └─────┘  └─────┘
```

### 7.2 服务发现与负载均衡


**服务发现的问题**：
微服务环境中，**服务的IP地址经常变化**，如何找到需要调用的服务？

**🔸 服务发现解决方案**
```yaml
# Consul服务发现配置
services:
  - name: "user-service"
    port: 8080
    check:
      http: "http://localhost:8080/health"
      interval: "10s"
    
  - name: "order-service"  
    port: 8081
    check:
      http: "http://localhost:8081/health"
      interval: "10s"
```

**🔸 负载均衡策略**
```nginx
# Nginx负载均衡配置
upstream user-service {
    least_conn;                    # 最少连接算法
    server user-service-1:8080;
    server user-service-2:8080;
    server user-service-3:8080;
}

server {
    listen 80;
    location /api/user/ {
        proxy_pass http://user-service;
        proxy_set_header Host $host;
    }
}
```

### 7.3 边缘计算场景适配


**什么是边缘计算**：
边缘计算就是把**计算能力放到离用户更近的地方**，减少延迟，提高响应速度

```
传统云计算架构：
用户设备 → 网络 → 远程数据中心 → 处理 → 返回结果
问题：延迟高、带宽消耗大

边缘计算架构：  
用户设备 → 边缘节点（本地处理） → 必要时连接云端
优势：延迟低、带宽节省、离线可用
```

**🔸 边缘计算的特殊挑战**
```
边缘环境特点：
• 硬件资源受限（CPU、内存、存储都比云端少）
• 网络不稳定（可能间歇性断网）  
• 维护困难（人员无法随时到达）
• 环境恶劣（温度、湿度、灰尘等）

对Linux发行版的要求：
• 轻量化：占用资源少
• 稳定性：长时间无人值守运行
• 自修复：网络恢复后自动同步
• 安全性：防止物理和网络攻击
```

### 7.4 边缘优化配置


**🔸 资源优化配置**
```bash
# 边缘节点系统优化
# 禁用不必要服务
systemctl disable bluetooth
systemctl disable cups
systemctl disable avahi-daemon

# 内存优化
echo 'vm.swappiness=10' >> /etc/sysctl.conf  # 减少swap使用
echo 'vm.vfs_cache_pressure=50' >> /etc/sysctl.conf  # 减少缓存压力

# 存储优化 - 使用压缩
echo 'compress=lzo' >> /etc/fstab  # 文件系统压缩
```

**🔸 离线运行支持**
```yaml
# 边缘节点容器配置
apiVersion: v1
kind: Pod  
spec:
  restartPolicy: Always
  containers:
  - name: edge-app
    image: my-edge-app:latest
    imagePullPolicy: IfNotPresent    # 优先使用本地镜像
    resources:
      limits:
        cpu: "0.5"                   # 限制CPU使用
        memory: "256Mi"              # 限制内存使用
      requests:
        cpu: "0.1" 
        memory: "128Mi"
```

**🔸 数据同步策略**
```bash
# 边缘数据同步脚本
#!/bin/bash
# 当网络恢复时自动同步数据

check_network() {
    ping -c 1 cloud-server.com > /dev/null 2>&1
    return $?
}

sync_data() {
    rsync -av --compress /local/data/ \
          cloud-server.com:/backup/edge-node-01/
}

# 每5分钟检查一次网络，有网络时同步
while true; do
    if check_network; then
        echo "网络可用，开始同步数据..."
        sync_data
        echo "数据同步完成"
    else
        echo "网络不可用，稍后重试"
    fi
    sleep 300  # 等待5分钟
done
```

---

## 8. 📋 核心要点总结


### 8.1 必须掌握的核心概念


```
🔸 容器技术本质：轻量级虚拟化，共享内核，进程级隔离
🔸 Docker vs Podman：有daemon vs 无daemon，root vs rootless
🔸 容器运行时：containerd（通用）vs CRI-O（专为K8s）
🔸 Kubernetes集成：容器编排平台，自动化管理大规模容器
🔸 云平台适配：cloud-init自动配置，元数据服务，多云兼容
🔸 内核优化：cgroups资源控制，网络参数调优，安全隔离
🔸 微服务支持：服务发现、负载均衡、分布式架构
🔸 边缘计算：资源受限、离线运行、数据同步
```

### 8.2 关键理解要点


**🔹 容器技术的价值**
```
解决的核心问题：
• "在我机器上可以运行" → 环境一致性
• "部署太复杂" → 标准化打包
• "资源浪费" → 轻量化虚拟化
• "扩展困难" → 弹性伸缩
```

**🔹 不同发行版的策略差异**
```
Red Hat系：
• 推广Podman（安全第一）
• 企业级OpenShift（完整解决方案）
• 严格的安全策略

Ubuntu系：
• 拥抱开源生态（Docker + K8s）
• 简化部署体验（snap安装）
• 云原生友好

选择原则：
• 企业环境 → Red Hat系
• 开发测试 → Ubuntu系  
• 特殊需求 → 专业发行版
```

**🔹 云原生的发展趋势**
```
技术演进路径：
物理机 → 虚拟机 → 容器 → 无服务器
↓        ↓       ↓      ↓
资源利用率逐步提升，管理复杂度逐步降低

未来方向：
• 更轻量的容器运行时
• 更智能的资源调度
• 更完善的安全隔离
• 更简单的开发体验
```

### 8.3 实际应用指导


**🎯 技术选型建议**
```
小团队/初学者：
• Docker + Docker Compose
• 简单直观，学习成本低

中等规模团队：
• Kubernetes + containerd
• 功能完整，生态丰富

大型企业：
• OpenShift + CRI-O
• 企业级特性，安全合规

边缘场景：
• K3s + Podman
• 轻量化，资源友好
```

**🔧 部署最佳实践**
```
安全第一：
✅ 使用rootless容器
✅ 启用SELinux/AppArmor
✅ 定期更新基础镜像
✅ 扫描镜像漏洞

性能优化：
✅ 调优内核参数
✅ 使用合适的网络插件
✅ 配置资源限制
✅ 监控系统指标

运维友好：
✅ 标准化镜像构建
✅ 自动化部署流程  
✅ 完善监控告警
✅ 备份恢复策略
```

**核心记忆口诀**：
- 容器轻量化，进程隔离化，部署标准化
- Docker有daemon，Podman更安全，运行时要选好
- K8s做编排，云平台要适配，边缘要优化
- 内核调参数，网络要配置，安全不能少