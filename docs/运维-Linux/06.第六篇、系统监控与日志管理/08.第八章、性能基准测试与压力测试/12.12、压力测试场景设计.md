---
title: 12、压力测试场景设计
---
## 📚 目录

1. [压力测试基础概念](#1-压力测试基础概念)
2. [压力测试场景分类](#2-压力测试场景分类)
3. [正常负载压力测试](#3-正常负载压力测试)
4. [峰值负载压力测试](#4-峰值负载压力测试)
5. [极限负载破坏性测试](#5-极限负载破坏性测试)
6. [渐增负载测试](#6-渐增负载测试)
7. [突发负载测试](#7-突发负载测试)
8. [长时间持续压力测试](#8-长时间持续压力测试)
9. [故障注入压力测试](#9-故障注入压力测试)
10. [核心要点总结](#10-核心要点总结)

---

## 1. 🎯 压力测试基础概念


### 1.1 什么是压力测试


**通俗理解**：压力测试就像给汽车做极限测试一样，看看在各种恶劣条件下，你的Linux系统能承受多大的负荷。

> 📖 **核心定义**
> 压力测试是通过给系统施加超出正常工作范围的负载，来检验系统在极限条件下的稳定性、可靠性和性能表现的测试方法。

### 1.2 为什么要做压力测试


**实际意义**：
- **发现性能瓶颈**：找出系统的薄弱环节
- **验证系统极限**：确定系统能承受的最大负载
- **预防生产故障**：提前发现可能的问题点
- **优化资源配置**：合理分配硬件资源

### 1.3 压力测试的核心要素


```
┌─────────────────────────────────────────┐
│              压力测试体系               │
├─────────────────┬───────────────────────┤
│   测试对象      │   系统资源            │
│   ─────────     │   ─────────           │
│   • CPU         │   • 内存              │
│   • 内存        │   • 磁盘I/O           │
│   • 磁盘        │   • 网络I/O           │
│   • 网络        │   • 进程/线程         │
├─────────────────┼───────────────────────┤
│   测试工具      │   监控指标            │
│   ─────────     │   ─────────           │
│   • stress      │   • 响应时间          │
│   • stress-ng   │   • 吞吐量            │
│   • sysbench    │   • 资源利用率        │
│   • ab/wrk      │   • 错误率            │
└─────────────────┴───────────────────────┘
```

---

## 2. 📊 压力测试场景分类


### 2.1 按负载强度分类


```
负载强度等级：

🟢 轻度负载 (0-30%)
   └── 日常运维操作
   
🟡 中度负载 (30-70%)
   └── 业务高峰期
   
🟠 重度负载 (70-90%)
   └── 突发流量冲击
   
🔴 极限负载 (90-100%)
   └── 系统承受极限
```

### 2.2 按测试目的分类


| 测试类型 | **主要目的** | **适用场景** | **关注指标** |
|---------|-------------|-------------|-------------|
| 🎯 **功能验证** | `确认基本功能正常` | `新系统上线前` | `功能完整性、正确性` |
| ⚡ **性能基准** | `建立性能基准线` | `系统优化对比` | `响应时间、吞吐量` |
| 🚀 **容量规划** | `确定系统容量上限` | `硬件采购决策` | `最大并发、资源使用率` |
| 🛡️ **稳定性验证** | `长期运行稳定性` | `生产环境部署` | `内存泄漏、系统稳定性` |

### 2.3 测试场景设计原则


**① 渐进式原则**
```
测试强度递增：
轻载 → 中载 → 重载 → 极限载
   ↓      ↓      ↓       ↓
 基准   目标   峰值   破坏点
```

**② 真实性原则**
- 模拟真实的业务场景
- 使用真实的数据量级
- 考虑实际的用户行为模式

**③ 可控性原则**
- 能够精确控制测试参数
- 可以随时停止测试
- 具备完整的监控和日志

---

## 3. 🔄 正常负载压力测试


### 3.1 测试目标与特点


**测试目标**：验证系统在正常工作负载下的性能表现，建立性能基准线。

**负载特点**：
- **负载强度**：30-50% 系统资源利用率
- **持续时间**：1-4小时
- **并发模式**：稳定的并发量
- **业务场景**：典型的日常业务操作

### 3.2 CPU正常负载测试


```bash
# 模拟正常CPU负载 (50%利用率)
stress --cpu 2 --timeout 3600s

# 监控CPU使用情况
top -p $(pgrep stress)
```

**测试步骤**：
1. **基线测量**：记录空闲状态下的系统指标
2. **施加负载**：启动适中强度的CPU压力
3. **持续监控**：观察系统响应和稳定性
4. **结果分析**：对比基线数据，评估性能

### 3.3 内存正常负载测试


**概念说明**：内存压力测试是指逐步增加内存使用量，观察系统在不同内存占用率下的表现。

```bash
# 占用1GB内存，持续30分钟
stress --vm 1 --vm-bytes 1G --timeout 1800s

# 查看内存使用情况
free -h && vmstat 1 5
```

### 3.4 磁盘I/O正常负载测试


```bash
# 持续的磁盘读写操作
stress --io 2 --hdd 1 --hdd-bytes 1G --timeout 3600s

# 监控磁盘I/O
iostat -x 1
```

**关键指标**：
- **IOPS**：每秒输入输出操作数
- **吞吐量**：每秒传输的数据量
- **延迟**：I/O操作的响应时间
- **队列深度**：等待处理的I/O请求数量

---

## 4. 🚀 峰值负载压力测试


### 4.1 峰值负载的定义


**通俗解释**：峰值负载就像商场在黑色星期五那天的人流量，是系统在特定时间段内需要处理的最高负载量。

> 💡 **峰值负载特征**
> - 负载强度：70-85% 系统资源利用率
> - 出现频率：周期性出现（如每日高峰、月末结算）
> - 持续时间：通常几十分钟到几小时
> - 业务影响：直接影响用户体验和业务收入

### 4.2 CPU峰值负载测试


```bash
# 高强度CPU压力测试
stress-ng --cpu 0 --cpu-load 80 --timeout 2h
```

**测试要点**：
- **并发数设置**：通常设为CPU核心数的1.5-2倍
- **负载强度**：维持在80%左右的CPU利用率
- **持续时间**：模拟真实峰值时长

### 4.3 内存峰值负载测试


**测试场景设计**：
```
内存使用策略：
┌─────────────────────────────────────┐
│  阶段1: 快速申请 (0-15分钟)          │
│  ├─ 申请到物理内存的80%             │
│  └─ 模拟系统启动后的内存占用         │
├─────────────────────────────────────┤
│  阶段2: 持续使用 (15-90分钟)        │
│  ├─ 维持80%内存使用率              │
│  └─ 观察系统swap使用情况           │
├─────────────────────────────────────┤
│  阶段3: 释放观察 (90-120分钟)       │
│  ├─ 逐步释放内存                   │
│  └─ 验证内存回收机制               │
└─────────────────────────────────────┘
```

```bash
# 占用系统80%内存
TOTAL_MEM=$(free -b | awk 'NR==2{print $2}')
TARGET_MEM=$((TOTAL_MEM * 80 / 100))
stress --vm 1 --vm-bytes ${TARGET_MEM} --timeout 7200s
```

### 4.4 综合峰值负载测试


**真实场景模拟**：
```bash
# 模拟Web服务器峰值负载
stress-ng --cpu 4 --io 2 --vm 2 --vm-bytes 2G --timeout 3600s &

# 同时进行网络压力测试
ab -n 10000 -c 100 http://localhost/
```

---

## 5. ⚠️ 极限负载破坏性测试


### 5.1 破坏性测试的含义


**概念解释**：破坏性测试就像测试一根钢筋能承受多大的拉力一样，我们要找到系统的"断裂点"。

> ⚠️ **重要提醒**
> 破坏性测试可能导致系统崩溃、数据丢失或服务中断，必须在隔离的测试环境中进行，绝不能在生产环境执行！

### 5.2 CPU极限负载测试


**测试目标**：找到CPU的绝对性能极限，观察系统在CPU资源耗尽时的行为。

```bash
# CPU满负载压力测试
stress-ng --cpu 0 --cpu-load 100 --timeout 1800s

# 监控系统负载和响应性
while true; do
    echo "Load: $(uptime | awk '{print $10,$11,$12}')"
    echo "Response: $(time ls > /dev/null 2>&1)"
    sleep 5
done
```

**观察重点**：
- **系统负载**：load average超过CPU核心数多少倍
- **响应延迟**：简单命令的执行时间
- **进程调度**：进程切换的频率和效率

### 5.3 内存极限破坏测试


**测试策略**：
```
内存耗尽测试流程：
   可用内存
        ↓
   ┌─────────────┐
   │ 90%内存占用 │ ← 观察swap开始使用
   ├─────────────┤
   │ 95%内存占用 │ ← 系统开始变慢  
   ├─────────────┤
   │ 99%内存占用 │ ← 系统严重卡顿
   ├─────────────┤
   │ 内存耗尽    │ ← OOM Killer启动
   └─────────────┘
        ↓
   系统保护机制
```

```bash
# 逐步消耗所有可用内存
stress-ng --vm 1 --vm-bytes $(free -b | awk 'NR==2{print $7}') --vm-keep
```

### 5.4 磁盘I/O极限测试


```bash
# 极限磁盘I/O压力
stress-ng --io 10 --hdd 5 --hdd-bytes 10G --timeout 3600s

# 填满磁盘空间测试
dd if=/dev/zero of=/tmp/fillup bs=1M
```

**系统保护机制观察**：
- **I/O调度策略**：系统如何处理大量I/O请求
- **磁盘满处理**：文件系统满时的系统行为
- **性能恢复**：压力解除后的恢复时间

---

## 6. 📈 渐增负载测试


### 6.1 渐增测试的价值


**核心思想**：像爬山一样一步步增加负载，找到系统性能的"拐点"。

**测试价值**：
- **性能拐点识别**：找到性能急剧下降的临界点
- **容量规划**：为系统扩容提供数据支撑
- **瓶颈定位**：确定首先出现瓶颈的资源类型

### 6.2 CPU渐增负载测试设计


```
CPU负载递增策略：
时间轴：  0    15   30   45   60   75   90分钟
        │    │    │    │    │    │    │
负载：   20%  40%  60%  70%  80%  90%  95%
        │    │    │    │    │    │    │
监控：   ✓    ✓    ✓    ✓    ✓    ✓    ✓
         │    │    │    │    │    │    │
        正常  正常  轻微  明显  严重  极限  ？
                   延迟  延迟  延迟  状态
```

**实现脚本**：
```bash
#!/bin/bash
# CPU渐增负载测试脚本

for load in 20 40 60 70 80 90 95; do
    echo "开始 ${load}% CPU负载测试..."
    stress-ng --cpu 0 --cpu-load ${load} --timeout 900s &
    
    # 记录性能指标
    echo "时间: $(date), 负载: ${load}%" >> cpu_test.log
    uptime >> cpu_test.log
    
    wait
    sleep 60  # 恢复间隔
done
```

### 6.3 内存渐增负载测试


**分阶段内存测试**：
```bash
#!/bin/bash
# 内存渐增测试

TOTAL_MEM=$(free -b | awk 'NR==2{print $2}')

for percent in 30 50 70 80 85 90 95; do
    TARGET=$((TOTAL_MEM * percent / 100))
    echo "内存使用率: ${percent}% ($(numfmt --to=iec ${TARGET}))"
    
    stress --vm 1 --vm-bytes ${TARGET} --timeout 600s &
    
    # 监控内存和swap使用情况
    free -h
    cat /proc/meminfo | grep -E "MemAvailable|SwapTotal|SwapFree"
    
    wait
    sleep 120  # 让系统恢复
done
```

### 6.4 综合资源渐增测试


**多维度压力递增**：
```
综合压力测试矩阵：
         CPU    内存    磁盘I/O   网络I/O
阶段1:   30%    40%     低        低
阶段2:   50%    60%     中        中  
阶段3:   70%    75%     高        高
阶段4:   85%    85%     极高      极高
阶段5:   95%    95%     极限      极限
```

---

## 7. ⚡ 突发负载测试


### 7.1 突发负载的特征


**生活类比**：突发负载就像突然有大批游客涌入景区，系统需要在很短时间内处理平时数倍的请求量。

**突发负载特点**：
- **瞬间爆发**：负载在几秒到几分钟内从低到高
- **短时持续**：通常持续几分钟到几十分钟
- **不可预知**：往往没有预警时间
- **影响巨大**：可能导致系统瞬间瘫痪

### 7.2 CPU突发负载模拟


```bash
# 模拟CPU突发负载
echo "准备CPU突发测试..."
sleep 5

# 瞬间启动高强度CPU压力
stress-ng --cpu 0 --cpu-load 95 --timeout 300s &

# 监控系统响应时间
for i in {1..60}; do
    start_time=$(date +%s.%N)
    ls > /dev/null 2>&1
    end_time=$(date +%s.%N)
    response_time=$(echo "$end_time - $start_time" | bc)
    echo "第${i}秒响应时间: ${response_time}秒"
    sleep 1
done
```

### 7.3 内存突发负载测试


**快速内存消耗**：
```bash
#!/bin/bash
# 模拟内存突发占用

echo "系统当前内存状态:"
free -h

echo "3秒后开始内存突发测试..."
sleep 3

# 快速消耗大量内存
BURST_MEM="4G"
echo "瞬间申请 ${BURST_MEM} 内存"
stress --vm 1 --vm-bytes ${BURST_MEM} --timeout 600s &

# 监控内存变化
for i in {1..30}; do
    echo "第${i}秒: $(free -h | grep Mem)"
    sleep 1
done
```

### 7.4 网络突发负载测试


**高并发连接突发**：
```bash
# 使用ab工具模拟突发网络请求
ab -n 5000 -c 200 -t 60 http://localhost/

# 使用wrk模拟更真实的突发场景
wrk -t 10 -c 200 -d 60s --latency http://localhost/
```

**突发测试关键指标**：
- **响应时间激增**：从毫秒级到秒级的变化
- **系统负载飙升**：load average的瞬间变化
- **错误率增加**：连接失败、超时等错误
- **恢复时间**：负载结束后系统恢复正常的时间

---

## 8. ⏰ 长时间持续压力测试


### 8.1 长时间测试的意义


**为什么要做长时间测试**：
- **内存泄漏检测**：发现程序长期运行中的内存泄漏问题
- **系统稳定性验证**：确认系统能够长期稳定运行
- **性能衰减观察**：检查长时间运行后的性能变化
- **资源累积问题**：发现资源清理不及时的问题

> 🕐 **时间建议**
> - 短期测试：4-8小时（检测明显问题）
> - 中期测试：24-48小时（检测累积问题）  
> - 长期测试：一周以上（检测隐藏问题）

### 8.2 长时间CPU压力测试


```bash
#!/bin/bash
# 24小时CPU压力测试

LOG_FILE="long_term_cpu_test.log"
echo "开始24小时CPU压力测试: $(date)" > ${LOG_FILE}

# 适中的CPU负载，避免系统完全无响应
stress-ng --cpu 0 --cpu-load 70 --timeout 86400s &
STRESS_PID=$!

# 每小时记录系统状态
for hour in {1..24}; do
    sleep 3600  # 等待1小时
    
    echo "=== 第${hour}小时状态 ===" >> ${LOG_FILE}
    echo "时间: $(date)" >> ${LOG_FILE}
    echo "系统负载: $(uptime)" >> ${LOG_FILE}
    echo "内存使用: $(free -h | grep Mem)" >> ${LOG_FILE}
    echo "CPU使用: $(top -bn1 | grep "Cpu(s)")" >> ${LOG_FILE}
    echo "" >> ${LOG_FILE}
done

kill ${STRESS_PID}
echo "测试完成: $(date)" >> ${LOG_FILE}
```

### 8.3 内存长期稳定性测试


**内存泄漏检测**：
```bash
#!/bin/bash
# 长期内存使用监控

MONITOR_LOG="memory_monitor.log"
echo "内存长期监控开始: $(date)" > ${MONITOR_LOG}

# 启动适度的内存压力
stress --vm 2 --vm-bytes 1G --timeout 86400s &
STRESS_PID=$!

# 每10分钟记录内存使用情况
while kill -0 ${STRESS_PID} 2>/dev/null; do
    echo "$(date): $(cat /proc/meminfo | grep -E 'MemTotal|MemFree|MemAvailable|Buffers|Cached')" >> ${MONITOR_LOG}
    sleep 600  # 10分钟
done

echo "内存监控结束: $(date)" >> ${MONITOR_LOG}
```

### 8.4 系统整体长期压力测试


**综合压力持续测试**：
```
长期测试监控点：
┌─────────────────────────────────────────┐
│  系统资源使用趋势                        │
│  ──────────────                        │
│  • CPU平均负载是否持续上升              │
│  • 内存使用是否出现只增不减              │
│  • 磁盘空间是否被意外占用                │
│  • 网络连接数是否累积增长                │
├─────────────────────────────────────────┤
│  性能指标变化                           │
│  ─────────────                         │
│  • 响应时间是否逐渐延长                  │
│  • 吞吐量是否逐渐下降                    │
│  • 错误率是否逐渐升高                    │
│  • 系统调用效率是否下降                  │
├─────────────────────────────────────────┤
│  稳定性检查                             │
│  ───────────                           │
│  • 是否出现进程异常退出                  │
│  • 是否出现内核错误日志                  │
│  • 是否出现磁盘错误                      │
│  • 是否出现网络异常                      │
└─────────────────────────────────────────┘
```

---

## 9. 💥 故障注入压力测试


### 9.1 故障注入测试概念


**什么是故障注入**：故意在系统中制造各种故障，测试系统在异常情况下的反应和恢复能力。

**故障注入的价值**：
- **容错能力验证**：测试系统的故障容忍度
- **恢复机制测试**：验证自动恢复功能
- **监控告警测试**：检查故障检测的有效性
- **运维响应验证**：测试故障处理流程

### 9.2 硬件故障模拟


**CPU故障模拟**：
```bash
# 模拟CPU核心故障（下线部分CPU）
echo 0 > /sys/devices/system/cpu/cpu1/online
echo 0 > /sys/devices/system/cpu/cpu2/online

# 监控系统在CPU减少情况下的表现
stress-ng --cpu 0 --cpu-load 80 --timeout 1800s

# 恢复CPU
echo 1 > /sys/devices/system/cpu/cpu1/online
echo 1 > /sys/devices/system/cpu/cpu2/online
```

**内存故障模拟**：
```bash
# 模拟内存故障（限制可用内存）
echo 2G > /sys/fs/cgroup/memory/memory.limit_in_bytes

# 在受限内存环境下进行压力测试
stress --vm 2 --vm-bytes 1G --timeout 3600s
```

### 9.3 网络故障注入


**网络中断模拟**：
```bash
# 模拟网络延迟
tc qdisc add dev eth0 root netem delay 100ms

# 模拟网络丢包
tc qdisc add dev eth0 root netem loss 5%

# 模拟网络带宽限制
tc qdisc add dev eth0 root tbf rate 1mbit burst 32kbit latency 400ms

# 在网络异常情况下测试系统表现
ab -n 1000 -c 50 http://remote-server/

# 恢复网络
tc qdisc del dev eth0 root
```

### 9.4 磁盘故障注入


**磁盘I/O故障模拟**：
```bash
# 模拟磁盘满故障
dd if=/dev/zero of=/tmp/fill_disk bs=1M count=1000

# 模拟磁盘I/O错误（只读文件系统）
mount -o remount,ro /tmp

# 在磁盘异常情况下测试应用行为
stress --hdd 2 --hdd-bytes 1G --timeout 1800s

# 恢复磁盘状态
rm -f /tmp/fill_disk
mount -o remount,rw /tmp
```

### 9.5 进程故障注入


**关键进程故障模拟**：
```bash
#!/bin/bash
# 模拟关键进程异常退出

# 找到目标进程
TARGET_PROCESS="nginx"
PID=$(pgrep ${TARGET_PROCESS})

if [ ! -z "$PID" ]; then
    echo "模拟进程 ${TARGET_PROCESS} 异常退出"
    kill -9 ${PID}
    
    # 监控系统恢复情况
    for i in {1..60}; do
        if pgrep ${TARGET_PROCESS} > /dev/null; then
            echo "第${i}秒: 进程已恢复"
            break
        else
            echo "第${i}秒: 进程仍未恢复"
        fi
        sleep 1
    done
else
    echo "未找到目标进程"
fi
```

---

## 10. 📋 核心要点总结


### 10.1 必须掌握的核心概念


```
🔸 压力测试分类：按负载强度和测试目的进行分类
🔸 测试场景设计：渐进式、真实性、可控性三大原则  
🔸 负载类型：正常负载、峰值负载、极限负载的区别
🔸 测试工具：stress、stress-ng、sysbench等工具的使用
🔸 监控指标：CPU、内存、磁盘、网络的关键监控指标
🔸 故障注入：硬件、网络、磁盘、进程的故障模拟方法
```

### 10.2 压力测试实施要点


**① 测试环境要求**
- ✅ **隔离环境**：绝不在生产环境进行破坏性测试
- ✅ **环境一致**：测试环境应尽可能接近生产环境
- ✅ **数据备份**：测试前做好重要数据备份
- ✅ **恢复准备**：准备快速恢复测试环境的方案

**② 测试执行策略**
```
测试执行流程：
准备阶段 → 基线测量 → 压力施加 → 持续监控 → 结果分析 → 环境恢复
    ↓          ↓          ↓          ↓          ↓          ↓
  环境检查   性能基准   负载控制   指标收集   问题定位   系统清理
```

**③ 关键监控指标**

| 资源类型 | **核心指标** | **正常范围** | **告警阈值** |
|---------|-------------|-------------|-------------|
| 🖥️ **CPU** | `利用率、负载、上下文切换` | `< 70%` | `> 85%` |
| 💾 **内存** | `使用率、可用内存、swap使用` | `< 80%` | `> 90%` |
| 💿 **磁盘** | `I/O利用率、队列长度、响应时间` | `< 80%` | `> 90%` |
| 🌐 **网络** | `带宽使用、连接数、丢包率` | `< 70%` | `> 85%` |

### 10.3 测试结果分析要点


**性能拐点识别**：
```
性能曲线分析：
     响应时间
        ↑
        │     ╱╲ 性能急剧恶化
        │    ╱  ╲
        │   ╱    ╲
        │  ╱      ╲
        │ ╱        ╲
        │╱          ╲
        └─────────────→ 负载强度
         │    │    │
       正常  拐点  极限
```

**问题定位方法**：
- **资源瓶颈**：首先出现100%使用率的资源
- **性能衰减**：响应时间大幅增加的临界点  
- **稳定性问题**：长期测试中出现的异常模式
- **恢复能力**：压力解除后的恢复时间

### 10.4 实际应用指导


**容量规划建议**：
- 📊 **安全裕度**：生产环境负载应保持在测试极限的60-70%
- 📈 **扩容时机**：当日常负载达到极限的50%时考虑扩容
- 🔄 **弹性设计**：系统应具备应对2-3倍突发负载的能力

**运维监控建议**：
- 🚨 **预警阈值**：基于压力测试结果设置合理的告警阈值
- 📋 **应急预案**：针对不同故障场景制定具体的处理流程
- 🔍 **定期测试**：每月进行一次压力测试，验证系统稳定性

**核心记忆口诀**：
- 压力测试分场景，渐进突发要分清
- 正常峰值到极限，长期稳定故障注
- 监控指标要全面，CPU内存磁盘网
- 隔离环境保安全，分析结果指运维