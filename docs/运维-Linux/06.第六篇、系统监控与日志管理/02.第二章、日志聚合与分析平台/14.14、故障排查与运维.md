---
title: 14、故障排查与运维
---
## 📚 目录

1. [故障排查基础概念](#1-故障排查基础概念)
2. [常见故障现象识别](#2-常见故障现象识别)
3. [集群状态诊断方法](#3-集群状态诊断方法)
4. [日志收集中断处理](#4-日志收集中断处理)
5. [索引损坏修复技术](#5-索引损坏修复技术)
6. [内存泄漏问题排查](#6-内存泄漏问题排查)
7. [网络连接问题诊断](#7-网络连接问题诊断)
8. [性能下降原因分析](#8-性能下降原因分析)
9. [运维自动化脚本编写](#9-运维自动化脚本编写)
10. [核心要点总结](#10-核心要点总结)

---

## 1. 🔍 故障排查基础概念


### 1.1 什么是ELK Stack故障排查


**简单理解**：就像医生给病人看病一样，当ELK系统出现问题时，我们需要找出病因并治疗。

```
ELK Stack = Elasticsearch + Logstash + Kibana
像一个数据处理工厂：
原材料(日志) → 加工车间(Logstash) → 仓库(Elasticsearch) → 展示厅(Kibana)

任何一个环节出问题，整个工厂就可能停摆
```

**核心组件故障影响**：
- **Elasticsearch故障** → 数据无法存储和搜索
- **Logstash故障** → 日志无法处理和转发
- **Kibana故障** → 用户无法查看和分析数据

### 1.2 故障排查的基本思路


**排查原则**：从现象到本质，从简单到复杂

```
故障排查思维导图：
发现问题 → 收集信息 → 分析原因 → 制定方案 → 实施修复 → 验证结果
    ↓         ↓         ↓         ↓         ↓         ↓
  报警监控   日志分析   根因定位   风险评估   谨慎操作   持续观察
```

**🎯 故障分类**：
- **🟢 轻微故障**：部分功能受影响，系统基本可用
- **🟡 中等故障**：核心功能受限，影响业务但不致命
- **🔴 严重故障**：系统不可用，业务完全中断

---

## 2. 👁️ 常见故障现象识别


### 2.1 用户视角的故障现象


**📊 Kibana界面异常**：
```
常见现象：
• 页面加载超时
• 图表显示空白
• 搜索结果为空
• 仪表板无法刷新

用户感受：
"怎么数据都没了？"
"系统是不是挂了？"
"昨天还好好的，今天就看不到了"
```

**🔍 搜索功能异常**：
```
现象描述：
• 搜索响应极慢(>30秒)
• 搜索结果不完整
• 特定时间段数据缺失
• 实时数据更新延迟

影响评估：
轻微 → 搜索慢但能用
严重 → 完全搜不到数据
```

### 2.2 系统层面的故障现象


**⚡ 性能指标异常**：

| 指标类型 | 正常范围 | 异常表现 | 严重程度 |
|---------|---------|----------|----------|
| **CPU使用率** | `<80%` | `>90%持续` | 🟡 中等 |
| **内存使用率** | `<85%` | `>95%` | 🔴 严重 |
| **磁盘使用率** | `<90%` | `>95%` | 🔴 紧急 |
| **网络延迟** | `<10ms` | `>100ms` | 🟡 中等 |

**📈 集群状态异常**：
```
健康状态颜色含义：
🟢 Green  - 一切正常，所有分片都可用
🟡 Yellow - 部分副本分片不可用，但主分片正常
🔴 Red    - 部分主分片不可用，数据可能丢失

常见异常模式：
Green → Yellow → Red (逐步恶化)
Green → Red (突然故障)
```

### 2.3 日志中的故障信号


**🚨 关键错误日志模式**：
```bash
# Elasticsearch常见错误
[ERROR] failed to send join request
[WARN] gc overhead, spent [500ms] collecting
[ERROR] disk usage exceeded flood-stage watermark

# Logstash典型问题
[ERROR] Pipeline worker error
[WARN] JDBC connection timeout
[ERROR] Failed to parse message

# 快速识别技巧
grep -E "(ERROR|FATAL|OutOfMemory)" /var/log/elasticsearch/
```

---

## 3. 🏥 集群状态诊断方法


### 3.1 基础健康检查


**🔧 集群整体状态查看**：
```bash
# 最重要的命令 - 集群健康状态
curl -X GET "localhost:9200/_cluster/health?pretty"

# 返回结果解读
{
  "cluster_name": "my-cluster",
  "status": "yellow",          # 🟡 需要关注
  "number_of_nodes": 3,        # 节点数量
  "active_primary_shards": 50, # 活跃主分片
  "active_shards": 95,         # 总活跃分片
  "unassigned_shards": 5       # 🚨 未分配分片(问题根源)
}
```

**📊 节点状态详细检查**：
```bash
# 查看所有节点状态
curl -X GET "localhost:9200/_cat/nodes?v&h=name,heap.percent,ram.percent,cpu,load_1m,disk.used_percent"

# 结果示例
name         heap.percent ram.percent cpu load_1m disk.used_percent
node-1       45           78          12  0.8     65.2
node-2       89           92          25  2.1     78.5  # 🚨 内存告急
node-3       -            -           -   -       -     # 🔴 节点离线
```

### 3.2 分片分布诊断


**🔍 分片状态详细分析**：
```bash
# 查看未分配的分片
curl -X GET "localhost:9200/_cat/shards?v&h=index,shard,prirep,state,unassigned.reason"

# 常见未分配原因
CLUSTER_RECOVERED          # 集群恢复中，正常
REPLICA_ADDED             # 新增副本，等待分配
NODE_LEFT                 # 节点离开集群 🚨
INDEX_CREATED             # 索引刚创建
ALLOCATION_FAILED         # 分配失败 🔴 需要处理
```

**💡 分片问题快速修复**：
```bash
# 强制分配卡住的分片(谨慎使用)
curl -X POST "localhost:9200/_cluster/reroute" -H 'Content-Type: application/json' -d'
{
  "commands": [
    {
      "allocate_empty_primary": {
        "index": "log-2024.01.01",
        "shard": 0,
        "node": "node-1",
        "accept_data_loss": true
      }
    }
  ]
}'
```

### 3.3 索引级别诊断


**📋 索引健康状态检查**：
```bash
# 查看所有索引状态
curl -X GET "localhost:9200/_cat/indices?v&s=health"

# 重点关注的字段
health | status | index              | pri | rep | docs.count | store.size
red    | open   | log-2024.01.01    | 5   | 1   | 1000000   | 2.5gb     # 🔴 有问题
yellow | open   | log-2024.01.02    | 5   | 1   | 950000    | 2.3gb     # 🟡 缺副本
green  | open   | log-2024.01.03    | 5   | 1   | 1100000   | 2.7gb     # ✅ 正常
```

---

## 4. 🔄 日志收集中断处理


### 4.1 日志流中断诊断


**🕵️ 数据流链路检查**：
```
日志数据流向：
应用服务器 → Filebeat → Logstash → Elasticsearch → Kibana
     ↓           ↓          ↓           ↓          ↓
   文件日志   → 采集代理 → 数据处理 → 数据存储 → 数据展示

中断可能发生在任何环节
```

**🔧 Filebeat状态检查**：
```bash
# 检查Filebeat是否在运行
systemctl status filebeat

# 查看Filebeat日志
tail -f /var/log/filebeat/filebeat

# 常见问题日志
ERROR: Failed to connect to backoff  # 连接Logstash失败
WARN: Harvester could not be started  # 文件读取失败
ERROR: File truncated               # 文件被截断
```

### 4.2 Logstash pipeline故障处理


**⚙️ Pipeline状态监控**：
```bash
# 查看Logstash pipeline状态
curl -X GET "localhost:9600/_node/stats/pipelines"

# 关键指标解读
{
  "pipelines": {
    "main": {
      "events": {
        "in": 50000,        # 输入事件数
        "filtered": 48000,  # 过滤后事件数
        "out": 47000        # 输出事件数
      },
      "plugins": {
        "inputs": [
          {
            "id": "beats-input",
            "events": {"out": 50000, "queue_push_duration_in_millis": 1200}
          }
        ]
      }
    }
  }
}
```

**🚨 常见Pipeline问题修复**：
```ruby
# Logstash配置文件常见错误
input {
  beats {
    port => 5044
    host => "0.0.0.0"  # 确保监听所有接口
  }
}

filter {
  if [fields][log_type] == "nginx" {
    grok {
      match => { "message" => "%{NGINXACCESS}" }
      tag_on_failure => ["_grokparsefailure"]  # 添加失败标签
    }
  }
}

output {
  elasticsearch {
    hosts => ["localhost:9200"]
    index => "logs-%{+YYYY.MM.dd}"
    template_overwrite => true
  }
  
  # 调试输出(生产环境注释掉)
  stdout { codec => rubydebug }
}
```

### 4.3 数据丢失检测与恢复


**📊 数据完整性检查**：
```bash
# 按时间统计文档数量，发现数据断层
curl -X GET "localhost:9200/logs-*/_search" -H 'Content-Type: application/json' -d'
{
  "aggs": {
    "logs_by_hour": {
      "date_histogram": {
        "field": "@timestamp",
        "calendar_interval": "1h"
      }
    }
  },
  "size": 0
}'

# 正常情况下，每小时文档数量应该相对稳定
# 如果某个时间段为0或明显偏少，说明有数据丢失
```

---

## 5. 🔧 索引损坏修复技术


### 5.1 索引损坏识别


**🔍 损坏症状识别**：
```bash
# 检查索引分片状态
curl -X GET "localhost:9200/_cat/shards/damaged-index?v"

# 典型损坏现象
UNASSIGNED p 0 ALLOCATION_FAILED    # 主分片分配失败
UNASSIGNED r 0 REPLICA_ADDED        # 副本无法创建
INITIALIZING p 0                    # 分片一直在初始化中
```

**💀 分片恢复失败日志**：
```bash
# Elasticsearch日志中的典型错误
grep "CorruptIndexException\|IndexFormatTooOldException" /var/log/elasticsearch/

# 常见错误类型
CorruptIndexException: codec mismatch       # 索引文件损坏
IndexFormatTooOldException: Format version # 版本不兼容
SecurityException: access denied           # 权限问题
```

### 5.2 索引修复策略


**🛠️ 安全修复流程**：

```bash
# 第一步：停止写入(防止进一步损坏)
curl -X PUT "localhost:9200/damaged-index/_settings" -H 'Content-Type: application/json' -d'
{
  "index.blocks.write": true
}'

# 第二步：创建快照备份
curl -X PUT "localhost:9200/_snapshot/backup/damaged-index-snapshot" -d'
{
  "indices": "damaged-index",
  "ignore_unavailable": true
}'

# 第三步：尝试恢复分片
curl -X POST "localhost:9200/_cluster/reroute" -d'
{
  "commands": [
    {
      "allocate_empty_primary": {
        "index": "damaged-index",
        "shard": 0,
        "node": "data-node-1",
        "accept_data_loss": true
      }
    }
  ]
}'
```

**🔄 重建索引方案**：
```bash
# 当修复无效时，重建索引
# 1. 从备份恢复
curl -X POST "localhost:9200/_snapshot/backup/damaged-index-snapshot/_restore"

# 2. 或者重新索引数据
curl -X POST "localhost:9200/_reindex" -d'
{
  "source": {
    "index": "old-damaged-index"
  },
  "dest": {
    "index": "new-recovered-index"
  }
}'
```

### 5.3 预防索引损坏


**📋 预防措施清单**：
```
✅ 定期快照备份
✅ 监控磁盘空间(>15%剩余)
✅ 使用SSD存储(减少I/O错误)
✅ 配置合适的副本数量
✅ 避免强制杀死ES进程
✅ 监控硬件健康状态
```

---

## 6. 🧠 内存泄漏问题排查


### 6.1 内存使用模式分析


**📊 JVM内存监控**：
```bash
# 查看JVM堆内存使用情况
curl -X GET "localhost:9200/_nodes/stats/jvm?pretty"

# 关键指标解读
{
  "nodes": {
    "node1": {
      "jvm": {
        "mem": {
          "heap_used_percent": 85,        # 🟡 堆内存使用率
          "heap_max_in_bytes": 2147483648, # 最大堆内存
          "non_heap_used_in_bytes": 150000000 # 非堆内存使用
        },
        "gc": {
          "old": {
            "collection_count": 45,       # GC次数
            "collection_time_in_millis": 1500 # GC耗时
          }
        }
      }
    }
  }
}
```

**🚨 内存泄漏警告信号**：
```
危险信号：
• 堆内存使用率持续上升(>90%)
• GC频率异常增高(>10次/分钟)
• GC耗时越来越长(>1秒)
• 系统响应越来越慢
• 最终导致OutOfMemoryError
```

### 6.2 内存泄漏根因分析


**🔍 常见内存泄漏场景**：

```
1. 🎯 查询缓存过大
原因：复杂查询结果缓存占用大量内存
解决：调整缓存大小或清理缓存

2. 📊 字段数据过多
原因：高基数字段加载到内存
解决：使用doc_values，避免大量聚合

3. 🔄 长时间运行的查询
原因：查询占用内存无法释放
解决：设置查询超时，优化查询语句
```

**⚙️ 内存配置优化**：
```bash
# elasticsearch.yml内存配置
# JVM堆大小(不超过32GB，不超过物理内存50%)
-Xms4g
-Xmx4g

# 字段数据缓存限制
indices.fielddata.cache.size: 20%

# 查询缓存配置  
indices.queries.cache.size: 10%

# 请求断路器配置
indices.breaker.total.limit: 95%
```

### 6.3 内存问题应急处理


**🚑 紧急处理步骤**：
```bash
# 1. 清理缓存释放内存
curl -X POST "localhost:9200/_cache/clear"

# 2. 取消长时间运行的查询
curl -X GET "localhost:9200/_tasks?detailed=true&actions=indices:data/read/search"
curl -X POST "localhost:9200/_tasks/task_id:12345/_cancel"

# 3. 临时增加堆内存(重启后生效)
echo '-Xmx8g' >> /etc/elasticsearch/jvm.options

# 4. 重启最严重的节点
systemctl restart elasticsearch
```

---

## 7. 🌐 网络连接问题诊断


### 7.1 网络连通性检查


**🔌 基础连通性测试**：
```bash
# 检查端口监听状态
netstat -tlnp | grep :9200  # Elasticsearch HTTP
netstat -tlnp | grep :9300  # Elasticsearch 集群通信
netstat -tlnp | grep :5601  # Kibana
netstat -tlnp | grep :5044  # Logstash Beats输入

# 测试服务连通性
curl -I http://localhost:9200/        # ES HTTP接口
curl -I http://localhost:5601/        # Kibana界面
telnet localhost 5044                 # Logstash Beats端口
```

**🔗 集群内部通信检查**：
```bash
# 检查集群节点发现
curl -X GET "localhost:9200/_cat/nodes?v&h=name,ip,port,master"

name    ip           port master
node-1  192.168.1.10 9300 m      # 主节点
node-2  192.168.1.11 9300 -      # 数据节点
node-3  192.168.1.12 9300 -      # 数据节点

# 如果节点缺失，检查网络配置
```

### 7.2 防火墙和安全组配置


**🛡️ 端口开放检查**：
```bash
# 检查iptables规则
iptables -L -n | grep -E "(9200|9300|5601|5044)"

# 检查firewalld状态
firewall-cmd --list-ports

# 开放必要端口
firewall-cmd --permanent --add-port=9200/tcp  # ES HTTP
firewall-cmd --permanent --add-port=9300/tcp  # ES 集群
firewall-cmd --permanent --add-port=5601/tcp  # Kibana
firewall-cmd --permanent --add-port=5044/tcp  # Logstash
firewall-cmd --reload
```

### 7.3 网络性能优化


**⚡ 网络延迟优化**：
```bash
# 检查网络延迟
ping -c 10 elasticsearch-node-1
ping -c 10 elasticsearch-node-2

# 检查网络带宽
iperf3 -s  # 服务端
iperf3 -c server-ip -t 30  # 客户端测试

# 优化网络参数
echo 'net.core.rmem_max = 16777216' >> /etc/sysctl.conf
echo 'net.core.wmem_max = 16777216' >> /etc/sysctl.conf
sysctl -p
```

---

## 8. 📈 性能下降原因分析


### 8.1 性能指标监控


**📊 关键性能指标**：

| 指标分类 | 监控项目 | 正常值 | 警告阈值 | 获取方法 |
|---------|---------|--------|----------|----------|
| **查询性能** | 平均响应时间 | `<100ms` | `>500ms` | `_cat/indices` |
| **索引性能** | 索引速率 | `>1000 docs/s` | `<100 docs/s` | `_stats` |
| **系统资源** | CPU使用率 | `<70%` | `>90%` | `top/htop` |
| **磁盘I/O** | 读写延迟 | `<10ms` | `>100ms` | `iostat` |

**🔍 性能监控脚本**：
```bash
#!/bin/bash
# elasticsearch_perf_monitor.sh

echo "=== ES性能监控 $(date) ==="

# 查询响应时间
curl -s "localhost:9200/_cat/indices?v&h=index,search.query_time_in_millis&s=search.query_time_in_millis:desc" | head -10

# 索引速率
curl -s "localhost:9200/_cat/indices?v&h=index,indexing.index_total,indexing.index_time_in_millis"

# 集群状态
curl -s "localhost:9200/_cluster/health" | jq '.status'

echo "=================="
```

### 8.2 慢查询分析


**🐌 慢查询日志配置**：
```bash
# 启用慢查询日志
curl -X PUT "localhost:9200/_settings" -H 'Content-Type: application/json' -d'
{
  "index.search.slowlog.threshold.query.warn": "10s",
  "index.search.slowlog.threshold.query.info": "5s",
  "index.search.slowlog.threshold.fetch.warn": "1s",
  "index.indexing.slowlog.threshold.index.warn": "10s"
}'

# 查看慢查询日志
tail -f /var/log/elasticsearch/my-cluster_index_search_slowlog.log
```

**🔧 查询优化技巧**：
```json
// 避免深度分页
{
  "query": {"match_all": {}},
  "from": 0,     // ✅ 从头开始
  "size": 100    // ✅ 合理大小
}

// 使用scroll查询大量数据
{
  "query": {"match_all": {}},
  "scroll": "1m",
  "size": 1000
}

// 避免通配符开头的查询
{
  "query": {
    "wildcard": {
      "field": "prefix*"  // ✅ 好
      // "field": "*suffix" // ❌ 慢
    }
  }
}
```

### 8.3 硬件资源瓶颈


**💾 磁盘性能优化**：
```bash
# 检查磁盘I/O状态
iostat -x 1 5

# 关键指标解读
Device: rrqm/s wrqm/s   r/s   w/s  await  %util
sda:     0.00   50.2   1.2  25.8   12.5   34.2  # 正常
sdb:     0.00  200.5  15.2 185.8  156.3   98.9  # 🚨 I/O瓶颈

# SSD优化配置
echo deadline > /sys/block/sda/queue/scheduler  # SSD调度器
echo 1 > /sys/block/sda/queue/nomerges         # 禁用合并
```

---

## 9. 🤖 运维自动化脚本编写


### 9.1 健康检查自动化


**🏥 集群健康监控脚本**：
```bash
#!/bin/bash
# elk_health_check.sh - ELK集群健康检查脚本

# 配置参数
ES_HOST="localhost:9200"
ALERT_EMAIL="admin@company.com"
LOG_FILE="/var/log/elk_health.log"

# 获取集群状态
get_cluster_status() {
    curl -s "$ES_HOST/_cluster/health" | jq -r '.status'
}

# 检查节点状态
check_nodes() {
    local node_count=$(curl -s "$ES_HOST/_cat/nodes?h=name" | wc -l)
    local expected_nodes=3
    
    if [ $node_count -lt $expected_nodes ]; then
        echo "WARNING: 只有 $node_count 个节点在线，期望 $expected_nodes 个"
        return 1
    fi
    return 0
}

# 检查磁盘空间
check_disk_space() {
    local disk_usage=$(df -h /var/lib/elasticsearch | awk 'NR==2 {print $5}' | sed 's/%//')
    
    if [ $disk_usage -gt 85 ]; then
        echo "WARNING: 磁盘使用率 ${disk_usage}%，超过85%阈值"
        return 1
    fi
    return 0
}

# 主函数
main() {
    local status=$(get_cluster_status)
    local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
    
    echo "[$timestamp] 开始健康检查" >> $LOG_FILE
    
    case $status in
        "green")
            echo "✅ 集群状态正常"
            ;;
        "yellow")
            echo "🟡 集群状态警告"
            check_nodes
            ;;
        "red")
            echo "🔴 集群状态严重"
            echo "[$timestamp] 集群状态RED - 发送告警" >> $LOG_FILE
            # 发送告警邮件
            echo "ELK集群状态异常，请立即检查" | mail -s "ELK告警" $ALERT_EMAIL
            ;;
    esac
    
    check_disk_space
}

# 运行检查
main
```

### 9.2 索引清理自动化


**🗑️ 索引清理脚本**：
```bash
#!/bin/bash
# index_cleanup.sh - 自动清理旧索引

# 配置
ES_HOST="localhost:9200"
RETENTION_DAYS=30
INDEX_PATTERN="logstash-*"

# 获取要删除的索引
get_old_indices() {
    curl -s "$ES_HOST/_cat/indices/$INDEX_PATTERN?h=index" | \
    while read index; do
        # 提取日期 (假设格式为 logstash-YYYY.MM.DD)
        index_date=$(echo $index | grep -o '[0-9]\{4\}\.[0-9]\{2\}\.[0-9]\{2\}')
        
        if [ ! -z "$index_date" ]; then
            # 转换为时间戳
            index_timestamp=$(date -d "${index_date//./-}" +%s)
            cutoff_timestamp=$(date -d "$RETENTION_DAYS days ago" +%s)
            
            if [ $index_timestamp -lt $cutoff_timestamp ]; then
                echo $index
            fi
        fi
    done
}

# 删除索引
delete_indices() {
    get_old_indices | while read index; do
        echo "删除索引: $index"
        curl -X DELETE "$ES_HOST/$index"
        
        if [ $? -eq 0 ]; then
            echo "✅ 成功删除 $index"
        else
            echo "❌ 删除失败 $index"
        fi
    done
}

# 执行清理
echo "开始清理 $RETENTION_DAYS 天前的索引"
delete_indices
echo "清理完成"
```

### 9.3 备份自动化


**💾 快照备份脚本**：
```bash
#!/bin/bash
# elasticsearch_backup.sh - ES快照备份脚本

# 配置
ES_HOST="localhost:9200"
REPO_NAME="backup_repo"
BACKUP_PATH="/backup/elasticsearch"
RETENTION_COUNT=7  # 保留最近7个快照

# 创建快照仓库(首次运行)
setup_repository() {
    curl -X PUT "$ES_HOST/_snapshot/$REPO_NAME" \
    -H 'Content-Type: application/json' -d"
    {
        \"type\": \"fs\",
        \"settings\": {
            \"location\": \"$BACKUP_PATH\"
        }
    }"
}

# 创建快照
create_snapshot() {
    local snapshot_name="snapshot_$(date +%Y%m%d_%H%M%S)"
    
    echo "创建快照: $snapshot_name"
    
    curl -X PUT "$ES_HOST/_snapshot/$REPO_NAME/$snapshot_name?wait_for_completion=true" \
    -H 'Content-Type: application/json' -d'
    {
        "indices": "*",
        "ignore_unavailable": true,
        "include_global_state": false
    }'
    
    if [ $? -eq 0 ]; then
        echo "✅ 快照创建成功: $snapshot_name"
    else
        echo "❌ 快照创建失败"
        return 1
    fi
}

# 清理旧快照
cleanup_old_snapshots() {
    # 获取快照列表，按时间排序
    local snapshots=$(curl -s "$ES_HOST/_snapshot/$REPO_NAME/_all" | \
                     jq -r '.snapshots[] | .snapshot' | \
                     sort -r | \
                     tail -n +$((RETENTION_COUNT + 1)))
    
    for snapshot in $snapshots; do
        echo "删除旧快照: $snapshot"
        curl -X DELETE "$ES_HOST/_snapshot/$REPO_NAME/$snapshot"
    done
}

# 主函数
main() {
    echo "开始ES备份 $(date)"
    
    # 确保目录存在
    mkdir -p $BACKUP_PATH
    
    # 设置仓库(如果不存在)
    setup_repository
    
    # 创建快照
    if create_snapshot; then
        # 清理旧快照
        cleanup_old_snapshots
        echo "备份完成 $(date)"
    else
        echo "备份失败 $(date)"
        exit 1
    fi
}

# 运行备份
main
```

---

## 10. 📋 核心要点总结


### 10.1 必须掌握的故障排查技能


```
🎯 基础技能清单：
✅ 快速判断故障严重程度(Green/Yellow/Red)
✅ 使用_cat API查看集群状态
✅ 分析节点和分片分布情况
✅ 读懂Elasticsearch日志错误信息
✅ 执行基本的集群维护操作
✅ 编写简单的健康检查脚本
```

### 10.2 故障处理优先级


**🚨 紧急处理顺序**：
```
1. 🔴 数据安全 - 防止数据丢失是第一优先级
2. 🟡 服务可用 - 恢复基本的搜索和索引功能  
3. 🟢 性能优化 - 提升系统响应速度和吞吐量
4. 🔵 预防措施 - 加强监控和自动化运维
```

### 10.3 运维最佳实践


**📋 日常运维要点**：
```
监控检查：
• 每日检查集群健康状态
• 关注磁盘空间使用情况
• 监控JVM内存和GC状况
• 验证数据备份完整性

预防措施：  
• 设置合理的告警阈值
• 建立应急响应流程
• 定期更新和打补丁
• 文档化运维操作手册

性能优化：
• 根据业务特点调整配置
• 定期清理不需要的索引
• 优化查询语句和聚合
• 合理规划硬件资源
```

### 10.4 常用故障排查命令速查


**⚡ 快速诊断命令**：
```bash
# 集群健康状态
curl localhost:9200/_cluster/health?pretty

# 节点信息
curl localhost:9200/_cat/nodes?v

# 索引状态  
curl localhost:9200/_cat/indices?v&s=health

# 分片分布
curl localhost:9200/_cat/shards?v

# 正在进行的任务
curl localhost:9200/_cat/tasks?v

# 集群统计信息
curl localhost:9200/_cluster/stats?pretty

# 节点统计信息
curl localhost:9200/_nodes/stats?pretty
```

**💡 记忆口诀**：
- 健康看health，节点看nodes  
- 索引看indices，分片看shards
- 性能看stats，任务看tasks
- 红色停止，黄色注意，绿色正常

**🎯 核心理念**：
- **预防胜于治疗** - 监控和告警是关键
- **数据第一** - 任何操作前先考虑数据安全
- **逐步处理** - 从简单到复杂，避免过度操作
- **文档记录** - 每次故障都要总结经验教训