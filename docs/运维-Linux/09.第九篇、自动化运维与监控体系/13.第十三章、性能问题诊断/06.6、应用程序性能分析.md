---
title: 6、应用程序性能分析
---
## 📚 目录

1. [应用程序性能指标监控](#1-应用程序性能指标监控)
2. [数据库查询性能分析](#2-数据库查询性能分析)
3. [Web服务响应时间分析](#3-Web服务响应时间分析)
4. [应用程序内存使用分析](#4-应用程序内存使用分析)
5. [线程池性能问题](#5-线程池性能问题)
6. [缓存命中率优化](#6-缓存命中率优化)
7. [应用程序瓶颈定位](#7-应用程序瓶颈定位)
8. [代码热点分析方法](#8-代码热点分析方法)
9. [核心要点总结](#9-核心要点总结)

---

## 1. 📊 应用程序性能指标监控


### 1.1 什么是应用程序性能监控


**定义**：应用程序性能监控（APM）是对运行中的应用程序进行实时性能数据采集和分析的过程。

简单理解，就像给应用程序装了一个"健康监测仪"，随时查看它的运行状况。

### 1.2 核心性能指标


**🔸 响应时间指标**
```
关键指标含义：
• 平均响应时间：所有请求响应时间的平均值
• P95响应时间：95%的请求在这个时间内完成
• P99响应时间：99%的请求在这个时间内完成

为什么关注P95/P99？
平均值会被极值"拉平"，P95/P99更能反映用户真实体验
```

**🔸 吞吐量指标**
```
吞吐量 = 每秒处理的请求数（QPS/TPS）

QPS：Queries Per Second，每秒查询数
TPS：Transactions Per Second，每秒事务数

实际意义：
QPS = 1000 表示应用每秒能处理1000个请求
```

**🔸 错误率指标**
```
错误率 = 错误请求数 / 总请求数 × 100%

分类统计：
• 4xx错误：客户端错误（如404、400）
• 5xx错误：服务器错误（如500、502）
• 超时错误：请求处理时间超过设定阈值
```

### 1.3 性能监控架构


**监控数据流向**：
```
应用程序 → 性能数据采集 → 数据存储 → 分析展示 → 告警处理

详细流程：
应用运行时产生性能数据
  ↓
通过探针或SDK采集数据
  ↓
发送到监控系统存储
  ↓
通过仪表盘可视化展示
  ↓
异常时触发告警通知
```

### 1.4 常用监控工具


| 工具类型 | **工具名称** | **适用场景** | **特点** |
|---------|------------|-------------|---------|
| 🌟 **APM平台** | `New Relic` | `商业应用监控` | `功能全面，开箱即用` |
| 🔧 **开源方案** | `Prometheus + Grafana` | `自建监控系统` | `灵活可定制，成本低` |
| ⚡ **轻量工具** | `top/htop` | `快速排查问题` | `系统自带，简单直观` |
| 🐍 **应用级** | `Python: psutil` | `应用内置监控` | `编程集成，精确控制` |

---

## 2. 🗃️ 数据库查询性能分析


### 2.1 数据库性能问题的影响


**为什么数据库性能很关键？**

大部分Web应用的性能瓶颈都在数据库层面。一个慢查询可能让整个应用变慢，影响所有用户体验。

### 2.2 SQL查询性能分析


**🔸 慢查询识别**
```bash
# MySQL慢查询日志分析
mysqldumpslow -s c -t 10 /var/log/mysql/slow.log

# 含义解释：
# -s c: 按查询次数排序
# -t 10: 显示前10个最慢的查询
# slow.log: 慢查询日志文件
```

**🔸 执行计划分析**
```sql
-- 查看SQL执行计划
EXPLAIN SELECT * FROM users WHERE email = 'user@example.com';

-- 关键字段含义：
-- type: 连接类型（const最快，ALL最慢）
-- key: 使用的索引
-- rows: 扫描的行数
```

**执行计划性能等级**：
```
性能从优到劣：
✅ const      - 常量查询，通过主键或唯一索引
✅ eq_ref     - 唯一索引扫描
✅ ref        - 非唯一索引扫描  
⚠️ range      - 范围索引扫描
⚠️ index      - 索引全扫描
❌ ALL        - 全表扫描（最慢）
```

### 2.3 数据库连接池分析


**🔸 连接池问题诊断**
```
常见连接池问题：
• 连接泄露：获取连接后未正确释放
• 连接超时：等待可用连接时间过长
• 连接数不足：并发请求超过连接池大小

监控指标：
- 活跃连接数 vs 最大连接数
- 平均获取连接时间
- 连接等待队列长度
```

**连接池健康状态判断**：
```
健康状态：
✅ 活跃连接 < 80% 最大连接数
✅ 获取连接时间 < 50ms
✅ 等待队列长度 = 0

需要优化：
⚠️ 活跃连接 > 90% 最大连接数  
⚠️ 获取连接时间 > 100ms
❌ 等待队列持续有排队
```

### 2.4 数据库性能优化策略


**🎯 索引优化**
```
索引创建原则：
• 为WHERE条件字段创建索引
• 为ORDER BY字段创建索引
• 避免过度索引（影响写入性能）

示例：
-- 原始查询很慢
SELECT * FROM orders WHERE user_id = 123 AND status = 'pending';

-- 创建复合索引加速
CREATE INDEX idx_user_status ON orders(user_id, status);
```

---

## 3. 🌐 Web服务响应时间分析


### 3.1 Web服务响应时间构成


**响应时间分解**：
```
总响应时间 = 网络传输 + 应用处理 + 数据库查询 + 外部API调用

典型分布比例：
网络传输: 10-50ms    (网络延迟)
应用处理: 50-200ms   (业务逻辑处理)  
数据库查询: 10-100ms (SQL执行)
外部API: 100-500ms   (第三方服务)
```

### 3.2 响应时间分析工具


**🔸 应用程序日志分析**
```bash
# 分析Nginx访问日志中的响应时间
awk '{print $NF}' access.log | sort -n | tail -20

# 含义：
# $NF: 最后一个字段（通常是响应时间）
# sort -n: 数值排序
# tail -20: 显示最慢的20个请求
```

**🔸 实时性能监控**
```bash
# 使用curl测试接口响应时间
curl -w "@curl-format.txt" -o /dev/null -s "http://example.com/api"

# curl-format.txt内容：
#     time_namelookup:  %{time_namelookup}\n
#      time_connect:  %{time_connect}\n
#   time_appconnect:  %{time_appconnect}\n
#      time_total:  %{time_total}\n
```

### 3.3 响应时间瓶颈定位


**🎯 分层分析方法**
```
从外到内逐层分析：

第1层：CDN/负载均衡
- 检查CDN缓存命中率
- 查看负载均衡器响应时间

第2层：Web服务器
- 分析Nginx/Apache响应时间
- 查看静态资源处理时间  

第3层：应用服务器
- 监控应用框架处理时间
- 分析业务逻辑执行时间

第4层：数据存储
- 数据库查询时间分析
- 缓存系统响应时间
```

### 3.4 常见响应时间问题


**🔸 问题类型与解决思路**

| 问题现象 | **可能原因** | **分析方法** | **解决思路** |
|---------|------------|-------------|-------------|
| 🐌 **整体变慢** | `系统负载高` | `查看CPU/内存使用率` | `扩容或优化代码` |
| ⚡ **偶发超时** | `GC或锁竞争` | `分析GC日志和线程dump` | `JVM调优或代码优化` |
| 🌊 **峰值变慢** | `并发处理不足` | `监控线程池使用情况` | `调整线程池配置` |
| 🔍 **特定接口慢** | `SQL查询低效` | `开启慢查询日志` | `优化SQL或加索引` |

---

## 4. 🧠 应用程序内存使用分析


### 4.1 内存使用基本概念


**内存分类理解**：
```
物理内存：服务器实际安装的RAM内存
虚拟内存：操作系统提供的内存抽象概念
堆内存：应用程序动态分配的内存区域
栈内存：存储局部变量和函数调用信息

简单理解：
物理内存 = 实际的内存条容量
虚拟内存 = 物理内存 + 磁盘交换空间
堆内存 = 程序运行时申请的数据存储空间
```

### 4.2 内存问题类型


**🔸 内存泄露**
```
什么是内存泄露？
程序申请了内存但使用完后没有释放，导致可用内存越来越少

典型现象：
• 应用运行时间越长，内存占用越高
• 最终导致OOM（Out Of Memory）错误
• 系统变慢，甚至崩溃

常见原因：
- 忘记关闭文件句柄或数据库连接
- 循环引用导致垃圾回收失效
- 缓存无限增长没有清理机制
```

**🔸 内存溢出**
```
内存溢出 vs 内存泄露的区别：
内存溢出：瞬间申请大量内存，超过系统限制
内存泄露：长时间累积，慢慢耗尽内存

内存溢出场景：
- 加载超大文件到内存
- 创建巨大的数组或集合
- 递归调用层次过深
```

### 4.3 内存分析工具


**🔧 系统级内存监控**
```bash
# 查看系统内存使用情况
free -h

# 输出解释：
#               total        used        free      shared  buff/cache   available
# Mem:           7.7G        2.1G        3.2G         45M        2.4G        5.2G

# 关键指标：
# used: 已使用内存
# available: 实际可用内存（比free更准确）
# buff/cache: 缓冲区和缓存占用
```

**🐍 应用程序内存分析**
```python
# Python内存使用分析示例
import psutil
import os

# 获取当前进程内存使用
process = psutil.Process(os.getpid())
memory_info = process.memory_info()

print(f"RSS内存: {memory_info.rss / 1024 / 1024:.2f} MB")
print(f"虚拟内存: {memory_info.vms / 1024 / 1024:.2f} MB")

# RSS: 实际占用的物理内存
# VMS: 虚拟内存大小
```

### 4.4 内存优化策略


**🎯 内存使用优化原则**
```
及时释放原则：
• 使用完的资源立即释放
• 数据库连接用完后关闭
• 大文件处理完后清理

合理缓存原则：
• 设置缓存大小限制
• 实现LRU等淘汰策略
• 定期清理过期数据

分批处理原则：
• 大数据集分批处理，避免一次性加载
• 使用流式处理代替批量加载
• 及时释放中间结果
```

---

## 5. 🧵 线程池性能问题


### 5.1 什么是线程池


**线程池基本概念**：

线程池就像一个"工人团队"，提前准备好固定数量的工人（线程），当有任务（请求）来的时候，直接分配给空闲的工人处理，而不是每次都临时招工人。

**为什么要用线程池？**
```
不使用线程池的问题：
• 每个请求都创建新线程，创建和销毁开销大
• 线程数量无法控制，可能创建过多线程
• 系统资源耗尽，性能急剧下降

使用线程池的好处：
• 复用线程，减少创建/销毁开销
• 控制并发数量，保护系统稳定
• 任务排队机制，优雅处理高并发
```

### 5.2 线程池核心参数


**🔸 关键参数含义**
```
核心线程数（Core Pool Size）：
始终保持活跃的线程数量，即使空闲也不会销毁

最大线程数（Maximum Pool Size）：
线程池允许的最大线程数量

队列容量（Queue Capacity）：
等待执行的任务队列大小

空闲时间（Keep Alive Time）：
非核心线程的最大空闲时间，超过后被销毁
```

**线程池工作流程**：
```
新任务到达时的处理逻辑：

1. 当前线程数 < 核心线程数？
   ✅ 创建新线程执行任务

2. 任务队列未满？
   ✅ 将任务放入队列等待

3. 当前线程数 < 最大线程数？
   ✅ 创建非核心线程执行任务

4. 否则：拒绝任务（触发拒绝策略）
```

### 5.3 线程池性能问题诊断


**🔸 常见性能问题**
```
线程池耗尽：
现象：新请求响应很慢或被拒绝
原因：任务执行时间长，线程被占用
解决：增加线程数或优化任务执行时间

队列积压：
现象：任务在队列中等待时间过长
原因：任务产生速度 > 处理速度
解决：增加线程数或优化处理逻辑

线程竞争：
现象：CPU使用率高但吞吐量低
原因：多线程访问共享资源冲突
解决：减少锁使用或优化锁粒度
```

**🔍 监控关键指标**
```bash
# Java应用线程监控示例
jstack <pid> | grep -A 10 -B 10 "BLOCKED\|WAITING"

# 关键监控指标：
# - 活跃线程数 vs 总线程数
# - 队列中等待任务数量
# - 平均任务执行时间
# - 线程状态分布（Running/Blocked/Waiting）
```

### 5.4 线程池调优策略


**🎯 参数调优指南**

| 应用类型 | **核心线程数建议** | **最大线程数建议** | **队列大小建议** |
|---------|-----------------|-----------------|----------------|
| 🧮 **CPU密集型** | `CPU核数` | `CPU核数 + 1` | `较小队列` |
| 💾 **IO密集型** | `CPU核数 * 2` | `CPU核数 * 4` | `较大队列` |
| 🌐 **Web应用** | `8-16` | `100-200` | `1000-5000` |
| 🔄 **异步处理** | `4-8` | `50-100` | `10000+` |

**调优经验**：
```
保守启动原则：
• 从较小的参数开始
• 逐步增加并观察效果
• 避免一次性大幅调整

监控驱动调优：
• 持续监控关键指标
• 根据实际负载调整参数
• 定期评估调优效果
```

---

## 6. 🚀 缓存命中率优化


### 6.1 缓存的作用和重要性


**什么是缓存？**

缓存就像书桌上的"常用物品"，把经常使用的数据放在快速访问的地方，避免每次都去远处（数据库）获取。

**缓存的价值**：
```
性能提升：
• 从内存读取比从磁盘快100-1000倍
• 减少数据库查询，降低DB压力
• 提升用户体验，降低响应时间

成本节约：
• 减少服务器资源消耗
• 降低数据库负载，延缓扩容需求
• 提高系统整体吞吐量
```

### 6.2 缓存命中率指标


**🔸 核心指标定义**
```
缓存命中率 = 缓存命中次数 / 总访问次数 × 100%

示例计算：
总访问：10000次
缓存命中：8500次  
命中率 = 8500 / 10000 × 100% = 85%

命中率等级划分：
🟢 优秀：> 90%
🟡 良好：80% - 90%  
🟠 需优化：60% - 80%
🔴 问题严重：< 60%
```

**🔸 相关指标**
```
缓存穿透率：缓存未命中的比例
缓存雪崩率：缓存大面积失效的比例
平均响应时间：命中时 vs 未命中时的响应时间差异
内存使用率：缓存占用的内存空间比例
```

### 6.3 影响缓存命中率的因素


**🎯 数据特征因素**
```
热点数据分布：
• 80/20原则：20%的数据承载80%的访问
• 识别并优先缓存热点数据
• 长尾数据缓存价值较低

数据变化频率：
• 静态数据：配置信息，字典数据
• 准静态数据：用户基本信息  
• 动态数据：实时计算结果
• 实时数据：当前在线用户数
```

**🔧 缓存策略因素**
```
缓存容量：
• 容量太小：频繁淘汰，命中率低
• 容量太大：内存浪费，成本高
• 最佳实践：根据热点数据量确定

淘汰策略：
• LRU：最近最少使用
• LFU：最不经常使用
• TTL：基于时间过期
• 选择合适的策略很关键
```

### 6.4 缓存命中率优化策略


**🚀 数据预热策略**
```python
# 缓存预热示例伪代码
def warm_up_cache():
    """系统启动时预热热点数据"""
    
    # 1. 查询热点数据
    hot_data = get_hot_data_from_analytics()
    
    # 2. 批量加载到缓存
    for data in hot_data:
        cache.set(data.key, data.value, ttl=3600)
    
    print(f"预热完成，加载 {len(hot_data)} 条热点数据")
```

**🎯 缓存更新策略**
```
写入策略选择：

Cache-Aside（旁路缓存）：
• 应用程序同时操作缓存和数据库
• 读时先查缓存，未命中再查DB
• 写时先更新DB，再删除/更新缓存

Write-Through（直写）：
• 写操作同时更新缓存和数据库
• 保证数据一致性，但写性能较低

Write-Back（回写）：
• 只更新缓存，异步更新数据库
• 写性能高，但可能丢失数据
```

---

## 7. 🎯 应用程序瓶颈定位


### 7.1 性能瓶颈的类型


**瓶颈分类理解**：

性能瓶颈就像交通堵塞，不同的"堵点"需要不同的解决方案。找到真正的瓶颈点，才能有效提升整体性能。

**🔸 常见瓶颈类型**
```
CPU瓶颈：
表现：CPU使用率持续高于80%
原因：计算密集型操作、无限循环、低效算法
影响：应用响应变慢，处理能力下降

内存瓶颈：  
表现：内存使用率高，频繁GC或OOM
原因：内存泄露、缓存过大、数据结构不当
影响：应用变慢甚至崩溃

IO瓶颈：
表现：磁盘IO或网络IO等待时间长
原因：磁盘读写频繁、网络延迟、数据库慢查询
影响：请求处理时间长，用户体验差

并发瓶颈：
表现：线程池满、连接数不足、锁竞争激烈
原因：并发设计不合理、资源池配置不当
影响：系统吞吐量低，响应时间不稳定
```

### 7.2 瓶颈定位方法论


**🔍 自顶向下分析法**
```
分析层次从外到内：

第1步：用户体验层
• 前端页面加载时间
• API接口响应时间
• 用户操作响应速度

第2步：应用服务层  
• Web服务器处理能力
• 应用框架性能
• 业务逻辑执行效率

第3步：中间件层
• 数据库查询性能
• 缓存系统效率
• 消息队列处理能力

第4步：基础设施层
• 服务器硬件资源
• 网络带宽和延迟
• 存储系统性能
```

### 7.3 瓶颈定位工具


**🛠️ Linux系统工具组合**
```bash
# CPU瓶颈分析
top -p <pid>           # 查看进程CPU使用率
perf top               # 查看CPU热点函数
iostat 1               # 查看CPU使用率趋势

# 内存瓶颈分析  
pmap -d <pid>          # 查看进程内存映射
valgrind --tool=massif <program>  # 内存使用分析

# IO瓶颈分析
iotop                  # 查看IO使用率排行
lsof -p <pid>          # 查看进程打开的文件
netstat -i             # 查看网络接口统计

# 综合性能分析
strace -p <pid>        # 跟踪系统调用
tcpdump -i eth0        # 网络包分析
```

### 7.4 瓶颈定位实战案例


**🔧 案例：Web应用响应慢**
```
问题现象：
• 用户反馈页面加载慢
• 平均响应时间从200ms上升到2秒
• 服务器负载正常，CPU使用率不高

定位步骤：

Step 1: 确认问题范围
• 检查监控系统，确认响应时间确实变慢
• 查看错误日志，是否有异常信息
• 确认是全部接口慢还是特定接口

Step 2: 分层排查
• 网络层：ping/traceroute检查网络延迟
• 负载均衡：检查上游响应时间
• Web服务器：查看access.log中的响应时间
• 应用层：开启调试日志，查看处理时间

Step 3: 深入分析  
• 数据库：检查慢查询日志
• 缓存：查看缓存命中率是否下降
• 外部依赖：检查第三方API响应时间

最终发现：
某个数据库查询因为数据量增长导致全表扫描，
添加索引后问题解决，响应时间恢复正常。
```

---

## 8. 🔥 代码热点分析方法


### 8.1 什么是代码热点


**热点代码定义**：

热点代码是指程序运行时执行频率最高、耗时最长的代码段。就像找出"最忙的员工"一样，优化这些热点代码能显著提升整体性能。

**热点分析的价值**：
```
80/20原则在代码中的体现：
• 80%的CPU时间花在20%的代码上
• 优化20%的热点代码，可获得80%的性能提升
• 比盲目优化所有代码更高效

实际意义：
- 精确定位性能瓶颈
- 有针对性的优化投入
- 避免过早和无效优化
```

### 8.2 热点分析工具


**🔧 Profiling工具分类**
```
采样型Profiler：
• 定期采样程序运行状态
• 对性能影响小，适合生产环境
• 精度稍低，但足够定位主要问题
• 代表：perf, async-profiler

插桩型Profiler：  
• 在代码中插入监控点
• 数据精确，但性能开销大
• 适合开发和测试环境
• 代表：JProfiler, VisualVM
```

**🐍 Python代码热点分析**
```python
import cProfile
import pstats

# 方法1：命令行profiling
# python -m cProfile -o profile_output.prof your_script.py

# 方法2：代码中使用
def profile_function():
    profiler = cProfile.Profile()
    profiler.enable()
    
    # 执行需要分析的代码
    your_function_to_profile()
    
    profiler.disable()
    
    # 分析结果
    stats = pstats.Stats(profiler)
    stats.sort_stats('cumulative')
    stats.print_stats(10)  # 显示前10个热点函数
```

### 8.3 热点分析实战


**🔍 分析报告解读**
```
典型profiling输出解读：

         3 function calls in 0.012 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.012    0.012 <string>:1(<module>)
        1    0.001    0.001    0.011    0.011 example.py:10(slow_function)
        1    0.010    0.010    0.010    0.010 example.py:15(bottleneck_function)

字段含义：
ncalls：调用次数
tottime：函数自身耗时（不包括子函数）
percall：平均每次调用耗时
cumtime：累计耗时（包括子函数）
```

**🎯 热点优化策略**
```python
# 示例：优化前的热点代码
def slow_data_processing(data_list):
    result = []
    for item in data_list:
        # 热点：重复的复杂计算
        processed = complex_calculation(item)
        if processed > threshold:
            result.append(processed)
    return result

# 优化后：缓存计算结果
@lru_cache(maxsize=1000)
def cached_complex_calculation(item):
    return complex_calculation(item)

def optimized_data_processing(data_list):
    result = []
    for item in data_list:
        processed = cached_complex_calculation(item)
        if processed > threshold:
            result.append(processed)
    return result
```

### 8.4 生产环境热点监控


**🚨 持续性能监控**
```
APM工具集成：
• 自动识别代码热点
• 提供调用链路追踪
• 实时性能指标监控
• 异常情况自动告警

关键监控指标：
- 函数调用次数和频率
- 平均执行时间变化趋势  
- CPU使用率分布
- 内存分配和GC情况

告警配置：
• 响应时间超过阈值
• CPU使用率异常升高
• 内存使用异常增长
• 错误率超过预期
```

---

## 9. 📋 核心要点总结


### 9.1 性能分析的关键思路


**🔸 分层分析方法**
```
性能问题的系统性分析：
用户感知层 → 应用服务层 → 中间件层 → 基础设施层

每一层都可能是瓶颈，需要从外到内逐层排查：
1. 先确认问题现象和影响范围
2. 通过监控数据定位大概范围
3. 使用工具深入分析具体原因
4. 验证优化效果，持续监控
```

**🔸 数据驱动优化**
```
避免凭感觉优化，必须依靠数据：
• 建立性能基线，量化问题严重程度
• 使用专业工具准确定位瓶颈
• 优化后对比数据验证效果
• 持续监控防止性能回退
```

### 9.2 实用工具速查


| 分析领域 | **推荐工具** | **使用场景** | **关键命令** |
|---------|------------|-------------|-------------|
| 🖥️ **系统性能** | `top, htop, iostat` | `快速查看系统状态` | `top -p <pid>` |
| 🗄️ **数据库** | `EXPLAIN, 慢查询日志` | `SQL性能分析` | `EXPLAIN SELECT ...` |
| 🌐 **Web服务** | `curl, ab, wrk` | `接口性能测试` | `curl -w "@format.txt"` |
| 🧠 **内存分析** | `valgrind, pmap` | `内存泄露检测` | `valgrind --leak-check=full` |
| 🧵 **并发分析** | `jstack, pstack` | `线程状态分析` | `jstack <pid>` |
| 🔥 **代码热点** | `perf, cProfile` | `CPU热点分析` | `perf record -g <program>` |

### 9.3 性能优化的优先级


**🎯 优化投入产出比排序**
```
高回报优化：
1. 数据库索引优化 - 立竿见影
2. 缓存策略优化 - 显著提升响应速度
3. 热点代码优化 - 精准提升CPU效率

中等回报优化：
4. 线程池参数调优 - 提升并发处理能力
5. JVM参数调优 - 减少GC影响
6. 连接池优化 - 减少连接开销

低回报优化：
7. 代码微优化 - 提升有限
8. 硬件升级 - 成本高，治标不治本
```

### 9.4 生产环境最佳实践


**✅ 监控告警体系**
```
必备监控指标：
• 响应时间：P95, P99响应时间
• 吞吐量：QPS/TPS峰值和趋势  
• 错误率：4xx, 5xx错误比例
• 资源使用：CPU, 内存, 磁盘IO

告警策略：
• 分级告警：警告 → 严重 → 紧急
• 智能降噪：避免告警风暴
• 自动恢复：简单问题自动处理
• 值班机制：确保问题及时响应
```

**🔧 应急处理流程**
```
性能问题应急步骤：
1. 快速评估影响范围和严重程度
2. 启用降级措施，保护核心功能  
3. 定位和修复根本问题
4. 监控修复效果，确保稳定
5. 复盘总结，完善预防机制
```

**核心记忆要点**：
- 性能分析要有系统性思维，分层分析找瓶颈
- 工具配合使用效果好，数据说话最重要
- 优化要抓重点，数据库和缓存是关键
- 生产环境要预防为主，监控告警不能少