---
title: 12、任务并发控制与锁机制
---
## 📚 目录

1. [并发控制基本概念](#1-并发控制基本概念)
2. [任务重复执行问题](#2-任务重复执行问题)
3. [文件锁机制（flock）](#3-文件锁机制flock)
4. [lockfile锁定机制](#4-lockfile锁定机制)
5. [进程互斥控制](#5-进程互斥控制)
6. [任务执行时间检测](#6-任务执行时间检测)
7. [长时间运行任务处理](#7-长时间运行任务处理)
8. [任务队列管理](#8-任务队列管理)
9. [并发任务协调](#9-并发任务协调)
10. [核心要点总结](#10-核心要点总结)

---

## 1. 🔐 并发控制基本概念


### 1.1 什么是任务并发控制


**简单理解**：就像排队买票一样，多个任务要使用同一个资源时，需要有序排队，避免冲突。

```
生活中的例子：
银行ATM机 → 一次只能服务一个人
公共厕所 → 有人在用时，门会锁上

计算机中：
数据库更新 → 避免同时修改同一条记录
日志写入 → 防止日志内容混乱
```

**核心问题**：
- **资源竞争**：多个任务争夺同一资源
- **数据一致性**：保证数据不被破坏
- **任务重复**：防止相同任务多次执行

### 1.2 为什么需要并发控制


**🔸 实际场景举例**

```
定时任务场景：
每分钟执行一次数据备份
→ 如果上次备份还没完成，新的备份又开始了
→ 结果：多个备份进程同时运行，系统资源耗尽

Web服务场景：
多个用户同时修改同一个文件
→ 没有锁控制的话，数据会相互覆盖
→ 结果：数据混乱，业务出错
```

### 1.3 并发控制的基本方法


| 方法类型 | **工作原理** | **适用场景** | **优缺点** |
|---------|------------|-------------|-----------|
| 🔒 **文件锁** | `创建锁文件，获取排他访问权` | `脚本互斥执行` | `简单可靠，但依赖文件系统` |
| 🚪 **进程锁** | `检查进程是否存在` | `服务进程控制` | `快速，但进程意外退出可能有问题` |
| ⏰ **时间控制** | `检查任务执行时间` | `长时间任务管理` | `灵活，但需要准确的时间判断` |

---

## 2. ⚠️ 任务重复执行问题


### 2.1 常见的重复执行场景


**🔸 定时任务重叠**

```bash
# 问题场景：每5分钟备份数据库，但备份需要8分钟
*/5 * * * * /scripts/backup.sh

时间线展示：
00:00 -------- 备份1开始 -------- 00:08 备份1结束
00:05 -------- 备份2开始 -------- 00:13 备份2结束
00:10 -------- 备份3开始 -------- 00:18 备份3结束
      ↑重叠执行，资源竞争↑
```

**🔸 系统负载问题**

> 💡 **问题分析**  
> 当多个相同任务同时运行时，会造成：
> - CPU和内存资源被大量占用
> - 磁盘IO竞争，读写速度下降
> - 网络带宽被瓜分，传输变慢
> - 数据库连接数耗尽，服务异常

### 2.2 如何检测重复执行


**🔧 进程检查方法**

```bash
# 检查是否有同名脚本在运行
if pgrep -f "backup.sh" > /dev/null; then
    echo "备份脚本正在运行，本次跳过"
    exit 0
fi
```

**🔧 PID文件方法**

```bash
#!/bin/bash
PIDFILE="/tmp/backup.pid"

# 检查PID文件是否存在
if [ -f "$PIDFILE" ]; then
    PID=$(cat $PIDFILE)
    # 检查进程是否真的在运行
    if kill -0 $PID 2>/dev/null; then
        echo "任务已在运行 (PID: $PID)"
        exit 0
    fi
fi

# 创建PID文件
echo $$ > $PIDFILE
```

---

## 3. 🔒 文件锁机制（flock）


### 3.1 flock基本概念


**简单理解**：`flock`就像给文件加一把锁，谁先拿到钥匙谁先干活，其他人只能等着。

**🔸 工作原理**

```
文件锁流程：
┌─────────┐    获取锁    ┌─────────┐
│ 进程A   │ ─────────→  │ 锁文件   │
└─────────┘              └─────────┘
                             │
┌─────────┐    等待锁    ┌───▼─────┐
│ 进程B   │ ─────────→  │ 队列等待 │
└─────────┘              └─────────┘
```

### 3.2 flock使用方法


**🔧 基本语法**

```bash
# 语法格式
flock [选项] 锁文件 命令

# 常用选项
-n  # 非阻塞模式，获取不到锁立即退出
-w  # 等待超时时间
-x  # 排他锁（默认）
-s  # 共享锁
```

**🔸 实际使用示例**

```bash
#!/bin/bash
# 使用flock保护脚本执行

LOCKFILE="/tmp/backup.lock"

# 方法1：直接使用flock命令
flock -n $LOCKFILE -c '
    echo "开始执行备份任务..."
    sleep 60  # 模拟备份过程
    echo "备份任务完成"
'

# 如果获取不到锁，上面的命令会立即退出
```

**🔧 更完整的脚本示例**

```bash
#!/bin/bash
LOCKFILE="/tmp/backup.lock"

# 尝试获取锁，最多等待10秒
if flock -w 10 200; then
    echo "成功获取锁，开始执行任务"
    
    # 你的实际任务代码
    echo "正在备份数据库..."
    mysqldump -u root -p database > /backup/db.sql
    echo "备份完成"
    
else
    echo "无法获取锁，可能有其他任务正在执行"
    exit 1
fi 200>$LOCKFILE
```

### 3.3 flock高级用法


**🎯 超时控制**

```bash
#!/bin/bash
LOCKFILE="/tmp/task.lock"

# 等待锁最多30秒，如果获取不到就放弃
if flock -w 30 $LOCKFILE -c 'echo "任务执行中..."; sleep 10'; then
    echo "任务执行成功"
else
    echo "等待超时，任务执行失败"
fi
```

**🎯 非阻塞检查**

```bash
#!/bin/bash
LOCKFILE="/tmp/check.lock"

# 非阻塞模式检查，不等待
if flock -n $LOCKFILE -c 'echo "没有冲突，可以执行"'; then
    echo "检查通过"
else
    echo "有其他任务在执行，本次跳过"
fi
```

---

## 4. 🔐 lockfile锁定机制


### 4.1 lockfile工具介绍


**简单理解**：`lockfile`是另一种创建锁的工具，它通过创建特殊的锁文件来控制访问。

**🔸 与flock的区别**

```
flock特点：
- 进程结束时自动释放锁
- 基于文件描述符的锁定
- 更可靠，不会留下僵尸锁

lockfile特点：
- 手动创建和删除锁文件
- 更灵活，可以跨系统使用
- 需要手动清理，可能留下僵尸锁
```

### 4.2 lockfile基本使用


**🔧 安装lockfile工具**

```bash
# Ubuntu/Debian
sudo apt-get install procmail

# CentOS/RHEL
sudo yum install procmail
```

**🔧 基本使用方法**

```bash
#!/bin/bash
LOCKFILE="/tmp/mytask.lock"

# 创建锁文件，等待最多60秒
if lockfile -r 3 -l 60 $LOCKFILE; then
    echo "获取锁成功，开始执行任务"
    
    # 你的任务代码
    echo "执行业务逻辑..."
    sleep 30
    
    # 手动释放锁
    rm -f $LOCKFILE
    echo "任务完成，锁已释放"
else
    echo "无法获取锁，退出"
    exit 1
fi
```

### 4.3 自制锁机制


**🔧 简单的锁实现**

```bash
#!/bin/bash
create_lock() {
    local lockfile=$1
    local timeout=${2:-30}
    local count=0
    
    while [ $count -lt $timeout ]; do
        # 原子操作创建锁文件
        if (set -C; echo $$ > $lockfile) 2>/dev/null; then
            return 0  # 成功获取锁
        fi
        
        # 检查锁文件中的进程是否还存在
        if [ -f $lockfile ]; then
            local pid=$(cat $lockfile 2>/dev/null)
            if ! kill -0 $pid 2>/dev/null; then
                # 进程不存在，删除僵尸锁
                rm -f $lockfile
                continue
            fi
        fi
        
        sleep 1
        count=$((count + 1))
    done
    
    return 1  # 获取锁失败
}

# 使用示例
LOCKFILE="/tmp/custom.lock"
if create_lock $LOCKFILE 10; then
    echo "获取锁成功"
    # 确保脚本退出时删除锁文件
    trap "rm -f $LOCKFILE; exit" INT TERM EXIT
    
    # 执行任务
    echo "正在执行任务..."
    sleep 20
else
    echo "获取锁失败"
    exit 1
fi
```

---

## 5. 🚦 进程互斥控制


### 5.1 基于进程名的互斥


**简单理解**：检查系统中是否已经有同名进程在运行，如果有就不启动新进程。

**🔧 使用pgrep检查**

```bash
#!/bin/bash
SCRIPT_NAME="data_sync.sh"

# 检查是否有同名脚本在运行（排除当前进程）
if pgrep -f "$SCRIPT_NAME" | grep -v $$ > /dev/null; then
    echo "发现同名脚本正在运行，退出"
    exit 0
fi

echo "开始执行数据同步..."
# 你的任务代码
```

**🔧 更精确的进程检查**

```bash
#!/bin/bash
check_running() {
    local script_name=$1
    local pids=$(pgrep -f "$script_name")
    
    for pid in $pids; do
        # 排除当前进程
        if [ "$pid" != "$$" ]; then
            # 检查进程是否真的存在
            if kill -0 $pid 2>/dev/null; then
                echo "发现运行中的进程: $pid"
                return 0
            fi
        fi
    done
    
    return 1
}

if check_running "backup_database.sh"; then
    echo "备份进程已在运行，本次跳过"
    exit 0
fi
```

### 5.2 PID文件管理


**🔸 完整的PID文件实现**

```bash
#!/bin/bash
PIDFILE="/var/run/myservice.pid"

# 创建PID文件的函数
create_pidfile() {
    local pidfile=$1
    
    # 检查PID文件是否存在
    if [ -f "$pidfile" ]; then
        local old_pid=$(cat $pidfile 2>/dev/null)
        
        # 检查进程是否还在运行
        if [ -n "$old_pid" ] && kill -0 $old_pid 2>/dev/null; then
            echo "进程已在运行 (PID: $old_pid)"
            return 1
        else
            echo "清理僵尸PID文件: $pidfile"
            rm -f $pidfile
        fi
    fi
    
    # 创建新的PID文件
    echo $$ > $pidfile
    return 0
}

# 清理PID文件的函数
cleanup_pidfile() {
    rm -f $PIDFILE
}

# 设置退出时清理
trap cleanup_pidfile EXIT

if create_pidfile $PIDFILE; then
    echo "服务启动成功 (PID: $$)"
    # 你的服务代码
    while true; do
        echo "服务运行中..."
        sleep 10
    done
else
    exit 1
fi
```

---

## 6. ⏱️ 任务执行时间检测


### 6.1 执行时间监控


**简单理解**：记录任务开始和结束时间，如果任务运行时间过长，可以采取相应措施。

**🔧 基本时间检测**

```bash
#!/bin/bash
MAX_RUNTIME=300  # 最大运行时间5分钟

# 记录开始时间
start_time=$(date +%s)

# 在后台执行任务
{
    echo "开始执行长时间任务..."
    # 你的实际任务
    sleep 600  # 模拟10分钟的任务
    echo "任务执行完成"
} &

task_pid=$!

# 监控任务执行时间
while kill -0 $task_pid 2>/dev/null; do
    current_time=$(date +%s)
    runtime=$((current_time - start_time))
    
    if [ $runtime -gt $MAX_RUNTIME ]; then
        echo "任务运行时间过长 ($runtime 秒)，强制终止"
        kill -TERM $task_pid
        sleep 5
        # 如果还没结束，强制杀死
        kill -KILL $task_pid 2>/dev/null
        exit 1
    fi
    
    sleep 10  # 每10秒检查一次
done

# 等待任务完成并获取退出状态
wait $task_pid
exit_code=$?

end_time=$(date +%s)
total_runtime=$((end_time - start_time))
echo "任务完成，总耗时: $total_runtime 秒"
```

### 6.2 基于时间戳的锁


**🔧 时间戳锁文件**

```bash
#!/bin/bash
LOCKFILE="/tmp/timestamp.lock"
MAX_AGE=3600  # 锁文件最大有效期1小时

check_lock_age() {
    local lockfile=$1
    local max_age=$2
    
    if [ -f "$lockfile" ]; then
        local lock_time=$(stat -c %Y "$lockfile" 2>/dev/null)
        local current_time=$(date +%s)
        local age=$((current_time - lock_time))
        
        if [ $age -gt $max_age ]; then
            echo "锁文件过期 (${age}秒)，清理旧锁"
            rm -f "$lockfile"
            return 1
        else
            echo "锁文件有效，剩余时间: $((max_age - age))秒"
            return 0
        fi
    fi
    
    return 1
}

# 检查并创建锁
if check_lock_age $LOCKFILE $MAX_AGE; then
    echo "任务正在执行中，退出"
    exit 0
fi

# 创建新锁
touch $LOCKFILE
echo "开始执行任务..."

# 确保退出时清理锁文件
trap "rm -f $LOCKFILE" EXIT

# 执行你的任务
sleep 30
echo "任务完成"
```

---

## 7. ⌛ 长时间运行任务处理


### 7.1 任务超时处理策略


**🔸 处理策略对比**

| 策略类型 | **描述** | **适用场景** | **实现难度** |
|---------|---------|-------------|-------------|
| 🚫 **强制终止** | `超时直接杀死进程` | `批处理任务` | `简单` |
| ⏸️ **优雅退出** | `发送信号让任务自己退出` | `数据库操作` | `中等` |
| 🔄 **任务分片** | `把大任务分成小块执行` | `大数据处理` | `复杂` |
| 📊 **进度监控** | `监控任务进度，动态调整` | `文件传输` | `中等` |

**🔧 优雅退出实现**

```bash
#!/bin/bash
cleanup_flag="/tmp/cleanup_requested"

# 信号处理函数
handle_signal() {
    echo "收到终止信号，准备优雅退出..."
    touch $cleanup_flag
}

# 注册信号处理
trap handle_signal TERM INT

# 主任务循环
process_data() {
    local total_items=1000
    local processed=0
    
    while [ $processed -lt $total_items ]; do
        # 检查是否需要退出
        if [ -f $cleanup_flag ]; then
            echo "检测到退出请求，保存当前进度..."
            echo $processed > /tmp/progress.txt
            rm -f $cleanup_flag
            exit 0
        fi
        
        # 处理一个数据项
        echo "处理项目 $((processed + 1))/$total_items"
        sleep 1  # 模拟处理时间
        processed=$((processed + 1))
        
        # 定期保存进度
        if [ $((processed % 100)) -eq 0 ]; then
            echo $processed > /tmp/progress.txt
        fi
    done
    
    echo "所有任务处理完成"
}

# 恢复之前的进度
if [ -f /tmp/progress.txt ]; then
    echo "发现之前的进度，是否继续？(y/n)"
    # 在实际脚本中可以自动决定
fi

process_data
```

### 7.2 任务分片执行


**🔧 按时间分片**

```bash
#!/bin/bash
# 将大任务按时间分片执行

BATCH_DURATION=300  # 每批次执行5分钟
TOTAL_WORK_TIME=1800  # 总共需要30分钟

process_batch() {
    local batch_num=$1
    local start_time=$(date +%s)
    
    echo "开始执行第${batch_num}批次"
    
    while true; do
        current_time=$(date +%s)
        elapsed=$((current_time - start_time))
        
        if [ $elapsed -ge $BATCH_DURATION ]; then
            echo "第${batch_num}批次完成，耗时${elapsed}秒"
            break
        fi
        
        # 实际工作代码
        echo "处理中... (已用时${elapsed}秒)"
        sleep 10
    done
}

# 计算需要多少批次
total_batches=$((TOTAL_WORK_TIME / BATCH_DURATION))

for i in $(seq 1 $total_batches); do
    echo "准备执行第${i}批次，总共${total_batches}批次"
    process_batch $i
    
    # 批次间休息
    echo "批次间休息30秒..."
    sleep 30
done

echo "所有批次执行完成"
```

---

## 8. 📋 任务队列管理


### 8.1 简单队列实现


**简单理解**：就像银行排号系统，任务按顺序排队执行，前一个完成后才执行下一个。

**🔧 基于文件的队列**

```bash
#!/bin/bash
QUEUE_DIR="/tmp/task_queue"
QUEUE_FILE="$QUEUE_DIR/queue.txt"
LOCK_FILE="$QUEUE_DIR/queue.lock"

# 初始化队列
init_queue() {
    mkdir -p $QUEUE_DIR
    touch $QUEUE_FILE
}

# 添加任务到队列
add_task() {
    local task_cmd=$1
    local task_id=$(date +%s%N)  # 使用纳秒时间戳作为ID
    
    flock $LOCK_FILE -c "
        echo \"$task_id:$task_cmd\" >> $QUEUE_FILE
        echo \"任务已加入队列: $task_id\"
    "
}

# 从队列获取任务
get_next_task() {
    flock $LOCK_FILE -c "
        if [ -s $QUEUE_FILE ]; then
            # 获取第一行任务
            head -n 1 $QUEUE_FILE
            # 删除第一行
            sed -i '1d' $QUEUE_FILE
        fi
    "
}

# 队列处理器
process_queue() {
    init_queue
    
    echo "队列处理器启动..."
    
    while true; do
        task=$(get_next_task)
        
        if [ -n "$task" ]; then
            task_id=$(echo $task | cut -d: -f1)
            task_cmd=$(echo $task | cut -d: -f2-)
            
            echo "执行任务 $task_id: $task_cmd"
            
            # 执行任务
            if eval $task_cmd; then
                echo "任务 $task_id 执行成功"
            else
                echo "任务 $task_id 执行失败"
                # 可以选择重新加入队列或记录错误
            fi
        else
            # 队列为空，休息一会
            sleep 5
        fi
    done
}

# 使用示例
case $1 in
    "add")
        add_task "$2"
        ;;
    "process")
        process_queue
        ;;
    *)
        echo "用法: $0 {add|process} [任务命令]"
        echo "示例:"
        echo "  $0 add 'echo Hello World'"
        echo "  $0 process"
        ;;
esac
```

### 8.2 优先级队列


**🔧 带优先级的任务队列**

```bash
#!/bin/bash
QUEUE_DIR="/tmp/priority_queue"
HIGH_QUEUE="$QUEUE_DIR/high.txt"
NORMAL_QUEUE="$QUEUE_DIR/normal.txt"
LOW_QUEUE="$QUEUE_DIR/low.txt"

# 添加任务（带优先级）
add_priority_task() {
    local priority=$1
    local task_cmd=$2
    local task_id=$(date +%s%N)
    
    case $priority in
        "high")
            echo "$task_id:$task_cmd" >> $HIGH_QUEUE
            ;;
        "low")
            echo "$task_id:$task_cmd" >> $LOW_QUEUE
            ;;
        *)
            echo "$task_id:$task_cmd" >> $NORMAL_QUEUE
            ;;
    esac
    
    echo "已添加 $priority 优先级任务: $task_id"
}

# 按优先级获取任务
get_priority_task() {
    # 先检查高优先级
    if [ -s $HIGH_QUEUE ]; then
        head -n 1 $HIGH_QUEUE
        sed -i '1d' $HIGH_QUEUE
        return 0
    fi
    
    # 再检查普通优先级
    if [ -s $NORMAL_QUEUE ]; then
        head -n 1 $NORMAL_QUEUE
        sed -i '1d' $NORMAL_QUEUE
        return 0
    fi
    
    # 最后检查低优先级
    if [ -s $LOW_QUEUE ]; then
        head -n 1 $LOW_QUEUE
        sed -i '1d' $LOW_QUEUE
        return 0
    fi
    
    return 1
}
```

---

## 9. 🤝 并发任务协调


### 9.1 任务依赖管理


**简单理解**：就像做菜一样，有些步骤必须按顺序来，洗菜→切菜→炒菜，不能颠倒。

**🔧 简单依赖检查**

```bash
#!/bin/bash
# 任务依赖管理器

TASK_STATUS_DIR="/tmp/task_status"
mkdir -p $TASK_STATUS_DIR

# 标记任务完成
mark_task_done() {
    local task_name=$1
    touch "$TASK_STATUS_DIR/$task_name.done"
    echo "任务 $task_name 已完成"
}

# 检查任务是否完成
is_task_done() {
    local task_name=$1
    [ -f "$TASK_STATUS_DIR/$task_name.done" ]
}

# 等待依赖任务完成
wait_for_dependencies() {
    local dependencies=("$@")
    
    echo "等待依赖任务完成: ${dependencies[*]}"
    
    while true; do
        all_done=true
        
        for dep in "${dependencies[@]}"; do
            if ! is_task_done "$dep"; then
                all_done=false
                echo "等待任务: $dep"
                break
            fi
        done
        
        if $all_done; then
            echo "所有依赖任务已完成"
            break
        fi
        
        sleep 5
    done
}

# 使用示例
case $1 in
    "data_clean")
        echo "开始数据清洗..."
        sleep 10  # 模拟数据清洗
        mark_task_done "data_clean"
        ;;
        
    "data_process")
        wait_for_dependencies "data_clean"
        echo "开始数据处理..."
        sleep 15  # 模拟数据处理
        mark_task_done "data_process"
        ;;
        
    "generate_report")
        wait_for_dependencies "data_clean" "data_process"
        echo "开始生成报告..."
        sleep 8   # 模拟报告生成
        mark_task_done "generate_report"
        ;;
esac
```

### 9.2 资源池管理


**🔧 连接池实现**

```bash
#!/bin/bash
# 简单的资源池管理

POOL_DIR="/tmp/resource_pool"
MAX_CONNECTIONS=3

init_pool() {
    mkdir -p $POOL_DIR
    
    # 创建可用连接
    for i in $(seq 1 $MAX_CONNECTIONS); do
        if [ ! -f "$POOL_DIR/conn_$i.busy" ]; then
            touch "$POOL_DIR/conn_$i.free"
        fi
    done
}

# 获取连接
get_connection() {
    local timeout=${1:-30}
    local count=0
    
    while [ $count -lt $timeout ]; do
        for i in $(seq 1 $MAX_CONNECTIONS); do
            if [ -f "$POOL_DIR/conn_$i.free" ]; then
                # 原子操作：获取连接
                if mv "$POOL_DIR/conn_$i.free" "$POOL_DIR/conn_$i.busy" 2>/dev/null; then
                    echo $i
                    return 0
                fi
            fi
        done
        
        echo "等待可用连接..." >&2
        sleep 1
        count=$((count + 1))
    done
    
    echo "获取连接超时" >&2
    return 1
}

# 释放连接
release_connection() {
    local conn_id=$1
    
    if [ -f "$POOL_DIR/conn_$conn_id.busy" ]; then
        mv "$POOL_DIR/conn_$conn_id.busy" "$POOL_DIR/conn_$conn_id.free"
        echo "连接 $conn_id 已释放"
    fi
}

# 使用示例
use_connection() {
    init_pool
    
    echo "尝试获取数据库连接..."
    if conn_id=$(get_connection 10); then
        echo "获得连接 $conn_id，开始执行任务"
        
        # 模拟数据库操作
        sleep 5
        echo "数据库操作完成"
        
        # 释放连接
        release_connection $conn_id
    else
        echo "无法获取连接，任务失败"
        exit 1
    fi
}

use_connection
```

---

## 10. 📋 核心要点总结


### 10.1 必须掌握的核心概念


```
🔸 并发控制本质：多个任务安全地共享有限资源
🔸 锁机制原理：通过排他性访问保证数据一致性
🔸 文件锁优势：自动释放，可靠性高
🔸 进程控制方法：PID检查，进程信号通信
🔸 时间管理策略：超时控制，任务分片
🔸 队列管理思想：有序执行，负载均衡
```

### 10.2 实际应用场景


**🔹 定时任务场景**
```
数据备份：防止多个备份同时进行
日志轮转：确保日志文件不被并发写入
系统监控：避免监控脚本重复执行
数据同步：保证数据传输的完整性
```

**🔹 Web服务场景**
```
文件上传：控制同时上传的文件数量
数据库操作：防止死锁和数据不一致
缓存更新：确保缓存数据的一致性
会话管理：避免会话冲突
```

### 10.3 最佳实践建议


> 💡 **选择合适的锁机制**  
> - 简单脚本互斥：使用 `flock`
> - 复杂任务协调：使用 PID 文件 + 信号
> - 跨主机协调：使用共享存储 + 时间戳

> ⚠️ **避免常见陷阱**  
> - 总是设置锁超时时间
> - 确保异常退出时清理锁文件
> - 检查僵尸进程和过期锁
> - 合理设置任务执行间隔

> 🔧 **性能优化要点**  
> - 锁粒度要合适：不能太粗也不能太细
> - 减少锁持有时间：尽快完成关键操作
> - 使用非阻塞检查：避免无意义的等待
> - 合理设计任务优先级：重要任务优先执行

**核心记忆口诀**：
- 并发控制防冲突，锁机制来保安全
- 文件锁和进程锁，各有优缺点要分清
- 超时检查防死锁，优雅退出要考虑
- 队列管理有序执行，资源池控制并发数