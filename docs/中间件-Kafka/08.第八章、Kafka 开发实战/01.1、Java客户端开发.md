---
title: 1ã€Javaå®¢æˆ·ç«¯å¼€å‘
---
## ğŸ“š ç›®å½•


1. [Kafka Javaå®¢æˆ·ç«¯åŸºç¡€æ¦‚å¿µ](#1-kafka-javaå®¢æˆ·ç«¯åŸºç¡€æ¦‚å¿µ)
2. [Mavenä¾èµ–ç®¡ç†](#2-mavenä¾èµ–ç®¡ç†)
3. [Producer APIè¯¦è§£ä¸å®æˆ˜](#3-producer-apiè¯¦è§£ä¸å®æˆ˜)
4. [Consumer APIè¯¦è§£ä¸å®æˆ˜](#4-consumer-apiè¯¦è§£ä¸å®æˆ˜)
5. [AdminClient APIç®¡ç†æ“ä½œ](#5-adminclient-apiç®¡ç†æ“ä½œ)
6. [å¼‚å¸¸å¤„ç†ä¸é”™è¯¯æ¢å¤](#6-å¼‚å¸¸å¤„ç†ä¸é”™è¯¯æ¢å¤)
7. [è¿æ¥ç®¡ç†ä¸èµ„æºä¼˜åŒ–](#7-è¿æ¥ç®¡ç†ä¸èµ„æºä¼˜åŒ–)
8. [çº¿ç¨‹å®‰å…¨ä¸å¹¶å‘å¤„ç†](#8-çº¿ç¨‹å®‰å…¨ä¸å¹¶å‘å¤„ç†)
9. [ç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µ](#9-ç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µ)
10. [æ ¸å¿ƒè¦ç‚¹æ€»ç»“](#10-æ ¸å¿ƒè¦ç‚¹æ€»ç»“)

---

# ğŸ¯ **å­¦ä¹ è·¯å¾„å¯¼èˆª**


**å‰ç½®çŸ¥è¯†**ï¼šéœ€è¦æŒæ¡JavaåŸºç¡€ã€Mavené¡¹ç›®ç®¡ç†ã€KafkaåŸºæœ¬æ¦‚å¿µ â†’ **å½“å‰å†…å®¹**ï¼šJavaå®¢æˆ·ç«¯ç¼–ç¨‹ â†’ **åç»­å­¦ä¹ **ï¼šå»ºè®®å­¦ä¹ Spring Booté›†æˆã€å¾®æœåŠ¡æ¶æ„

â±ï¸ **é¢„è®¡å­¦ä¹ æ—¶é—´**ï¼šæœ¬ç« é¢„è®¡90åˆ†é’Ÿ | å®è·µç»ƒä¹ 60åˆ†é’Ÿ

ğŸ·ï¸ **é‡è¦ç¨‹åº¦æ ‡è¯†**ï¼š`#æ ¸å¿ƒå¿…æŒæ¡` `#ç”Ÿäº§å¿…å¤‡` `#é¢è¯•é‡ç‚¹`

---

## 1. ğŸš€ Kafka Javaå®¢æˆ·ç«¯åŸºç¡€æ¦‚å¿µ



### 1.1 ä»€ä¹ˆæ˜¯Kafka Javaå®¢æˆ·ç«¯



**ğŸ”¸ æ ¸å¿ƒå®šä¹‰**
Kafka Javaå®¢æˆ·ç«¯æ˜¯Apache Kafkaå®˜æ–¹æä¾›çš„Javaè¯­è¨€APIåº“ï¼Œè®©æˆ‘ä»¬èƒ½ç”¨Javaä»£ç ä¸Kafkaé›†ç¾¤è¿›è¡Œäº¤äº’ã€‚

**ğŸ’¡ é€šä¿—ç†è§£**
æƒ³è±¡Kafkaæ˜¯ä¸€ä¸ªé‚®å±€ç³»ç»Ÿï¼š
- **Producerï¼ˆç”Ÿäº§è€…ï¼‰**ï¼šåƒå¯„ä¿¡çš„äººï¼ŒæŠŠæ¶ˆæ¯æŠ•é€’åˆ°é‚®ç®±
- **Consumerï¼ˆæ¶ˆè´¹è€…ï¼‰**ï¼šåƒæ”¶ä¿¡çš„äººï¼Œä»é‚®ç®±å–èµ°æ¶ˆæ¯  
- **AdminClientï¼ˆç®¡ç†å‘˜ï¼‰**ï¼šåƒé‚®å±€ç®¡ç†å‘˜ï¼Œè´Ÿè´£åˆ›å»ºé‚®ç®±ã€æŸ¥çœ‹çŠ¶æ€

### 1.2 å®¢æˆ·ç«¯ç±»å‹ä¸èŒè´£



**ğŸ“‹ ä¸‰å¤§æ ¸å¿ƒå®¢æˆ·ç«¯**

| **å®¢æˆ·ç«¯ç±»å‹** | **ä¸»è¦èŒè´£** | **ä½¿ç”¨åœºæ™¯** | **å¤æ‚åº¦** |
|---------------|-------------|-------------|-----------|
| **Producer** | å‘é€æ¶ˆæ¯åˆ°Topic | æ•°æ®é‡‡é›†ã€æ—¥å¿—æ”¶é›† | â­â­ |
| **Consumer** | ä»Topicè¯»å–æ¶ˆæ¯ | æ•°æ®å¤„ç†ã€äº‹ä»¶å“åº” | â­â­â­ |
| **AdminClient** | ç®¡ç†Kafkaé›†ç¾¤ | è¿ç»´ç®¡ç†ã€ç›‘æ§ | â­â­â­â­ |

### 1.3 å®¢æˆ·ç«¯å·¥ä½œåŸç†



**ğŸ”„ æ•°æ®æµè½¬ç¤ºæ„**
```
Javaåº”ç”¨ç¨‹åº
    â†“ Producerå‘é€
Kafka Brokeré›†ç¾¤ (Topic/Partition)
    â†“ Consumeræ¶ˆè´¹
Javaåº”ç”¨ç¨‹åº

ç®¡ç†æµç¨‹ï¼š
AdminClient â†â†’ Kafkaé›†ç¾¤å…ƒæ•°æ®
```

**âš¡ æ ¸å¿ƒç‰¹æ€§**
- **é«˜æ€§èƒ½**ï¼šå¼‚æ­¥å‘é€ï¼Œæ‰¹é‡å¤„ç†
- **å®¹é”™æ€§**ï¼šè‡ªåŠ¨é‡è¯•ï¼Œæ•…éšœè½¬ç§»
- **å¯æ‰©å±•**ï¼šæ”¯æŒåˆ†åŒºï¼Œæ°´å¹³æ‰©å±•
- **äº‹åŠ¡æ€§**ï¼šæ”¯æŒç²¾ç¡®ä¸€æ¬¡è¯­ä¹‰

---

## 2. ğŸ“¦ Mavenä¾èµ–ç®¡ç†



### 2.1 åŸºç¡€ä¾èµ–é…ç½®



**ğŸ“‹ æ ‡å‡†Mavené…ç½®**
åœ¨é¡¹ç›®çš„`pom.xml`æ–‡ä»¶ä¸­æ·»åŠ Kafkaå®¢æˆ·ç«¯ä¾èµ–ï¼š

```xml
<dependencies>
    <!-- Kafkaå®¢æˆ·ç«¯æ ¸å¿ƒåº“ -->
    <dependency>
        <groupId>org.apache.kafka</groupId>
        <artifactId>kafka-clients</artifactId>
        <version>3.5.0</version>
    </dependency>
    
    <!-- æ—¥å¿—æ¡†æ¶ -->
    <dependency>
        <groupId>ch.qos.logback</groupId>
        <artifactId>logback-classic</artifactId>
        <version>1.4.7</version>
    </dependency>
    
    <!-- JSONå¤„ç†åº“ï¼ˆå¯é€‰ï¼‰ -->
    <dependency>
        <groupId>com.fasterxml.jackson.core</groupId>
        <artifactId>jackson-databind</artifactId>
        <version>2.15.2</version>
    </dependency>
</dependencies>
```

### 2.2 ç‰ˆæœ¬é€‰æ‹©æŒ‡å¯¼



**ğŸ¯ ç‰ˆæœ¬å…¼å®¹æ€§è¯´æ˜**

| **Kafkaç‰ˆæœ¬** | **æ¨èåœºæ™¯** | **ä¸»è¦ç‰¹æ€§** |
|---------------|-------------|-------------|
| **3.5.x** | ç”Ÿäº§ç¯å¢ƒé¦–é€‰ | æ€§èƒ½ä¼˜åŒ–ã€å®‰å…¨å¢å¼º |
| **3.3.x** | ç¨³å®šç‰ˆæœ¬ | åŠŸèƒ½å®Œå–„ã€å…¼å®¹æ€§å¥½ |
| **2.8.x** | è€é¡¹ç›®ç»´æŠ¤ | é•¿æœŸæ”¯æŒç‰ˆæœ¬ |

> ğŸ’¡ **é€‰æ‹©å»ºè®®**ï¼šæ–°é¡¹ç›®æ¨èä½¿ç”¨3.5.xç‰ˆæœ¬ï¼Œè€é¡¹ç›®å¯ä»¥æ¸è¿›å¼å‡çº§

### 2.3 é¡¹ç›®ç»“æ„å»ºè®®



**ğŸ“ æ¨èçš„é¡¹ç›®ç›®å½•ç»“æ„**
```
kafka-demo/
â”œâ”€â”€ src/main/java/
â”‚   â”œâ”€â”€ producer/          # ç”Ÿäº§è€…ç›¸å…³ä»£ç 
â”‚   â”œâ”€â”€ consumer/          # æ¶ˆè´¹è€…ç›¸å…³ä»£ç 
â”‚   â”œâ”€â”€ admin/             # ç®¡ç†å®¢æˆ·ç«¯ä»£ç 
â”‚   â””â”€â”€ config/            # é…ç½®ç®¡ç†
â”œâ”€â”€ src/main/resources/
â”‚   â”œâ”€â”€ kafka.properties   # Kafkaé…ç½®æ–‡ä»¶
â”‚   â””â”€â”€ logback.xml        # æ—¥å¿—é…ç½®
â””â”€â”€ pom.xml
```

---

## 3. ğŸ“¤ Producer APIè¯¦è§£ä¸å®æˆ˜



### 3.1 Produceræ ¸å¿ƒæ¦‚å¿µ



**ğŸ”¸ Producerçš„å·¥ä½œåŸç†**
Producerå°±åƒä¸€ä¸ªå¿«é€’å‘˜ï¼Œå®ƒè¦åšä¸‰ä»¶äº‹ï¼š
1. **æ‰“åŒ…æ¶ˆæ¯**ï¼šæŠŠè¦å‘é€çš„æ•°æ®åºåˆ—åŒ–
2. **é€‰æ‹©è·¯çº¿**ï¼šå†³å®šå‘é€åˆ°å“ªä¸ªåˆ†åŒº
3. **æŠ•é€’æ¶ˆæ¯**ï¼šå‘é€åˆ°Kafkaé›†ç¾¤

### 3.2 åŸºç¡€Producerå®ç°



**ğŸ“ æœ€ç®€å•çš„Producerç¤ºä¾‹**

```java
public class SimpleProducer {
    public static void main(String[] args) {
        // 1. åˆ›å»ºProduceré…ç½®
        Properties props = new Properties();
        props.put("bootstrap.servers", "localhost:9092");
        props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        
        // 2. åˆ›å»ºProducerå®ä¾‹
        KafkaProducer<String, String> producer = new KafkaProducer<>(props);
        
        try {
            // 3. å‘é€æ¶ˆæ¯
            ProducerRecord<String, String> record = 
                new ProducerRecord<>("my-topic", "key1", "Hello Kafka!");
            
            producer.send(record);
            System.out.println("æ¶ˆæ¯å‘é€æˆåŠŸï¼");
            
        } finally {
            // 4. å…³é—­Producer
            producer.close();
        }
    }
}
```

**ğŸ’¡ ä»£ç è§£æ**
- `bootstrap.servers`ï¼šå‘Šè¯‰Producerå»å“ªé‡Œæ‰¾Kafkaé›†ç¾¤
- `key.serializer`ï¼šå¦‚ä½•æŠŠkeyè½¬æ¢æˆå­—èŠ‚æµ
- `value.serializer`ï¼šå¦‚ä½•æŠŠæ¶ˆæ¯å†…å®¹è½¬æ¢æˆå­—èŠ‚æµ

### 3.3 Produceræ ¸å¿ƒé…ç½®è¯¦è§£



**âš™ï¸ é‡è¦é…ç½®å‚æ•°**

| **é…ç½®é¡¹** | **ä½œç”¨** | **æ¨èå€¼** | **è¯´æ˜** |
|-----------|---------|-----------|---------|
| `bootstrap.servers` | é›†ç¾¤åœ°å€ | `localhost:9092` | å¤šä¸ªåœ°å€ç”¨é€—å·åˆ†éš” |
| `acks` | ç¡®è®¤æœºåˆ¶ | `all` | ç¡®ä¿æ¶ˆæ¯ä¸ä¸¢å¤± |
| `retries` | é‡è¯•æ¬¡æ•° | `3` | ç½‘ç»œå¼‚å¸¸æ—¶é‡è¯• |
| `batch.size` | æ‰¹æ¬¡å¤§å° | `16384` | æå‡ååé‡ |
| `buffer.memory` | ç¼“å†²åŒºå¤§å° | `33554432` | 32MBç¼“å†² |

### 3.4 å¼‚æ­¥å‘é€ä¸å›è°ƒå¤„ç†



**ğŸš€ å¼‚æ­¥å‘é€ç¤ºä¾‹**

```java
public class AsyncProducer {
    
    public void sendMessageAsync() {
        Properties props = createProducerConfig();
        KafkaProducer<String, String> producer = new KafkaProducer<>(props);
        
        // å¼‚æ­¥å‘é€æ¶ˆæ¯
        producer.send(
            new ProducerRecord<>("my-topic", "async-key", "å¼‚æ­¥æ¶ˆæ¯"),
            new Callback() {
                @Override
                public void onCompletion(RecordMetadata metadata, Exception exception) {
                    if (exception == null) {
                        // å‘é€æˆåŠŸ
                        System.out.printf("æ¶ˆæ¯å‘é€æˆåŠŸï¼špartition=%d, offset=%d%n", 
                            metadata.partition(), metadata.offset());
                    } else {
                        // å‘é€å¤±è´¥
                        System.err.println("æ¶ˆæ¯å‘é€å¤±è´¥ï¼š" + exception.getMessage());
                    }
                }
            }
        );
        
        producer.close();
    }
}
```

**ğŸ’¡ å¼‚æ­¥çš„ä¼˜åŠ¿**
- **é«˜æ€§èƒ½**ï¼šä¸éœ€è¦ç­‰å¾…æœåŠ¡å™¨å“åº”
- **æ‰¹é‡å¤„ç†**ï¼šå¤šæ¡æ¶ˆæ¯ä¸€èµ·å‘é€
- **é”™è¯¯å¤„ç†**ï¼šé€šè¿‡å›è°ƒå¤„ç†æˆåŠŸ/å¤±è´¥æƒ…å†µ

### 3.5 æ¶ˆæ¯åˆ†åŒºç­–ç•¥



**ğŸ¯ åˆ†åŒºé€‰æ‹©æœºåˆ¶**

**é»˜è®¤åˆ†åŒºç­–ç•¥**ï¼š
1. **æœ‰Key**ï¼šæ ¹æ®Keyçš„å“ˆå¸Œå€¼é€‰æ‹©åˆ†åŒº
2. **æ— Key**ï¼šè½®è¯¢æ–¹å¼é€‰æ‹©åˆ†åŒº

**è‡ªå®šä¹‰åˆ†åŒºå™¨ç¤ºä¾‹**ï¼š

```java
public class CustomPartitioner implements Partitioner {
    
    @Override
    public int partition(String topic, Object key, byte[] keyBytes, 
                        Object value, byte[] valueBytes, Cluster cluster) {
        
        int partitionCount = cluster.partitionCountForTopic(topic);
        
        if (key != null) {
            String keyStr = key.toString();
            // æ ¹æ®keyçš„é¦–å­—æ¯é€‰æ‹©åˆ†åŒº
            if (keyStr.startsWith("A")) {
                return 0;
            } else if (keyStr.startsWith("B")) {
                return 1 % partitionCount;
            }
        }
        
        // é»˜è®¤ä½¿ç”¨è½®è¯¢
        return Math.abs(value.hashCode()) % partitionCount;
    }
    
    @Override
    public void configure(Map<String, ?> configs) {}
    
    @Override
    public void close() {}
}
```

---

## 4. ğŸ“¥ Consumer APIè¯¦è§£ä¸å®æˆ˜



### 4.1 Consumeræ ¸å¿ƒæ¦‚å¿µ



**ğŸ”¸ Consumerçš„å·¥ä½œåŸç†**
Consumerå°±åƒä¸€ä¸ªè®¢é˜…æŠ¥çº¸çš„è¯»è€…ï¼š
1. **è®¢é˜…ä¸»é¢˜**ï¼šå‘Šè¯‰ç³»ç»Ÿè¦è¯»å“ªäº›æŠ¥çº¸ï¼ˆTopicï¼‰
2. **å®šæœŸæ‹‰å–**ï¼šä¸»åŠ¨å»å–æ–°çš„æŠ¥çº¸ï¼ˆPullæ¨¡å¼ï¼‰
3. **è®°å½•è¿›åº¦**ï¼šè®°ä½è¯»åˆ°å“ªé‡Œäº†ï¼ˆOffsetï¼‰

### 4.2 åŸºç¡€Consumerå®ç°



**ğŸ“– ç®€å•Consumerç¤ºä¾‹**

```java
public class SimpleConsumer {
    
    public static void main(String[] args) {
        // 1. åˆ›å»ºConsumeré…ç½®
        Properties props = new Properties();
        props.put("bootstrap.servers", "localhost:9092");
        props.put("group.id", "my-consumer-group");
        props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
        props.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
        props.put("auto.offset.reset", "earliest");
        
        // 2. åˆ›å»ºConsumerå®ä¾‹
        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);
        
        try {
            // 3. è®¢é˜…ä¸»é¢˜
            consumer.subscribe(Arrays.asList("my-topic"));
            
            // 4. æ¶ˆè´¹æ¶ˆæ¯
            while (true) {
                ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(1000));
                
                for (ConsumerRecord<String, String> record : records) {
                    System.out.printf("æ¥æ”¶æ¶ˆæ¯ï¼špartition=%d, offset=%d, key=%s, value=%s%n",
                        record.partition(), record.offset(), record.key(), record.value());
                }
            }
            
        } finally {
            consumer.close();
        }
    }
}
```

**ğŸ’¡ ä»£ç è¦ç‚¹**
- `group.id`ï¼šæ¶ˆè´¹è€…ç»„IDï¼ŒåŒç»„å†…çš„æ¶ˆè´¹è€…ä¼šåˆ†æ‘Šåˆ†åŒº
- `auto.offset.reset`ï¼šé¦–æ¬¡æ¶ˆè´¹æ—¶ä»å“ªé‡Œå¼€å§‹è¯»å–
- `poll()`ï¼šæ‹‰å–æ¶ˆæ¯ï¼Œç±»ä¼¼å»é‚®ç®±å–ä¿¡

### 4.3 Consumeræ ¸å¿ƒé…ç½®è¯¦è§£



**âš™ï¸ å…³é”®é…ç½®å‚æ•°**

| **é…ç½®é¡¹** | **ä½œç”¨** | **æ¨èå€¼** | **è¯´æ˜** |
|-----------|---------|-----------|---------|
| `group.id` | æ¶ˆè´¹è€…ç»„ | `my-group` | å¿…å¡«ï¼Œç”¨äºè´Ÿè½½å‡è¡¡ |
| `auto.offset.reset` | åˆå§‹ä½ç½® | `earliest` | latest/earliest/none |
| `enable.auto.commit` | è‡ªåŠ¨æäº¤ | `true` | æ˜¯å¦è‡ªåŠ¨æäº¤offset |
| `max.poll.records` | å•æ¬¡æ‹‰å–æ•°é‡ | `500` | æ§åˆ¶å¤„ç†æ‰¹æ¬¡å¤§å° |
| `session.timeout.ms` | ä¼šè¯è¶…æ—¶ | `10000` | å¿ƒè·³è¶…æ—¶æ—¶é—´ |

### 4.4 æ‰‹åŠ¨æäº¤Offset



**ğŸ›ï¸ ç²¾ç¡®æ§åˆ¶æ¶ˆè´¹è¿›åº¦**

```java
public class ManualCommitConsumer {
    
    public void consumeWithManualCommit() {
        Properties props = createConsumerConfig();
        props.put("enable.auto.commit", "false");  // å…³é—­è‡ªåŠ¨æäº¤
        
        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);
        consumer.subscribe(Arrays.asList("my-topic"));
        
        try {
            while (true) {
                ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(1000));
                
                for (ConsumerRecord<String, String> record : records) {
                    // å¤„ç†æ¶ˆæ¯
                    processMessage(record);
                }
                
                // æ‰‹åŠ¨æäº¤offset
                if (!records.isEmpty()) {
                    consumer.commitSync();  // åŒæ­¥æäº¤
                    System.out.println("Offsetæäº¤æˆåŠŸ");
                }
            }
        } catch (Exception e) {
            System.err.println("æ¶ˆè´¹å¼‚å¸¸ï¼š" + e.getMessage());
        } finally {
            consumer.close();
        }
    }
    
    private void processMessage(ConsumerRecord<String, String> record) {
        // å¤„ç†ä¸šåŠ¡é€»è¾‘
        System.out.println("å¤„ç†æ¶ˆæ¯ï¼š" + record.value());
        
        // æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
        try {
            Thread.sleep(100);
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
        }
    }
}
```

**âš ï¸ æ‰‹åŠ¨æäº¤çš„ä¼˜åŠ¿ä¸æ³¨æ„äº‹é¡¹**

**ä¼˜åŠ¿**ï¼š
- **ç²¾ç¡®æ§åˆ¶**ï¼šåªæœ‰å¤„ç†æˆåŠŸæ‰æäº¤
- **é¿å…é‡å¤**ï¼šé˜²æ­¢æ¶ˆæ¯å¤„ç†åˆ°ä¸€åŠç¨‹åºå´©æºƒ

**æ³¨æ„äº‹é¡¹**ï¼š
- **æ€§èƒ½å½±å“**ï¼šåŒæ­¥æäº¤ä¼šé™ä½ååé‡
- **å¼‚å¸¸å¤„ç†**ï¼šæäº¤å¤±è´¥éœ€è¦é‡è¯•æœºåˆ¶

### 4.5 Consumeræ¶ˆè´¹æ¨¡å¼



**ğŸ”„ å¤šç§æ¶ˆè´¹ç­–ç•¥**

**æŒ‰åˆ†åŒºæ¶ˆè´¹**ï¼š
```java
// æŒ‡å®šåˆ†åŒºæ¶ˆè´¹
TopicPartition partition = new TopicPartition("my-topic", 0);
consumer.assign(Arrays.asList(partition));

// ä»æŒ‡å®šoffsetå¼€å§‹æ¶ˆè´¹
consumer.seek(partition, 100L);
```

**å¤šçº¿ç¨‹æ¶ˆè´¹**ï¼š
```java
public class MultiThreadConsumer {
    
    public void startMultipleConsumers(int threadCount) {
        ExecutorService executor = Executors.newFixedThreadPool(threadCount);
        
        for (int i = 0; i < threadCount; i++) {
            executor.submit(new ConsumerWorker("worker-" + i));
        }
    }
    
    private class ConsumerWorker implements Runnable {
        private final String workerId;
        
        public ConsumerWorker(String workerId) {
            this.workerId = workerId;
        }
        
        @Override
        public void run() {
            KafkaConsumer<String, String> consumer = createConsumer();
            consumer.subscribe(Arrays.asList("my-topic"));
            
            while (!Thread.currentThread().isInterrupted()) {
                ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(1000));
                
                for (ConsumerRecord<String, String> record : records) {
                    System.out.println(workerId + " å¤„ç†æ¶ˆæ¯ï¼š" + record.value());
                }
            }
            
            consumer.close();
        }
    }
}
```

---

## 5. ğŸ› ï¸ AdminClient APIç®¡ç†æ“ä½œ



### 5.1 AdminClientåŸºç¡€ç”¨æ³•



**ğŸ”§ AdminClientçš„ä½œç”¨**
AdminClientå°±åƒæ•°æ®åº“ç®¡ç†å‘˜ï¼Œè´Ÿè´£ï¼š
- **åˆ›å»º/åˆ é™¤Topic**ï¼šç®¡ç†æ¶ˆæ¯ä¸»é¢˜
- **æŸ¥çœ‹é›†ç¾¤ä¿¡æ¯**ï¼šç›‘æ§é›†ç¾¤çŠ¶æ€
- **é…ç½®ç®¡ç†**ï¼šä¿®æ”¹Kafkaé…ç½®

### 5.2 Topicç®¡ç†æ“ä½œ



**ğŸ“‹ Topicåˆ›å»ºä¸ç®¡ç†**

```java
public class KafkaAdminExample {
    
    public void manageTopics() {
        // 1. åˆ›å»ºAdminClient
        Properties props = new Properties();
        props.put("bootstrap.servers", "localhost:9092");
        
        try (AdminClient admin = AdminClient.create(props)) {
            
            // 2. åˆ›å»ºTopic
            createTopic(admin, "new-topic", 3, (short) 1);
            
            // 3. åˆ—å‡ºæ‰€æœ‰Topic
            listTopics(admin);
            
            // 4. åˆ é™¤Topic
            deleteTopic(admin, "old-topic");
            
        } catch (Exception e) {
            System.err.println("ç®¡ç†æ“ä½œå¤±è´¥ï¼š" + e.getMessage());
        }
    }
    
    private void createTopic(AdminClient admin, String topicName, 
                           int partitions, short replicationFactor) throws Exception {
        
        NewTopic newTopic = new NewTopic(topicName, partitions, replicationFactor);
        
        CreateTopicsResult result = admin.createTopics(Collections.singletonList(newTopic));
        result.all().get();  // ç­‰å¾…åˆ›å»ºå®Œæˆ
        
        System.out.println("Topicåˆ›å»ºæˆåŠŸï¼š" + topicName);
    }
    
    private void listTopics(AdminClient admin) throws Exception {
        ListTopicsResult result = admin.listTopics();
        Set<String> topics = result.names().get();
        
        System.out.println("ç°æœ‰Topicåˆ—è¡¨ï¼š");
        topics.forEach(System.out::println);
    }
    
    private void deleteTopic(AdminClient admin, String topicName) throws Exception {
        DeleteTopicsResult result = admin.deleteTopics(Collections.singletonList(topicName));
        result.all().get();  // ç­‰å¾…åˆ é™¤å®Œæˆ
        
        System.out.println("Topicåˆ é™¤æˆåŠŸï¼š" + topicName);
    }
}
```

### 5.3 é›†ç¾¤ä¿¡æ¯æŸ¥è¯¢



**ğŸ“Š é›†ç¾¤çŠ¶æ€ç›‘æ§**

```java
public void monitorCluster(AdminClient admin) throws Exception {
    
    // 1. æŸ¥çœ‹é›†ç¾¤ä¿¡æ¯
    DescribeClusterResult clusterResult = admin.describeCluster();
    Collection<Node> nodes = clusterResult.nodes().get();
    
    System.out.println("é›†ç¾¤èŠ‚ç‚¹ä¿¡æ¯ï¼š");
    for (Node node : nodes) {
        System.out.printf("èŠ‚ç‚¹ï¼š%s:%d (id=%d)%n", 
            node.host(), node.port(), node.id());
    }
    
    // 2. æŸ¥çœ‹Topicè¯¦ç»†ä¿¡æ¯
    DescribeTopicsResult topicsResult = admin.describeTopics(Arrays.asList("my-topic"));
    TopicDescription desc = topicsResult.values().get("my-topic").get();
    
    System.out.println("Topicä¿¡æ¯ï¼š" + desc.name());
    for (TopicPartitionInfo partition : desc.partitions()) {
        System.out.printf("åˆ†åŒº%dï¼šleader=%s, replicas=%s%n",
            partition.partition(), 
            partition.leader().id(),
            partition.replicas().stream().map(n -> String.valueOf(n.id())).collect(Collectors.joining(","))
        );
    }
}
```

---

## 6. âš ï¸ å¼‚å¸¸å¤„ç†ä¸é”™è¯¯æ¢å¤



### 6.1 å¸¸è§å¼‚å¸¸ç±»å‹



**ğŸš¨ Producerå¸¸è§å¼‚å¸¸**

| **å¼‚å¸¸ç±»å‹** | **åŸå› ** | **è§£å†³æ–¹æ¡ˆ** |
|-------------|---------|-------------|
| `TimeoutException` | å‘é€è¶…æ—¶ | å¢åŠ è¶…æ—¶æ—¶é—´æˆ–é‡è¯• |
| `NotLeaderForPartitionException` | åˆ†åŒºLeaderå˜æ›´ | è‡ªåŠ¨é‡è¯•ï¼Œæ— éœ€å¤„ç† |
| `RecordTooLargeException` | æ¶ˆæ¯è¿‡å¤§ | æ‹†åˆ†æ¶ˆæ¯æˆ–è°ƒæ•´é…ç½® |
| `SerializationException` | åºåˆ—åŒ–å¤±è´¥ | æ£€æŸ¥æ•°æ®æ ¼å¼ |

### 6.2 Producerå¼‚å¸¸å¤„ç†



**ğŸ›¡ï¸ å®Œå–„çš„å¼‚å¸¸å¤„ç†æœºåˆ¶**

```java
public class RobustProducer {
    
    private KafkaProducer<String, String> producer;
    private int maxRetries = 3;
    
    public void sendMessageWithRetry(String topic, String key, String value) {
        int attempts = 0;
        
        while (attempts < maxRetries) {
            try {
                ProducerRecord<String, String> record = new ProducerRecord<>(topic, key, value);
                
                Future<RecordMetadata> future = producer.send(record);
                RecordMetadata metadata = future.get(5, TimeUnit.SECONDS);
                
                System.out.printf("æ¶ˆæ¯å‘é€æˆåŠŸï¼špartition=%d, offset=%d%n", 
                    metadata.partition(), metadata.offset());
                return;  // å‘é€æˆåŠŸï¼Œé€€å‡ºé‡è¯•å¾ªç¯
                
            } catch (TimeoutException e) {
                attempts++;
                System.err.printf("å‘é€è¶…æ—¶ï¼Œç¬¬%dæ¬¡é‡è¯•...%n", attempts);
                
                if (attempts >= maxRetries) {
                    System.err.println("é‡è¯•æ¬¡æ•°ç”¨å°½ï¼Œæ¶ˆæ¯å‘é€å¤±è´¥");
                    // å¯ä»¥é€‰æ‹©å†™å…¥æ­»ä¿¡é˜Ÿåˆ—æˆ–æŒä¹…åŒ–é‡è¯•
                    handleFailedMessage(topic, key, value, e);
                }
                
                try {
                    Thread.sleep(1000 * attempts);  // æŒ‡æ•°é€€é¿
                } catch (InterruptedException ie) {
                    Thread.currentThread().interrupt();
                    return;
                }
                
            } catch (SerializationException e) {
                System.err.println("æ¶ˆæ¯åºåˆ—åŒ–å¤±è´¥ï¼Œè·³è¿‡è¯¥æ¶ˆæ¯ï¼š" + e.getMessage());
                return;  // åºåˆ—åŒ–é”™è¯¯ä¸éœ€è¦é‡è¯•
                
            } catch (Exception e) {
                attempts++;
                System.err.printf("å‘é€å¼‚å¸¸ï¼š%sï¼Œç¬¬%dæ¬¡é‡è¯•...%n", e.getMessage(), attempts);
                
                if (attempts >= maxRetries) {
                    handleFailedMessage(topic, key, value, e);
                    return;
                }
            }
        }
    }
    
    private void handleFailedMessage(String topic, String key, String value, Exception e) {
        // å¤„ç†å¤±è´¥æ¶ˆæ¯ï¼šè®°å½•æ—¥å¿—ã€å†™å…¥æ­»ä¿¡é˜Ÿåˆ—ç­‰
        System.err.printf("æ¶ˆæ¯æœ€ç»ˆå‘é€å¤±è´¥ï¼štopic=%s, key=%s, error=%s%n", 
            topic, key, e.getMessage());
        
        // å¯ä»¥å®ç°ä»¥ä¸‹å¤„ç†ç­–ç•¥ï¼š
        // 1. å†™å…¥æœ¬åœ°æ–‡ä»¶ï¼Œç¨åé‡è¯•
        // 2. å‘é€åˆ°æ­»ä¿¡Topic
        // 3. è®°å½•åˆ°æ•°æ®åº“
        // 4. å‘é€å‘Šè­¦é€šçŸ¥
    }
}
```

### 6.3 Consumerå¼‚å¸¸å¤„ç†



**ğŸ”„ Consumeré”™è¯¯æ¢å¤**

```java
public class RobustConsumer {
    
    public void consumeWithErrorHandling() {
        KafkaConsumer<String, String> consumer = createConsumer();
        consumer.subscribe(Arrays.asList("my-topic"));
        
        while (true) {
            try {
                ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(1000));
                
                for (ConsumerRecord<String, String> record : records) {
                    try {
                        processMessage(record);
                    } catch (Exception e) {
                        handleMessageProcessingError(record, e);
                    }
                }
                
                // åªæœ‰æ‰€æœ‰æ¶ˆæ¯éƒ½å¤„ç†æˆåŠŸæ‰æäº¤offset
                consumer.commitSync();
                
            } catch (WakeupException e) {
                System.out.println("Consumerè¢«å”¤é†’ï¼Œå‡†å¤‡å…³é—­");
                break;
                
            } catch (Exception e) {
                System.err.println("æ¶ˆè´¹å¼‚å¸¸ï¼š" + e.getMessage());
                
                // æ ¹æ®å¼‚å¸¸ç±»å‹å†³å®šæ˜¯å¦ç»§ç»­
                if (isRecoverableException(e)) {
                    continue;  // å¯æ¢å¤å¼‚å¸¸ï¼Œç»§ç»­å¤„ç†
                } else {
                    System.err.println("ä¸å¯æ¢å¤å¼‚å¸¸ï¼ŒConsumeråœæ­¢");
                    break;
                }
            }
        }
        
        consumer.close();
    }
    
    private void handleMessageProcessingError(ConsumerRecord<String, String> record, Exception e) {
        System.err.printf("æ¶ˆæ¯å¤„ç†å¤±è´¥ï¼špartition=%d, offset=%d, error=%s%n",
            record.partition(), record.offset(), e.getMessage());
        
        // å¤„ç†ç­–ç•¥ï¼š
        // 1. è®°å½•é”™è¯¯æ—¥å¿—
        // 2. å‘é€åˆ°é”™è¯¯Topic
        // 3. è·³è¿‡è¯¥æ¶ˆæ¯ï¼ˆæ…ç”¨ï¼‰
        // 4. é‡è¯•å¤„ç†ï¼ˆéœ€è¦é˜²æ­¢æ­»å¾ªç¯ï¼‰
    }
    
    private boolean isRecoverableException(Exception e) {
        // åˆ¤æ–­æ˜¯å¦ä¸ºå¯æ¢å¤å¼‚å¸¸
        return !(e instanceof SerializationException);
    }
}
```

---

## 7. ğŸ”— è¿æ¥ç®¡ç†ä¸èµ„æºä¼˜åŒ–



### 7.1 è¿æ¥æ± ç®¡ç†



**âš¡ Producerè¿æ¥ä¼˜åŒ–**

```java
public class KafkaProducerManager {
    
    private static final Map<String, KafkaProducer<String, String>> producerPool = new ConcurrentHashMap<>();
    
    // è·å–æˆ–åˆ›å»ºProducer
    public static KafkaProducer<String, String> getProducer(String configKey) {
        return producerPool.computeIfAbsent(configKey, key -> {
            Properties props = loadProducerConfig(key);
            return new KafkaProducer<>(props);
        });
    }
    
    // å…³é—­æ‰€æœ‰Producer
    public static void closeAllProducers() {
        producerPool.values().forEach(producer -> {
            try {
                producer.close(Duration.ofSeconds(5));
            } catch (Exception e) {
                System.err.println("å…³é—­Producerå¤±è´¥ï¼š" + e.getMessage());
            }
        });
        producerPool.clear();
    }
    
    private static Properties loadProducerConfig(String configKey) {
        Properties props = new Properties();
        props.put("bootstrap.servers", "localhost:9092");
        props.put("key.serializer", StringSerializer.class.getName());
        props.put("value.serializer", StringSerializer.class.getName());
        
        // æ€§èƒ½ä¼˜åŒ–é…ç½®
        props.put("batch.size", 16384);           // æ‰¹æ¬¡å¤§å°
        props.put("linger.ms", 5);                // å»¶è¿Ÿå‘é€
        props.put("buffer.memory", 33554432);     // ç¼“å†²åŒºå¤§å°
        props.put("compression.type", "snappy");  // å‹ç¼©ç®—æ³•
        
        return props;
    }
}
```

### 7.2 èµ„æºç›‘æ§ä¸è°ƒä¼˜



**ğŸ“Š æ€§èƒ½ç›‘æ§æŒ‡æ ‡**

```java
public class KafkaMetricsMonitor {
    
    public void monitorProducerMetrics(KafkaProducer<String, String> producer) {
        Map<MetricName, ? extends Metric> metrics = producer.metrics();
        
        // å…³é”®æ€§èƒ½æŒ‡æ ‡
        printMetric(metrics, "record-send-rate");      // å‘é€é€Ÿç‡
        printMetric(metrics, "record-error-rate");     // é”™è¯¯ç‡
        printMetric(metrics, "record-retry-rate");     // é‡è¯•ç‡
        printMetric(metrics, "batch-size-avg");        // å¹³å‡æ‰¹æ¬¡å¤§å°
        printMetric(metrics, "request-latency-avg");   // å¹³å‡å»¶è¿Ÿ
    }
    
    private void printMetric(Map<MetricName, ? extends Metric> metrics, String metricName) {
        metrics.entrySet().stream()
            .filter(entry -> entry.getKey().name().equals(metricName))
            .forEach(entry -> {
                System.out.printf("%s: %.2f%n", metricName, entry.getValue().metricValue());
            });
    }
}
```

### 7.3 ä¼˜é›…å…³é—­æœºåˆ¶



**ğŸ›‘ å®‰å…¨å…³é—­ç¤ºä¾‹**

```java
public class GracefulShutdownExample {
    
    private volatile boolean running = true;
    private KafkaConsumer<String, String> consumer;
    
    public void startConsumer() {
        // æ³¨å†Œå…³é—­é’©å­
        Runtime.getRuntime().addShutdownHook(new Thread(this::shutdown));
        
        consumer = createConsumer();
        consumer.subscribe(Arrays.asList("my-topic"));
        
        try {
            while (running) {
                ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(1000));
                
                for (ConsumerRecord<String, String> record : records) {
                    processMessage(record);
                    
                    // æ£€æŸ¥æ˜¯å¦éœ€è¦åœæ­¢
                    if (!running) {
                        break;
                    }
                }
                
                if (!records.isEmpty()) {
                    consumer.commitSync();
                }
            }
        } catch (WakeupException e) {
            // æ­£å¸¸å…³é—­ï¼Œä¸éœ€è¦å¤„ç†
        } catch (Exception e) {
            System.err.println("Consumerå¼‚å¸¸ï¼š" + e.getMessage());
        } finally {
            consumer.close();
            System.out.println("Consumerå·²å®‰å…¨å…³é—­");
        }
    }
    
    private void shutdown() {
        System.out.println("å¼€å§‹ä¼˜é›…å…³é—­...");
        running = false;
        
        // å”¤é†’Consumerï¼Œè®©å®ƒé€€å‡ºpoll()å¾ªç¯
        if (consumer != null) {
            consumer.wakeup();
        }
    }
}
```

---

## 8. ğŸ” çº¿ç¨‹å®‰å…¨ä¸å¹¶å‘å¤„ç†



### 8.1 çº¿ç¨‹å®‰å…¨è¯´æ˜



**âš ï¸ é‡è¦å®‰å…¨æç¤º**

| **å®¢æˆ·ç«¯ç±»å‹** | **çº¿ç¨‹å®‰å…¨æ€§** | **ä½¿ç”¨å»ºè®®** |
|---------------|---------------|-------------|
| **KafkaProducer** | âœ… çº¿ç¨‹å®‰å…¨ | å¯åœ¨å¤šçº¿ç¨‹é—´å…±äº« |
| **KafkaConsumer** | âŒ éçº¿ç¨‹å®‰å…¨ | æ¯ä¸ªçº¿ç¨‹ç‹¬äº«ä¸€ä¸ªå®ä¾‹ |
| **AdminClient** | âœ… çº¿ç¨‹å®‰å…¨ | å¯åœ¨å¤šçº¿ç¨‹é—´å…±äº« |

### 8.2 å¤šçº¿ç¨‹Produceræ¨¡å¼



**ğŸš€ é«˜å¹¶å‘Producerå®ç°**

```java
public class MultiThreadProducerExample {
    
    private final KafkaProducer<String, String> sharedProducer;
    private final ExecutorService executorService;
    
    public MultiThreadProducerExample() {
        this.sharedProducer = createProducer();
        this.executorService = Executors.newFixedThreadPool(10);
    }
    
    public void sendMessagesParallel(List<String> messages) {
        for (String message : messages) {
            executorService.submit(() -> {
                try {
                    // Produceræ˜¯çº¿ç¨‹å®‰å…¨çš„ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨
                    ProducerRecord<String, String> record = 
                        new ProducerRecord<>("my-topic", message);
                    
                    sharedProducer.send(record, (metadata, exception) -> {
                        if (exception == null) {
                            System.out.printf("çº¿ç¨‹%så‘é€æˆåŠŸï¼šoffset=%d%n", 
                                Thread.currentThread().getName(), metadata.offset());
                        } else {
                            System.err.println("å‘é€å¤±è´¥ï¼š" + exception.getMessage());
                        }
                    });
                    
                } catch (Exception e) {
                    System.err.println("å‘é€å¼‚å¸¸ï¼š" + e.getMessage());
                }
            });
        }
    }
    
    public void shutdown() {
        executorService.shutdown();
        try {
            if (!executorService.awaitTermination(60, TimeUnit.SECONDS)) {
                executorService.shutdownNow();
            }
        } catch (InterruptedException e) {
            executorService.shutdownNow();
        }
        
        sharedProducer.close();
    }
}
```

### 8.3 Consumerçº¿ç¨‹éš”ç¦»æ¨¡å¼



**ğŸ”„ å®‰å…¨çš„å¤šConsumerå¹¶å‘**

```java
public class MultiConsumerManager {
    
    private final List<ConsumerWorker> workers = new ArrayList<>();
    private final ExecutorService executorService;
    
    public MultiConsumerManager(int consumerCount) {
        this.executorService = Executors.newFixedThreadPool(consumerCount);
        
        // ä¸ºæ¯ä¸ªçº¿ç¨‹åˆ›å»ºç‹¬ç«‹çš„Consumer
        for (int i = 0; i < consumerCount; i++) {
            ConsumerWorker worker = new ConsumerWorker("consumer-" + i);
            workers.add(worker);
            executorService.submit(worker);
        }
    }
    
    private class ConsumerWorker implements Runnable {
        private final String workerId;
        private final KafkaConsumer<String, String> consumer;
        private volatile boolean running = true;
        
        public ConsumerWorker(String workerId) {
            this.workerId = workerId;
            this.consumer = createConsumer(workerId);  // æ¯ä¸ªçº¿ç¨‹ç‹¬ç«‹çš„Consumer
        }
        
        @Override
        public void run() {
            consumer.subscribe(Arrays.asList("my-topic"));
            
            try {
                while (running) {
                    ConsumerRecords<String, String> records = 
                        consumer.poll(Duration.ofMillis(1000));
                    
                    for (ConsumerRecord<String, String> record : records) {
                        processMessage(workerId, record);
                    }
                    
                    if (!records.isEmpty()) {
                        consumer.commitSync();
                    }
                }
            } catch (WakeupException e) {
                // æ­£å¸¸å…³é—­
            } catch (Exception e) {
                System.err.printf("%så¼‚å¸¸ï¼š%s%n", workerId, e.getMessage());
            } finally {
                consumer.close();
                System.out.println(workerId + " å·²å…³é—­");
            }
        }
        
        public void shutdown() {
            running = false;
            consumer.wakeup();
        }
    }
    
    public void shutdownAll() {
        workers.forEach(ConsumerWorker::shutdown);
        executorService.shutdown();
    }
}
```

---

## 9. ğŸ† ç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µ



### 9.1 é…ç½®ä¼˜åŒ–å»ºè®®



**âš™ï¸ ç”Ÿäº§ç¯å¢ƒæ¨èé…ç½®**

**Producerä¼˜åŒ–é…ç½®**ï¼š
```java
public Properties createProductionProducerConfig() {
    Properties props = new Properties();
    
    // åŸºç¡€è¿æ¥é…ç½®
    props.put("bootstrap.servers", "kafka1:9092,kafka2:9092,kafka3:9092");
    props.put("key.serializer", StringSerializer.class.getName());
    props.put("value.serializer", StringSerializer.class.getName());
    
    // å¯é æ€§é…ç½®
    props.put("acks", "all");                    // ç­‰å¾…æ‰€æœ‰å‰¯æœ¬ç¡®è®¤
    props.put("retries", 3);                     // é‡è¯•æ¬¡æ•°
    props.put("retry.backoff.ms", 1000);         // é‡è¯•é—´éš”
    props.put("enable.idempotence", true);       // å¹‚ç­‰æ€§
    
    // æ€§èƒ½ä¼˜åŒ–é…ç½®
    props.put("batch.size", 32768);              // 32KBæ‰¹æ¬¡
    props.put("linger.ms", 10);                  // å»¶è¿Ÿ10ms
    props.put("buffer.memory", 67108864);        // 64MBç¼“å†²
    props.put("compression.type", "snappy");     // å‹ç¼©ç®—æ³•
    
    // è¶…æ—¶é…ç½®
    props.put("request.timeout.ms", 30000);      // è¯·æ±‚è¶…æ—¶30ç§’
    props.put("delivery.timeout.ms", 120000);    // ä¼ è¾“è¶…æ—¶2åˆ†é’Ÿ
    
    return props;
}
```

**Consumerä¼˜åŒ–é…ç½®**ï¼š
```java
public Properties createProductionConsumerConfig() {
    Properties props = new Properties();
    
    // åŸºç¡€è¿æ¥é…ç½®
    props.put("bootstrap.servers", "kafka1:9092,kafka2:9092,kafka3:9092");
    props.put("key.deserializer", StringDeserializer.class.getName());
    props.put("value.deserializer", StringDeserializer.class.getName());
    
    // æ¶ˆè´¹è€…ç»„é…ç½®
    props.put("group.id", "production-consumer-group");
    props.put("client.id", "consumer-" + System.currentTimeMillis());
    
    // å¯é æ€§é…ç½®
    props.put("enable.auto.commit", false);      // æ‰‹åŠ¨æäº¤offset
    props.put("auto.offset.reset", "earliest");  // ä»å¤´å¼€å§‹æ¶ˆè´¹
    
    // æ€§èƒ½ä¼˜åŒ–é…ç½®
    props.put("fetch.min.bytes", 1024);          // æœ€å°æ‹‰å–1KB
    props.put("fetch.max.wait.ms", 500);         // æœ€å¤§ç­‰å¾…500ms
    props.put("max.poll.records", 1000);         // å•æ¬¡æ‹‰å–1000æ¡
    props.put("max.partition.fetch.bytes", 1048576); // åˆ†åŒºæ‹‰å–1MB
    
    // ä¼šè¯é…ç½®
    props.put("session.timeout.ms", 30000);      // ä¼šè¯è¶…æ—¶30ç§’
    props.put("heartbeat.interval.ms", 10000);   // å¿ƒè·³é—´éš”10ç§’
    
    return props;
}
```

### 9.2 é”™è¯¯å¤„ç†ç­–ç•¥



**ğŸ›¡ï¸ å®Œæ•´çš„é”™è¯¯å¤„ç†æ¡†æ¶**

```java
public class ProductionKafkaHandler {
    
    private final KafkaProducer<String, String> producer;
    private final String deadLetterTopic;
    
    public ProductionKafkaHandler() {
        this.producer = new KafkaProducer<>(createProductionProducerConfig());
        this.deadLetterTopic = "dead-letter-topic";
    }
    
    public boolean sendMessageSafely(String topic, String key, String value) {
        int maxRetries = 3;
        int attempt = 0;
        
        while (attempt < maxRetries) {
            try {
                ProducerRecord<String, String> record = new ProducerRecord<>(topic, key, value);
                
                RecordMetadata metadata = producer.send(record).get(30, TimeUnit.SECONDS);
                
                // è®°å½•æˆåŠŸæ—¥å¿—
                logSuccess(topic, key, metadata);
                return true;
                
            } catch (Exception e) {
                attempt++;
                logError(topic, key, attempt, e);
                
                if (attempt >= maxRetries) {
                    // å‘é€åˆ°æ­»ä¿¡é˜Ÿåˆ—
                    sendToDeadLetterQueue(topic, key, value, e);
                    return false;
                }
                
                // æŒ‡æ•°é€€é¿é‡è¯•
                try {
                    Thread.sleep(1000L * attempt);
                } catch (InterruptedException ie) {
                    Thread.currentThread().interrupt();
                    return false;
                }
            }
        }
        
        return false;
    }
    
    private void sendToDeadLetterQueue(String originalTopic, String key, String value, Exception error) {
        try {
            // æ„é€ åŒ…å«é”™è¯¯ä¿¡æ¯çš„æ¶ˆæ¯
            String deadLetterValue = String.format(
                "{\"originalTopic\":\"%s\",\"originalKey\":\"%s\",\"originalValue\":\"%s\",\"error\":\"%s\",\"timestamp\":\"%s\"}",
                originalTopic, key, value, error.getMessage(), Instant.now()
            );
            
            ProducerRecord<String, String> deadLetterRecord = 
                new ProducerRecord<>(deadLetterTopic, key, deadLetterValue);
            
            producer.send(deadLetterRecord);
            
        } catch (Exception e) {
            // æ­»ä¿¡é˜Ÿåˆ—å‘é€å¤±è´¥ï¼Œè®°å½•åˆ°æœ¬åœ°æ–‡ä»¶
            writeToLocalFile(originalTopic, key, value, error);
        }
    }
    
    private void logSuccess(String topic, String key, RecordMetadata metadata) {
        System.out.printf("[SUCCESS] Topic=%s, Key=%s, Partition=%d, Offset=%d%n",
            topic, key, metadata.partition(), metadata.offset());
    }
    
    private void logError(String topic, String key, int attempt, Exception e) {
        System.err.printf("[ERROR] Topic=%s, Key=%s, Attempt=%d, Error=%s%n",
            topic, key, attempt, e.getMessage());
    }
}
```

### 9.3 ç›‘æ§ä¸å‘Šè­¦



**ğŸ“Š ç”Ÿäº§çº§åˆ«ç›‘æ§**

**å…³é”®ç›‘æ§æŒ‡æ ‡**ï¼š
- **ProduceræŒ‡æ ‡**ï¼šå‘é€é€Ÿç‡ã€é”™è¯¯ç‡ã€å»¶è¿Ÿ
- **ConsumeræŒ‡æ ‡**ï¼šæ¶ˆè´¹å»¶è¿Ÿã€å¤„ç†é€Ÿç‡
- **é›†ç¾¤æŒ‡æ ‡**ï¼šåˆ†åŒºçŠ¶æ€ã€å‰¯æœ¬åŒæ­¥

**ç›‘æ§å®ç°ç¤ºä¾‹**ï¼š
```java
public class KafkaMonitoringService {
    
    private final ScheduledExecutorService scheduler = Executors.newScheduledThreadPool(1);
    
    public void startMonitoring(KafkaProducer<String, String> producer, 
                               KafkaConsumer<String, String> consumer) {
        
        // æ¯åˆ†é’Ÿæ”¶é›†ä¸€æ¬¡æŒ‡æ ‡
        scheduler.scheduleAtFixedRate(() -> {
            collectProducerMetrics(producer);
            collectConsumerMetrics(consumer);
        }, 0, 1, TimeUnit.MINUTES);
    }
    
    private void collectProducerMetrics(KafkaProducer<String, String> producer) {
        Map<MetricName, ? extends Metric> metrics = producer.metrics();
        
        double sendRate = getMetricValue(metrics, "record-send-rate");
        double errorRate = getMetricValue(metrics, "record-error-rate");
        double avgLatency = getMetricValue(metrics, "request-latency-avg");
        
        // æ£€æŸ¥å‘Šè­¦é˜ˆå€¼
        if (errorRate > 0.01) {  // é”™è¯¯ç‡è¶…è¿‡1%
            sendAlert("Produceré”™è¯¯ç‡è¿‡é«˜ï¼š" + errorRate);
        }
        
        if (avgLatency > 1000) {  // å»¶è¿Ÿè¶…è¿‡1ç§’
            sendAlert("Producerå»¶è¿Ÿè¿‡é«˜ï¼š" + avgLatency + "ms");
        }
        
        // è®°å½•æŒ‡æ ‡
        System.out.printf("[METRICS] SendRate=%.2f, ErrorRate=%.4f, Latency=%.2fms%n",
            sendRate, errorRate, avgLatency);
    }
    
    private void sendAlert(String message) {
        // å®ç°å‘Šè­¦é€»è¾‘ï¼šé‚®ä»¶ã€çŸ­ä¿¡ã€é’‰é’‰ç­‰
        System.err.println("[ALERT] " + message);
    }
}
```

---

## 10. ğŸ“‹ æ ¸å¿ƒè¦ç‚¹æ€»ç»“



### 10.1 å¿…é¡»æŒæ¡çš„æ ¸å¿ƒæ¦‚å¿µ



```
ğŸ”¸ Kafkaå®¢æˆ·ç«¯ä¸‰å¤§ç±»ï¼šProducerå‘é€æ¶ˆæ¯ã€Consumeræ¶ˆè´¹æ¶ˆæ¯ã€AdminClientç®¡ç†é›†ç¾¤
ğŸ”¸ Mavenä¾èµ–ï¼škafka-clientsæ˜¯æ ¸å¿ƒåº“ï¼Œç‰ˆæœ¬é€‰æ‹©è¦ä¸æœåŠ¡ç«¯åŒ¹é…
ğŸ”¸ Producerç‰¹ç‚¹ï¼šçº¿ç¨‹å®‰å…¨ã€æ”¯æŒå¼‚æ­¥å‘é€ã€å¯é…ç½®åˆ†åŒºç­–ç•¥
ğŸ”¸ Consumerç‰¹ç‚¹ï¼šéçº¿ç¨‹å®‰å…¨ã€æ”¯æŒæ¶ˆè´¹è€…ç»„ã€éœ€è¦ç®¡ç†offset
ğŸ”¸ é…ç½®ä¼˜åŒ–ï¼šç”Ÿäº§ç¯å¢ƒè¦é‡ç‚¹å…³æ³¨å¯é æ€§å’Œæ€§èƒ½é…ç½®
ğŸ”¸ å¼‚å¸¸å¤„ç†ï¼šè¦æœ‰å®Œå–„çš„é‡è¯•æœºåˆ¶å’Œæ­»ä¿¡é˜Ÿåˆ—
```

### 10.2 å…³é”®ç†è§£è¦ç‚¹



**ğŸ”¹ ä¸ºä»€ä¹ˆProduceræ˜¯çº¿ç¨‹å®‰å…¨çš„**
```
è®¾è®¡åŸå› ï¼š
- Producerå†…éƒ¨ä½¿ç”¨äº†çº¿ç¨‹å®‰å…¨çš„æ•°æ®ç»“æ„
- å‘é€æ“ä½œæ˜¯å¼‚æ­¥çš„ï¼Œä¸ä¼šé˜»å¡è°ƒç”¨çº¿ç¨‹
- ä¸€ä¸ªProducerå®ä¾‹å¯ä»¥è¢«å¤šä¸ªçº¿ç¨‹å…±äº«ä½¿ç”¨

å®é™…å¥½å¤„ï¼š
- å‡å°‘è¿æ¥æ•°ï¼ŒèŠ‚çœèµ„æº
- æé«˜å‘é€æ•ˆç‡ï¼Œæ‰¹é‡å¤„ç†
- ç®€åŒ–åº”ç”¨ç¨‹åºä»£ç 
```

**ğŸ”¹ ä¸ºä»€ä¹ˆConsumerä¸æ˜¯çº¿ç¨‹å®‰å…¨çš„**
```
è®¾è®¡åŸå› ï¼š
- Consumeréœ€è¦ç»´æŠ¤å¤æ‚çš„çŠ¶æ€ä¿¡æ¯ï¼ˆoffsetã€åˆ†åŒºåˆ†é…ç­‰ï¼‰
- å¤šçº¿ç¨‹æ“ä½œä¼šå¯¼è‡´çŠ¶æ€ä¸ä¸€è‡´
- ç®€åŒ–å†…éƒ¨å®ç°ï¼Œæé«˜æ€§èƒ½

ä½¿ç”¨å»ºè®®ï¼š
- æ¯ä¸ªæ¶ˆè´¹çº¿ç¨‹ä½¿ç”¨ç‹¬ç«‹çš„Consumerå®ä¾‹
- é€šè¿‡æ¶ˆè´¹è€…ç»„å®ç°å¹¶è¡Œæ¶ˆè´¹
- ä½¿ç”¨çº¿ç¨‹æ± ç®¡ç†å¤šä¸ªConsumer
```

**ğŸ”¹ offsetç®¡ç†çš„é‡è¦æ€§**
```
offsetçš„ä½œç”¨ï¼š
- è®°å½•æ¶ˆè´¹è¿›åº¦ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ 
- é˜²æ­¢æ¶ˆæ¯é‡å¤æ¶ˆè´¹æˆ–ä¸¢å¤±
- å®ç°ç²¾ç¡®ä¸€æ¬¡æ¶ˆè´¹è¯­ä¹‰

ç®¡ç†ç­–ç•¥ï¼š
- è‡ªåŠ¨æäº¤ï¼šç®€å•ä½†å¯èƒ½ä¸¢æ¶ˆæ¯
- æ‰‹åŠ¨æäº¤ï¼šå¯é ä½†éœ€è¦å¤„ç†å¼‚å¸¸
- ä¸šåŠ¡å¹‚ç­‰ï¼šæœ€å®‰å…¨çš„æ–¹å¼
```

### 10.3 ç”Ÿäº§å®è·µç»éªŒ



**ğŸ¯ æ€§èƒ½ä¼˜åŒ–å»ºè®®**
```
Producerä¼˜åŒ–ï¼š
- å¯ç”¨æ‰¹é‡å‘é€ï¼ˆbatch.sizeã€linger.msï¼‰
- ä½¿ç”¨å‹ç¼©ç®—æ³•å‡å°‘ç½‘ç»œä¼ è¾“
- åˆç†è®¾ç½®ç¼“å†²åŒºå¤§å°
- å¯ç”¨å¹‚ç­‰æ€§ä¿è¯æ¶ˆæ¯ä¸é‡å¤

Consumerä¼˜åŒ–ï¼š
- è°ƒæ•´æ‹‰å–å‚æ•°ï¼ˆfetch.min.bytesã€max.poll.recordsï¼‰
- ä½¿ç”¨å¤šçº¿ç¨‹æˆ–å¤šè¿›ç¨‹å¹¶è¡Œæ¶ˆè´¹
- åˆç†è®¾ç½®å¿ƒè·³å’Œä¼šè¯è¶…æ—¶æ—¶é—´
- æ‰‹åŠ¨ç®¡ç†offsetæäº¤
```

**ğŸ›¡ï¸ å¯é æ€§ä¿éšœ**
```
æ¶ˆæ¯ä¸ä¸¢å¤±ï¼š
- Producerè®¾ç½®acks=all
- Consumeræ‰‹åŠ¨æäº¤offset
- ä½¿ç”¨äº‹åŠ¡ä¿è¯åŸå­æ€§

æ¶ˆæ¯ä¸é‡å¤ï¼š
- Producerå¯ç”¨å¹‚ç­‰æ€§
- Consumerä¸šåŠ¡é€»è¾‘å¹‚ç­‰
- ä½¿ç”¨å”¯ä¸€é”®å»é‡

é«˜å¯ç”¨ä¿éšœï¼š
- å¤šä¸ªbrokeråœ°å€
- åˆç†çš„é‡è¯•å’Œè¶…æ—¶é…ç½®
- ç›‘æ§å’Œå‘Šè­¦æœºåˆ¶
```

### 10.4 å­¦ä¹ æ£€æŸ¥æ¸…å•



- [ ] èƒ½å¤Ÿåˆ›å»ºå¹¶é…ç½®Producerå‘é€æ¶ˆæ¯
- [ ] ç†è§£Consumerçš„æ¶ˆè´¹æ¨¡å¼å’Œoffsetç®¡ç†
- [ ] æŒæ¡AdminClientçš„åŸºæœ¬ç®¡ç†æ“ä½œ
- [ ] ä¼šå¤„ç†å¸¸è§å¼‚å¸¸å’Œé”™è¯¯æ¢å¤
- [ ] äº†è§£çº¿ç¨‹å®‰å…¨æ€§å’Œå¹¶å‘å¤„ç†
- [ ] èƒ½å¤Ÿç¼–å†™ç”Ÿäº§çº§åˆ«çš„Kafkaåº”ç”¨

### 10.5 å¸¸è§é¢è¯•é—®é¢˜



**ğŸ¯ é«˜é¢‘é¢è¯•é¢˜**
- **Q**: Kafka Consumeræ˜¯å¦çº¿ç¨‹å®‰å…¨ï¼Ÿ
- **A**: ä¸æ˜¯ã€‚æ¯ä¸ªçº¿ç¨‹éœ€è¦ç‹¬ç«‹çš„Consumerå®ä¾‹

- **Q**: å¦‚ä½•ä¿è¯æ¶ˆæ¯ä¸ä¸¢å¤±ï¼Ÿ
- **A**: Producerè®¾ç½®acks=allï¼ŒConsumeræ‰‹åŠ¨æäº¤offset

- **Q**: ä»€ä¹ˆæ˜¯Consumer Groupï¼Ÿ
- **A**: å¤šä¸ªConsumerç»„æˆçš„ç»„ï¼Œè‡ªåŠ¨åˆ†é…åˆ†åŒºï¼Œå®ç°è´Ÿè½½å‡è¡¡

**ğŸ”‘ æ ¸å¿ƒè®°å¿†å£è¯€**
> Producerçº¿ç¨‹å®‰å…¨å¯å…±äº«ï¼ŒConsumerç‹¬ç«‹å„è‡ªç®¡
> å¼‚æ­¥å‘é€é…å›è°ƒï¼Œæ‰‹åŠ¨æäº¤æ›´å¯é 
> å¼‚å¸¸å¤„ç†è¦å®Œå–„ï¼Œç›‘æ§å‘Šè­¦ä¿å¹³å®‰

**ğŸ’¡ å»¶ä¼¸å­¦ä¹ å»ºè®®**
- æ·±å…¥å­¦ä¹ Kafka Stream APIè¿›è¡Œæµå¤„ç†
- äº†è§£Schema Registryè¿›è¡Œæ¶ˆæ¯æ ¼å¼ç®¡ç†
- ç ”ç©¶Kafka Connectè¿›è¡Œæ•°æ®é›†æˆ
- å­¦ä¹ Spring Bootä¸Kafkaçš„é›†æˆå¼€å‘