---
title: 17、日志清理
---
## 📚 目录

1. [日志清理基本概念](#1-日志清理基本概念)
2. [清理策略详解](#2-清理策略详解)
3. [kafka-log-cleaner.sh工具使用](#3-kafka-log-cleanersh工具使用)
4. [压实日志管理](#4-压实日志管理)
5. [清理进度监控](#5-清理进度监控)
6. [性能调优实践](#6-性能调优实践)
7. [异常处理与故障排查](#7-异常处理与故障排查)
8. [核心要点总结](#8-核心要点总结)

---

## 1. 🧹 日志清理基本概念


### 1.1 什么是Kafka日志清理


**🔸 简单理解**
想象你的电脑硬盘空间有限，但每天都在产生新文件。如果不定期清理，硬盘很快就会满。Kafka的日志清理就是这个道理 - 定期清理老旧数据，为新数据腾出空间。

**🔸 专业定义**
Kafka日志清理（Log Cleaning）是一种自动化的数据管理机制，用于：
- **回收存储空间**：删除过期或不需要的数据
- **保持性能**：防止日志文件过大影响读写性能
- **数据压缩**：对重复键的消息进行合并优化

### 1.2 为什么需要日志清理


**🎯 核心原因**

```
数据增长问题：
生产者持续写入 → 日志文件不断增大 → 磁盘空间耗尽
     ↓                ↓                ↓
性能下降问题     存储成本上升        系统不可用

日志清理解决方案：
自动删除过期数据 → 控制存储使用 → 保持系统稳定
     ↓                ↓                ↓
释放磁盘空间     降低存储成本        维持高性能
```

**💡 生活类比**
就像家里的垃圾桶，如果不定期倒垃圾，很快就会满溢。Kafka的日志清理就是"自动倒垃圾"的机制。

### 1.3 清理机制概览


**🔸 两种主要策略**

| 清理策略 | **工作原理** | **适用场景** | **数据保留** |
|---------|-------------|-------------|-------------|
| 🗑️ **删除清理** | `基于时间或大小删除整个段` | `日志类数据，不需要历史` | `完全删除` |
| 🗜️ **压实清理** | `保留每个键的最新值` | `状态类数据，需要最新状态` | `保留最新值` |

---

## 2. ⚙️ 清理策略详解


### 2.1 删除清理策略（Delete）


**🔸 基本工作原理**
删除清理就像定期清空回收站，到了指定时间或大小限制时，直接删除整个日志段。

**🔸 触发条件配置**

```properties
# 基于时间的清理（保留7天数据）

log.retention.hours=168
log.retention.minutes=10080
log.retention.ms=604800000

# 基于大小的清理（保留1GB数据）

log.retention.bytes=1073741824

# 基于日志段大小的清理

log.segment.bytes=1073741824
log.segment.ms=604800000
```

**💡 配置说明**
- `log.retention.hours`：数据保留小时数，默认168小时（7天）
- `log.retention.bytes`：每个分区保留的最大字节数
- `log.segment.bytes`：单个日志段的最大大小

**🔸 删除过程示意**

```
时间轴示意：
Day1   Day2   Day3   Day4   Day5   Day6   Day7   Day8
[段1]  [段2]  [段3]  [段4]  [段5]  [段6]  [段7]  [段8]
  ↓      ↓      ↓                                  ↑
删除   删除   删除                              当前活跃段

保留策略：保留7天数据
结果：段1、段2、段3被删除，段4-段8保留
```

### 2.2 压实清理策略（Compact）


**🔸 基本工作原理**
压实清理像是整理通讯录，如果同一个人有多个电话号码记录，只保留最新的那个。

**🔸 压实过程图解**

```
压实前的日志：
Offset: 0    1    2    3    4    5    6    7
Key:   [A]  [B]  [A]  [C]  [B]  [A]  [D]  [C]
Value: v1   v1   v2   v1   v2   v3   v1   v2

压实后的日志：
Offset: 5    6    7
Key:   [A]  [D]  [C]
Value: v3   v1   v2

解释：保留每个键的最新值
- 键A：最新值是v3（offset 5）
- 键B：被完全删除（没有在保留范围内）
- 键C：最新值是v2（offset 7）
- 键D：最新值是v1（offset 6）
```

**🔸 压实配置参数**

```properties
# 启用日志压实

log.cleanup.policy=compact

# 压实相关参数

log.cleaner.min.cleanable.ratio=0.5
log.cleaner.min.compaction.lag.ms=0
log.segment.bytes=104857600
```

**💡 参数解释**
- `log.cleanup.policy=compact`：启用压实清理
- `log.cleaner.min.cleanable.ratio`：可清理比例阈值
- `log.cleaner.min.compaction.lag.ms`：压实延迟时间

---

## 3. 🛠️ kafka-log-cleaner.sh工具使用


### 3.1 工具基本介绍


**🔸 工具作用**
`kafka-log-cleaner.sh`是Kafka提供的日志清理管理工具，用于：
- 查看清理状态
- 手动触发清理
- 调试清理问题

> 💡 **注意事项**  
> 这个工具主要用于监控和调试，实际的清理工作是由Kafka内置的清理线程自动完成的。

### 3.2 常用命令操作


**🔸 查看清理状态**

```bash
# 查看所有主题的清理状态

kafka-log-cleaner.sh --bootstrap-server localhost:9092 \
  --describe

# 查看特定主题的清理状态  

kafka-log-cleaner.sh --bootstrap-server localhost:9092 \
  --describe --topic my-topic
```

**🔸 启动/停止清理线程**

```bash
# 启动日志清理线程

kafka-log-cleaner.sh --bootstrap-server localhost:9092 \
  --start

# 停止日志清理线程

kafka-log-cleaner.sh --bootstrap-server localhost:9092 \
  --stop
```

**🔸 查看清理进度**

```bash
# 查看清理线程状态

kafka-log-cleaner.sh --bootstrap-server localhost:9092 \
  --status

# 查看清理历史记录

kafka-log-cleaner.sh --bootstrap-server localhost:9092 \
  --history --topic my-topic
```

### 3.3 实际操作示例


**🚀 完整操作流程**

```bash
# 1. 检查当前清理状态

kafka-log-cleaner.sh --bootstrap-server localhost:9092 --describe

# 2. 查看特定主题信息

kafka-topics.sh --bootstrap-server localhost:9092 \
  --describe --topic user-events

# 3. 修改主题清理策略为压实

kafka-configs.sh --bootstrap-server localhost:9092 \
  --entity-type topics --entity-name user-events \
  --alter --add-config cleanup.policy=compact

# 4. 验证配置是否生效

kafka-configs.sh --bootstrap-server localhost:9092 \
  --entity-type topics --entity-name user-events \
  --describe
```

---

## 4. 🗜️ 压实日志管理


### 4.1 压实日志的核心概念


**🔸 什么是压实日志**
压实日志就像一个"智能存储柜"，对于同一个物品（键），只保留最新的版本，自动丢弃旧版本。

**🔸 压实的工作机制**

```
压实过程详解：

1. 日志分段：
   [活跃段]    [可压实段1]    [可压实段2]
   最新数据     较旧数据        最旧数据

2. 构建索引：
   键A → 最新offset
   键B → 最新offset  
   键C → 最新offset

3. 重写日志：
   只保留索引中记录的最新值
   删除所有旧值

4. 替换原段：
   用压实后的新段替换原来的多个段
```

### 4.2 压实配置最佳实践


**🔸 关键配置参数**

```properties
# 核心压实配置

cleanup.policy=compact
segment.bytes=104857600          # 100MB段大小
min.cleanable.dirty.ratio=0.5    # 50%可清理比例
delete.retention.ms=86400000     # 删除标记保留1天

# 性能优化配置

cleaner.threads=2                # 清理线程数
cleaner.io.max.bytes.per.second=104857600  # 清理IO限制
segment.ms=604800000            # 7天后段可被压实
```

**💡 配置说明表格**

| 参数名称 | **默认值** | **作用说明** | **调优建议** |
|---------|-----------|-------------|-------------|
| `min.cleanable.dirty.ratio` | `0.5` | `可压实的脏数据比例` | `高写入频率可调低至0.3` |
| `segment.bytes` | `1GB` | `段文件大小限制` | `高吞吐量可设为100MB` |
| `delete.retention.ms` | `24h` | `删除标记保留时间` | `根据消费者延迟调整` |

### 4.3 压实日志应用场景


**🔸 典型使用案例**

```
用户状态管理：
键：user_id_123
值：用户最新状态信息

配置管理：
键：config_key_name  
值：配置的最新值

商品信息：
键：product_id_456
值：商品最新价格和库存
```

> 🎯 **适用判断**  
> 如果你的数据特点是"每个键只关心最新值"，那么压实清理就是最佳选择。

---

## 5. 📊 清理进度监控


### 5.1 监控关键指标


**🔸 核心监控指标**

```
清理性能指标：
┌─────────────────────────────────┐
│ 清理吞吐量   │ 清理完成率        │
│ 清理延迟     │ 错误清理次数      │
│ 清理线程状态 │ 存储空间回收率    │
└─────────────────────────────────┘
```

**🔸 JMX监控指标**

| 指标名称 | **JMX路径** | **含义说明** |
|---------|------------|-------------|
| `cleaner-recopy-percent` | `kafka.log:type=LogCleaner,name=cleaner-recopy-percent` | `清理重复拷贝百分比` |
| `max-buffer-utilization` | `kafka.log:type=LogCleaner,name=max-buffer-utilization-percent` | `缓冲区最大使用率` |
| `cleaner-runs` | `kafka.log:type=LogCleaner,name=cleaner-runs` | `清理运行次数` |

### 5.2 实际监控命令


**🔸 查看清理状态**

```bash
# 检查清理线程状态

kafka-log-cleaner.sh --bootstrap-server localhost:9092 --describe

# 查看JMX指标（需要启用JMX）

jconsole localhost:9999
# 或使用命令行工具

java -jar jmxterm-1.0.0-uber.jar -l localhost:9999
```

**🔸 日志文件监控**

```bash
# 查看清理相关日志

tail -f /var/log/kafka/server.log | grep -i "log.cleaner"

# 监控清理进度

grep "Log cleaner thread" /var/log/kafka/server.log
```

### 5.3 清理进度计算


**🔸 进度计算公式**

```
清理进度 = (已清理字节数 / 总可清理字节数) × 100%

可清理比例 = 脏数据字节数 / 总段字节数

预计完成时间 = 剩余数据量 / 当前清理速率
```

---

## 6. ⚡ 性能调优实践


### 6.1 清理性能影响因素


**🔸 主要性能因素**

```
影响因素分析：
  数据写入速率 ──┐
  清理线程数量 ──┤
  磁盘IO性能  ──┼──▶ 清理性能
  内存缓冲区   ──┤
  网络带宽     ──┘
```

**🔸 性能瓶颈识别**

| 瓶颈类型 | **表现症状** | **解决方案** |
|---------|-------------|-------------|
| 🔴 **CPU瓶颈** | `清理线程CPU使用率100%` | `增加清理线程数量` |
| 🟡 **磁盘IO瓶颈** | `磁盘IO等待时间长` | `限制清理IO速率` |
| 🔵 **内存瓶颈** | `缓冲区使用率高` | `增大清理缓冲区` |

### 6.2 性能调优配置


**🔸 高性能清理配置**

```properties
# 清理线程优化

log.cleaner.threads=4                    # 增加清理线程
log.cleaner.io.max.bytes.per.second=209715200  # 200MB/s IO限制

# 内存优化

log.cleaner.buffer.size=134217728        # 128MB清理缓冲区
log.cleaner.io.buffer.size=524288        # 512KB IO缓冲区

# 清理频率优化

log.cleaner.min.cleanable.ratio=0.3     # 降低清理阈值
log.cleaner.backoff.ms=15000             # 清理间隔15秒
```

**🔸 分场景调优策略**

```
高写入场景：
- 降低min.cleanable.ratio到0.3
- 增加cleaner.threads到CPU核数
- 适当增大buffer.size

高读取场景：  
- 限制cleaner.io.max.bytes.per.second
- 错峰进行清理操作
- 监控清理对读取延迟的影响

存储受限场景：
- 提高清理频率
- 降低segment.bytes
- 缩短retention时间
```

### 6.3 性能监控与调优


**🔸 性能监控脚本示例**

```bash
#!/bin/bash

# Kafka清理性能监控脚本


echo "=== Kafka清理性能报告 ==="
echo "时间: $(date)"

# 检查清理线程状态

echo "1. 清理线程状态:"
kafka-log-cleaner.sh --bootstrap-server localhost:9092 --describe

# 检查磁盘使用情况

echo "2. 磁盘使用情况:"
df -h /var/kafka-logs

# 检查清理相关JMX指标

echo "3. 清理性能指标:"
# 这里需要配置JMX监控工具

echo "请查看JMX监控面板获取详细指标"
```

---

## 7. 🚨 异常处理与故障排查


### 7.1 常见清理异常


**🔸 典型异常类型**

```
异常分类：
  清理线程死锁 ──┐
  磁盘空间不足 ──┤
  配置参数错误 ──┼──▶ 清理失败
  索引损坏     ──┤
  权限问题     ──┘
```

**🔸 异常症状与原因**

| 异常症状 | **可能原因** | **排查方法** |
|---------|-------------|-------------|
| 🔴 **清理停止** | `线程异常退出` | `查看server.log错误日志` |
| 🟡 **清理缓慢** | `IO性能不足` | `监控磁盘IO和CPU使用率` |
| 🔵 **内存溢出** | `缓冲区配置过大` | `调整buffer.size参数` |

### 7.2 故障诊断步骤


**🔸 标准诊断流程**

```
1️⃣ 检查清理线程状态
   ↓
2️⃣ 查看错误日志
   ↓  
3️⃣ 验证配置参数
   ↓
4️⃣ 检查系统资源
   ↓
5️⃣ 测试手动清理
```

**🔸 诊断命令集合**

```bash
# 1. 检查清理线程状态

kafka-log-cleaner.sh --bootstrap-server localhost:9092 --describe

# 2. 查看详细错误日志

grep -i "error\|exception" /var/log/kafka/server.log | grep -i cleaner

# 3. 检查磁盘空间

df -h /var/kafka-logs
du -sh /var/kafka-logs/*

# 4. 检查进程状态

ps aux | grep kafka
top -p $(pgrep -f kafka)

# 5. 验证主题配置

kafka-configs.sh --bootstrap-server localhost:9092 \
  --entity-type topics --entity-name problem-topic --describe
```

### 7.3 异常处理方案


**🔸 常用修复方法**

> ⚠️ **重要提醒**  
> 在生产环境进行任何修复操作前，请务必备份重要数据！

```bash
# 重启清理线程

kafka-log-cleaner.sh --bootstrap-server localhost:9092 --stop
kafka-log-cleaner.sh --bootstrap-server localhost:9092 --start

# 重置有问题的主题配置

kafka-configs.sh --bootstrap-server localhost:9092 \
  --entity-type topics --entity-name problem-topic \
  --alter --delete-config cleanup.policy

# 手动删除损坏的日志段（谨慎操作）

# 停止Kafka服务后，删除问题日志文件

sudo systemctl stop kafka
rm -f /var/kafka-logs/problem-topic-0/*.index
sudo systemctl start kafka
```

### 7.4 预防措施


**🔸 预防性配置**

```properties
# 增强错误处理

log.cleaner.abort.on.error=false        # 遇到错误继续清理
log.cleaner.delete.retention.ms=86400000 # 保留删除标记1天

# 监控配置

log.cleaner.enable=true                  # 确保清理功能启用
log.retention.check.interval.ms=300000  # 5分钟检查一次
```

**🔸 运维最佳实践**

```
📋 运维检查清单：
- [ ] 定期监控磁盘使用率
- [ ] 设置清理性能告警
- [ ] 备份重要配置文件
- [ ] 记录清理操作日志
- [ ] 定期清理监控数据
```

---

## 8. 📋 核心要点总结


### 8.1 必须掌握的关键概念


```
🔸 清理策略：删除清理 vs 压实清理
🔸 工具使用：kafka-log-cleaner.sh的基本操作
🔸 配置管理：关键参数的含义和调优
🔸 监控诊断：性能指标和异常排查方法
🔸 最佳实践：不同场景下的配置策略
```

### 8.2 实用记忆要点


**🧠 核心概念速记**
- **删除清理**：像清空垃圾桶，到时间就全部删掉
- **压实清理**：像整理通讯录，每个人只保留最新信息
- **清理工具**：主要用于监控和调试，不是手动清理
- **性能调优**：平衡清理速度和系统性能

### 8.3 实际应用指导


**🎯 选择清理策略的判断标准**

```
删除清理适用场景：
✅ 日志型数据（如访问日志）
✅ 时间序列数据  
✅ 不需要保留历史状态
✅ 存储成本敏感

压实清理适用场景：
✅ 状态型数据（如用户信息）
✅ 配置数据
✅ 需要保留最新状态
✅ 键值对数据
```

**🔧 运维操作建议**

```
日常运维：
1️⃣ 监控清理线程状态
2️⃣ 定期检查磁盘使用率  
3️⃣ 关注清理性能指标
4️⃣ 备份重要配置

问题处理：
1️⃣ 先查看日志文件
2️⃣ 检查系统资源状况
3️⃣ 验证配置参数
4️⃣ 必要时重启清理线程
```

### 8.4 学习进阶路径


**📈 深入学习建议**

```
基础掌握 → 配置调优 → 监控诊断 → 故障处理
   ↓           ↓          ↓          ↓
理解概念    实际配置    性能监控    问题解决
```

**🔗 相关知识扩展**
- 深入学习：[Kafka存储原理](#kafka存储原理)
- 实战应用：[生产环境配置](#生产环境配置)  
- 监控运维：[集群监控体系](#集群监控体系)

---

> 💡 **学习提醒**  
> Kafka日志清理是保障集群稳定运行的重要机制。建议在测试环境充分实践后，再应用到生产环境。记住：理解原理比死记命令更重要！

**🎯 核心记忆口诀**：
- 删除清理像倒垃圾，压实清理像整理柜
- 监控状态很重要，异常排查有章法
- 配置调优需谨慎，生产操作要备份