---
title: 6ã€æ•°æ®å¯é æ€§ä¿è¯
---
## ğŸ“š ç›®å½•

1. [æ•°æ®å¯é æ€§åŸºç¡€æ¦‚å¿µ](#1-æ•°æ®å¯é æ€§åŸºç¡€æ¦‚å¿µ)
2. [æ•°æ®ä¸ä¸¢å¤±ä¿è¯æœºåˆ¶](#2-æ•°æ®ä¸ä¸¢å¤±ä¿è¯æœºåˆ¶)
3. [æ¶ˆæ¯å»é‡ç­–ç•¥](#3-æ¶ˆæ¯å»é‡ç­–ç•¥)
4. [é¡ºåºä¿è¯æœºåˆ¶](#4-é¡ºåºä¿è¯æœºåˆ¶)
5. [ä¸€è‡´æ€§ä¿è¯](#5-ä¸€è‡´æ€§ä¿è¯)
6. [è·¨æ•°æ®ä¸­å¿ƒå¤åˆ¶](#6-è·¨æ•°æ®ä¸­å¿ƒå¤åˆ¶)
7. [ç¾éš¾æ¢å¤ç­–ç•¥](#7-ç¾éš¾æ¢å¤ç­–ç•¥)
8. [æ•°æ®æ ¡éªŒæœºåˆ¶](#8-æ•°æ®æ ¡éªŒæœºåˆ¶)
9. [å¯é æ€§æµ‹è¯•æ–¹æ³•](#9-å¯é æ€§æµ‹è¯•æ–¹æ³•)
10. [ç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µ](#10-ç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µ)
11. [æ ¸å¿ƒè¦ç‚¹æ€»ç»“](#11-æ ¸å¿ƒè¦ç‚¹æ€»ç»“)

---

## 1. ğŸ›¡ï¸ æ•°æ®å¯é æ€§åŸºç¡€æ¦‚å¿µ


### 1.1 ä»€ä¹ˆæ˜¯æ•°æ®å¯é æ€§


**ğŸ”¸ é€šä¿—ç†è§£**
æƒ³è±¡ä½ åœ¨å¯„å¿«é€’ï¼Œæ•°æ®å¯é æ€§å°±åƒç¡®ä¿ï¼š
- åŒ…è£¹ä¸ä¼šä¸¢å¤±ï¼ˆ**ä¸ä¸¢å¤±**ï¼‰
- ä¸ä¼šæ”¶åˆ°é‡å¤çš„åŒ…è£¹ï¼ˆ**ä¸é‡å¤**ï¼‰  
- åŒ…è£¹æŒ‰é¡ºåºåˆ°è¾¾ï¼ˆ**æœ‰åºæ€§**ï¼‰
- åŒ…è£¹å†…å®¹å®Œæ•´æ— æŸï¼ˆ**å®Œæ•´æ€§**ï¼‰

**ğŸ”¸ åœ¨Kafkaä¸­çš„å«ä¹‰**
```
æ•°æ®å¯é æ€§çš„å››ä¸ªç»´åº¦ï¼š

ğŸ“¦ ä¸ä¸¢å¤±ï¼ˆDurabilityï¼‰ï¼š
æ¶ˆæ¯ä¸€æ—¦å‘é€æˆåŠŸï¼Œå°±ä¸ä¼šå› ä¸ºç³»ç»Ÿæ•…éšœè€Œä¸¢å¤±

ğŸ”„ ä¸é‡å¤ï¼ˆExactly Onceï¼‰ï¼š
åŒä¸€æ¡æ¶ˆæ¯ä¸ä¼šè¢«å¤„ç†å¤šæ¬¡

ğŸ“‹ æœ‰åºæ€§ï¼ˆOrderingï¼‰ï¼š
æ¶ˆæ¯æŒ‰ç…§å‘é€é¡ºåºè¢«æ¶ˆè´¹

âœ… å®Œæ•´æ€§ï¼ˆIntegrityï¼‰ï¼š
æ¶ˆæ¯å†…å®¹åœ¨ä¼ è¾“è¿‡ç¨‹ä¸­ä¸ä¼šè¢«ç¯¡æ”¹
```

### 1.2 å¯é æ€§ç­‰çº§åˆ†ç±»


**ğŸ“Š å¯é æ€§ä¿è¯çº§åˆ«**

| çº§åˆ« | **ä¿è¯å†…å®¹** | **æ€§èƒ½å½±å“** | **é€‚ç”¨åœºæ™¯** |
|------|-------------|-------------|-------------|
| ğŸŸ¢ **è‡³å°‘ä¸€æ¬¡** | `ä¸ä¸¢å¤±ï¼Œå¯èƒ½é‡å¤` | `é«˜æ€§èƒ½` | `æ—¥å¿—æ”¶é›†ã€ç›‘æ§æ•°æ®` |
| ğŸŸ¡ **è‡³å¤šä¸€æ¬¡** | `ä¸é‡å¤ï¼Œå¯èƒ½ä¸¢å¤±` | `æœ€é«˜æ€§èƒ½` | `å®æ—¶åˆ†æã€ä¸´æ—¶æ•°æ®` |
| ğŸ”´ **æ°å¥½ä¸€æ¬¡** | `æ—¢ä¸ä¸¢å¤±ä¹Ÿä¸é‡å¤` | `æ€§èƒ½å¼€é”€å¤§` | `é‡‘èäº¤æ˜“ã€è®¢å•å¤„ç†` |

> ğŸ’¡ **é€‰æ‹©å»ºè®®**ï¼šåƒé€‰æ‹©å¿«é€’æœåŠ¡ä¸€æ ·
> - æ™®é€šåŒ…è£¹ï¼šè‡³å°‘ä¸€æ¬¡ï¼ˆå¹³è¡¡æ€§èƒ½å’Œå¯é æ€§ï¼‰
> - é‡è¦æ–‡ä»¶ï¼šæ°å¥½ä¸€æ¬¡ï¼ˆä¸èƒ½å‡ºé”™ï¼‰
> - ä¼ å•å¹¿å‘Šï¼šè‡³å¤šä¸€æ¬¡ï¼ˆå¿«é€ŸæŠ•é€’ï¼‰

### 1.3 å¯é æ€§é¢ä¸´çš„æŒ‘æˆ˜


**âš ï¸ å¸¸è§æ•°æ®é£é™©**
```
ç½‘ç»œå±‚é¢ï¼š
ğŸ“¡ ç½‘ç»œåˆ†åŒºï¼šæœºæˆ¿é—´ç½‘ç»œä¸­æ–­
ğŸ“¶ ç½‘ç»œæŠ–åŠ¨ï¼šå¶å‘çš„ç½‘ç»œå»¶è¿Ÿ
ğŸ”Œ è¿æ¥ä¸­æ–­ï¼šTCPè¿æ¥æ„å¤–æ–­å¼€

ç³»ç»Ÿå±‚é¢ï¼š
ğŸ’¥ è¿›ç¨‹å´©æºƒï¼šProducer/Consumerå¼‚å¸¸é€€å‡º
ğŸ”„ é‡å¯ç»´æŠ¤ï¼šè®¡åˆ’å†…çš„ç³»ç»Ÿé‡å¯
ğŸ’¾ ç£ç›˜æ•…éšœï¼šå­˜å‚¨è®¾å¤‡æŸå

åº”ç”¨å±‚é¢ï¼š
ğŸ› ä»£ç Bugï¼šå¤„ç†é€»è¾‘é”™è¯¯
â° å¤„ç†è¶…æ—¶ï¼šä¸šåŠ¡é€»è¾‘æ‰§è¡Œè¿‡æ…¢
ğŸ”„ é‡å¤å¤„ç†ï¼šé‡è¯•æœºåˆ¶å¯¼è‡´çš„é‡å¤
```

---

## 2. ğŸ”’ æ•°æ®ä¸ä¸¢å¤±ä¿è¯æœºåˆ¶


### 2.1 Producerç«¯ä¸ä¸¢å¤±é…ç½®


**ğŸš€ ç”Ÿäº§è€…å¯é æ€§é…ç½®**

```java
Properties props = new Properties();
// æ ¸å¿ƒé…ç½®ï¼šç­‰å¾…æ‰€æœ‰å‰¯æœ¬ç¡®è®¤
props.put("acks", "all");  // æˆ–è€… "acks", "-1"

// é‡è¯•é…ç½®ï¼šç½‘ç»œå¼‚å¸¸æ—¶è‡ªåŠ¨é‡è¯•
props.put("retries", "3");
props.put("retry.backoff.ms", "1000");

// å¹‚ç­‰æ€§ï¼šé˜²æ­¢é‡è¯•å¯¼è‡´é‡å¤
props.put("enable.idempotence", "true");

// æ‰¹é‡æ§åˆ¶ï¼šå¹³è¡¡æ€§èƒ½å’Œå¯é æ€§
props.put("batch.size", "16384");
props.put("linger.ms", "10");
```

**ğŸ” å‚æ•°è¯¦è§£**

**ackså‚æ•°**ï¼šå†³å®šProducerä½•æ—¶è®¤ä¸ºæ¶ˆæ¯å‘é€æˆåŠŸ
```
acks=0ï¼šå‘äº†å°±ç®—æˆåŠŸï¼ˆæœ€å¿«ï¼Œå¯èƒ½ä¸¢å¤±ï¼‰
    Producer â†’ [å‘é€] â†’ Kafka â†’ ä¸ç­‰ç¡®è®¤å°±è¿”å›
    
acks=1ï¼šLeaderç¡®è®¤å°±ç®—æˆåŠŸï¼ˆå¹³è¡¡ï¼‰
    Producer â†’ [å‘é€] â†’ Leaderç¡®è®¤ â†’ è¿”å›æˆåŠŸ
    
acks=allï¼šæ‰€æœ‰å‰¯æœ¬ç¡®è®¤æ‰ç®—æˆåŠŸï¼ˆæœ€å¯é ï¼‰
    Producer â†’ [å‘é€] â†’ Leader+æ‰€æœ‰Followerç¡®è®¤ â†’ è¿”å›æˆåŠŸ
```

> ğŸ“ **ç”Ÿæ´»ç±»æ¯”**ï¼šåƒå‘å¾®ä¿¡æ¶ˆæ¯
> - acks=0ï¼šå‘é€å³å¯ï¼Œä¸ç®¡å¯¹æ–¹æ˜¯å¦æ”¶åˆ°
> - acks=1ï¼šå¯¹æ–¹æ‰‹æœºæ”¶åˆ°å°±è¡Œï¼Œä¸ç®¡æ˜¯å¦å·²è¯»
> - acks=allï¼šå¯¹æ–¹æ”¶åˆ°ä¸”å·²è¯»å›å¤æ‰ç®—æˆåŠŸ

### 2.2 Brokerç«¯ä¸ä¸¢å¤±é…ç½®


**âš™ï¸ Brokerå¯é æ€§è®¾ç½®**

```properties
# å‰¯æœ¬é…ç½®ï¼šæ•°æ®å†—ä½™ä¿è¯
default.replication.factor=3    # é»˜è®¤3ä¸ªå‰¯æœ¬
min.insync.replicas=2          # è‡³å°‘2ä¸ªå‰¯æœ¬åŒæ­¥

# æŒä¹…åŒ–é…ç½®ï¼šæ•°æ®è½ç›˜ä¿è¯
log.flush.interval.messages=1   # æ¯æ¡æ¶ˆæ¯éƒ½åˆ·ç›˜
log.flush.interval.ms=1000      # æœ€å¤š1ç§’åˆ·ç›˜ä¸€æ¬¡

# Leaderé€‰ä¸¾ï¼šç¡®ä¿æ•°æ®å®Œæ•´æ€§
unclean.leader.election.enable=false  # ç¦æ­¢è„Leaderé€‰ä¸¾
```

**ğŸ“Š å‰¯æœ¬æœºåˆ¶è¯¦è§£**
```
æ­£å¸¸æƒ…å†µä¸‹çš„æ•°æ®æµï¼š
Producer â†’ Leader Partition â†’ Follower1 â†’ Follower2
              â†“
         è¿”å›ackç»™Producer

æ•…éšœæ¢å¤æ—¶ï¼š
LeaderæŒ‚äº† â†’ ä»Followerä¸­é€‰å‡ºæ–°Leader â†’ ç»§ç»­æœåŠ¡

å…³é”®ç†è§£ï¼š
â€¢ replication.factor=3ï¼šä¸€ä»½æ•°æ®å­˜3ä¸ªåœ°æ–¹
â€¢ min.insync.replicas=2ï¼šè‡³å°‘2ä¸ªå‰¯æœ¬åŒæ­¥æ‰ç®—æˆåŠŸ
â€¢ è¿™æ ·å³ä½¿1ä¸ªå‰¯æœ¬æŒ‚äº†ï¼Œæ•°æ®ä¹Ÿä¸ä¼šä¸¢å¤±
```

### 2.3 Consumerç«¯ä¸ä¸¢å¤±å¤„ç†


**ğŸ“¥ æ¶ˆè´¹è€…å¯é æ€§å®è·µ**

```java
// 1. å…³é—­è‡ªåŠ¨æäº¤ï¼Œæ‰‹åŠ¨æ§åˆ¶offset
props.put("enable.auto.commit", "false");

// 2. æ¶ˆè´¹é€»è¾‘
while (true) {
    ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(1000));
    
    for (ConsumerRecord<String, String> record : records) {
        try {
            // ä¸šåŠ¡å¤„ç†
            processMessage(record.value());
            
            // å¤„ç†æˆåŠŸåæ‰æäº¤offset
            consumer.commitSync();
            
        } catch (Exception e) {
            // å¤„ç†å¤±è´¥ï¼Œè®°å½•æ—¥å¿—ï¼Œä¸æäº¤offset
            log.error("å¤„ç†æ¶ˆæ¯å¤±è´¥: " + record.value(), e);
            // å¯ä»¥é€‰æ‹©é‡è¯•æˆ–å‘é€åˆ°æ­»ä¿¡é˜Ÿåˆ—
        }
    }
}
```

**ğŸ”„ æ¶ˆè´¹å¤±è´¥å¤„ç†ç­–ç•¥**
```
ç­–ç•¥1ï¼šé‡è¯•æœºåˆ¶
å¤±è´¥ â†’ é‡è¯•3æ¬¡ â†’ ä»å¤±è´¥ â†’ å‘é€æ­»ä¿¡é˜Ÿåˆ—

ç­–ç•¥2ï¼šè·³è¿‡ç»§ç»­
å¤±è´¥ â†’ è®°å½•æ—¥å¿— â†’ è·³è¿‡æ­¤æ¶ˆæ¯ â†’ ç»§ç»­å¤„ç†ä¸‹ä¸€æ¡

ç­–ç•¥3ï¼šåœæ­¢æ¶ˆè´¹
å¤±è´¥ â†’ åœæ­¢æ¶ˆè´¹ â†’ äººå·¥å¤„ç† â†’ ä¿®å¤åç»§ç»­

é€‰æ‹©åŸåˆ™ï¼š
â€¢ é‡è¦æ•°æ®ï¼šä½¿ç”¨ç­–ç•¥1ï¼ˆé‡è¯•+æ­»ä¿¡é˜Ÿåˆ—ï¼‰
â€¢ ä¸€èˆ¬æ•°æ®ï¼šä½¿ç”¨ç­–ç•¥2ï¼ˆè·³è¿‡ç»§ç»­ï¼‰
â€¢ æ ¸å¿ƒä¸šåŠ¡ï¼šä½¿ç”¨ç­–ç•¥3ï¼ˆåœæ­¢å¤„ç†ï¼‰
```

---

## 3. ğŸ”„ æ¶ˆæ¯å»é‡ç­–ç•¥


### 3.1 é‡å¤äº§ç”Ÿçš„åŸå› 


**ğŸ¤” ä¸ºä»€ä¹ˆä¼šäº§ç”Ÿé‡å¤ï¼Ÿ**

```
Producerç«¯é‡å¤ï¼š
ç½‘ç»œè¶…æ—¶ â†’ Produceré‡è¯• â†’ å®é™…ä¸Šç¬¬ä¸€æ¬¡å·²æˆåŠŸ â†’ äº§ç”Ÿé‡å¤

Consumerç«¯é‡å¤ï¼š
å¤„ç†å®Œæ¶ˆæ¯ â†’ æäº¤offsetå‰å®•æœº â†’ é‡å¯åé‡æ–°æ¶ˆè´¹ â†’ äº§ç”Ÿé‡å¤

æ—¶åºå›¾ç¤ºä¾‹ï¼š
Producer                Kafka Broker
   |                         |
   |--[1]å‘é€æ¶ˆæ¯----------->|
   |                         |--å†™å…¥æˆåŠŸ
   |<--X ç½‘ç»œè¶…æ—¶ï¼Œæœªæ”¶åˆ°ack--|
   |                         |
   |--[2]é‡è¯•å‘é€ç›¸åŒæ¶ˆæ¯---->|--å†æ¬¡å†™å…¥ï¼ˆé‡å¤ï¼ï¼‰
   |<--[3]æ”¶åˆ°æˆåŠŸack--------|
```

### 3.2 Producerç«¯å»é‡


**ğŸ”‘ å¹‚ç­‰æ€§Produceré…ç½®**

```java
// å¼€å¯å¹‚ç­‰æ€§ï¼šKafkaè‡ªåŠ¨å»é‡
Properties props = new Properties();
props.put("enable.idempotence", "true");

// å¹‚ç­‰æ€§è¦æ±‚çš„é…ç½®ï¼ˆè‡ªåŠ¨è®¾ç½®ï¼‰
props.put("acks", "all");              // å¿…é¡»ç­‰å¾…æ‰€æœ‰å‰¯æœ¬ç¡®è®¤
props.put("retries", Integer.MAX_VALUE); // å…è®¸é‡è¯•
props.put("max.in.flight.requests.per.connection", "5"); // æ§åˆ¶å¹¶å‘
```

**ğŸ› ï¸ å¹‚ç­‰æ€§å·¥ä½œåŸç†**
```
åŸç†ï¼šProducer ID + åºåˆ—å·æœºåˆ¶

æ¯ä¸ªProducerå¯åŠ¨æ—¶ï¼š
1. è·å¾—å”¯ä¸€çš„Producer IDï¼ˆPIDï¼‰
2. ä¸ºæ¯ä¸ªPartitionç»´æŠ¤åºåˆ—å·

å‘é€æ¶ˆæ¯æ—¶ï¼š
æ¶ˆæ¯ = æ•°æ® + PID + åºåˆ—å·

Brokerç«¯æ£€æŸ¥ï¼š
if (æ”¶åˆ°çš„åºåˆ—å· == æœŸæœ›çš„åºåˆ—å·) {
    æ­£å¸¸å¤„ç†
} else if (æ”¶åˆ°çš„åºåˆ—å· < æœŸæœ›çš„åºåˆ—å·) {
    é‡å¤æ¶ˆæ¯ï¼Œç›´æ¥ä¸¢å¼ƒ
} else {
    ä¹±åºæ¶ˆæ¯ï¼Œæ‹’ç»å¤„ç†
}
```

> ğŸ’¡ **ç±»æ¯”ç†è§£**ï¼šåƒé“¶è¡Œè½¬è´¦å‡­è¯
> - PID = ä½ çš„èº«ä»½è¯å·
> - åºåˆ—å· = è½¬è´¦æµæ°´å·  
> - é“¶è¡Œæ”¶åˆ°é‡å¤çš„æµæ°´å·ä¼šè‡ªåŠ¨æ‹’ç»

### 3.3 äº‹åŠ¡æ€§Producer


**ğŸ¦ äº‹åŠ¡ä¿è¯çš„å®Œæ•´æ€§**

```java
// äº‹åŠ¡Produceré…ç½®
Properties props = new Properties();
props.put("enable.idempotence", "true");
props.put("transactional.id", "my-transaction-id");

KafkaProducer<String, String> producer = new KafkaProducer<>(props);

// åˆå§‹åŒ–äº‹åŠ¡
producer.initTransactions();

try {
    // å¼€å§‹äº‹åŠ¡
    producer.beginTransaction();
    
    // å‘é€æ¶ˆæ¯
    producer.send(new ProducerRecord<>("topic1", "key1", "value1"));
    producer.send(new ProducerRecord<>("topic2", "key2", "value2"));
    
    // æäº¤äº‹åŠ¡ï¼šè¦ä¹ˆå…¨éƒ¨æˆåŠŸï¼Œè¦ä¹ˆå…¨éƒ¨å¤±è´¥
    producer.commitTransaction();
    
} catch (Exception e) {
    // å¼‚å¸¸æ—¶å›æ»šäº‹åŠ¡
    producer.abortTransaction();
}
```

**ğŸ“‹ äº‹åŠ¡vså¹‚ç­‰æ€§å¯¹æ¯”**

| ç‰¹æ€§ | **å¹‚ç­‰æ€§Producer** | **äº‹åŠ¡Producer** |
|------|------------------|-----------------|
| ğŸ¯ **ç›®æ ‡** | `å•æ¡æ¶ˆæ¯ä¸é‡å¤` | `å¤šæ¡æ¶ˆæ¯çš„åŸå­æ€§` |
| ğŸ”§ **å®ç°** | `PID+åºåˆ—å·` | `äº‹åŠ¡åè°ƒå™¨` |
| âš¡ **æ€§èƒ½** | `å‡ ä¹æ— å½±å“` | `æœ‰ä¸€å®šå¼€é”€` |
| ğŸŒ **èŒƒå›´** | `å•ä¸ªPartition` | `è·¨å¤šä¸ªTopic/Partition` |
| ğŸ’¼ **åœºæ™¯** | `ä¸€èˆ¬ä¸šåŠ¡` | `æ ¸å¿ƒä¸šåŠ¡ã€è½¬è´¦ç­‰` |

### 3.4 Consumerç«¯å»é‡


**ğŸ¯ ä¸šåŠ¡å±‚é¢å»é‡ç­–ç•¥**

**ç­–ç•¥1ï¼šåŸºäºä¸šåŠ¡ä¸»é”®å»é‡**
```java
// ä½¿ç”¨Redisç­‰ç¼“å­˜è®°å½•å·²å¤„ç†çš„æ¶ˆæ¯
public void processMessage(String messageId, String content) {
    String key = "processed:" + messageId;
    
    // æ£€æŸ¥æ˜¯å¦å·²å¤„ç†
    if (redis.exists(key)) {
        log.info("æ¶ˆæ¯å·²å¤„ç†ï¼Œè·³è¿‡: " + messageId);
        return;
    }
    
    try {
        // ä¸šåŠ¡å¤„ç†
        doBusinessLogic(content);
        
        // è®°å½•å·²å¤„ç†ï¼ˆè®¾ç½®è¿‡æœŸæ—¶é—´ï¼‰
        redis.setex(key, 3600, "processed");
        
    } catch (Exception e) {
        // å¤„ç†å¤±è´¥ï¼Œä¸è®°å½•çŠ¶æ€ï¼Œå…è®¸é‡è¯•
        throw e;
    }
}
```

**ç­–ç•¥2ï¼šæ•°æ®åº“å”¯ä¸€çº¦æŸ**
```sql
-- åœ¨æ•°æ®åº“å±‚é¢é˜²é‡å¤
CREATE TABLE message_process_log (
    message_id VARCHAR(64) PRIMARY KEY,  -- æ¶ˆæ¯å”¯ä¸€ID
    process_time TIMESTAMP,
    content TEXT
);

-- ä¸šåŠ¡å¤„ç†æ—¶æ’å…¥è®°å½•ï¼Œé‡å¤ä¼šæŠ›å¼‚å¸¸
INSERT INTO message_process_log (message_id, process_time, content) 
VALUES (?, NOW(), ?);
```

**ç­–ç•¥3ï¼šçŠ¶æ€æœºæ–¹å¼**
```java
// è®¢å•çŠ¶æ€é˜²é‡å¤
public void processOrderPayment(String orderId, BigDecimal amount) {
    Order order = orderService.getById(orderId);
    
    // æ£€æŸ¥è®¢å•çŠ¶æ€
    if (order.getStatus() != OrderStatus.PENDING) {
        log.warn("è®¢å•çŠ¶æ€ä¸å…è®¸æ”¯ä»˜: " + orderId + ", å½“å‰çŠ¶æ€: " + order.getStatus());
        return;
    }
    
    // æ›´æ–°çŠ¶æ€ï¼ˆæ•°æ®åº“å±‚é¢ä¿è¯åŸå­æ€§ï¼‰
    boolean updated = orderService.updateStatus(orderId, 
                                              OrderStatus.PENDING, 
                                              OrderStatus.PAID);
    if (!updated) {
        log.warn("è®¢å•çŠ¶æ€å·²è¢«å…¶ä»–çº¿ç¨‹ä¿®æ”¹: " + orderId);
        return;
    }
    
    // æ‰§è¡Œæ”¯ä»˜é€»è¾‘
    doPayment(orderId, amount);
}
```

---

## 4. ğŸ“‹ é¡ºåºä¿è¯æœºåˆ¶


### 4.1 é¡ºåºæ€§çš„é‡è¦æ€§


**ğŸ¯ ä¸ºä»€ä¹ˆéœ€è¦æ¶ˆæ¯é¡ºåºï¼Ÿ**

**ğŸ“± å®é™…åœºæ™¯ä¸¾ä¾‹**
```
ç”¨æˆ·æ“ä½œåºåˆ—ï¼š
1. ç”¨æˆ·æ³¨å†Œ â†’ åˆ›å»ºç”¨æˆ·è´¦å·
2. ç”¨æˆ·ç™»å½• â†’ è®°å½•ç™»å½•æ—¥å¿—  
3. ä¿®æ”¹å¯†ç  â†’ æ›´æ–°ç”¨æˆ·ä¿¡æ¯

å¦‚æœä¹±åºå¤„ç†ï¼š
3. ä¿®æ”¹å¯†ç  â†’ å¤±è´¥ï¼ˆç”¨æˆ·ä¸å­˜åœ¨ï¼‰
1. ç”¨æˆ·æ³¨å†Œ â†’ æˆåŠŸ
2. ç”¨æˆ·ç™»å½• â†’ æˆåŠŸ

ç»“æœï¼šå¯†ç ä¿®æ”¹ä¸¢å¤±ï¼
```

**ğŸ’° é‡‘èåœºæ™¯ç¤ºä¾‹**
```
è´¦æˆ·æ“ä½œé¡ºåºï¼š
1. å­˜æ¬¾ +1000å…ƒ â†’ ä½™é¢ï¼š1000
2. è½¬è´¦ -500å…ƒ  â†’ ä½™é¢ï¼š500
3. å­˜æ¬¾ +200å…ƒ  â†’ ä½™é¢ï¼š700

ä¹±åºå¤„ç†ï¼š
2. è½¬è´¦ -500å…ƒ â†’ å¤±è´¥ï¼ˆä½™é¢ä¸è¶³ï¼‰
1. å­˜æ¬¾ +1000å…ƒ â†’ ä½™é¢ï¼š1000
3. å­˜æ¬¾ +200å…ƒ â†’ ä½™é¢ï¼š1200

ç»“æœï¼šè½¬è´¦ä¸¢å¤±ï¼Œä½™é¢é”™è¯¯ï¼
```

### 4.2 Kafkaçš„é¡ºåºä¿è¯æœºåˆ¶


**ğŸ” åˆ†åŒºçº§åˆ«çš„é¡ºåºä¿è¯**

```
Kafkaçš„é¡ºåºä¿è¯è§„åˆ™ï¼š
âœ… åŒä¸€ä¸ªPartitionå†…ï¼šä¸¥æ ¼æŒ‰é¡ºåºå¤„ç†
âŒ ä¸åŒPartitioné—´ï¼šæ— æ³•ä¿è¯é¡ºåº

Topic: user-events (3ä¸ªåˆ†åŒº)
Partition 0: [æ¶ˆæ¯1] â†’ [æ¶ˆæ¯4] â†’ [æ¶ˆæ¯7]  âœ… æœ‰åº
Partition 1: [æ¶ˆæ¯2] â†’ [æ¶ˆæ¯5] â†’ [æ¶ˆæ¯8]  âœ… æœ‰åº  
Partition 2: [æ¶ˆæ¯3] â†’ [æ¶ˆæ¯6] â†’ [æ¶ˆæ¯9]  âœ… æœ‰åº

æ•´ä½“é¡ºåºï¼šå¯èƒ½æ˜¯ 1â†’2â†’3â†’4â†’5â†’6... ä¹Ÿå¯èƒ½æ˜¯ 2â†’1â†’4â†’3â†’6â†’5...
```

**ğŸ—ï¸ ä¿è¯é¡ºåºçš„å…³é”®é…ç½®**

```java
// Producerç«¯é…ç½®
Properties props = new Properties();
// ç¡®ä¿æ¶ˆæ¯æŒ‰é¡ºåºå‘é€
props.put("max.in.flight.requests.per.connection", "1");
// å¼€å¯å¹‚ç­‰æ€§ï¼ˆé¡ºåºä¿è¯çš„å‰æï¼‰
props.put("enable.idempotence", "true");

// å‘é€æ—¶æŒ‡å®šç›¸åŒçš„keyç¡®ä¿è¿›å…¥åŒä¸€åˆ†åŒº
producer.send(new ProducerRecord<>("topic", "user123", "ç”¨æˆ·æ³¨å†Œ"));
producer.send(new ProducerRecord<>("topic", "user123", "ç”¨æˆ·ç™»å½•"));
producer.send(new ProducerRecord<>("topic", "user123", "ä¿®æ”¹å¯†ç "));
```

### 4.3 åˆ†åŒºç­–ç•¥è®¾è®¡


**ğŸ¯ åˆç†çš„åˆ†åŒºç­–ç•¥**

**ç­–ç•¥1ï¼šæŒ‰ä¸šåŠ¡ä¸»ä½“åˆ†åŒº**
```java
// æŒ‰ç”¨æˆ·IDåˆ†åŒºï¼šåŒä¸€ç”¨æˆ·çš„æ“ä½œæœ‰åº
String partitionKey = "user:" + userId;
producer.send(new ProducerRecord<>("user-events", partitionKey, event));

// æŒ‰è®¢å•IDåˆ†åŒºï¼šåŒä¸€è®¢å•çš„æ“ä½œæœ‰åº  
String partitionKey = "order:" + orderId;
producer.send(new ProducerRecord<>("order-events", partitionKey, event));
```

**ç­–ç•¥2ï¼šè‡ªå®šä¹‰åˆ†åŒºå™¨**
```java
public class BusinessPartitioner implements Partitioner {
    
    @Override
    public int partition(String topic, Object key, byte[] keyBytes, 
                        Object value, byte[] valueBytes, Cluster cluster) {
        
        String keyStr = (String) key;
        int partitions = cluster.partitionCountForTopic(topic);
        
        if (keyStr.startsWith("urgent:")) {
            // ç´§æ€¥æ¶ˆæ¯å›ºå®šåˆ°åˆ†åŒº0
            return 0;
        } else if (keyStr.startsWith("user:")) {
            // ç”¨æˆ·æ¶ˆæ¯æŒ‰ç”¨æˆ·IDå“ˆå¸Œ
            String userId = keyStr.substring(5);
            return Math.abs(userId.hashCode()) % partitions;
        } else {
            // å…¶ä»–æ¶ˆæ¯è½®è¯¢åˆ†é…
            return ThreadLocalRandom.current().nextInt(partitions);
        }
    }
}
```

### 4.4 Consumerç«¯é¡ºåºæ¶ˆè´¹


**ğŸ“¥ ç¡®ä¿æ¶ˆè´¹é¡ºåº**

```java
// Consumeré…ç½®ï¼šå•çº¿ç¨‹æ¶ˆè´¹ä¿è¯é¡ºåº
Properties props = new Properties();
props.put("max.poll.records", "1");  // æ¯æ¬¡åªå–ä¸€æ¡æ¶ˆæ¯

KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);
consumer.subscribe(Arrays.asList("user-events"));

while (true) {
    ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(1000));
    
    for (ConsumerRecord<String, String> record : records) {
        // å•çº¿ç¨‹é¡ºåºå¤„ç†
        processMessageInOrder(record);
        
        // å¤„ç†å®Œä¸€æ¡æ‰æäº¤offset
        consumer.commitSync();
    }
}
```

**âš¡ æå‡æ€§èƒ½çš„é¡ºåºæ¶ˆè´¹æ–¹æ¡ˆ**
```java
// æ–¹æ¡ˆï¼šåˆ†åŒºå†…å¹¶å‘ï¼Œåˆ†åŒºé—´æœ‰åº
Map<Integer, BlockingQueue<ConsumerRecord<String, String>>> partitionQueues = 
    new ConcurrentHashMap<>();

// ä¸ºæ¯ä¸ªåˆ†åŒºåˆ›å»ºç‹¬ç«‹çš„å¤„ç†çº¿ç¨‹
consumer.assignment().forEach(partition -> {
    BlockingQueue<ConsumerRecord<String, String>> queue = new LinkedBlockingQueue<>();
    partitionQueues.put(partition.partition(), queue);
    
    // æ¯ä¸ªåˆ†åŒºä¸€ä¸ªå¤„ç†çº¿ç¨‹
    Thread worker = new Thread(() -> {
        while (true) {
            try {
                ConsumerRecord<String, String> record = queue.take();
                processMessage(record);
            } catch (InterruptedException e) {
                break;
            }
        }
    });
    worker.start();
});

// ä¸»çº¿ç¨‹åˆ†å‘æ¶ˆæ¯åˆ°å¯¹åº”åˆ†åŒºé˜Ÿåˆ—
while (true) {
    ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(1000));
    
    for (ConsumerRecord<String, String> record : records) {
        int partition = record.partition();
        partitionQueues.get(partition).offer(record);
    }
    
    consumer.commitAsync();
}
```

---

## 5. âš–ï¸ ä¸€è‡´æ€§ä¿è¯


### 5.1 ä¸€è‡´æ€§çº§åˆ«ç†è§£


**ğŸ¯ ä»€ä¹ˆæ˜¯ä¸€è‡´æ€§ï¼Ÿ**

**ğŸ“š é€šä¿—ç†è§£**
æƒ³è±¡ä¸€ä¸ªå›¾ä¹¦é¦†æœ‰å¤šä¸ªåˆ†é¦†ï¼š
- **å¼ºä¸€è‡´æ€§**ï¼šæ‰€æœ‰åˆ†é¦†çš„ä¹¦ç›®å¿…é¡»å®æ—¶åŒæ­¥ï¼Œå€Ÿèµ°ä¸€æœ¬ä¹¦ï¼Œæ‰€æœ‰åˆ†é¦†ç«‹å³çŸ¥é“
- **æœ€ç»ˆä¸€è‡´æ€§**ï¼šå…è®¸çŸ­æš‚ä¸åŒæ­¥ï¼Œä½†æœ€ç»ˆæ‰€æœ‰åˆ†é¦†çš„ä¹¦ç›®ä¼šä¸€è‡´
- **å¼±ä¸€è‡´æ€§**ï¼šå„åˆ†é¦†çš„ä¹¦ç›®å¯èƒ½é•¿æœŸä¸ä¸€è‡´

**ğŸ” Kafkaä¸­çš„ä¸€è‡´æ€§åœºæ™¯**
```
åœºæ™¯ï¼šè®¢å•æœåŠ¡å‘åº“å­˜æœåŠ¡å‘é€æ¶ˆæ¯
é—®é¢˜ï¼šå¦‚ä½•ä¿è¯è®¢å•åˆ›å»ºå’Œåº“å­˜æ‰£å‡çš„ä¸€è‡´æ€§ï¼Ÿ

ä¼ ç»Ÿæ–¹æ¡ˆé—®é¢˜ï¼š
è®¢å•æœåŠ¡ï¼šåˆ›å»ºè®¢å• âœ…
         â†“
      å‘é€æ¶ˆæ¯ âŒ (ç½‘ç»œå¤±è´¥)
         â†“
åº“å­˜æœåŠ¡ï¼šæœªæ”¶åˆ°æ¶ˆæ¯ï¼Œåº“å­˜æœªæ‰£å‡

ç»“æœï¼šè®¢å•åˆ›å»ºäº†ï¼Œä½†åº“å­˜æ²¡æ‰£ï¼Œæ•°æ®ä¸ä¸€è‡´ï¼
```

### 5.2 äº‹åŠ¡æ€§ä¿è¯


**ğŸ¦ Kafkaäº‹åŠ¡æœºåˆ¶**

```java
// å®Œæ•´çš„äº‹åŠ¡å¤„ç†ç¤ºä¾‹
@Service
public class OrderService {
    
    @Autowired
    private KafkaTransactionTemplate kafkaTemplate;
    
    @Autowired
    private OrderRepository orderRepository;
    
    @Transactional
    public void createOrder(Order order) {
        // åœ¨Kafkaäº‹åŠ¡ä¸­æ‰§è¡Œ
        kafkaTemplate.executeInTransaction(operations -> {
            
            // 1. ä¿å­˜è®¢å•åˆ°æ•°æ®åº“
            orderRepository.save(order);
            
            // 2. å‘é€åº“å­˜æ‰£å‡æ¶ˆæ¯
            operations.send("inventory-topic", 
                          "reduce:" + order.getProductId() + ":" + order.getQuantity());
            
            // 3. å‘é€æ”¯ä»˜æ¶ˆæ¯  
            operations.send("payment-topic",
                          "pay:" + order.getId() + ":" + order.getAmount());
            
            // è¦ä¹ˆå…¨éƒ¨æˆåŠŸï¼Œè¦ä¹ˆå…¨éƒ¨å›æ»š
            return null;
        });
    }
}
```

**ğŸ”„ äº‹åŠ¡æ‰§è¡Œæµç¨‹**
```
äº‹åŠ¡å¼€å§‹ï¼š
1. å¼€å¯æ•°æ®åº“äº‹åŠ¡
2. å¼€å¯Kafkaäº‹åŠ¡

æ‰§è¡Œé˜¶æ®µï¼š
3. ä¿å­˜è®¢å•æ•°æ®
4. å‘é€Kafkaæ¶ˆæ¯ï¼ˆæš‚å­˜åœ¨äº‹åŠ¡æ—¥å¿—ï¼‰

æäº¤é˜¶æ®µï¼š
5. æ•°æ®åº“æäº¤
6. Kafkaäº‹åŠ¡æäº¤ï¼ˆæ¶ˆæ¯çœŸæ­£å‘é€ï¼‰

å¼‚å¸¸å¤„ç†ï¼š
å¦‚æœä»»ä½•æ­¥éª¤å¤±è´¥ï¼š
- æ•°æ®åº“å›æ»š
- Kafkaäº‹åŠ¡å›æ»šï¼ˆæ¶ˆæ¯ä¸ä¼šå‘é€ï¼‰
```

### 5.3 Sagaæ¨¡å¼å®ç°


**ğŸ”— åˆ†å¸ƒå¼äº‹åŠ¡çš„ç°å®æ–¹æ¡ˆ**

**SagaåŸºæœ¬æ€æƒ³**ï¼šæŠŠå¤§äº‹åŠ¡æ‹†æˆå°äº‹åŠ¡ï¼Œæ¯ä¸ªå°äº‹åŠ¡éƒ½æœ‰å¯¹åº”çš„è¡¥å¿æ“ä½œ

```java
// è®¢å•å¤„ç†çš„Sagaæµç¨‹
public class OrderSaga {
    
    public void processOrder(Order order) {
        List<SagaStep> steps = Arrays.asList(
            new CreateOrderStep(order),      // åˆ›å»ºè®¢å•
            new ReduceInventoryStep(order),  // æ‰£å‡åº“å­˜
            new ProcessPaymentStep(order),   // å¤„ç†æ”¯ä»˜
            new SendEmailStep(order)         // å‘é€ç¡®è®¤é‚®ä»¶
        );
        
        SagaOrchestrator.execute(steps);
    }
}

// æ¯ä¸ªæ­¥éª¤éƒ½æœ‰æ­£å‘å’Œåå‘æ“ä½œ
public class ReduceInventoryStep implements SagaStep {
    
    @Override
    public void execute() {
        // æ­£å‘ï¼šæ‰£å‡åº“å­˜
        inventoryService.reduce(productId, quantity);
        sendMessage("inventory-topic", "reduce:" + productId + ":" + quantity);
    }
    
    @Override
    public void compensate() {
        // åå‘ï¼šæ¢å¤åº“å­˜  
        inventoryService.add(productId, quantity);
        sendMessage("inventory-topic", "add:" + productId + ":" + quantity);
    }
}
```

**ğŸ“Š äº‹åŠ¡vs Sagaå¯¹æ¯”**

| æ–¹é¢ | **ACIDäº‹åŠ¡** | **Sagaæ¨¡å¼** |
|------|-------------|-------------|
| ğŸ¯ **ä¸€è‡´æ€§** | `å¼ºä¸€è‡´æ€§` | `æœ€ç»ˆä¸€è‡´æ€§` |
| âš¡ **æ€§èƒ½** | `å¯èƒ½é˜»å¡` | `å¼‚æ­¥å¤„ç†` |
| ğŸ”§ **å¤æ‚åº¦** | `ç®€å•` | `éœ€è¦è®¾è®¡è¡¥å¿é€»è¾‘` |
| ğŸŒ **é€‚ç”¨åœºæ™¯** | `å•ä½“åº”ç”¨` | `å¾®æœåŠ¡æ¶æ„` |
| ğŸ’ª **å®¹é”™æ€§** | `é‡é”™å›æ»š` | `éƒ¨åˆ†å¤±è´¥å¯è¡¥å¿` |

### 5.4 å¹‚ç­‰æ€§ä¸ä¸€è‡´æ€§


**ğŸ”‘ å¹‚ç­‰æ€§ä¿è¯ä¸€è‡´æ€§**

```java
// å¹‚ç­‰çš„åº“å­˜æ‰£å‡æœåŠ¡
@Service
public class InventoryService {
    
    @KafkaListener(topics = "inventory-topic")
    public void handleInventoryMessage(String message) {
        // è§£ææ¶ˆæ¯ï¼šæ“ä½œç±»å‹:å•†å“ID:æ•°é‡:è¯·æ±‚ID
        String[] parts = message.split(":");
        String operation = parts[0];
        String productId = parts[1]; 
        int quantity = Integer.parseInt(parts[2]);
        String requestId = parts[3];  // å”¯ä¸€è¯·æ±‚ID
        
        // å¹‚ç­‰æ€§æ£€æŸ¥
        if (operationLogService.exists(requestId)) {
            log.info("æ“ä½œå·²æ‰§è¡Œï¼Œè·³è¿‡: " + requestId);
            return;
        }
        
        try {
            if ("reduce".equals(operation)) {
                reduceInventory(productId, quantity);
            } else if ("add".equals(operation)) {
                addInventory(productId, quantity);
            }
            
            // è®°å½•æ“ä½œæ—¥å¿—ï¼ˆé˜²æ­¢é‡å¤æ‰§è¡Œï¼‰
            operationLogService.save(requestId, operation, productId, quantity);
            
        } catch (Exception e) {
            log.error("åº“å­˜æ“ä½œå¤±è´¥: " + requestId, e);
            // å‘é€åˆ°æ­»ä¿¡é˜Ÿåˆ—è¿›è¡Œäººå·¥å¤„ç†
            sendToDeadLetterQueue(message);
        }
    }
}
```

---

## 6. ğŸŒ è·¨æ•°æ®ä¸­å¿ƒå¤åˆ¶


### 6.1 è·¨æ•°æ®ä¸­å¿ƒéœ€æ±‚


**ğŸ¢ ä¸ºä»€ä¹ˆéœ€è¦è·¨æ•°æ®ä¸­å¿ƒï¼Ÿ**

**ğŸ“ å®é™…ä¸šåŠ¡åœºæ™¯**
```
å…¨çƒåŒ–å…¬å¸çš„æŒ‘æˆ˜ï¼š
ğŸŒ åŒ—äº¬æ•°æ®ä¸­å¿ƒï¼šæœåŠ¡äºšæ´²ç”¨æˆ·
ğŸŒ çº½çº¦æ•°æ®ä¸­å¿ƒï¼šæœåŠ¡ç¾æ´²ç”¨æˆ·  
ğŸŒ ä¼¦æ•¦æ•°æ®ä¸­å¿ƒï¼šæœåŠ¡æ¬§æ´²ç”¨æˆ·

éœ€æ±‚ï¼š
â€¢ å°±è¿‘æœåŠ¡ï¼šç”¨æˆ·è®¿é—®æœ€è¿‘çš„æ•°æ®ä¸­å¿ƒ
â€¢ æ•°æ®åŒæ­¥ï¼šé‡è¦æ•°æ®éœ€è¦å…¨çƒåŒæ­¥
â€¢ ç¾éš¾æ¢å¤ï¼šä¸€ä¸ªæ•°æ®ä¸­å¿ƒæ•…éšœï¼Œå…¶ä»–ç»§ç»­æœåŠ¡
â€¢ åˆè§„è¦æ±‚ï¼šæŸäº›æ•°æ®å¿…é¡»å­˜å‚¨åœ¨ç‰¹å®šåœ°åŒº
```

**âš ï¸ è·¨æ•°æ®ä¸­å¿ƒçš„æŒ‘æˆ˜**
```
ç½‘ç»œæŒ‘æˆ˜ï¼š
ğŸ“¡ å»¶è¿Ÿé«˜ï¼šè·¨å¤§æ´‹ç½‘ç»œå»¶è¿Ÿ100-300ms
ğŸ“¶ å¸¦å®½æœ‰é™ï¼šä¸“çº¿æˆæœ¬é«˜æ˜‚
ğŸ”Œ ä¸ç¨³å®šï¼šæµ·åº•å…‰ç¼†å¶å‘æ•…éšœ

æ•°æ®æŒ‘æˆ˜ï¼š  
â° æ—¶é—´å·®ï¼šä¸åŒæ—¶åŒºçš„æ—¶é—´åŒæ­¥
ğŸ”„ å†²çªè§£å†³ï¼šåŒæ—¶ä¿®æ”¹ç›¸åŒæ•°æ®æ€ä¹ˆåŠï¼Ÿ
ğŸ“Š æ•°æ®é‡å¤§ï¼šå…¨é‡åŒæ­¥æ—¶é—´é•¿
```

### 6.2 MirrorMaker 2.0é…ç½®


**ğŸª Kafkaå®˜æ–¹çš„è·¨é›†ç¾¤å¤åˆ¶å·¥å…·**

**åŸºç¡€é…ç½®ç¤ºä¾‹**
```properties
# sourceé›†ç¾¤é…ç½®
clusters = beijing, newyork
beijing.bootstrap.servers = beijing-kafka1:9092,beijing-kafka2:9092
newyork.bootstrap.servers = newyork-kafka1:9092,newyork-kafka2:9092

# å¤åˆ¶é…ç½®ï¼šä»åŒ—äº¬åˆ°çº½çº¦
beijing->newyork.enabled = true
beijing->newyork.topics = user-events, order-events, payment-events

# å¤åˆ¶ç­–ç•¥
beijing->newyork.replication.factor = 3
beijing->newyork.sync.topic.acls.enabled = true

# æ’é™¤ç³»ç»Ÿtopicï¼ˆé¿å…å¤åˆ¶å†…éƒ¨æ•°æ®ï¼‰
beijing->newyork.topics.blacklist = __.*

# æ•°æ®å‹ç¼©ï¼šå‡å°‘ç½‘ç»œä¼ è¾“
beijing->newyork.producer.compression.type = lz4
beijing->newyork.producer.batch.size = 65536
```

**ğŸ”„ åŒå‘å¤åˆ¶é…ç½®**
```properties
# åŒ—äº¬ â†’ çº½çº¦
beijing->newyork.enabled = true
beijing->newyork.topics = global-events

# çº½çº¦ â†’ åŒ—äº¬  
newyork->beijing.enabled = true
newyork->beijing.topics = global-events

# é˜²æ­¢ç¯å½¢å¤åˆ¶ï¼šè¿‡æ»¤å·²å¤åˆ¶çš„æ¶ˆæ¯
beijing->newyork.replication.policy.separator = .
newyork->beijing.replication.policy.separator = .

# Topicé‡å‘½åï¼šé¿å…å†²çª
beijing->newyork.replication.policy.class = 
    org.apache.kafka.connect.mirror.DefaultReplicationPolicy
```

### 6.3 å¤åˆ¶ç­–ç•¥è®¾è®¡


**ğŸ¯ åˆ†çº§å¤åˆ¶ç­–ç•¥**

```
æ•°æ®åˆ†ç±»å’Œå¤åˆ¶ç­–ç•¥ï¼š

ğŸ”´ æ ¸å¿ƒä¸šåŠ¡æ•°æ®ï¼ˆå®æ—¶åŒæ­¥ï¼‰ï¼š
â€¢ ç”¨æˆ·æ³¨å†Œä¿¡æ¯
â€¢ è®¢å•äº¤æ˜“æ•°æ®  
â€¢ æ”¯ä»˜è®°å½•
â†’ å¤åˆ¶å»¶è¿Ÿï¼š< 1ç§’ï¼Œ3ä¸ªå‰¯æœ¬

ğŸŸ¡ é‡è¦ä¸šåŠ¡æ•°æ®ï¼ˆå‡†å®æ—¶åŒæ­¥ï¼‰ï¼š
â€¢ ç”¨æˆ·è¡Œä¸ºæ—¥å¿—
â€¢ å•†å“æµè§ˆè®°å½•
â€¢ æ¨èæ•°æ®
â†’ å¤åˆ¶å»¶è¿Ÿï¼š< 10ç§’ï¼Œ2ä¸ªå‰¯æœ¬

ğŸŸ¢ ä¸€èˆ¬æ•°æ®ï¼ˆå®šæœŸåŒæ­¥ï¼‰ï¼š
â€¢ ç³»ç»Ÿç›‘æ§æ•°æ®
â€¢ ä¸´æ—¶ç¼“å­˜æ•°æ®
â€¢ è°ƒè¯•æ—¥å¿—
â†’ å¤åˆ¶å»¶è¿Ÿï¼š< 5åˆ†é’Ÿï¼Œ1ä¸ªå‰¯æœ¬
```

**ğŸ“Š å¤åˆ¶é…ç½®æ¨¡æ¿**
```properties
# æ ¸å¿ƒæ•°æ®é…ç½®
core.topics = user-register, orders, payments
core.replication.factor = 3
core.acks = all
core.retries = 10
core.max.in.flight.requests.per.connection = 1

# é‡è¦æ•°æ®é…ç½®  
important.topics = user-behavior, product-views
important.replication.factor = 2
important.acks = 1
important.retries = 3

# ä¸€èˆ¬æ•°æ®é…ç½®
normal.topics = system-logs, cache-data
normal.replication.factor = 1
normal.acks = 0
normal.retries = 0
```

### 6.4 ç½‘ç»œä¼˜åŒ–ç­–ç•¥


**ğŸš€ æå‡è·¨æ•°æ®ä¸­å¿ƒæ€§èƒ½**

**ç­–ç•¥1ï¼šæ•°æ®å‹ç¼©**
```properties
# Producerç«¯å‹ç¼©
compression.type = lz4  # å¿«é€Ÿå‹ç¼©ç®—æ³•
batch.size = 65536      # å¢å¤§æ‰¹æ¬¡å¤§å°
linger.ms = 100         # ç­‰å¾…æ›´å¤šæ•°æ®ä¸€èµ·å‘é€

# å‹ç¼©æ•ˆæœï¼š
# åŸå§‹æ•°æ®ï¼š1GB
# lz4å‹ç¼©ï¼š400MBï¼ˆå‹ç¼©ç‡60%ï¼‰
# ç½‘ç»œä¼ è¾“æ—¶é—´ï¼šä»10åˆ†é’Ÿé™åˆ°4åˆ†é’Ÿ
```

**ç­–ç•¥2ï¼šæ™ºèƒ½è·¯ç”±**
```java
// è‡ªå®šä¹‰è·¯ç”±é€»è¾‘ï¼šå°±è¿‘è¯»å–
@Service 
public class IntelligentKafkaRouter {
    
    public KafkaConsumer<String, String> getConsumer(String region) {
        Properties props = new Properties();
        
        if ("asia".equals(region)) {
            // äºšæ´²ç”¨æˆ·è®¿é—®åŒ—äº¬é›†ç¾¤
            props.put("bootstrap.servers", "beijing-kafka:9092");
        } else if ("america".equals(region)) {
            // ç¾æ´²ç”¨æˆ·è®¿é—®çº½çº¦é›†ç¾¤  
            props.put("bootstrap.servers", "newyork-kafka:9092");
        } else {
            // å…¶ä»–ç”¨æˆ·è®¿é—®å»¶è¿Ÿæœ€ä½çš„é›†ç¾¤
            props.put("bootstrap.servers", detectLowestLatencyCluster());
        }
        
        return new KafkaConsumer<>(props);
    }
}
```

**ç­–ç•¥3ï¼šå¢é‡åŒæ­¥**
```java
// åªåŒæ­¥å˜åŒ–çš„æ•°æ®ï¼Œä¸æ˜¯å…¨é‡å¤åˆ¶
@Component
public class IncrementalReplication {
    
    public void syncChanges() {
        // è·å–ä¸Šæ¬¡åŒæ­¥çš„offset
        long lastOffset = getLastSyncOffset();
        
        // åªæ¶ˆè´¹æ–°å¢çš„æ¶ˆæ¯
        consumer.seek(partition, lastOffset);
        
        ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(30));
        
        for (ConsumerRecord<String, String> record : records) {
            // å‘é€åˆ°ç›®æ ‡é›†ç¾¤
            targetProducer.send(new ProducerRecord<>(record.topic(), 
                                                   record.key(), 
                                                   record.value()));
        }
        
        // è®°å½•åŒæ­¥è¿›åº¦
        saveLastSyncOffset(consumer.position(partition));
    }
}
```

---

## 7. ğŸ†˜ ç¾éš¾æ¢å¤ç­–ç•¥


### 7.1 ç¾éš¾ç±»å‹ä¸å½±å“


**ğŸ’¥ å¸¸è§ç¾éš¾åœºæ™¯**

```
ç¡¬ä»¶çº§ç¾éš¾ï¼š
ğŸ”¥ æœºæˆ¿ç«ç¾ï¼šæ•´ä¸ªæ•°æ®ä¸­å¿ƒä¸å¯ç”¨
ğŸŒŠ è‡ªç„¶ç¾å®³ï¼šåœ°éœ‡ã€æ´ªæ°´ç­‰
âš¡ æ–­ç”µäº‹æ•…ï¼šUPSæ•…éšœï¼Œé•¿æ—¶é—´åœç”µ
ğŸ’¾ å­˜å‚¨æ•…éšœï¼šç£ç›˜é˜µåˆ—å®Œå…¨æŸå

è½¯ä»¶çº§ç¾éš¾ï¼š
ğŸ› ç³»ç»ŸBugï¼šä»£ç ç¼ºé™·å¯¼è‡´æ•°æ®æŸå
ğŸ”„ é”™è¯¯æ“ä½œï¼šè¯¯åˆ Topicã€é”™è¯¯é…ç½®
ğŸš« å®‰å…¨äº‹ä»¶ï¼šé»‘å®¢æ”»å‡»ã€å‹’ç´¢è½¯ä»¶
ğŸ“Š æ•°æ®æŸåï¼šæ–‡ä»¶ç³»ç»Ÿé”™è¯¯

ç½‘ç»œçº§ç¾éš¾ï¼š
ğŸ“¡ ç½‘ç»œåˆ†åŒºï¼šæœºæˆ¿é—´ç½‘ç»œä¸­æ–­
ğŸŒ DNSæ•…éšœï¼šåŸŸåè§£æå¤±è´¥
ğŸ”Œ å…‰ç¼†ä¸­æ–­ï¼šç‰©ç†ç½‘ç»œæ–­å¼€
```

### 7.2 RTOå’ŒRPOç›®æ ‡


**â° æ¢å¤æ—¶é—´å’Œæ•°æ®ä¸¢å¤±æ§åˆ¶**

**ğŸ“Š ä¸šåŠ¡ç­‰çº§åˆ’åˆ†**
```
æ ¸å¿ƒä¸šåŠ¡ï¼ˆé‡‘èäº¤æ˜“ï¼‰ï¼š
â€¢ RTOï¼š< 5åˆ†é’Ÿï¼ˆ5åˆ†é’Ÿå†…æ¢å¤æœåŠ¡ï¼‰
â€¢ RPOï¼š< 30ç§’ï¼ˆæœ€å¤šä¸¢å¤±30ç§’æ•°æ®ï¼‰

é‡è¦ä¸šåŠ¡ï¼ˆç”µå•†è®¢å•ï¼‰ï¼š
â€¢ RTOï¼š< 30åˆ†é’Ÿ
â€¢ RPOï¼š< 5åˆ†é’Ÿ

ä¸€èˆ¬ä¸šåŠ¡ï¼ˆç”¨æˆ·è¡Œä¸ºï¼‰ï¼š
â€¢ RTOï¼š< 2å°æ—¶  
â€¢ RPOï¼š< 30åˆ†é’Ÿ

æ—¥å¿—æ•°æ®ï¼š
â€¢ RTOï¼š< 24å°æ—¶
â€¢ RPOï¼š< 4å°æ—¶
```

**ğŸ¯ å®ç°ç­–ç•¥**
```
RTOå®ç°ç­–ç•¥ï¼š
â€¢ çƒ­å¤‡é›†ç¾¤ï¼šå®æ—¶åŒæ­¥ï¼Œæ•…éšœæ—¶ç«‹å³åˆ‡æ¢
â€¢ æ¸©å¤‡é›†ç¾¤ï¼šå®šæœŸåŒæ­¥ï¼Œæ•…éšœæ—¶å¿«é€Ÿå¯åŠ¨
â€¢ å†·å¤‡é›†ç¾¤ï¼šå®šæœŸå¤‡ä»½ï¼Œæ•…éšœæ—¶é‡æ–°éƒ¨ç½²

RPOå®ç°ç­–ç•¥ï¼š  
â€¢ åŒæ­¥å¤åˆ¶ï¼šacks=allï¼Œæ•°æ®å®æ—¶åŒæ­¥
â€¢ å¼‚æ­¥å¤åˆ¶ï¼šå®šæœŸæ‰¹é‡åŒæ­¥
â€¢ å¿«ç…§å¤‡ä»½ï¼šå®šæ—¶åˆ¶ä½œæ•°æ®å¿«ç…§
```

### 7.3 å¤šçº§å¤‡ä»½ç­–ç•¥


**ğŸ—ï¸ åˆ†å±‚å¤‡ä»½æ¶æ„**

```
å¤‡ä»½å±‚çº§è®¾è®¡ï¼š

ç¬¬1å±‚ï¼šæœ¬åœ°å‰¯æœ¬ï¼ˆåŒæœºæˆ¿ï¼‰
åŒ—äº¬æ•°æ®ä¸­å¿ƒï¼š
â”œâ”€â”€ Kafkaé›†ç¾¤Aï¼ˆä¸»ï¼‰ï¼š3ä¸ªå‰¯æœ¬
â””â”€â”€ Kafkaé›†ç¾¤Bï¼ˆå¤‡ï¼‰ï¼š3ä¸ªå‰¯æœ¬
â†’ RTO: 1åˆ†é’Ÿï¼ŒRPO: 0ç§’

ç¬¬2å±‚ï¼šåŒåŸç¾å¤‡ï¼ˆä¸åŒæœºæˆ¿ï¼‰
åŒ—äº¬Aæœºæˆ¿ â†” åŒ—äº¬Bæœºæˆ¿
â†’ RTO: 10åˆ†é’Ÿï¼ŒRPO: 30ç§’

ç¬¬3å±‚ï¼šå¼‚åœ°ç¾å¤‡ï¼ˆä¸åŒåŸå¸‚ï¼‰  
åŒ—äº¬æ•°æ®ä¸­å¿ƒ â†” ä¸Šæµ·æ•°æ®ä¸­å¿ƒ
â†’ RTO: 30åˆ†é’Ÿï¼ŒRPO: 5åˆ†é’Ÿ

ç¬¬4å±‚ï¼šäº‘ç«¯å¤‡ä»½ï¼ˆä¸åŒäº‘å‚å•†ï¼‰
è‡ªå»ºæœºæˆ¿ â†” é˜¿é‡Œäº‘/è…¾è®¯äº‘
â†’ RTO: 2å°æ—¶ï¼ŒRPO: 1å°æ—¶
```

**âš™ï¸ è‡ªåŠ¨åŒ–å¤‡ä»½é…ç½®**
```bash
#!/bin/bash
# è‡ªåŠ¨åŒ–å¤‡ä»½è„šæœ¬

# ç¬¬1å±‚ï¼šå®æ—¶å¤åˆ¶ï¼ˆMirrorMakerï¼‰
./kafka-mirror-maker.sh --consumer.config source.properties \
                       --producer.config target.properties \
                       --whitelist "core-topics.*"

# ç¬¬2å±‚ï¼šå®šæœŸå¿«ç…§
kafka-topics.sh --bootstrap-server localhost:9092 --list | \
while read topic; do
    kafka-console-consumer.sh --bootstrap-server localhost:9092 \
                             --topic $topic \
                             --from-beginning \
                             --timeout-ms 30000 > backup/$topic.$(date +%Y%m%d).txt
done

# ç¬¬3å±‚ï¼šå‹ç¼©ä¼ è¾“åˆ°å¼‚åœ°
tar -czf kafka-backup-$(date +%Y%m%d).tar.gz backup/
rsync -az kafka-backup-*.tar.gz remote-server:/backup/kafka/

# ç¬¬4å±‚ï¼šä¸Šä¼ åˆ°äº‘å­˜å‚¨
aws s3 cp kafka-backup-$(date +%Y%m%d).tar.gz s3://kafka-disaster-recovery/
```

### 7.4 æ•…éšœåˆ‡æ¢æµç¨‹


**ğŸ”„ è‡ªåŠ¨åŒ–æ•…éšœåˆ‡æ¢**

```java
@Component
public class DisasterRecoveryManager {
    
    private final HealthChecker healthChecker;
    private final ClusterManager clusterManager;
    
    @Scheduled(fixedDelay = 10000) // æ¯10ç§’æ£€æŸ¥ä¸€æ¬¡
    public void checkClusterHealth() {
        ClusterHealth primaryHealth = healthChecker.checkPrimary();
        ClusterHealth backupHealth = healthChecker.checkBackup();
        
        if (!primaryHealth.isHealthy() && backupHealth.isHealthy()) {
            log.warn("ä¸»é›†ç¾¤å¼‚å¸¸ï¼Œå‡†å¤‡åˆ‡æ¢åˆ°å¤‡é›†ç¾¤");
            initiateFailover();
        }
    }
    
    private void initiateFailover() {
        try {
            // 1. åœæ­¢å‘ä¸»é›†ç¾¤å†™å…¥
            clusterManager.stopProducers();
            
            // 2. ç­‰å¾…æ•°æ®åŒæ­¥å®Œæˆ
            waitForDataSync();
            
            // 3. æ›´æ–°DNSæŒ‡å‘å¤‡é›†ç¾¤
            dnsManager.updateRecords("kafka.company.com", backupClusterIPs);
            
            // 4. å¯åŠ¨å¤‡é›†ç¾¤çš„Consumer
            clusterManager.startBackupConsumers();
            
            // 5. é€šçŸ¥ç›¸å…³å›¢é˜Ÿ
            alertManager.sendAlert("Kafkaé›†ç¾¤å·²åˆ‡æ¢åˆ°å¤‡ç”¨é›†ç¾¤");
            
            log.info("æ•…éšœåˆ‡æ¢å®Œæˆï¼ŒæœåŠ¡å·²æ¢å¤");
            
        } catch (Exception e) {
            log.error("æ•…éšœåˆ‡æ¢å¤±è´¥", e);
            alertManager.sendCriticalAlert("Kafkaæ•…éšœåˆ‡æ¢å¤±è´¥ï¼Œéœ€è¦äººå·¥ä»‹å…¥");
        }
    }
}
```

**ğŸ“‹ æ•…éšœåˆ‡æ¢æ£€æŸ¥æ¸…å•**
```
åˆ‡æ¢å‰æ£€æŸ¥ï¼š
â˜ å¤‡é›†ç¾¤å¥åº·çŠ¶æ€æ­£å¸¸
â˜ æ•°æ®åŒæ­¥å»¶è¿Ÿåœ¨å¯æ¥å—èŒƒå›´å†…
â˜ ç½‘ç»œè¿æ¥æ­£å¸¸
â˜ å­˜å‚¨ç©ºé—´å……è¶³

åˆ‡æ¢è¿‡ç¨‹ï¼š
â˜ åœæ­¢ä¸»é›†ç¾¤Producer
â˜ ç­‰å¾…æ•°æ®åŒæ­¥å®Œæˆ
â˜ æ›´æ–°DNSé…ç½®
â˜ å¯åŠ¨å¤‡é›†ç¾¤æœåŠ¡
â˜ éªŒè¯æœåŠ¡å¯ç”¨æ€§

åˆ‡æ¢åéªŒè¯ï¼š
â˜ æ¶ˆæ¯å‘é€æ­£å¸¸
â˜ æ¶ˆæ¯æ¶ˆè´¹æ­£å¸¸  
â˜ ç›‘æ§æŒ‡æ ‡æ­£å¸¸
â˜ ä¸šåŠ¡åŠŸèƒ½æ­£å¸¸
â˜ æ€§èƒ½æŒ‡æ ‡è¾¾æ ‡
```

---

## 8. ğŸ” æ•°æ®æ ¡éªŒæœºåˆ¶


### 8.1 æ¶ˆæ¯å®Œæ•´æ€§æ ¡éªŒ


**âœ… ç¡®ä¿æ•°æ®ä¼ è¾“æ­£ç¡®æ€§**

**ğŸ” æ ¡éªŒå’Œæœºåˆ¶**
```java
// Producerç«¯ï¼šæ·»åŠ æ ¡éªŒå’Œ
public class ChecksumProducer {
    
    public void sendMessage(String topic, String key, String value) {
        // è®¡ç®—æ¶ˆæ¯æ ¡éªŒå’Œ
        String checksum = calculateMD5(value);
        
        // åœ¨æ¶ˆæ¯å¤´ä¸­æ·»åŠ æ ¡éªŒå’Œ
        ProducerRecord<String, String> record = new ProducerRecord<>(topic, key, value);
        record.headers().add("checksum", checksum.getBytes());
        
        producer.send(record);
    }
    
    private String calculateMD5(String input) {
        try {
            MessageDigest md = MessageDigest.getInstance("MD5");
            byte[] hash = md.digest(input.getBytes());
            return DatatypeConverter.printHexBinary(hash);
        } catch (Exception e) {
            throw new RuntimeException("è®¡ç®—æ ¡éªŒå’Œå¤±è´¥", e);
        }
    }
}
```

```java
// Consumerç«¯ï¼šéªŒè¯æ ¡éªŒå’Œ
@KafkaListener(topics = "verified-topic")
public void handleMessage(ConsumerRecord<String, String> record) {
    String value = record.value();
    
    // è·å–æ ¡éªŒå’Œ
    Header checksumHeader = record.headers().lastHeader("checksum");
    if (checksumHeader == null) {
        log.warn("æ¶ˆæ¯ç¼ºå°‘æ ¡éªŒå’Œï¼Œè·³è¿‡å¤„ç†");
        return;
    }
    
    String expectedChecksum = new String(checksumHeader.value());
    String actualChecksum = calculateMD5(value);
    
    if (!expectedChecksum.equals(actualChecksum)) {
        log.error("æ¶ˆæ¯æ ¡éªŒå¤±è´¥ï¼Œé¢„æœŸ: {}, å®é™…: {}", expectedChecksum, actualChecksum);
        // å‘é€åˆ°é”™è¯¯Topicè¿›è¡Œäººå·¥å¤„ç†
        sendToErrorTopic(record);
        return;
    }
    
    // æ ¡éªŒé€šè¿‡ï¼Œæ­£å¸¸å¤„ç†
    processMessage(value);
}
```

### 8.2 æ¶ˆæ¯åºå·éªŒè¯


**ğŸ”¢ æ£€æµ‹æ¶ˆæ¯ä¸¢å¤±å’Œä¹±åº**

```java
// å¸¦åºå·çš„æ¶ˆæ¯å‘é€
public class SequentialProducer {
    
    private final AtomicLong sequenceNumber = new AtomicLong(0);
    
    public void sendMessage(String topic, String content) {
        long seq = sequenceNumber.incrementAndGet();
        
        // æ„é€ å¸¦åºå·çš„æ¶ˆæ¯
        SequentialMessage message = new SequentialMessage(seq, content, System.currentTimeMillis());
        String json = JSON.toJSONString(message);
        
        producer.send(new ProducerRecord<>(topic, String.valueOf(seq), json));
    }
}

// åºå·éªŒè¯Consumer
@Component
public class SequentialConsumer {
    
    private final Map<String, Long> lastSequenceMap = new ConcurrentHashMap<>();
    
    @KafkaListener(topics = "sequential-topic")
    public void handleMessage(ConsumerRecord<String, String> record) {
        SequentialMessage message = JSON.parseObject(record.value(), SequentialMessage.class);
        String key = record.key();
        long currentSeq = message.getSequenceNumber();
        
        Long lastSeq = lastSequenceMap.get(key);
        if (lastSeq == null) {
            // ç¬¬ä¸€æ¡æ¶ˆæ¯
            lastSequenceMap.put(key, currentSeq);
        } else if (currentSeq == lastSeq + 1) {
            // åºå·æ­£å¸¸
            lastSequenceMap.put(key, currentSeq);
        } else if (currentSeq <= lastSeq) {
            // é‡å¤æ¶ˆæ¯
            log.warn("æ”¶åˆ°é‡å¤æ¶ˆæ¯ï¼Œåºå·: {}, é¢„æœŸ: {}", currentSeq, lastSeq + 1);
            return;
        } else {
            // æ¶ˆæ¯ä¸¢å¤±
            log.error("æ£€æµ‹åˆ°æ¶ˆæ¯ä¸¢å¤±ï¼Œæ”¶åˆ°åºå·: {}, é¢„æœŸ: {}, ä¸¢å¤±: {}", 
                     currentSeq, lastSeq + 1, currentSeq - lastSeq - 1);
            
            // è§¦å‘å‘Šè­¦
            alertManager.sendAlert("æ¶ˆæ¯åºå·å¼‚å¸¸ï¼Œå¯èƒ½æœ‰æ¶ˆæ¯ä¸¢å¤±");
        }
        
        processMessage(message.getContent());
    }
}
```

### 8.3 ç«¯åˆ°ç«¯ç›‘æ§


**ğŸ“Š å…¨é“¾è·¯æ•°æ®ç›‘æ§**

```java
// æ¶ˆæ¯ç”Ÿå‘½å‘¨æœŸè¿½è¸ª
@Component
public class MessageLifecycleTracker {
    
    // å‘é€ç«¯åŸ‹ç‚¹
    public void trackProduceSent(String messageId, String topic) {
        MetricEvent event = new MetricEvent()
            .setMessageId(messageId)
            .setTopic(topic)
            .setEvent("PRODUCED")
            .setTimestamp(System.currentTimeMillis());
            
        metricsCollector.collect(event);
    }
    
    // æ¥æ”¶ç«¯åŸ‹ç‚¹
    public void trackConsumeReceived(String messageId, String topic) {
        MetricEvent event = new MetricEvent()
            .setMessageId(messageId)
            .setTopic(topic)
            .setEvent("CONSUMED")
            .setTimestamp(System.currentTimeMillis());
            
        metricsCollector.collect(event);
    }
    
    // å¤„ç†å®ŒæˆåŸ‹ç‚¹
    public void trackProcessCompleted(String messageId, String topic) {
        MetricEvent event = new MetricEvent()
            .setMessageId(messageId)
            .setTopic(topic)
            .setEvent("PROCESSED")
            .setTimestamp(System.currentTimeMillis());
            
        metricsCollector.collect(event);
    }
}
```

**ğŸ“ˆ ç›‘æ§æŒ‡æ ‡ä»ªè¡¨æ¿**
```
å®æ—¶ç›‘æ§æŒ‡æ ‡ï¼š

ğŸ“Š ååé‡æŒ‡æ ‡ï¼š
â€¢ æ¯ç§’å‘é€æ¶ˆæ¯æ•°ï¼ˆTPSï¼‰
â€¢ æ¯ç§’æ¶ˆè´¹æ¶ˆæ¯æ•°ï¼ˆCPSï¼‰
â€¢ æ¶ˆæ¯å¤„ç†æˆåŠŸç‡

â±ï¸ å»¶è¿ŸæŒ‡æ ‡ï¼š
â€¢ ç«¯åˆ°ç«¯å»¶è¿Ÿï¼ˆP99, P95, P50ï¼‰
â€¢ Producerå‘é€å»¶è¿Ÿ
â€¢ Consumerå¤„ç†å»¶è¿Ÿ

ğŸš¨ å¼‚å¸¸æŒ‡æ ‡ï¼š
â€¢ æ¶ˆæ¯ä¸¢å¤±æ•°é‡
â€¢ é‡å¤æ¶ˆæ¯æ•°é‡
â€¢ å¤„ç†å¤±è´¥æ•°é‡
â€¢ æ ¡éªŒå¤±è´¥æ•°é‡

ğŸ’¾ å­˜å‚¨æŒ‡æ ‡ï¼š
â€¢ ç£ç›˜ä½¿ç”¨ç‡
â€¢ æ¶ˆæ¯ä¿ç•™æ—¶é—´
â€¢ åˆ†åŒºå¤§å°
```

### 8.4 æ•°æ®è´¨é‡ç›‘æ§


**ğŸ¯ ä¸šåŠ¡æ•°æ®éªŒè¯**

```java
// æ•°æ®è´¨é‡æ£€æŸ¥è§„åˆ™
@Component
public class DataQualityChecker {
    
    @KafkaListener(topics = "user-events")
    public void validateUserEvent(String message) {
        UserEvent event = JSON.parseObject(message, UserEvent.class);
        
        List<String> errors = new ArrayList<>();
        
        // å­—æ®µå®Œæ•´æ€§æ£€æŸ¥
        if (StringUtils.isBlank(event.getUserId())) {
            errors.add("ç”¨æˆ·IDä¸èƒ½ä¸ºç©º");
        }
        
        if (event.getTimestamp() == null) {
            errors.add("æ—¶é—´æˆ³ä¸èƒ½ä¸ºç©º");
        }
        
        // æ•°æ®åˆç†æ€§æ£€æŸ¥
        if (event.getTimestamp() > System.currentTimeMillis() + 60000) {
            errors.add("æ—¶é—´æˆ³ä¸èƒ½è¶…è¿‡å½“å‰æ—¶é—´1åˆ†é’Ÿ");
        }
        
        // ä¸šåŠ¡è§„åˆ™æ£€æŸ¥
        if ("purchase".equals(event.getEventType()) && event.getAmount() <= 0) {
            errors.add("è´­ä¹°é‡‘é¢å¿…é¡»å¤§äº0");
        }
        
        if (!errors.isEmpty()) {
            log.warn("æ•°æ®è´¨é‡æ£€æŸ¥å¤±è´¥: {}, é”™è¯¯: {}", message, errors);
            // å‘é€åˆ°æ•°æ®è´¨é‡é—®é¢˜Topic
            sendToDataQualityTopic(message, errors);
        } else {
            // æ•°æ®è´¨é‡æ­£å¸¸ï¼Œç»§ç»­å¤„ç†
            processUserEvent(event);
        }
    }
}
```

---

## 9. ğŸ§ª å¯é æ€§æµ‹è¯•æ–¹æ³•


### 9.1 æ··æ²Œå·¥ç¨‹æµ‹è¯•


**ğŸ’¥ æ•…æ„åˆ¶é€ æ•…éšœéªŒè¯ç³»ç»Ÿ**

**ğŸ”§ ç½‘ç»œæ•…éšœæ¨¡æ‹Ÿ**
```bash
#!/bin/bash
# æ··æ²Œå·¥ç¨‹ï¼šç½‘ç»œåˆ†åŒºæµ‹è¯•

echo "å¼€å§‹ç½‘ç»œåˆ†åŒºæµ‹è¯•..."

# 1. é˜»æ–­Kafka Brokeré—´çš„é€šä¿¡
iptables -A INPUT -s 192.168.1.100 -j DROP  # é˜»æ–­broker1
sleep 30

# 2. è§‚å¯Ÿç³»ç»Ÿè¡Œä¸º
echo "æ£€æŸ¥Leaderé€‰ä¸¾æ˜¯å¦æ­£å¸¸..."
kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic test-topic

# 3. æ¢å¤ç½‘ç»œ
iptables -D INPUT -s 192.168.1.100 -j DROP
echo "ç½‘ç»œå·²æ¢å¤"

# 4. æ£€æŸ¥æ•°æ®ä¸€è‡´æ€§
echo "éªŒè¯æ•°æ®å®Œæ•´æ€§..."
kafka-console-consumer.sh --bootstrap-server localhost:9092 \
                         --topic test-topic \
                         --from-beginning --timeout-ms 10000 | wc -l
```

**âš¡ è¿›ç¨‹æ•…éšœæ¨¡æ‹Ÿ**
```bash
#!/bin/bash
# æ¨¡æ‹ŸKafkaè¿›ç¨‹å¼‚å¸¸ç»ˆæ­¢

# éšæœºé€‰æ‹©ä¸€ä¸ªBrokerè¿›ç¨‹
BROKER_PID=$(ps aux | grep kafka | grep -v grep | awk '{print $2}' | head -1)

echo "æ¨¡æ‹ŸBrokerè¿›ç¨‹å´©æºƒï¼ŒPID: $BROKER_PID"
kill -9 $BROKER_PID

# ç­‰å¾…ç³»ç»Ÿè‡ªæ„ˆ
sleep 60

# æ£€æŸ¥ç³»ç»ŸçŠ¶æ€
echo "æ£€æŸ¥é›†ç¾¤çŠ¶æ€..."
kafka-broker-api-versions.sh --bootstrap-server localhost:9092

# é‡å¯è¢«æ€æ­»çš„Broker
echo "é‡å¯Broker..."
nohup kafka-server-start.sh /opt/kafka/config/server.properties > /dev/null 2>&1 &
```

### 9.2 å‹åŠ›æµ‹è¯•


**ğŸ“ˆ æ€§èƒ½å’Œç¨³å®šæ€§éªŒè¯**

```java
// é«˜å¹¶å‘Produceræµ‹è¯•
public class KafkaStressTest {
    
    private static final int THREAD_COUNT = 10;
    private static final int MESSAGES_PER_THREAD = 100000;
    
    public void runProducerStressTest() {
        ExecutorService executor = Executors.newFixedThreadPool(THREAD_COUNT);
        CountDownLatch latch = new CountDownLatch(THREAD_COUNT);
        AtomicLong successCount = new AtomicLong(0);
        AtomicLong failureCount = new AtomicLong(0);
        
        long startTime = System.currentTimeMillis();
        
        for (int i = 0; i < THREAD_COUNT; i++) {
            final int threadId = i;
            executor.submit(() -> {
                try {
                    KafkaProducer<String, String> producer = createProducer();
                    
                    for (int j = 0; j < MESSAGES_PER_THREAD; j++) {
                        String key = "thread-" + threadId + "-msg-" + j;
                        String value = "æµ‹è¯•æ¶ˆæ¯å†…å®¹-" + System.currentTimeMillis();
                        
                        producer.send(new ProducerRecord<>("stress-test-topic", key, value),
                            (metadata, exception) -> {
                                if (exception == null) {
                                    successCount.incrementAndGet();
                                } else {
                                    failureCount.incrementAndGet();
                                    log.error("å‘é€å¤±è´¥", exception);
                                }
                            });
                    }
                    
                    producer.flush();
                    producer.close();
                    
                } finally {
                    latch.countDown();
                }
            });
        }
        
        try {
            latch.await();
            long endTime = System.currentTimeMillis();
            long duration = endTime - startTime;
            
            System.out.println("å‹åŠ›æµ‹è¯•ç»“æœ:");
            System.out.println("æ€»æ¶ˆæ¯æ•°: " + (THREAD_COUNT * MESSAGES_PER_THREAD));
            System.out.println("æˆåŠŸå‘é€: " + successCount.get());
            System.out.println("å‘é€å¤±è´¥: " + failureCount.get());
            System.out.println("æ€»è€—æ—¶: " + duration + "ms");
            System.out.println("TPS: " + (successCount.get() * 1000 / duration));
            
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
        }
        
        executor.shutdown();
    }
}
```

### 9.3 æ•°æ®ä¸€è‡´æ€§éªŒè¯


**ğŸ” ç«¯åˆ°ç«¯æ•°æ®éªŒè¯**

```java
// æ•°æ®ä¸€è‡´æ€§éªŒè¯å·¥å…·
@Component
public class DataConsistencyValidator {
    
    public void validateEndToEndConsistency() {
        String testTopicName = "consistency-test-" + System.currentTimeMillis();
        int messageCount = 10000;
        
        // 1. å‘é€æµ‹è¯•æ•°æ®
        Set<String> sentMessages = sendTestMessages(testTopicName, messageCount);
        
        // 2. ç­‰å¾…æ•°æ®ä¼ æ’­
        Thread.sleep(30000);
        
        // 3. æ¶ˆè´¹å¹¶éªŒè¯æ•°æ®
        Set<String> receivedMessages = consumeTestMessages(testTopicName);
        
        // 4. å¯¹æ¯”ç»“æœ
        validateResults(sentMessages, receivedMessages);
    }
    
    private Set<String> sendTestMessages(String topic, int count) {
        Set<String> sentMessages = new HashSet<>();
        KafkaProducer<String, String> producer = createProducer();
        
        for (int i = 0; i < count; i++) {
            String messageId = UUID.randomUUID().toString();
            String message = "test-message-" + i + "-" + messageId;
            
            producer.send(new ProducerRecord<>(topic, messageId, message));
            sentMessages.add(message);
        }
        
        producer.flush();
        producer.close();
        
        log.info("å‘é€æµ‹è¯•æ¶ˆæ¯å®Œæˆï¼Œå…± {} æ¡", sentMessages.size());
        return sentMessages;
    }
    
    private Set<String> consumeTestMessages(String topic) {
        Set<String> receivedMessages = new HashSet<>();
        KafkaConsumer<String, String> consumer = createConsumer();
        
        consumer.subscribe(Collections.singletonList(topic));
        
        long startTime = System.currentTimeMillis();
        while (System.currentTimeMillis() - startTime < 60000) { // æœ€å¤šç­‰å¾…60ç§’
            ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(1000));
            
            for (ConsumerRecord<String, String> record : records) {
                receivedMessages.add(record.value());
            }
            
            if (records.isEmpty()) {
                break; // æ²¡æœ‰æ›´å¤šæ¶ˆæ¯
            }
        }
        
        consumer.close();
        log.info("æ¥æ”¶æµ‹è¯•æ¶ˆæ¯å®Œæˆï¼Œå…± {} æ¡", receivedMessages.size());
        return receivedMessages;
    }
    
    private void validateResults(Set<String> sent, Set<String> received) {
        Set<String> missing = new HashSet<>(sent);
        missing.removeAll(received);
        
        Set<String> extra = new HashSet<>(received);
        extra.removeAll(sent);
        
        System.out.println("=== æ•°æ®ä¸€è‡´æ€§éªŒè¯ç»“æœ ===");
        System.out.println("å‘é€æ¶ˆæ¯æ•°: " + sent.size());
        System.out.println("æ¥æ”¶æ¶ˆæ¯æ•°: " + received.size());
        System.out.println("ä¸¢å¤±æ¶ˆæ¯æ•°: " + missing.size());
        System.out.println("å¤šä½™æ¶ˆæ¯æ•°: " + extra.size());
        
        if (missing.isEmpty() && extra.isEmpty()) {
            System.out.println("âœ… æ•°æ®ä¸€è‡´æ€§éªŒè¯é€šè¿‡");
        } else {
            System.out.println("âŒ æ•°æ®ä¸€è‡´æ€§éªŒè¯å¤±è´¥");
            if (!missing.isEmpty()) {
                System.out.println("ä¸¢å¤±çš„æ¶ˆæ¯æ ·ä¾‹: " + missing.iterator().next());
            }
            if (!extra.isEmpty()) {
                System.out.println("å¤šä½™çš„æ¶ˆæ¯æ ·ä¾‹: " + extra.iterator().next());
            }
        }
    }
}
```

### 9.4 æ•…éšœæ¢å¤æµ‹è¯•


**ğŸ”„ ç³»ç»Ÿæ¢å¤èƒ½åŠ›éªŒè¯**

```bash
#!/bin/bash
# æ•…éšœæ¢å¤è‡ªåŠ¨åŒ–æµ‹è¯•è„šæœ¬

echo "=== Kafkaæ•…éšœæ¢å¤æµ‹è¯• ==="

# æµ‹è¯•åœºæ™¯1ï¼šå•ä¸ªBrokeræ•…éšœ
echo "1. æµ‹è¯•å•ä¸ªBrokeræ•…éšœæ¢å¤..."
./test-single-broker-failure.sh

# æµ‹è¯•åœºæ™¯2ï¼šç½‘ç»œåˆ†åŒº
echo "2. æµ‹è¯•ç½‘ç»œåˆ†åŒºæ¢å¤..."
./test-network-partition.sh

# æµ‹è¯•åœºæ™¯3ï¼šç£ç›˜æ•…éšœ
echo "3. æµ‹è¯•ç£ç›˜æ•…éšœæ¢å¤..."
./test-disk-failure.sh

# æµ‹è¯•åœºæ™¯4ï¼šZooKeeperæ•…éšœ
echo "4. æµ‹è¯•ZooKeeperæ•…éšœæ¢å¤..."
./test-zookeeper-failure.sh

# ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
echo "=== ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š ==="
./generate-test-report.sh

echo "æ•…éšœæ¢å¤æµ‹è¯•å®Œæˆï¼"
```

---

## 10. ğŸ­ ç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µ


### 10.1 ç›‘æ§ä½“ç³»å»ºè®¾


**ğŸ“Š å®Œæ•´çš„ç›‘æ§ä½“ç³»**

```yaml
# Prometheusç›‘æ§é…ç½®
version: '3'
services:
  prometheus:
    image: prom/prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml

  grafana:
    image: grafana/grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin

  kafka-exporter:
    image: danielqsj/kafka-exporter
    ports:
      - "9308:9308"
    command:
      - '--kafka.server=kafka1:9092'
      - '--kafka.server=kafka2:9092'
      - '--kafka.server=kafka3:9092'
```

**ğŸ¯ å…³é”®ç›‘æ§æŒ‡æ ‡**
```
é›†ç¾¤å¥åº·æŒ‡æ ‡ï¼š
â€¢ kafka_server_brokertopicmetrics_messagesin_totalï¼šæ¶ˆæ¯å…¥é‡
â€¢ kafka_server_brokertopicmetrics_messagesout_totalï¼šæ¶ˆæ¯å‡ºé‡  
â€¢ kafka_server_replicamanager_leadercountï¼šLeaderåˆ†åŒºæ•°
â€¢ kafka_server_replicamanager_partitioncountï¼šåˆ†åŒºæ€»æ•°
â€¢ kafka_controller_kafkacontroller_activecontrollercountï¼šæ´»è·ƒControlleræ•°

æ€§èƒ½æŒ‡æ ‡ï¼š
â€¢ kafka_server_brokertopicmetrics_bytein_totalï¼šå…¥æµé‡å­—èŠ‚æ•°
â€¢ kafka_server_brokertopicmetrics_byteout_totalï¼šå‡ºæµé‡å­—èŠ‚æ•°
â€¢ kafka_network_requestmetrics_totaltimemsï¼šè¯·æ±‚å¤„ç†æ—¶é—´
â€¢ kafka_server_delayedoperationpurgatory_numdelayedoperationsï¼šå»¶è¿Ÿæ“ä½œæ•°

å¯é æ€§æŒ‡æ ‡ï¼š
â€¢ kafka_server_replicamanager_underreplicatedpartitionsï¼šå‰¯æœ¬ä¸è¶³çš„åˆ†åŒº
â€¢ kafka_controller_kafkacontroller_offlinepartitionscountï¼šç¦»çº¿åˆ†åŒºæ•°
â€¢ kafka_server_replicamanager_isr_shrinks_per_secï¼šISRæ”¶ç¼©é¢‘ç‡
â€¢ kafka_server_replicamanager_isr_expands_per_secï¼šISRæ‰©å±•é¢‘ç‡
```

### 10.2 å‘Šè­¦ç­–ç•¥é…ç½®


**ğŸš¨ åˆ†çº§å‘Šè­¦æœºåˆ¶**

```yaml
# Alertmanagerå‘Šè­¦è§„åˆ™
groups:
- name: kafka-critical
  rules:
  - alert: KafkaClusterDown
    expr: up{job="kafka"} < 0.5
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "Kafkaé›†ç¾¤ä¸å¯ç”¨"
      description: "è¶…è¿‡50%çš„KafkaèŠ‚ç‚¹ä¸å¯ç”¨"

  - alert: OfflinePartitions  
    expr: kafka_controller_kafkacontroller_offlinepartitionscount > 0
    for: 30s
    labels:
      severity: critical
    annotations:
      summary: "å‘ç°ç¦»çº¿åˆ†åŒº"
      description: "æœ‰ {{ $value }} ä¸ªåˆ†åŒºç¦»çº¿"

- name: kafka-warning
  rules:
  - alert: UnderReplicatedPartitions
    expr: kafka_server_replicamanager_underreplicatedpartitions > 0
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "å‰¯æœ¬ä¸è¶³è­¦å‘Š"
      description: "æœ‰ {{ $value }} ä¸ªåˆ†åŒºå‰¯æœ¬ä¸è¶³"

  - alert: HighProduceLatency
    expr: kafka_network_requestmetrics_totaltimems{request="Produce"} > 1000
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "Producerå»¶è¿Ÿè¿‡é«˜"
      description: "æ¶ˆæ¯å‘é€å»¶è¿Ÿè¶…è¿‡1ç§’"
```

### 10.3 å®¹é‡è§„åˆ’æŒ‡å¯¼


**ğŸ“ ç”Ÿäº§ç¯å¢ƒå®¹é‡è®¡ç®—**

```
å®¹é‡è§„åˆ’è®¡ç®—å…¬å¼ï¼š

å­˜å‚¨å®¹é‡è§„åˆ’ï¼š
æ¯æ—¥æ•°æ®é‡ = å¹³å‡æ¶ˆæ¯å¤§å° Ã— æ¯æ—¥æ¶ˆæ¯æ•°é‡
ä¿ç•™æœŸå­˜å‚¨ = æ¯æ—¥æ•°æ®é‡ Ã— ä¿ç•™å¤©æ•° Ã— å‰¯æœ¬æ•°
å®‰å…¨ç¼“å†² = ä¿ç•™æœŸå­˜å‚¨ Ã— 1.5ï¼ˆ50%ç¼“å†²ï¼‰

å®ä¾‹è®¡ç®—ï¼š
å¹³å‡æ¶ˆæ¯å¤§å°ï¼š2KB
æ¯æ—¥æ¶ˆæ¯æ•°é‡ï¼š1äº¿æ¡
ä¿ç•™æœŸï¼š7å¤©
å‰¯æœ¬æ•°ï¼š3

æ¯æ—¥æ•°æ®é‡ = 2KB Ã— 1äº¿ = 200GB
ä¿ç•™æœŸå­˜å‚¨ = 200GB Ã— 7 Ã— 3 = 4.2TB
å®é™…éœ€è¦ = 4.2TB Ã— 1.5 = 6.3TB

ç½‘ç»œå¸¦å®½è§„åˆ’ï¼š
å³°å€¼æµé‡ = å¹³å‡æµé‡ Ã— å³°å€¼å€æ•°
ç”Ÿäº§è€…å¸¦å®½ = å³°å€¼æµé‡
æ¶ˆè´¹è€…å¸¦å®½ = å³°å€¼æµé‡ Ã— æ¶ˆè´¹è€…ç»„æ•°é‡
å‰¯æœ¬åŒæ­¥å¸¦å®½ = å³°å€¼æµé‡ Ã— (å‰¯æœ¬æ•°-1)

æ€»å¸¦å®½éœ€æ±‚ = ç”Ÿäº§è€…å¸¦å®½ + æ¶ˆè´¹è€…å¸¦å®½ + å‰¯æœ¬åŒæ­¥å¸¦å®½
```

**ğŸ“Š æ€§èƒ½åŸºå‡†æµ‹è¯•**
```bash
#!/bin/bash
# Kafkaæ€§èƒ½åŸºå‡†æµ‹è¯•

echo "=== å¼€å§‹Kafkaæ€§èƒ½åŸºå‡†æµ‹è¯• ==="

# æµ‹è¯•1ï¼šProduceræ€§èƒ½
echo "1. æµ‹è¯•Produceræ€§èƒ½..."
kafka-producer-perf-test.sh \
  --topic perf-test \
  --num-records 1000000 \
  --record-size 1024 \
  --throughput 100000 \
  --producer-props bootstrap.servers=localhost:9092 \
                    acks=all \
                    batch.size=16384 \
                    linger.ms=10

# æµ‹è¯•2ï¼šConsumeræ€§èƒ½  
echo "2. æµ‹è¯•Consumeræ€§èƒ½..."
kafka-consumer-perf-test.sh \
  --topic perf-test \
  --messages 1000000 \
  --bootstrap-server localhost:9092 \
  --threads 1

# æµ‹è¯•3ï¼šç«¯åˆ°ç«¯å»¶è¿Ÿ
echo "3. æµ‹è¯•ç«¯åˆ°ç«¯å»¶è¿Ÿ..."
kafka-run-class.sh kafka.tools.EndToEndLatency \
  localhost:9092 \
  perf-test \
  1000 \
  1 \
  1024

echo "=== æ€§èƒ½åŸºå‡†æµ‹è¯•å®Œæˆ ==="
```

### 10.4 è¿ç»´è‡ªåŠ¨åŒ–


**ğŸ¤– è‡ªåŠ¨åŒ–è¿ç»´è„šæœ¬**

```bash
#!/bin/bash
# Kafkaæ—¥å¸¸è¿ç»´è‡ªåŠ¨åŒ–è„šæœ¬

# å‡½æ•°ï¼šæ£€æŸ¥é›†ç¾¤å¥åº·çŠ¶æ€
check_cluster_health() {
    echo "æ£€æŸ¥é›†ç¾¤å¥åº·çŠ¶æ€..."
    
    # æ£€æŸ¥BrokerçŠ¶æ€
    broker_count=$(kafka-broker-api-versions.sh --bootstrap-server localhost:9092 2>/dev/null | wc -l)
    expected_brokers=3
    
    if [ $broker_count -eq $expected_brokers ]; then
        echo "âœ… æ‰€æœ‰Brokeræ­£å¸¸è¿è¡Œ ($broker_count/$expected_brokers)"
    else
        echo "âŒ Brokeræ•°é‡å¼‚å¸¸ ($broker_count/$expected_brokers)"
        send_alert "Kafka Brokeræ•°é‡å¼‚å¸¸"
    fi
    
    # æ£€æŸ¥TopicçŠ¶æ€
    offline_partitions=$(kafka-log-dirs.sh --bootstrap-server localhost:9092 --describe | grep -c "offline")
    if [ $offline_partitions -eq 0 ]; then
        echo "âœ… æ‰€æœ‰åˆ†åŒºæ­£å¸¸"
    else
        echo "âŒ å‘ç° $offline_partitions ä¸ªç¦»çº¿åˆ†åŒº"
        send_alert "Kafkaåˆ†åŒºç¦»çº¿"
    fi
}

# å‡½æ•°ï¼šæ¸…ç†è¿‡æœŸæ—¥å¿—
cleanup_logs() {
    echo "æ¸…ç†è¿‡æœŸæ—¥å¿—..."
    
    # æ¸…ç†Kafkaæ—¥å¿—ï¼ˆä¿ç•™7å¤©ï¼‰
    find /opt/kafka/logs -name "*.log" -mtime +7 -delete
    
    # æ¸…ç†åº”ç”¨æ—¥å¿—ï¼ˆä¿ç•™30å¤©ï¼‰
    find /var/log/kafka-app -name "*.log" -mtime +30 -delete
    
    echo "æ—¥å¿—æ¸…ç†å®Œæˆ"
}

# å‡½æ•°ï¼šå¤‡ä»½é…ç½®æ–‡ä»¶
backup_configs() {
    echo "å¤‡ä»½é…ç½®æ–‡ä»¶..."
    
    backup_dir="/backup/kafka/$(date +%Y%m%d)"
    mkdir -p $backup_dir
    
    # å¤‡ä»½Kafkaé…ç½®
    cp -r /opt/kafka/config $backup_dir/
    
    # å¤‡ä»½Topicé…ç½®
    kafka-topics.sh --bootstrap-server localhost:9092 --list > $backup_dir/topics.list
    
    # å¤‡ä»½Consumer Groupä¿¡æ¯
    kafka-consumer-groups.sh --bootstrap-server localhost:9092 --list > $backup_dir/consumer-groups.list
    
    echo "é…ç½®å¤‡ä»½å®Œæˆ: $backup_dir"
}

# å‡½æ•°ï¼šæ€§èƒ½æ£€æŸ¥
performance_check() {
    echo "æ‰§è¡Œæ€§èƒ½æ£€æŸ¥..."
    
    # æ£€æŸ¥ç£ç›˜ä½¿ç”¨ç‡
    disk_usage=$(df /opt/kafka/data | tail -1 | awk '{print $5}' | sed 's/%//')
    if [ $disk_usage -gt 80 ]; then
        echo "âš ï¸ ç£ç›˜ä½¿ç”¨ç‡è¿‡é«˜: ${disk_usage}%"
        send_alert "Kafkaç£ç›˜ä½¿ç”¨ç‡è¿‡é«˜: ${disk_usage}%"
    fi
    
    # æ£€æŸ¥å†…å­˜ä½¿ç”¨
    memory_usage=$(free | grep Mem | awk '{printf("%.1f", $3/$2 * 100.0)}')
    echo "å†…å­˜ä½¿ç”¨ç‡: ${memory_usage}%"
    
    # æ£€æŸ¥CPUè´Ÿè½½
    cpu_load=$(uptime | awk -F'load average:' '{print $2}' | awk '{print $1}' | sed 's/,//')
    echo "CPUè´Ÿè½½: $cpu_load"
}

# å‡½æ•°ï¼šå‘é€å‘Šè­¦
send_alert() {
    local message=$1
    # è¿™é‡Œå¯ä»¥é›†æˆä¼ä¸šå¾®ä¿¡ã€é’‰é’‰ã€é‚®ä»¶ç­‰å‘Šè­¦æ–¹å¼
    echo "ğŸš¨ å‘Šè­¦: $message"
    
    # ç¤ºä¾‹ï¼šå‘é€åˆ°Slack
    # curl -X POST -H 'Content-type: application/json' \
    #      --data '{"text":"Kafkaå‘Šè­¦: '$message'"}' \
    #      YOUR_SLACK_WEBHOOK_URL
}

# ä¸»æµç¨‹
main() {
    echo "=== Kafkaè‡ªåŠ¨åŒ–è¿ç»´æ£€æŸ¥å¼€å§‹ ===" 
    echo "æ‰§è¡Œæ—¶é—´: $(date)"
    
    check_cluster_health
    cleanup_logs  
    backup_configs
    performance_check
    
    echo "=== è‡ªåŠ¨åŒ–è¿ç»´æ£€æŸ¥å®Œæˆ ==="
}

# æ‰§è¡Œä¸»æµç¨‹
main
```

---

## 11. ğŸ“‹ æ ¸å¿ƒè¦ç‚¹æ€»ç»“


### 11.1 å¿…é¡»æŒæ¡çš„æ ¸å¿ƒæ¦‚å¿µ


```
ğŸ”¸ æ•°æ®å¯é æ€§å››è¦ç´ ï¼š
  â€¢ ä¸ä¸¢å¤±ï¼ˆDurabilityï¼‰ï¼šacks=all + å‰¯æœ¬æœºåˆ¶
  â€¢ ä¸é‡å¤ï¼ˆExactly Onceï¼‰ï¼šå¹‚ç­‰æ€§ + äº‹åŠ¡
  â€¢ æœ‰åºæ€§ï¼ˆOrderingï¼‰ï¼šåˆ†åŒºå†…é¡ºåº + åˆç†åˆ†åŒºç­–ç•¥  
  â€¢ å®Œæ•´æ€§ï¼ˆIntegrityï¼‰ï¼šæ ¡éªŒå’Œ + ç«¯åˆ°ç«¯ç›‘æ§

ğŸ”¸ å¯é æ€§ç­‰çº§é€‰æ‹©ï¼š
  â€¢ è‡³å°‘ä¸€æ¬¡ï¼šé«˜æ€§èƒ½ï¼Œå…è®¸é‡å¤
  â€¢ è‡³å¤šä¸€æ¬¡ï¼šæœ€é«˜æ€§èƒ½ï¼Œå…è®¸ä¸¢å¤±
  â€¢ æ°å¥½ä¸€æ¬¡ï¼šæœ€å¯é ï¼Œæ€§èƒ½å¼€é”€å¤§

ğŸ”¸ æ ¸å¿ƒé…ç½®å‚æ•°ï¼š
  â€¢ acks=allï¼šç­‰å¾…æ‰€æœ‰å‰¯æœ¬ç¡®è®¤
  â€¢ retries>0ï¼šå…è®¸é‡è¯•
  â€¢ enable.idempotence=trueï¼šå¼€å¯å¹‚ç­‰æ€§
  â€¢ min.insync.replicasâ‰¥2ï¼šæœ€å°åŒæ­¥å‰¯æœ¬æ•°
```

### 11.2 å…³é”®å®è·µè¦ç‚¹


**ğŸ”¹ Producerç«¯æœ€ä½³é…ç½®**
```
ç”Ÿäº§ç¯å¢ƒæ¨èé…ç½®ï¼š
acks = all                          # ç­‰å¾…æ‰€æœ‰å‰¯æœ¬ç¡®è®¤
retries = 3                         # é‡è¯•3æ¬¡
enable.idempotence = true           # å¼€å¯å¹‚ç­‰æ€§  
batch.size = 16384                  # æ‰¹é‡å¤§å°16KB
linger.ms = 10                      # ç­‰å¾…10msæ”¶é›†æ›´å¤šæ¶ˆæ¯
compression.type = lz4              # ä½¿ç”¨LZ4å‹ç¼©
max.in.flight.requests.per.connection = 5  # æ§åˆ¶å¹¶å‘
```

**ğŸ”¹ Consumerç«¯å¯é å¤„ç†**
```
æ¶ˆè´¹å¤„ç†æ¨¡å¼ï¼š
1. å…³é—­è‡ªåŠ¨æäº¤ï¼šenable.auto.commit=false
2. ä¸šåŠ¡å¤„ç†æˆåŠŸåæ‰‹åŠ¨æäº¤offset
3. å¼‚å¸¸æ—¶ä¸æäº¤ï¼Œå…è®¸é‡æ–°æ¶ˆè´¹
4. å®ç°å¹‚ç­‰æ€§å¤„ç†é€»è¾‘
5. è®¾ç½®åˆç†çš„è¶…æ—¶æ—¶é—´
```

**ğŸ”¹ é›†ç¾¤é…ç½®è¦ç‚¹**
```
Brokerç«¯å…³é”®é…ç½®ï¼š
default.replication.factor = 3      # é»˜è®¤3å‰¯æœ¬
min.insync.replicas = 2             # æœ€å°‘2å‰¯æœ¬åŒæ­¥
unclean.leader.election.enable = false  # ç¦æ­¢è„é€‰ä¸¾
log.flush.interval.messages = 1     # æ¯æ¡æ¶ˆæ¯åˆ·ç›˜
log.retention.hours = 168           # ä¿ç•™7å¤©
```

### 11.3 æ•…éšœå¤„ç†ç­–ç•¥


**ğŸ› ï¸ å¸¸è§æ•…éšœå¤„ç†æµç¨‹**

```
ç½‘ç»œåˆ†åŒºæ•…éšœï¼š
1. ç›‘æ§å‘ç°ISRå‰¯æœ¬å‡å°‘
2. æ£€æŸ¥ç½‘ç»œè¿é€šæ€§
3. ç­‰å¾…ç½‘ç»œæ¢å¤æˆ–æ‰‹åŠ¨ä¿®å¤
4. éªŒè¯å‰¯æœ¬åŒæ­¥çŠ¶æ€
5. ç¡®è®¤æ•°æ®ä¸€è‡´æ€§

Brokerå®•æœºæ•…éšœï¼š
1. å…¶ä»–Brokerè‡ªåŠ¨æ¥ç®¡Leaderè§’è‰²
2. é‡æ–°å¯åŠ¨æ•…éšœBroker
3. ç­‰å¾…å‰¯æœ¬é‡æ–°åŒæ­¥
4. æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®ä¸¢å¤±
5. éªŒè¯é›†ç¾¤åŠŸèƒ½æ­£å¸¸

æ•°æ®ä¸ä¸€è‡´ï¼š
1. åœæ­¢ç›¸å…³Producerå’ŒConsumer
2. æ£€æŸ¥å„å‰¯æœ¬çš„æ•°æ®çŠ¶æ€  
3. ä»æœ€å®Œæ•´çš„å‰¯æœ¬æ¢å¤æ•°æ®
4. é‡æ–°å¯åŠ¨æœåŠ¡
5. éªŒè¯æ•°æ®å®Œæ•´æ€§
```

### 11.4 ç›‘æ§å‘Šè­¦è¦ç‚¹


**ğŸ“Š å…³é”®ç›‘æ§æŒ‡æ ‡**
```
å¿…ç›‘æ§æŒ‡æ ‡ï¼š
ğŸ”´ ç¦»çº¿åˆ†åŒºæ•°ï¼škafka_controller_kafkacontroller_offlinepartitionscount
ğŸ”´ å‰¯æœ¬ä¸è¶³åˆ†åŒºï¼škafka_server_replicamanager_underreplicatedpartitions  
ğŸŸ¡ æ¶ˆæ¯å †ç§¯ï¼škafka_consumer_lag_sum
ğŸŸ¡ è¯·æ±‚å»¶è¿Ÿï¼škafka_network_requestmetrics_totaltimems
ğŸŸ¢ ååé‡ï¼škafka_server_brokertopicmetrics_messagesin_total

å‘Šè­¦çº§åˆ«ï¼š
â€¢ Criticalï¼šé›†ç¾¤ä¸å¯ç”¨ã€æ•°æ®ä¸¢å¤±é£é™©
â€¢ Warningï¼šæ€§èƒ½ä¸‹é™ã€å®¹é‡é¢„è­¦
â€¢ Infoï¼šæ—¥å¸¸è¿è¥ä¿¡æ¯
```

### 11.5 ç”Ÿäº§éƒ¨ç½²æ£€æŸ¥æ¸…å•


**âœ… ä¸Šçº¿å‰æ£€æŸ¥æ¸…å•**
```
é…ç½®æ£€æŸ¥ï¼š
â˜ acks=allå·²è®¾ç½®
â˜ å‰¯æœ¬æ•°â‰¥3å·²é…ç½®
â˜ min.insync.replicasâ‰¥2å·²è®¾ç½®
â˜ å¹‚ç­‰æ€§å·²å¼€å¯
â˜ é‡è¯•æœºåˆ¶å·²é…ç½®

ç›‘æ§æ£€æŸ¥ï¼š
â˜ Prometheusç›‘æ§å·²éƒ¨ç½²
â˜ Grafanaä»ªè¡¨æ¿å·²é…ç½®  
â˜ å‘Šè­¦è§„åˆ™å·²è®¾ç½®
â˜ å‘Šè­¦é€šé“å·²æµ‹è¯•

å®¹ç¾æ£€æŸ¥ï¼š
â˜ å¤‡ä»½ç­–ç•¥å·²åˆ¶å®š
â˜ æ¢å¤æµç¨‹å·²æµ‹è¯•
â˜ è·¨æœºæˆ¿å¤åˆ¶å·²é…ç½®
â˜ æ•…éšœåˆ‡æ¢å·²éªŒè¯

æ€§èƒ½æ£€æŸ¥ï¼š
â˜ åŸºå‡†æµ‹è¯•å·²å®Œæˆ
â˜ å®¹é‡è§„åˆ’å·²ç¡®è®¤
â˜ ç½‘ç»œå¸¦å®½å·²è¯„ä¼°
â˜ å­˜å‚¨ç©ºé—´å·²é¢„ç•™
```

> ğŸ’¡ **æ ¸å¿ƒè®°å¿†å£è¯€**
> 
> **å¯é é…ç½®ä¸‰è¦ç´ **ï¼šackså…¨ç¡®è®¤ï¼Œå‰¯æœ¬è¦è¶³å¤Ÿï¼Œå¹‚ç­‰é˜²é‡å¤
> 
> **ç›‘æ§å‘Šè­¦å››ç»´åº¦**ï¼šé›†ç¾¤å¥åº·çœ‹çŠ¶æ€ï¼Œæ€§èƒ½æŒ‡æ ‡çœ‹å»¶è¿Ÿï¼Œæ•°æ®è´¨é‡çœ‹å®Œæ•´ï¼Œå®¹é‡è§„åˆ’çœ‹è¶‹åŠ¿
> 
> **æ•…éšœå¤„ç†äº”æ­¥æ³•**ï¼šå¿«é€Ÿå‘ç°ï¼Œå‡†ç¡®å®šä½ï¼ŒåŠæ—¶å¤„ç†ï¼ŒéªŒè¯æ¢å¤ï¼Œæ€»ç»“æ”¹è¿›

**ğŸ¯ å®é™…åº”ç”¨ä»·å€¼**
- **é‡‘èè¡Œä¸š**ï¼šäº¤æ˜“æ•°æ®é›¶ä¸¢å¤±ï¼Œèµ„é‡‘å®‰å…¨æœ‰ä¿éšœ
- **ç”µå•†å¹³å°**ï¼šè®¢å•å¤„ç†ä¸é‡å¤ï¼Œåº“å­˜æ•°æ®å¼ºä¸€è‡´  
- **ç‰©è”ç½‘ç³»ç»Ÿ**ï¼šè®¾å¤‡æ•°æ®å¯è¿½æº¯ï¼Œå¼‚å¸¸åŠæ—¶èƒ½å‘ç°
- **æ—¥å¿—ç³»ç»Ÿ**ï¼šè¿ç»´æ•°æ®å…¨ä¿ç•™ï¼Œé—®é¢˜æ’æŸ¥æœ‰ä¾æ®

è¿™å¥—å¯é æ€§ä¿è¯æœºåˆ¶å¸®åŠ©ä¼ä¸šåœ¨å¤§æ•°æ®æ—¶ä»£æ„å»ºçœŸæ­£å¯ä¿¡èµ–çš„æ•°æ®æµå¤„ç†å¹³å°ï¼