---
title: 7、集群维护管理
---
## 📚 目录

1. [集群维护基础概念](#1-集群维护基础概念)
2. [节点维护模式详解](#2-节点维护模式详解)
3. [节点排空与封锁操作](#3-节点排空与封锁操作)
4. [集群组件升级管理](#4-集群组件升级管理)
5. [集群健康检查体系](#5-集群健康检查体系)
6. [版本兼容性管理](#6-版本兼容性管理)
7. [核心要点总结](#7-核心要点总结)

---

## 1. 🔧 集群维护基础概念


### 1.1 什么是集群维护


**🔸 通俗理解**
集群维护就像是给一个大型工厂做保养维修。工厂有很多机器（节点），生产线上有很多产品（Pod），我们需要在不停产的情况下，对机器进行维护升级。

```
现实中的工厂维护：                K8s集群维护：
┌─────────────────┐              ┌─────────────────┐
│  生产线A(正常)   │              │   Node1(正常)   │
├─────────────────┤              ├─────────────────┤
│  生产线B(维护中) │     ←→       │   Node2(维护中)  │
├─────────────────┤              ├─────────────────┤
│  生产线C(正常)   │              │   Node3(正常)   │
└─────────────────┘              └─────────────────┘
```

**💡 核心理念**
- **不停机维护**：保证业务连续性
- **渐进式操作**：一次只维护部分节点
- **安全第一**：确保数据和服务不丢失
- **可回滚性**：出问题能快速恢复

### 1.2 维护场景分类


**🎯 常见维护场景**

| 维护类型 | **现实比喻** | **具体操作** | **影响程度** |
|---------|------------|-------------|-------------|
| 🔄 **日常维护** | `定期保养机器` | `重启节点、清理资源` | `影响小` |
| ⬆️ **版本升级** | `更换新设备` | `升级K8s组件` | `影响中等` |
| 🔧 **硬件维护** | `更换零部件` | `更换服务器硬件` | `影响大` |
| 🚨 **故障处理** | `紧急抢修` | `修复异常节点` | `影响紧急` |

### 1.3 维护原则


**🌟 安全维护四原则**
```
1. 📊 评估影响：维护前评估对业务的影响
2. 🔄 分批操作：不要同时维护多个节点
3. 💾 备份优先：重要数据必须先备份
4. 📈 监控到位：维护过程全程监控
```

---

## 2. 🛠️ 节点维护模式详解


### 2.1 节点状态理解


**🔸 节点就像工厂里的机器**
- **Ready（准备就绪）**：机器正常运行，可以生产产品
- **NotReady（未就绪）**：机器出故障了，暂时不能生产
- **SchedulingDisabled（调度禁用）**：机器封存了，不再安排新任务

```
节点状态转换图：
            维护开始
Ready  ────────────→  SchedulingDisabled
  ↑                        │
  │                        │ 排空完成
  │                        ↓
  └──────────────  NotReady/Maintenance
            维护结束
```

### 2.2 维护模式分类


**🔹 三种维护模式对比**

| 模式 | **操作** | **Pod状态** | **新Pod调度** | **适用场景** |
|------|---------|-----------|-------------|-------------|
| 🚧 **Cordon封锁** | `kubectl cordon` | `继续运行` | `❌ 禁止` | `计划维护前准备` |
| 🚿 **Drain排空** | `kubectl drain` | `迁移到其他节点` | `❌ 禁止` | `需要重启节点时` |
| 🔓 **Uncordon解封** | `kubectl uncordon` | `正常调度` | `✅ 允许` | `维护完成恢复` |

### 2.3 维护前的准备工作


**📋 维护前检查清单**
```
🔍 检查集群状态
  ├── kubectl get nodes          # 查看所有节点状态
  ├── kubectl get pods --all-namespaces  # 查看Pod分布
  └── kubectl top nodes          # 查看资源使用情况

📊 评估业务影响
  ├── 统计该节点上的关键服务
  ├── 检查是否有单点服务（只在该节点运行）
  └── 确认是否在业务低峰期

💾 备份关键数据
  ├── 备份etcd数据
  ├── 导出重要配置文件
  └── 记录当前Pod分布状态
```

---

## 3. 🎮 节点排空与封锁操作


### 3.1 kubectl cordon 节点封锁


**🔸 什么是节点封锁**
就像在工厂机器上贴个"维修中，请勿使用"的标签。机器上现有的工作继续进行，但不再安排新工作。

```bash
# 封锁节点（禁止新Pod调度到该节点）
kubectl cordon worker-node-1

# 查看节点状态
kubectl get nodes
```

**💡 封锁后的效果**
```
封锁前：
Master调度器：这个节点可以接收新Pod ✅
worker-node-1：[Pod1] [Pod2] [Pod3]

封锁后：
Master调度器：这个节点不接收新Pod ❌
worker-node-1：[Pod1] [Pod2] [Pod3] (现有Pod继续运行)
```

**🎯 适用场景**
- ✅ 计划维护前的准备
- ✅ 逐渐减少节点负载
- ✅ 测试其他节点的承载能力

### 3.2 kubectl drain 节点排空


**🔸 什么是节点排空**
就像要维修一条生产线，需要把所有产品转移到其他生产线上，然后才能安全维修。

```bash
# 排空节点（迁移所有Pod到其他节点）
kubectl drain worker-node-1 --ignore-daemonsets --delete-emptydir-data

# 强制排空（适用于有本地数据的Pod）
kubectl drain worker-node-1 --ignore-daemonsets --delete-emptydir-data --force
```

**🔧 排空参数详解**

| 参数 | **作用** | **比喻说明** |
|------|---------|-------------|
| `--ignore-daemonsets` | `忽略DaemonSet Pod` | `系统守护程序不用搬走` |
| `--delete-emptydir-data` | `删除临时数据` | `清理临时文件` |
| `--force` | `强制删除Pod` | `紧急情况下强制搬迁` |
| `--grace-period=300` | `优雅删除时间` | `给300秒时间打包搬家` |

### 3.3 排空过程详解


**🔄 排空的完整流程**
```
排空过程示意：

步骤1: 标记节点不可调度
worker-node-1: [Pod1] [Pod2] [Pod3] ← ❌ 新Pod禁止进入

步骤2: 逐个驱逐Pod
Pod1: 正在迁移到worker-node-2 🚚
Pod2: 正在迁移到worker-node-3 🚚  
Pod3: 等待迁移... ⏳

步骤3: 等待Pod完全迁移
worker-node-1: [空] ✅ 可以安全维护
worker-node-2: [Pod1] [其他Pod...]
worker-node-3: [Pod2] [其他Pod...]
```

### 3.4 特殊情况处理


**🚨 排空可能遇到的问题**

```
问题1: Pod卡住不能删除
原因：Pod有PVC（持久化存储）
解决：kubectl delete pod <pod-name> --force --grace-period=0

问题2: DaemonSet Pod阻止排空
原因：系统守护进程不能删除
解决：使用 --ignore-daemonsets 参数

问题3: 单副本服务导致业务中断
原因：只有一个副本的服务会暂时不可用
解决：提前扩容副本数，确保高可用
```

### 3.5 恢复节点调度


**🔓 kubectl uncordon 解封节点**

```bash
# 维护完成后，恢复节点调度
kubectl uncordon worker-node-1

# 验证节点状态
kubectl get nodes
# NAME           STATUS   ROLES    AGE   VERSION
# worker-node-1  Ready    worker   10d   v1.28.0  ← 状态变为Ready
```

**📊 验证恢复效果**
```bash
# 创建测试Pod验证调度
kubectl run test-pod --image=nginx --dry-run=client -o yaml | kubectl apply -f -

# 查看Pod是否能调度到恢复的节点
kubectl get pods -o wide
```

---

## 4. ⬆️ 集群组件升级管理


### 4.1 K8s升级策略理解


**🔸 升级就像给工厂更新设备**
想象工厂要把所有机器从1.0版本升级到2.0版本，不能一下子全部更换，需要有计划地逐步升级。

```
升级策略对比：
┌─────────────────┐    ┌─────────────────┐
│ 滚动升级(推荐)   │    │  停机升级(不推荐) │
│                │    │                │
│ 旧版本 → 新版本  │    │ 全部停止 → 全部更新 │
│ 一个一个升级     │    │ 业务中断        │
│ 业务不中断       │    │ 风险高         │
└─────────────────┘    └─────────────────┘
```

### 4.2 升级前的准备工作


**📋 升级前必做检查**
```
🔍 兼容性检查
  ├── 查看当前K8s版本: kubectl version
  ├── 确认目标版本兼容性
  └── 检查应用是否支持新版本API

💾 备份关键数据
  ├── 备份etcd: etcdctl snapshot save backup.db
  ├── 备份kubeconfig配置文件
  └── 导出重要资源配置: kubectl get all --all-namespaces -o yaml > backup.yaml

📊 集群健康检查
  ├── kubectl get nodes          # 所有节点Ready
  ├── kubectl get pods --all-namespaces  # 所有Pod正常
  └── kubectl get componentstatuses      # 组件状态正常
```

### 4.3 Master节点升级


**🔧 Master节点升级步骤**

```bash
# 1. 升级kubeadm工具
sudo apt-get update
sudo apt-get install -y kubeadm=1.28.0-00

# 2. 查看升级计划
sudo kubeadm upgrade plan

# 3. 执行Master升级
sudo kubeadm upgrade apply v1.28.0

# 4. 升级kubelet和kubectl
sudo apt-get install -y kubelet=1.28.0-00 kubectl=1.28.0-00
sudo systemctl restart kubelet
```

**💡 升级过程说明**
```
Master升级过程：
1. 🛑 暂停API服务器
2. 📦 更新控制平面组件
3. 🔄 重启各个组件
4. ✅ 验证升级成功

期间影响：
- kubectl命令临时不可用（约1-2分钟）
- 现有Pod继续正常运行
- 新Pod暂时无法调度
```

### 4.4 Worker节点升级


**🔄 Worker节点逐个升级**

```bash
# 在Master节点执行：排空要升级的Worker节点
kubectl drain worker-node-1 --ignore-daemonsets --delete-emptydir-data

# 在Worker节点执行：升级组件
sudo apt-get update
sudo apt-get install -y kubeadm=1.28.0-00 kubelet=1.28.0-00
sudo systemctl restart kubelet

# 在Master节点执行：恢复节点
kubectl uncordon worker-node-1
```

**📊 升级进度跟踪**
```bash
# 查看升级进度
kubectl get nodes -o wide
# NAME            STATUS   VERSION
# master-node     Ready    v1.28.0  ← 已升级
# worker-node-1   Ready    v1.28.0  ← 已升级  
# worker-node-2   Ready    v1.27.0  ← 待升级
# worker-node-3   Ready    v1.27.0  ← 待升级
```

---

## 5. 🔍 集群健康检查体系


### 5.1 健康检查的重要性


**🔸 健康检查就像体检**
就像人需要定期体检一样，K8s集群也需要定期检查各个"器官"是否正常工作。

```
人体体检 vs K8s健康检查：
┌─────────────────┐    ┌─────────────────┐
│   人体体检      │    │  K8s健康检查    │
│                │    │                │
│ 心脏 ← 心跳正常  │    │ API Server ← 响应正常 │
│ 肺部 ← 呼吸顺畅  │    │ etcd ← 数据完整    │
│ 肝脏 ← 功能正常  │    │ Node ← 资源充足    │
│ 肾脏 ← 代谢良好  │    │ Pod ← 运行正常     │
└─────────────────┘    └─────────────────┘
```

### 5.2 基础健康检查命令


**🔧 日常检查命令套装**

```bash
# 1. 集群整体状态
kubectl cluster-info

# 2. 节点健康状态  
kubectl get nodes -o wide

# 3. 系统组件状态
kubectl get componentstatuses

# 4. 所有Pod状态
kubectl get pods --all-namespaces

# 5. 资源使用情况
kubectl top nodes
kubectl top pods --all-namespaces
```

### 5.3 详细健康检查指标


**📊 健康检查项目清单**

| 检查项目 | **检查命令** | **正常标准** | **异常处理** |
|---------|------------|-------------|-------------|
| 🖥️ **节点状态** | `kubectl get nodes` | `所有节点Ready` | `重启异常节点` |
| 🧠 **控制平面** | `kubectl get cs` | `所有组件Healthy` | `重启相关服务` |
| 📦 **Pod健康** | `kubectl get pods -A` | `无Pending/Error Pod` | `查看日志修复` |
| 💾 **存储状态** | `kubectl get pv,pvc` | `所有存储Bound` | `检查存储后端` |
| 🌐 **网络连通** | `kubectl get svc,endpoints` | `服务端点正常` | `检查网络插件` |

### 5.4 自动化健康检查脚本


**🤖 简单健康检查脚本**

```bash
#!/bin/bash
# k8s-health-check.sh

echo "🔍 K8s集群健康检查开始..."

# 检查节点状态
echo "📊 节点状态："
kubectl get nodes | grep -v Ready && echo "❌ 发现异常节点" || echo "✅ 所有节点正常"

# 检查系统Pod
echo "📦 系统Pod状态："
kubectl get pods -n kube-system | grep -E "(Error|Pending|CrashLoop)" && echo "❌ 发现异常Pod" || echo "✅ 系统Pod正常"

# 检查资源使用
echo "💻 资源使用情况："
kubectl top nodes | awk '{if(NR>1 && ($3>80 || $5>80)) print "❌ 节点 "$1" 资源使用过高"}'

echo "🎉 健康检查完成！"
```

---

## 6. 📋 版本兼容性管理


### 6.1 K8s版本兼容性原理


**🔸 版本兼容性就像软件更新**
就像手机app更新一样，新版本通常向后兼容老版本，但有时候也会淘汰一些老功能。

```
K8s版本兼容性规则：
┌─────────────────┐
│   版本 1.28     │ ← 最新版本
├─────────────────┤
│   版本 1.27     │ ← 完全兼容
├─────────────────┤  
│   版本 1.26     │ ← 兼容，部分API弃用
├─────────────────┤
│   版本 1.25     │ ← 部分功能可能不支持
└─────────────────┘
```

**💡 兼容性原则**
- **向后兼容1个版本**：1.28可以管理1.27的节点
- **API版本渐进淘汰**：老API先标记弃用，几个版本后删除
- **组件版本匹配**：kubectl、kubelet版本不能超过API Server

### 6.2 版本检查方法


**🔍 全面版本检查**

```bash
# 查看集群版本信息
kubectl version --output=yaml

# 查看各节点kubelet版本
kubectl get nodes -o custom-columns="NAME:.metadata.name,VERSION:.status.nodeInfo.kubeletVersion"

# 查看API版本支持情况
kubectl api-versions

# 检查弃用的API
kubectl api-resources --verbs=list --namespaced -o name | xargs -n 1 kubectl get --show-kind --ignore-not-found -o name
```

### 6.3 版本升级路径规划


**🛣️ 安全升级路径**

```
当前版本：1.25.0
目标版本：1.28.0

❌ 错误升级（跨度太大）：
1.25.0 ────────────→ 1.28.0  (可能出问题)

✅ 正确升级（逐步升级）：
1.25.0 → 1.26.0 → 1.27.0 → 1.28.0

每次升级间隔：建议1-2周，确保稳定运行
```

### 6.4 API版本管理


**📖 API版本生命周期**

| API状态 | **说明** | **操作建议** | **示例** |
|---------|---------|-------------|---------|
| 🟢 **Stable** | `稳定版本，可放心使用` | `优先选择` | `apps/v1` |
| 🟡 **Beta** | `测试版本，功能基本稳定` | `谨慎使用` | `batch/v1beta1` |
| 🔴 **Alpha** | `实验版本，随时可能变更` | `避免生产使用` | `networking.k8s.io/v1alpha1` |
| ⚠️ **Deprecated** | `已弃用，将来会删除` | `尽快迁移` | `extensions/v1beta1` |

**🔄 API迁移示例**

```yaml
# 老版本API（已弃用）
apiVersion: extensions/v1beta1
kind: Deployment

# 迁移到新版本API
apiVersion: apps/v1
kind: Deployment
```

---

## 7. 📋 核心要点总结


### 7.1 必须掌握的核心概念


```
🔸 节点维护三步曲：Cordon封锁 → Drain排空 → Uncordon解封
🔸 集群升级策略：备份先行、分批升级、滚动更新
🔸 健康检查体系：节点、组件、Pod、资源四个维度
🔸 版本兼容原则：逐步升级、API渐进淘汰、组件版本匹配
```

### 7.2 关键操作命令速查


**🔧 节点维护命令**
```bash
# 封锁节点
kubectl cordon <node-name>

# 排空节点  
kubectl drain <node-name> --ignore-daemonsets --delete-emptydir-data

# 解封节点
kubectl uncordon <node-name>
```

**📊 健康检查命令**
```bash
kubectl get nodes                    # 节点状态
kubectl get componentstatuses        # 组件状态
kubectl get pods --all-namespaces    # 所有Pod状态
kubectl top nodes                    # 资源使用情况
```

### 7.3 最佳实践要点


**🌟 维护最佳实践**
- ✅ **计划维护**：选择业务低峰期进行维护
- ✅ **分批操作**：不要同时维护多个节点
- ✅ **备份优先**：重要操作前必须备份
- ✅ **监控到位**：维护过程全程监控集群状态
- ✅ **测试验证**：维护后验证所有功能正常

**🚨 常见错误避免**
- ❌ 同时排空多个节点导致Pod无处调度
- ❌ 跨版本升级导致兼容性问题
- ❌ 维护前不备份导致数据丢失
- ❌ 强制删除Pod导致数据不一致

### 7.4 故障应急处理


**🆘 紧急情况处理流程**
```
1. 🔍 快速定位问题
   kubectl describe node <problem-node>
   
2. 🚨 隔离问题节点
   kubectl cordon <problem-node>
   
3. 🚑 迁移关键服务
   kubectl drain <problem-node> --force --ignore-daemonsets
   
4. 🔧 修复问题
   重启服务/更换硬件/修复配置
   
5. ✅ 验证恢复
   kubectl uncordon <problem-node>
   kubectl get nodes
```

**核心记忆**：
- 集群维护如工厂保养，安全第一不停产
- 封锁排空解封三步曲，维护节点有章法  
- 健康检查要定期，版本升级需谨慎
- 备份监控要到位，应急处理有预案