---
title: 3、亲和性反亲和性
---
## 📚 目录


1. [亲和性调度基础概念](#1-亲和性调度基础概念)
2. [节点亲和性(NodeAffinity)](#2-节点亲和性nodeaffinity)
3. [Pod亲和性(PodAffinity)](#3-pod亲和性podaffinity)
4. [Pod反亲和性(PodAntiAffinity)](#4-pod反亲和性podantiaffinity)
5. [硬性要求与软性偏好](#5-硬性要求与软性偏好)
6. [权重配置与优先级](#6-权重配置与优先级)
7. [拓扑域概念详解](#7-拓扑域概念详解)
8. [实战应用场景](#8-实战应用场景)
9. [核心要点总结](#9-核心要点总结)

---

# 🎯 **学习路径导航**


**前置知识**：需要掌握Pod基础、Node标签机制 → **当前内容**：亲和性反亲和性调度 → **后续学习**：建议学习污点容忍、资源限制

⏱️ **预计学习时间**：本章预计45分钟 | 实践操作30分钟

🎓 **学习目标**
- [ ] 理解亲和性调度的基本概念和作用
- [ ] 掌握节点亲和性的配置方法
- [ ] 学会Pod亲和性和反亲和性的应用
- [ ] 了解硬性要求和软性偏好的区别

---

## 1. 🎯 亲和性调度基础概念



### 1.1 什么是亲和性调度



**🔸 通俗理解**
想象你要安排学生住宿：
- **亲和性**：让好朋友住在同一个宿舍楼（喜欢在一起）
- **反亲和性**：让容易吵架的同学分开住（不能在一起）
- **节点亲和性**：学生对宿舍楼的偏好（我想住新楼）

**💡 Kubernetes中的含义**
```
亲和性调度：控制Pod被调度到哪些节点上的高级策略
目的：让应用更合理地分布在集群中
核心思想：根据节点特性或其他Pod位置来决定调度位置
```

### 1.2 亲和性调度的三大类型



**📋 类型对比**

| **类型** | **作用对象** | **主要用途** | **生活类比** |
|----------|-------------|-------------|-------------|
| **NodeAffinity** | `节点特性` | `根据节点标签选择` | `选择宿舍楼层` |
| **PodAffinity** | `其他Pod位置` | `与指定Pod靠近` | `和好友住一起` |
| **PodAntiAffinity** | `其他Pod位置` | `与指定Pod分离` | `避开不合适的室友` |

### 1.3 为什么需要亲和性调度



**🎯 解决的实际问题**
- **性能优化**：数据库和缓存部署在高性能节点
- **网络延迟**：相关服务部署在同一机架减少延迟
- **高可用性**：关键服务分散部署避免单点故障
- **资源隔离**：生产和测试环境分离部署

---

## 2. 🖥️ 节点亲和性(NodeAffinity)



### 2.1 节点亲和性基本概念



**💡 简单理解**
节点亲和性就像选房子：
- 我**必须**要有电梯的楼（硬性要求）
- 我**希望**靠近地铁站（软性偏好）
- 我**不要**一楼（反向选择）

**🔸 核心作用**
```
根据节点的标签(Label)来决定Pod部署位置
比nodeSelector更灵活，支持复杂的选择逻辑
可以设置硬性要求和软性偏好
```

### 2.2 硬性要求配置示例



**📝 必须满足的条件**
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: web-app-prod
spec:
  affinity:
    nodeAffinity:
#      # 硬性要求：调度时必须满足
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
#          # 必须部署在生产环境节点
          - key: environment
            operator: In
            values: ["production"]
#          # 必须有SSD存储
          - key: storage-type
            operator: In
            values: ["ssd"]
  containers:
  - name: web
    image: nginx:1.20
```

**🔍 配置解读**
- `requiredDuringScheduling`：调度时**必须满足**的条件
- `matchExpressions`：匹配表达式，支持多种操作符
- 如果没有满足条件的节点，Pod就会一直处于Pending状态

### 2.3 软性偏好配置示例



**📝 最好满足的条件**
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: web-app-flexible
spec:
  affinity:
    nodeAffinity:
#      # 软性偏好：优先考虑但不强制
      preferredDuringSchedulingIgnoredDuringExecution:
#      # 权重100：优先选择高性能节点
      - weight: 100
        preference:
          matchExpressions:
          - key: node-type
            operator: In
            values: ["high-performance"]
#      # 权重80：其次选择新节点
      - weight: 80
        preference:
          matchExpressions:
          - key: age
            operator: In
            values: ["new"]
  containers:
  - name: web
    image: nginx:1.20
```

### 2.4 操作符详解



**🔧 常用操作符说明**

| **操作符** | **含义** | **使用场景** | **示例** |
|-----------|---------|-------------|----------|
| `In` | `值在列表中` | `多选一` | `environment In [prod,staging]` |
| `NotIn` | `值不在列表中` | `排除某些值` | `zone NotIn [zone-a]` |
| `Exists` | `标签存在` | `只要有这个标签` | `gpu Exists` |
| `DoesNotExist` | `标签不存在` | `排除有某标签的节点` | `spot-instance DoesNotExist` |
| `Gt` | `数值大于` | `性能要求` | `cpu-cores Gt 4` |
| `Lt` | `数值小于` | `资源限制` | `memory Lt 16` |

---

## 3. 🤝 Pod亲和性(PodAffinity)



### 3.1 Pod亲和性基本概念



**💡 生活类比**
就像安排座位：
- 让**翻译**坐在**外国客人**旁边（服务配合）
- 让**前端开发**和**后端开发**坐在一起（协作方便）
- 让**数据库管理员**坐在**服务器机房**附近（就近管理）

**🔸 Kubernetes中的应用**
```
根据其他Pod的位置来决定当前Pod的部署位置
主要用于需要协作或数据共享的应用
通过标签选择器找到目标Pod，然后部署在相同区域
```

### 3.2 基础Pod亲和性配置



**📝 与特定Pod部署在一起**
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: web-frontend
spec:
  affinity:
    podAffinity:
#      # 硬性要求：必须与后端服务在同一节点
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: app
            operator: In
            values: ["backend-service"]
#        # 拓扑域：同一个节点
        topologyKey: "kubernetes.io/hostname"
  containers:
  - name: frontend
    image: nginx:1.20
```

**🎯 实际效果**
- 这个前端Pod**必须**和标签为`app=backend-service`的Pod部署在同一个节点上
- 如果后端服务不存在或没有合适的节点，前端Pod就无法调度

### 3.3 软性Pod亲和性配置



**📝 最好与特定Pod在一起**
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: cache-service
spec:
  affinity:
    podAffinity:
#      # 软性偏好：优先与数据库服务靠近
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchExpressions:
            - key: app
              operator: In
              values: ["database"]
#          # 拓扑域：同一个可用区
          topologyKey: "topology.kubernetes.io/zone"
  containers:
  - name: redis
    image: redis:6.2
```

---

## 4. 🚫 Pod反亲和性(PodAntiAffinity)



### 4.1 反亲和性基本概念



**💡 通俗解释**
反亲和性就像避免冲突：
- **同一个应用的多个副本**要分开部署（避免单点故障）
- **资源冲突的应用**不能在一起（比如两个占用大量CPU的应用）
- **安全隔离的需求**（生产和测试环境分离）

**🔸 主要应用场景**
- **高可用部署**：同一服务的副本分散到不同节点
- **资源冲突避免**：避免资源竞争激烈的应用部署在一起
- **安全隔离**：敏感应用与其他应用物理隔离

### 4.2 高可用反亲和性配置



**📝 实现应用高可用**
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-app-ha
spec:
  replicas: 3
  selector:
    matchLabels:
      app: web-app
  template:
    metadata:
      labels:
        app: web-app
    spec:
      affinity:
        podAntiAffinity:
#          # 硬性要求：同一应用的Pod不能在同一节点
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values: ["web-app"]
            topologyKey: "kubernetes.io/hostname"
      containers:
      - name: web
        image: nginx:1.20
```

**🎯 配置效果**
- 3个Pod副本**必须**分布在不同的节点上
- 确保任何单个节点故障都不会影响整个服务
- 如果节点数量不够，部分Pod会保持Pending状态

### 4.3 软性反亲和性配置



**📝 尽量避免部署在一起**
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: cpu-intensive-app
spec:
  replicas: 2
  selector:
    matchLabels:
      app: cpu-app
  template:
    metadata:
      labels:
        app: cpu-app
        type: cpu-intensive
    spec:
      affinity:
        podAntiAffinity:
#          # 软性偏好：尽量与其他CPU密集型应用分开
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: type
                  operator: In
                  values: ["cpu-intensive"]
              topologyKey: "kubernetes.io/hostname"
      containers:
      - name: app
        image: cpu-intensive-app:1.0
        resources:
          requests:
            cpu: 2000m
```

---

## 5. 💪 硬性要求与软性偏好



### 5.1 两种调度策略对比



**📊 核心区别**

| **维度** | **硬性要求(Required)** | **软性偏好(Preferred)** |
|---------|----------------------|----------------------|
| **执行力度** | `必须满足，否则不调度` | `优先考虑，但不强制` |
| **失败处理** | `Pod保持Pending状态` | `选择其他合适节点` |
| **使用场景** | `安全隔离、合规要求` | `性能优化、成本控制` |
| **配置复杂度** | `相对简单` | `需要设置权重` |

### 5.2 组合使用策略



**🎯 实际应用中的最佳实践**
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: business-app
spec:
  affinity:
    nodeAffinity:
#      # 硬性要求：必须在生产环境
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: environment
            operator: In
            values: ["production"]
#      # 软性偏好：优先选择高性能节点
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 80
        preference:
          matchExpressions:
          - key: node-type
            operator: In
            values: ["high-performance"]
    podAntiAffinity:
#      # 硬性要求：不与测试应用在同一节点
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: environment
            operator: In
            values: ["test"]
        topologyKey: "kubernetes.io/hostname"
  containers:
  - name: app
    image: business-app:1.0
```

### 5.3 策略选择指导



**🔍 何时使用硬性要求**
- **安全合规**：敏感数据必须在特定节点
- **资源保证**：关键应用必须有足够资源
- **物理隔离**：生产测试环境严格分离

**💡 何时使用软性偏好**
- **性能优化**：希望更好的性能但可以接受一般性能
- **成本控制**：优先使用便宜的节点但可以使用贵的
- **均匀分布**：希望负载均匀但允许一定程度的不均匀

---

## 6. ⚖️ 权重配置与优先级



### 6.1 权重机制原理



**💡 权重就像打分系统**
想象Kubernetes是一个房屋中介：
- **权重100**：这个要求很重要（90-100分）
- **权重50**：这个要求比较重要（40-60分）
- **权重10**：这个要求不太重要（5-15分）

最后选择**总分最高**的节点来部署Pod

### 6.2 多权重配置示例



**📝 复杂权重配置**
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: smart-scheduling-app
spec:
  affinity:
    nodeAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
#      # 最重要：优先选择SSD节点（权重100）
      - weight: 100
        preference:
          matchExpressions:
          - key: storage-type
            operator: In
            values: ["ssd"]
#      # 比较重要：优先选择新节点（权重70）
      - weight: 70
        preference:
          matchExpressions:
          - key: node-age
            operator: In
            values: ["new"]
#      # 一般重要：优先选择低负载节点（权重50）
      - weight: 50
        preference:
          matchExpressions:
          - key: load-level
            operator: In
            values: ["low"]
#      # 次要：优先选择便宜的节点（权重20）
      - weight: 20
        preference:
          matchExpressions:
          - key: cost-tier
            operator: In
            values: ["cheap"]
  containers:
  - name: app
    image: my-app:1.0
```

**🎯 调度计算过程**
假设有三个节点候选：

```
节点A: SSD(100分) + 旧(0分) + 低负载(50分) + 贵(0分) = 150分
节点B: HDD(0分) + 新(70分) + 高负载(0分) + 便宜(20分) = 90分  
节点C: SSD(100分) + 新(70分) + 中负载(0分) + 中等(0分) = 170分

结果：选择节点C（总分最高）
```

### 6.3 权重设置最佳实践



**🎯 权重分配建议**

| **优先级** | **权重范围** | **使用场景** | **示例** |
|-----------|-------------|-------------|----------|
| **最高** | `80-100` | `核心业务需求` | `高性能存储、安全区域` |
| **高** | `60-79` | `重要但非必须` | `较新节点、低延迟网络` |
| **中** | `40-59` | `性能优化` | `负载均衡、成本优化` |
| **低** | `20-39` | `次要考虑` | `节点标识、统计信息` |
| **最低** | `1-19` | `微调细节` | `调试信息、元数据` |

---

## 7. 🌐 拓扑域概念详解



### 7.1 拓扑域基础概念



**💡 拓扑域就像地址层级**
```
国家 > 省份 > 城市 > 区域 > 街道 > 楼栋 > 房间

Kubernetes拓扑域：
集群 > 可用区 > 节点 > Pod
```

**🔸 常用拓扑域标签**
- `kubernetes.io/hostname`：节点级别（最小范围）
- `topology.kubernetes.io/zone`：可用区级别（中等范围）
- `topology.kubernetes.io/region`：区域级别（最大范围）

### 7.2 拓扑域选择策略



**📊 不同拓扑域的影响范围**

| **拓扑域** | **影响范围** | **使用场景** | **示例效果** |
|-----------|-------------|-------------|-------------|
| **hostname** | `单个节点` | `性能要求高、资源共享` | `前后端部署在同一台服务器` |
| **zone** | `可用区级别` | `容灾、网络延迟优化` | `数据库主从分布在不同机房` |
| **region** | `地理区域` | `全球部署、法规遵循` | `欧洲用户数据只在欧洲处理` |

### 7.3 拓扑域实战配置



**📝 多层次拓扑域配置**
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: multi-tier-app
spec:
  replicas: 6
  selector:
    matchLabels:
      app: multi-tier
  template:
    metadata:
      labels:
        app: multi-tier
    spec:
      affinity:
        podAntiAffinity:
#          # 硬性要求：不同可用区分布（容灾）
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values: ["multi-tier"]
            topologyKey: "topology.kubernetes.io/zone"
#          # 软性偏好：同一可用区内分散到不同节点（性能）
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values: ["multi-tier"]
              topologyKey: "kubernetes.io/hostname"
      containers:
      - name: app
        image: multi-tier-app:1.0
```

**🎯 配置效果分析**
```
假设集群有3个可用区，每个区2个节点：

期望分布：
可用区A: 节点1(1个Pod) + 节点2(1个Pod) = 2个Pod
可用区B: 节点3(1个Pod) + 节点4(1个Pod) = 2个Pod  
可用区C: 节点5(1个Pod) + 节点6(1个Pod) = 2个Pod

总计：6个Pod均匀分布，既保证容灾又保证性能
```

---

## 8. 🎪 实战应用场景



### 8.1 微服务应用架构



**🏗️ 电商系统部署策略**
```yaml
# 前端服务：与网关服务亲和

apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend-service
spec:
  replicas: 3
  template:
    spec:
      affinity:
        podAffinity:
#          # 与网关服务部署在同一可用区（减少延迟）
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 80
            podAffinityTerm:
              labelSelector:
                matchLabels:
                  app: api-gateway
              topologyKey: "topology.kubernetes.io/zone"
        podAntiAffinity:
#          # 前端服务副本分散部署（高可用）
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app: frontend-service
            topologyKey: "kubernetes.io/hostname"
      containers:
      - name: frontend
        image: ecommerce-frontend:1.0
---
# 数据库服务：高性能节点 + 反亲和部署

apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: database-cluster
spec:
  replicas: 3
  template:
    spec:
      affinity:
        nodeAffinity:
#          # 必须部署在高性能存储节点
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: storage-type
                operator: In
                values: ["ssd"]
              - key: node-type
                operator: In
                values: ["high-memory"]
        podAntiAffinity:
#          # 数据库副本必须分散到不同可用区
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app: database-cluster
            topologyKey: "topology.kubernetes.io/zone"
      containers:
      - name: mysql
        image: mysql:8.0
```

### 8.2 大数据处理场景



**📊 数据分析集群配置**
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spark-workers
spec:
  replicas: 6
  template:
    spec:
      affinity:
        nodeAffinity:
#          # 优先选择计算节点
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            preference:
              matchExpressions:
              - key: workload-type
                operator: In
                values: ["compute-intensive"]
#          # 优先选择大内存节点  
          - weight: 80
            preference:
              matchExpressions:
              - key: memory-size
                operator: In
                values: ["large", "xlarge"]
        podAffinity:
#          # 与数据存储服务靠近（减少网络传输）
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 60
            podAffinityTerm:
              labelSelector:
                matchLabels:
                  app: hdfs-datanode
              topologyKey: "topology.kubernetes.io/zone"
        podAntiAffinity:
#          # Worker节点尽量分散（负载均衡）
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 50
            podAffinityTerm:
              labelSelector:
                matchLabels:
                  app: spark-workers
              topologyKey: "kubernetes.io/hostname"
      containers:
      - name: spark-worker
        image: spark:3.2.0
```

### 8.3 生产测试环境隔离



**🔒 环境隔离最佳实践**
```yaml
# 生产应用配置

apiVersion: v1
kind: Pod
metadata:
  name: prod-payment-service
  labels:
    app: payment-service
    environment: production
spec:
  affinity:
    nodeAffinity:
#      # 硬性要求：必须在生产节点
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: environment
            operator: In
            values: ["production"]
#          # 必须在合规节点（满足安全要求）
          - key: compliance
            operator: In
            values: ["pci-dss"]
    podAntiAffinity:
#      # 硬性要求：不与任何测试应用在同一节点
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: environment
            operator: In
            values: ["test", "development"]
        topologyKey: "kubernetes.io/hostname"
#      # 软性偏好：支付服务分散部署
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchLabels:
              app: payment-service
          topologyKey: "kubernetes.io/hostname"
  containers:
  - name: payment
    image: payment-service:prod-1.2.0
```

---

## 9. 📋 核心要点总结



### 9.1 必须掌握的核心概念



```
🔸 亲和性调度：让Pod智能地选择部署位置的调度策略
🔸 节点亲和性：根据节点标签特性选择部署节点
🔸 Pod亲和性：让相关Pod部署在一起，提升协作效率
🔸 Pod反亲和性：让Pod分散部署，提高可用性和避免冲突
🔸 硬性要求：必须满足的调度条件，不满足就不调度
🔸 软性偏好：优先考虑的调度条件，通过权重评分选择最佳节点
🔸 拓扑域：定义"在一起"或"分开"的物理/逻辑范围
```

### 9.2 关键理解要点



**🔹 为什么需要亲和性调度**
```
默认调度的问题：
- 只考虑资源够不够，不考虑业务需求
- 可能把相关服务分得很远，影响性能
- 可能把同一服务的副本放在一起，存在单点故障风险

亲和性调度的价值：
- 性能优化：相关服务部署在一起减少网络延迟
- 高可用保障：关键服务分散部署避免单点故障
- 资源合理利用：根据应用特性选择合适的节点
- 合规要求：满足安全、法规等特殊部署要求
```

**🔹 硬性要求 vs 软性偏好的选择**
```
硬性要求适用场景：
- 安全合规：敏感数据必须在特定区域
- 资源依赖：必须有GPU的节点才能运行AI应用
- 环境隔离：生产和测试绝对不能混部

软性偏好适用场景：
- 性能优化：希望更快但能接受稍慢
- 成本控制：优先便宜的但必要时用贵的
- 负载均衡：希望分散但允许一定程度集中
```

**🔹 拓扑域的理解技巧**
```
拓扑域就像划分"影响范围"：
- hostname：房间级别（最小范围，性能最优）
- zone：楼栋级别（中等范围，平衡性能和容灾）
- region：城市级别（最大范围，主要用于容灾和合规）

选择原则：
- 需要高性能协作 → 选择小范围（hostname）
- 需要容灾保护 → 选择大范围（zone/region）
- 需要负载均衡 → 根据集群规模选择合适范围
```

### 9.3 实际应用指导



**🎯 配置策略建议**
- **Web应用**：前端与后端亲和 + 副本反亲和
- **数据库**：高性能节点亲和 + 跨区域反亲和
- **缓存服务**：与应用亲和 + 节点分散反亲和
- **批处理**：计算节点亲和 + 与在线服务反亲和

**⚠️ 常见配置误区**
```
误区1：所有应用都用硬性要求
正确：优先使用软性偏好，只在必要时用硬性要求

误区2：权重设置过于复杂
正确：区分3-4个优先级即可，不要设置太多层次

误区3：拓扑域选择不当  
正确：根据实际需求选择合适的拓扑域范围

误区4：忽略节点资源容量
正确：设置亲和性的同时要考虑节点能否承载
```

### 9.4 学习检查清单



- [ ] 理解亲和性调度的三种类型和基本作用
- [ ] 能够配置节点亲和性选择合适的部署节点
- [ ] 掌握Pod亲和性让相关服务部署在一起
- [ ] 会用Pod反亲和性实现高可用部署
- [ ] 理解硬性要求和软性偏好的区别和使用场景
- [ ] 能够合理设置权重实现智能调度
- [ ] 掌握拓扑域概念并能正确选择拓扑域范围

**🔑 核心记忆口诀**
> 亲和靠近反分离，节点Pod级要分清
> 硬性必须软优先，权重打分选最优  
> 拓扑域名定范围，hostname zone region记
> 性能容灾巧平衡，业务需求是核心

**💡 延伸学习建议**
- 学习污点(Taint)和容忍(Toleration)机制
- 了解资源配额和限制范围(LimitRange)
- 研究自定义调度器的实现方法
- 实践多集群联邦调度的高级特性