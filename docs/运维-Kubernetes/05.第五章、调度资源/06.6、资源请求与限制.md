---
title: 6、资源请求与限制
---
## 📚 目录

1. [资源管理基础概念](#1-资源管理基础概念)
2. [CPU资源管理详解](#2-CPU资源管理详解)
3. [内存资源管理详解](#3-内存资源管理详解)
4. [资源请求requests机制](#4-资源请求requests机制)
5. [资源限制limits机制](#5-资源限制limits机制)
6. [资源超卖与调度策略](#6-资源超卖与调度策略)
7. [OOMKilled问题处理](#7-OOMKilled问题处理)
8. [核心要点总结](#8-核心要点总结)

---

## 1. 💡 资源管理基础概念


### 1.1 什么是Kubernetes资源管理


> **💡 通俗理解**
> 
> 想象你是一个酒店经理，需要合理分配房间给客人：
> - **资源请求(requests)**：客人预订时说"我至少需要一间标准房"
> - **资源限制(limits)**：酒店规定"每位客人最多只能要总统套房"
> - **调度器**：酒店前台根据房间情况安排客人住宿

**🔍 核心概念解析**：

```
Kubernetes资源管理 = 合理分配集群计算资源

主要管理的资源类型：
┌─────────────────┐
│   CPU资源       │ ← 计算处理能力
├─────────────────┤
│   内存资源      │ ← 存储临时数据
├─────────────────┤
│   存储资源      │ ← 持久化数据
├─────────────────┤
│   网络资源      │ ← 带宽和端口
└─────────────────┘
```

### 1.2 为什么需要资源管理


**🎯 解决的核心问题**：

| 问题场景 | **没有资源管理** | **有了资源管理** | **实际效果** |
|---------|-----------------|-----------------|-------------|
| 🏃 **资源竞争** | `多个应用抢占CPU，相互影响` | `每个应用都有保证的资源` | `性能稳定可预期` |
| 💥 **资源耗尽** | `一个应用占满内存，其他崩溃` | `限制单个应用最大使用量` | `系统整体稳定` |
| 🎲 **调度混乱** | `不知道节点能否运行新应用` | `调度器精确计算资源需求` | `合理分配工作负载` |
| 📊 **资源浪费** | `申请了大量资源却不使用` | `按需申请，提高利用率` | `成本优化` |

---

## 2. ⚡ CPU资源管理详解


### 2.1 CPU资源单位详解


> **🧠 生活类比**
>
> CPU就像餐厅的厨师：
> - **1个CPU核心** = 1个专业厨师
> - **500m CPU** = 半个厨师的工作能力
> - **2000m CPU** = 2个厨师的工作能力

**📊 CPU单位换算表**：

```
CPU单位换算关系：

1 CPU = 1000m (毫核)
├─ 100m  = 0.1个CPU核心  ← 轻量级应用
├─ 500m  = 0.5个CPU核心  ← 中等应用  
├─ 1000m = 1个完整CPU核心 ← 计算密集应用
└─ 2000m = 2个CPU核心    ← 高性能应用

实际理解：
500m CPU = 在任意1秒内，最多使用0.5秒的CPU时间
```

### 2.2 CPU调度原理


**🔄 CPU调度工作流程**：

```
Pod请求CPU流程：

用户提交Pod → 调度器检查节点 → 分配CPU时间片 → 监控使用情况
     ↓              ↓                ↓              ↓
   声明需求      计算可用资源       CFS调度算法     超限时限流
```

**⚖️ CPU资源分配机制**：

```yaml
# CPU资源配置示例
resources:
  requests:
    cpu: "500m"      # 保证至少500m CPU
  limits:
    cpu: "1000m"     # 最多使用1000m CPU
```

**💭 实际运行效果**：

```
CPU使用情况分析：

正常情况：Pod使用500m-1000m之间的CPU
├─ 空闲时：可能只用200m（低于requests也没问题）
├─ 繁忙时：可以用到1000m（上限是limits）
└─ 超限时：被内核限流，不会分配更多CPU时间

注意：CPU是可压缩资源，不会因为超限被杀死！
```

---

## 3. 💾 内存资源管理详解


### 3.1 内存资源单位详解


> **🏠 生活类比**
>
> 内存就像房子的空间：
> - **1Gi内存** = 一个标准房间
> - **512Mi内存** = 半个房间的存储空间
> - **用完了** = 房间装不下了，必须清理或搬走

**📊 内存单位换算表**：

```
内存单位换算（二进制）：
1Ki = 1024 bytes
1Mi = 1024 Ki = 1,048,576 bytes
1Gi = 1024 Mi = 1,073,741,824 bytes

内存单位换算（十进制）：
1k = 1000 bytes
1M = 1000 k = 1,000,000 bytes  
1G = 1000 M = 1,000,000,000 bytes

推荐使用：Mi、Gi（更精确）
```

### 3.2 内存管理特点


**⚠️ 内存 vs CPU 的关键区别**：

| 特性 | **CPU资源** | **内存资源** | **影响** |
|------|-------------|-------------|----------|
| 🔄 **可压缩性** | `可压缩` | `不可压缩` | `CPU可以限流，内存不行` |
| 💥 **超限后果** | `性能下降` | `进程被杀死` | `内存超限风险更大` |
| 📊 **回收机制** | `时间片结束自动回收` | `需要程序主动释放` | `内存泄漏影响更严重` |
| ⏱️ **释放速度** | `立即生效` | `可能需要GC` | `内存释放有延迟` |

```yaml
# 内存资源配置示例
resources:
  requests:
    memory: "256Mi"    # 保证至少256Mi内存
  limits:
    memory: "512Mi"    # 最多使用512Mi内存
```

---

## 4. 🎯 资源请求requests机制


### 4.1 requests的核心作用


> **🎪 预订座位的比喻**
>
> requests就像提前预订演唱会座位：
> - **预订了座位**：保证你有地方坐（资源保证）
> - **可能坐得更舒服**：如果旁边没人，可以放东西（可以用更多资源）
> - **不能没收座位**：预订的座位一定属于你（调度器承诺）

**🔍 requests的三大功能**：

```
功能1：调度决策
┌─────────────────────┐
│   调度器工作流程     │
├─────────────────────┤
│ 1. 收到Pod调度请求   │
│ 2. 检查各节点资源    │
│ 3. 找出满足requests  │
│    要求的节点       │
│ 4. 选择最合适节点    │
└─────────────────────┘

功能2：资源预留
节点总资源: 4核8Gi
已分配requests: 2核4Gi  
剩余可调度: 2核4Gi ← 新Pod看这个数字

功能3：QoS分级
Guaranteed > Burstable > BestEffort
└─ 有requests的Pod优先级更高
```

### 4.2 requests配置最佳实践


**📋 配置策略指南**：

```yaml
# 推荐的requests配置
apiVersion: v1
kind: Pod
spec:
  containers:
  - name: web-app
    resources:
      requests:
        cpu: "200m"      # 基础负载需要的CPU
        memory: "256Mi"   # 启动和基本运行需要的内存
      limits:
        cpu: "500m"      # 高峰期可能需要的CPU  
        memory: "512Mi"   # 最大内存使用量
```

**💡 requests设置技巧**：

- **🎯 CPU requests**：设置为平均负载的80%
- **🎯 Memory requests**：设置为启动内存 + 基础运行内存
- **🎯 不要设置过大**：浪费集群资源
- **🎯 不要设置过小**：可能影响调度和性能

---

## 5. 🚫 资源限制limits机制


### 5.1 limits的保护作用


> **🏎️ 限速器的比喻**
>
> limits就像汽车的限速器：
> - **防止超速**：保护自己不出事故（防止资源滥用）
> - **保护他人**：不影响其他车辆行驶（保护其他Pod）
> - **遵守规则**：符合交通规则（集群资源管理）

**⚡ limits的工作机制**：

```
CPU limits工作原理：
应用请求CPU → 内核CFS调度 → 达到limits时限流
     ↓              ↓              ↓
   正常运行     按时间片分配    暂停一段时间

内存limits工作原理：
应用申请内存 → 内核检查使用量 → 超过limits时杀死进程
     ↓              ↓                ↓
   正常分配      监控RSS内存      发送OOMKilled信号
```

### 5.2 limits设置策略


**📊 limits配置建议**：

| 应用类型 | **CPU limits建议** | **Memory limits建议** | **原因** |
|---------|-------------------|---------------------|----------|
| 🌐 **Web应用** | `requests的2-3倍` | `requests的1.5-2倍` | `突发流量需要更多CPU` |
| 📊 **数据库** | `requests的1.5倍` | `requests的1.2倍` | `内存使用相对稳定` |
| 🔄 **批处理** | `不设置或设置很大` | `必须设置合理值` | `CPU可以充分利用，内存需要控制` |
| 🎯 **微服务** | `requests的2倍` | `requests的1.5倍` | `轻量级，但需要处理突发请求` |

---

## 6. 📈 资源超卖与调度策略


### 6.1 什么是资源超卖


> **✈️ 航空公司超卖的类比**
>
> 资源超卖就像航空公司卖票：
> - **超卖机制**：卖了110张票，但飞机只有100座位
> - **统计规律**：通常有10%的人不会来
> - **风险控制**：如果都来了，需要有应对方案
> - **经济效益**：提高了座位利用率

**🔍 Kubernetes超卖机制**：

```
超卖工作原理：

节点实际资源: 4核8Gi
├─ 所有Pod requests总和: 6核12Gi  ← 超卖了！
├─ 实际使用情况: 3核6Gi          ← 通常用不满
└─ 调度器决策: 基于requests调度   ← 可能调度失败

为什么可以超卖：
┌─────────────────────┐
│   应用实际使用特点   │
├─────────────────────┤
│ • 很少用满requests   │
│ • 使用量有波峰波谷   │  
│ • CPU可以时间共享    │
│ • 提高整体利用率     │
└─────────────────────┘
```

### 6.2 QoS服务质量等级


**🏆 QoS等级详解**：

```yaml
# Guaranteed（最高优先级）
# requests = limits，资源有严格保证
resources:
  requests:
    cpu: "500m"
    memory: "1Gi"
  limits:
    cpu: "500m"      # 与requests相等
    memory: "1Gi"    # 与requests相等

# Burstable（中等优先级） 
# 设置了requests，但limits > requests
resources:
  requests:
    cpu: "200m"
    memory: "256Mi"
  limits:
    cpu: "500m"      # 大于requests
    memory: "512Mi"   # 大于requests

# BestEffort（最低优先级）
# 没有设置requests和limits
# 没有resources字段
```

**⚖️ QoS等级影响**：

| QoS等级 | **资源保证** | **被杀死优先级** | **适用场景** |
|---------|-------------|----------------|-------------|
| 🥇 **Guaranteed** | `严格保证` | `最后被杀死` | `核心业务，数据库` |
| 🥈 **Burstable** | `部分保证` | `中等优先级` | `一般应用，Web服务` |
| 🥉 **BestEffort** | `无保证` | `首先被杀死` | `批处理，测试任务` |

---

## 7. 💀 OOMKilled问题处理


### 7.1 什么是OOMKilled


> **🏠 房间装不下的比喻**
>
> OOMKilled就像房间装满了东西：
> - **Out Of Memory**：房间空间用完了
> - **Killed**：不得不把一些东西扔掉
> - **选择标准**：通常扔掉最不重要或最占地方的

**🔍 OOMKilled发生流程**：

```
OOMKilled触发流程：

Pod内存使用增长 → 达到limits限制 → 内核OOM Killer → 杀死进程
       ↓                ↓               ↓            ↓
   应用申请更多内存    超过配置限制    系统保护机制    Pod重启
```

### 7.2 OOMKilled的识别与诊断


**🔍 查看OOMKilled状态**：

```bash
# 查看Pod状态
kubectl get pods
# 输出示例：
# NAME     READY   STATUS      RESTARTS   AGE
# my-app   0/1     OOMKilled   3          5m

# 查看详细事件
kubectl describe pod my-app
# 关键信息：
#   State:        Terminated
#   Reason:       OOMKilled
#   Exit Code:    137
```

**📊 监控内存使用趋势**：

```bash
# 实时查看资源使用
kubectl top pod my-app

# 查看历史使用情况（需要监控系统）
# Grafana看板显示内存使用曲线
内存使用量
    ▲
512Mi ├─────────────────●── limits限制线
    │                 /│
256Mi ├──────●────────/ │── requests保证线
    │     /│         /  │
    │    / │        /   │
    │   /  │       /    │
    └──●───┴──────┴────┴─→ 时间
     启动  运行    高峰  OOM
```

### 7.3 OOMKilled解决方案


**🛠️ 解决策略矩阵**：

| 问题原因 | **解决方案** | **配置调整** | **代码优化** |
|---------|-------------|-------------|-------------|
| 🎯 **limits太小** | `适当增加memory limits` | `limits: "1Gi"` | `无需改动` |
| 💧 **内存泄漏** | `修复代码内存泄漏` | `临时增加limits` | `检查对象释放` |
| 📊 **数据量大** | `优化数据处理逻辑` | `增加limits和requests` | `分批处理数据` |
| ⚡ **突发负载** | `设置合理的resources` | `增加limits，保持requests` | `实现优雅降级` |

**📋 标准解决流程**：

```yaml
# 第一步：调整资源配置
resources:
  requests:
    memory: "512Mi"    # 适当提高requests
  limits:
    memory: "1Gi"      # 给予更多内存空间

# 第二步：添加监控告警
# 在Prometheus中配置内存使用率告警
# 当使用率超过80%时提前预警

# 第三步：应用层面优化
# • 增加内存释放逻辑
# • 实现对象池复用
# • 分批处理大数据
# • 添加内存使用监控日志
```

---

## 8. 📋 核心要点总结


### 8.1 必须掌握的核心概念


```
🔸 资源请求(requests)：调度器保证的最小资源，用于调度决策
🔸 资源限制(limits)：容器能使用的最大资源，防止资源滥用  
🔸 CPU单位：1CPU = 1000m，CPU是可压缩资源
🔸 内存单位：推荐使用Mi/Gi，内存是不可压缩资源
🔸 QoS等级：Guaranteed > Burstable > BestEffort
🔸 OOMKilled：内存超限时容器被杀死重启
```

### 8.2 关键理解要点


**🔹 requests与limits的关系**
```
最佳配置原则：
• requests：设置为平均需求
• limits：设置为峰值需求的1.2-2倍
• 避免差距过大导致资源浪费
• 避免设置过小导致性能问题
```

**🔹 CPU与内存的区别**
```
关键差异：
• CPU超限：被限流，性能下降，不会死亡
• 内存超限：被杀死，Pod重启，可能数据丢失
• CPU可以超卖，内存需要谨慎分配
```

**🔹 资源管理策略**
```
生产环境建议：
• 核心应用：使用Guaranteed QoS
• 一般应用：使用Burstable QoS  
• 测试应用：可以使用BestEffort QoS
• 监控资源使用，定期优化配置
```

### 8.3 实际应用指导


**🎯 新手配置建议**：
```yaml
# 保守但安全的配置
resources:
  requests:
    cpu: "100m"      # 从小开始，观察实际使用
    memory: "128Mi"   # 保证基本运行
  limits:
    cpu: "500m"      # 给予足够突发能力
    memory: "256Mi"   # 防止OOM，但不浪费
```

**📊 监控指标关注点**：
- **CPU使用率**：长期超过80%考虑增加resources
- **内存使用率**：超过limits的80%需要警惕
- **Pod重启次数**：频繁重启可能是OOMKilled
- **调度失败**：可能是requests设置过高

**🔧 常见问题解决**：
- **调度失败**：检查requests是否过大，或集群资源不足
- **性能下降**：可能CPU被限流，检查CPU使用情况
- **频繁重启**：很可能是内存OOM，增加memory limits
- **资源浪费**：监控实际使用，适当降低limits

**核心记忆口诀**：
- requests保调度，limits防滥用
- CPU可压缩，内存要小心
- 监控很重要，调优要及时
- 从小开始配，逐步来优化